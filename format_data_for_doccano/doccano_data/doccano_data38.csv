"No one enjoys choking on smog, but are more trees really the answer for polluted city air? It’s not as clear-cut as you might think. Air pollution is clearly a problem for health and well-being – and as more and more people across the world move to live in megacities, they could miss out on the fresh air associated with the green countryside. So far, many strategies have been put in place to try and mitigate urban air pollution: from introducing congestion charges  to imposing car bans, promoting electric vehicles to providing more car-free zones. One group has even suggested making London a “national park city”. If you can’t escape to the countryside, then you can instead bring the countryside feel to the city. Urban planners seem to be increasingly focused on promoting more green spaces in our towns and cities, creating a truly “urban jungle”. Why not? After all, trees really do make you feel better, according to recent research published in the journal Scientific Reports. The study, in Canada, found ten extra trees in a city block meant local people’s health perceptions improved an amount comparable to being given a US$10,000 raise or suddenly being seven years younger. One of the reasons for this, the researchers suggested, was that “trees reduce air pollution”. No one can deny that finding a quiet space in a bustling city is challenging, and that city parks offer a place for you to catch a breath of fresh air. Thus given how trees improve our wellbeing, supporting the concept of making a city greener seems like a no-brainer … right? Work in which I have been involved considers how air flows in and around city streets, dispersing vehicle emissions on innocent pedestrians and cyclists. If you consider any wall, parked cars, hedges or trees as barriers that cause the natural pattern of air flow to be diverted, then you can see how trees may not always point transport pollutants in the “right” direction. On the extreme side of things, your typical street with avenue trees, can almost lead to a “green” roof effect, when the canopy in full bloom. This can prevent pollutants from escaping the street and air quality can be greatly impacted. In less extreme circumstances, a single tree in a street corner may break the wind flow and lead to pollution dropping into the breathing zone of pedestrians walking by. To cut a long story short, trees can be as detrimental to air quality as a Slipknot concert in your apartment is to noise pollution. It’s all about their location. Carbon dioxide is usually labelled as the “bad guy”, and it is – in terms of climate change at least. However when it comes to our health the range of other pollutants emitted from cars such as nitrogen oxides (NOx) and particulate matter (PM) present the greatest risk. Young children, the sick and the elderly are particularly vulnerable to harmful gases and particles released by fuel combustion in cars, lorries and buses. Whatever impact trees may have on reducing carbon dioxide in cities, how they may, or may not, control these other pollutants is not too clear. The importance of trees is not in question, as protecting our green spaces is vital for the environment on a global scale. However, if we choose to plant trees in our city streets, at a local level, the outcome on air quality may be somewhat different. It is important to consider the type of tree you wish to plant, the shape of the street, what direction the wind blows, and where your pollutant source (cars) and receptors (pedestrians) are located. Work by a Belgian research group entitled “Improving local air quality in cities: to tree or not to tree?” (… that is the question) sums things up. Sometimes, planting trees in cities is driven by people who may be informed of the benefits, but not all of the facts. I just want to make sure all the facts are looked at to make a well-informed decision. It’s what research is about. It is the responsibility of urban planners and local authorities to ensure trees are not just planted where they look nice, but perhaps where they can do more good than bad for air quality on city footpaths. I’m in no way saying trees in cities are bad, they do add some colour to our otherwise grey landscape, but I will say that “terms and conditions apply”. Before planting those urban trees, make sure you read the small print."
"Although Tesla’s Powerwall battery storage is likely to be a disruptive force for electrical energy systems around the world, it is not going to supplant the major forms of electrical energy storage anytime soon, and is ill-suited to storing energy over longer timeframes such as between seasons. When powering a modern economy, electrical energy comes with one major disadvantage – it requires that supply and demand must be balanced within strict limits at all times, as an imbalance will lead to voltage changes that can damage connected equipment and even the networks themselves. This challenge of network balancing has conventionally been managed by keeping the electricity “stored” in fossil or nuclear fuels until it is required.  This presents a storage problem for renewables, especially weather-dependent wind and solar. As we cannot hope to store the weather, we have to instead store the generator’s output, which is the electricity. This is what Tesla’s Powerwall and the bigger Powerpack both intend to help with. At full capacity Tesla’s first Gigafactory is planned to produce batteries totalling 35 GWhe (gigawatthours electrical) each year. It’s an impressive figure – enough to power England, Scotland and Wales for about an hour. However, to put this into perspective, Great Britain (Northern Ireland is counted separately) stores on average 800 times as much energy in its coal stockpiles alone. The chart below shows the total electrical energy equivalent stored in its coal stockpiles over the past two decades, with the amount stored tending to peak each autumn in preparation for an increase of electrical demand over winter. (The 2009 spike was partly caused by power plants stocking up on cheap coal after the financial crash). Over these two decades Great Britain has averaged just over 30,000GWhe of electrical energy stored this way. Great Britain also has up to 32,000GWh of natural gas in long-term storage (which dropped from 41,400GWh earlier this year). While most is used directly for cooking or heating, the rest is consumed to make electricity. It’s tough to know exactly what proportion this is, since it’s difficult to apportion gas that came directly from storage as opposed to gas that came via liquified natural gas ships or through pipelines. However if we estimated that 30% ends up in power plants with an efficiency of 50% then the electrical energy stored is around 4,800GWhe. Again, far more than Tesla’s Gigafactory annual 35GWhe output. It’s even harder to tell how much energy is stored in Great Britain’s reserves of nuclear fuels of uranium and plutonium – the information is classified. These simple calculations show Great Britain remains overwhelmingly dependent on fossil fuels to store its electrical energy. The country needed nearly 800 GWhe of electrical energy in an average day last year, which suggests that batteries would have some way to go to supplant fuels, even for a day. This storage of vast amounts of energy in fossil fuels is typical of many modern economies as we have become accustomed to the flexibility that they allow us; they are able to decouple supply from demand by location as well as by time, and at a phenomenally low cost for storage. Regardless of the falling price of batteries (Tesla’s or anyone else’s) they are always likely to be ill-suited to the long-term seasonal storage of thousands of GWhs of energy. Batteries are simply the wrong technology. But the fuels we mainly rely on for electrical storage – coal and gas – are not ultimately sustainable, and contribute to increased CO2 emissions if burned without carbon capture. So if fossil fuels and batteries are not the answer to the seasonal storage of electricity – what is? Carbon capture and storage holds out the promise of the continued use of fossil fuels, with all the fuel storage advantages this would allow. Additionally, fuels such as hydrogen or synthetic methane could be generated using low-cost, low-carbon energy and stored at scale too.  A continued use of fuels isn’t necessarily competition for Tesla’s disruptive new battery packs; the two complement each other. They are different horses for courses, as not all energy storage is the same, and in the long run we are going to require both. Tesla’s batteries aren’t about to take over the world just yet, especially if you count fuels as “energy storage”. But if the company goes on to produce a similarly disruptive force in the area of power-generated fuels, that really would be a gamechanger. Lets hope it or some other firm does soon – then we would truly have the components to decouple our economies from carbon emissions."
nan
"
Share this...FacebookTwitter 

A remarkably unsophisticated paper was published a few months ago curiously entitled Internet Blogs, Polar Bears, and Climate-Change Denial by Proxy.  Among the list of co-authors of Harvey et al. (2017) are two rather familiar names in climate science circles: Michael E. Mann and Stephan Lewandowsky.
The 14 authors liberally utilize name-calling and broad-brushed accusation (i.e., “unsubstantiated opinions of climate-change deniers”) to make the claim that “climate-change deniers” have no scientific backing for their “opinions”, and so they consequently use the same scare-mongering rhetorical devices and tactics as creationism apologists to advance their cause.
“Proponents of creationism and intelligent design use the same strategy [as climate-change deniers]: Instead of providing scientific evidence in favor of their opinions, they instead focus selectively on certain lines of evidence for evolution and attempt to cast doubt on them (Nisbet 2009).”
“Rhetorical devices to evoke fear and other emotions, such as implying that the public is under threat from deceitful scientists, are common tactics employed by science-denier groups (Barry et al. 2008).”
The purpose of their paper is to make the case that widely-read “denier blogs” like Watts Up With That and Climate Depot have cherry-picked an anthropogenic global warming (AGW) icon, the polar bear, and then proceeded to hand-wave by denying the “well established” science that says these bears’ survival and ability to obtain food (i.e., hunt seal) is threatened by reductions in sea ice.   In denying that these animals are endangered by sea ice losses, the polar bear has become a “proxy” or “keystone domino” for denying all the other dire consequences associated with AGW.
“Here, focusing on Arctic sea ice and polar bears, we show that blogs that deny or downplay AGW disregard the overwhelming scientific evidence of Arctic sea-ice loss and polar bear vulnerability. By denying the impacts of AGW on polar bears, bloggers aim to cast doubt on other established ecological consequences of AGW.”  
Indeed, Harvey et al. (2017) authors claim that the evidence is both “overwhelming” and “well established” that polar bears can only hunt and catch their main prey, seals, “from the surface of the sea ice”.   They can not catch seals in the open water.  Consequently, as long as there is less sea ice available, “AGW assures that all polar bears ultimately will be negatively affected.”
Inuit Observations, And Scientists Who Record Them, Are Now ‘Climate-Change Denial’
The native Inuit peoples who have lived in the Arctic and observed polar bear hunting practices for generations are apparently deserving of the “climate-change denier” moniker.
For that matter, the audacious scientists who risk the ire of the AGW gatekeepers to interview these community leaders and then publish their results in scientific journals apparently must be classified as “climate-change deniers” too.
Why?  Because there appears to be widespread agreement among Inuit observers that polar bears are skilled swimmers who can catch seals in open water (and not just from sea ice surfaces).   This observation wholly contradicts the “well established” and “overwhelming” scientific evidence identified in Harvey et al. (2017) that says polar bears can only catch seals from a sea ice platform.
“The [native populations’] view of polar bears as effective open-water hunters is not consistent with the Western scientific understanding that bears rely on the sea ice platform for catching prey (Stirling and McEwan, 1975; Smith, 1980). The implications of this disagreement are paramount, given that scientists suggest that the greatest threat to polar bears associated with a decrease in sea ice is a significant decrease in access to marine mammal prey (Stirling and Derocher, 1993; Derocher et al., 2004).” — Laforest et al., 2018
‘There’s Too Many Polar Bears Now’
Not only do the generational observations indicate that polar bears’ hunting practices are not duly harmed by sea ice reduction, but community participants consistently report thriving and growing polar bear populations — especially in recent years.
An extensive analysis by York et al. (2016), relying heavily on native reports, concluded that 12 of 13 Canadian Arctic sub-populations have been stable or growing in recent decades.   Wong et al. (2017) recorded Inuit community members reporting “there’s too many polar bears now.”
Even aerial analysis has revealed stable to growing polar bear populations across wide swaths of the Arctic.  Aars et al. (2017), for example, report that there is “no evidence” that reduced sea ice has led to a reduction in polar bear population size.  To the contrary, these scientists found that polar bears living near the Barents Sea increased in number by 42% — from 685 to 973 — between 2004 and 2015.
Unconvincing Claims Of ‘Overwhelming Scientific Evidence’ 
The fact that the real-world observations of seal-hunting in open water can be collaborated by stable to growing population sizes would appear to support the Inuit version of polar bear science and to simultaneously undermine the Harvey et al. (2017) version of polar bear science.
If Michael E. Mann, Stephan Lewandowsky, and the other authors of the Harvey et al. (2017) polemic wish to characterize those who reject observational evidence (i.e., science) as “deniers”, perhaps they should first get their own “facts” straight.
As a requisite, Mann and his colleagues should seek to persuade Inuit community members that they have not actually witnessed polar bears hunt seals in open waters, or that they have not actually observed an increase in polar bear population size in recent decades.
After this insidious “denialism” permeating Inuit communities has been eradicated, the 14 authors of Harvey et al. (2017) might then have a leg to stand on in going after the “denier blogs” and their creationist-style tactics and scare-mongering rhetorical devices.

Aars et al., 2017
The number and distribution of polar 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




bears in the western Barents Sea
“In August 2015, we conducted a survey in the Norwegian Arctic to estimate polar bear numbers and reveal population substructure. … Mainly by aerial survey line transect distance sampling methods, we estimated that 264 (95% CI = 199 – 363) bears were in Svalbard, close to 241 bears estimated for August 2004. The pack ice area had an estimated 709 bears (95% CI = 334 – 1026). The pack ice and the total (Svalbard + pack ice, 973 bears [in 2015], 95% CI = 334 – 1026) both had higher estimates compared to August 2004 (444 and 685 bears [in 2004], respectively), but the increase was not significant.”
“There is no evidence that the fast reduction of sea-ice habitat in the area has yet led to a reduction in population size.”


Laforest et al., 2018
Traditional Ecological Knowledge 
of Polar Bears […] Québec, Canada
“Communities also differed in their perception of the prevalence of problem polar bears and the conservation status of the species, with one-third of participants reporting that polar bears will be unaffected by, or even benefit from, longer ice-free periods. A majority of participants indicated that the local polar bear population was stable or increasing.”
“[Participants] indicated that polar bear body condition is stable; they cited the fact that polar bears are capable of hunting seals in open water as a factor contributing to the stable body condition of the bears. … None of the participants explicitly linked the effects of a warming climate to specific impacts on polar bears.”
“Five participants indicated that polar bears are adept swimmers capable of hunting seals in open water. Residents of communities along Baffin Bay have also expressed this viewpoint (Dowsley and Wenzel, 2008), whereas Inuvialuit of the Western Arctic had variable perceptions of the ability of bears to catch seals in open water (Joint Secretariat, 2015). The [native populations’] view of polar bears as effective open-water hunters is not consistent with the Western scientific understanding that bears rely on the sea ice platform for catching prey (Stirling and McEwan, 1975; Smith, 1980). The implications of this disagreement are paramount, given that scientists suggest that the greatest threat to polar bears associated with a decrease in sea ice is a significant decrease in access to marine mammal prey (Stirling and Derocher, 1993; Derocher et al., 2004).”
“A recent aerial survey of the Southern Hudson Bay subpopulation concluded that the abundance of polar bears has remained steady since 1986 (943 bears; SE: 174) (Obbard et al., 2015). The survey included the entire coastal range and offshore island habitat of the Southern Hudson Bay subpopulation, except for the eastern James Bay coast. Taken together, the results of the aerial survey and the participant responses from Wemindji and Chisasibi indicate that the local population has remained stable. However, the unanimous responses from participants in Whapmagoostui/Kuujjuarapik suggest that there has been a localized increase in the number of bears near Whapmagoostui/Kuujjuarapik.”

Wong et al., 2017
Inuit perspectives of polar bear research:
Lessons for community-based collaborations
“All [Inuit] participants reported having more bear encounters in recent years than in the past. Some participants indicated that the bears they have encountered are healthy.”
Inuit observations: “Last year he said that there’s more bears that are more fat … they rarely see unhealthy bears … the only time they would see one is when it’s pretty old … it won’t hunt—hunt as much … and it’s skinny. (AB9)  … Our elders, they say, they migrate, into other area… for years, and then they come back … that’s what we’re experiencing now … back in early 80s, and mid 90s, there were hardly any bears … there’s too many polar bears now.  Bears can catch seals even—even if the—if the ice is really thin … they’re great hunters those bears … they’re really smart … they know how to survive”

York et al., 2016
Demographic and traditional knowledge perspectives on 
the current status of Canadian polar bear subpopulations
“Considering both [observations from native populations] and scientific information, we suggest that the current status of Canadian polar bear subpopulations in 2013 was 12 stable/increasing and one declining (Kane Basin).”
“We do not find support for the perspective that polar bears within or shared with Canada are currently in any sort of climate crisis.”
“We show that much of the scientific evidence indicating that some polar bear subpopulations are declining due to climate change-mediated sea ice reductions is likely flawed”
“Reduction in the heavy multiyear ice and increased productivity from a longer open water season may even enhance polar bear habitat in some areas.”
“It seems unlikely that polar bears (as a species) are at risk from anthropogenic global warming.”

Dowsley and Wenzel, 2008
“The Time of the Most Polar Bears”
“In the interviews, Inuit reported numerous changes in polar bears over the past 10 – 15 years [1990s to 2000s].”
“During the Inuit knowledge survey in the Baffin Bay area, Inuit knowledge varied significantly between communities on whether there was any change in the population of polar bears (p = 0.010) (Dowsley, 2005, 2007). In the northern community of Pond Inlet, all 14 respondents indicated a population increase. In the central community of Clyde River, 16 of 17 respondents reported an increase. In the most southern community of Qikiqtarjuaq, 9 of 15 reported an increase. The other six respondents in Qikiqtarjuaq reported either that they did not know, or that no change was observed. No respondent in any of the communities reported a decrease in the bear population.”

Dowsley, 2007
Inuit Perspectives on Polar Bears (Ursus maritimus)
and Climate Change in Baffin Bay, Nunavut, Canada
“A significant difference between communities was also observed regarding the number of polar bears. Only 60% of respondents in Qikiqtarjuaq felt the bear population had increased over the past 10-15 years, compared to over 90% of respondents in the other two communities.”
“No, because polar bears can go and follow the seals further [if sea ice retreats], so they won’t have trouble hunting. Also the snow covers the [seals’] breathing holes but polar bears can still hunt, it’s just for people.”
“There is more rough ice, more thin ice. But it won’t affect polar bears’ hunting.”
Share this...FacebookTwitter "
"Residents of London, Los Angeles and Beijing often complain about air pollution. And they’re right to – their concerns are backed by lots of data. However, not all cities are measured as rigorously. Notably, the air quality in many African cities is almost completely unmonitored. By 2050, both Lagos and Kinshasa will exceed 30m people – shouldn’t we know more about pollution in this fast-growing part of the world? The World Health Organisation calculates air quality is responsible for more than 500,000 deaths a year in Africa from both indoor and outdoor air pollution. To put this into perspective, around 11,000 people died in the recent Ebola epidemic. Yet the WHO’s ability to make these estimates is limited both by the lack of air measurements and the lack of medical studies linking pollution to deaths in Africa. It seems unlikely that the current air quality impact studies based on the populations of Los Angeles or London can be directly transferred to  Lagos or Kinshasa. London and Lagos have entirely different air quality problems. In cities such as London, it’s mainly due to the burning of hydrocarbons for transport. A complicated problem for sure, but one that can be addressed by tackling petrol usage through electric vehicles, car free zones, and so on. African pollution isn’t like that. There is the burning of rubbish, cooking indoors with inefficient solid fuel stoves, millions of small diesel electricity generators, cars which have had the catalytic converters removed and petrochemical plants, all pushing pollutants into the air over the cities.  It’s not even obvious what source to tackle first. Compounds such as sulfur dioxide, benzene and carbon monoxide that haven’t been issues in Western cities for decades may be a significant problem in African cities. We simply don’t know. Nature isn’t helping here either. Compounds such as hydrocarbons which may be inoffensive in themselves are emitted into the atmosphere and a complex web of chemical reactions process them into harmful products such as ozone and aerosols. These reactions are driven by the sun, and Africa has that in spades.  Natural sources of harmful compounds also abound. Sahara sand storms can cloak cities with choking dust. Chemicals emitted by trees in Africa’s vast forested areas may magnify the impact of human emissions in the same way as they do in the southern US, and smoke from seasonal forest fires can drift over population centres.  The relative importance of these natural sources compared to the human sources, and, even how we separate out the natural versus human are hotly debated by scientists. How much of the forest burning we see is due to natural courses such as lightning strikes and how much is linked to agricultural practices? Again without improved observations it is hard to tell. These air pollutants also harm vegetation and crops. In Asia it is estimated that around 10% of the food crop is destroyed by pollutants. For Africa we’ve got no good idea. First because we don’t have the same controlled field experiments on Africa’s staple crops such as cassava or millet as we do for Europe and North America’s crops. Second, because if we know little about air quality in cities, we know even less about what is happening in agricultural areas. The need to focus on air quality in Africa’s new megacities is the topic of a new paper, which I co-authored, in the journal Nature Climate Change.  Not only is pollution in these cities killing local residents, we found these emissions may even be altering the climate along the coast of West Africa, leading to changes in the clouds and so potentially to rainfall with devastating effects. Things aren’t going to get better any time soon. Half of the global population growth between 2015 and 2050 will occur in Africa, and the continent is becoming increasingly urbanised. Economic development will put increased strain on resources. A 2012 OECD report suggests successes in dealing with other problems such as access to drinking water and malaria is likely to make air quality the dominant environmental risk for premature deaths globally by 2030, if it isn’t already. Africa will not be far behind. Scientists can help. The latest generation of satellites is providing high-resolution information about these pollutants on an unprecedented scale, and cheap new sensors can monitor the composition of the air over cities.  Couple this with the revolution in big data and the decades of research that has been undertaken in North American, European and now Asian cities and we should soon be able to understand the air quality problems of African cities. And once we’ve understood the problem, science will be able to suggest solutions. Then it will be up to African cities to implement changes needed to prevent the deaths of thousands of their citizens."
"We are not far from the ocean here. The air smells of salt and sulphur, of marine life. But the square of black, cracked mud in front of us, bounded by its four crumbling walls of sand, is no place for living things. It was previously a pond for cultivating tiger prawns, the lucrative species that was the reason for cutting the lush mangrove forest that once covered this area. The recent history of this abandoned place is sadly representative of the story of thousands of hectares in this region in the west of Sri Lanka.  A swelling appetite for shrimps and prawns in America, Europe and Japan has fuelled industrial farming of shellfish in the past few decades. The industry now has a farm-gate value of $10bn (£6.4bn) per year globally and the prawn in your sandwich is much more likely to have come from a pond than from the sea. While the industry is dominated by the likes of China, Vietnam and Thailand, a large number of other countries have invested heavily in cultivation too.  One is Sri Lanka, which saw the industry as a passport to strong economic growth and widespread employment. Just outside the world’s top ten producers, it accounts for approximately 50% of the total export earnings from Sri Lankan fisheries. More than 90% of the harvested cultured prawns are exported, going mostly to Japan.  Yet the picture is decidedly mixed on a closer inspection. The country saw an explosion of unregulated aquaculture on the island in the 1980s and 1990s, bringing riches to a few and the hope of riches or at least an income to many more. But poor coastal management also brought white spot syndrome virus, a virulent disease that spreads in water and on the feet of birds, and can kill all the prawns in a pond in under a week.  Crowding shrimp together in warm little pools full of nutrients creates the perfect conditions for an outbreak. It contributes to the fact that here and elsewhere in the tropics, most intensively farmed ponds remain productive for only five to ten years (the other main reason is the build-up of an organic ooze, rich in uneaten food and prawn faeces). Such ponds are then abandoned in favour of new areas of wetland to convert for another brief harvest. The disease kills off prawns in the wild in large numbers too.   To get a sense of how bad the problem has been in Sri Lanka, I was one of a group of researchers who studied the Puttalam area on the west coast, one of the first in the country where large-scale aquaculture was introduced.  We looked at satellite imagery from 1992 to 2012, which showed an explosion in prawn farms from less than 40ha in our study area to over 1,100ha (a rise of over 2,700%). This combined with a decline in natural habitats – mangroves lost some 36% of their area over the period. Yet most of these historic ponds are now unproductive or abandoned.  The evidence from the satellite images combined with interviews with local people suggest that a staggering 90% of ponds are lying idle. The story is unlikely to be quite as bad across the country as a whole, since Puttalam was one of the early areas to be cultivated. Detailed figures are thin on the ground, but certainly overall shrimp exports in 2012 were 65% below their 1999 peak.  Prawn aquaculture has been likened to slash-and-burn cultivation – find a pristine spot, remove the vegetation and farm it for a few years before moving on. But the analogy is misleadingly benign. Slash-and-burn systems on a small scale can be sustainable, since the cut plots can recover afterwards.  In the case of prawn farming, a better phrase would be “slash and sink”. Mangroves are among the most carbon-dense of all ecosystems, often storing more than 2,000 tonnes of carbon per hectare in sediments beneath the forest floor, according to research that our group has yet to publish. Cut them down and this carbon is oxidised and emitted into the atmosphere as CO2.  We estimate that nearly 192,000 additional tonnes of carbon have been added to climate change as a result of these land-use changes in Puttalam, Sri Lanka alone. And that of course excludes any emissions during farm operations and the potential for the lost mangroves to capture carbon in future.  An additional issue is the sinking shoreline. In the face of global rising sea levels of more than 3mm a year, healthy mangrove forests are among the best protection since they bind together sediments and even elevate their soils to match the rising tide. Lose them and the chances of coastal subsidence, erosion and storm damage goes up.  In fact, mangroves are such useful ecosystems that destroying them almost never makes sense, even from a narrow economic perspective. A recent analysis in southern Kenya showed that conserving and restoring the forests was worth at least $20m more in present value than allowing current cutting to continue. So what about Sri Lanka? A positive recent development was that the government announced that it would protect all of its remaining mangroves, totalling some 8,800 hecatares. It also promised to replace a further 3,900 – a task that will require careful restoration of the right tidal conditions and planting trees where necessary. Another positive sign is that there are now local movements that are coordinating production among zones and farms to avoid disease and achieve better sustainability. This is on the back of a commitment by the government in 2010 to expand the industry.  The country should also look to return some of its abandoned ponds to production, provided producers are supported to adopt best practice and work together to avoid disease outbreaks and pollution in future. As for us in the West who import these shellfish in vast quantities each year, we need to think harder about the real costs of that cheap prawn sandwich. Without knowing where it has come from and what farming practices have been used, we would do well to steer clear."
"Britain’s countryside is becoming ever more socially exclusive as spiralling house prices turn once-normal villages into rich ghettos. Contrary to the popular imagination, few of the cast of The Archers could now afford to live in Ambridge, or anywhere else in rural Britain for that matter. It’s getting ever harder for people on medium and lower incomes to buy a first home, and there is very little so-called “affordable housing”. The proposed extension of the Right to Buy to tenants of housing associations will only make matters much worse. As the internet explodes with articles focused on London, it’s is an ideal moment to take stock of the situation and ensure people in the countryside don’t get drowned out. The UK is unique in having higher house prices in its rural areas than in its towns and cities. Rural homes now cost 26% more on average than those in urban England (London aside), and work out to around 11 times the average local salary. These prices are well beyond the means of most families living and working in the countryside, who are outbid by wealthy commuters, retirees and second home owners who earn their living elsewhere. For people unable to afford to buy a home, renting should be viable alternative, but this is also a problem. Private rents are just as high as in urban areas, despite lower earnings in rural communities (local earnings in rural England average £19,700 compared to £26,900 in major urban areas). Rented social housing provided by housing associations and councils could help out, but again rural areas are lacking: 12% of rural housing is social compared to 19% in urban areas. Even this small stock of social housing has been further depleted under the Right to Buy scheme, and in some areas affordable housing has all but disappeared. The few opportunities which do arise for people with local connections and ordinary incomes to share in rural life, helping keep schools and services going, derive primarily from the efforts of housing associations. Where these associations have built small-scale developments, shops remain open, buses keep running, and local communities thrive. The government is now proposing to force housing associations against their will to sell their stock to tenants at heavily discounted prices. The bill, estimated at £5.8 billion or more, will partly be met by forcing local authorities to sell their most valuable council houses. The government argues that this will allow housing associations to build new affordable housing, even though since 2012 just 46% of houses sold under the Right to Buy scheme have been replaced. Unless the government ensures replacements are built in the same settlement, affordable homes will inevitably be lost in larger numbers from attractive villages and hamlets (as happened under the original Right to Buy of council houses) and that they will be replaced, if at all, elsewhere where sites are cheaper and planning regulations more sympathetic. Lord Kerslake, until recently head of the civil service, described this proposal as “wrong in principle and wrong in practice”. We are already seeing those on low and medium incomes, and especially young people, priced out of small towns and villages across the country. With housing association properties sold off at great cost to the taxpayer, and unlikely to be replaced in any substantial quantities, the wealth divide in rural communities will deepen even further. Not only will the forced sale of housing association properties affect the social and demographic make-up of rural communities; it will also have an effect on local employers. With rural areas becoming increasingly socially exclusive, local businesses – from farms and shops to accountants and software developers – will find it even harder to attract the young, skilled, ambitious people they need. We urgently need more affordable homes to be built, not the disposal of the few that remain in rural areas. The government must reconsider the proposed Right to Buy extension, at least exempting rural areas. Instead they should implement the recommendations made by the Rural Housing Policy Review, to provide more affordable rural housing. This would not only provide much-needed housing supply, but would help rural economies contribute more fully to the government’s growth agenda."
nan
"The average British person will have emitted more carbon dioxide in the first two weeks of this year than a citizen of any one of seven African nations does in an entire year. This is the key finding of an Oxfam project, published on Sunday, which discovered that someone in the UK will take just five days to emit the same carbon as someone in Rwanda does in a year.  And by next Sunday, 12 January, the average Briton’s emissions will have overtaken the annual per capita emissions of a further six African countries: Madagascar, Malawi, Ethiopia, Uganda, Guinea and Burkina Faso. The study revealed that annual emissions of carbon dioxide, per head of population, is 0.09 tonnes in Rwanda, 0.19 in Malawi and 0.25 in Burkina Faso. Further up the scale, it was found that Nigeria emits 0.49 tonnes of carbon per person every year while in India the figure is 1.68. These figures compare with a global average of 4.7 tonnes per person per year. In Britain the figure is 8.3. Danny Sriskandarajah, the chief executive of Oxfam GB, described the scale of global inequality revealed by the study as staggering. “It’s a shock to realise that in just a few days our high-carbon lifestyles here in the UK produce the same emissions as the annual footprint of people in some poor countries. However, the encouraging thing is the willingness of the British public to take action.” This view is supported by the results of a YouGov poll, carried out for Oxfam and also published on Sunday. It shows that 61% of people in Britain want the government to do more to address the climate emergency. Most respondents also say they would be willing to act to reduce their own carbon footprints. The poll found that 55% of Britons say they worry about the impact of global heating and as many as 79% said they were likely to take one of a number of actions to reduce their carbon footprint. Responses ranged from 79% of people who said they were likely to recycle more, down to 38% who were likely to change their diet, such as by eating less meat or dairy. More than two-thirds (68%) said they were likely to use energy-efficient products or utility providers, and almost half to limit their air travel (49%) or buy ethically made or second-hand products (49%). “Just as large numbers of the public are resolving to reduce their carbon footprint, we need a bold new year’s resolution from the prime minister to get us on track to net-zero emissions much earlier than the current 2050 deadline,” added Sriskandarajah. “As the UK government gets ready to host global climate talks later this year, it needs to show that it is deadly serious about leading the fight against climate change.”"
"
Share this...FacebookTwitterOutgoing director of the Potsdam Institute for Climate Impact Research (PIK) believes mankind, through its activities, is headed for a “mass extinction” event and an anthropogenic calamity comparable to a geological scale asteroid hit.

Outgoing Potsdam Institute director Hans-Joachim “John” Schellnhuber tells German national daily that mankind has run out of time and faces “mass extinction” and calamity of geological proportions. Photo: PNAS. 
In an online article titled Climate Change Like An Asteroid Strike appearing in Germany’s national daily Süddeutsche Zeitung (SZ), journalist Alex Rühle reports on the outgoing director of Germany’s alarmist Potsdam Institute for Climate Impact Research (PIK), Prof. Hans-Joachim “John” Schellnhuber.
Prof. Schellnhuber, widely known in Germany as the Climate Pope, is considered in Europe as the leading climate science authority and the architect of the Master Plan for transforming global society – dubbed The Great Transformation – which aims to make global society climate compatible by applying draconian, surrealistic measures. Moreover the plan calls for all of it to happen in just a matter of a couple of decades!
A number of critics have characterized the whole idea as detached from economic reality and dystopian.
Risks mounting “by the hour”
Schellnhuber is also the father of the “2°C climate target”, a warming he claims that the world must never exceed, lest it’ll tip hopelessly into a state of rapid, irreversible climatic collapse.
The SZ article reports how the outgoing Schellnhuber believes the planet is in fact approaching the climatic catastrophe at “a crazy speed” and that the risks “are mounting quasi by the hour”.
The alarmist Potsdam Institute professor has been known for a number of shrill comments made in the past, but in this most recent SZ article, Schellnhuber’s shrillness arguably reaches a whole new level that shoots beyond the realms of reason.
Rapid, epic disaster of geologic dimensions
Now that Schellnhuber is stepping down as director of the Potsdam Institute after 25 years as its director, he reflects back, telling the SZ how he feels about the overall public “disinterest with regards to the consequences of climate change” that has taken hold globally.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In Schellnhuber’s view, world leaders are moving far too sluggishly to avert what he sees is a climatic disaster of epic geological proportions, and compares it to earlier calamities which the earth witnessed tens of millions of years ago.
100 times faster than Permian–Triassic extinction event
The Potsdam director tells the SZ that the globe’s temperature today is rising at a rate of 5°C per century! – or “100 times faster than during the time of the Permian–Triassic extinction event” which occurred some 250 million years ago and is believed to have wiped out 90% of all land life on the planet at the time.
According to Rühle, Schellnhuber compares today’s climate change to the “largest mass extinctions in the history of the earth.”
Comparable to the Cretaceous–Paleogene extinction event!
If one mass extinction event was not enough to illustrate what in Schellnhuber’s mind is climatically in store for humanity, the former PIK director piles on with yet another geological catastrophe to describe the course on which he claims man has put the planet on. He tells the SZ:
What man is doing today is similar to the asteroid strike known as the Cretaceous–Paleogene extinction event.”
According to the SZ, Schellnhuber says, “We’ve shirked our responsibility much too long”.
He then compares the situation to a sinking ship that urgently demands top priority:
If we don’t get climate change under control, and if we can no longer keep the ship afloat, then we won’t need to think about distribution of income, racism and good taste any longer.”
Embarrassing climate science even more
Luckily Schellnhuber’s dire claims are very much in dispute and considered extreme outliers, but do provide much fodder to the media. If anything is certain, it is that Schellnhuber is definitely not leaving his post a minute too soon. His most recent claims are an embarrassment to science.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAustralian Bushfires Have Become Less Frequent Over The Past 15 Years
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
In the Australian state of Victoria, 50,000 km² of land have burned and 12 people and 1 million sheep and thousands of heads of cattle lost their lives. The regions hit by fire were near Portland, Westernport and in the Plenty Ranges, as well as the Wimmera and Dandenong districts. The burned regions extended over a quarter of the state. Conditions for the fires were made favorable by the long-lasting drought period, which changed the landscape into a tinderbox. Finally the fire was exacerbated by strong winds, which carried off a glowing ember from a campfire and ignited the adjacent grassy region.
What role did climate change play in the fire disaster? The Potsdam Institute for Climate Impact Research (PIK) and other alarmists remained surprisingly moot here. Normally climate alarmists rush to the microphones and claim that although such single events are not easily linked to climate change, the probability is in any case is much higher. Loaded dice.
Proponents of a climate catastrophe kept silent in the case of these Victoria fires because they had not been born yet.
The described above fires occurred in February, 1851 and are known as the ‘Black Thursday Bushfires‘.
There have always been bushfires in Australia. For example at the end of the 19th century and the start of the 20th century in New South Wales. Apparently that fact was not even known by the former General Secretary of the Climate Framework Convention of the United Nations (UNFCCC), Christiana Figueres, who in 2013 described in knee-jerk fashion that the fires in New South Wales (NSW) were a consequence of climate change. A classic gaffe – one that should never happen for someone occupying such a position.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The provincial government defended itself against such misinterpretations. The German business daily Handelsbatt wrote on October 25, 2013:
The new conservative government accuses environmental protection activists are exploiting the fires to oppose the planned repeal of of the CO2-tax. ‘Some people are trying to profit from all the tragedy and suffering of this week,’ said Environment Minister Greg Hunt. By the way, the CSIRO research authority just explained that there have been bushfires in Australia for millions of years.”
If one counts the damage from bushfires in NSW compared to the number of homes, then there has been no recognizable trend over the past 90 years.  In The Conversation, John McAneney presented the facts. Foremost he sees deficits with regards to land-use planning, which made the extent of the fire damage possible.
In July 2017 a study by Nick Earl und Ian Simmonds appeared in the Journal of Geophysical Research. The authors analyzed the Australian bushfire statistics from 2001-2015 and found a reduction in fires. Yet, they did find a large temporal and spatial variability which in part was controlled by ocean cycles such as the El Nino or the Indian Ocean Dipole. Abstract:
Variability, trends, and drivers of regional fluctuations in Australian fire activity
Throughout the world fire regimes are determined by climate, vegetation, and anthropogenic factors, and they have great spatial and temporal variability. The availability of high-quality satellite data has revolutionized fire monitoring, allowing for a more consistent and comprehensive evaluation of temporal and spatial patterns. Here we utilize a satellite based “active fire” (AF) product to statistically analyze 2001–2015 variability and trends in Australian fire activity and link this to precipitation and large-scale atmospheric structures (namely, the El Niño–Southern Oscillation (ENSO) and the Indian Ocean Dipole (IOD)) known to have potential for predicting fire activity in different regions. It is found that Australian fire activity is decreasing (during summer (December–February)) or stable, with high temporal and spatial variability. Eastern New South Wales (NSW) has the strongest decreasing trend (to the 1% confidence level), especially during the winter (JJA) season. Other significantly decreasing areas are Victoria/NSW, Tasmania, and South-east Queensland. These decreasing fire regions are relatively highly populated, so we suggest that the declining trends are due to improved fire management, reducing the size and duration of bush fires. Almost half of all Australian AFs occur during spring (September–November). We show that there is considerable potential throughout Australia for a skillful forecast for future season fire activity based on current and previous precipitation activity, ENSO phase, and to a lesser degree, the IOD phase. This is highly variable, depending on location, e.g., the IOD phase is for more indicative of fire activity in southwest Western Australia than for Queensland.”
 
Share this...FacebookTwitter "
"Royal Dutch Shell is at risk of falling short on plans to invest up to $6bn (£4.6bn) in green energy projects between 2016 and the end of 2020, with its slow progress likely to raise concern that oil companies are not moving fast enough to help tackle the climate crisis. The Anglo-Dutch oil company has spent an estimated $2bn on building a low-carbon energy and electricity generation business since setting up its “new energies” division in 2016. With a year to go, the sum is well below Shell’s own guidance that the total investment between 2016 and the end of 2020 would be between $4bn and $6bn. Shell’s green energy plans are some of the most ambitious in the oil industry, despite assigning just a 10th of its spending pot to “new energies”. Shell told investors in 2017 it would spend between $1bn to $2bn a year developing a clean energy business up to the end of 2020, up from a previous plan to spend up to $1bn a year in the same period. Under the plans Shell would spend up to $6bn on green investment , but instead it is on track to meet a third of this, with only a year left for the company to meet its guidance. Up to the end of 2019, Shell’s guidance suggests it should have spent at least $3bn. In the same four years the company spent more than $120bn developing fossil fuel projects and set out plans to increase its total spending to $30bn a year in the early 2020s. A spokesman for Shell declined to comment. Shell is considered a climate leader within the oil industry despite spending a fraction of its total budget on new energies, which include biofuels, hydrogen and electricity investments. Data from Rystad Energy, a Norwegian consultancy, shows that Europe’s five largest oil companies – Shell, BP, Total, Eni and Equinor – together spent a total of $5.5bn on renewable energy projects to date, comparedwith a combined total budget of almost $90bn last year alone. Stephen Kretzmann, the executive director of Oil Change International, said executives “trumpet their relatively tiny investments in renewables” but continue to “pour more fuel on the fire of global warming every day”. He said: “It used to be the case that some people believed that an oil company that invested even only a small portion of their resources in renewable energy was worthy of praise… because it makes us feel better to believe that the people who run these powerful companies get it.” Oil bosses have voiced support for global climate targets in public but the industry continues to invest an estimated 1% of its annual spending budget on clean energy while producing more fossil fuel products than the Paris Climate Agreement allows. “The executives that run the carbon companies definitely do not get the part about the need for them to make less of the thing that is driving climate disaster,” Kretzmann added. “The big problem isn’t too little investment in renewables - it’s too much investment in, and government support for, fossil fuels.” Shell’s green spending plans were dealt a blow earlier this year when the company missed out on a multibillion dollar race to buy Dutch utility Eneco, which has a large renewable energy portfolio. Shell and its pension fund partner lost out to a consortium of investors led by Japan’s Mitsubishi, which paid $4.5bn for the company. The deal might have pushed Shell’s green investment towards its planned spending range. Shell said it was disappointed it lost the bid, and said that it would continue to invest growing gas and electricity generation from renewable sources. Shell’s previous acquisitions have included UK energy supplier First Utility, a 49% stake in Australian solar company ESCO Pacific, and Eolfi, a French renewable energy developer that specialises in floating wind projects. Shell plans to spend $2bn to $3bn through its “new energies division” every year between 2021 to 2025. The company said it plans to become the world’s biggest electricity company by the 2030s, and hopes to bring a reliable electricity supply to 100 million people in developing countries by 2030."
"By the end of the century, the world’s remaining tropical forests will be left in a fragmented, simplified, and degraded state. No patch will remain untouched – most remnants will be overrun by species that disperse well, which often means “weedy” plants like fast-growing pioneer trees and small rodents that thrive in disturbed areas. Most of the rest will be “the living dead” – tiny remnant populations of plants and animals hanging on with no future. There is no cast-iron law that dictates this scenario – but it appears likely unless we see a series of major policy changes. What could unfold? In research published in the journal Science, colleagues and I outline an all too common chain of events. The first cut of timber from any natural forest is the most lucrative. The most remote places, in the interior of Amazonia, in central Congo and the heart of Borneo are all coveted by industrial loggers. The logging frontier marches relentlessly on. They selectively take the biggest trees and along with them the habitat of species that rely them.  Today, less than 25% of tropical forests have escaped industrial logging and each year new concessions are given to industrial loggers in forests that had hitherto never been logged. While parts of the forest remain following logging, truly intact tropical forests may soon become a thing of the past. Logging pushes roads into the forest. It’s estimated that an astonishing 25m kilometres of road will be built in the tropics by 2050. Roads begin to isolate fragments of forest, and some ground-dwelling specialist species fail to cross even small openings.  Roads also bring hunters and markets together: in the decade to 2011 some 62% of Africa’s forest elephants were killed for their tusks. Usually international logging companies cut first, for export, and then they sell on their concession. This encourages a second cut of less desirable timber species, without waiting for the forest to recover, and further degradation ensues. This degraded forest is more susceptible to forest fires which kill trees and drive out many species. Heavily logged and degraded forest is then often slated for conversion to agricultural plantations. About 100m hectares of tropical forest – four times the size of the UK – has been converted over the past 30 years. Ominously, the palm oil industry which devastated much of Indonesia’s and Malaysia’s forests is now moving into Africa, which up to now has had relatively low deforestation rates. With food demand set to double, this pressure on tropical forests will intensify. Much more forest looks set to be lost. The remaining forest is fragmented and surrounded by other agriculture. The trend is towards small patches of isolated, fire-impacted, logged-over forests, with no large animals due to overhunting.  Now add a new pressure to this process: climate change. On the positive side, more carbon dioxide in the atmosphere increases tree growth and their resilience to drought. Yet, on current emissions scenarios, tropical forests are set to warm by about 4℃ this century. With hotter temperatures and increased frequency of the most extreme El Niño events that cause droughts, huge forest fires would rage, turning even areas that escape conversion to agriculture into savanna-type vegetation rather than tropical forest. As the climate rapidly changes, plants and animals will need to move to continue to live within their ecological tolerances – one study calculated they would need to keep moving 300 metres each year through this century to keep in the current temperature they live in.  How are organisms supposed to move through fragmented, isolated and degraded forest patches? Climate change and forest fragmentation together is a recipe for the mass extinction of tropical forest species this century. How might such a fate be avoided? Aside from a rapid global shift to low-carbon energy, two changes of policy direction would help. First, given widespread poverty in tropical forest regions, policies that enourage “development without destruction” are needed to increase prosperity without undermining the forest and the services it provides. Unfortunately, most of the benefits from logging, mining and intensive agriculture flow away from local people. Giving forest-dwellers long-term collective legal rights over their land would mean benefits flow to them. Importantly, studies show local people with legally recognised land rights preserve forests. A study of 292 protected areas in Amazonia showed that indigenous reserves were highly effective at avoiding deforestation in high pressure areas. A study of 80 forest commons across Asia, Africa, and Latin America showed forest was maintained when local people managed them. Of course, forest-dwellers won’t be perfect managers of forests, but they won’t look for a quick profit and then move on, as big businesses often do. And they represent a win-win situation for human rights and conservation. Unbroken forested corridors linking tropical forest landscapes with those 4℃ cooler will also be necessary to reduce levels of extinction. So landscape planning is required on a massive scale – and new areas will require restoring to provide links between forest areas. For example, those rare tracts of intact forest in Southeast Asia need connecting all the way to the foothills of the Himalayas. This sounds dramatic, but neither climate change nor forest wildlife stick within political borders.  Is development without destruction an academic dream? There is good news among the bad: the UN New York Declaration on Forests is a promising start – more than 100 signatories, including governments, businesses and indigenous peoples groups have pledged to halve deforestation by 2020 and ensure palm oil, soy, paper and beef production is deforestation free. The declaration also includes promoting land rights. The UN climate talks in Paris will also show whether institutions can rise to the challenges of our globally changing environment. Agreements on reducing deforestation, including durable finance, could play an important role in keeping forests standing, as would allocating funds for land-use planning to retain forest connectivity. There are signs of changes in policy to avoid a global simplification of tropical forests, but the window of opportunity is closing."
"The death of a celebrity often makes the headlines, but it is less common that the death of wild animal has the same effect. However, it appears that the entire world has mourned the loss of Cecil the lion, killed on a private game reserve bordering a national park in Zimbabwe. But is the recent barrage of attacks on trophy hunting, and the US dentist who killed Cecil, justified? Let’s be clear: Cecil was killed illegally, which we don’t condone. The landowner who allowed the hunt on his reserve without the necessary permit should face the justice system. But this one bad apple should not tarnish an entire industry. Legally hunting lions in Zimbabwe is highly regulated: it requires various permits and licenses from the client, professional hunter and hunting reserve owner. National quotas aim to ensure sustainable off-take of the species and, in western Zimbabwe, lions are only killed once they have reached a certain age to make sure they’ve had the chance to pass their genes on. As a result, lion populations in Zimbabwe are either stable or increasing.  So if hunts are conducted following these rules, can trophy hunting really help conserve lions? Some argue that even if this were the case, the practice still shouldn’t be allowed because it involves killing a charismatic and threatened animal for fun. Opponents suggest that non-lethal alternatives such as photographic tourism should be the main way in which conservation is funded.  But there are a number of problems with this argument. Hunters are willing to go to remote and unstable areas into which most photographic tourists are unwilling to venture. Far more photographic tourists than hunters would have to travel to Africa to make up the same level of revenue, so the carbon footprint from all that air travel would surely have a significant environmental impact. It should also be noted that the potential for nature tourism is not equally distributed, with the industry often focused only around a few locations. This leaves other regions without access to tourism revenue. Oh, and let’s not forget that wildlife reserves can also kill lions. If the goal is to preserve populations and species (as opposed to the welfare of individual animals), countries with healthy wildlife populations should be able to use their natural resources to cover the costs of management. This is particularly the case in countries such as Zimbabwe, one of the poorest places in the world. Zimbabwe has a tradition of using trophy hunting to promote wildlife conservation. Through the CAMPFIRE programme, which ran from 1989 to 2001, more than US$20m was given to participating communities, 89% of which came from sports hunting. In more recent times, populations of elephants and other large herbivores have been shown to benefit from trophy hunting. Zimbabwean trophy hunting generates roughly US$16m of revenue annually. While it has been rightly pointed out that only 3% of this goes towards local communities, the ethical implications of removing this money without a clear alternative need to be examined.  The economic impact of trophy hunting in comparison to tourism as a whole may not be huge, but what is the alternative if it is made illegal?  Zambia banned trophy hunting of big cats in 2013, only to reverse it earlier this year because the government needed the money to fund conservation.  Conservation costs money – so does the damage done by lions killing livestock.  It is not clear whether photographic tourism alone could cover these financial burdens. If trophy hunting is to continue, how can we make it more sustainable?  One study suggested we need to enforce age restrictions on trophy animals throughout the entire country, improve monitoring, change quotas over time depending on environmental conditions and ensure that lion hunts are at least 21 days long.  Another study found that trophy hunting can be beneficial to lion conservation when the income is shared with locals who live with this species (and have to deal with the negative consequences of their presence).   While it is sad that we sometimes have to resort to killing animals for conservation, let’s not allow emotions to overtake our arguments. Conservation is a complex, difficult industry and needs all the financial help it can get: we are after all living through the sixth mass extinction. How much money will that take to fix?"
"
Share this...FacebookTwitterConservationist/wind-energy protest group Rettet den Odenwald (Save the Forest of Odes) here writes that yet another endangered stork nest was recently destroyed at the forested location near a proposed JuWi wind park.
Controversy swirls over German wind park builder JuWi 
Normally the clearing of forest land to make way for industry is required to undergo an extremely strict permitting process involving very detailed environmental impact studies. Violations are usually punished extremely harshly. But when it comes to wind parks in Germany, the fox in the henhouse often seems to rule. This also may be the case at a proposed JuWi wind park location in the area of Donnersberg (Palatinate).
Back in 2016 the existence of a nest at the location of interest was proven. The nest belonged to a pair of rare black storks that later gave birth to three offsprings that year, and to four more in 2017. Normally with such a nest in the area, obtaining a permit to clear away forest and to set up an industrial complex would be totally out of the question.
Rare and legally protected black stork nest gets allegedly destroyed in what is suspected to be a criminal attempt to clear the way for a wind park construction permit. Photo see: Rettet den Odenwald
According to Rettet den Odenwald, the nest belonging to the pair of rare black storks appears to have been recently willfully and criminally destroyed.
Earlier, local citizens had worked closely with authorities to stop the construction of five JuWi wind turbines, which had been permitted to be built right close to what later was discovered as the nest belonging to the pair of protected black storks. The black stork pair had been expected to return to its nest by early March to produce offsprings.
Tree and nest destroyed
But then on February 10, 2018, Rettet den Odenwald broke the tragic news: the tree in which the nest had been perched had been singled out and  illegally cut down “by unknown attackers” using a power saw, thus preventing the stork pair from returning and successfully nesting this year.
The obstacle blocking the construction of the JuWi windpark in the area was in effect disposed of.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Destroyed tree in the Forest of Odes (Odenwald). Home to the nest of a pair of rare, legally-protected black storks was illegally cut down. Conservationists and wind park opponents suspect foul play by the wind industry. Photo see: Rettet den Odenwald
Path “reopens for greed”
The conservationist Rettet den Odenwald site writes:
This lawbreaking allows the permitting process for the planned and halted wind park to now appear in a new light. … The lawful protection that was established by the provision of facts was illegally undone and thus has again reopened the door for the greed of those with a stake in the wind park.”
The outrage by conservationists and wind park opponents came swiftly and loudly. Already on February 12 Rettet den Odenwald issued a press release in which they demand the Environment Ministry to assure that no permit be granted in the event of such criminal acts and that they take swift action.
JuWi condemns destruction
In a press release, JuWi stated that it “condemns the criminal act in the harshest terms”. Moreover the press release adds: “JuWi is filing criminal charges against unknown perpetrators for violating federal nature protection laws”.
The latest in a series of criminal environmental destruction acts
This is not the first time that nests and homes for protected species located in proposed wind park areas have been destroyed in Germany. Der Spiegel has reported on this before, e.g. see here.
Also read “wind power mafia” destroys stork’s nest here.  
When it comes to saving the planet, wind parks seem to get away with everything nowadays. Often times wind turbines get installed right up close to residents and thus make them sick from infrasound, or they ruin idyllic landscapes, destroy biotopes, cause hazards in the North Sea, shred migrating birds, etc. Environmental concerns from citizens be damned!
As far as the wind park in Odenwald is concerned, don’t be surprised if its construction ends up getting permitted soon. Greed disguised as green always gets its way in Germany.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAt Die kalte Sonne site here, geologist Dr. Sebastian Lüning and Prof. Fritz Vahrenholt comment on the controversy surrounding allegations of Big Oil “covering up” knowledge of the impacts their products could have on climate.
For example on April 16, 2018, renowned German weekly Spiegel reported on how “a confidential Shell study” showed the oil company “kept knowledge over climate change secret” and how “Shell knew already in detail 30 years ago about the greenhouse gas effect – and decided to keep silent.”
Now just a couple of weeks later, we find out that back then oil companies like Shell in fact didn’t know any more about climate change than other climate experts. The clandestine “Shell study” summarized:
–A thorough review of climate science literature, including acknowledgement of fossil fuels’ dominant role in driving greenhouse gas emissions. More importantly, Shell quantifies its own products’ contribution to global CO2 emissions.
–A detailed analysis of potential climate impacts, including rising sea levels, ocean acidification, and human migration.
–A discussion of the potential impacts to the fossil fuel sector itself, including legislation, changing public sentiment, and infrastructure vulnerabilities. Shell concludes that active engagement from the energy sector is desirable.
–A cautious response to uncertainty in scientific models, pressing for sincere consideration of solutions even in the face of existing debates.
–A warning to take policy action early, even before major changes are observed to the climate.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




At the time of the Shell study, the history of the earth’s climate over the past 2000 years had been poorly understood, and so Lüning and Vahrenholt find the cover-up accusations against Shell a bit strange. Overall the two German scientists say the whole story tells us just how weak the accusations of the activist side really are.
Natural factors have been proven
Some three decades later, the two German scientists note that far more is known today: for example the important roles played by natural ocean cycles and the global phenomenon of the Medieval Ice Age, which now is acknowledged and make the climate models look obsolete. Moreover, CO2 climate sensitivity has been dialed back with each passing year.
Lüning and Vahrenholt add:
Over the coming months and years the IPCC will have to admit to some changes in its understanding of the climate.”
The real scandal is the cover-up of natural factors
But the real intent of the climate activists turning to litigation is about generating publicity, as plainly admitted by German site Klimafakten on 16 April 2018:
Going to court for more climate protection – and for more transparency
Everywhere across the world activists are fighting against climate change by using litigation. Experts already count about one thousands court proceedings in 24 countries. For the litigants it’s not only about getting a ruling, but about publicity: The suits are  a means for strategic communication.”
The real deal, say Lüning and Vahrenholt, is that natural climate factors have been known as real drivers for over a decade, and activists, scientists and the IPCC continue to cover them up.
In fact, Lüning and Vahrenholt say that this is the real story that needs to be the subject of litigation. The real scandal is
How activists and the IPCC covered up knowledge of natural climate change.”
Share this...FacebookTwitter "
"The Israeli public broadcaster has come under fire from angry listeners after broadcasting an interview with Tony Abbott in which he said the world was “in the grip of a climate cult”. During the interview, recorded on 15 December while his home state of New South Wales was fighting terrifying bushfires, Abbott denied that carbon dioxide was driving global warming. The interview was broadcast on New Year’s Eve in a special show reviewing key international issues of the decade. Abbott said: “While we still seem to be in the grip of a climate cult, the climate cult is going to produce policy outcomes that will cause people to wake up to themselves.” After claiming, incorrectly, that a focus on emissions reduction in Australia had caused blackouts and rising power prices, Abbott said: “Sooner or later, in the end, people get hit over the head by reality.” The host of the show, Israel Public Broadcasting Corporation foreign editor Eran Mor-Cicurel, interjected part-way through the interview, pointing out Australia had been hit by fires and disasters “happening again and again”. The link between rising greenhouse gas emissions and increased bushfire risk is complex but, according to major science agencies, clear. Climate change does not create bushfires, but it can and does make them worse. A number of factors contribute to bushfire risk, including temperature, fuel load, dryness, wind speed and humidity.  The Bureau of Meteorology and the CSIRO say Australia has warmed by 1C since 1910 and temperatures will increase in the future. The Intergovernmental Panel on Climate Change says it is extremely likely increased atmospheric concentrations of greenhouse gases since the mid-20th century is the main reason it is getting hotter. The Bushfire and Natural Hazards research centre says the variability of normal events sits on top of that. Warmer weather increases the number of days each year on which there is high or extreme bushfire risk. Dry fuel load - the amount of forest and scrub available to burn - has been linked to rising emissions. Under the right conditions, carbon dioxide acts as a kind of fertiliser that increases plant growth.  Dryness is more complicated. Complex computer models have not found a consistent climate change signal linked to rising CO2 in the decline in rain that has produced the current eastern Australian drought. But higher temperatures accelerate evaporation. They also extend the growing season for vegetation in many regions, leading to greater transpiration (the process by which water is drawn from the soil and evaporated from plant leaves and flowers). The result is that soils, vegetation and the air may be drier than they would have been with the same amount of rainfall in the past. The year coming into the 2019-20 summer has been unusually warm and dry for large parts of Australia. Above average temperatures now occur most years and 2019 has been the fifth driest start to the year on record, and the driest since 1970. Not a significant one. Two pieces of disinformation, that an “arson emergency”, rather than climate change, is behind the bushfires, and that “greenies” are preventing firefighters from reducing fuel loads in the Australian bush have spread across social media. They have found their way into major news outlets, the mouths of government MPs, and across the globe to Donald Trump Jr and prominent right-wing conspiracy theorists. NSW’s Rural Fire Service has said the major cause of ignition during the crisis has been dry lightning. Victoria police say they do not believe arson had a role in any of the destructive fires this summer. The RFS has also contradicted claims that environmentalists have been holding up hazard reduction work. Mor-Cicurel asked Abbott if he was “denying that fact we are in the process of global warming and global change”. Abbott responded that while there was “no doubt that climate has changed”, previous warming events had happened before the industrial revolution. Abbott’s points are contradicted by every major science academy in the world, as well as the expertise of government science agencies in his own country. His anti-science views on climate change are well known in Australia and have been corrected many times by leading climate scientists but Mor-Cicurel was not aware of his views before the interview. Mor-Cicurel told Guardian Australia the radio network had been reporting regularly on Australia’s bushfire crisis and was not aware of Abbott’s views before the interview. He said: “Personally I was surprised [by Abbott’s views on climate change]. I did not expect a former prime minister of Australia to be so blunt about environmental issues in the middle of an environmental crisis in Australia. “When we put it to air, people were terribly angry at us for airing such extremist views, especially from environmental organisations that were annoyed that we had given the stage to these kinds of views.” Well, Israel is a small country with big problems. However it has a large and vocal environmental movement. They were outraged. Some have blamed us for spreading lies as they failed to differentiate between the broadcaster and the interviewee. Abbott said changes to climate in the past “makes me think as a matter of simple logic that carbon dioxide emissions, particularly human carbon dioxide, are not the only, or even the main factor here”. He said that “all things being equal of course we should try and reduce our carbon dioxide emissions”. But, he said: “The last thing we should do is drive our industries offshore and be putting pressure on household budgets and risk third world-style blackouts all in the name of climate change. We have got to be sensible and balanced and proportionate about these things and I don’t think other policy makers are right now.” Australia’s bushfire season began in August, much earlier than usual, and has claimed at least 19 lives, destroyed more than 1,600 homes and burned at least 4.6m hectares of land – an area more than double the size of Israel. Earlier in the interview, Abbott named three key themes for the globe over the past decade: the “challenge of China”, the “climate cult” and the “ongoing Islamist challenge”. He said: “I think the western world has continued to suffer from serious self-doubt over the last decade and it’s exacerbated by the rise of what are effectively new religions like the climate cult and there is an ongoing Islamist challenge … and it’s been obvious since September 2001.” Abbott was prime minister from September 2013 to 2015. He lost his Sydney seat of Warringah at the 2019 general election."
"For those that haven’t noticed, it’s been rather warm in Europe. In fact, last Wednesday was the UK’s hottest July day since records began. The temperature at Heathrow soared to 36.7°C, approximately 15°C higher than the average maximum daily temperature for the month. In mainland Europe it has been even hotter, with much of Spain well into the 40s and Paris seeing its highest temperature since 1947. However, the extreme conditions haven’t been limited to high temperatures – thunderstorms were generated that produced fantastical lightning shows, heavy downpours and hail stones the sizes of ping pong balls.  The World Meteorological Organisation defines a heatwave as five or more consecutive days when the maximum daily temperatures are at least 5°C above average for that time of year.   Persistent hot weather of this type is linked to high pressure systems, where air descends, heats up and drys out. This suppresses the formation of clouds and allows for clear conditions for days or even weeks.  Western Europe’s weather is largely governed by the jet stream. This high-altitude, high-velocity river of air meanders around the globe and is constantly changing position. When an omega-shaped wave is present on the jet stream which arcs over Europe, warm dry air from southern Europe and Africa can be pulled north, pushing temperatures higher than normal. If this upper level feature coincides with high pressure at the surface with relatively low pressure to the east and west an omega block is formed.  This pattern of flow can be very persistent and lead to long periods of fine weather in summer. Decreased cloud cover and transport of warm air over a number of days can produce very high temperatures. Such a situation occurred last week, replacing the usually cool westerly air stream with warm air from over continental Europe. An important consequence of this situation has been the formation of a Spanish plume, which transports warm dry air from over Spain to the UK (sometimes North Africa, which explains the red dust left on your car after it rains).  This air rises as it travels and acts as a lid under which energy is trapped and builds. This energy is then suddenly and dramatically released through thunderstorms, as the warm air bumps into the colder from the jet steam and further north. The strongest thunderstorms are generated at the edge of the high pressure region – hence the storms over the UK last Wednesday. Europe has been affected by two notable heatwaves in recent memory, during the summers of 2003 and 2006. Both were caused by very similar meteorological conditions to those occurring now.  While hot, dry weather might seem like perfect summer conditions, such severe heatwaves can be deadly. The “lid” in the atmosphere causes pollutants to build up near the surface. Exposure to these, together with dehydration and heat stress pose a very real risk. In the heatwave of 2003 almost 15,000 deaths were attributed to the weather conditions in France alone. Heatwaves can also be responsible for destruction of crops, widespread drought, power cuts due to lightning strikes, accelerated glacier melt and destructive forest fires – governments across Europe have plans specifically designed for reducing the impact. What impact will climate change have on this? It will no doubt lead to higher temperatures in Europe, and with hotter conditions the air is able to hold more water. This means there is more energy that can be released by thunderstorms, which is expected to lead to heavier downpours and other more severe weather.  However, it is impossible to attribute a particular event to climate change. Just like rolling a loaded die, you cannot say whether any particular six you roll was because the die is loaded, only that the chance of a six was higher.  The key components of a heatwave are the flow patterns on a continental-scale, and whether the frequency of these patterns will be significantly changed in an altered climate is still uncertain. As such, it is an important and interesting topic of debate among scientists."
nan
"
Share this...FacebookTwitterAnthropogenic Influence On Arctic Climate
 ‘Too Small To Be Detected’

Source: Haine, 2016

The evidence compiled in scientific papers continues to rapidly accumulate.
An anthropogenic signal in the regional Arctic climate is still too small to be detected.
Temperature, glacier melt, and sea ice changes are all well within the range of natural variation for the Arctic region.  The changes that do occur have identifiable origins that are unrelated to atmospheric CO2 concentrations or human emissions.
Below is a brief summary of some of the latest research that underscores the lack of connection between anthropogenic influences and climate-related changes in the Arctic.

Arctic Temperature And Ice Retreat Mechanisms
1. Arctic Warming Since 1990s ‘Dominated By Natural Variability’ (NAO)
Orsi et al., 2017
The recent warming trend in North Greenland  … We find that δ 18O [temperature/climate proxy] has been increasing over the past 30 years, and that the decade 1996-2005 is the second highest decade in the 287-year record (Figure 4). The highest δ 18O values were found in 1928, which is also an extreme year in GISP2 and NGRIP ice cores, and in a coastal South Greenland composite [Vinther et al., 2006; Masson-Delmotte et al., 2015], but the decadal average (1926-1935) is not statistically different from the decade (2002-2011).
The surface warming trend has been principally attributed to sea ice retreat and associated heat fluxes from the ocean [Serreze et al., 2009; Screen and Simmonds, 2010a, b], to a negative trend in the North Atlantic Oscillation (NAO) since 1990, increasing warm air advection on the West Coast of Greenland and Eastern Canada [Hanna et al., 2012; Fettweis et al., 2013; Ding et al., 2014], and to an increase in the Greenland Blocking Index [Hanna et al., 2013]. These latter mechanisms could be dominated by natural variability rather than forced response to the anthropogenic increase in greenhouse gases [Fettweis et al., 2013; Screen et al., 2014].
2. Arctic Ice Melt Since 1995 Due To Natural Cloud Cover Decrease, NAO
Hofer et al., 2017
Decreasing cloud cover drives the recent mass loss on the Greenland Ice Sheet … The Greenland Ice Sheet (GrIS) has been losing mass at an accelerating rate since the mid-1990s. … We show, using satellite data and climate model output, that the abrupt reduction in surface mass balance since about 1995 can be attributed largely to a coincident trend of decreasing summer cloud cover enhancing the melt-albedo feedback. Satellite observations show that, from 1995 to 2009, summer cloud cover decreased by 0.9 ± 0.3% per year. Model output indicates that the GrIS summer melt increases by 27 ± 13 gigatons (Gt) per percent reduction in summer cloud cover, principally because of the impact of increased shortwave radiation over the low albedo ablation zone. The observed reduction in cloud cover is strongly correlated with a state shift in the North Atlantic Oscillation promoting anticyclonic conditions in summer and suggests that the enhanced surface mass loss from the GrIS is driven by synoptic-scale changes in Arctic-wide atmospheric circulation. … Th[e] strong correlation between summertime NAO index and the MAR-based cloud cover could be used to forecast whether the observed reduction in cloud cover during summer, and the associated increase in GrIS melt, is likely to continue.

3. Geothermal Heat Flux From ‘All Over’ Greenland The ‘Primary Process’ Behind Temperature Changes
Rysgaard et al., 2018
The Greenland ice sheet (GIS) is losing mass at an increasing rate due to surface melt and flow acceleration in outlet glaciers. … Recently it was suggested that there may be a hidden heat source beneath GIS caused by a higher than expected geothermal heat flux (GHF) from the Earth’s interior. Here we present the first direct measurements of GHF from beneath a deep fjord basin in Northeast Greenland. Temperature and salinity time series (2005–2015) in the deep stagnant basin water are used to quantify a GHF of 93 ± 21 mW m−2 which confirm previous indirect estimated values below GIS. A compilation of heat flux recordings from Greenland show the existence of geothermal heat sources beneath GIS and could explain high glacial ice speed areas such as the Northeast Greenland ice stream. … Geothermal springs with source water temperatures above 0 °C have been found all over Greenland, especially around Disko Island in West Greenland, where several thousands of such springs have been identified. … Therefore, we assume that vertical turbulent mixing and GHF [geothermal heat flux] are the primary processes behind the observed salinity and temperature change.
4. Recent Winter Arctic Warming Driven By Planetary Scale Waves
Baggett and Lee, 2017
The dynamical mechanisms that lead to wintertime Arctic warming during the planetary-scale wave (PSW) and synoptic-scale wave (SSW) life cycles are identified by performing a composite analysis of ERA-Interim reanalysis data. The PSW life cycle is preceded by localized tropical convection over the Western Pacific. Upon reaching the mid-latitudes, the PSWs amplify as they undergo baroclinic conversion and constructively interfere with the climatological stationary waves. The PSWs [planetary scale waves] flux large quantities of sensible and latent heat into the Arctic which produces a regionally enhanced greenhouse effect that increases downward IR and warms the Arctic two-meter temperature. The SSW life cycle is also capable of increasing downward IR and warming the Arctic two-meter temperature, but the greatest warming is accomplished in the subset of SSW events with the most amplified PSWs. Consequently, during both the PSW and SSW life cycles, wintertime Arctic warming arises from the amplification of the PSWs [planetary scale waves].
5. Recent Canadian Arctic Warming (1988-1996) And Cooling (1997-2016) Driven By The AO
Mallory et al., 2018
The AO [Arctic Oscillation] has positive and negative phases that infuence broad weather patterns across the northern hemisphere (Thompson et al. 2000). For example, during the positive phase of the AO, atmospheric pressure over the Arctic is lower than average, which tends to result in warmer and wetter winters in northern regions as warmer air is able to move further north (Thompson et al. 2000; Aanes et al. 2002). …  From 1988 to 1996, the summer intensity of the AO was largely in the positive phase, with a mean value of 0.207 (± 0.135 SE), and this was a period of population stability or growth for each of the three herds that we examined here. In contrast, from 1997 to 2016 the summer AO has remained largely in the negative phase [cooling], with a mean value of − 0.154 (± 0.077 SE), and over this period the Bathurst, Beverly, and Qamanirjuaq herds declined in abundance. … We found that positive intensities of the Arctic Oscillation (AO) in the summer were associated with warmer temperatures, improved growing conditions for vegetation, and better body condition of caribou.
6. Greenland Glacier Retreat, Growth Linked To The NAO
Bjørk et al., 2017     
Changes in Greenland’s peripheral glaciers linked to the North Atlantic Oscillation … [W]e map glacier length fluctuations of approximately 350 peripheral glaciers and ice caps in East and West Greenland since 1890. Peripheral glaciers are found to have recently undergone a widespread and significant retreat at rates of 12.2 m per year and 16.6 m per year in East and West Greenland, respectively; these changes are exceeded in severity only by the early twentieth century post-Little-Ice-Age retreat. Regional changes in ice volume, as reflected by glacier length, are further shown to be related to changes in precipitation associated with the North Atlantic Oscillation (NAO), with a distinct east–west asymmetry; positive phases of the NAO increase accumulation, and thereby glacier growth, in the eastern periphery, whereas opposite effects are observed in the western periphery. Thus, with projected trends towards positive NAO in the future, eastern peripheral glaciers may remain relatively stable, while western peripheral glaciers will continue to diminish.
7. Arctic’s Polar Vortex Changes ‘Primarily A Result Of Natural Internally-Generated Climate Variability’
Seviour, 2017
Weakening and shift of the Arctic stratospheric polar vortex: Internal variability or forced response? … By comparing large ensembles of historical simulations with pre-industrial control simulations for two coupled climate models, the ensemble mean response of the vortex is found to be small relative to internal variability. There is also no relationship between sea-ice decline and trends in either vortex location or strength. Despite this, individual ensemble members are found to have vortex trends similar to those observed, indicating that these trends may be primarily a result of natural internally-generated climate variability.
Arctic Temperature Changes In Recent Decades
8. No Net Warming Since 1940s/1950s In Alaska, Subarctic North Atlantic, Siberia…Climate Trends Consistent With 50-90 Year AMO
Nicolle et al., 2018
Persistent multidecadal variability with a period of 50– 90 years is consistent between the subarctic North Atlantic mean record and the AMO over the last 2 centuries (AD 1856–2000). … In the North Atlantic sector, instrumental sea surface temperature (SST) variations since AD 1860 highlight low-frequency oscillations known as the AMO (Kerr, 2000).  …  The LIA is, however, characterized by an important spatial and temporal variability, particularly visible on a more regional scale (e.g., PAGES 2k Consortium, 2013). It has been attributed to a combination of natural external forcings (solar activity and large volcanic eruptions) and internal sea ice and ocean feedback, which fostered long-standing effects of short-lived volcanic events (Miller et al., 2012).



9. Greenland Has Been Cooling Since 2001
Westergaard-Nielsen et al., 2018
Here we quantify trends in satellite-derived land surface temperatures and modelled air temperatures, validated against observations, across the entire ice-free Greenland. … Warming trends observed from 1986–2016 across the ice-free Greenland is mainly related to warming in the 1990’s. The most recent and detailed trends based on MODIS (2001–2015) shows contrasting trends across Greenland, and if any general trend it is mostly a cooling. The MODIS dataset provides a unique detailed picture of spatiotemporally distributed changes during the last 15 years. … Figure 3 shows that on an annual basis, less than 36% of the ice-free Greenland has experienced a significant trend and, if any, a cooling is observed during the last 15 years (<0.15 °C change per year).

10. Greenland Has Been Cooling Since 2005
Kobashi et al., 2017 
For the most recent 10 years (2005 to 2015), apart from the anomalously warm year of 2010, mean annual temperatures at the Summit exhibit a slightly decreasing trend in accordance with northern North Atlantic-wide cooling.  The Summit temperatures are well correlated with southwest coastal records (Ilulissat, Kangerlussuaq, Nuuk, and Qaqortoq).

11. No Net Warming In Greenland For The Last 90 Years
Kobashi et al., 2017


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Arctic Sea Ice Changes 
12. Arctic Sea Ice Expanding Since 1988 (Bohai Sea), AO & NAO ‘Primary’ Climate Factors 
Yan et al., 2017
Afforded by continuous satellite imagery, evolution of sea ice cover over nearly three decades from 1988 to 2015 in the Bohai Sea [North China] as a peculiar mid-latitude frozen sea area is reported for the first time. An anomalous trend of slight overall increase of 1.38 ± 1.00% yr–1 (R = 1.38, i.e. at a statistical significance of 80%) in Bohai Sea ice extent was observed over the 28 year period. …  Correlation with decreasing Arctic Oscillation (AO) index (r = –0.60, p < 0.01) and North Atlantic Oscillation (NAO) index (r = –0.69, p < 0.01) over the study period suggested AO and NAO as the primary large-scale climate factors for Bohai Sea ice.

13. Arctic Sea Ice Oscillates…Not Significantly Lower Now Than In The 1940s
Connolly et al., 2017
According to this new dataset, the recent period of Arctic sea ice retreat since the 1970s followed a period of sea ice growth after the mid 1940s, which in turn followed a period of sea ice retreat after the 1910s. Our reconstructions agree with previous studies that have noted a general decrease in Arctic sea ice extent (for all four seasons) since the start of the satellite era (1979). However, the timing of the start of the satellite era is unfortunate in that it coincided with the end of several decades during which Arctic sea ice extent was generally increasing. This late-1970s reversal in sea ice trends was not captured by the hindcasts of the recent CMIP5 climate models used for the latest IPCC reports, which suggests that current climate models are still quite poor at modelling past sea ice trends.

14. Arctic Sea Ice Extent Only Slightly Lower Now Than During Little Ice Age, Much Higher Now Than Most Of Last 7,000 Years
Perner et al., 2018
[W]e find evidence of distinct late Holocene millennial-scale phases of enhanced El Niño/La Niña development, which appear synchronous with northern hemispheric climatic variability. Phases of dominant El Niño-like states occur parallel to North Atlantic cold phases: the ‘2800 years BP cooling event’, the ‘Dark Ages’ and the ‘Little Ice Age’, whereas the ‘Roman Warm Period’ and the ‘Medieval Climate Anomaly’ parallel periods of a predominant La Niña-like state. Our findings provide further evidence of coherent interhemispheric climatic and oceanic conditions during the mid to late Holocene, suggesting ENSO as a potential mediator.

15. Solar Forcing Drives Arctic Sea Ice Trends, Sea Ice Higher Now Than Nearly All Of The Last 8,000 Years
Yamamoto et al., 2017
Millennial to multi-centennial variability in the quartz / feldspar ratio (the BG [Beaufort Gyre] circulation) is consistent with fluctuations in solar irradiance, suggesting that solar activity affected the BG [Beaufort Gyre] strength on these timescales. … Multi-century to millennial fluctuations, presumably controlled by solar activity, were also identified in a proxy-based BSI [Bering Strait in-flow] record characterized by the highest age resolution. … Proxy records consistent with solar forcing were reported from a number of paleoclimatic archives, such as Chinese stalagmites (Hu et al., 2008), Yukon lake sediments (Anderson et al., 2005), and ice cores (Fisher et al., 2008), as well as marine sediments in the northwestern Pacific (Sagawa et al., 2014) and the Chukchi Sea (Stein et al., 2017).

16. Southwest Greenland: Sea Ice Increasing Since 1930s, No Net Change In Temperature Since 1600
Kryk et al., 2017     
Our study aims to investigate the oceanographic changes in SW Greenland over the past four centuries (1600-2010) based on high-resolution diatom record using both, qualitative and quantitative methods.  July SST during last 400 years varied only slightly from a minimum of 2.9 to a maximum of 4.7 °C and total average of 4°C. 4°C is a typical surface water temperature in SW Greenland during summer.
The average April SIC [sea ice concentration] was low (c. 13%) [during the 20th century], however a strong peak of 56.5% was recorded at 1965. This peak was accompanied by a clear drop in salinity (33.2 PSU).

17. Arctic Sea Ice Trends Linked To The AMO, NAO, Sea Ice Lower Than Today During Medieval Climate Anomaly
Kolling et al., 2017     
[O]ur reconstructions reveal several oscillations with increasing/decreasing sea ice concentrations that are linked to the known late Holocene climate cold/warm phases, i.e. the Roman Warm Period, Dark Ages Cold Period, Medieval Climate Anomaly and Little Ice Age. The observed changes seem to be connected to general ocean atmosphere circulation changes, possibly related to North Atlantic Oscillation and Atlantic Multidecadal Oscillation regimes. Furthermore, we identify a cyclicity of 73–74 years in sea ice algae and phytoplankton productivity over the last 1.2 kyr, which may indicate a connection to Atlantic Multidecadal Oscillation mechanisms.

18. Arctic Amplification, Sea Ice Loss Not Explained By CO2 Forcing
Kim et al., 2017
Understanding the Mechanism of Arctic Amplification and Sea Ice Loss
Sea ice reduction is accelerating in the Barents and Kara Seas. Several mechanisms are proposed to explain the accelerated loss of polar sea ice, which remains an open question. … [T]he role of upward and downward longwave radiations in Arctic amplification is vague and not fully understood.
[CO2 is not mentioned in the paper as a mechanism responsible for Arctic amplification or sea ice loss.]
Long Term Changes In Arctic Region Temperatures
19. Greenland 1°C to 3°C Warmer Than Now For Most Of The Last 8,000 Years
Kobashi et al., 2017
After the 8.2 ka event, Greenland temperature reached the Holocene thermal maximum with the warmest decades occurring during the Holocene (2.9 ± 1.4 °C warmer than the recent decades) at 7960 ± 30 years B.P.

20. Arctic-Wide Temperatures Warmer Than Now During The Medieval Warm Period
Werner et al., 2017
[S]tatistical testing could not provide conclusive support of the contemporary warming to supersede the peak of the MCA [Medieval Climate Anomaly] in terms of the pan-Arctic mean summer temperatures.

21. Northern Alaska Warmer During Medieval Times
Hanna et al., 2018
Here, we utilize one such sediment archive from Simpson Lagoon, Alaska, located adjacent to the Colville River Delta to reconstruct temperature variability and fluctuations in sediment sourcing over the past 1700 years. Quantitative reconstructions of summer air temperature […] reveal temperature departures correlative with noted climate events (i.e. ‘Little Ice Age’, ‘Medieval Climate Anomaly’). … Reconstructed temperatures are generally coolest between 300 and 800 CE (Tavg = 2.24 ± 0.98°C), displaying three temperature minima centered at 410 CE (1.34 ± 0.72°C), 545 CE (1.91 ± 0.69°C), and 705 CE (1.49 ± 0.69°C). Temperatures then rapidly increased, reaching the warmest interval (800–1000 CE) in the approximately 1700-year record. During this interval, average temperatures were 3.31 ± 0.65°C, with a maximum temperature of 3.98°C.

Share this...FacebookTwitter "
"The most extreme weather of all rarely gets a mention, even in the UK where we’re famous for our weather talk. Far above our heads the Earth is regularly hit by colossal, tsunami-like waves of scorching gas and savage, supersonic winds from space.  The culprit for this extra-terrestrial weather is sat at the centre of our solar system. The familiar pictures of our Sun that portray a plain, incandescent orb, serenely holding the planets in place, couldn’t be further from the truth. The Sun is a rowdy place. One of the most spectacular forms of space weather are Coronal Mass Ejections, where the Sun sporadically throws out billions of tonnes of hot gas and magnetic field into space.  The Sun also generates its own wind, which ranges from “breezes” to “hurricanes”. It’s all on a much bigger scale though – even average solar winds are much more ferocious than anything we could ever experience, with speeds varying between a gentle 500,000 miles per hour to a gusty 2,000,000 mph.  These winds carry with them a part of the Sun’s atmosphere, a million-℃ gas composed of highly energetic electrons, protons and alpha particles. The winds are accelerated along the sun’s outstretched, tentacle-like magnetic field, which originates deep under its surface and extends out past Earth to the edges of the solar system. Being able to forecast the solar wind has its problems though. For example, we know they predominantly originate in darker, less dense patches of the Sun’s atmosphere known as coronal holes, however we are still unable to locate the other significant sources that must contribute to the wind. More importantly, we don’t have a clear explanation of how the winds are heated and accelerated. My colleagues and I were interested in the processes underlying these tempestuous winds. In a study published in the journal Nature Communications, we investigate powerful magnetic waves, known as Alfvén waves, located in the regions where the solar wind originates. These waves cause the Sun’s magnetic field to violently sway back and forth at tens of thousands of miles per hour, transporting energy around the star’s atmosphere and out into space. It is this role as a magnetic energy carrier that means the Alfvén waves are often responsible for accelerating the solar wind to such monstrous speeds. We found that some of the necessary conditions exist for the waves to break down their energy to smaller scales and supply some of it to the wind (potentially via the interactions of the waves with particles)  – something predicted for a couple of decades but never observed. Future studies of Alfvén waves should reveal how much energy they feed to the solar wind and may even allow us to forecast wind speeds.  “Space weather forecasts” may seem like one for the future but such reports are already used by a host of agencies. The UK’s National Grid, for instance, relies upon daily updates to avoid overloads of the electrical grid due to resulting geomagnetic storms (an extreme case in 1989 cut off power for six million people in Quebec). We don’t often encounter the consequences of space weather in our day-to-day lives, but as society becomes increasingly dependent on technology it will surely be felt more keenly. Recent reports have demonstrated how wide-ranging this can be, for example, disrupting radio communications, damaging satellites and causing increased radiation levels on commercial flights. The UK government is concerned enough that space weather was added to the National Risk Register and, in late 2014, it set up the Met Office Space Weather Operations Centre to monitor it and provide an assessment of the risks. Looking forward, if we are to regularly engage in space tourism, asteroid mining or manned trips to other worlds, then travellers and technology will be exposed to the elements once they leave the safety of Earth’s protective magnetic field. While space weather may be hazardous, there are some suggestions we can exploit the solar wind to power spacecraft using magnetic or electric sails or even harvest some of its energy using a so called Dyson-Harrop satellite. Our findings are an example of one of the many advances being made in understanding the origins of space weather, although much more is needed to bring our predictive abilities in line with those of our meteorological friends. Space weather forecasters will also need to continue popularising the lexicon of extra-terrestrial weather and raising awareness of its impact here on Earth. Then, maybe one day, people will tune in to the morning’s space weather report to see whether they should take that trip to Mars."
"Amazon has threatened to fire employees for speaking publicly about the company’s role in the climate crisis, tech workers at the retail giant have revealed.  An email shared with the Guardian shows Amazon’s human resources department launched an “investigation” into one employee, Maren Costa, over comments made to the media that called for the company to do more to tackle the climate crisis. In the email, Costa is told she will not face punishment at this point – but that any future comments unauthorized by Amazon “may result in formal corrective action, to and including termination of your employment with Amazon”. A group of Amazon employees who banded together to call for stronger climate action by the company said several members have been questioned by legal and HR representatives about their public comments. Some received follow-up emails similar to Costa’s that threaten dismissal for speaking out in the future. Costa said four employees have been questioned and two have been threatened with termination if they continue speaking up about Amazon’s role in the climate crisis without seeking approval. Costa, a user experience principal designer, said: “It was scary to be called into a meeting like that, and then to be given a follow-up email saying that if I continued to speak up, I could be fired. “But I spoke up because I’m terrified by the harm the climate crisis is already causing, and I fear for my children’s future. Any policy that says I can’t talk about something that is a threat to my children – all children – is a problem for me.” According to Amazon, it started updating its external communications policy for staff in spring last year. It said it was not aimed at any particular group of employees. A company spokeswoman said: “Our policy regarding external communications is not new and, we believe, is similar to other large companies. We recently updated the policy and related approval process to make it easier for employees to participate in external activities such as speeches, media interviews, and use of the company’s logo. “As with any company policy, employees may receive a notification from our HR team if we learn of an instance where a policy is not being followed.” Amazon’s threats to Costa and other employees occurred after it announced a “climate pledge” in September. The plan commits Amazon to using 100% renewable energy by 2030, before becoming carbon neutral by 2040. To help achieve this, Amazon has ordered 100,000 fully electric delivery vehicles for its fleet. Jeff Bezos, Amazon’s chief executive, said he was “done being in the middle of the herd” on climate policies at the policy’s unveiling, which took place just a day before 1,500 Amazon employees planned to walk out of work to join a wave of global climate strike rallies inspired by Swedish teenager Greta Thunberg. Amazon’s shift on climate change represented a victory for its employee group, which is called Amazon Employees for Climate Justice. The group had previously pushed, unsuccessfully, a shareholder resolution to set a climate change plan. A further 8,000 Amazon employees subsequently signed an open letter to Bezos calling for concrete climate goals; to cancel contracts with oil and gas companies; and to stop donations to politicians who deny the reality of the climate crisis. Amazon employees said the company updated its policy on staff speaking to the press and on social media in early September, a day after the plan to join the climate walkout was announced. The new policy requires staff members to seek permission from Amazon prior to talking in a public forum while identified as an employee. Victoria Liang, a software engineer at Amazon, said: “Amazon’s newly updated communications policy is having a chilling effect on workers who have the backbone to speak out and challenge Amazon to do better. This policy is aimed at silencing discussion around publicly available information. It has nothing to do with protecting confidential data, which is covered by a completely different set of policies.” Bezos, the world’s richest person, has said he understands the concerns of employees and has promised to review Amazon’s political donations. He has rejected, however, calls to sever ties with oil and gas companies. Amazon Employees for Climate Justice said it will continue to push the company to do more on climate, despite the threat of recriminations for speaking out publicly. Justin Campbell, a data engineer at Amazon, said: “Amazon’s policy is not going to stop the momentum tech workers have built over the past year at Amazon. The climate crisis is the greatest challenge we face, and the only way we can find solutions is by protecting people’s right to speak freely and disrupting the status quo.”"
nan
"Russia has published a plan to adapt its economy and population to climate change, aiming to mitigate damage but also “use the advantages” of warmer temperatures. The document, published on the government’s website on Saturday, outlines a plan of action and acknowledges changes to the climate are having a “prominent and increasing effect” on socioeconomic development, people’s lives, health and industry.  Russia is warming 2.5 times faster than the planet as a whole, on average, and the two-year “first stage” plan is an indication the government officially recognises this as a problem, even though Vladimir Putin denies human activity is the cause. It lists preventive measures such as dam building or switching to more drought-resistant crops, as well as crisis preparations including emergency vaccinations or evacuations in case of a disaster. The plan says climate change poses risks to public health, endangers permafrost, and increases the likelihood of infections and natural disasters. It also can lead to species being pushed out of their usual habitats. Possible “positive” effects are decreased energy use in cold regions, expanding agricultural areas and navigational opportunities in the Arctic Ocean. Among a list of 30 measures, the government will calculate the risks of Russian products becoming uncompetitive and failing to meet new climate-related standards, as well as prepare new educational materials to teach climate change in schools. Russia is one of the most vulnerable countries to climate change, with vast Arctic regions and infrastructure built over permafrost. Recent floods and wildfires have been among the planet’s worst climate-related disasters. Moscow formally adopted the Paris climate accord in September last year and criticised the US withdrawal from the pact. Putin, however, has repeatedly denied the scientific consensus that climate change is primarily caused by emissions deriving from human activity, blaming it last month on some “processes in the universe”. He has also criticised the Swedish climate campaigner Greta Thunberg, describing her as an uninformed, impressionable teenager possibly being “used” in someone’s interests. He has also voiced scepticism on numerous occasions about solar and wind energy, expressing alarm about the dangers of turbines to birds and worms, causing them to “come out of the ground” by vibrating. While there is evidence that large wind-power installations can pose a risk to birds, known research does not suggest they harm worms. On Sunday, Russia’s meteorological service predicted temperatures up to 16C higher than normal for Monday and Tuesday, when Russia celebrates Orthodox Christmas."
"The UK is a rich, stable country with oil and gas reserves, lots of wind, and more than enough scientists and engineers to make the most of its resources. So why do so many people in the country continue to tolerate high energy bills and poor service? The question of what can be done to encourage energy consumers to become more active and engaged has come to a head after the Competition and Markets Authority (CMA) published provisional findings from its investigation into the UK’s energy market.  One of the things the report considers is the attitudes and behaviour of the energy consumer – ordinary bill-payers like you or I. And one of the findings is that inactive, disengaged consumers are partly responsible for tolerating weak competition. Energy suppliers exploit this inertia to increase their profits.  Only a minority of the UK’s 27m electricity customers, or the 23m gas customers, are regularly shopping around for the best deal, or switching their energy supplier. In fact, 19m buy both their electricity and gas from the same supplier and most of them remain on open-ended, standard variable tariffs (SVTs), rather than fixed term, non-standard tariffs, which are generally (but not always) cheaper.  While this consumer apathy persists, the “Big Six” energy suppliers have little incentive to compete aggressively on either price or service. The first point to make here is that not all energy consumers are the same. However, it could be argued that a failure to acknowledge this has been one of the key problems with the energy market. Privatisation promised increased choice and competition, but the constraints of the supply chain and a shared infrastructure have worked against the development of a truly free market. How different do you really expect EDF and npower to be when they both carry the same electricity on the same grid?  Instead, the UK energy consumer has been bewildered by complicated pricing and paralysed by the belief that changing supplier involves too much hassle and carries the risk of ending up worse off in the long run. Previous sharp practice, using door-to-door sales techniques (which ended in 2012), has left a legacy of mistrust towards the whole industry. Some regulations designed to protect consumers, such as a ban on regional price discrimination and an enforced reduction in the number of tariffs, may have actually weakened competition. There are consumers who are prepared to search for the best deal, either by using a price comparison website, or by joining a buying consortium such as a community energy scheme. They may also have invested in technology to monitor their energy consumption patterns. However, as the latest energy market report points out, these consumers tend to be relatively wealthy and highly educated. They may be motivated by a desire not just to save money, but also by environmental concerns to reduce their carbon footprint. Many other consumers do not or cannot search for the best deal. This may be because they don’t have the necessary numeracy skills, internet access or confidence to make an informed decision. They may be poor, old or living in rented accommodation and more pre-occupied with their immediate short-term finances, leaving them unable or unwilling to make long-term financial choices. Another cause of inaction and apathy is the fact that gas and electricity are perceived as rather boring, undifferentiated commodities; necessary evils that are difficult to get excited about.  For the energy market to work more efficiently and fairly, both the regulators and the energy providers must understand and serve the different types of energy consumer, by segmenting the market in an appropriate way. One study of the Swiss energy market identified six clusters of energy customer, based on their knowledge, values, capabilities and habits. These segments were characterised as “idealistic energy-savers”, “convenience-oriented indifferent energy consumers”, and so on.  The researchers concluded that each group needs to be targeted with different messages and incentives, tailored to their particular characteristics and circumstances. This makes a lot of sense – a wealthy person obsessed with cutting their carbon footprint is hardly likely to be swayed by an advert promising cheap energy aimed at an entirely different demographic. Another method of segmentation based on cost-of-service has been proposed as a possible basis for supplier strategy in the future. The authors of the study, two Stanford scientists, pointed out that two different consumers of energy may have the same overall power usage, but the cost of supplying them can vary greatly, because of their different consumption patterns, such as usage at peak and off-peak times. They argue detailed information on the presence of certain household appliances such as tumble dryers is a strong predictor of energy usage. Combined with detailed data from smart meters (which are planned to be installed in all UK households by 2020), energy suppliers could gain valuable insights into each customers’ energy needs and behaviour. This knowledge could allow them to offer individualised tariffs, perhaps to incentivise off-peak usage of expensive appliances such as tumble dryers. At the same time, data from smart meters, combined with greater trust in the information provided by comparison websites, will be key to consumers becoming more engaged in understanding their own energy usage and encouraging them to switch suppliers on a regular basis."
"
Share this...FacebookTwitterFirst a note:
If you haven’t already picked up a copy of the The Politically Incorrect Guide to Climate Change, please do get your hands on one.
According to its author Marc Morano, people have been snatching them up and a third printing has started. The book even made the Amazon top 100 best selling books for awhile.
It also ranked first in a number of categories. In his book, NoTricksZone gets mentioned 4 times and even took up one full page at one spot!
So now on to today’s post…
Less heat days near Tokyo
As in Germany, a heat day in Japan is defined as one reaching 30°C or higher.
And according to the manmade CO2 theory, global temperatures are supposed to be rising rapidly and hence we should be seeing many more “heat days” than say 50 or 100 years ago.
Yet Japanese blogger Kirye presents data over Hachijo Island, out to sea east of Tokyo, a location shielded from the urban heat island effect, which tell us that more heat days is not the case at all:

On Hachijo Island, Tokyo, the number of days over 30℃ has not trended since 1926. Source: www.data.jma.go.jp/
Examining the above chart, we see that the number of “heat days” since 2000 is a bit below that of the period from 1940 to 1960. Note the cool 1970 to 1990 period, which likely can be explained by natural oceanic oscillations.
Another chart Kirye provides at Twitter breaks it down in more detail:
 Source: www.data.jma.go.jp/




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Kirye writes, when looking at the past 111 years, the trend in Hachijo Island’s number of days over 30℃ from 1906 to 2017 “denies the anthropogenic global warming hypothesis” and that it does not support the myth of a widespread man-made climate change.
No trend in the city of Tokyo
Also the last 24 years in the city Tokyo show no trend, and even a declining trend since 2010:


Data source: Japanese Meteorological Agency (JMA)
What follows is the month-by-month breakdown, May to October:

Data Source: www.data.jma.go.jp/
Urban heat island
Kirye also presents here a comparison of the Tokyo and Hachijo Island temperature course over the past 111 years. Note urban Tokyo has risen while the island off the coast has risen only very slightly:

Data source: JMA
Urban heat island effect? Kirye notes:

The mean daily maximum temperatures for Tokyo and Hachijo Island differed by more than 2C with the early trend during the period from 1907 to 2015, but temperature difference of close to 0.7C with the trend in the latter period.”




Share this...FacebookTwitter "
"
Share this...FacebookTwitterA documentary dubbed “The Weather Machine” produced in 1975 – long before NASA fiddled with the data – warned of an impending ice age (10:35), and maintained that the globe is cooling. Hat-tip: reader The Indomitable Snowman.
The documentary attempted and succeeded at presenting the latest on climate change at the time.
Changing climate accepted as normal
It is true that back in 1975 climatologists already knew that the climate behaved cyclically, as evidenced by the ice cores and tree ring sets extracted from the American Southwest.
Climate change back then was known to be a normal, natural phenomenon. Moreover, after 3 decades of temperature decline, scientists indeed were concerned that the globe was cooling at a worrisome rate.

Part 1: Weather Machine. Exiled Czech climate scientist Dr. George Kukla said in the 1970s: “The ice age is now due any time.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Also, contrary to what was suggested by Michael Mann”s notorious hockey stick chart, the little Ice Age did in fact exist and was clearly evidenced by old historical records from ships, The Weather Machine documentary tells us.
And note that the documentary stated that the Jet Stream also changed its course naturally, just as it does today, and that there was much more to it than just Arctic sea ice extent, on which today some scientists are trying to blame for the frigid winter we are now witnessing.
In Part 2, viewers are told how the ocean cycles have a major impact on the weather cycles, something today that is ridiculously being blamed on trace gas CO2 from human activity.
Little Ice Age warnings…
At the 6 minute mark of Part 2 again we are warned of cooling and the potential of a little ice age, or worse.

Prof. George Denton, University of Maine at Orono, warned we could easily return to Little Ice Age conditions.
Humans may be causing cooling
Later into Part 2 Dr. Reid Bryson of the University of Wisconsin claims that man’s activity may be contributing to the cooling through the “Human Volcano” spewing aerosols into the atmosphere that “blots out” the sun.
Share this...FacebookTwitter "
"At the outset of the 2020s, the UK economy embarks on a new decade with little momentum. Growth has stalled, not least because Brexit uncertainty and a slowdown in the global economy has served as a handbrake on business investment. Meanwhile, consumers have begun tightening their belts and the job market boom of the past decade has petered out. For at least the duration of 2020 another groundhog year awaits thanks to the ongoing Brexit saga, despite the promise Boris Johnson made before the election. But as the economist Mat Lawrence has argued, Brexit is just the firing gun on a wider decade of disruption. The prime minister will not be able to declare the job done and his mission accomplished after the UK’s formal exit later this month. Instead it will mark the first steps towards redefining the nation’s place in a rapidly-changing world. In a prescient report for the Institute for Public Policy Research three years ago, Lawrence outlined five powerful trends that will drive change in the 2020s: The aftershock of Brexit, a demographic tipping point from an ageing society, the rise of new technologies, a shifting global economic order and the existential threat of global heating. These trends aside, much about the coming decade will be tough to predict from today’s vantage point. Johnson says his 10-year plan for Britain will usher in a “new golden age”. Yet, some on the left think Labour could remove him from office in half the time. Donald Trump could be deposed this year. Rising tension in the Middle East could spark a fresh Gulf war, sending oil prices soaring.. One hope in the wake of the election is that the decade ahead will not lead to another 10 years of crippling austerity. The British state is set to grow, with spending as a share of national income due to rise under Johnson’s Tories to 1970s levels according to the Resolution Foundation. This shift is vital to begin the lengthy job of fixing the battered public realm. But the 2020s will still be largely defined by the cost-cutting of the past given the extent of the harm it caused. Britain has three primary economic problems to address from the outset, all arguably made far worse by the spending constraint of the 2010s. First will be to reboot the flatlining productivity growth of the 2010s. Second is the task of rebalancing a fractured nation, by addressing inequalities of wealth, gender, race, education, geography and opportunity. Third will be to decarbonise the UK’s economic model, to prevent the climate emergency from turning into catastrophe. Johnson will need to address each point while also taking on the complex task of redrawing Britain’s trading relationships with the EU, as well as striking new trade deals with other countries. All this comes as the economic world order of the past century faces substantial change that will shape the coming decade for Britain. Asia’s GDP is expected to overtake that of the rest of the world this year, while China could replace the US as the planet’s largest economy by the end of the decade. Asia at large is expected to contribute to roughly 60% of global economic growth by 2030, and should be home to almost all the world’s 2.4 billion new members of the middle class. Britain will fall down the international league table, according to the City bank Standard Chartered, out of the top 10 to rank behind nations such as India and Indonesia by 2030. The emergence of Asia as an economic powerhouse has so far been against a backdrop of ever increasing globalisation. But the 2010s probably marked the high point for the economic integration of recent decades. Trade policy uncertainty reached unprecedented levels in 2019. Phase one of a resolution in the US-China trade dispute that provided much of that uncertainty is expected next week, but economists expect the world to increasingly fragment over the next decade. At the same time as our economies look set to slip further apart, global heating and a new mass extinction mean greater political cooperation will be required to tackle the climate emergency. Amid these competing forces, there are warnings from the World Bank that doing nothing could mean climate impacts pushing an additional 100 million people into poverty by 2030. The poorest regions of the world – Sub-Saharan Africa and south Asia – are expected to be hit the hardest, prompting a migration crisis as people flee increasingly extreme weather events. To respond to the threat, the decade ahead will be pivotal. World leaders have targeted the 2020s as a “decade of delivery” to reach the UN’s sustainable development goals – 17 targets to eliminate extreme poverty, cut inequalities and combat the climate emergency – adopted by the UN general assembly to hit by 2030. Progress is being made, but much more needs to be done. A major risk will be that countries get distracted from the task by another global recession. Given rising geopolitical tensions, and the simple fact that national recessions tend to take place roughly ever ten years, the chances are rising. For the US, the current expansion is the longest on record, while in the UK the 2010s marked the first decade since reliable records began – in the 1700s - in which recession was completely avoided. Either way economists expect growth over the 2020s in wealthy nations to be much slower than average in the decades before the 2008 financial crisis amid an ongoing demographic shift. Working-age populations are expected to shrink, including in the UK, where the number of over 85-year-olds is projected to almost double in the next 25 years – raising questions for growth and the funding of public services. There are hopes that technological advances could address both the demographic shift and the climate emergency. But like a common thread running through these issues facing Britain in the 2020s, greater government coordination and funding will be required to realise the ambition. Central banks head into the 2020s with interest rates close to, at, or below zero, meaning that the effectiveness of tweaking interest rates to stimulate demand is effectively neutered. Andrew Bailey will have an important role to play to continue the work of Mark Carney at the Bank of England, becoming governor for eight years of the 2020s starting in March, but low inflation and lack of room for manoeuvre mean the government must take the primary role. Voters are increasingly fed up with kick-the-can policymaking. At the outset of the 2020s, Britain and the world are entering a disruption decade. • Sign up to the daily Business Today email here or follow Guardian Business on Twitter at @BusinessDesk."
nan
"Inside Digital Realty’s Dublin data centre, racks of shiny black servers throb and whirr as unseen fans cool machines that steadily process unending data. It operates 24 hours a day from the business park, sited on a former orchard, and the data joins a digital torrent in an underground fibre ring network that sweeps around the Irish capital and connects to undersea cables – the physical backbones of the digital world.  It is not just for Ireland. This is also how the UK and continental Europe accesses a lot of email, social media, online shopping, Netflix and other internet services. “Everything with the word smart in front of it has a data centre behind it,” said Ben Bryan, Digital Realty’s technical operations manager in Dublin. But there is a catch. The surge in Irish data processing will require significant new energy infrastructure and increase emissions, complicating Ireland’s response to the climate crisis. The cloud can create carbon: it is estimated that when the music video Despacito reached 5bn streamed YouTube views in 2018, the energy consumption was equivalent to powering 40,000 US homes a year (it has now exceeded 6.5bn views). By 2028 data centres and other large users will consume 29% of Ireland’s electricity, according to EirGrid, Ireland’s state-owned transmission system operator. Worldwide data centres consume about 2% of electricity, a figure set to reach 8% by 2030. Few countries, if any, will match Ireland’s level. It is already Europe’s data centre capital, with Amazon, Google and Microsoft siting operations there. Dozens of centres have opened in recent years, bringing the total to 54, with a combined power capacity of 642MW. Once a leading exporter of floppy discs and CD-Roms, Ireland has successfully transitioned to the big data era. It is just the beginning. With the state’s blessing another 10 centres are under construction, including a €1bn (£845m) Amazon hub in Mulhuddart, west Dublin, that together will add 202MW. Another 31 centres have planning permission, which would add 629MW. There has been one setback: planning approval delays prompted Apple to scrap a planned €850m (£743m) centre last year. “The data centre industry is growing so fast it’s hard to fathom,” said Patrick Bresnihan, a geography professor at Maynooth University in Ireland. “But somehow the tech companies get far less attention than aviation or fossil fuel companies.” Ireland faces a dilemma. The expanding web of data centres is part of a strategy to anchor tech companies that drive economic growth. They have been designated as “critical infrastructure”, facilitating planning approval. “Data centre presence in Ireland raises our visibility internationally as a technology-rich, innovative economy,” said a spokesperson for the Department of Business, Enterprise and Innovation (DoBEI). But the boom will exact a price. Ireland is one of the EU’s worst carbon emission offenders and faces fines of more than €250m for missing 2020 targets on reducing greenhouse gas emissions. Missing later targets will trigger steeper fines. A report by the Irish Academy of Engineering (IAE) has estimated data centre expansion will require almost €9bn in new energy infrastructure and add at least 1.5m tonnes to Ireland’s carbon emissions by 2030 – up 13% spike on current electricity sector emissions. Ireland’s data centres have a low profile. They tend to operate from anonymous-looking business parks with high-security perimeter fences and intruder detection alarms. A Google centre has colourful murals but the rest are grey and nondescript, with discreet signage. Digital Realty, whose headquarters is in San Francisco, has a relatively small centre in Profile Park, part of a cluster in west Dublin. Its two data halls are powered by 9MW, a fraction of some neighbours but enough to require an electricity substation. It powers the servers and fans which during winter suck in cool air from outside. If the power – and cooling – stopped the machines would swiftly overheat, said Bryan. That has never happened but just in case there are backup diesel generators on the roof. The electricity came from 100% renewable sources, said Valerie Walsh, a company vice-president. “There is a huge amount of thought to make sure we’re sustainable and do the right thing.” Google and Amazon representatives also said their Irish data centres were energy efficient and entirely supplied by – or soon would be - renewable energy. Earlier this year Amazon Web Services announced backing for a 91.2MW windfarm in Donegal and a 23.2MW windfarm in Cork. Such deals could act as a catalyst for renewable energy investment, said the DoBEI, citing a 2018 government report. Asked about the estimated 1.5m tonnes of carbon emissions, it replied: “The department is not in a position to comment on the accuracy or otherwise of the estimates of the IAE study, which it is not a party to.” Bresnihan, the academic, said Ireland’s dependence on big tech companies should not obscure their environmental cost. “If they left Ireland would be in a pretty bad situation but there’s only so long you can put off these contradictions.”"
"The restoration of natural ecosystems – “rewilding” – ought to be a chance to create inspiring new habitats. However the movement around it risks becoming trapped by its own reverence of the past; an overly nostalgic position that makes rewilding less realistic and harder to achieve. The recent launch of Rewilding Britain is certainly exciting and timely. However George Monbiot’s vision of bringing back 15 iconic species falls short of the rewilding visions being discussed in universities.  These are emerging from advances in functional ecology and Earth system science. The vision of rewilding is more ambitious: it is about restoring ecological processes through reassembling the species that drive them. For example rooting by wild boars has repercussions throughout a woodland ecosystem. Such animals shouldn’t be reintroduced simply because they were once there, but because they could do something productive in future. Monbiot’s quest to restore “lost” species harks back to a past age. However many conservation scientists are more relaxed concerning the question of “nativenes”. They are willing to consider introducing non-native species if they contribute a  functional role in ecosystems, and they view the past not as a benchmark to preserve or replicate but as an inspiration for ecosystem restoration.  For instance, “Monbiot’s 15” omits the auroch  and tarpan which are classed as extinct. However in the 1980s progressive Dutch ecologists realised that their functional analogues survived as cattle and ponies and their ecological role could be restored through “de-domestication”. They set about de-domesticating them at the famous Oostvaardersplassen reserve located a 40 minute drive from Amsterdam. This produced a “Serengeti-like” landscape: a type of nature unknown to Europe since humans settled down and started farming.  The OVP, as it is known, made nature conservation political again and has become a landmark public experiment in ecology. I first visited it with a group of students in 2003 when we travelled to the Netherlands to meet the radical ecologist Frans Vera and engage with the controversies created by rewilding.   The OVP is created on reclaimed land and opponents argued that the fences and flood control created an artifical landscape that undermined any claims to its authenticity as a restored ecosystem. More seriously the policy of allowing the cattle and ponies to die of “natural” starvation enraged animal welfare and farmer groups who believed they should be subjected to the same welfare standards applied to animals in labs, farms and zoos. The controversies surrounding the experiment, Vera’s hypothesis that Europe’s original vegetation was wood-pasture rather than high-forest, and other radical rewilding visions are inspiring a re-examination of the fundamental premise of nature conservation. I recently published a Rewilding agenda for Europe in the journal Ecography, as my contribution to the European Council’s “fitness check” of its nature legislation. The Birds and Habitats directives under review derive from the science and policy context of the 1970s. They are ageing. Both science and society have moved on.  Any revisions to European nature legislation should support the creation of experimental rewilding sites. Across the UK we could imagine the creation of wild cattle and pony step-lands on the Ridgeway, wild boar and deer-driven woodland ecosystems in Wales, and a Scottish arcadia of bison, moose, wolves and pine forest.  We also need many more OVP-like public rewilding experiments close to urban areas. These would be contained sites that inspire and inform the public about scientific advances, and provoke us all to ask: what sort of nature do we want for the future? Rewilding might offer fresh solutions to intractable conservation problems. For example, conservationists want to remove pine trees introduced to the Sefton Coast dune system near Liverpool but local residents love them for their scenic grandeur and red squirrels.  The famous Formby footprints dating from 2,500 BC show that humans, wild cattle, deer and wolf once inhabited these coastal areas. Suggesting the reintroducing of wild cattle and companion herbivores and seeing what happens might prompt a unified vision for the dunes. In practice rewilding is constrained by regulations on biohazards, public access and animal husbandry – and rigid and powerful 20th century conservation legislation and agencies which have no real incentive to innovate. Conservation institutions need to modernise but no one wants to dismantle them and start over. We need designated spaces with regulatory flexibility – experimental rewilding sites – where we can plan future natures that will improve the quality of life for people and the planet. Ordinary people are disenfranchised. Conservation policy is influenced by a coordinated lobby of a few big charities who have built their organisational models on the institutional structures of the late 20th century.  George Monbiot’s vision catches the attention but advocates of rewilding need to develop realistic policy mechanisms to take their ideas forward. Rewilding experiments would give space for wider reflection and debate and give our conservation institutions time to adapt. Crucially they would reinvigorate conservation as a cultural force in the 21st century."
"The plan to ban the growing of genetically modified crops is disappointing to many scientists. It would be highly unsatisfactory if, as it appears, such an important decision has been made by the Scottish government without a proper informed debate that takes the scientific evidence fully into consideration. It is not enough for the rural affairs secretary, Richard Lochhead, to say that he is not prepared to “gamble” with the future of Scotland’s £14bn food and drink sector.  What we are talking about is simply biological technology with potentially wide and varied applications. Our work at the University of Stirling’s Institute of Aquaculture is a case in point. We have been testing and assessing oils from genetically modified (GM) oilseed crops developed to provide sustainable sources of long-chain omega-3 fatty acids. These nutrients are recommended as part of a healthy diet because they can protect against cardiovascular diseases and promote heart health.  Marine microalgae make most of the world’s omega-3, allowing it to work its way up the marine food chain as they are consumed. As a result, it can only be obtained in any significant amount from fish and seafood. This is why oily fish such as Atlantic salmon are among the best sources of the nutrient.   When it comes to farmed fish, the omega-3 has to be included in their diets, both for the good of their own health and to ensure that they have the high levels required to pass on to the consumer. This means that the feeds must mimic their wild cousins’ natural diet – hence the historic use of fishmeal and fish oil in “traditional” feeds. These tend to be imported at present, particularly from the west coast of south America, from Peru and Chile.  Unfortunately there is insufficient omega-3 of the type required available in the world to satisfy human dietary requirements. As fishmeal and especially fish oil supplies are finite and limited, they are being spread thinner in feeds, and the levels of omega-3 in farmed fish are declining. Without new sources of omega-3, the absolute levels of the nutrient will fall below those of wild fish.   The oils that we are developing from GM oilseed crops – in collaboration with crop scientists led by Professor Johnathan Napier at Rothamsted Research – offer a new and sustainable source of omega-3 that can be used to replace the wild fish oil. Having proven the concept, we are now seeking funding for commercial-scale trials. With a fair wind, the work will foreseeably be ready for full-scale commercialisation in the next two or three years.  The project addresses not only an important aspect of population health but also issues of environmental impact, sustainability and food security. When you consider that Scotland has a high death rate from heart disease – one third of all deaths – it is ironic that that we are also a nation producing many thousands of tonnes of farmed salmon that can be a rich source of the beneficial omega-3 fatty acids.  Yet the Scottish government would not permit these GM crops to be grown in the very country where the oils the crops produce can be applied most effectively. Assuming our work reaches the market, this would mean that Scotland would lose the financial benefits from growing the oilseed. Neither is it environmentally sound to grow crops elsewhere and ship the oils around the world when they could be grown locally. These extra costs could undermine the sustainability of the aquaculture industry in Scotland, one of the key segments of the country’s food and drink sector. This is of direct relevance to the health and welfare of its people, not to mention consumers of Scottish farmed salmon all over the world.  Obviously this is not to suggest that omega-3 or GM are panaceas for all our ills. Our research simply highlights one application of GM technology to solve a critical problem, and the context within which it was developed. But while few would disagree that Scotland has a beautiful natural environment or that seeking to protect it is a good policy, what exactly are the risks that growing GM crops actually pose? The Scottish government’s announcement is rather unclear when it comes to this question.  In September 2014, Scotland showed the world how to have a truly public and inclusive debate on a subject of massive national and international importance, make a decision based on that debate, and then accept and live with that decision. If the true lesson of that was not to have a debate that you think you might lose, the Scottish government appears to have learned it all too well."
"
Share this...FacebookTwitter Already 14 New (2018)
Non-Hockey Stick Papers

During 2017, there were 150 graphs from 122 scientific papers published in peer-reviewed journals that indicated modern temperatures are not unprecedented, unusual, or hockey-stick-shaped — nor do they fall outside the range of natural variability.
Less than 3 weeks into the new publication year, the explosion of non-alarming depictions of modern climate change continues.



Blarquez et al., 2018


 Magyari et al., 2018
…its climatic tolerance limits were used to infer July mean temperatures exceeding modern values by 2.8°C at this time [8200-6700 cal yr BP] (Magyari et al., 2012).


White et al., 2018
Our data, together with published work, indicate both a long-term trend in ENSO strength due to June insolation [solar] forcing and high-amplitude decadalcentennial fluctuations; both behaviors are shown in models. The best-supported mechanism for insolation-driven dampening of ENSO is weakening of the upwelling feedback by insolation-forced warming/deepening of thermocline source waters. … Another potential source of decadal-centennial forcing is total solar irradiance, which varied more in the early Holocene than the mid- to late Holocene [Marchitto et al., 2010]. Changing solar irradiance is theoretically capable of affecting ENSO via ocean dynamical cooling [Emile-Geay et al., 2007], and is correlated with centennial-scale variations in early Holocene ENSO [Marchitto et al., 2010].


Song et al., 2018
[A] general warm to cold climate trend from the mid-Holocene to the present, which can be divided into two different stages: a warmer stage between 6842 and 1297 cal yr BP and a colder stage from 1297 cal yr BP to the present. … The general cooling trend may represent a response to decreasing solar insolation; however, the relative dryness or wetness of the climate may have been co-determined by westerlies and the East Asian summer monsoon (EASM). The climate had a teleconnection with the North Atlantic region, resulting from changes in solar activity.


Huang et al., 2018
A period of weak chemical weathering, related to cold and dry climatic conditions, occurred during the Little Ice Age (LIA), whereas more intense chemical weathering, reflecting warm and humid climatic conditions, was recorded during the Medieval Warm Period (MWP). Besides, an intensification of chemical weathering in Poyang Lake during the late Holocene agrees well with strong ENSO activity, suggesting that moisture variations in central China may be predominantly driven by ENSO variability. … Rao et al. (2016b) demonstrated that a humid late-Holocene in central China and an arid late-Holocene in southern and northern China were significantly related to strong ENSO activity. Thus, it seems that ENSO forcing may be likely dominant factor controlling moisture variations in central China.


Perner et al., 2018
[W]e find evidence of distinct late Holocene millennial-scale phases of enhanced El Niño/La Niña development, which appear synchronous with northern hemispheric climatic variability.
Phases of dominant El Niño-like states occur parallel to North Atlantic cold phases: the ‘2800 years BP cooling event’, the ‘Dark Ages’ and the ‘Little Ice Age’, whereas the ‘Roman Warm Period’ and the ‘Medieval Climate Anomaly’ parallel periods of a predominant La Niña-like state.
Our findings provide further evidence of coherent interhemispheric climatic and oceanic conditions during the mid to late Holocene, suggesting ENSO as a potential mediator.





<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Maley et al., 2018



Polovodova Asteman et al., 2018
The record demonstrates a warming during the Roman Warm Period (~350 BCE – 450 CE), variable bottom water temperatures during the Dark Ages (~450 – 850 CE), positive bottom water temperature anomalies during the Viking Age/Medieval Climate Anomaly (~850 – 1350 CE) and a long-term cooling with distinct multidecadal variability during the Little Ice Age (~1350 – 1850 CE). The fjord BWT [bottom water temperatures] record also picks up the contemporary warming of the 20th century, which does not stand out in the 2500-year perspective and is of the same magnitude as the Roman Warm Period and the Medieval Climate Anomaly.

 


Papadomanolaki et al., 2018  (Baltic Sea)
A large fraction of the Baltic Proper became hypoxic again between 1.4 and 0.7 ka BP, during the Medieval Climate Anomaly (MCA), when mean air temperatures were 0.9–1.4 °C higher than temperatures recorded in the period 1961–1990 (e.g. Mann et al., 2009; Jilbert and Slomp, 2013).

20th/21st Centuries Non-Warming

Yi, 2018
As measures of climate response, temperature and precipitation data from the north, east, and south-facing mountain ranges of Shennongjia Massif in the coldest and hottest months (January and July), different seasons (spring, summer, autumn, and winter) and each year were analyzed from a long-term dataset (1960 to 2003) to tested variations characteristics, temporal and spatial quantitative relationships of climates. The results showed that the average seasonal temperatures and precipitation in the north, east, and south aspects of the mountain ranges changed at different rates. The average seasonal temperatures change rate ranges in the north, east, and south-facing mountain ranges were from –0.0210 ℃/yr to 0.0143 ℃/yr, –0.0166 ℃/yr to 0.0311 ℃/yr, and  –0.0290 ℃/yr to 0.0084 ℃/yr, respectively, and seasonal precipitation variation magnitude were from –1.4940 mm/yr to 0.6217 mm/yr, –1.6833 mm/yr to 2.6182 mm/yr, and –0.8567 mm/yr to 1.4077 mm/yr, respectively. The climates variation trend among the three mountain ranges were different in magnitude and direction, showing a complicated change of the climates in mountain ranges and some inconsistency with general trends in global climate change.


Bereiter et al., 2018
Our reconstruction provides unprecedented precision and temporal resolution for the integrated global ocean, in contrast to the depth-, region-, organism- and season-specific estimates provided by other methods. We find that the mean global ocean temperature is closely correlated with Antarctic temperature and has no lead or lag with atmospheric CO2, thereby confirming the important role of Southern Hemisphere climate in global climate trends. We also reveal an enigmatic 700-year warming during the early Younger Dryas period (about 12,000 years ago) that surpasses estimates of modern ocean heat uptake.

(press release)
“Our precision is about 0.2 ºC (0.4 ºF) now, and the warming of the past 50 years is only about 0.1 ºC,” he said, adding that advanced equipment can provide more precise measurements, allowing scientists to use this technique to track the current warming trend in the world’s oceans.


 Purich et al., 2018
Observed Southern Ocean changes over recent decades include a surface freshening (Durack and Wijffels 2010; Durack et al. 2012; de Lavergne et al. 2014), surface cooling (Fan et al. 2014; Marshall et al. 2014; Armour et al. 2016; Purich et al. 2016a) and circumpolar increase in Antarctic sea ice (Cavalieri and Parkinson 2008; Comiso and Nishio 2008; Parkinson and Cavalieri 2012).  … [A]s high-latitude surface freshening is associated with surface cooling and a sea ice increase, this may be another factor contributing to the CMIP5 models excessive Southern Ocean surface warming contrasting the observed surface cooling (Marshall et al. 2014; Purich et al. 2016a), and sea ice decline contrasting the observed increases (Mahlstein et al. 2013; Polvani and Smith 2013; Swart and Fyfe 2013; Turner et al. 2013; Zunz et al. 2013; Gagne et al. 2015) over recent decades. … Our results suggest that recent multi-decadal trends in large-scale surface salinity over the Southern Ocean have played a role in the observed surface cooling seen in this region. … The majority of CMIP5 models do not simulate a surface cooling and increase in sea ice (Fig. 8b), as seen in observations.


Cerrone and Fusco, 2018
Compelling evidence indicates that the large increase in the SH sea ice, recorded over recent years, arises from the impact of climate modes and their long-term trends. The examination of variability ranging from seasonal to interdecadal scales, and of trends within the climate patterns and total Antarctic sea ice concentration (SIC) for the 32-yr period (1982–2013), is the key focus of this paper. The results herein indicate that a progressive cooling has affected the year-to-year climate of the sub-Antarctic since the 1990s. This feature is found in association with increased positive SAM and SAO phases detected in terms of upward annual and seasonal trends (in autumn and summer) and upward decadal trends. In addition, the SIC [sea ice concentration] shows upward annual, spring, and summer trends, indicating the insulation of Antarctica from the warmer flows in the midlatitudes.

Palmer et al., 2018

Share this...FacebookTwitter "
"Imagine a world populated by woolly mammoths, giant sloths and car-sized armadillos – 50,000 years ago more than 150 types of these mysterious large-bodied mammals roamed our planet. But by 10,000 years ago, two-thirds of them had disappeared.  Since the end of the 19th century, scientists have puzzled over where these “megafauna” went. In 1796, the famous French palaeontologist Georges Cuvier suggested a global catastrophe had wiped them out. Others were appalled. The great Thomas Jefferson was so against Cuvier’s idea he sent an expedition to try to find vast herds of these animals grazing contentedly in the American interior. The only thing anyone could say with certainty was there should be a lot more of them than we see today.  Alfred Wallace, who wrote the first paper on evolution by natural selection with Charles Darwin, noted that “we live in a zoologically impoverished world, from which all the hugest, and fiercest, and strangest forms have recently disappeared”.  It’s one of the great historical whodunnits: what happened to the megafauna, and when did they disappear? As with any good mystery, there are two main suspects: climate and humans. The idea that our ancestors may have hunted the huge beasts to extinction has long been a popular view, particularly as the spread of humans around the world appears closely associated with their demise. Several major criticisms continue to be levelled at this theory, the most popular being that many large animals are still present in Africa, despite it having the longest record of occupation by people. Others in turn argue that humans co-evolved alongside megafauna in Africa for millions of years, giving animals time to learn from human behaviour. The alternative is that a rapidly changing climate caused the habitat of the megafauna to shrink or disappear. As the planet warmed out of the last ice age 12,000 years ago, many animals would have struggled to adapt to the new environment. A major criticism here is that there have been other major climatic changes in the past, some of which have been equally extreme and rapid. What could have been so different with this most recent warming? In a research paper published in the journal Science, we report new advances in ancient DNA, carbon dating and climate reconstruction that finally give some answers. Previously, as long as species appeared to survive in the fossil record the interpretation had been that nothing significant had happened for tens of millennia.  But thanks to ancient DNA analysis of megafaunal bones we now know that this approach has missed a series of events throughout the past 50,000 years when major parts of a species’ genetic diversity, or even the whole species itself, disappeared. Alongside this, more accurate carbon dating of the fossil remains shows these extinctions did not all happen at a single time but were staggered through time and space. It’s important to realise the backdrop to these extinctions was a wildly fluctuating climate. The ice age of the northern hemisphere was not one long frigid wasteland.  Instead, frozen conditions were punctuated by many short, rapid warming periods, known as interstadials, where temperatures would soar from 4 to 16˚C within just a few decades and last for hundreds to thousands of years. They represent some of the most profound climate changes detected in the recent geological past.  When we precisely compared the dates for European and American extinctions with climate records, we were amazed to find they coincided with the abrupt warming of the interstadials; in stark contrast there is a complete absence of extinctions at the height of the last ice age.  As temperatures rose during the interstadials, dramatic shifts in global rainfall and vegetation patterns would have placed the megafauna under immense stress. Those that could not adapt to the rapidly changing conditions would have quickly succumbed. The European cave lion, for instance (Panthera leo spelaea in the chart below), survived through periods when much of the continent was covered in ice, only to go extinct during relatively benign conditions around 14,500 years ago. There seems little doubt humans would have contributed to extinctions, however. While the dramatic climate shifts were the major driver in megafaunal extinction events, humans would have applied the coup de grâce to populations already suffering major stress.  In one likely scenario, humans would have concentrated their hunting efforts along dispersal routes, killing the few bold individuals moving out to re-establish an extinct population, causing localised extinctions to expand into larger and larger areas, that would have eventually led to an irreversible ecosystem collapse. It’s likely the scattered pattern of extinctions and the difficulty of detecting them from fossils alone is why the relationship with warming events has not been detected before. So what does this mean for the future? Well for a start, rapidly increasing temperatures are not good news for the megafauna that survived the last warming. In many ways the rise of atmospheric CO2 levels and resulting warming effects are expected to have a similar rate of change to the onset of past interstadials, heralding another major phase of large mammal extinctions.  This seems all the more likely thanks to our “success” in developing the planet’s surface, breaking up areas of natural habitat and disrupting any connectivity that once existed between areas. Migration is becoming increasingly less of an option for species struggling to adapt to changing temperatures with little chance of back filling from neighbouring areas for re-establishing populations. Even after all these years, megafauna are providing a precious lesson from the past."
"
Share this...FacebookTwitterIn Germany there is one weather station that has be intact and unchanged for some 138 years. 
It has never been moved and never been corrupted by the urban heat island (UHI) effect. Moreover it has consistently used the same instrumentation and computation method over the entire period, thus making it rare indeed. Few station can boast having those instrumentation qualities.
That measurement station is one operated at the Klostergarten of the St. Stephan Abbey in Augsburg just northwest of Munich.
44-year veteran German meteorologist Klaus Hager reports the following results of this station (reproduced with permission):
======================================
A look at the January mean temperature in Augsburg from 1879 – 2017 ( 138 years)

The chart below shows the chaotic ups and downs of the mean value of the January temperatures measured in the Klostergarten of the St. Stephan Abbey in Augsburg:

First it’s important to note:

The measurement location has not changed since 1879, nor has it been relocated. The garden area remains 1 hectare in size, and thus is completely representative of the Augsburg inner city area.
The mean temperature was computed by halving the sum of the high temperature and the low temperature.
The measurements were always done using glass thermometers – a mercury thermometer for the maximum and an alcohol thermometer for the minimum – inside an official so-called Stevenson screen.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Thus real continuity with respect to measurement is assured.
Over the entire 138-year observation period the measurements were carried out according to the same technical requirements, which is something that unfortunately can only be said about very few measurement stations.
As the chart above shows, one can see considerable temperature fluctuations from year to year. The deviations from the 138-year mean of -1.0°C are shown in red for above-mean temperatures and in blue for those below the mean. Of course since the end of the 1980s, positive deviations have been far more common, but there remains no detectable relationship with the continuously rising CO2 in the air.
Because nature – as is the case with temperature – is constantly undergoing fluctuations, one ought to be especially careful when it comes to making projections into the future. Unfortunately nature’s complexity also does not allow it to be modelled adequately.
January of 2017 was the seventh coldest since 1879, posting a mean of – 6.1°C.
Finally let’s not forget to thank the fathers of the St. Stephan Abbey for having recorded the temperatures every day until today.
 

Share this...FacebookTwitter "
"Tens of thousands of people remained stranded on Thursday evening while attempting to flee bushfire-ravaged areas of the south-east Australian coast – having earlier been urged to leave before the return of extreme and dangerous weather conditions. The mass evacuation of communities in New South Wales and Victoria is among the largest ever emergency movements of people in Australia. The numbers fleeing the bushfire crisis remain unclear, but are expected to compare to the 60,000 people who were flown out of Darwin after Cyclone Tracy in 1974. Visitors told to flee a vast evacuation area along the NSW south coast reported sitting in gridlock for up to 10 hours after responding to the order to evacuate, as further outbreaks of fire and sheer weight of traffic blocked escape routes north of Ulladulla and near Cooma in the Snowy Mountains. The prime minister, Scott Morrison, urged people to be patient, as he again deflected criticism about his government’s policies to address the causes of climate change. “I know you can have kids in the car and there is anxiety and there is stress and the traffic is not moving quickly but the best thing to do – the best thing that helps those out there volunteering, out there trying to restore some order to these situations, is for everyone to be patient,” Morrison said. On Thursday afternoon an angry protester told Morrison he should be “ashamed of himself” and that he had “left the country to burn” during a tour of the burnt out town of Cobargo. Authorities in Victoria hold grave fears for 17 people missing across the state, and advised anyone who could do so to leave fire-affected places in the East Gippsland region. The link between rising greenhouse gas emissions and increased bushfire risk is complex but, according to major science agencies, clear. Climate change does not create bushfires, but it can and does make them worse. A number of factors contribute to bushfire risk, including temperature, fuel load, dryness, wind speed and humidity.  The Bureau of Meteorology and the CSIRO say Australia has warmed by 1C since 1910 and temperatures will increase in the future. The Intergovernmental Panel on Climate Change says it is extremely likely increased atmospheric concentrations of greenhouse gases since the mid-20th century is the main reason it is getting hotter. The Bushfire and Natural Hazards research centre says the variability of normal events sits on top of that. Warmer weather increases the number of days each year on which there is high or extreme bushfire risk. Dry fuel load - the amount of forest and scrub available to burn - has been linked to rising emissions. Under the right conditions, carbon dioxide acts as a kind of fertiliser that increases plant growth.  Dryness is more complicated. Complex computer models have not found a consistent climate change signal linked to rising CO2 in the decline in rain that has produced the current eastern Australian drought. But higher temperatures accelerate evaporation. They also extend the growing season for vegetation in many regions, leading to greater transpiration (the process by which water is drawn from the soil and evaporated from plant leaves and flowers). The result is that soils, vegetation and the air may be drier than they would have been with the same amount of rainfall in the past. The year coming into the 2019-20 summer has been unusually warm and dry for large parts of Australia. Above average temperatures now occur most years and 2019 has been the fifth driest start to the year on record, and the driest since 1970. Not a significant one. Two pieces of disinformation, that an “arson emergency”, rather than climate change, is behind the bushfires, and that “greenies” are preventing firefighters from reducing fuel loads in the Australian bush have spread across social media. They have found their way into major news outlets, the mouths of government MPs, and across the globe to Donald Trump Jr and prominent right-wing conspiracy theorists. NSW’s Rural Fire Service has said the major cause of ignition during the crisis has been dry lightning. Victoria police say they do not believe arson had a role in any of the destructive fires this summer. The RFS has also contradicted claims that environmentalists have been holding up hazard reduction work. At the Victorian coastal inlet of Mallacoota, which is among 20 towns that have been isolated by the fires since Tuesday, between 3,000 and 4,000 people were facing an impending food and water shortage as they waited to be evacuated by sea. On Thursday afternoon, Australian defence force officials said they expected to relocate 800 people using the naval ship HMAS Choules, while others will be airlifted out. Evacuation plans for #Mallacoota are underway, as #YourADF works with emergency services to prepare transferring people to HMAS Choules tomorrow AM. Commanding Officer of Choules, CMDR Houlihan, led the ADF team onshore today to provide timely and relevant support. pic.twitter.com/ecphjfLg9f New South Wales has declared a seven-day state of emergency before extreme conditions, including temperatures exceeding 40C, return to the south coast, Snowy Mountains and the outskirts of Sydney on Friday and Saturday. Evacuation orders were issued to holidaymakers from Batemans Bay to the Victorian border and people were advised that two highway escape routes were opened – north to Sydney along the Princes Highway, and south, via the Monaro Highway, hooking back to Canberra through Cooma. But on Thursday evening both routes were at a standstill as the fire threat lingered, with tailbacks of up to 25km reported. The northern route was blocked from about midday by a bushfire that closed the Princes Highway. Motorists heading north were advised to delay their trip or take shelter at Ulladulla. The road remained closed about 6pm. Motorists were reported abandoning their cars or heading to the south. Gridlock all the way through Ulladulla, similar scenes in Milton, Nowra and Batemans Bay. Just met a woman who’s arrived in Ulladulla after leaving Depot Beach - 30km south - at 7am. I’ll have more on @abcnews The World Today @ 12.10pm on Local Radio, 1pm on @RadioNational pic.twitter.com/iIWnTxPTIv The southern route was also hampered by a bushfire that came close to the Monaro Highway and caused delays north of Cooma. Witnesses said the lines of stationary traffic near Cooma were more than 30km long. Monaro Hwy from Cooma to Canberra. Drive carefully folks. pic.twitter.com/Ltbd5xjU9o Residents in the town of Batlow, famous for its apples, were advised to leave by Friday morning because of forecast fire danger in the Kosciuszko national park and surrounding areas. The entire park has been evacuated and authorities warned conditions were likely to be so severe that surrounding towns could not be defended. One account from a friend trying to evacuate from Malua Bay today:Headed north at 6am. Took 6.5 hours to do 80kms.... then highway closed at Benalong and we were turned back. so we headed south. now at a standstill coming into Bega 10 hours in the car and counting. NSW Rural Fire Service commissioner Shane Fitzsimmons said conditions on Saturday were forecast to be worse than those on New Year’s Eve. “Those fires have spread at the absolute worst-case scenario, which typically is not what happens when it plays out on the ground,” Fitzsimmons said. “The conditions on Saturday are likely to be worse than New Year’s Eve and a lot of those areas in the south-east quadrant of the state have the potential to be impacted and impacted very heavily.” The New South Wales premier, Gladys Berejiklian, said the state of emergency from Friday would give emergency services the authority to undertake forced evacuations and road closures at short notice. “We don’t take these decisions lightly but we also want to make sure we’re taking every single precaution to be prepared for what could be a horrible day on Saturday,” she said. Since Christmas Day, nine people have been killed in bushfires across New South Wales and Victoria, while 17 people have died since the season began. About 150 fires continued to burn in Victoria and NSW on Thursday afternoon and officials warned they would be unable to control the blazes before conditions worsen. “We have no capacity to contain these fires … the fires are going to do what they are going to do, and people have to get out of that area,” NSW Rural Fire Service deputy commissioner Rob Rogers said. Earlier on Tuesday, Morrison attended the funeral of Geoffrey Keaton, a volunteer firefighter who died on 19 December when his truck rolled at Green Wattle Creek, south of Sydney. At a press conference afterwards, Morrison was repeatedly asked about his government’s climate policy. “I understand the anxiety and I understand the fear that is there for many and I understand the frustration, but this is a natural disaster,” he said. “What we are saying is we cannot control the natural disaster but what we can do is control our response. “The drought has created a tinder box around the country and that has, through various forms of ignition, has seen these fires run for long periods of time.”"
"
Share this...FacebookTwitterUPDATE:Hat-tip: Kenneth
Graph showing increasing Adélie penguin numbers during 1982-2015
Che-Castaldo et al., 2017
“We found a marked and steady increase in [Adélie penguin] abundance around the rest of the Antarctic continent, including both Eastern Antarctica and the Ross Sea [during 1982-2015].”
Scientists have historically determined that increasing Adélie penguin numbers seem to coincide with warm periods, whereas cooling periods elicit population declines (Emslie et al., 2007; Huang et al., 2009).
===============================================
Once again I’m bringing you today another one from Lüning’s and Vahrenholt’s Die kalte Sonne, this one concerning a recent study claiming the “king penguin populations are at heavy extinction risk under the current global warming predictions“.

With dire (phony) study claims of king penguins being threatened by global warming, climate science and media once again do their usual number on the public. Image source here. CC BY-SA 3.0
=====================================================
What did the king penguins do 1500 years ago when it was warmer than it is today?
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
The online Swiss daily Luzerner Zeitung reported on 27 February 2018:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




King’s penguin threatened by climate change
Climate change is threatening more than 70 percent of the king penguin colonies. So writes an international team of scientists in the journal ‘Nature Climate Change’. The animals have to move further south and thus into colder areas. […] The king penguin (aptenodytes patagonicus) is the second largest type of penguin after the emperor penguin. According to the study, the population is currently 1.6 breeding pairs. Over thousands of years the king penguins have been able to rely on the Antarctic polar front, the researchers write. That is a system of currents the transports masses of water from the depths to the surface and so provides for a large fish supply for a relatively small area. Because of climate change, the polar front is shifting to the south and is leaving the Crozet Islands, the Kerguelen and Marion Island on which the penguins live.”
Read more at the Luzerner Zeitung.
Once again we have the fairy tale that everything in the past was stable and that today it’s warmer than ever before. But just one look at Stenni et al. 2017 would have sufficed:
Antarctic climate variability on regional and continental scales over the last 2000 years
[…] Our new reconstructions confirm a significant cooling trend from 0 to 1900 CE across all Antarctic regions where records extend back into the 1st millennium, with the exception of the Wilkes Land coast and Weddell Sea coast regions. Within this long-term cooling trend from 0 to 1900 CE, we find that the warmest period occurs between 300 and 1000 CE, and the coldest interval occurs from 1200 to 1900 CE. Since 1900 CE, significant warming trends are identified for the West Antarctic Ice Sheet, the Dronning Maud Land coast and the Antarctic Peninsula regions, and these trends are robust across the distribution of records that contribute to the unweighted isotopic composites and also significant in the weighted temperature reconstructions. Only for the Antarctic Peninsula is this most recent century-scale trend unusual in the context of natural variability over the last 2000 years. […]”
Let’s take a look at the temperature chart for all of Antarctica over the past 2000 years:

Temperature curve for Antarctica over the past 2000 years. Source: Stenni et al. 2017.
As we see, it has not even been 1000 years ago since the penguins were forced to leave the area where they currently find themselves due to oncoming cold. We would gladly provide the activists with a new pair of spectacles that would correct their climate-historical myopia.
 
Share this...FacebookTwitter "
"Wolves and foxes are closely related and share many of the same characteristics. But look at their eyes – where wolves have rounded pupils like humans, foxes instead have a thin vertical line. But it isn’t just canines –across the animal kingdom, pupils come in all shapes and sizes. So why the differences? It’s a question that has long interested scientists working on vision and optics. In a new study published in the journal Science Advances, colleagues from Durham, Berkeley and I explain why these pupil shapes have developed. Goats, sheep, horses, domestic cats, and numerous other animals have pupils which vary from fully circular in faint light to narrow slits or rectangles in bright light. The established theory for this is that elongated pupils allow greater control of the amount of light entering the eye. For instance, a domestic cat can change its pupil area by a factor of 135 from fully dilated to fully constricted, whereas humans, with a round pupil, can only change area by a factor of 15. This is particularly useful for animals that are active both day and night, allowing for much better vision in low light conditions. However, if the only reason for elongated pupils was to control the amount of light entering the eye, the orientation would not be important: horizontal, vertical, or diagonal would all offer the same advantages.  Instead, the pupils are almost always horizontal or vertical, which suggests there must be other benefits which explain this orientation. Our work has focused on the visual benefits of vertical and horizontal pupils in mammals and snakes. One of the most interesting factors we found is that the orientation of the pupil can be linked to an animal’s ecological niche. This has been described before, but we went one step further to quantify the relationship.  We found animals with vertically elongated pupils are very likely to be ambush predators which hide until they strike their prey from relatively close distance. They also tend to have eyes on the front of their heads. Foxes and domestic cats are clear examples of this. The difference between foxes and wolves is down to the fact wolves are not ambush predators – instead they hunt in packs, chasing down their prey. In contrast, horizontally elongated pupils are nearly always found in grazing animals, which have eyes on the sides of their head. They are also very likely to be prey animals such as sheep and goats. We produced a computer model of eyes which simulates how images appear with different pupil shapes, in order to explain how orientation could benefit different animals. This modelling showed that the vertically elongated pupils in ambush predators enhances their ability to judge distance accurately without having to move their head, which could give away their presence to potential prey. Grazing animals have different problems to deal with. They need to check all around for prey and they need to flee rapidly in case of attack. Having eyes towards the side of their head helps them to see nearly all around them. Having a horizontal pupil enhances the amount of light they can receive in front of and behind them while reducing the amount of light from above and below. This allows them panoramic vision along the ground to help detect potential predators as early as possible. The horizontal pupil also enhances the image quality of horizontal planes and this enhanced view at ground level is also an advantage when running at speed to escape. So, vertically elongated pupils help ambush predators capture their prey and horizontally elongated pupils help prey animals avoid their predators. We realised our hypothesis predicted that shorter animals should have a greater benefit from vertical pupils than taller ones. So we rechecked the data on animals with frontal eyes and vertical pupils and found that 82% are what is considered “short” (which we defined as having a shoulder height of less than 42cm) compared with only 17% of animals with circular pupils.  We also realised that there is a potential problem with the theory for horizontal elongation. If horizontal pupils are such an advantage to grazing animals, what happens when they bend their head down to graze? Is the pupil no longer horizontally aligned with the ground?  We checked this by observing animals in both a zoo and on farms. We found that eyes of goats, deer, horses, and sheep rotate as they bend their head down to eat, keeping the pupil aligned with the ground. This remarkable eye movement, which is in opposite directions in the two eyes, is known as cyclovergence. Each eye in these animals rotates by 50 degrees, possibly more (we can only make the same movement by a few degrees). There are still some unexplained pupils in nature. For example, mongooses have forward-facing eyes but horizontal pupils, geckos have huge circular pupils when dilated which reduce down to several discrete pinholes when constricted and cuttlefish have “W”-shaped pupils. Understanding all these variations is an interesting challenge for the future."
"Most life in the sea ultimately depends on photosynthetic plankton. Also known as microalgae, these tiny or microscopic organisms live near the surface and take their energy from the sun and pass it on through the marine food chain.  But these plankton have a big role to play above the surface of the sea too. In new study published in the journal Science Advances, colleagues and I found that plankton help to control clouds over remote seas far from land. These clouds in turn bounce the sun’s energy back into space, regulating the Earth’s climate and keeping temperatures cooler than they would otherwise be without them. Clouds are made up of many tiny droplets of water that have condensed from water vapour onto microscopic particles floating in the Earth’s atmosphere. These particles are known as cloud condensation nuclei. Plankton essentially help provide clouds with these nuclei to form around.  The number of these particles in a given volume helps to determine the number of droplets in a cloud, which can have a big influence on how much sunlight a cloud reflects back into space. The more droplets a given mass of cloud water is broken up into, the more sunlight is reflected, as the overall surface area of the cloud’s droplets increases. Since a significant portion of the planet’s reflectivity, or albedo, is due to clouds, this can have a major impact on the energy balance of the Earth. To investigate the link between plankton and clouds, we looked at the Southern Ocean. This sea, encircling Antarctica, is one of the most remote places on the planet and far from any man-made sources of particles. And yet it is also one of the cloudiest places on Earth. What then are these clouds clinging on to? We analysed satellite cloud data in a section of the Southern Ocean spanning right around the globe between the 35th parallel south (which passes through Australia and just south of South Africa) and the 55th (which just clips the bottom of South America).  We found that more cloud droplets tended to occur above patches of the ocean with more plankton, indicated by increased concentrations of a type of chlorophyll used in photosynthesis. This means plankton are likely to influence cloud albedo and the amount of energy from the sun that is reflected to space.  Most of this is down to plankton releasing gases either through cell ageing, or when they are broken open and eaten by their microscopic animal counterparts zooplankton. Some of this gas is then converted into new microscopic solid particles, or adds to existing particles, which act as extra condensation nuclei. However, we also found that some organic material – which can come from the bodies of the plankton, other sea creatures, viruses, bacteria and so on – is emitted directly into the atmosphere through sea spray. Water can condense around these tiny particles, forming extra cloud droplets (although organic material may affect droplet numbers in other ways too – the science is still hotly debated). We also estimated how much extra solar energy was prevented from reaching the surface due to the extra cloud droplets formed by phytoplankton – up to ten watts per square metre in summer. That’s comparable to similar estimates of the annual mean effect on clouds from man-made particles downwind of highly polluted regions. Thus, in a lifeless ocean without phytoplankton it is likely that the Southern Ocean’s surface would be somewhat warmer.  Many climate models underestimate the amount of sunlight reflected back into space by clouds in the Southern Ocean. This can lead to errors in regional sea surface temperature predictions and incorrect large-scale circulation patterns both locally  and in far afield regions such as the tropics, and so it is important that they are corrected.  These biases might partly be down to an unrealistic representation of the link between phytoplankton and cloud formation. Somewhat ironically, uncertainties in our knowledge of the “baseline” effect of these natural condensation nuclei are also one of the biggest causes of uncertainties in how anthropogenic aerosols are affecting the climate. Due to its remoteness and inhospitality there is, however, very little in-situ data available from within Southern Ocean clouds with which to study what is going on. This makes satellite data very valuable, but also emphasises the need for more direct observations in this region."
"Since the dawn of aviation, planes have primarily been powered by carbon-based fuels such as gasoline or kerosene. These contain a lot of energy for their weight, providing the vast power required to lift large commercial airliners on journeys across the globe. But with oil resources declining and penalties on greenhouse gas emissions increasing, the future of aviation is dependent on finding an alternative power source. Is electricity the answer? A first step is to develop “more electric aircraft” – jet-powered planes that maximise the use of electricity for all the other aircraft systems. The idea is to significantly reduce fuel consumption by improving overall energy efficiency. In practice, this means reducing the weight of the aircraft, reducing drag with improved aerodynamics and optimising the flight profile to use less fuel.  But though these improvements can save on fuel, that alone isn’t enough. The shift to more sustainable aircraft requires major, longer-term solutions. Such significant innovations have often been driven by military requirements. The jet turbine engine was developed during World War II and the US Air Force’s Chuck Yaeger first broke the sound barrier in the Bell X-1 as part of the Cold War race to achieve supersonic speeds. The drive for new technologies led to massive improvements in performance and reliability, which has since filtered through to commercial aviation and made mass intercontinental air travel a reality. Concorde was the ultimate expression of this transformation from military to high-performance commercial aircraft, but despite its phenomenal performance it was plagued by complaints of excessive noise and pollution. Modern jet air travel still consistently raises such environmental concerns and, while the military has an obvious incentive to design the fastest aircraft, its motivation to go green is less obvious. We may need to look elsewhere for the next big innovation. Solar-powered endurance aircraft have received a lot of attention recently, with the Solar Impulse team attempting to make the first round-the-world flight. But solar power, while an interesting technical challenge, is not a particularly realistic option for mass transit of passengers. As can be seen from the Solar Impulse aircraft, the power output from the Solar Panels on a very wide wingspan is able to transport only the aircraft and the pilot for any significant distance. Battery storage is the key limiting factor for electric aircraft. If electric aircraft are held back by either weight or fuel restrictions, it’s probably down to the battery. Aircraft typically have a longer fuelling time than a car, so rapid recharging is possible and effective, as current jet aircraft take about the same time to refuel (and also for passenger and cargo turnaround) so electric charging of about 1hr is reasonable, however the critical problem is energy density – how much energy does the battery provide for its weight?  Typical lithium-ion batteries in use today have a maximum energy density of around 1,000,000 joules of energy per kilogram, and while newer research promises the possibility of higher densities, these are not available commercially. A million joules sounds like a lot. However, compare this with 43 million joules per kilogram for aviation fuel. Swapping the fuel tanks for a battery weighing 43 times as much isn’t a viable option – clearly there’s a significant storage problem to be solved before electricity can power large aircraft over long distances. So where does electric power fit in the long-term vision for consumer air travel? Despite the obvious technical challenges, The Airbus prototype E-Fan aircraft is due to be put into production by 2017. The E-fan is a very light two-seater plane powered by two electric motors, with a relative speed and carrying capacity far lower than those required by commercial carriers. However,  Within the next decade, this technology may extend to short-range commuter and business aircraft – especially targeting routes that still use conventional propeller propulsion. Airbus has medium-term plans for such an aircraft, with a target capacity of perhaps 60 passengers – making it a suitable platform for short-haul commuter flights. Safety and reliability must be addressed before electric aircraft are adopted by commercial airlines. Much as the electric car still has to achieve a critical level of public confidence, perceived reliability will have a significant impact on consumer trust in new aircraft.  If prototypes such as the E-Fan can build public confidence, this may mark a “tipping point” in overcoming the technical challenges inherent in any new form of transportation, especially in aviation which has a track record of rapid innovation. Advances – particularly in new materials, storage and power electronics technology – may offer the prospect of purely electric commercial aircraft within the next two decades."
nan
"Dairy farmers were racing to shore up supplies of fodder and fuel on Friday as they prepared for a hot weekend that could see the return of fires that have already ravaged much of Australia’s east coast. Two key dairy areas, East Gippsland in Victoria and the New South Wales south coast, were heavily burned during fires over the new year, adding to the woes of an industry already suffering from a crippling drought and persistently low milk prices.  Supermarkets say the fire crisis has not curbed the supply of fresh milk but the head of NSW farmers’ body Dairy Connect, Shaughn Morgan, said it could do so if it continued. “It could have an impact, depending on the amount of milk that’s not collected,” he said.  He said it was hard to get information but the fires were “impacting quite heavily on the south coast from Nowra down”. “These guys aren’t able to get the milk from their farms, they’re spilling their milk,” he said. “We’re very grateful to the processors, who are continuing to pay the farmers.” He said he hoped the declaration of a state of emergency by the state government on Thursday would allow roads to open and farmers to bring in fodder. “If there’s no fodder to feed them [the cows],” he said. “It raises serious questions about the viability of their farms. “Saturday’s a real concern because it is another flashpoint – it’s going to be something that we need to monitor really closely. “The people down there are at their wit’s end and have been under enormous pressure for days.” The president of the United Dairyfarmers of Victoria, Paul Mumford, said there had been reports of pasture damage and some stock losses in East Gippsland and up into the state’s north-east, but information was “still reasonably sketchy coming out of both areas”. “The big problem farmers are having is fire damage not only to pastures but infrastructure – but more importantly getting services back on to the farm.” He said farmers needed fodder to feed their cows, and fuel to power milking equipment. “The cows have to be fed and the cows also have to be milked,” he said. “Some farms may not have been able to milk their cows since the fire went through their district. “Because tomorrow and Sunday are going to be such problem days for heat, from what I understand today no fodder or services will be allowed in or out of those districts until the worst of the danger has passed.” Max Roberts, the chairman of milk processor Bega, said it had been difficult to collect milk. “If they’re not on fire, we can’t get to them,” he said. “There’ve been a number of farms that haven’t milked for up to 50 hours, 60 hours, and that’s an issue for cow health.” He said the company was working on getting fodder and diesel to farms, while emergency services were helping to get milk tankers out to dairy farms. “It’s highly unusual to get a milk tanker turning up with a police escort but that’s what’s happening.” He was “not sure” how much it was costing Bega to pay for milk it could not collect. “It’d be a bigger cost if the farm went broke,” he said. “You take a longer-term view on these things.” Production at the company’s factory in Bega will grind to a standstill over the weekend. “The factory will close down all but a skeleton operation all through Saturday and Sunday to allow people to stay home and look after themselves,” Roberts said. “There will be milk tanker pickups but again the instruction is that, if it isn’t safe to do it, don’t.” Steve Guthrey, a former dairy farmer who now grows fodder and agists livestock at his property near Bega, said the community was bracing for the weekend. “Pretty much everybody’s just watching and waiting for the moment,” he said. “We know we’ve got a pretty serious day tomorrow. “We’re all on tenterhooks, preparing our houses and farms as best we can.” He said he feared fires to the north-east and north-west could join together. “We haven’t gotten any aircraft down here to help us,” he said. “A lot of the vehicles down here are really limited in what they can do. “We’ve run out of irrigation water now. The dams are virtually empty … We’ve still got a long summer ahead of us now.”"
"
Share this...FacebookTwitter
Comedy clubs aren’t usually thought of as venues for serious debate about controversial topics like climate change.
And yet in a rare debate opportunity, Harvard-Smithsonian Center astrophysicist Dr. Willie Soon took full advantage of the short time he had available to him.  He critiqued “consensus” science, the ocean acidification narrative, the poverty-inducing reliance on wind and solar energies, and climate change alarmism in general.
Dr. Jon Christensen, his opponent, an adjunct assistant professor in the Institute of the Environment and Sustainability, emphasized the “consensus” and the “existential threat” of climate change, extolled the expansion of renewable energy sources like wind and solar in California, and insisted that politicians in the Golden State are focused on not burdening poor people with their “green” policies.
A summary highlighting some of the more interesting exchanges and their corresponding timelines follows.

(1) Dr. Soon: CO2 a benefit, minimal sea level rise awaits
Dr. Christensen: CO2 rise an existential, apocalyptic threat
2:25 Dr. Willie Soon “They try to demonize carbon dioxide as if this is something that’s going to kill everybody.  Which is really not true. …  CO2 has a lot of potential benefit[s].  There are some potential negatives.  If it’s [CO2] going to cause sea levels to rise,  we’re going to have 4 inches or 8 inches or 12 inches…per century.”
3:30 Dr. Jon Christensen “The way I like to think about all this is…sunny with a chance of apocalypse. … (3:59) There is an existential threat out there. (5:40)  Everybody…who is under 40 is going to experience the effects of climate change, global warming, increase in sea level rise, flooding…in their lifetime.”
What the science says…
1. During 1958 to 2014, global sea levels rose at a rate of 1.3 mm per year to 1.5 mm per year, which is a rate of just over 3 inches per century; the Greenland and Antarctica ice sheets have combined to add just 0.59 of an inch of melt water to sea level rise since 1958 (Frederiske et al.,2018).   There has been “a recent lack of any detectable acceleration in the rate of sea level rise” (Parker and Ollier, 2017).  
2. Since the 1980s, coastal land area across the globe has been expanding, meaning that more land are is above sea level today (2015) than in 1985 (Donchyts et al., 2016).
“Coastal areas were also analysed, and to the scientists’ surprise, coastlines had gained more land – 33,700 sq km (13,000 sq miles) – than they had been lost to water (20,100 sq km or 7,800 sq miles). ‘We expected that the coast would start to retreat due to sea level rise, but the most surprising thing is that the coasts are growing all over the world,’ said Dr Baart.  ‘We were able to create more land than sea level rise was taking (press release).'”
3. Hurricane frequencies and intensities have been declining (Truchelut and Staeling, 2018, Zhao et al., 2018, Klotzbach et al., 2018).
4. Extreme weather events (floods, droughts) have decreased in frequency and intensity (or showed no detectable change) (Zhang et al., 2017, McCabe et al., 2017, Cheng et al., 2016, Hodgkiins et al., 2017, McAneney et al., 2017).
5. In recent decades 92% of Canadian polar bear subpopulations have remained stable or increased, leading scientists to conclude that “it seems unlikely that polar bears (as a species) are at risk from anthropogenic global warming” (York et al., 2016).  Local Inuit populations even report that there are “too many polar bears now” (Wong et al., 2017).   There has also been a “marked and steady increase“ in penguin populations between 1982 and 2015 (Che-Castaldo et al. 2017). 

(2) Dr. Soon: Ocean acidification is a myth.
Dr. Christensen: Ocean acidification is science.
11:21 Dr. Willie Soon “Can I say something about ocean acidification?  It’s a myth. … The ocean has something you can measure.  Basically, it’s called ion of the hydrogen.  It’s called [the] pH scale. You have 0 to 14.  Seven is neutral.  Seven to 0 is acidic.  Seven to 14 is called basic.   The ocean is right about 8.03, 8.04 [non-acidic].  But deep inside the ocean, about 2,000 meters down, it’s actually very acidic.  If you wanna talk about ocean acidification – it’s one of the most dangerous myths that there is.  A very radical one.  It’s not sensible.  Who created this myth, actually…?”
12:23 Dr. Jon Christensen “They call it [ocean acidification] science.”
12:25 Dr. Willie Soon “No, it’s not even science, excuse me, because… Do you know what the pH of rainwater is?  It’s 5.5. (Wikihow.com:  “Ordinary rainwater is naturally acidic with a pH between 5.0 and 5.5.”) …  [T]hat means you have to outlaw all the [naturally acidic] rain that’s falling down?  You want to outlaw all the slightly acidic water that is sitting on the bottom of the ocean?”
13:05  Dr. Jon Christensen “No….It’s not that hard to actually read the science.  It can seem a little bit daunting but anybody who can read can work their way through many of these papers and you can see that there’s a wide variety of findings and results and conclusions…  There is in science a fair degree of certainty on a lot of things. …  What we know is that there’s a wide spectrum of results here and we need to look at the data and the whole big picture of the science and not just write it off one way or the other.”
15:08 Dr. Willie Soon “Jon, my whole point is that ocean acidification is an extreme.  It is one of the most extreme things they could come up with because they are not able to find the fingerprint of the carbon dioxide warming of the atmosphere so then they started to come up with this new scheme [ocean acidification].  Next thing…they’re going [to claim] carbon dioxide is killing all of the polar bears.  It’s going to melt all the ice sheets.  It’s completely not even true.”
What the science says…
McElhany, 2017
“Documenting an effect of OA [ocean acidification] involves showing a change in a species (e.g. population abundance or distribution) as a consequence of anthropogenic changes in marine carbonate chemistry. To date, there have been no unambiguous demonstrations of a population level effect of anthropogenic OA [ocean acidification], as that term is defined by the IPCC. … [I]t is important to acknowledge that there are no studies that directly demonstrate modern day effects of OA [ocean acidification] on marine species.”
Duarte et al., 2014
“[T]here have been a few claims for already realized impacts of ocean acidification on calcifiers, such as a decline in the number of oysters on the West Coast of North America (Barton et al. 2012) and in Chesapeake Bay (Waldbusser et  al. 2011). However, the link between these declines and ocean acidification through anthropogenic CO2 is unclear.    Corrosive waters affecting oysters in hatcheries along the Oregon coast were associated with upwelling (Barton et  al. 2012), not anthropogenic CO2. The decline in pH affecting oysters in Chesapeake Bay (Waldbusser et al. 2011) was not attributable to anthropogenic CO2 but was likely attributable to excess respiration associated with eutrophication. Therefore, there is, as yet, no robust evidence for realized severe disruptions of marine socioecological links from ocean acidification to anthropogenic CO2, and there are significant uncertainties regarding the level of pH change that would prompt such impacts.  [D]espite the strong mechanistic or physiological basis for a role of warming in coral bleaching and coral growth, a robust demonstration of a direct causal link between global warming and global coral bleaching over decadal time scales has not yet been produced.”
Wei et al., 2015
“It is worth noting that the errors of these estimates are fairly large with RSD of 65% for that these two time-series do not show significant decreasing trend for pH. Despite of such large errors, estimated from these rates, the seawater pH has decreased by about 0.07–0.08 U over the past 200 years in these regions. … The average calculated seawater pH over the past 159 years was 8.04 [with a] a seawater pH variation range of 7.66–8.40.”


(3) Dr. Soon: Thank God for fossil fuels.
Dr. Christensen: We may fly planes with bio-gas.
8:27 Dr. Willie Soon “You gotta stick to the facts.  Wind and solar – oh boy, so useful.  Every time I look at this sad situation of all these landfalling hurricanes (Irma, Harvey)…the only thing I have to say about that is ‘Thank God for fossil fuels’.  … Fossil fuels offer the most energy density.  There is no viable energy replacement.  Wind and solar could never do anything…”
9:25 Bryan Dey “You’re never gonna get a plane off the ground with wind and solar.”
9:30 Dr. Jon Christensen “You may [get a plane off the ground] with bio-gas, though.”
What the science says…
DeCicco et al., 2016
“Biofuels increase, rather than decrease, heat-trapping carbon dioxide … The researchers conclude that rising biofuel use has been associated with a net increase—rather than a net decrease, as many have claimed—in the carbon dioxide emissions that cause global warming.”

(4) Dr. Christensen: In CA, we believe, we’re
doing something, and we’re helping the poor
17:03 Dr. Jon Christensen “The majority of people in every congressional district in the United States believes that climate change is real, it’s caused by people, it will harm people in the future, and we should do something about it.  […] Great vast majorities of people in California [are believers], where we have decided we’re going to do something about it…we’re on that path which I call the California way or the Paris way where we continue to make commitments, continue to raise our commitments, continue to ratchet down…”
17: 49 Bryan Dey “But all the [green] solutions that come from the Left are really going to be punishing poor people the most…”
17:54  Dr. Jon Christensen “No, they’re not, actually…”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




17: 56 Bryan Dey (adamant) “Yes, they will!  It’s poor people that are going to suffer the most!”
Californians in the audience clap and cheer
18:00 Panelist “We’ve got people [in the audience] who love poor people.”
18:03 Dr. Willie Soon “Oh, poor people are clapping.  Can I say something?”
18:12 Dr. Jon Christensen “Look at the laws in California.  Every single law that is being passed about climate change, cap-and-trade, environmental… has explicit language that is to make those benefits go to poor, disadvantaged communities…”
Californians in the audience shout “No, not true!”
18:30 Bryan Dey “If your electric bill goes up by 20 percent…”
18:34 Dr. Jon Christensen (to audience) “I don’t know who’s saying that [green policies don’t help poor people] but I can show it to you — this is what I do my research on.”
28:20 Question from audience “Do you think it’s appropriate for the government to use force and tax penalties which really affect middle income and lower income people based on climate science that is obviously hotly contested?”
28:50 Dr. Jon Christensen “In California, anyway, … [politicians] make sure that those burdens do not fall on lower income people.”
What the science says…
Environmental Progress (February, 2018)
“The burden of higher cost electricity and benefits of renewable energy subsidies fall unevenly on Californians. Between 2007 and 2014, the highest-income 40 percent of California households received three times more in solar subsidies — valued between $10,000 and $20,000 per household — as the lowest-income 40 percent. California households with over $100,000 in annual income benefited from energy efficiency subsidies at twice the rate of households whose income was under $50,000.”
Poorest households hit hardest by UK climate change levy despite using least energy (March, 2018)
“We found that, in a year, the richest households each consumed on average the same amount of energy that would be produced by 12.7 tonnes of oil, compared to 3.3 tonnes for the poorest households. But the poorest spent a much greater proportion of their income (10%) on energy than the richest (3%). And the energy used for heating and powering their homes – the part that their climate change levy bill is measured on – represented a much greater proportion of their overall energy use.”
“This means that adding the climate change levy to household energy bills hits the poorest households hardest. Energy bills account for a much greater share of their household income and more of their energy use is charged. In fact, the levy only affects a quarter of the total energy consumption of the richest households, compared to 53% for the poorest households. As a result, the richest homes use nearly four times more total energy than the poorest but only pay 1.8 times more towards energy policy costs.”

(5) Dr. Christensen: CA economy is growing
25:55 Dr. Jon Christensen “California’s economy has been growing while emissions have been decreasing.”
What the science says…
Los Angeles Times (January, 2018) 
“Guess which state has the highest poverty rate in the country? Not Mississippi, New Mexico, or West Virginia, but California, where nearly one out of five residents is poor.”

(6) Dr. Soon: Science does not work by consensus
19:13 Dr. Willie Soon “I’m very, very sorry.  Science does not work by consensus.  …  This nonsense about consensus…”
19:50 Dr. Willie Soon “This 97 percent consensus… We have published a peer-reviewed paper (Legates et al., 2013) that shows that it’s only 41 papers out of 12,000.  So it’s only 0.3 percent.”
What the science says…
Legates et al., 2013
“Cook et al. (2013), after a subjective review of only the abstracts of 11,944 papers on climate change which ‘‘matched the topics ‘global climate change’ or ‘global warming’’’ (p. 1), conclude that 97.1 % of those that expressed an opinion endorsed the hypothesis as defined in their introduction (i.e., the standard definition). However, 66.4 % percent of the abstracts had expressed no position. Thus, 32.6 % of the entire sample, or 97.1 % of the 33.6 % who had expressed an opinion, were said to be in agreement with the standard definition. However, inspection of the authors’ own data file showed that they had themselves categorized only 64 abstracts, just 0.5 % of the sample, as endorsing the standard definition [a majority of the warming since 1950 was human-caused]. Inspection shows only 41 of the 64 papers, or 0.3 % of the sample of 11,944 papers, actually endorsed that definition.”

(7) Dr. Soon: CO2 increase is greening the planet
21:20  Dr. Willie Soon “One of the most powerful effects of carbon dioxide is not on temperature because if you talk about greenhouse gases it’s water vapor that’s more important [than] CO2. […]  The only proof we have so far is that it [CO2] is greening the planet.  Twenty to fifty percent of the [Earth’s] vegetated area has been greening, only 4% has been showing a little browning.  That tell[s] you that the overwhelming effect of this [increase in CO2] is fertilization of the atmosphere. […] We’re [currently] in a CO2 starvation state.  Today our air has only 400 parts per million.  If you don’t know what that means, it’s 4 cents for every hundred dollars.”
What the science says…
Zhu et al., 2016
“Global environmental change is rapidly altering the dynamics of terrestrial vegetation, with consequences for the functioning of the Earth system and provision of ecosystem services.  Yet how global vegetation is responding to the changing environment is not well established. Here we use three long-term satellite leaf area index (LAI) records and ten global ecosystem models to investigate four key drivers of LAI trends during 1982–2009. We show a persistent and widespread increase of growing season integrated LAI (greening) over 25% to 50% of the global vegetated area, whereas less than 4% of the globe shows decreasing LAI (browning). Factorial simulations with multiple global ecosystem models suggest that CO2 fertilization effects explain 70% of the observed greening trend, followed by nitrogen deposition (9%), climate change (8%) and land cover change (LCC) (4%). CO2 fertilization effects explain most of the greening trends in the tropics, whereas climate change resulted in greening of the high latitudes and the Tibetan Plateau.”

(8) Dr. Christensen: The goal is to increase the cost of carbon
29:30 Dr. Jon Christensen “A lot of what’s happening is figuring out ways to use the market to increase the cost of carbon…  (Audience: No! No!) …to take into account the cost that we’re paying in health and environmental effects…which are externalities that have not been factored in. … Those revenues [from increasing the cost of carbon] are used to benefit the whole state of California with particular attention to people who are lower income.”
What the science says…
Environmental Progress (February, 2018)
“Between 2011 and 2017, California’s electricity prices rose five times faster than they did nationally. Today, Californians pay 60 percent more, on average, than the rest of the nation, for residential, commercial and industrial electricity.”

“California’s high penetration of intermittent renewables such as solar and wind are likely a key factor in higher prices.”
“Economists agree that “the dominant policy driver in the electricity sector [in California] has unquestionably been a focus on developing renewable sources of electricity generation.”
“High levels of renewable energy penetration make electricity expensive around the world, not just in California. As Germany deployed high levels of renewables over the last 10 years it saw its electricity prices rise 34 percent. Today, German electricity costs twice as much as that in neighboring France.”
“As wind and solar capacity climbs, the returns of usable power diminish because of increasing curtailment during surges that the grid cannot absorb. More and more intermittent capacity has to be pushed onto the grid to get less and less additional renewable electricity. The dynamic of soaring overcapacity and falling prices is the inevitable result of the fundamental inability of intermittent wind and solar generators to efficiently match supply to demand.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe article that follows below is from the UK online Independent here.
Regrettably the editors screwed up and inserted the wrong English text in the video and misidentified the participants as well. The discussion is in fact about CO2 being the sole real driver of global climate. Moreover, the talk round took place in London, and not Egypt.
This is not fake news, but merely a case of human error on the part of the Independent. It happens. 🙂
As a public service, we at NTZ have corrected the article by the Independent (below). Again, pay no attention to the erroneous English text in the video, which is really about a climate skeptic, James Delingpole, at a Talkshow presenting an alternative theory on why the globe is warming a bit.
================================
Corrected version of the Independent article: 
Climate denialist kicked off live Climate TV show for ‘inappropriate’ ideas: ‘Go straight to a psychiatric hospital’
‘We cannot promote such destructive ideas…you set a very bad example for the World’s youth’

A climate skeptic has been kicked off a live TV show taped in London after the host accused him of being ‘confused and unreliable’ and being in need of psychiatric treatment.
James Delingpole was presenting his reasons for being climate science skeptic on Current TV (co-founded by Al Gore) when host George Abd Al-Halim Monbiot told him he was being ‘inappropriate’.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Sheikh of Al Mahmoud Gore, who was also on the programme, agreed, telling him: ‘Look dear James, you need psychiatric treatment. Many young people today suffer from mental illnesses due to material or mental circumstances.’
When Delingpole suggested ‘the sun‘ as an explanation for climate change, George Abd Al-Halim Monbiot exploded and demanded that he ‘stop using difficult words’ and reminded him that he was ‘addressing simple people and to not use big words for no reason’.
George Abd Al-Halim Monbiot then accused James: ‘You deny the existence of CO2 as the climate driver and reject our religion and science.’
Next Mr. Al-Halim Monbiot demanded Mr. Delingpole to leave, saying: ‘We cannot promote such destructive ideas…you set a very bad example for the world’s youth.’
He added: ‘I advise you to leave the studio and go straight to a psychiatric hospital.’
Blasphemy and denialism are illegal in climate science, and prosecution is routinely recommended by NASA GISS, PIK and NOAA if people should insult or defame Climatism and CO2 under proposed climate science RICO laws.
======================================
We at NoTricksZone are glad to have been able to get this cleared up. As you can see, the video now makes perfect sense.
 
Share this...FacebookTwitter "
"An American trophy hunter has kicked off another social media furore after defending a recent giraffe kill in South Africa by claiming they were “very dangerous animals”. In one sense she is right – giraffes are big and strong and you certainly wouldn’t want one kicking you. But attacks on humans are very rare. A more relevant question is whether hunting is a key threat to giraffes.
The International Union for the Conservation of Nature (IUCN) Red List assessment does not list legal hunting as a threatening process at all. However illegal hunting for meat and trophies is listed as threatening as it reduces the effective size of their protected areas and, if allowed to proceed unchecked, can cause the collapse of wildlife populations. Giraffes are popular among bushmeat poachers because of their size, high meat yield and the ease with which they can be hunted. The giraffe is currently listed as “least concern” on the IUCN Red List, but this doesn’t present the full picture. Back in 1999 wildlife expert Rod East estimated there were 140,000 in Africa – today the Giraffe Conservation Foundation estimates there are only 80,000 left. Such a rapid decline suggests they may soon qualify as being vulnerable to extinction. But why does a 40% drop in giraffe numbers not resonate worldwide? After all, everyone knows African elephants are threatened yet there are still 500,000 left in the world. So why is the giraffe being ignored? Normally, it is the uncharismatic species that decline without much public sympathy, but that doesn’t apply here. Giraffes are one of the megastars of the African savannah. Tourists love them. Children who have never been to Africa know what a giraffe looks like. It is the world’s tallest animal despite having the same number of bones in its neck as we do. It is almost comical in appearance with its orange dappled pyjama onesie – although when you feel it, giraffe skin is thick and tough. A drive through a well-managed protected area, such as Kruger National Park in South Africa, gives the impression that both elephants and giraffes are secure. You can sit at a waterhole and watch elephants cavorting in the water while a lone giraffe browses peacefully on the acacias nearby. In Zimbabwe’s Hwange National Park I once saw 32 giraffes without even turning my head. It could be that this familiarity has blinded society to the decline of the species, in addition to a lack of well-publicised trafficking busts that occurs with elephant ivory or rhino horn. But the rapid decline of giraffes isn’t the only story – because in southern Africa, populations are increasing. A major reason for this increase has been the development of wildlife ranches and the reintroduction and protection of giraffes on those lands. There are significant numbers on wildlife ranches in South Africa, Botswana, Zimbabwe, and a recent study estimated that 23,000 giraffes occupy such lands in Namibia. Ironically, many of those ranches only developed because there was potential for deriving income from trophy hunting, including giraffes. Elsewhere, though, other sub-species are faring far worse. The reticulated giraffe from Somalia, Kenya and Ethiopia has been reduced to just 5,000 individuals through illegal poaching and war. The West African giraffe in Niger had only 50 animals in the mid-1990s, but robust environmental protection has resulted in an increase to around 400 today.  The taxonomy of giraffes is currently being studied, and it may be that the dozen or so giraffe sub-species are elevated to distinct species, which would totally reform their conservation status assessments. It seems clear that to protect giraffes, we need to prevent both habitat loss and illegal hunting. These targets can be achieved through adequate management of protected area estates and through the creation of incentives for conservation on lands outside of protected areas. Trophy hunting contributes to both in some countries by generating income from and for wildlife.  The controversy over the killing of Cecil the lion highlights how much is needed to make sure legal hunting industries are adequately managed. However, until an alternative to the income from trophy hunting is found, the answer lies not in banning the practice or on clamping down on trophy imports, but in helping African countries manage the industry better."
"
Share this...FacebookTwitterWhat follows is one example why caution is absolutely essential when dealing with results and findings issued by (activist) government agencies.
Once popular diesel engines now public enemy no. 1
Nowhere in the world have the diesel engines enjoyed so much popularity as in Germany. Diesel engines had long been considered in Germany as being more environmentally friendly then the Otto type engines due to their much higher fuel mileage. Taxes on diesel fuel were and are today much lower.
But Germany has withdrawn its welcome mat for diesel engine. Like CO2, the government and environmental groups recently began waging full-scale war on diesel engines. The official reason for the crack down on diesel is the alleged high levels of dangerous emissions of nitrous oxides, and is what many suspect is mostly part of what is the overall war on the internal combustion engine and thus the effort to get people to switch to “clean” electric cars.
Ministry of Environment’s, media’s absurd claims
To underscore the risks of diesel fumes and to spread fear of diesel engines, Germany’s Ministry of Environment (UBA) recently released “new findings” claiming diesel engines are responsible for 6000 premature deaths every year. Unsurprisingly: the German press and activist groups went bananas uncritically reporting the findings in the most spectacular ways they could imagine.
For example: the Frankfurter Rundschau wrote:
Also diseases such as diabetes mellitus, high blood pressure, stroke and asthma are connected to irritant gas concentration. Eight percent of the diabetes mellitus illnesses in Germany in 2014 can be linked to nitrous oxide in the air outside: ‘That corresponds to some 437,000 cases,‘ said Myriam Tobollik, health researcher at the Ministry of Environment.”
“A political number” that “sounds like science”
Fortunately the hysteria and gross exaggerations did not escape the attention of the German press consumers, who have recently seen the value of their diesel engine vehicles plummet, and the few, still responsible journalists out there. It turns out the UBA report was based on exceptionally terrible science and the claims bordering on the absurd.
For example, Spiegel’s Jan Fleischhauer wrote here:
The made-up dead
Every year 6000 premature deaths from nitrous oxide – that’s how the Environment Ministry panicked the German citizenry. What sounds like science in truth is  a political number from a completely politicized government administration.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In the Spiegel article Fleischhauer asks why aren’t other devices not targets: “A gas cooking stove during reaches peak values of 4000 micrograms per cubic meter. Where’s the campaign against the gas stove?”
It is a fact that many workplaces see routinely far higher nitrous oxide concentrations than what is measured near streets.
Measurement station folly (again), fake crisis
Fleischhauer also reminds readers that the EU directives specify that limit values for exhaust concentrations be measured at a distance of 25 meters from a busy intersection. After having looked through the UBA report, the Spiegel journalist adds:
Now I read the the measurement instruments in Germany are placed directly next to the roadway. I have not verified that. But if it’s true, then it should not be a surprise we find ourselves in a state of a diesel alarm.”
Diesel study “botched”
That the 6000 deaths a year figure was a fraud came to the attention of German mass daily Bild from its own readers. Bild was compelled on March 11 to publish the following headline:

Bild daily headline: “Reader anger over the botched diesel study”
The European Institute for Environment and Climate (EIKE) here commented that the German Environment Ministry “irrevocably ruined the reputation of the 1500-employee large agency behemoth”.
“Politicians lying, playing games”
One Bild reader, Wolfgang Bügener of Oberhausen, wrote: “It is peculiar how our politicians are playing games with and lying to us.”
Another added: “The real scam not only happened in Wolfsburg [VW headquarters] but also at the environmental organizations and Ministries, who throw around false and unproven claims.”
Share this...FacebookTwitter "
nan
"In the mid-20th century pilot whaling still took place in many north Atlantic nations such as the US and Canada. Now, only the Faraoese have a dedicated pilot whale hunt, the grindadráp. Many of us don’t like the idea of this. I am a scientist. I do not profit from the pilot whale hunt nor do I have anything to gain by writing this article. Indeed, I risk retaliation from those that feel what I say departs from the accepted mantra. I study and work with dolphins and whales and for a while I spent more time around dolphins than people. For no logical reason, these animals are special to me, and that they are hunted upsets me. But these are personal opinions which have no place in this debate – a debate that is too easily ruled by emotions. The Faroese catch around 900 pilot whales, actually a type of dolphin, every year. This catch level does not threaten the conservation status of this population estimated to have more than 750,000 whales. Often forgotten or ignored is that an estimated several hundred pilot whales from the same populations are drowned every year in the nets of our fishing fleets. The scale of the Faroese pilot whale hunt is very different to the industrial whaling led by the UK and Norway during the 19th and 20th centuries which, in only 50 to 70 years, over-exploited whales in the Antarctic Ocean and drove them almost to extinction. Nor is it comparable to the commercial pilot whaling in Newfoundland from the 1950s and 1960s which over-exploited the stock. In comparison, the Faroese pilot whale hunt has continued for close to 1,000 years without over-exploitation, with records going back to 1584.  Since pilot whales are top predators in the north Atlantic, they accumulate levels of heavy metals and other pollutants that make their meat hazardous to eat. Yet the hunt is part of the social fabric of the islands, and the meat is eaten nevertheless. The Faroese pilot whale hunt is a dramatic sight. The animals are driven close to the shore in shallow bays and slaughtered with knives and lances. It results in a lot of blood in the water, clearly visible from the shore where many often gather to watch. The need for animals that we eat to be killed quickly and humanely is well understood and agreed. The pilot whale killing method was chosen to ensure that the whales die as quickly as possible, considering all the factors in the hunt.  Killing an animal is not a pleasant business, be it a whale, a deer, or a chicken. However, all welfare issues considered, I do not see how the pilot whale hunt is different from non-stalking hunts for animals on land, many of which take place in countries where opponents to the whale hunt live. Time-to-death is kept as short as possible, even if sometimes it’s longer than we would like. One thing is certain: it’s much shorter than the time it takes a pilot whale to drown in a fishing net that we use to catch our daily fish. The hunt itself is a different story. We have very recently stopped hunting foxes with dogs in the UK on welfare grounds. Driving pilot whales into bays to kill them takes time and is not unlike the process of hunting with dogs, and I think it raises welfare questions that need to be discussed. I personally have difficulties weighing these welfare questions against those raised by the industrial farming which generates most of the meat we consume in anti-whaling nations. Anyone that signs a petition to stop this hunt only to go home and roast a chicken that never saw daylight or moved much when it was reared is a hypocrite. Would it be more ethical of the Faroese to replace the wild-caught meat they have available to them with imported, industrially produced meat? Many of the arguments against the Faroese subsistence whaling should equally apply to the subsistence whaling that goes on in other countries, such as among the Inuit and Eskimo of the US and Canada and the Siberian peoples in Russia. One argument against subsistence hunting is that as the world develops, access to other food sources increases. But alternative food sources are as prevalent in these other countries as they are in the Faroe Islands. Yet the Intuit and Eskimo for example are not subject to the same criticism, and are even lauded for protecting their cultural traditions – are Faroese traditions somehow less worthy of protection? We need an unemotional public debate about all forms of whaling, and a commonly agreed definition of subsistence whaling, dietary or cultural, that is more tightly defined and less open to interpretation. The debate is too driven by emotions, with too many groups that stand to gain while whaling remains a Punch and Judy show. As Gandhi said: “Anger and intolerance are the enemies of correct understanding.” We must never again allow whaling on an industrial scale. But I enjoy my venison and I have no problem with deer hunts. I am one of the millions of hypocrites that eat meat but cannot bear the idea of killing an animal myself. I eat tuna despite its health risks – if I was born in the Faroe Islands, wouldn’t I equally enjoy my pilot whale?"
"We all know about the obvious dangers of DIY and construction work – smashed thumbs, stubbed toes and so on. Even hanging wallpaper results in 1,500 British people going to hospital every year. But the biggest threat might be invisible. Research by my team has revealed that drilling, cutting and sawing releases into the air dangerous levels of ultrafine particles. These tiny specks of dust that are 700 to 70,000 times thinner than human hair are small enough to slip through most masks and could cause serious heart and lung diseases due to prolonged exposure. Our latest study, published in the Journal of Nanoparticle Research indicates peak concentrations during drilling, cutting or sawing could reach as high as 4,000 times as much as the level at the same site when there is no work going on.  We measured the particles released by a variety of different DIY and construction activities – wall chasing (cutting grooves into a wall using an electrical tool, for example to lay electrical cables) released the most particles but, on average, up to 40-times higher concentrations were recorded during refurbishment work compared with local background levels (when no construction work was taking place). These tiny particles are especially dangerous as their large surface area relative to their size increases their potential chemical reactivity and ability to be absorbed into the human body. They can pass deep into the respiratory system, reacting with the lung tissues and potentially entering the blood stream. This isn’t an issue with larger particles (such as regular, visible dust), which cannot pass through cell membranes. We’ve previously calculated traffic-related emissions of these nanoparticles are responsible for around 40,000 deaths per year in Delhi alone, and roughly 300,000 deaths per year in Asian megacities. The problems with traffic emissions are well known – construction-related nanoparticles, less so. Yet it’s an issue that won’t go away. By 2030 the world population will hit 8.3 billion, and all those extra people will need more urban infrastructure – new construction, demolition of old buildings and renovation of existing ones. The DIY market is growing in the UK and is expected to grow even further as existing buildings show their age. At the University of Surrey we’ve looked at a series of health risks associated with this topic, highlighting for instance the high exposure of construction workers to ultrafine particles.  Our latest observations clearly indicate workers on refurbishment sites are even more exposed than those working on the roadside, even given the already high concentrations of ultrafine particles (from vehicle emissions) you’d expect to find beside a road. We need to limit the occupational hazards on refurbishment sites – builders work long hours and end up experiencing more exposure to ultrafine particles than equivalent workers outdoors or in cars. These particles were also found to travel further than their larger counterparts, putting even passers by and the occupants of nearby buildings at risk. Water sprays do a good job of suppressing dust emissions. Respiratory masks are also effective at blocking out coarse (visible) dust – however they weren’t so effective with ultrafine particles because they simply aren’t designed to protect against nano-size dust particles. While renewing rather than replacing is great for sustainability, it is less positive for those working in and around these sites. With the potential to breathe in harmful dust particles including silicon, copper and aluminium, our research shows that we need more regulatory guidelines, not only to protect construction workers, but to protect the general public. In the meantime, construction workers and those undertaking their own building projects, should always err on the side of caution and wear face masks when undertaking activities that could throw out dust. Some of the most dangerous particles are invisible and we shouldn’t underestimate the effect on our health – and on the health of those around us."
"Martin Jacques writes about the “world-transforming” effect of China’s economic growth on Europe and the US (This decade belonged to China. So will the next one, 1 January). Arguably, he’s referring to states and corporations rather than citizens, though individuals and companies are likewise enmeshed in global capitalism. Recently, Arsenal’s distancing from Mesut Özil after he raised awareness of the persecution of Uighurs in Xinjiang, and Tesco’s complicity in alleged forced prison labour, have shown how western corporations have disdained humanitarian basics in favour of international profit – perhaps an indication of what to expect from future power shifts.  However, the “existential crisis” of climate collapse might prompt global bodies to respond to the growing number of world citizens who are demanding entirely new structures. It may be that “we” westerners are less afraid of economic fragmentation and more eager to meet with the best of China’s “rich and intellectually endowed civilisation”, even as we hold the country to account.Libby RuffleWaldringfield, Suffolk • Martin Jacques’s paean to the Chinese ruling class noticeably fails to mention “democracy”, “human rights” and “free trade unions”. Nor does it mention a million Uighurs in internment camps. None of this may matter to Mr Jacques, because he believes the global dominance of China is “ultimately irresistible”.  I am reminded of Orwell’s comment about James Burnham (an intellectual who admired authoritarian regimes): “Power worship blurs political judgment because it leads, almost unavoidably, to the belief that present trends will continue. Whoever is winning at the moment will always seem to be invincible.”Jim DenhamBirmingham • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"If you are very lucky you might have seen an orangutan in the wild. Most people have only seen them on television. In either case the animal was probably deep in some remote forest, as yet untainted by people. This is the image we associate with these critically endangered animals: vulnerable, dependent on pristine habitats, and incapable of coexisting with people. But that view may be wrong. Until recently, our ideas about conservation were constrained by romantic notions of “wild” nature and our limited grasp of just how adaptable and robust nature can be. Yet understanding how prolonged exposure to humans has impacted even well-studied species can help overturn assumptions about them and make conservation more effective. The orangutan is a good example. Orangutans are the largest mammals to primarily live in trees, and they have few predators aside from humans. They generally live at low densities and are unique among apes in being largely solitary. Though orangutan species were once widespread in mainland South-East Asia, the three that remain are restricted to small populations on Sumatra (Pongo abelii and the newly described P. tapanuliensis) and Borneo (Pongo pygmaeus). All orangutans are critically endangered, but it was assumed that significant human impacts mostly took place within the past 60 years, leading to the view of orangutans as “untouched” and lacking the capacity to adapt to humans. But we may have misjudged the orangutan. That’s the conclusion of research we have just published, together with co-authors, in Science Advances. Rather than being an ecologically-fragile ape, there is evidence that orangutans have long been adapting to humans. The modern orangutan is the product of both environmental and human impacts, and where they live and how they act appear to reflect our shared history. We are not implying that orangutans aren’t endangered by current human activities – they are. For example, between 1999 and 2015, Borneo’s orangutan population plummeted by about 50%, a loss of an estimated 100,000 individuals in 16 years. The main factor responsible for this was likely hunting. But if major threats like hunting are controlled – an important “if” – then orangutans may be better able to coexist with people than is widely thought. This opens up opportunities for conservation beyond simply protecting remote forests. People and orangutans have been in contact ever since modern humans made their home in the wet tropics some 70,000 years ago. At that time orangutans were widespread and abundant. Their teeth are relatively common among animal remains found in China, Vietnam, and Thailand suggesting they were easy pickings for prehistoric hunters. Orangutans underwent a precipitous decline around 20,000 years ago, resulting in a restricted distribution and low densities even before mass deforestation over the past century. While the climate likely had some effect, evidence from fossils, archaeology and genetics strongly suggests a human role. Specifically, we found that the arrival of humans – and especially advances in their hunting technologies, such as projectile weapons and, later, blowguns and guns – match up with orangutan declines.  Indeed, it appears that ancient humans nearly wiped out the orangutan, as they did the woolly rhino, giant ground sloths, and other Pleistocene megafauna. Surviving orangutans probably modified their behaviour to counter this threat, perhaps retreating further into the thickest forests to avoid human hunters. That ability to adapt is still present in orangutans, and is also why they are still around today. Recent studies have found they can get by reasonably well in logged forests, and they even inhabit fragmented forest landscapes dominated by oil palm and other crops, although they still need access to natural forest. When their preferred foods (ripe fruit) are not available, orangutans are even able to eat a wide variety of “fallback foods” like bark.  The realisation that orangutans have already adapted to a world dominated by humans has implications for conservation. The fact that these animals can survive relatively well in plantations and farmland outside pristine forests – as long as they are not being hunted – means that these areas should be integrated into conservation strategies. This is especially important given that most orangutans today do not live in protected forests, but in areas open to human use. The line between nature and human-dominated world is increasingly blurred. Most species have adapted to human activities in some manner. This isn’t always a good thing, but with the orangutan it allows us to see conservation opportunities that were previously invisible."
"Passenger cars are still the most popular transportation mode. In 2014 nearly 68m were produced globally. They’re not only a vital part of our economy and our personal lives but also an important social and cultural tool, used to present a certain image and status – real or imagined.  Our entrenched reliance on – and attachment to – this method of travel means that, even if we shift away from such widespread car ownership, we need to change our perception of what cars are if we want to mitigate their high environmental costs. This doesn’t just mean moving to electric vehicles. Just at the resource extraction level, roughly five tons of materials are needed to produce a 1.2 ton car, creating ten tons of effluents and 2.5 tons of emissions. Processing these materials into components, assembling and distributing the cars around the world – and then using, servicing and disposing of them generates even more emissions. In total, a typical mid-size car is responsible for around 17 tons of CO₂. The total embodied emissions for alternatively fuelled vehicles such as hybrids, electric and fuel-cell vehicles may even be higher than normal internal combustion engines – even when they produce no tail-pipe emissions (based on the as-yet unpublished Greet2 study). This is perhaps because such technologies are more energy intensive to produce due to the materials that compose them. So what is the alternative to the current system? If car travel is going to remain common, perhaps we need to be smarter about how we build and use them. Our cars currently spend 92% of their time parked – and, when driving, most of their weight is used only to carry one person most of the time. Cars could be produced in fewer numbers, to be smaller, longer-lasting and shared by more people. And instead of focusing on turning out as many new cars with relatively short lifespans as possible, manufacturers could provide more services to keep vehicles on the road for longer and deal with their disposal. The role of car designers could also change. First by designing simpler basic cars, without “gimmicks” such as mood lights or massaging seats. Timeless lines rather than subject to the fads of the day. Instead of working on one project after another, the designer could be involved in an upgrading process that would see each model evolve through re-manufacturing in a more direct interaction with consumers. Other changes in the features of the cars themselves could also produce more sustainable models. For example, safety standards today are driven by electronic systems such as collision-avoidance and pedestrian-detection systems. These could be upgraded during service life more easily than physical features. Based on my own (as yet unpublished) research, I believe that if these systems prove to be highly reliable, there will be no need for low-speed impact structures, reducing the use of materials. This model might be easier to move to than it first sounds. So-called millennials are less interested in cars than previous generations, applying for driver’s licences later in life and more likely to live in highly congested cities where access to public transport is easier. They are also used to sharing or renting services, for example with taxi-hailing or liftsharing apps such as Uber. Owning a car, on the other hand, is seen as an expensive liability. The car manufacturing industry is also at a cross-roads. Powertrain options are multiplying, driverless technology is poised to make big changes and non-automotive companies including Google want a share of the market. As materials become more expensive, relying on cars with relatively shorter lifespans to flood the market is not in anyone’s interest. Not even the car makers, who at best can only make 5% annual profit. The current business model may not survive in the longer term. It may naturally make more sense for manufacturers to build and service cars as long-lasting rental products. Some electric vehicle manufacturers have already introduced rental schemes for their batteries, which are likely to need replacing far quicker than the rest of the car. Extending the lifespan and the product life cycle will impact on production. Fewer cars means that the return on investment may take longer. But it could also mean less need to update costly manufacturing tools – and factories could be made more modular and flexible to produce different types of cars in one assembly line. Plants could be more localised to meet the different needs of the different megacities of the future. And redundant assembly workers could be retrained into servicing and maintenance or other car-related services. This model would require us to think differently about cars, redefining terms such as “old” and “used” and educating consumers, especially those from older generations who are unfamiliar with sharing systems. Not all cars will survive into the future, but if we are better stewards of what we have now and learn to cherish products in a more subjective way than the market does, cars can definitely last for longer."
"The Guardian has always been a purpose-led organisation, and this year we committed to focusing on that even more. B Corporations are companies that value purpose as much as profit, so it felt like a natural fit with our own values. Being a B Corp means a few different things: it’s a way of having a rigorous, objective view of where we are doing well and where we need to work harder when it comes to our environmental and social impact. It’s a way of demonstrating to our readers what type of business we are and it’s also a community of like-minded businesses that want to share ideas and encourage each other.  A lot of companies are talking about the idea of “purpose” at the moment so it’s important to us that we can demonstrate to our readers that we are doing more than just talking – we are actually acting on things like our working practices, how we recruit, our environmental performance and how we support local communities. We believe we are the first major media organisation to become a B Corp anywhere in the world so we are proud to have taken this step. There are currently about 3,000 certified companies globally. The certification started in the US and around half of all certified companies are based there, but it is growing quickly in Europe and beyond. The outdoor clothing brand Patagonia is one of the best known B Corps, the Body Shop recently certified and food company Danone is in the process of certifying all of its subsidiaries. There are also lots of smaller companies doing everything from law to teabags to wetsuits! It feels like consumer and business attitudes are changing really quickly and people increasingly want to know that companies are behaving in an ethical way. We have committed to being carbon neutral by 2030 and we already have a target of eliminating the gender pay gap in the top half of our organisation by 2022. We’re already doing a lot of work to be a more diverse and representative employer, which will continue to be a priority. We’re currently working on a plan for what other specific improvements we want to achieve by the time we get reassessed in three years. The B Corp assessment measures our performance across five areas - governance, workers, community, environment and customers. We have to recertify every three years so we will be able to track our progress. Our climate pledge was really driven by our reporting on the severity of the climate crisis, and the strength of feeling among our readers and our staff. We believe that the world is in the grip of an environmental emergency but too many governments and businesses are not taking meaningful action to address it. The biggest way that we can play a role is through our reporting, highlighting the impact of the climate crisis on communities around the world and helping our readers to understand the issue. But it was also important to us that we held ourselves to account and made a commitment to improve our own performance. The more companies that commit to net zero, the more momentum there will be to develop solutions, and hopefully the more pressure it will put on governments to take meaningful action. We are currently in the process of doing a full audit of our carbon emissions, both within our own operations but also across our supply chain. We hope to complete that soon and then identify where we can make the biggest reductions in our footprint. One of the things we will be looking at is how we reduce the amount of air travel. We’ll also be looking at things like where all our energy supplies come from and how we could reduce emissions associated with our printing operations. For example, we previously switched the packaging for some of our weekend papers from plastic to compostable materials, but we are now looking at other alternatives that are easier to recycle. Our priority is to reduce the emissions that we cause. We will also look at ways that we can offset the emissions that we can’t remove. We want to approach that in a really thoughtful way as there are a lot of conflicting views about the merits of different offsetting options, and growing cynicism about the ways some companies are using it as a way of appearing green instead of making meaningful change to the way they operate. That doesn’t mean that we shouldn’t do it, but we want to make sure that we support schemes that are verifiable and have a real benefit. You can encourage the companies you buy from to become B Corps – it’s a rigorous certification and if all major companies did it then everything from labour standards to environmental performance would be a lot better! You can advocate for the government to implement stronger corporate standards so that companies are obliged to consider the long-term impact of their actions on employees, the environment and society alongside the impact on shareholders. And we hope that our climate pledge will inspire readers to take action in their own lives, whether it’s taking fewer flights, shopping more locally or reducing the amount of plastic in your life. Julie Richards is the delivery portfolio director at Guardian News & Media Support Guardian journalism today, by making a single or recurring contribution, or subscribing "
"The discovery of 26 bodies with lethal injuries in a 7,000 year old mass grave in Germany provides more evidence of organised large-scale violence in Neolithic Europe. The findings, reported in the journal PNAS, also help us understand the sudden and perhaps brutal ending of central Europe’s first farming culture. The Linear Pottery (Linienbandkeramik, or LBK) culture which dominated central Europe between 5600 and 4900 BC was once depicted as peaceful and pioneering – farmers who cleared land and carved new communities out of the heavily-forested “wilderness”. This view began to crumble with the discovery in the late 1980s of a mass grave at Talheim in southern Germany, containing the remains of 34 men, women and children, many of whom showed evidence of lethal injuries caused by stone axes.  This was followed not long after by the findings from an enclosure (a precursor to fortified Roman army camps) at Asparn/Schletz in Austria. Here, the remains of 67 people were found lying in haphazard positions in the bottom of just one section of the enclosure ditch, the implication being that many more individuals are represented across the site as a whole. It is clear that they too died violently, with many skulls showing signs of multiple blows.  That fact both of these massacres – no other word can be applied – fell near the end of the Linear Pottery culture, around 5000 BC, raised the possibility that things ended less than peacefully. In the latest paper, a German team led by Christian Meyer present the recently discovered third instalment in this story. A long trench at the site of Schöneck-Kilianstädten, central Germany, held the remains of at least 26 individuals, found commingled in a mass grave, again with evidence of multiple injuries showing no signs of healing. Most were caused by stone axes, but there were also arrowhead wounds. This was almost certainly a single event, again dating to around 5000 BC.  Intriguingly, as at Asparn/Schletz, the graves contained no children aged 9-16 or young women. This suggests the capture of children and young women may have been one of the motivations for conflict, as it has been in more recently recorded societies around the world. These events were devastating not only to those involved, but to the entire society. While we have only the vaguest idea of the total population of Neolithic Europe at any particular point, we do have some sense of the size of local villages – usually around 50 to 100 inhabitants. Thus, the deaths of even 26 or 34 people represents an event that, scaled up for an appropriate comparison with modern population levels, would entail killing on a scale seen today only in the most war-torn countries. Archaeology deals with fragments of the past, and there is always the possibility of bias in what survives and what does not, as well as in what is found and what remains hidden. Add to this the fact that radio-carbon estimates provide a date range rather than a specific year and the discovery of one massacre falling at approximately the same time as the disappearance of Linear Pottery may be no more than a coincidence.  The finding of a second example begins to suggest a pattern, however tentatively. The discovery of a third case looks very suspicious indeed. The question that naturally arises is why this particular point in time should see such a widespread outbreak of conflict, involving the killing of what could easily be the entire populations of small hamlets. While there is certainly evidence of conflict both before (including among the hunter-gatherers that preceded the Neolithic) and after 5000 BC, this usually takes the form of isolated incidents involving relatively few individuals. These mass graves were the result of something larger and more organised. One theory blames the environment. A period of climatic instability led to increased competition for resources and eventually to conflict – including the extermination of some entire communities. This interpretation very much divides the room. Many researchers take exception to what they see as an overly simplistic, environmentally deterministic explanation, and favour internal causes for conflict. Other strategies could have been employed to cope with shortages, emphasising greater cooperation rather than competition.  There is also the problem of precisely correlating climatic records and archaeological events. While there is some evidence of a climatic downturn at the end of the 6th millennium BC, there is still considerable leeway in the dating of both this downturn, and in the massacres discussed here, making it very difficult to link them in a causal way. The findings at Schöneck-Kilianstädten will no doubt fuel this debate, and rightly so, since it is an important one that is not without implications for our own future. Some studies have suggested that global warming is likely to lead to a massive increase in levels of conflict worldwide. If such a link does turn out to have been the case in Neolithic Europe, it would be depressing if we have not learned anything in the intervening millennia that would enable us to avoid a similar fate."
nan
"
Share this...FacebookTwitterCO2 Climate Sensitivity So Low It’s ‘Impossible 
To Detect Or Measure In The Real Atmosphere’

“In particular, formula 5 (and 6) as presented here, totally rules out
any possibility that a 33°C greenhouse effect of the type proposed
by the IPCC in their reports can exist in the real atmosphere.”
– Holmes, 2017

In a new peer-reviewed scientific paper published in the journal Earth Sciences last December (2017), a Federation University (Australia) Science and Engineering student named Robert Holmes contends he may have found the key to unlocking our understanding of how planets with thick atmospheres (like Earth) remain “fixed” at 288 Kelvin (K), 740 K (Venus), 165 K (Jupiter)…without considering the need for a planetary greenhouse effect or changes in atmospheric CO2 concentrations.
The Greenhouse Effect ‘Thought Experiment’ 
Perhaps the most fundamental conceptualization in climate science is the “thought experiment” that envisions what the temperature of the Earth might possibly be if there was no greenhouse effect, greenhouse gases, or atmosphere.
Dr. Gavin Schmidt, NASA  
“The size of the greenhouse effect is often estimated as being the difference between the actual global surface temperature and the temperature the planet would be without any atmospheric absorption, but with exactly the same planetary albedo, around 33°C. This is more of a ‘thought experiment’ than an observable state, but it is a useful baseline.”
Simplistically, the globally averaged surface temperature clocks in at 288 K.   In the “thought experiment”, an imaginary Earth that has no atmosphere (and thus no greenhouse gases to absorb and re-emit the surface heat) would have a temperature of only 255 K.  The difference between the real and imagined Earth with no atmosphere is 33 K, meaning that the Earth would be much colder (and uninhabitable) without the presence of greenhouse gases bridging the hypothetical “heat gap”.
Of that 33 K greenhouse effect, 20.6 K is imagined to derive from water vapor droplets in the atmosphere (1,000 to 40,000 parts per million [ppm] by volume), whereas 7.2 K is thought to stem from the “natural” (or pre-industrial) 200-280 ppm atmospheric CO2 concentration (Kramm et al., 2017).
As a “thought experiment”, the critical heating role for water vapor droplets and CO2 concentrations lacks real-world validation.  For example, the Earth’s oceans account for 93% of the planet’s heat energy (Levitus et al., 2012), and yet no real-world physical measurements exist that demonstrate how much heating or cooling is derived from varying CO2 concentrations up or down over a body of water in volume increments of parts per million (0.000001).  Consequently, the CO2 greenhouse effect is a hypothetical, model-based conceptualization.
And in recent years, many scientific papers have been published that question the fundamentals of not only the Earth’s hypothetical greenhouse effect, but the role of greenhouse gases for other planets with thick atmospheres (like Venus) as well Hertzberg et al., 2017, Kramm et al., 2017, Nikolov and Zeller, 2017 , Allmendinger, 2017, Lightfoot and Mamer, 2017, Blaauw, 2017, Davis et al., 2018).   The Holmes paper highlighted here may just be among the most recent.
‘Extremely Accurate’ Planetary Temperature Calculations With Pressure/Density/Mass Formula
Holmes has argued that the average temperature for 8 planetary bodies with thick (0.1 bar or more) atmospheres can be precisely measured with “extreme” accuracy — an error range of just 1.2% — by using a formula predicated on the knowledge of 3 parameters: “[1] the average near-surface atmospheric pressure, [2] the average near surface atmospheric density and [3] the average mean molar mass of the near-surface atmosphere.”
Holmes used the derived pressure/density/mass numbers for each planetary body.   He then calculated the planets’ temperatures with these figures.
Venus’ temperature was calculated to be 739.7 K with the formula.  Its measured temperature is 740 K.  This indicates that the formula’s accuracy is within an error range of just 0.04% for Venus.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Given Earth’s pressure/density/mass, its calculated temperature is 288.14 K using Holmes’ formula.  Earth’s measured temperature is 288 K, an exact fit.
Saturn’s calculated temperature is 132.8 K.  Its measured temperature is 134 K — an error range of only 0.89%.
The impressive accuracy of the formula is illustrated below in Table 1. and Figure 2.

Atmospheric Pressure/Density And Surface Temperature
In large part, the density of a planet’s atmosphere is a primary determinant of its temperature.   Planets with thick atmospheres are hotter.  Planets with thin atmospheres are cooler.  The further away from the surface, the less gravity/pressure there is and the cooler it gets.  And vice versa.
Sciencing.com
“In general, the weaker the gravitational pull of a planet, the thinner the atmosphere will be. A planet with weak gravity will tend to have less mass and allow more atmosphere to escape into space. Thus the thickness or thinness of the atmosphere depends upon the strength or weakness of gravity. For example, the gravity on Jupiter is 318 times greater than Earth, and thus Jupiter’s atmosphere is much thicker than Earth’s. Gravity gets weaker the further away it is from a planet, so the atmosphere will be thicker near the surface.”
A facile illustration of the effects of atmospheric pressure on the surface temperatures of a planet like Earth can be found in the Grand Canyon, Southwestern U.S.  There, the North Rim is about 1,000 feet (305 meters) higher in elevation than the South Rim.  Interestingly, the North Rim is also about 9 degrees Fahrenheit colder than the South Rim due to the influence of atmospheric pressure/gravity.   The bottom of the canyon reaches temperatures 20-25 degrees warmer than the top.  The stark temperature difference is unrelated to the greenhouse gas concentrations for the two locations, nor is it connected to sunlight.   It’s the gravitational pressure that creates the heat divergence.
Subia, 2014
“Elevation and season of the year determine average temperatures at the the Grand Canyon. Elevations at top of the South Rim average around 7,000 feet. The North Rim averages about 8,000 feet. The higher the elevation, the cooler the temperature. At any given time, the North Rim will average 8-10 degrees Fahrenheit cooler versus the South Rim. … [T]he very bottom of the canyon can increase 20 to 25 degrees warmer than the top of the respective rims.”
Sensitivity To CO2 Concentration Changes ‘Extremely Low’
Holmes points out that the implications of his precise calculations for planetary temperatures necessarily lead to the conclusion that there is no need to have a greenhouse effect or greenhouse gases to bridge a hypothetical “heat gap.”  Instead, he writes that “planetary bodies with thick atmospheres cannot be mainly determined by the ‘greenhouse effect’, but instead most likely by an effect from fluid dynamics, namely, adiabatic autocompression.”
This effectively rules out the possibility that CO2 is a predominant climate driver.
In fact, Holmes’ calculation for CO2 climate sensitivity (doubling the atmospheric CO2 concentration from 0.03% to 0.06%) is -0.03°C.
As he ostensibly understates in his conclusion, “This climate sensitivity is already so low that it would be impossible to detect or measure in the real atmosphere.”

Holmes, 2017
Molar Mass Version of the Ideal Gas Law 
Points to a Very Low Climate Sensitivity
Introduction
Presented here is a simple and reliable method of accurately calculating the average near surface atmospheric temperature on planetary bodies which possess a surface atmospheric pressure of over 10kPa [a thick atmosphere, 0.1 bar or more]. This method requires a gas constant and the knowledge of only three gas parameters: [1] the average near-surface atmospheric pressure, [2] the average near surface atmospheric density and [3] the average mean molar mass of the near-surface atmosphere. The formula used is the molar version of the ideal gas law.
It is here demonstrated that the information contained in just these three gas parameters alone is an extremely accurate predictor of atmospheric temperatures on planets with atmospheres >10kPa. This indicates that all information on the effective plus the residual near-surface atmospheric temperature on planetary bodies with thick atmospheres, is automatically ‘baked-in’ to the three mentioned gas parameters.
This formula proves itself here to be not only more accurate than any other method heretofore used, but is far simpler to calculate.  It requires no input from parameters previously thought to be essential; solar insolation, albedo, greenhouse gas content, ocean circulation and cloud cover among many others.
Given this, it is shown that no one gas has an anomalous effect on atmospheric temperatures that is significantly more than any other gas.
In short, there can be no 33°C ‘greenhouse effect’ on Earth, or any significant ‘greenhouse effect’ on any other planetary body with an atmosphere of >10kPa.
The Formula: An ‘Extremely Accurate Predictor’ Of Planetary Temperatures

[T]he hypothesis being put forward here is that in the case of Earth, solar insolation provides the ‘first’ 255 Kelvin – in accordance with the black body law [11]. Then adiabatic auto-compression provides the ‘other’ 33 Kelvin, to arrive at the known and measured average global temperature of 288 Kelvin. The ‘other’ 33 Kelvin cannot be provided by the greenhouse effect, because if it was, the molar mass version of the ideal gas law could not then work to accurately calculate planetary temperatures, as it clearly does here.
It is apparent that this simple formula calculates the ‘surface’ temperatures of many planetary bodies in our Solar System accurately (Figure 2).
Specifically, those which have atmospheres thick enough to form a troposphere (i.e. possessing an atmospheric pressure of over 10kPa or 0.1bar). These are: Venus, Earth, Jupiter, Saturn, Titan, Uranus and Neptune. All calculated temperatures are within 1.2% of the NASA reported ‘surface’ temperature (except for Mars, which is excluded because it has a much lower atmospheric pressure than 10kPa).
This accuracy is achieved without using the S-B black body law, or the need to include terms for such parameters as TSI levels, albedo, clouds, greenhouse effect or, for that matter, adiabatic auto-compression. All that is required to be able to accurately calculate the average near-surface atmospheric temperature, is the relevant gas constant and the knowledge of three variable gas parameters.
The Implications: CO2 Climate Sensitivity (-0.03°C) ‘Extremely Low’
Some reflection upon the simplicity and accuracy of these results will bring an unbiased person to the obvious implications of this work. These are that the residual (residual being the difference between S-B law results and actual) near-surface atmospheric temperatures on planetary bodies with thick atmospheres cannot be mainly determined by the ‘greenhouse effect’, but instead most likely by an effect from fluid dynamics, namely, adiabatic autocompression.
Another implication leads directly to the conclusion that the climate sensitivity to, for example, a doubling of the atmospheric carbon dioxide concentration has to be operating instantaneously, and also must be extremely low. Under this scenario, the climate sensitivity to CO2 cannot be very different to the addition of a similar quantity of any other gas.
In particular, formula 5 (and 6) as presented here, totally rules out any possibility that a 33°C greenhouse effect of the type proposed by the IPCC in their reports [23] can exist in the real atmosphere. The reason is that the IPCC state in their reports that a 0.03% [300 ppm] increase in atmospheric CO2 (i.e. a doubling from pre-industrial levels) must result in a global temperature rise of ~3°C; (a range of 1.5°C to 4.5°C, which has hardly changed since 1990) [24]. This is the so-called ‘climate sensitivity’. Anything like this magnitude of warming caused by such a small change in gas levels is completely ruled out by the molar mass version of the ideal gas law.
Calculate for a doubling of CO2 from the pre-industrial level of 0.03% [300 ppm]:
Calculated temperature after doubling of CO2 to 0.06% ≈ 288.11K. Climate sensitivity to CO2 is ≈ 288.14 – 288.11 ≈ – 0.03K.
The change would in fact be extremely small and difficult to estimate exactly, but would be of the order -0.03°C. That is, a hundred times smaller than the ‘likely’ climate sensitivity of 3°C cited in the IPCC’s reports, and also probably of the opposite sign [cooling]. Even that small number would likely be a maximum change, since if fossil fuels are burned to create the emitted CO2, then atmospheric O2 will also be consumed, reducing that gas in the atmosphere – and offsetting any temperature change generated by the extra CO2. This climate sensitivity is already so low that it would be impossible to detect or measure in the real atmosphere, even before any allowance is made for the consumption of atmospheric O2.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter…EU enacts law to regulate the color of potato and grain-based foods with the aim of protecting public from high cooking temperatures

Too dark! EU now regulating bread color from baking at too high temperatures. Photo credit: Fritzs, Creative Commons Attribution-Share Alike 3.0 Unported.
The following should be a viewed as a shot across the bow concerning the extent and zeal to which the EU is capable of when it comes to regulation. Just imagine if they were given a free hand to regulate all things related to CO2 and climate change. It’s getting frightening.
I’ve gotten used to the high levels of regulation here in Europe, and it’s gotten tough to surprise me. Yet, EU bureaucrats never fail at finding new ways to do so.
Nanny state
The latest pertains to the color of bread. The most recent news on EU regulation is reported for example by the Austrian online Wochenblick here, which writes: “EU regulation: Effective immediately our bread is not allowed to be too dark”!
The risk, according to the EU, is acrylamide, a carcinogenic compound that can form on starchy food if the cooking temperature is too high (some studies suggest).
European nannies are afraid some people could get sick from eating overly dark bread.
Meanwhile, it’s business-as-usual for the obviously dangerous product sugar, whose consumption in Europe has reached dangerous levels with diabetes becoming an epidemic. But the days of unregulated sugar use may also be coming to an end. Regulating sugar would make sense.
Aim is to curb acrylamide from high temperature cooking


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The dark-bread regulation went into effect last Wednesday, and appears to be a part of the regulation package to ban golden, crispy french fries as well.
Wochenblick reports that the regulation are for all products based on potatoes, grains, and also coffee. The EU intends to conduct food inspections in the future.
Regulating living down to the detail
The new highly intrusive regulations are the latest rules aimed at limiting coffee machines, restricting wood-burning stoves, vacuum cleaner power ratings, and lawn mower emissions, to name a few.
A Google search already shows that EU regulations for outdoor barbecues are likely in the works. Readers can look into that themselves to determine if that’s the case or not. Just imagine what that would look like.

The EU is only just getting started with all the regulation-mania.
More background here.
 
Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitterPublic opinion of wind energy in Germany, once unanimously high, has eroded considerably over the past years as more people begin to realize that the country’s once idyllic countryside is turning into a blighted industrial landscape.
The earlier visions of environmental purity are instead turning out to be illusions by con-artists. The reality is an environmental hell.
In an opinion piece at German flagship daily Die Welt, Wolfgang Büscher wrote:
Wind energy is destroying the country more than any other industry.” 
Blighted landscape…everything “blinking and rotating”
And the irony could not be more glaring. German environmentalists used to be devoted to all things that protected forests and rural countryside against the ravages of industrialization. But now, Büscher writes, “It’s the same activists who are blandishing the blighting of the landscape.”
Büscher describes the views of wind parks in Bavaria as “massively appalling”. While German industry once only ruined local areas of the country, such as the Ruhr industrial region, Büscher adds:
The wind industry is not satisfied with that. It wishes to subject the entire country to its moral galvanized industry. Whether it’s Magdeburg or Warburg Saxony Anhalt regions, whether it’s Holstein or the lower Harz region – everything is rotating and blinking, the further north you go, the worse it is.”
Büscher forgot to mention “whooshing” and “shredding”.
Germany’s march into environmental insanity
Yet, in the eyes of the wind industry, Büscher laments, “The wind industrialization of Germany is not only without alternative, it is an aesthetic benefit. The industry truly believes the entire country needs to by planted with turbines from border to border.”
As incredible as it may be that a country managed to get its citizens to march into the murderous folly of Nazism some 85 years ago, a similar phenomenon is happening today on the environmental front: there’s now the mad march into environmental murder. The collective German conscience still truly believes it’s all going to rescue the planet from a climate calamity which a group of (false) prophets foresee arriving in the year 2100. Environmental purity awaits!
Back on the eerie path of self-destruction


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Of course wind industrialization cannot be compared to Nazism on the scales of murder and destruction, but the path and development stages of the two insanities are the eerily similar. Both proceeded as follows: 1) visions and promises of purification, 2) the mad, blind rush into the project 3) critics silenced, 4) signs of mounting failure ignored, 5) denial, retreat to the bunkers and 6) in evitable self-destruction. In both cases it’s all brought on by intoxicated leaders, one-sided media apparatus, crony industries, dogmatist institutions and unscrupulous banks.
Once madness goes collective, it becomes very difficult to stop.
When Germany gets an obsession in its head, the only thing that is left to stop it is the act of letting it play out and until it destroys itself. We may soon be witnessing the Rise and Fall of The Environmental Reich. Currently we find ourselves somewhere between phases 4 and 5.
Fortunately there are shimmers of hope that leading politicians are beginning to understand, as the newly formed Merkel-led government seems to be in no hurry to keep promoting big wind at any cost.
Former federal minister: “high price to pay”
Not only is the environmental price mentioned by Büscher excruciatingly high, but so is the financial price of the Energiewende, this according to former German Transportation Minister, Peter Ramsauer, now Chairman of the Committee for Economic Cooperation and Development.
In a recent interview with the Passauer Neuen Presse (PNP), Ramsauer slammed Germany’s rapid march into the Energiewende, telling the Bavarian online daily: “We have a high price to pay for the Energiewende.”
“Object lesson to other countries”
Ramsauer warned against the hasty shutdown of half of the country’s nuclear power plants in the wake of the Fukushima disaster back in 2011, “but no one wanted to listen”.
The PNP writes that it was “a fundamental mistake to believe that it would be possible to adequately replace the nuclear power”. Ramsauer told the PNP:
Germany is paying a high price for it and offers an object lesson to other countries.”
The PNP summarizes: “There’s no going back. The deadline for shutting down the remaining nuclear reactors is 2022. Ramsauer says that Germany will have to get used to high electricity prices and dependency on Russian gas. The folly will then be complete.”
Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitterHere’s something you don’t witness very often…German national public radio telling listeners that natural factors are behind observed changes in something related to climate.
I can’t tell you how many times I’ve heard the German media claim storms are linked to our disdainful energy gluttony. So it comes as quite a shock when you hear something about climate that doesn’t conform to Potsdam Institute dogmatism.
At their Die kalte Sonne site here, Dr. Sebastian Lüning and Prof. Fritz Vahrenholt bring up an example of how German DLF national radio. I’ve translated the German text:
=====================================
Hurricanes are developing more quickly today than 30 years ago due to the Atlantic ocean cycle
A team of researchers at the US Department of Energy and the Pacific Northwest National Laboratory recently made an exciting discovery: Apparently hurricanes are developing more quickly today than they did 30 years ago. Earlier it took longer, but now maximum strength is reached sooner.
The scientists have found the culprit – drum roll – no, it’s not the wanton activity of mankind, rather it’s the Atlantic AMO ocean cycle, which fluctuates with a period of 60 years. During the course of the AMO cycle, hurricanes change accordingly.
Here’s the press release from May 9, 2018:

Powerful hurricanes strengthen faster now than 30 years ago
The storms intensify more rapidly today due largely to a natural climate phenomenon
Hurricanes that intensify rapidly — a characteristic of almost all powerful hurricanes — do so more strongly and quickly now than they did 30 years ago, according to a study published recently in Geophysical Research Letters, a journal of the American Geophysical Union. While many factors are at play, the chief driver is a natural phenomenon that affects the temperature of the waters in the Atlantic where hurricanes are powering up, according to scientists at the U.S. Department of Energy’s Pacific Northwest National Laboratory and the National Oceanic and Atmospheric Administration. They found that a climate cycle known as the Atlantic Multidecadal Oscillation or AMO is central to the increasing intensification of hurricanes, broadly affecting conditions like sea temperature that are known to influence hurricanes.
Stronger hurricanes in a day’s time
Last year’s lineup of powerful storms — Harvey, Irma, Jose and Maria — spurred the scientists to take a close look at the rapid intensification process. This occurs when the maximum wind speed in a hurricane goes up by at least 25 knots (28.8 miles per hour) within a 24-hour period. It’s a rite of passage for nearly all major hurricanes, including the big four of 2017. The team, comprised of Karthik Balaguru and Ruby Leung of PNNL and Greg Foltz of NOAA, analyzed 30 years’ worth of satellite hurricane data encompassing 1986 through 2015. Information came from NOAA’s National Hurricane Center and the U.S. Navy’s Joint Typhoon Warning Center. Consistent with other studies, the scientists did not find that rapid intensification is happening more often nowadays.
But the scientists also looked closely at just how much the storms are strengthening. They found a sizeable jump in the strength of fast-growing storms — the storms are getting more powerful more quickly within a 24-hour period than they were 30 years ago. The team found that the average boost in wind speed during a 24-hour intensification event is about 13 mph more than it was 30 years ago — on average about 3.8 knots (4.3 mph) for each of the three decades studied. Several factors play a role when a hurricane gains more power rapidly, including the temperature of the surface of the ocean, humidity, characteristics of the clouds, the heat content in the ocean, and the direction of the wind at the surface compared to miles above. Among the biggest factors affecting the increase in magnitude in the last 30 years, according to the team’s analysis:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




–The amount of heat available in the uppermost layer of the ocean, known as the ocean heat content. The warmer the upper ocean, the more powerful a hurricane can become.
–Wind shear: The less the vertical wind shear — the difference in the direction and force of the winds at the surface compared to several miles into the air — the more powerful the hurricane can become.The influence of the Atlantic Multidecadal Oscillation
The team found that the biggest factor explaining the increasingly rapid intensification is the AMO. The result comes in part from analyses using 16 separate climate models to isolate the impact from global warming. “This was a surprise, that the AMO seems to be a bigger influence in rapid intensification than other factors, including overall warming,” said Balaguru, the first author of the paper.
The AMO governs how the temperature of the waters in the North Atlantic cycles between warmer and cooler, with each period typically lasting a decade or more. The cycling occurs for reasons scientists don’t completely understand, but it has broad effects on the environment. For example, it plays a big part in determining the heat content of the oceans, an important factor powering hurricanes. The AMO has generally been “positive” — causing warmer waters — since the late 1990s.
Balaguru noted that while rapid intensification historically has occurred more often in the western Atlantic, that’s not where the team found the increasing strength of the last 30 years. Rather, the phenomenon is strengthening more in the central and eastern Atlantic, especially to the east of the islands of the Lesser Antilles, which includes the Virgin Islands and Saint Kitts. That’s the same area where the AMO creates warmer waters and boosts ocean heat content, in the central and eastern Atlantic. That’s exactly the alley where hurricanes Irma, Jose and Maria powered up rapidly last year. It’s a proving ground of sorts where many of the most powerful hurricanes strengthen dramatically. Balaguru notes that teasing out the effects of the AMO from broader effects of global warming was beyond the scope of the current study but is a focus for scientists.”
Even the IPCC-trumpeting Deutschlandfunk (DLF) found this worth reporting. On May 9, 2018, listeners indeed heard on the daily program “Forschung Aktuell” (Current Research) the following points:
1) Despite climate change, hurricanes have not become more frequent (which totally contradicts the usual DLF claims on this subject).
2) The current faster strengthening of hurricanes has NOTHING to do with anthropogenic global warming (AGW), but rather it depends on the AMO phase.
3) The causes of the AMO cycles are unknown and have nothing to do with AGW.
Yet, it is a pity that these revolutionary climate-realist claims (by DLF standards) were presented in just a very short report and that the inconvenient facts were not reported on in greater detail…you can listen to this small DLF revolution here (starting at 1:33).
==================================
Don’t hold your breath thinking this is a new media awakening happening in Germany. Expect Stefan Rahmstorf of the alarmist Potsdam Vatican to order the science illiterate DLF editors to be led deep down somewhere in the catacombs, and be made to recant the heresy.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterKenneth set to show in just minutes what a sham all the sea level rise alarmism really is. (Now busy setting the troll filter on high!)

NASA photo – public domain
Stay tuned! 🙂
Share this...FacebookTwitter "
"The world’s leading scientists, politicians and even the pope are agreed that the world is warming thanks to human activities. Yet despite this, extreme cold weather still happens. The unusually chilly UK winter of 2009/10, for instance, led to understandable scepticism from some commentators who argued that this “global cooling” conflicted with predictions of warmer winters. There’s no contradiction – the world simply doesn’t work like that. In fact, even after another 85 years of global warming there will still be a small chance of a 2009/10-style winter – a 0.6% chance, to be precise. That’s according to new research by the UK’s Met Office which assesses how likely these sorts of unusual seasons will be in future. The study, published in the journal Nature Climate Change, also says the chances of the sort of historically hot summer that we might currently see only once every two decades will rise to 90% by 2100. What we would today consider a wetter-than-average summer will, by 2100, be relatively rare – just a 20% chance. Importantly, these projections are expressed as probabilities. Climate is most commonly defined by the long-term average of the weather, typically temperature and rain or snowfall, taken over a 30-year time period. This way long-term trends, such as anthropogenic climate change, don’t get lost in the “noise” over much shorter periods. But it’s equally important to assess how variable the weather is. When predicting the long-term effect of climate change it’s necessary to figure out not just what the “background” climate will look like, but also how common freak events, seasons or even years might be. An “average temperature rise of 2℃” isn’t much use to someone working in disaster management, for instance – they need to know whether to prepare for frequent heatwaves, floods or snow. The Met Office uses a climate model known as HadCM3 to make long-term predictions. In this study, several hundred slightly different versions of the model were run to help represent uncertainty in the atmosphere and ocean climate system, for instance in winds and temperatures. The models were also run backwards in time and were assigned degrees of reliability according to their ability to simulate recent climate changes.  The results give a sense of short-term unpredictability of the weather in any given year, rather than merely highlighting what a “typical” year might look like – something not helped by the usual portrayal of projected temperature trends as a smooth line. The cold 2009/10 winter is a good example of year-to-year variability that bucks the trend. The same confusion can happen in shorter timeframes – in the US, Senator Jim Inhofe brought a snowball into congress after it snowed last February to “prove” the world wasn’t getting warmer.  Freak events or even entire seasons don’t invalidate the kind of thorough projections described above. Climate scientists define the norm as within the 2.5-97.5 percentile range, yet these are just probabilities – and 5% of the time anomalies outside that range are expected to occur. The record-breaking winter of 1962/63, the UK’s coldest of the 20th century, or the wet winter of 2013/14 that caused major flooding, simply represent seasons that will only crop up a tiny fraction of the time.  Even a series of seemingly unusual events doesn’t necessarily mean the “background” has changed. England and Wales had a series of wet summers from 2007 through to 2012, which were part of a rising summer rainfall trend after several years of relative “drought” conditions in the 1990s –- a rise that actually goes against long-term predictions of drier summers.  But on the chart below we can see these wet summers are still within the upper shaded grey region (the 2.5-97.5 percentiles) of the probabilistic projections and we can therefore attribute these summers to short-term variability, or noise, in the climate system.  Climate models don’t always capture the amount of year-to-year variability we actually observe in reality, so sometimes they need rescaling. And this variability itself may change over longer timescales, for example the North Atlantic Oscillation (a seesaw of atmospheric surface pressure across the North Atlantic) has become much more variable in winter over the past 50-100 years.  Models are also rather poor at capturing fluctuations in the all-important jet stream which is crucial for simulating precipitation and temperature changes over the British Isles.  Nevertheless, despite some remaining provisos, climate models are an indispensable tool for making predictions, and this new Hadley Centre study is a thorough new benchmark for all those concerned with the impact of climate change in Britain."
"The prime minister, Scott Morrison, has promised an aid package for areas ravaged by Australia’s continuing bushfire crisis and says he will consider a royal commission into the deadly blazes, which have burned vast areas on the east coast. Speaking during a press conference the prime minister also said there had been a breakdown in communications with New South Wales authorities that left the Rural Fire Service and their Australian Defence Force liaison unaware army reservists had been called up to help with the fire effort.  Morrison, who has been heavily criticised for taking a holiday in Hawaii during the crisis and was heckled by locals in Cobargo after forcing a handshake on an unwilling woman, also defended his leadership during the emergency. He said he and the treasurer, Josh Frydenberg, would announce a financial aid package for farmers, small businesses and “others who engage in the rebuilding effort” on Monday, after it was approved by cabinet, and ruled out a bushfire levy to fund it. “We will be committing everything that is needed and more as it is required,” he said. He said he would consider a royal commission into the fires “in concert with states and territories”. “There are matters referred to about planning and building regulations and where people are allowed to build residences and in what circumstances and the land clearing arrangements, of course hazard reduction has been a constant refrain as I have been on the ground,” he said. “I also acknowledge the drought conditions can make that very difficult on occasion but we also know there have been many occasions where the hazard reduction has been actively resisted and that is something that we will have to learn from as well.” This was an apparent reference to the idea, which has been described as a conspiracy theory, that green activism has stopped the practice of burning off during the winter. Morrison said he would not be “distracted” by criticism of his leadership during the crisis and the community expected him to concentrate on the needs of communities hurt by the blazes. “That is very much my focus is and that’s where it will continue to be, working closely with the states and territories, working closely with my ministers and the agencies, the defence forces, the recovery agency, to be led by Mr Colvin and ensuring they have the support they need,” he said. However, he said there had been “a breakdown in communications” that meant the NSW Rural Fire Service commissioner, Shane Fitzsimmons, wasn’t told about the reserves being called out. “And so there has been a subsequent conversation between myself and the premier and the minister of NSW and we have addressed any of those issues that arose from that,” he said. Morrison has previously portrayed the response to the bushfires as primarily a state responsibility, saying as recently as Thursday that he did not want state and federal governments “to be tripping over each other in order to somehow outbid each other in the response”. The defence minister, Linda Reynolds, also admitted to traveling overseas during the crisis, initially telling reporters she had been on holidays over Christmas, without saying where she had been. She said that she “spent time with my family over Christmas but throughout that time I can assure you that I have been regularly on the phone with the prime minister, with [emergency management] minister Littleproud constantly”. Asked directly if she was in Bali she said: “Yes I was.” Defence force personnel have played a key supporting role in the firefighting effort, providing transport, logistics and other help to emergency services since early September. Over the weekend, navy ships evacuated more than 1,000 people from Mallacoota, in East Gippsland, and yesterday the federal government called up 3,000 army reservists to bolster the effort. Does climate change cause bushfires? The link between rising greenhouse gas emissions and increased bushfire risk is complex but, according to major science agencies, clear. Climate change does not create bushfires, but it can and does make them worse. A number of factors contribute to bushfire risk, including temperature, fuel load, dryness, wind speed and humidity.  What is the evidence on rising temperatures?  The Bureau of Meteorology and the CSIRO say Australia has warmed by 1C since 1910 and temperatures will increase in the future. The Intergovernmental Panel on Climate Change says it is extremely likely increased atmospheric concentrations of greenhouse gases since the mid-20th century is the main reason it is getting hotter. The Bushfire and Natural Hazards research centre says the variability of normal events sits on top of that. Warmer weather increases the number of days each year on which there is high or extreme bushfire risk. What other effects do carbon emissions have? Dry fuel load - the amount of forest and scrub available to burn - has been linked to rising emissions. Under the right conditions, carbon dioxide acts as a kind of fertiliser that increases plant growth.  So is climate change making everything dryer?  Dryness is more complicated. Complex computer models have not found a consistent climate change signal linked to rising CO2 in the decline in rain that has produced the current eastern Australian drought. But higher temperatures accelerate evaporation. They also extend the growing season for vegetation in many regions, leading to greater transpiration (the process by which water is drawn from the soil and evaporated from plant leaves and flowers). The result is that soils, vegetation and the air may be drier than they would have been with the same amount of rainfall in the past. What do recent weather patterns show? The year coming into the 2019-20 summer has been unusually warm and dry for large parts of Australia. Above average temperatures now occur most years and 2019 has been the fifth driest start to the year on record, and the driest since 1970. Is arson a factor in this year's extreme bushfires? Not a significant one. Two pieces of disinformation, that an “arson emergency”, rather than climate change, is behind the bushfires, and that “greenies” are preventing firefighters from reducing fuel loads in the Australian bush have spread across social media. They have found their way into major news outlets, the mouths of government MPs, and across the globe to Donald Trump Jr and prominent right-wing conspiracy theorists. NSW’s Rural Fire Service has said the major cause of ignition during the crisis has been dry lightning. Victoria police say they do not believe arson had a role in any of the destructive fires this summer. The RFS has also contradicted claims that environmentalists have been holding up hazard reduction work. Morrison claimed there was “no dispute in this country about the issue of climate change, globally, and its effect on global weather patterns, and that includes how that impacts in Australia”. “The government has always made this connection and that has never been in dispute,” he said. However, overnight the government backbencher Craig Kelly told the BBC there was “no link” between climate change and the fires. In November, the deputy prime minister, Michael McCormack, described people who drew a link between the fires and global heating as “inner-city raving lunatics”."
"Trend-spotters may have declared the car is dead for 20-somethings in central London or Paris but among the rest of humanity sales of the ubiquitous gas-guzzler continue to climb. It seems however environmental we may wish to be, owning a set of wheels is just too convenient to give up. But maybe not for long. A more radical solution to tackling climate change is proposed in a paper in the journal Nature Climate Change. As the industry inches towards self-driving cars isn’t it time to consider trading in the family wagon and simply hail a lift? The argument is seductively simple. We can’t do without cars. No transport alternative offers the same flexibility, personalised comfort and sense of control. But automobiles are spectacularly inefficient in terms of environmental and personal cost. Cars depreciate rapidly, are left idle most of their life-time, eat through fuel while seats are often left empty and they demand no end of real-estate to be parked on. If any field is overdue a wave of disruption it’s personal car ownership. Car-sharing schemes such as BMW’s DriveNow and on-demand services such as Uber give us a glimpse of the benefits cloud computing can bring to fleet management. Autonomous vehicles (AVs) however, could transform this field. Autonomous taxis would be more expensive than a normal car, but with no driver the running costs would be substantially lower. Operators would therefore be likely to run large fleets and would keep their cars on the road for as long as possible – meaning that in areas of high population a vehicle would never be too far away. These vehicles would be different. Just as electric cars have increased interior space by doing away with the engine, dispensing with the steering wheel, gear stick and other controls would free up room for extra people and their belongings. This also links to the potential for what the paper’s authors, two Berkeley scientists, call “right-sizing”. If a wide range of vehicles are in constant circulation, people will be able to order whatever suits them: a people carrier to take the kids to school, then a sporty coupé for the commute to work. This would mean more choice for the individual, but with a knock-on benefit for the environment through reducing the number of large fuel-hungry vehicles with only one occupant. It points towards another expected benefit of autonomous taxis. If fleet operators want cheap and easy re-fuelling (to lower those overheads) then fully-electric vehicles make sense. Whereas single car-owning individuals are likely to be concerned about vehicle range, taxi firms smooth out journey and fuelling requirements over an entire fleet, enabling them always to take advantage of the cheapest electricity. Autonomous vehicles could revolutionise driving. Sensors linked to sophisticated electronic control units would enable cars to anticipate and to respond to risk faster than a human driver. Breaking distances could be reduced, enabling convoys of cars to reduce aerodynamic drag and use their power more efficiently. A great vision for the future, one might observe, but isn’t this all a bit sci-fi? Well at this stage, the answer is probably “yes”. Vehicle automation has of course been with us for years and is actively used in high-risk fields such as bomb disposal, mining or submersibles, not to mention the release into the world of robot vacuum cleaners. But these are relatively controlled environments to operate within, and a world away from the complexity of fast-paced, complex city streets. As it stands there are substantial limitations on autonomous vehicles. Cars are reliant on processing, in advance, extensively mapped environments – making any spontaneous deviations from a route difficult. Snow, heavy rain or bright light can cause havoc with sensors, and “reading” visual symbols such as a police officer signalling would be beyond most current processors. Add to this, the cyber-security risks inherent in all connected vehicles and it becomes plain just how much work developers have to do. Even if these challenges can be overcome in any realistic time-frame the usual drawback of car-sharing services would still apply to autonomous vehicles. Being able to hail a taxi when you want it, never mind in the form one desires it, requires a huge fleet to be operating in densely populated area. We’d also need advanced GPS mapping and tracking systems and large out-of-town charging bays – because although more autonomous taxis would mean less parking needed overall, the fleet as a whole would likely seek cheaper overnight charging at a similar time. Yet what was once science fiction has a tendency to move into the mainstream. Carmakers such as BMW and Tesla have been acquiring driverless technology, as have tech giants Google and Apple – not to mention the car-and-driver-for-hire firm Uber. Indeed one doesn’t need to be an early adopter to see driver assistance and connected technologies becoming commonplace. Crossing the hurdle to fully autonomous vehicles will be a major challenge, but once it has been credibly achieved (and credibility is everything), a whole new market may be awaiting the pioneers. Ultimately this is the point. From San Francisco to Moscow, from Seoul to mighty Coventry (where the UK’s largest driverless car test is taking place), there is a digital infrastructure being laid down and growing expectations among the younger generation of ever more connectivity. Autonomous taxis may not be appropriate everywhere or for everyone, but they do have the potential to capture a large slice of interest in urban centres and, because the capital costs are borne by the transport operators not individuals, there is lots of potential for the business models to spread quickly.  By 2030 our cities, not to mention our cars, may start looking very different. It might be worth thinking about grassing over your driveway."
"Extreme storms and rising sea levels will threaten the existence of coastal cities worldwide, unless preventative action is undertaken. With population growth and sea-level rise set to continue, research has estimated that by 2050, we can expect more than US$1 trillion worth of damages per year to be incurred by 136 of the world’s largest cities, if there is no attempt to adapt. The game changer came in 2005, when we saw one of the most active hurricane seasons in US history. Hurricane Katrina, the fifth hurricane of that season, resulted in nearly 1,600 deaths. Almost half of these fatalities occurred in New Orleans: 80% of the city was flooded, at a cost of US$40 billion. When the water subsided, so did the population: ten years on, the city that used to house 500,000 is now home to only 300,000 people.  There are a number of ways to go about changing cities to account for rising sea levels: we can raise coastal defences, build houses on stilts, or simply move cities and their populations away from the coast. Which of these strategies works best was one of many questions set out in Climate Change: A Risk Assessment – a new report led by Sir David King and the Foreign and Commonwealth Office. Globally, sea levels have been remarkably stable since civilisation started to develop several thousand years ago. During the 20th century, sea levels rose about 17cm, at an average rate of 1.8mm per year. Over the past few decades, that rate has doubled to more than 3mm per year. This trend is expected to continue and accelerate. According to the latest Intergovernmental Panel on Climate Change report, the sea level is projected to rise up to 1m by 2100. If the large ice sheets of Greenland and Antarctica melted, even higher rises are considered possible, albeit highly uncertain. Importantly, if carbon emissions are stabilised, or even decrease, the sea level will continue to rise for many centuries, as the deep ocean slowly warms and the large ice sheets reach a new equilibrium. Simply put, sea-level rise is here to stay. It is likely to lead to greater flooding, salinisation (the build up of salt in surface and groundwater) and erosion in coastal areas, affecting millions of people worldwide and costing billions of dollars of damage. The high costs of economic damage and loss of life are becoming less acceptable in a world where extreme weather events can be accurately forecast and coastal protection is possible. In many parts of the world, damages and loss of life remain high, as seen during Typhoon Haiyan, which hit the Philippines in 2013. Preparing coastal cities for extreme events and adapting them to cope with sea-level rise remains challenging: King’s report highlights the engineering, financial and socio-political limits of the adaptation challenge.  But cities are starting to embrace these challenges. For example, last year, Boston put forward the bold, novel idea of becoming an American Venice – a city full of canals to hold water as sea levels rise. New York has considered building a barrier to keep water out, in light of the fact that, with a 1m rise in the sea level, a 1-in-100 year event (that is, a severe storm one would expect to occur once every 100 years) could become 200 times more likely to occur.  London has also developed a range of flexible options that would protect the Thames Estuary against up to 5m of sea-level rise. These include raising defences, implementing flood storage and constructing a new and bigger Thames Barrier further downstream. In developing countries, few cities are preparing for sea-level rise, despite the awareness that this is a long-term hazard. Developing cities also frequently have rapid population growth. In Shanghai and Kolkata more than 400,000 people live less than 2m above the present-day sea level. A rise of 1m will increase the frequency of a current 1-in-100 year event by 40 times in Shanghai, and about 1,000 times in Kolkata. Local ground subsidence is another factor to worry about. This involves the sinking of the land relative to the sea due to natural and sometimes human processes (such as groundwater withdrawal). Local ground subsidence will worsen conditions in about a quarter of coastal cities – namely, those built on susceptible deltaic soils (those at the mouth of a river). Small islands and their cities are also under serious threat from sea-level rise as they are low-lying, remote and dispersed in their territories, and often have limited financial resources. Far from being a green, spacious island, Malé – the capital of the Maldives – is one of the world’s most densely populated cities. Building protective structures is one way of reducing the impacts of extreme events: Malé is surrounded by a sea wall and giant tetrapods (a four-pronged concentrate structure about 2m high). But a lack of space limits future coastal protection.  To overcome this, a new island has been constructed, Hulhumalé, with sea-level rise also in mind. The solution to sea-level rise is simply to build upwards: The island was raised to 2m above present day sea level to protect against storms. This buys time, but moving into the late 21st or early 22nd century this may not be enough. Other Maldivian islands are following suit, with the Safer Islands programme selectively raising parts of islands. This may help the parts of the country, but clearly much more work is required to ensure the long-term prospects of this fragile island nation. Ultimately, these case studies show us that there’s no one-size-fits-all approach to adapting cities to rising sea levels. Rather, the best bet for cities to adapt against rising sea levels is to dare to be different. Both engineering design, government authorities and social attitudes must acknowledge that change needs to occur, if we’re to avoid disaster."
"A hot summer brings out the sunglasses, ice cream and bare feet. Unfortunately it also brings out the flying, biting pests. The UK has 7,000 species of flies, including midges, horse flies and the ones with arguably the worst reputation, mosquitoes. The most common mosquito species in the UK is Culex pipiens. Few people are actually bitten by it, since it mainly feeds on birds, but this year there are likely to be more C. pipiens and other mosquito species than usual. This is down to seasonal conditions. Pregnant female mosquitoes hibernate and the mild winter will have resulted in greater survival – and more eggs. A wet May was ideal for the aquatic larvae. A hot summer means more fly activity and more people outside to be bitten. So the cycle continues.  Mosquitoes have needle-like mouth parts that pierce flesh so they can suck blood. They also secrete anticoagulants that prevent clotted blood blocking their mouth parts, and a local anaesthetic so you can’t feel the bite. But these bites aren’t just annoying – they’re potentially deadly. Mosquito saliva can be a vehicle for transmission of diseases such as malaria, caused by a tiny protozoan organism called Plasmodium. In 2013, between 124m and 283m people contracted the disease and an estimated 584,000 people died from it. As well as malaria, mosquitoes can transmit viruses including dengue fever, yellow fever, West Nile virus and chikungunya. Luckily for the UK, the species that carries most of these diseases, Aedes egypti, doesn’t live here, but it is increasing its range. It recolonised Madeira in 2004-2005 and there are concerns that it could be transported to western European countries. There are very few recent cases of malaria transmission in the UK, although there is evidence for the disease’s presence from the 14th to the 17th centuries. Shakespeare even mentioned it in The Tempest. Malaria in the UK virtually died out by the end of the 19th century due to a combination of marsh drainage, use of quinine and better sanitation.  Aside from this, the absence of malaria in Western Europe is most likely due to its climate. Plasmodium needs a sustained high temperature to complete its reproduction in the mosquito. The lack of the species mainly involved in transmission of the disease is also crucial.    However, the UK’s freedom from dangerous mosquitoes could be set to change. Firstly, with increased globalisation and faster transport, non-native species could be introduced in sufficient numbers to establish a breeding population. Most insects are strongly “r-selected”, meaning they have evolved to produce large numbers of offspring but live relatively short lives. That means once a species has established itself in a location it can increase very rapidly. For example, Harlequin ladybirds spread over most of southern Britain in just 10 years, with a much slower breeding rate than mosquitoes. Secondly, temperatures are predicted to increase due to climate change. A review published in The Lancet Infectious Diseases concludes that warmer conditions and more rainfall could provide the right conditions for disease carrying mosquitoes to arrive in the UK.  Existing species such as the common Culex pipiens, could spread West Nile Virus here. Another virus-carrying species, Culex modestus has already established colonies in the Thames estuary. A further problem is the Asian tiger mosquito (Aedes albopictus), which spreads dengue fever and chikungunya. Both can be serious illnesses and have no effective treatment. This mosquito’s spread, especially in the United States, has been exacerbated by the international trade in used tyres, whose colour and structure provide ideal incubation pools for the species’ aquatic larvae. Predictions based on a 2oC temperature rise – the commonly agreed limit before which “dangerous” climate change will kick in – could extend Tiger mosquitoes’ activity season by a month and its range by up to 30% by 2030. In the past 10 years insect-borne diseases have spread within Europe, including Greece (malaria) West Nile virus (Eastern Europe), Italy and France (chikungunya). This temperature rise could lead to outbreaks of chikungunya in south-eastern England by the second half of the century. So as the climate warms, mosquitoes in the UK may no longer be just a pest that gets worse during the occasional heatwave. They may become a widespread, constant and dangerous health threat."
"Muslims have a religious duty to take action against climate change, according to a declaration released by a major group of Islamic scholars, faith leaders and politicians from 20 countries. The Islamic Declaration on Global Climate Change, launched in Istanbul, is aimed at the world’s 1.6 billion Muslims and suggests mosques and Islamic schools should immediately take action.  In using religious authority to call for stronger climate change policies at the UN summit in Paris this December, the Islamic declaration follows a similar intervention by the Pope earlier in the year.  There is a solid religious case for this declaration. Muslims around the world take the Qur’an and the prophetic tradition (sunna) as the main two authoritative sources of the Islamic legal system (Sharia). You won’t find any direct references to carbon budgets or biodiversity in the sacred scriptures of course – the global environmental crisis is far too recent. However there is an environmental framework inherently embedded within the traditional principles of Islam, and it is possible to extend these principles to consider contemporary changes. Traditionally there are five major obligations for all Muslims: proclamation in the oneness of Allah, prayer, fasting, pilgrimage and alms-giving (charity towards the poor). Each can help the environment. The concept of oneness may be extended to the unity of creation – the idea that there is one planet for all humanity to share. Thus Islam teaches an inter-connectedness between the environment and human beings.  Prayer is about seeking guidance from Allah. Similarly, the environment has a purpose and forms another kind of revelation, which may be seen as a source of guidance for humanity. Fasting is performed for Allah but recently Muslim faith-activists have fasted for the planet. For example representatives from Wisdom in Nature, an ecological activist group in Britain, would fast so they could contemplate the human impact on the environment.  Also, during pilgrimage Muslims must be considerate to animals and vegetation in designated areas. Finally, the process of alms-giving indicates Muslims are thoughtful and effectively share resources. This means there is already an Islamic ethic for sustainability, particularly equity within and between generations. Climate change affects us all, and by taking action, mosques can make themselves vital and accessible parts of civil society. In Western states, action will present an opportunity to build bridges between Muslims and non-Muslims, emphasising the importance of mosques in the public sphere.  Of course, such action depends on the people responsible for running each mosque.  Generally each follows a particular way of Islamic thinking and the leadership may be reluctant to take on climate change, particularly when other issues, such as the conflicts in Syria and Palestine/Israel dominate current affairs.   Even so, mosques will need input from environmental NGOs to improve their understanding of the Islamic perspective on climate change. And, as climate change tends to be of interest to younger people, mosques will need to keep young people on board, many of whom now feel alienated from the Islamic establishment. It will be vital to encourage climate change action through the various Islamic schools across the world. These children could have a big impact, as it’s a very new field – academics and Muslim scholars are only just catching up with the ways Islam can be applied to today’s climate problems. Whether young Muslims choose to join campaigns, become scientists or simply decide to lead more sustainable lifestyles, they will help develop the idea of Islamic environmentalism and what it could be.  However, there are great global disparities with regard to the importance of Islamic schooling. In Indonesia, for example, it is particularly significant and climate education would make a huge difference. On the other hand, the operation of Islamic schools is more difficult in the West, where Muslim children tend to assimilate into mainstream state-owned schools.  There is certainly an environmental ethic in the Islamic faith, but those behind the declaration need to consider the challenges facing Muslims, mosques and Islamic schools – it’s easy enough to have sustainable principles, but putting them into practice is much harder."
"If we have put too much CO2 into the air, wouldn’t it make sense to find ways to remove it again? Well, yes: it would. But sadly it isn’t likely to be easy or cheap and, according to new research, it isn’t an adequate “solution” to the problems of climate change.  The possible “carbon removal” techniques are very diverse. They include growing trees on land or algae in the sea and capturing and burying some of the carbon they have taken from the atmosphere. There are also engineered solutions that “scrub” CO2 directly from the air, using chemical absorbents, and then recover, purify, compress and liquefy it, so that it can be buried deep underground. That sounds difficult and expensive, and at the moment, it is. Both the UK Royal Society and the US National Research Council point out that doing it on a large enough scale to make a real difference would be hard. Nevertheless, a joint communiqué from UK learned societies recently argued that to limit global warming to 2℃ we are likely to need CO2 removal (CDR) rates in the latter part of this century that will exceed emissions at that time (“net negative emissions”). That will only be possible if we can deploy CDR technologies. A new paper in Nature Communications shows just how big the required rates of removal actually are. Even under the IPCC’s most optimistic scenario of future CO2 emission levels (RCP2.6), in order to keep temperature rises below 2℃ we would have to remove from the atmosphere at least a few billion tons of carbon per year and maybe ten billion or more – depending on how well conventional mitigation goes.  We currently emit around eight billion tonnes of carbon per year, so the scale of the enterprise is massive: it’s comparable to the present global scale of mining and burning fossil fuels. Carbon removal could potentially help to reduce problems such as ocean acidification. So a second paper in Nature Climate Change is also discouraging because it shows that even massive and sustained carbon removal at rates of five billion tonnes a year or more would not be enough to restore anything like pre-industrial conditions in the oceans, if mitigation efforts were to be relaxed. Does all this mean that carbon removal is a blind alley, and that further research is a waste of time (and money)? Well, no. But it is nothing like a magic bullet: this latest research should serve to prevent any unrealistic expectations that we could find a “solution” to climate change, or that carbon removal is any sort of alternative to reducing emissions.  Maintaining and increasing our efforts to reduce emissions is still the crucial top priority. But if we can develop removal methods that are safe and affordable, and that can be scaled up to remove a few billion tonnes per year, that would be useful even now, as it could augment those efforts to reduce CO2 emissions (which is not proving to be easy either). In the longer term, once we have eliminated all the “easily” fixed sources of CO2 emissions, by generating more electricity from renewable sources and capturing carbon from power plants, we shall still be left with several intractable sources, including aviation and agriculture, that are exceedingly hard to abate.  It is then that we shall really need CO2 removal, to take from the air what cannot easily be prevented from reaching it. And beyond that, should we eventually decide that the level of CO2 in the air at which we have stabilised is too high for comfort, and should be reduced, carbon removal will be the only way to achieve that. The low-tech biologically based removal methods are all going to be limited in their scale, not least by potential side-effects in the oceans and conflicts over alternative uses for any land required. However several groups are working on promising methods for direct (physical and/or chemical) capture from the air, trying to reduce the energy, water and materials demands – and of course the costs – to acceptable levels.  In the longer term someone may find a suitable catalyst to accelerate the natural geochemical weathering processes that already remove CO2 from the air (but much too slowly to cope with man-made emissions). That would solve the CO2 disposal problem too, especially if we can avoid mining billions of tons of minerals to use as absorbent. But it’s likely to take several decades to get from the lab to industrial-scale deployment – and none of these technologies will be deployed in practice until we have established a price on carbon emissions that makes them commercially worthwhile.  Carbon removal is not a magic bullet, but it is still a vitally important technology that we shall almost certainly need eventually. We should be researching it steadily and seriously, because it is going to take time and a lot of effort to develop methods that are safe and affordable and can be deployed on a massive scale.  So we should continue to research removal, not as a possible quick fix, but as a vital tool for the end game. It’s a massive scientific and engineering challenge that really needs the sort of concerted effort that was devoted to going to the moon or building the Large Hadron Collider. And in my opinion it would be far more worthwhile."
nan
"
Share this...FacebookTwitterGerman skeptic and weather expert ‘Schneefan’ here writes how climate activist Mark C. Serreze recently announced this year’s sea ice extent was at the smallest all-time area. But since then Arctic temperatures have plummeted and sea ice area has grown to over 14 million square kilometers:
At the sea ice portal, the development is clearly shown.

Chart: University of Bremen
On March 103 2018 sea ice extent in the Arctic reached 14.55 million km² and so the end of Arctic sea ice growth had in fact not been reached.
The plunge in the mean temperature north of 80°N to -25°C can be seen in the plot by the DMI, and so a growth in sea ice was expected.

After an increase to about -10°C in February (due to a weather pattern) the average temperature above 80°N latitude has since fallen to -25°C. Source: DMI.
Naturally the German mainstream media such as ARD television pounced on the news and set off the climate catastrophe alarms, and thus ended up reporting totally falsely again on the real sea ice development in the Arctic: ARD: heat wave in Arctic.
A heat wave at a mean temperature of -10°C?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Below is what the ARD fake “heat wave” really looks like in the Arctic for the entire 2017/18 winter, shown by a plot of the NOAA reanalysis using measured and computed mean temperatures:

The NOAA reanalysis shows the mean 2m-temperatures for the northern hemisphere in the winter of 2017/18. Source: NOAA reanalysis
Perhaps the editors at ARD should have been more careful in checking where this faulty Arctic information came from before coming out with such climate-alarmist fake news.
A check in the Internet shows that the ARD report quoted Mark C. Serreze, a known climate activist, IPCC author and the person who coined the term Arctic sea ice “death spiral”.
He worked earlier together with the now embarrassed Peter Wadhams, who over the past years falsely forecast  the disappearance of Arctic sea ice on multiple occasions. What unfortunately has escaped the media, such as ARD, is the fact that the Arctic ice cap at the start of March 2018 is much thicker than it was 10 years ago, see the alternating charts that follow:

Impressive growth: sea ice volume (smaller chart, black curve) is greater in March 2018 than the two previous years and is near the average level (gray area) of the past years.
As everyone is aware, the multiple-year ice melts more slowly than the thinner one-year ice – and so we sill see how many Wadhams (1 Wadham = 1 million km²) will be left in September 2018.
This leads us to conclude that there is nothing left of the absurd, Al Gore envisioned, ice-free Arctic fantasies which were suppose to come true already in 2016.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterPaleoclimate data still spotty and incomplete, leaving climate models vague, uncalibrated and filled with uncertainty
Paleo-climatological data, used for the reconstruction of past climate from proxy records such as ice cores, tree rings, sediment cores etc., have not had adequate geographical coverage.

Lake Tanganyika, Tanzania, where a sediment core was extracted. Credit: Andreas31,  CC BY-SA 3.0.
For example although the Medieval Climate Anomaly has also been well documented in other parts of the world, there has been little data when it comes to the Arabian Peninsula and the African continent, which comprise about one quarter of Earth’s land surface.
Too often scientists reconstructing past climates have been overly eager in drawing far-reaching conclusions based only a few datasets, and attempted to adventurously apply them to neighboring regions or even globally.
Climate Anomaly in Africa and Arabia as well
Now a new paper published on Eos.org here by Lüning et al. attempts to fill this data chasm. Their publication “correlated and synthesized the findings of 44 published paleotemperature case studies” from across the Afro-Arabian region and mapped the resulting trends of the Medieval anomaly’s central period of about 1000 to 1200 CE.
The paper is titled: “Warming and Cooling: The Medieval Climate Anomaly in Africa and Arabia”.
“Uncalibrated” and “vague” models
“Enormous data gaps exist,” wrote Lüning in an e-mail. “A high impact study program is needed to close these gaps. Paleoclimate information is essential to validate climate models, which otherwise are not calibrated and remain vague.”
According to their findings, paleotemperature reconstructions from these published case studies show “the Afro-Arabian region experienced climate perturbations, including an extended period of anomalously warm conditions, during medieval times. Because this Medieval Climate Anomaly represents the closest analogue to modern warming, it defines a crucial baseline by which modern postindustrial climate trends can be compared.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Lüning wrote NTZ:
This work is based on a large numbers of valuable paleoclimate studies. We have mosaiced these data points together and found that the Medieval Climate Anomaly was characterized by warming in most of Africa and Arabia, therefore justifying the term “Medieval Warm Period” for the African land area. An exception was the southern Levant where its got cooler.”
In a nutshell, the findings suggest the majority of onshore Afro-Arabian sites also experienced warming during the Medieval Climate Anomaly, and thus the warming was not just a phenomenon confined to the North Atlantic and Europe, as some scientists have tried to suggest.
Outstanding resource
Lüning has spent years researching and compiling paleoclimate data, and as a result has produced a “Climate Reconstruction Map of the Medieval Warm Period“.
Link to solar and oceanic cycles
In some of the records in the newly published study the researchers found that cold spikes corresponded with periods of low decreased solar activity or declining ocean cycles. thus suggesting that solar forcing and changing ocean circulation are the most likely causes of medieval era climate change.
Lüning added:
Climate patterns never cover the whole globe, therefore it is important to first map out trends and understand the pattern distribution. Otherwise the meaning of purely mathematically stacked data series remains unclear.”
This study represents a step toward globally characterizing the Medieval Climate Anomaly, an improved understanding of which will help scientists refine global climate models and improve hind-casting.
Read more at Research Spotlight.
Share this...FacebookTwitter "
"Conservationists tend to spend their time worrying about protecting forests, catching poachers or keeping carbon out of the atmosphere. But all these things (and more) are driven by humans. Given that it’s easier and cheaper to reduce the human birth rate than it is to address these other issues, why aren’t conservationists more concerned about keeping our population down? After all, it is estimated that more than three-quarters of the world’s ice-free land has been modified by people. We are already overstepping the planet’s boundaries and our actions are causing climate change and the sixth mass extinction.  By 2050 human population growth alone will threaten a further 14% of the planet’s species; this is on top of the 52% decline in numbers of mammals, birds, reptiles, amphibians and fish over the past four decades. Only 13 years ago, we were 6 billion; just seven years later, we hit 7 billion and by 2100 we could be as many as 12.3 billion people. Shockingly, with each child a woman has, her carbon emissions legacy is increased six-fold. It cannot be denied that our size, density and growth rate all increase wildlife extinctions.  But all is not lost. Fertility rates decline the longer a girl spends in school. By simply providing better female education, the overall population in 2050 could be 1 billion less than current projections. This is because women who are empowered through education have fewer children, as well as having them later in life and therefore have the resources to provide them with better care. Along with this, one in five women – 800m worldwide – have an unmet need for modern contraception; in developing countries this can be as high as 60%.   We aren’t suggesting any evil population control schemes here – it’s about providing resources to girls who want an education and women who want access to family planning. The benefits can be seen relatively quickly: between 1960-2000, contraceptive use by married women in developing nations increased from 10% to 60%, reducing the average number of children per woman from six to three.  However, we still pay surprisingly little attention to what this all means for the world’s wildlife.  A small but growing number of organisations are beginning to integrate wildlife conservation with family planning. Blue Ventures, a marine conservation organisation in Madagascar, has trained local women to provide contraception in rural villages close to protected areas. In three years, the project reduced its own ecological footprint by 267 global hectares purely by providing access to family planning. A slightly different approach was taken by The Center for Biological Diversity in the US. On World Population Day last year the organisation distributed 40,000 condoms wrapped in packaging depicting endangered species with catchy slogans such as “Don’t go bare … Panthers are rare”. It is unclear whether this had any effect on human behaviour, but the emphasis on bringing the issue to a developed country with a high consumption rate is commendable, given the typical focus on stemming population growth only in developing countries. A more holistic approach combines family planning and other healthcare services with alternative livelihood options – this has been implemented in some key high biodiversity areas that have an unmet need for contraception and healthcare. One programme in Nepal led to an increased use of condoms and reduced wood fuel usage equivalent to saving nearly 9,000 trees annually.  There is an increasing gap between donations and demand for contraception. Filling the unmet need for family planning across developing countries would cost US$8.1 billion annually; finding this amount of money will clearly be challenging. Furthermore, contraceptive use and female access to education are affected by strong cultural and religious problems. We cannot simply advocate for more access to family planning and education without addressing barriers to access. Population growth doesn’t seem to be a major concern for conservationists but it should be. Researchers should investigate the effects of human population interventions on wildlife, while conservationists could form alliances with other sectors of society, such as reproductive choice and womens’ rights groups. As environmental organisations often integrate educational aspects into their programs, it would not be difficult to direct further educational materials towards women and girls. We now have evidence to show the links between human population size, growth and density on the environment, but we need to increase our research efforts on how contraception and female education policies affect biodiversity. Conservation scientists cannot dismiss the effects of overconsumption on the natural world, but we also cannot disregard the effect our sheer population size and growth have on the planet.  Addressing human population growth may be a relatively fast and cheap remedy for wildlife loss, which can help reduce consumption and brings us closer to achieving true sustainability. The sooner we start to pull the brakes, the easier it will be to eventually come to a stop. So what are we waiting for?"
"
Share this...FacebookTwitterGame over for green energies and CO2 reductions? 
Journalist Daniel Wetzel of German national daily Die Welt here presents a devastating commentary on Paris Accord and Germany’s so far “illusionary” CO2 reductions targets. The German failure is a signal that could have significant global consequences.
Wetzel not only calls the targets illusionary, he also believes the existing Energiewende (transition to green energies) is “at an end”.
2030 target completely illusionary
According to Wetzel, “The Energiewende and climate change are not among the priorities of the government” and that Germany reaching its self-imposed targets is achievable only if “everyone were forced to switch off every boiler, oven, motor. Completely illusionary.”
Lots of talk, no action
While German political leaders like to continue pretending they are taking real action to combat climate change, the reality is that the German government has been rolling back subsidies for green energies such as wind and sun over the past years. And many localities have made the permitting of wind parks far more stringent.
The days of unfettered support for green energies are over.

Germany’s CO2 equivalent greenhouse gas emissions in millions of tonnes (Source: UBA Federal Office of Environment)
The result: Germany has not reduced its CO2 equivalent emissions for close to a decade (see chart above). Wetzel writes that everyone agrees that it is unrealistic to think that Germany will somehow make the sudden downward trend turn.
German Energiewende “at the end”
The Die Welt journalist adds: “Practically all renowned environmental analysts and government experts have already determined that the German Energiewende structurally has reached the end and that a system change is needed.”
Humans burning fuel one million years
In his commentary Wetzel also reminds that humans have been using fire for some one million years, and that it cannot be expected that they will just stop doing so during the course of one single generation.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Wetzel compares the Energiewende to the Apollo space program, which put man on the moon after 12 years and 120 billion dollars of investment. He notes that compared to the great transformation which Energiewende would entail, this was peanuts.
He warns that implementing the Energiewende could cost the country a back-breaking three trillion euros (without mentioning the impact on climate would be negligible) and doubts the public would ever accept such a large-scale, draconian transformation of society.
German credibility takes a blow
Wetzel also comments the Germany’s failure to make the 2020 targets has tarnished the country’s image as a leader in climate protection, and adds: “The coalition agreement and the German Federal Budget for 2018 robbed all remaining credibility.”
In short Germany’s is not serious about reducing CO2.
Environmental groups and the Potsdam Institute, for example, are fuming, yet keep insisting it’s still not too late and achieving the target is still possible. But Wetzel injects sobriety and realism: “In the meantime we know that Germany will not only fail resoundingly to meet its self-imposed 2020 targets, but also those of the EU itself.”
With Germany as Europe’s largest economy, and regarded as a role model for all things green, the country’s failure would send a devastating message to the rest of the continent and the world: The Green Revolution was mostly a dream and was in fact never attainable. If tech-savvy Germany can’t do it, who can?
“No reality basis”
Yet, German officials continue to insist they can meet the 2030 target! But Die Welt’s Wetzel notes that doing so would mean Germany cutting it’s CO2 equivalent emissions by some 40%, or 350 million tonnes, within the next 12 years. That would mean radical and painful transformations. Recall that Germany has not managed to emissions at over the past decade (see chart above). Wetzel asks: “How credible is this target?”
Die Welt’s Wetzel summarizes:
The feasibility rhetoric of policymakers as a rule has no reality basis.”
Finally, he reminds that Germany going it alone will never work, and that climate protection has to be “organized internationally – or not at all”.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterHere at NTZ we are glad to see that German weather and climate blogger Schneefan is back from his hiatus and this week he presents a couple of interesting posts, here and here.
Cold to grip Europe for rest of month
First he writes that the latest weather models and patterns are now pointing to an extended winter this year for Europe. For example the 14-day forecast for Hanover shows frosty conditions ahead.
Also a recent run by the European weather model shows severe cold potentially gripping Europe in 9 days:

February 1°C cooler than normal 
So far Germany has seen the first half of February come in almost 1°C cooler than normal, making it among the coldest in years, says meteorologist Dominik Jung of www.wetter.net.
Earlier projection was entirely wrong
According weather experts, March is also expected to be wintry and could be one of the coldest in years. That’s quite a turnaround given that the earlier CFS forecast made back in mid-January which showed blow torch temperatures cooking Europe in February:

The US National Weather Service (CFS) 2m surface temperature forecast made on 18 January, 2018, showed very warm conditions for February. That forecast has since been drastically revised.
La Nina dragging temperatures down
So why have we been hearing about so many harsh winter conditions all over the northern hemisphere this winter?
One reason likely has something to do with the fact that the globe has been cooling off substantially since the last El Nino ended in 2016. Currently we are now experiencing La Niña conditions:

Chart shows the weekly deviations from the mean for the El Niño-region 3.4 from May 2016 until the beginning of February 2018. Currently we find ourselves in the cool La Nina phase. Source: KNMI
Furthermore, the National Weather Service continues to show La Nina conditions persisting through most of 2018, which means a greater likelihood of a further cooling of the globe’s surface:

Over the past 2 years global surface temperatures as measured by satellites show steady cooling. Source: WoodForTrees.org.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Another longer term culprit suspected of being behind the cooling is the current solar cycle number 24, which has been abnormally weak over the entire current decade. The Cycle 24 was the weakest in 200 years. Low solar activity has been shown to lead to cooling surface temperatures.

Screenshot shows the number of spotless days on the sun up to February 14, 2018. Source: www.spaceweather.com/
Oceans cooling over past 3 years
Another sign that bodes especially ill for continued surface cooling is that the world’s oceans have been cooling. 71% of the earth’s surface is covered by water, which means these temperature changes will have significant impacts on the globe’s climate.
In January 2018 Ron Clutz reported at Science Matters on an unexpected phenomenon: the cooling of the global oceans over the past 3 years:
The chart below shows SST monthly anomalies as reported in HadSST3 starting in 2015 through December 2017.”


After a bump in October the downward temperature trend has strengthened. As will be shown in the analysis below, 0.4C has been the average global anomaly since 1995 and December has now gone lower to 0.325C.  NH dropped  sharply along with the Tropics.  SH held steady erasing the Oct. bump.  All parts of the ocean are clearly lower than at any time in the past 3 years.
For Reference:
Global SSTs are the lowest since 3/2013
NH SSTs are the lowest since 3/2014
SH SSTs are the lowest since 1/2012
Tropics SSTs are the lowest since 3/2012
[…]
The oceans are driving the warming this century.  SSTs took a step up with the 1998 El Nino and have stayed there with help from the North Atlantic, and more recently the Pacific northern “Blob.”  The ocean surfaces are releasing a lot of energy, warming the air, but eventually will have a cooling effect.  The decline after 1937 was rapid by comparison, so one wonders: How long can the oceans keep this up?”
Read the entire post at Science Matters.
“Bad times” for global warming alarmists
Ron also looks at the AMO ocean cycle. Schneefan summarizes it all in a nutshell:
Everything points to an imminent tipping of the AMO cycle. That’s going to pull global temperatures downward. For Rahmstorf and Co. bad times are starting.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterDuring 2017, there were 150 graphs from 122 scientific papers published in peer-reviewed journals indicating modern temperatures are not unprecedented, unusual, or hockey-stick-shaped — nor do they fall outside the range of natural variability.  We are a little over 4 months into the new publication year and already 81 graphs from 62 scientific papers undermine claims that modern era warming is climatically unusual.



Zheng et al., 2018
“In this study we present a detailed GDGT data set covering the last 13,000 years from a peat sequence in the Changbai Mountain in NE China. The brGDGT-based temperature reconstruction from Gushantun peat indicates that mean annual air temperatures in NE China during the early Holocene were 5–7°C higher than today.  Furthermore, MAAT records from the Chinese Loess Plateau also suggested temperature maxima 7–9°C higher than modern during the early Holocene (Peterse et al., 2014; Gao et al., 2012; Jia et al., 2013). Consequently, we consider the temperatures obtained using the global peat calibration to be representative of climate in (NE) China. … The highest temperatures occurred between ca. 8 and 6.8 kyr BP, with occasional annual mean temperatures >8.0 ± 4.7°C, compared to the modern-day MAAT of ∼3°C.”


Anderson et al., 2018
“We estimate that air temperatures were 2.5–3.0 °C higher during the Holocene Thermal Maximum than the local 1960–1990 average. … Between 1700 and 1925 CE temperatures were likely 0.6–0.8 °C lower than the 1950–2015 reference temperature.“


Harning et al., 2018
“Iceland’s terrestrial HTM [Holocene Thermal Maximum] has previously been constrained to ~7.9 to 5.5 ka based on qualitative lake sediment proxies (Larsen et al., 2012; Geirsdottir et al., 2013), likely in association with progressive strengthening and warming of the Irminger Current (Castaneda et al., 2004; Smith et al., 2005; Olafsdottir et al., 2010). Numerical modeling experiments for Drangajokull suggest that peak air temperatures were 2.5 – 3°C warmer at this time relative to the 1961-1990 CE average (Anderson et al., 2018). … During the Little Ice Age (LIA, 1250-1850 CE), the Vestfirðir region entered the lowest multi centennial spring/summer temperature anomalies of the last 9 ka. Based on recent numerical  modeling simulations, this anomaly is estimated to be 0.6-0.8°C below the 1950-2015 average on Vestfirðir (Anderson et al., 2018).”



Grieman et al., 2018
“[C]limate anomalies appear to be reflected in the Tunu VA [vanillic acid] record, with elevated VA [vanillic acid] during the warm periods and lower levels during the colder periods. The data suggest a positive correlation between North American fire and hemispheric mean temperature. This relationship could be due to climate-driven changes in temperature or precipitation on burning extent, frequency, or location, as well as to changes in atmospheric transport patterns. …  … [E]levated VA [vanillic acid] early in the record [Roman Warm Period] and around the MCA [Medieval Climate Anomaly]. It also emphasizes the decreasing trend from 1200-1900 CE [Little Ice Age] and the increase during the 20th century [Current Warm Period].”



Thornalley et al., 2018


Maley et al., 2018


Polovodova Asteman et al., 2018
“The record demonstrates a warming during the Roman Warm Period (~350 BCE – 450 CE), variable bottom water temperatures during the Dark Ages (~450 – 850 CE), positive bottom water temperature anomalies during the Viking Age/Medieval Climate Anomaly (~850 – 1350 CE) and a long-term cooling with distinct multidecadal variability during the Little Ice Age (~1350 – 1850 CE). The fjord BWT [bottom water temperatures] record also picks up the contemporary warming of the 20th century, which does not stand out in the 2500-year perspective and is of the same magnitude as the Roman Warm Period and the Medieval Climate Anomaly.”



Wündsch et al., 2018


McGowan et al., 2018
“Our reconstructed Tmax [temperature maximum] for these warmer conditions peaks around 1390 CE at + 0.8 °C above the 1961–90 mean, similar to the peak Tmax during the RWP [Roman Warm Period]. These results are aligned with the findings that show the period from 1150 to 1350 CE to be the warmest pre-industrial chronzone of the past 1000 yrs for southeast Australia.”


Wu et al., 2018


Hanna et al., 2018
“Reconstructed temperatures are generally coolest between 300 and 800 CE (Tavg = 2.24 ± 0.98°C), displaying three temperature minima centered at 410 CE (1.34 ± 0.72°C), 545 CE (1.91 ± 0.69°C), and 705 CE (1.49 ± 0.69°C). Temperatures then rapidly increased, reaching the warmest interval (800–1000 CE) in the approximately 1700-year record. During this interval, average temperatures were 3.31 ± 0.65°C, with a maximum temperature of 3.98°C.”


Li et al., 2018
“There are also other studies that suggest that the recent climate warming over the southeastern TP actually began in the 1820s (Shi et al., 2015). However, a few reconstructions from the west and northwest parts of Sichuan or from the southeastern TP indicate that there were no obvious increase of temperature during the past decades (Li et al., 2015b; Zhu et al., 2016).”
 


Qin et al., 2018     


Allen et al., 2018
“The longest sustained period of relatively high temperatures in the reconstructions is the post 1950 CE period although there are clearly individual years much earlier that were warmer than any in the post-1950 period.”


Li et al, 2018   (North China)


Levy et al., 2018
“The three historical moraine crests indicate that there were at least three ice-margin stillstands or advances during historical time. Summer temperature records from North lake (Axford et al. 2013) and Lake N3 (Thomas et al. 2016) broadly register cooling in the past 200 years in western Greenland, which likely influenced the advance to the historical moraines.”


Perner et al., 2018
“From c. 1.5 ka BP onwards, we record a prominent subsurface cooling and continued occurrence of fresh and sea‐ice loaded surface waters at the study site.”



Zhang et al., 2018



Guo et al., 2018


Belle et al., 2018


Lemmen and Lacourse, 2018
“The early Holocene was marked by relatively stable temperatures that exceeded modern by ~2 to 3°C. Inferred temperatures generally decrease through the remainder of the Holocene.”




Oppedal et al., 2018


Blundell et al., 2018     


Badino et al., 2018     
“Between ca. 8.4-4 ka cal BP [8,400 to 4,000 years before present], our site [Italian Alps] experienced a mean TJuly of ca. 12.4 °C, i.e. 3.1 °C warmer than today [9.3 °C]. … Between 7400 and 3600 yrs cal BP, an higher-than-today forest line position persisted under favorable growing conditions (i.e. TJuly at ca. 12 °C).”



Song et al., 2018
“[A] general warm to cold climate trend from the mid-Holocene to the present, which can be divided into two different stages: a warmer stage between 6842 and 1297 cal yr BP and a colder stage from 1297 cal yr BP to the present.”


Blarquez et al., 2018


Perner et al., 2018
“[W]e find evidence of distinct late Holocene millennial-scale phases of enhanced El Niño/La Niña development, which appear synchronous with northern hemispheric climatic variability. … Phases of dominant El Niño-like states occur parallel to North Atlantic cold phases: the ‘2800 years BP cooling event’, the ‘Dark Ages’ and the ‘Little Ice Age’, whereas the ‘Roman Warm Period’ and the ‘Medieval Climate Anomaly’ parallel periods of a predominant La Niña-like state.”


 Magyari et al., 2018
“…its climatic tolerance limits were used to infer July mean temperatures exceeding modern values by 2.8°C at this time [8200-6700 cal yr BP] (Magyari et al., 2012).”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Mikis, 2018


Kelley et al., 2018
“Historical and remote-sensing records indicate that Nordenskiöld Gletscher has been stable or advancing since AD 1950 (Weidick, 1968, 1994).”


Papadomanolaki et al., 2018  (Baltic Sea)
“A large fraction of the Baltic Proper became hypoxic again between 1.4 and 0.7 ka BP, during the Medieval Climate Anomaly (MCA), when mean air temperatures were 0.9–1.4 °C higher than temperatures recorded in the period 1961–1990 (e.g. Mann et al., 2009; Jilbert and Slomp, 2013).”

Leonard et al., 2018  (Great Barrier Reef, Australia)
“Coral derived sea surface temperature (SST-Sr/Ca) reconstructions demonstrate conditions ∼1 ◦C warmer than present at ∼6200 (recalibrated 14C) and 4700 yr BP, with a suggested increase in salinity range (δ18O) associated with amplified seasonal flood events, suggestive of La Niña (Gagan et al., 1998; Roche et al., 2014).”

Suvorov and Kitov, 2018 (Eastern Sayan, Siberia)
“The authors examined the variability of activity of modern glaciation and variation of natural conditions of the periglacial zone on climate and on dendrochronological data. Results of larch and Siberian stone pine growth data were revealed at the higher border of forest communities. …  It is believed that the temperature could be 3.5 °C warmer at the Holocene optimum than at the present time (Vaganov and Shiyatov 2005). … Since 2000, there has been growth of trees instability associated with a decrease in average monthly summer temperatures. …  Since the beginning of 2000, decrease in summer temperatures was marked.”

Lozhkin et al., 2018 (East Siberia)
“The postglacial occurrence of relatively warm/dry and warm/wet intervals is consistent with results of a regional climate‐model simulation that indicates warmer than present temperatures and decreased effective moisture at 11 000 cal. a BP and persistence of warm conditions but with greater moisture and longer growing season at 6000 cal. a BP.”

Xu et al., 2018 (Northern South China Sea)
“This study provides evidence that thermal coral bleaching events have occurred in the warmer mid-Holocene (where maximum monthly summer SST was 2 °C higher than at present) in Hainan island.  … [C]oral bleaching events under high SST conditions have already occurred in the mid-Holocene and are by no means a new ecological phenomenon of current global warming.”

20th/21st Centuries Non-Warming

Lansner and Pepke Pedersen, 2018
“In locations best sheltered and protected against ocean air influence, the vast majority of thermometers worldwide trends show temperatures in recent decades rather similar to the 1920–1950 period. This indicates that the present-day atmosphere and heat balance over the Earth cannot warm areas – typically valleys – worldwide in good shelter from ocean trends notably more than the atmosphere could in the 1920–1950 period. … [T]he lack of warming in the OAS temperature trends after 1950 should be considered when evaluating the climatic effects of changes in the Earth’s atmospheric trace amounts of greenhouse gasses as well as variations in solar conditions.”













Partridge et al., 2018
“We present a novel approach to characterize the spatiotemporal evolution of regional cooling across the eastern U.S. (commonly called the U.S. warming hole), by defining a spatially explicit boundary around the region of most persistent cooling. The warming hole emerges after a regime shift in 1958 where annual maximum (Tmax) and minimum (Tmin) temperatures decreased by 0.46°C and 0.83°C respectively.”



Payomrat et al., 2018
“During the third segment (1870–2001), the maximum temperature pattern seemed to be constant compared to the changing rate (+0.004 °C/decade). … The short fourth segment, which occurred from 2002 to 2013, showed a deceasing trend at a rate of -0.12 °C/decade.”


Mikkelsen et al., 2018


Westergaard-Nielsen et al., 2018
“Here we quantify trends in satellite-derived land surface temperatures and modelled air temperatures, validated against observations, across the entire ice-free Greenland. … Warming trends observed from 1986–2016 across the ice-free Greenland is mainly related to warming in the 1990’s. The most recent and detailed trends based on MODIS (2001–2015) shows contrasting trends across Greenland, and if any general trend it is mostly a cooling. The MODIS dataset provides a unique detailed picture of spatiotemporally distributed changes during the last 15 years. … Figure 3 shows that on an annual basis, less than 36% of the ice-free Greenland has experienced a significant trend and, if any, a cooling is observed during the last 15 years (<0.15 °C change per year).”


Smeed et al., 2018


 Ahn et al., 2018


Eck, 2018     
“[A] majority (12/14) of the regions within the SAM [Southern Appalachian Mountains] have experienced a long-term decline in mean winter temperatures since 1910.  Even after removing the highly anomalous 2009-2010 winter season, which was more than two standard deviations away from the long-term mean, the cooling of mean winter temperatures is still evident. … Higher winter temperatures dominated the early 20th century in the SAM [Southern Appalachian Mountains] with nine of the ten warmest winter seasons on record in the region having occurred before 1960. The 1931-1932 winter season, the warmest on record, averaged 8.0°C for DJF [December-February], nearly 4.7°C higher than the 1987-2017 normal mean winter temperature of 3.3°C. … Despite the 2016-2017 winter season finishing with the highest mean temperatures (5.7ºC) observed in the SAM [Southern Appalachian Mountains]  since 1956-1957, there have been several years of anomalous negative temperature anomalies, with the 2009-2010 (0.3ºC) and 2010-2011 (1.2ºC) winter seasons finishing as two of the coldest on record for all regions.”


Yi, 2018


Nicolle et al., 2018     



Purich et al., 2018     
“Observed Southern Ocean changes over recent decades include a surface freshening (Durack and Wijffels 2010; Durack et al. 2012; de Lavergne et al. 2014), surface cooling (Fan et al. 2014; Marshall et al. 2014; Armour et al. 2016; Purich et al. 2016a) and circumpolar increase in Antarctic sea ice (Cavalieri and Parkinson 2008; Comiso and Nishio 2008; Parkinson and Cavalieri 2012).  …  Our results suggest that recent multi-decadal trends in large-scale surface salinity over the Southern Ocean have played a role in the observed surface cooling seen in this region. … The majority of CMIP5 models do not simulate a surface cooling and increase in sea ice, as seen in observations.”


Palmer et al., 2018


Clem et al., 2018
“This study finds recent (post-1979) surface cooling of East Antarctica during austral autumn to also be tied to tropical forcing, namely, an increase in La Niña events. … The South Atlantic anticyclone is associated with cold air advection, weakened northerlies, and increased sea ice concentrations across the western East Antarctic coast, which has increased the rate of cooling at Novolazarevskaya and Syowa stations after 1979. This enhanced cooling over western East Antarctica is tied more broadly to a zonally asymmetric temperature trend pattern across East Antarctica during autumn that is consistent with a tropically forced Rossby wave rather than a SAM pattern; the positive SAM pattern is associated with ubiquitous cooling across East Antarctica.”


Kim et al., 2018     
“Recent surface cooling in the Yellow and East China Seas and the associated North Pacific climate regime shift … The Yellow and East China Seas (YECS) are widely believed to have experienced robust, basin-scale warming over the last few decades. However, the warming reached a peak in the late 1990s, followed by a significant cooling trend.  … The most striking evolution pattern is that a robust warming trend at a rate of +0.40°C per decade reached a peak in the late 1990s, and then it turned downward at a rate of  −0.36°C per decade. The positive and then negative trends are estimated throughout the YECS for the periods 1982−1997.”


Shu et al., 2018
“The link between boreal winter cooling over the midlatitudes of Asia and the Barents Oscillation (BO) since the late 1980s is discussed in this study, based on five datasets. Results indicate that there is a large-scale boreal winter cooling during 1990–2015 over the Asian midlatitudes, and that it is a part of the decadal oscillations of long-term surface air temperature (SAT) anomalies.”


Mallory et al., 2018


Jones et al., 2018


Burger et al., 2018
“Previous studies have identified spatial and temporal trends in temperature and precipitation in Chile over recent decades. Temperature rose significantly during the mid to late 20th century in coastal locations between 18 to 33 °S (Rosenblüth et al., 1997), but then started to decrease, with a cooling trend up to -0.20ºC decade-1 dominating over the past 20-30 years (Falvey and Garreaud, 2009).”
 

Hrbáček et al., 2018
“Active layer monitoring in Antarctica: an overview of results from 2006 to 2015 … Air temperatures showed significant regional differences within the study areas. In the western Antarctic Peninsula region, Vestfold Hills and northern Victoria Land, a slight air temperature cooling was detected, while at other sites in Victoria Land and East Antarctica the air temperature was more irregular, showing no strong overall trend of warming or cooling during the study period (Figure 2). The Antarctic Peninsula region has been reported as the most rapidly warming part of Antarctica (e.g. Turner et al., 2005, 2014), but cooling has been reported since 2000 (Turner et al., 2016). Relatively stable air temperature conditions during the past 20 years were reported in Victoria Land (Guglielmin & Cannone, 2012).”


Ramesh and Soni, 2018
“The present paper reviews the progress of India’s scientific research in polar meteorology. The analysis of 25 years meteorological data collected at Maitri station for the period 1991–2015 is presented in the paper. The observed trend in the temperature data of 19 Antarctic stations obtained from READER project for the period 1991–2015 has also been examined. The 25 years long term temperature record shows cooling over Maitri station. The Maitri station showed cooling of 0.054 °C per year between 1991 and 2015, with similar pronounced seasonal trends. The nearby Russian station Novolazarevskaya also showed a cooling trend of 0.032 °C per year. … The temperature trend in average temperature of 19 Antarctica stations is also examined to ascertain the extent of cooling or warming trend (Supplementary Table_S1). The majority of stations in East Antarctica close to the coast show cooling or no significant trend. … Turner et al. (2016) using stacked temperature record found a significant cooling trend for the Antarctic Peninsula for the period 1999–2014.”


Gennaretti et al., 2018
 

Liu et al., 2018


Tang et al., 2018
“The study of Antarctic precipitation has attracted a lot of attention recently. The reliability of climate models in simulating Antarctic precipitation, however, is still debatable. This work assess the precipitation and surface air temperature (SAT) of Antarctica (90°S to 60°S) using 49 Coupled Model Intercomparison Project phase 5 (CMIP5) global climate models”


 Cerrone and Fusco, 2018  (Antarctica)
“Compelling evidence indicates that the large increase in the SH sea ice, recorded over recent years, arises from the impact of climate modes and their long-term trends. The examination of variability ranging from seasonal to interdecadal scales, and of trends within the climate patterns and total Antarctic sea ice concentration (SIC) for the 32-yr period (1982–2013), is the key focus of this paper. The results herein indicate that a progressive cooling has affected the year-to-year climate of the sub-Antarctic since the 1990s.”
Fernandoy et al., 2018  (Antarctic Peninsula)
“As shown by firn core analysis, the near-surface temperature in the northern-most portion of the Antarctic Peninsula shows a decreasing trend (−0.33°C year−1) between 2008 and 2014 [-1.98°C].”
Vignon et al., 2018  (Antarctica)
“The near‐surface Antarctic atmosphere experienced significant changes during the last decades (Steig et al., 2009; Turner et al., 2006). In particular, the near‐surface air over the Western part of Antarctica exhibits one of the major warming over the globe (Bromwich et al., 2013a), with heating rates larger than 0.5 K per decade at some places. Despite a significant warming in the end of the 20th century, the Antarctic Peninsula has been slightly cooling since 1998, reflecting the high natural variability of the climate in this region (Turner et al., 2016). East Antarctica has experienced a slight cooling trend (Nicolas & Bromwich, 2014; Smith & Polvani, 2017) particularly marked during autumn.”
Lei et al.,2018 (N, NE, SE China)
“The authors analyzed the observed winter surface air temperature in eastern mainland China during the recent global warming hiatus period through 1998-2013. The results suggest a substantial cooling trend of about -1.0°/decade in Eastern China, Northeast China and Southeast China.”
Share this...FacebookTwitter "
"British dairy farmers are once again protesting over the low prices on offer for their milk. They worry that too many producers are going bust, and that long-term milk supplies are at risk. Supermarkets are usually cast as the villains in this piece and this time it is no different. Farming unions are meeting Morrisons to ask for a fairer deal – and protesters in Stafford even took two cows into an Asda branch to help make their point. However it is too simplistic to blame the supermarkets – the real problem is global. Too much low-value milk is being produced around the world. Over the past decade, UK milk production averaged 14 billion litres per year, of which around 500m litres are exported. Just 139m litres are imported. Milk made in the UK tends to stay in the UK.  Nonetheless the number of dairy farmers continues to decline, from 40,000 at the start of the 1990s to 14,159 in 2013. This is alarming to some, but it shouldn’t be. For long-term security of milk supplies, it doesn’t really matter how many dairy farmers pack up production. The cows often move to another farm and it is easy enough to step up production through more intensive feeding and selective breeding. After all, even though the total number of cows in the UK has halved since the 1970s, production has remained steady thanks to the fact average yields have doubled. Farmers are literally squeezing more out of each cow.  Half of domestic milk production has to be diverted from the more lucrative liquid market into cheese, yoghurt, ice cream, butter and other manufactured products.  This is partly because people drink a lot less milk these days; from five pints per week in the 1960s to around three pints today. Consumption is down 8.1% in the past ten years alone. Any industry would struggle in such circumstances. This supply and demand problem is replicated across the world – and there is currently a massive oversupply of manufactured milk products on world markets due largely to increased production in China, India, Brazil and New Zealand (where they are dealing with similar issues). This surplus, combined with a collapse in global demand especially in China, has depressed prices. A Russian import ban in retaliation for EU action over Ukraine has also hit prices. Russia used to buy 27% of the EU’s cheese exports and 19% of its butter. The Global Dairy Trade auction, the industry’s main dairy commodities index, hit a 13-year low in August 2015. The GDT has now lost 64% of its value since a record high in February 2014.  The amount paid to farmers – the UK’s farm gate price – has declined sharply since early 2014 to just 23.66p per litre. When it costs farmers around 30p to produce each litre, it’s easy to see why they are annoyed. The major milk processors have to balance their operations across the various markets they sell in and, as a consequence, pay dairy farmers an average price. Farmers will not get, and should not expect to get, the supermarket price for liquid milk. Some supermarkets – Tesco, Marks & Spencer, Sainsbury’s and Waitrose – have agreed direct contracts with dairy farmers that allow them to recover their production costs, but these only involve a small number of farms. Retail supermarket prices for liquid milk are much higher than farm gate, at typically 55-60p per pint (£1.30 or so per litre), but there is no evidence that milk is being used as a “loss leader”. Four pints for 89p at Asda is probably as low as they can get, but the price spread is understandable, appropriate and market-justified; we can’t just hold supermarkets alone responsible. If there is a villain in this piece, it is the world market. With too much supply and not enough demand, farmers have two options. Those near big cities can opt out of the globalised milk market through establishing farmer co-operatives to supply just the local area where they can possibly charge higher prices. Or they can seek high-value, niche markets such as yoghurts, farm-produced ice cream and organic milk. One other way of dealing with supply-demand imbalances would be to bring back dairy quotas, at least at lower levels. The EU introduced quotas in 1984 to control milk production and eradicate butter mountains but they were abolished in April this year.  The problem currently facing the British dairy industry is that it is easy to produce milk in the UK’s green, wet and pleasant land, but it is very difficult to find profitable markets for 14 billion litres of the stuff. Until dairy farmers resolve this overproduction dilemma, many will continue to go out of business.  Uneconomic dairy farms, like uneconomic coal mines, must close down and the adjustment process is harsh and painful for farmers and miners alike. In today’s highly globalised world a more humane outcome is unlikely."
"Wouldn’t it be great if scientists could make their minds up? One minute they’re telling us our planet is warming up due to human activity and we run the risk of potentially devastating environmental change.  Next, they’re warning that the Earth is heading for a mini ice age in the next 15 years. The latter headline has its roots in a recent press release from the UK’s National Astronomy Meeting that reported on a study suggesting the sun is heading towards a period of very low output.   Fluctuations in solar activity are not a new discovery. The 11-year variation in the number of dark sunspots on the solar surface was discovered more than 150 years ago. We now understand that these spots are symptoms of increased magnetic activity and occur during periods when explosive outbursts of energy and material such as solar flares and coronal mass ejections are more frequent. The scientists behind the new research have modelled the rhythmic variations in solar activity over recent decades and predict that a deep low is due between 2030 and 2040.  Specifically, the press release suggests that this dip in activity could mark a return to quiet solar conditions not seen for more than 350 years. How is this astronomy story related to an impending ice age? The period of low solar activity in the 17th century, known as the Maunder minimum, lasted about 70 years and roughly coincided with the “Little Ice Age”, a era characterised by an abnormally high number of harsh winters across the UK and Europe.  As almost all newspaper stories have reported, during several particularly cold winters the Thames froze, enabling frost fairs to be held on the ice. Given the apparently strong link between low solar activity and the Little Ice Age reported in the press, it’s understandable that the prospect of a return to Maunder minimum conditions has stimulated a lot of interest.   If this link between variations in solar activity and changes in the Earth’s climate seems obvious, that’s because it is. When the amount of energy emitted by the sun changes, it has an affect on our climate.   But the real issue is just how strong this influence is compared to other factors. The total solar irradiance, a measure of the power produced by the sun in the form of electromagnetic radiation, varies by only about 0.1% over the course of the 11-year solar cycle. Climate scientists have understood this effect for some time and it is already built into the computer models that are used to try and forecast our climate. But there are still some uncertainties. Changes in the ultraviolet portion of the Sun’s output over a solar cycle can be much greater and can deposit energy in the stratosphere – at altitudes above 10km. How this energy influences our weather and climate in the lower atmosphere is still not clear, but there is growing evidence that during periods of low solar activity, atmospheric “blocking” events are more prevalent. These blocking episodes comprise extensive and almost stationary anti-cyclones in the eastern Atlantic that can last for several weeks, hindering the flow of the jet stream and leading to colder winters in the UK and Europe. The good news is that if the sun is heading towards Maunder minimum conditions, the likelihood of which varies greatly in different studies, then a new ice age is not inevitable. During the Little Ice Age, the atmospheric blocking effect probably played a role, but so did increased global volcanic activity that ejected gas and ash in the atmosphere, reflecting solar radiation back into space.   So we have to be careful associating the Maunder minimum with the Little Ice Age. A look at the data shows that the Little Ice Age began a long time (certainly more than a century) before the start of the Maunder minimum – and continued long after it ended. In any case, the Little Ice Age wasn’t really an ice age. Although cold winters in Europe were unusually common, it doesn’t seem to have been a global phenomenon. Research suggests it was a regional phenomenon and that the colder winters in Europe would have been accompanied by warmer ones elsewhere. So what about global climate change?  If solar activity is falling, and that has a cooling influence over the UK and Europe, isn’t that a good thing? Unfortunately not. The overwhelming consensus among the world’s climate scientists is that the influence of solar variability on the climate is dwarfed by the impact of increased levels of carbon dioxide in the atmosphere.  Most calculations suggest that a new “grand solar minimum” in activity would have a cooling effect that would temporarily offset just a few year’s worth of the warming due to the emission of carbon dioxide by humans. We may well be heading towards a period of low solar activity, but a new mini ice age seems very unlikely at this point."
"
Share this...FacebookTwitterUsing a comparison, Japanese skeptic blogger Kirye at KiryeNet drives home how “the real Arctic sea ice volume is much higher than in 2008.”

Source of images: DMI: http://ocean.dmi.dk
Using images and data from the Danish Meteorological Institute (DMI), Kirye put together and posted a comparator showing the immense March/early April sea ice volume increase the Arctic has seen since 2008. It totally defies the panicky claims of a “melting” Arctic, she tweeted.
You can see the animation comparator Kirye put together in action here at Twitter.

Arctic sea ice volume surges a whopping 3000 cubic kilometers since March 1st. Chart: DMI.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Kirye comments that although we have not once seen alarmists’ climate predictions come true, they continue to threaten us with sea ice doom.
Amid rapidly growing Arctic sea ice volume, they continue to cling to the claim it’s melting. That’s irrational.
Media hyperbole
Yesterday Anthony Watts posted here on the Arctic, remarking that the media claims of earlier this year of an unprecedented Arctic warmth had much more to do with hyperbole than with reality. Lately the Arctic has been a generous source of fake news from the global mainstream media giants, all claiming something that is not real, or making something that’s happened many times before look “unprecedented”.
Warm 12°C temperature spikes more than 70 times!
Back in January, 2016, I wrote here how “the Washington Post screamed bloody murder that the North Pole was in meltdown as temperatures at that singular location rose some “50 degrees above normal”, making it sound like this event had been an unprecedented phenomenon.
For that post I had gone back and examined DMI data Arctic temperatures above 80°N latitude going back some 58 years. Here’s what I found:
And examining all the years since 1958 we see that a temperature spike of some 12°K or more in a matter of a few days (during the November to March deep winter period) occurred more than 70 times! And over 100 times for spikes of 10°K and more.”
Once again, hat-tip: KiyreNet.
Share this...FacebookTwitter "
"Russell Crowe and Cate Blanchett have used their Golden Globes speeches to highlight Australia’s bushfire crisis, and the link between climate change and worsening bushfires. The unprecedented fire season has so far burned through 8.4 million hectares across Australia, destroyed thousands of homes and killed 23 people. On Sunday night, Australian actors thanked volunteer firefighters and drew attention to the “climate disaster” that has made the country’s fire season longer and more intense. Crowe won best actor in a limited series or motion picture made for TV for his performance as Roger Ailes in The Loudest Voice. But the Australian actor, whose home in Nana Glen in New South Wales was hit by fires in November, did not attend the ceremony because he was with his family preparing for the latest bushfires. Actor Jennifer Aniston, who was presenting the award, read out Crowe’s statement on his behalf. “Make no mistake the tragedy unfolding in Australia is climate-change based,” Crowe said. “We need to act based on science, move our global workforce to renewable energy and respect our planet for the unique and amazing place it is.” Blanchett, who was presenting an award, used her speech to give thanks to volunteer firefighters, and draw attention to the global “climate disaster”. “There are a lot of Australians in the room tonight,” she said. “I know we are all very grateful for the call-outs to our fellow compatriots who are suffering under the bushfires, so thank you. “I wanted to do a special call-out to the volunteer firefighters who have been at the centre of battling the climate disaster that is facing Australia. “And of course, when one country faces a climate disaster, we all face a climate disaster, so we’re in it together, so thank you very much.” ""I want to do a special callout to the volunteer firefighters who have been at the centre of battling the climate disaster in Australia. And of course when one country faces a climate disaster we all face a climate disaster. We're in it together."" #GoldenGlobes pic.twitter.com/uiumjV4XpT Other actors and presenters, including Patricia Arquette, Phoebe Waller-Bridge and Ellen DeGeneres, also spoke about the Australian bushfires, and urged viewers to donate. Arquette won best supporting actress in a series, limited series or TV movie for her role in Hulu series The Act. “I am so happy to be here and celebrate this, but also I know that … we see a country on the brink of war, the United States of America … and the continent of Australia on fire,” she said. “While I love my kids so much, I beg of us all to give them a better world. For our kids and their kids, we have to vote in 2020 and beg and plead for everyone we know to vote in 2020.” Before the ceremony, fellow Australians Margot Robbie and Nicole Kidman also used social media to encourage people to donate to Australian firefighters.  @redcrossau @wireswildliferescue @salvosau @nswrfs @cfavic A post shared by @ margotrobbie on Jan 5, 2020 at 1:08pm PST  Our family’s support, thoughts and prayers are with everyone affected by the fires all over Australia. We are donating $500,000 to the Rural Fire Services who are all doing and giving so much right now. A post shared by  Nicole Kidman (@nicolekidman) on Jan 4, 2020 at 3:10pm PST"
nan
"Rabbi Dr Barbara Borts calls Paul the Apostle “a troublesome character” (Letters, 28 December). He was a man of his time, but before you write him off read chapter 13 of his first letter to Corinthians. He says, among other things: “Love is patient; love is kind; love is not envious or boastful or arrogant or rude. It does not insist on its own way; it is not irritable or resentful; it does not rejoice in wrongdoing, but rejoices in the truth. It bears all things, hopes all things, endures all things … Pursue love.”Val SpougeBraintree, Essex • Your editorial (3 January) rightly lambasts the Australian government for its attitude to climate change but on the back page of the same edition you print a full-page advert for high-carbon budget airfares under the banner “The world has never been closer”. Substitute “closer” with “hotter” and we might have the truth of it. Tutting on the sidelines is no longer good enough. The Guardian is in the game too and needs to up it.Richard HawksworthHorwich, Bolton  • Cherry Weston (Letters, 27 December) gets to the heart of Labour’s communications crisis. The time-tested answer is few syllables and even fewer words: Keep it simple, stupid.Val SeddonYork • I don’t know whether flowering daffodils in Stoke Gabriel is a record (Letters, 3 January), but I think that hot cross buns on sale on 26 December in Epsom may be.Jane GarrattEpsom, Surrey • I haven’t seen any daffodils yet but my climbing rose has been flowering since the end of December and I live in Yorkshire.Pam WellsAddingham, West Yorkshire • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"
Share this...FacebookTwitterA few days ago I posted on how brutal cold and snow were gripping the northern hemisphere from every direction. Prominently featured was the western Pacific country of Japan.
“Amazingly cold”
Not only had it been cold and brutal in January, but the story was the same already back in mid December as well, as Japanese skeptic blogger Kirye here tweeted:

Image cropped from Twitter
On December 10th, the Japanese blogger tweeted here:
This year early December in Japan amazingly cold throughout the country. In particular, the daily mean temperature in Sapporo city has been well below 1981-2010 average.”
Coldest October in 46 years
Already back in October Kirye had been tweeting of Japan getting started on the very cold side as she noted how Tokyo had seen its coldest October in almost 50 years:
October 2017 in Tokyo the mean monthly temperature was 16.8℃, the coldest October since 1971.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In fact the cold in Japan started even well before October, 2017. Already in September Japan had had a colder than normal month when Kirye informed me that “Japan’s temperature anomaly for September, 2017, was -0.22C,” and then added she expected the coming winter to be “very interesting”.
And interesting it’s been.
Unusual cold and snow persisting in February 
And now that we find ourselves well into February, there are still no signs of the brutal winter conditions letting up in Japan, let alone of the famous cherry blossoms making their debut any time soon.
According to the English language Asahi Shimbun here on February 8, seven people had been killed and public roads and services had been crippled “as record snowfall kept traffic at a standstill across much of the Hokuriku region of northwestern Japan.”
The Asahi Shimbun added:
Authorities said that 1,400 or vehicles got stuck from Feb. 6, creating a line that stretched about 20 kilometers.”
At her blogsite, Kirye reports here that so far this year 59 stations (out of 928 stations) in Japan marked an all-time temperature low in 2018. In Ohtake in Hokkaido Prefecture, for example, the mercury plummeted to – 24.9°C.
The Mainichi here reported of “cold air” and “heavy snow” along the Sea of Japan coast and added: “The city of Fukui in the region had over 130 centimeters of snow for the first time in 37 years.”
Share this...FacebookTwitter "
"What if there were a way to suck carbon dioxide right out of the air and turn it into useful products? It might seem fantastic but scientists have actually proved it’s possible. One of the challenges with making it a viable process, however, is manufacturing products that are valuable enough to cover the high costs of extracting the carbon dioxide. Some excellent new research has raised the possibility of a breakthrough in this area by using CO2 directly captured from the air to produce a type of graphene, the two-dimensional form of carbon often described as a “wonder material”. But reported claims that this amounts to producing “diamonds from the sky” are somewhat misleading. There is already a significant market for CO2 and products made from it, most obviously fertiliser and fuels. This process of treating the gas as a feedstock rather than a waste product is known as carbon dioxide utilisation (CDU) and usually starts by capturing CO2 from industrial flue gases – exhaust from furnaces or fuel-powered generators. In 2012, carbon dioxide utilisation accounted for 180 megatonnes of CO2 that would otherwise have gone into the atmosphere, and this has been forecast to rise to 256 megatonnes in 2016. But total global greenhouse gas emissions are around 35 gigatonnes and rising, meaning other emission-reduction strategies such as energy efficiency and renewable power currently play a much larger role. Sucking CO2 directly from the air can be a trickier process compared to more concentrated sources such as flue gases. As CO2 represents just 0.04% of the atmosphere, you have to treat very large amounts of air just to produce even modest quantities of the gas. However, several companies have managed to design chemical processes that are more efficient than those used in flue gas capture and produce enough industrial CO2 to be economically viable. The new research from George Washington University in the US demonstrates a way to directly capture CO2 from the air and turn it into carbon nanofibres, powered just by a few volts of solar electricity and solar heat. These smaller-than-microscopic structures are effectively irregular cylinders made from layers of graphene and can be used to strengthen materials for building aircraft, wind turbines and even sports equipment. The researchers claim their new manufacturing method is much cheaper than existing techniques and so could open up new uses for the nanofibres. If they can scale the process up to the level of mass production and keep it cost-effective, this would really help grow the market. But a robust life-cycle analysis is needed to substantiate these claims. If the technique does prove to be a cheap way of mass-producing carbon nanofibres, could it become so widely used that it significantly reduces atmospheric CO2 levels, a claim attributed to the authors (but not in the peer-reviewed paper)? Current production of carbon nanofibres is around 500 tonnes a year and predicted to increase to around 10,000 tonnes a year. But this is still far from the hundreds of millions of tonnes that would be needed to make a meaningful contribution to greenhouse gas levels. It is difficult to see at this time how a market for carbon nanofibres could develop to these levels. One exception might be if the price of nanofibres became so low we could start using it to cost-effectively strengthen building materials. This would also provide an interesting addition to current techniques that turn CO2 and other chemicals and waste products into stable solids. Developing viable direct air capture techniques is a major research challenge that will hopefully one day have far-reaching impact. It could help make CO2 a resource that is available anywhere in the world where a capture unit can be installed. Carbon nanofibres will play a part in the portfolio of technologies that make up carbon dioxide utilisation, again an area that is growing in application and promise. Sadly it’s most unlikely this interesting breakthrough will be scaled up to limit climate change in the way that has been claimed. We believe that due to the size of the potential market, carbon nanofibres alone will not be able to make a significant impact on CO2 mitigation. However, many transformative technologies and materials start with a niche area before moving into more mainstream uses. And perhaps this could be the case for direct air capture nanofibres. After all, change has to start somewhere."
"In a year when the all-important UN climate change summit  will take place in Paris and the UN’s sustainable development goals will be finalised, one would have thought the government of one of the world’s most powerful nations might seize the moment to put forward progressive environmental policies. Unfortunately the summer budget introduced by UK chancellor, George Osborne,  has failed to do just that. Nothing announced this week will put the UK into a leadership position at the negotiations later this year – and it becomes increasingly clear things will not change for the next five years of Conservative government. It’s hard to remember now but the beginning of David Cameron’s Tory leadership was marked by an increasing sense of urgency over environmental issues. He visited Arctic glaciers to see the effects of climate change – and famously hugged the local huskies. On taking office he pronounced the coalition would be “the greenest government ever”. But the new, fully Conservative, government has signalled a rollback of green policies. In his summer budget, Osborne promised continued tax breaks and subsidies for North Sea oil and gas – which, understandably, delights the industry. This comes on top of vast existing direct or hidden subsidies to the UK fossil fuel industry which in 2012/13 amounted to almost £2 billion, according to a Friends of the Earth study. Osborne’s budget continued the onslaught on renewable energy, as he announced the removal of the climate change levy (CCL) exemption for renewables, which might cost the green energy industry up to £1 billion by 2020/21. This comes after the Queen’s Speech announcement to end subsidies for onshore wind projects. Not to forget the chancellor’s new commitment to road building, financed by a new system of green car taxes. New roads will not help reduce the significant share  of the UK’s private transport system in carbon emissions and will increase the pressure on UK cities’ air quality, which is among the worst in Europe. The government has also ditched its pledge to ensure all new homes were zero carbon. In a year when climate change should be on top of the political agenda these policy U-turns are, at best, counter-productive. At worst, making fossil fuels more competitive is nothing but reckless and extremely shortsighted. The chancellor is clearly responding to conservative forces in his party who have called for the removal of green subsidies for a long time. But he’s also listening hard to the needs of oil and gas majors such as Shell and BP which have far more access to Whitehall  than the renewable energy industry. It is not that George Osborne and David Cameron are climate change deniers. Far from it. Along with the big fossil fuel companies – even ExxonMobil – they know about the risks climate change poses to economies and the entire planet. But what the big oil and gas majors are extremely good at is lobbying to keep the existing fossil fuel-driven status quo in place for as long as possible. Shell plans to still expand fossil fuel production until at least 2050 . The G7 doesn’t want to phase out fossil fuels until 2100 . Every sensible climate scientist knows that these are unsustainable projections, posing a real risk to the planet’s biosphere. Yet, at the same time, most major fossil fuel companies have already factored in some form of carbon tax, as ExxonMobil recently admitted. On the one hand it seems oil and gas majors want to prolong the good times (and big profits) they’ve enjoyed. On the other hand, they know perfectly well that this cannot go on forever (and have taken measures accordingly). What’s missing is political leadership. While – back in 2010 – Cameron made political hay out of his commitment to “green up” his government, the first Conservative budget for almost 20 years signals a return to the unsustainable ways of the past. The UK’s environmental and other progressive forces need to unite to pressure the government to honour its legal climate change commitments and follow the Pope’s moral leadership in tackling the big environmental and social issues of our time."
"
Share this...FacebookTwitterA new research institute in Switzerland set to rock the climate science boat…will investigate natural causes of climate change. Director calls claims CO2 the main driver and a pollutant “absurd”.

Swiss institute director and climate scientist Hans-Joachim Dammschneider says natural factors in large part behind recent climate change. Photo credit: IFHGK
The Swiss Basler Zeitung (BZ) reported on April 13, 2018, that a new research institute opened at Lake Aegeri in Switzerland last year: the Institute for Hydrography, Geo-ecology and Climate Sciences (IFHGK), which will focus on the natural causes of climate change.
Contrary to the other government-funded institutes, the IFHGK focusses on the natural causes of climate change: the Institute for Geo-ecology and Climate Sciences wishes to show that CO2 is not necessarily the main driver behind global warming and thus goes against the alleged broad consensus among mainstream researchers, the Baseler Zeitung writes.
A real climate scientist
The new institute, founded at the start of 2017, is located in Oberägeri, Switzerland is directed by Hans-Joachim Dammschneider. who according to the BZ explained:
Unlike many others who speak on the subject of global warming, I’m actually a climate scientist.”
The institute consists of scientists who work on a volunteer basis and operates on a shoestring. Decisive in the founding of the institute was Dr. Hans-Joachim Dammschneider’s encounter with Dr. Sebastian Lüning, who together with Prof. Fritz Vahrenholt wrote the Spiegel bestseller “Die kalte Sonne“,  which upset German mainstream climate science. Lüning also runs the Die kalte Sonne climate site, where he posts daily.
Looking at climate science with “calm, common sense and reason”
Dr. Lüning, a geologist, long ago concluded that the mainstream climate scientists have navigated themselves into a dead end. Dammschneider told the BZ that the institute will look at the issues with “calm, common sense and understanding.”
Dammschneider, who considers himself a climate realist, says that it is absurd that CO2 has been designated a pollutant and that the substance is mainly to blame for es climate change. Dr. Dammschneider is a leading German expert in the field of geography, climate research, oceanography and geology.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The BZ reports that already Dammschneider has published some papers in their own publication series and that he specializes in the field of periodic temperatures changes of the oceans, which have a direct impact on the atmosphere. He told the BZ:
The atmospheric temperatures tend to correspond with the oscillations of the oceans and are subject to a comparable pattern.”
Today’s warmth “not unique”
The German-born researcher believes it is essential to record these changes and to see if the climate changes are normal, or if they only have existed since man started burning fossil fuels.
His research and the findings of Sebastian Lüning for the North African region show that during the period of the year 1000 to 1200 A.D. it was similarly as warm as it is today. The BZ writes:
The works of Lüning and his team show that during this period very optimal climate conditions predominated. They also indicate that today’s warm period is not unique.”
The fear to dissent
On the future success of the institute, the BZ writes that Dammschnei­der is aware that it’s going to be a long and difficult road, saying that “young climate scientists as a rule cannot afford to question asserted truths if they do not want to endanger their careers. Thus the new climate science skeptic institute will have to rely on support from independent scientists and retired professors who are free to speak without the fear of harsh consequences.
Funding needed
The BZ writes that the institute is working to gain public attention, but is in need of funding. However: “business sponsors look promising, and so it hopes to employ some workers,” the BZ reports.
Concerning the widespread alarmism over man-made climate change, Dammschneider told the BZ:
Sooner or later they will have to soften the positions they’ve held so far.”
Read the entire story in German at the Basler Zeitung
Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitterA new study shows that the Antarctic Ice Shelf has been thickening – in times of global warming. Logic: Global warming cannot be the driving factor for Antarctic ice shelf mass, let alone CO2.
=====================================
West Antarctic Ice Shelf: El Nino takes, La Nina gives
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P. Gosselin)

Antarctic ice shelf. NASA photo (Chris Larsen) – public domain.
Whenever a chunk of ice breaks off the Antarctic ice shelf, the guilty party is immediately found by the media: man. He did it with his SUVs, his planes and his container ships.
But what makes everything all the more surprising is a recent press release from Scripps Institution of Oceanography from 8 January 2018. Weather phenomenon El Niño is causing the ice shelf in the Amundsen Sea to melt from underneath.
Additional snowfall is unable to compensate for the loss. During a La Niña phase the opposite occurs: The ice sheet grows. It’s natural variability at work. Gradually we are beginning to understand how it works. The press release follows:
New Study Reveals Strong El Niño Events Cause Large Changes in Antarctic Ice Shelves
Oscillations of water temperature in the tropical Pacific Ocean can induce rapid melting of Antarctic ice shelves. A new study published Jan. 8 in the journal Nature Geoscience [Paolo et al. 2018] reveals that strong El Niño events can cause significant ice loss in some Antarctic ice shelves while the opposite may occur during strong La Niña events.
El Niño and La Niña are two distinct phases of the El Niño/Southern Oscillation (ENSO), a naturally occurring phenomenon characterized by how water temperatures in the tropical Pacific periodically oscillate between warmer than average during El Niños and cooler during La Niñas. The research, funded by NASA and the NASA Earth and Space Science Fellowship, provides new insights into how Antarctic ice shelves respond to variability in global ocean and atmospheric conditions.
The study was led by Fernando Paolo while a PhD graduate student and postdoc at Scripps Institution of Oceanography at the University of California San Diego. Paolo is now a postdoctoral scholar at NASA’s Jet Propulsion Laboratory. Paolo and his colleagues, including Scripps glaciologist Helen Fricker, discovered that a strong El Niño event causes ice shelves in the Amundsen Sea sector of West Antarctica to gain mass at the surface and melt from below at the same time, losing up to five times more ice from basal melting than they gain from increased snowfall. The study used satellite observations of the height of the ice shelves from 1994 to 2017.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




‘We’ve described for the first time the effect of El Niño/Southern Oscillation on the West Antarctic ice shelves,’ Paolo said. ‘There have been some idealized studies using models, and even some indirect observations off the ice shelves, suggesting that El Niño might significantly affect some of these shelves, but we had no actual ice-shelf observations. Now we have presented a record of 23 years of satellite data on the West Antarctic ice shelves, confirming not only that ENSO affects them at a yearly basis, but also showing how.’
The opposing effects of El Niño on ice shelves – adding mass from snowfall but taking it away through basal melt – were at first difficult to untangle from the satellite data. ‘The satellites measure the height of the ice shelves, not the mass, and what we saw at first is that during strong El Niños the height of the ice shelves actually increased,’ Paolo said. ‘I was expecting to see an overall reduction in height as a consequence of mass loss, but it turns out that height increases.’
After further analysis of the data, the scientists found that although a strong El Niño changes wind patterns in West Antarctica in a way that promotes flow of warm ocean waters towards the ice shelves to increase melting from below, it also increases snowfall particularly along the Amundsen Sea sector. The team then needed to determine the contribution of the two effects. Is the atmosphere adding more mass than the ocean is taking away or is it the other way around?
‘We found out that the ocean ends up winning in terms of mass. Changes in mass, rather than height, control how the ice shelves and associated glaciers flow into the ocean,’ Paolo said.  While mass loss by basal melting exceeds mass gain from snowfall during strong El Niño events, the opposite appears to be true during La Niña events. Over the entire 23-year observation period, the ice shelves in the Amundsen Sea sector of Antarctica had their height reduced by 20 centimeters (8 inches) a year, for a total of 5 meters (16 feet), mostly due to ocean melting. The intense 1997-98 El Niño increased the height of these ice shelves by more than 25 centimeters (10 inches). However, the much lighter snow contains far less water than solid ice does. When the researchers took density of snow into account, they found that ice shelves lost about five times more ice by submarine melting than they gained from new surface snowpack.
‘Many people look at this ice-shelf data and will fit a straight line to the data, but we’re looking at all the wiggles that go into that linear fit, and trying to understand the processes causing them,’ said Fricker, who was Paolo’s PhD adviser at the time the study was conceived. ‘These longer satellite records are allowing us to study processes that are driving changes in the ice shelves, improving our understanding on how the grounded ice will change,’ Fricker said.
‘The ice shelf response to ENSO climate variability can be used as a guide to how longer-term changes in global climate might affect ice shelves around Antarctica,’  said co-author Laurie Padman, an oceanographer with Earth & Space Research, a nonprofit research company based in Seattle. ‘The new data set will allow us to check if our ocean models can correctly represent changes in the flow of warm water under ice shelves,’ he added. Melting of the ice shelves doesn’t directly affect sea level rise, because they’re already floating. What matters for sea-level rise is the addition of ice from land into the ocean, however it’s the ice shelves that hold off the flow of grounded ice toward the ocean. Understanding what’s causing the changes in the ice shelves ‘puts us a little bit closer to knowing what’s going to happen to the grounded ice, which is what will ultimately affect sea-level rise,’ Fricker said. ‘The holy grail of all of this work is improving sea-level rise projections,’ she added.”
Meanwhile the Potsdam Institute (PIK) continues to work from the alarmism playbook.
Surprisingly there is also a finding from the Ross ice shelf. There researchers carried out a bore sample through the ice. Amazingly the ice  appears to be growing instead of melting for the time being. National Geographic reports on the unexpected result:
Deep Bore Into Antarctica Finds Freezing Ice, Not Melting as Expected
[…] The surprises began almost as soon as a camera was lowered into the first borehole, around December 1. The undersides of ice shelves are usually smooth due to gradual melting. But as the camera passed through the bottom of the hole, it showed the underside of the ice adorned with a glittering layer of flat ice crystals—like a jumble of snowflakes—evidence that in this particular place, sea water is actually freezing onto the base of the ice instead of melting it.”
Read the entire article at National Geographic.
Share this...FacebookTwitter "
"The US Clean Power Plan puts a national limit on greenhouse gas emissions for the first time. Despite a few critics, environmentalists have on the whole reacted positively. Yet, as societies around the world are already struggling with the effects of climate change, is Obama’s plan ambitious enough? As he acknowledged himself, “there is such a thing as being too late when it comes to climate change”. We suggest precisely that: his plan is too little, given that it has arrived so late. The Clean Power Plan aims for a reduction in greenhouse gas emissions associated with coal, oil, and gas-fired power plants by 32% below 2005 levels by 2030. It focuses on the electricity sector, which is a good thing. Electricity generation from fossil fuels is the largest single industrial source  of CO2 emissions and 31% of the US total. The plan gives US states a flexible deadline of September 2016 to submit plans for emissions reduction. They must comply by 2022. States have a few different policy options: Yet, if they do not draw up a plan for reducing emissions, the EPA will impose emissions trading by default. As with any climate policy, the ambition of an instrument must be judged in terms of the detail and much of that will depend on how the states react. At this point, we take issue with two aspects of the scheme: first, the ambition of the emissions target and industrial coverage; and second, the potential loophole that emissions trading will create. Obama is right to start with the emissions-intensive electricity sector. However, we should remember that energy exports, transport, agriculture, mining and industrial emissions are outside the scope of the scheme. This is a common problem in climate policy. All too often, major “national” economic drivers of greenhouse emissions do not fall into the scope of federal climate policy. For instance in Australia, the booming energy export market has contributed to a major increase in global greenhouse emissions, but only the “fugitive” emissions associated with mining were regulated under the former carbon trading scheme. Then there is the 2005 baseline the US has chosen, while the Kyoto Protocol established a baseline of 1990. Why? Because from 2005 on the US has experienced a shale gas “revolution”, which crowded dirty coal out of the energy market and reduced emissions. While the Clean Power Plan is clearly a step in the right direction, it is a case of too little given the world’s largest economy is acting so late. We need much more ambitious action from the US and other like nations, if we want to have a realistic chance of staying within the globally agreed 2°C, or better 1.5°C of “safe” global warming. The Clean Power Plan is likely to become a patchwork of emissions trading schemes, something not emphasised in the initial proposals. However, the EPA’s January proposal  and the final rule single out emissions trading as a preferred policy option. If a state does not deliver a plan for emissions reduction, then a federal cap-and-trade program becomes the default policy. States are also able to link to existing state-level emissions trading programs, the California cap-and-trade scheme and the Regional Greenhouse Gas Initiative. How this is managed has been a subject of debate, particularly regarding carbon offsets. Thankfully, the use of “carbon offset” credits from sectors outside the electricity sector for compliance purposes is not likely to be possible. The use of carbon offsets would not qualify under the EPA’s definition of the “best system of emissions reduction” for purposes of the Clean Air Act section 111(d) (see Section V pp. 517-520 of the rule). States which include trading schemes like the California cap-and-trade scheme which relies on forest carbon offsets to a significant degree will have to demonstrate that emissions reductions have occurred in the power sector. Some states and carbon trading advocates have been unhappy that carbon offsets cannot be used. It is for the best they have not been successful in the call for “flexibility” through offsetting. The introduction of carbon-offset credits in the Clean Power Plan would have made it similar to the Australian Direct Action Plan. In the Australian scheme, the “safeguard mechanism” to keep emissions to a minimum seems likely to be turned effectively into a baseline-and-credit carbon trading scheme. This means any kind of “cap” the safeguard mechanism could impose on the most heavy emitters will be undermined. While the US Clean Power Plan is an improvement on the Australian situation, we remain concerned about the direction of US climate policy, particularly the likelihood a jumble of emissions trading schemes will be created. In our recent published research, we find carbon trading lacking on a number of counts. There have been numerous problems with carbon trading, including ineffectiveness, weak regulation and implementation, instances of fraud, little or no emissions reduction and major legitimacy issues for governments and the private sector. The Clean Power Plan design makes a complex set of carbon trading arrangements likely, which may in turn replicate the problems of existing carbon trading schemes across the world. Given the increasingly urgent timeline within which we need to act to radically reduce emissions, the incorporation of carbon trading as an option in the Clean Power Plan is half-baked."
"
Share this...FacebookTwitterNew Paper Spurns Anthropogenic CO2 Warming,
Unveils Natural Explanation For Climate Change

University of California (Santa Cruz) Professor W. Jackson Davis (Ph.D.), President of the Environmental Studies Institute, has published a new paper with colleagues in the journal Climate that thoroughly undermines the conceptualization of a dominant role for anthropogenic CO2 in the global warming since 1850.
Davis points out that CO2 and global temperature have been “decoupled” throughout much of geological history, and that the amplification of CO2 concentrations yields increasingly smaller radiative effects, meaning that the higher the CO2 concentration rises, the weaker its influence.
He even suggests that the reason why the anthropogenic global warming (AGW) hypothesis (it has not reached theoretical status) has been popularized is because there are reputed to be no convincing alternative explanations.
But Davis and two other University of California (SC) scientists have proposed a newly-termed alternative explanation for the 0.8°C global temperature change since 1850.  The Antarctic Centennial Oscillation (ACO) has been identified as varying in sync with solar cycles (orbital), and correlates with glacial-interglacial transitions, the 1,500-year abrupt, global-scale temperature changes (Dansgaard-Oeschger cycles), and, as the name suggests, century-scale fluctuations in global temperature.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Consequently, as the authors conclude, properties of the ACO “can explain the current global warming signal”.

Davis et al., 2018
Introduction:
[T]he contemporary global warming increase of ~0.8 °C recorded since 1850 has been attributed widely to anthropogenic emissions of carbon dioxide (CO2) into the atmosphere. Recent research has shown, however, that the concentration of CO2 in the atmosphere has been decoupled from global temperature for the last 425 million years [Davis, 2017] owing to well-established diminishing returns in marginal radiative forcing (ΔRF) as atmospheric CO2 concentration increases. Marginal forcing of temperature from increasing CO2 emissions declined by half from 1850 to 1980, and by nearly two-thirds from 1850 to 1999 [Davis, 2017]. Changes in atmospheric CO2 therefore affect global temperature weakly at most.
The anthropogenic global warming (AGW) hypothesis has been embraced partly because “…there is no convincing alternative explanation…” [USGCRP, 2017] (p. 12).
The ACO provides a possible alternative explanation in the form of a natural climate cycle that arises in Antarctica, propagates northward to influence global temperature, and peaks on a predictable centennial timetable.
Abstract:
We report a previously-unexplored natural temperature cycle recorded in ice cores from Antarctica—the Antarctic Centennial Oscillation (ACO)—that has oscillated for at least the last 226 millennia. Here we document the properties of the ACO and provide an initial assessment of its role in global climate. We analyzed open-source databases of stable isotopes of oxygen and hydrogen as proxies for paleo-temperatures. We find that centennial-scale spectral peaks from temperature-proxy records at Vostok over the last 10,000 years occur at the same frequencies (±2.4%) in three other paleoclimate records from drill sites distributed widely across the East Antarctic Plateau (EAP), and >98% of individual ACOs evaluated at Vostok match 1:1 with homologous cycles at the other three EAP drill sites and conversely.
The period and amplitude of ACOs oscillate in phase with glacial cycles and related surface insolation associated with planetary orbital forces. We conclude that the ACO: encompasses at least the EAP; is the proximate source of D-O oscillations in the Northern Hemisphere; therefore affects global temperature; propagates with increased velocity as temperature increases; doubled in intensity over geologic time; is modulated by global temperature variations associated with planetary orbital cycles; and is the probable paleoclimate precursor of the contemporary Antarctic Oscillation (AAO). Properties of the ACO/AAO are capable of explaining the current global warming signal.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMedia in typhoon-prone Japan ignore new important findings suggesting hurricanes and typhoon intensification speed depends mostly on natural oceanic cycles, and not related to atmospheric CO2. 
Recently I posted on the surprising and science-realistic German DLF national public radio report on how hurricanes are intensifying more quickly today than they did 30 years ago.
Findings by scientists from the US Department of Energy (DOE) and the Pacific Northwest National Laboratory show it all has to do natural oceanic cycles that change every 30 years.

Hurricane intensification speed depends on natural ocean cycles, scientists recently determined. Yet much of the media remained silent over the findings – even cyclone-prone Japan. Photo image: NASA, public domain
Cyclones of great importance for Japan
And now that NTZ is committed to putting some focus on climate news and developments coming from Japan, I naturally wondered how these new, sober findings were received by the media there. After all, Japan is a country that regularly gets hit by typhoons, and so the subject of tropical cyclones and their genesis and future trends ought to be of great public and civic interest. Moreover, better long-term forecasting is crucial and could save lives.
Yet, no real media reporting by Japanese media
So I asked Japanese blogger Kirye of KiryeNet climate blog to do a quick Google search of the Japanese sites for reports on these findings, which she kindly did. Regrettably I’ve got to report that her search did not find a single report from any major Japanese media outlet on these latest findings.
She informed: “There seems to be no link of those articles published in the Japanese version of Google this year.”
Why would the media in a typhoon-prone country like Japan not find the recent finding worthy of reporting? This is somewhat mind-boggling (unless of course the media’s aim there is to just keep its own people in the dark when it comes to climate facts).
Kirye also wrote that the Japanese media generally have remained steadfast in their promotion of climate alarmism, and that skeptics don’t get any coverage in Japan.
Japan typhoons show no link to “global warming”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Not only do the recent DOE findings show that Atlantic hurricane intensification speed depends on natural ocean cycles, and thus these cycles need to be examined in the Pacific as well, but also the climate-science critical Japanese blogger mentioned other good news concerning cyclones earlier at her blog, namely the number of landings in Japan show no link at all to “global warming”.
Citing the Japanese Meteorological Agency, she wrote:
The number of typhoons formed decreased and the number of landings in Japan has been flat since 1951:
And Kirye provided the following chart:









Chart of typhoon non-alarmism. Courtesy of KiryeNet. 
Here she is in fact being somewhat modest because as you will notice the reality is that trend for the number of typhoons forming has been clearly downward, and thus it defies all the earlier predictions of more storms made by the “climate experts”. Things were considerably worse back in the 1960s when the planet was cooler and atmospheric CO2 lower.
In summary it is puzzling that the Japanese media would so recklessly handle the critical topic of typhoons and mislead the public of Japan in the face of glaring facts.
It’s the sort of information management one would come to expect for Japan’s nearby foe, which the world is currently grappling with.
Link to natural cycles provides useful forecasting tool
By having found a strong link between ocean cycles and tropical storm development, a very useful, longer-term forecasting tool emerges – if only it were acknowledged.
Sometimes it takes awhile before truth trumps obstinance.
Share this...FacebookTwitter "
"Flying cars in The Jetsons and Back to the Future, or Star Trek’s spaceships and teleportation, may have captured the imagination decades ago, but most current methods of transport have been around a long time. Railways were being rolled out rapidly from the 1830s, while the commercial breakthroughs in petrol and diesel engines date to 1876 and 1892 respectively. Even the jet engine that made mass aviation possible can be traced back to Frank Whittle’s first patent in 1932. Despite decades of futuristic predictions, modern transport wouldn’t look all that different to someone from the 1950s – certainly not compared to communications or entertainment. So why has there been so little recent innovation in transport? And will the latest batch of proposed driverless cars, levitating trains and electric aircraft actually make a serious breakthrough? In part, there hasn’t been a revolution because existing technologies have been able to evolve. Engines have become more efficient, fuel is higher quality, we have lighter materials, more aerodynamic designs and better brakes that mean vehicles can operate safely closer together. However, eventually there will be a limit to these evolutions. In any event, transport is not just about technology. It is also about people – and people don’t always like change. We may be locked in to current technology, partly due to habit but also due to economics.  We have an extensive transport refuelling system based on petrol and diesel. To convert to electricity or, more fancifully, to hydrogen, will involve substantial re-tooling that will be difficult to finance. In the UK, drivers are used to manual transmissions and may be reluctant to learn how to use more automated systems, just as we would be reluctant to retrain to use a different keyboard even if it were more efficient. We are stuck with what we have – the economics of QWERTY.   Human factors may lead to unintended consequences – one of the ironies of automation is that it can lead to less attention to related tasks. For example adaptive cruise control can make car drivers less aware of hazards. Even with full automation, when we still have trouble making all trains driverless, one might suggest driverless cars are a flight of fancy. Innovative aeroplane designs, such as the blended wing, are stymied by the human requirements for a window seat (NASA has suggested windows could be replaced with real-time video). Fancy new inventions have to be accompanied by a business model and the right infrastructure, or else they’ll just languish as prototypes like the pneumatic transit system demonstrated in New York City in the early 1870s and a forerunner to Elon Musk’s proposed Hyperloop. Take flying cars. Even supposing the technology works, where would they land?  Such a system would only succeed if infrastructure – air traffic control, landing space and so on – was set aside. While flying cars could technically operate from airport to airport, what’s the point? Until there are sufficient numbers to set aside pieces of land or roads for takeoff we won’t achieve any of the benefits. And there won’t be sufficient demand until this land is set aside. Catch 22. When looking at how technology interacts with wider society it’s helpful to think in terms of three different levels: niches, regimes and landscapes.  In transport, there are plenty of niche innovations – battery electric vehicles, hydrogen fuel cells, car clubs – but few become mainstream.  An exception might be hybrid electric vehicles such the Toyota Prius, but even here the underlying technology may be traced back to a patent registered in 1898 (by Ferdinand Porsche, no less).  The problem isn’t coming up with new ideas – it’s changing the bigger picture. At regime level, new transport technologies have faced resistance from vested interests such as oil producers and car makers. And the wider landscape has not always favoured major innovations – especially low oil prices.  With lots of different individual suppliers, transport is also vulnerable to tragedy of the commons-type outcomes and clashes between rival designs and brands. Navigation technologies can only be sold commercially if they benefit the individual consumer. However, if we all have access to such technologies, we can be collectively worse off due to congestion – for the greater good, it would be beneficial if sometimes our SatNav sends us on a longer route, but who is knowingly going to buy something like that?  Electric battery technology might have more rapid adoption if the technology was standardised, permitting automated battery swaps. But standardised to whose technology? Magnetic levitation train adoption is limited by the fact they can’t run on traditional rail lines and have only limited overlap with other maglevs. In short, despite the fuss over disruptive technologies such as Uber, it is unlikely that transport will have a technology paradigm shift until there is a major landscape change. Of course, with volatile oil prices, limited reserves and sensitive geopolitics, such a change could be just round the corner. But for the moment the technology push does not seem to be complemented by a societal pull – people might like to watch sci-fi, but they aren’t yet ready to live it."
"
Share this...FacebookTwitterWe’ve heard about all the cold and icy weather reports and results coming from all corners of the planet lately, and so naturally most of us sense that it just doesn’t jive with all the alarmist global warming claims and rhetoric we hear.
Tremendous ice growth
For example over the past winter the Arctic ice cap did see unusually warm surface temperatures, yet Arctic sea ice did not shrink as some would intuitively expect it to do.
The truth is that Arctic sea ice volume has gained close to 2 trillion cubic meters over last year alone, and over 2016 – using the data provided by the Danish Meteorological Institute here.
Obviously Arctic sea ice has a lot more to do with other factors than just surface air temperatures in the region. Clearly other major factors must be at play in causing this huge increase.
Japanese skeptic blogger Kirye provided at Twitter a nice animation showing the recent development from April 20 – to May 10:

From April 20 to May 10, 2018, Arctic sea ice volume has been greatest in the last four years.ʕ´•ᴥ•`ʔσDMI:https://t.co/UKdL3sM4Y8~#気候変動 #温暖化? #地球温暖化？ #ClimateChange pic.twitter.com/ET2d3PJ5HR
— キリエ (@KiryeNet) May 12, 2018

As one can see, there’s about 2000 cubic kilometers (2 trillion cubic meters) more ice volume than there was a year earlier and in 2016.
Enormous amount of energy
To put this in perspective, 2 trillion cubic meters of ice are enough to…
– Provide every single human being on the planet with 250 tonnes of ice!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




– Cover entire United States with more than 20 cm of solid ice.
– Cover 67,000 Manhattans with almost a meter of ice!
– Circle the earth with 1 cubic meter blocks 50,000 times!
– Stack 1 m³ blocks to make a pile high enough to reach the sun…13 times!
Imagine: 250 tonnes of ice for each and every person. I’d have to run through the numbers, but I don’t think the average person could freeze that amount of water with the total power he/she uses in a year. We’re talking some serious energy here.
So where could all the ice have come from when we consider that the Arctic surface air temperatures have been so warm?
And what about all the heat that had to be extracted from the water to form the ice? Where did it all go? Most of it of course go radiated out into space and so is forever gone and lost.
Surface temperatures not decisive
As discussed above, surface atmospheric temperatures of course do not play the only major role when it comes to the Arctic sea ice show. Obviously other very powerful factors play huge roles, such as natural oceanic cycles and weather patterns over all Arctic atmospheric layers.
Complex, poorly-understood oceanic-atmospheric system
And vice versa, it also implies that these factors also play a role during the summertime when the Arctic sees unusual summer time melt. Surface temperature cannot be the one and only explanation here, as global warming alarmists like to insist it is. Here as well the oceans, winds and clouds, to name a few, play crucial roles.
Polar sea ice depends on the entire oceanic-atmospheric polar “weather” system — from seabed to upper stratosphere — which sober scientists have long realized is an extremely complex one and is still very poorly understood.
===================================
Check out latest on Southern Hemisphere here.
Share this...FacebookTwitter "
"Mediterranean egrets balancing on the backs of cows, multicoloured moths the size of a human hand, and impossibly exotic bee-eaters hawking for insects under English skies. All are here as a direct consequence of the climate crisis, which has allowed continental European species to extend their ranges northwards, and then make the leap across the Channel to gain a foothold in southern Britain. Whenever I take a walk along the disused railway line across the Avalon marshes, near my Somerset home, I can’t help noticing these new arrivals. Tall and elegant, great white egrets first arrived here from France just a few years ago; now I encounter them every time I visit. Down the road, at the Somerset Wildlife Trust’s reserve at Catcott Lows, flocks of cattle egrets – the same species we see in wildlife films from Africa – gather to feed, perched appropriately on the backs of cattle. Elsewhere on the marshes, secretive night herons and little bitterns have also bred in recent years.  When I moved to Somerset with my young family just over a dozen years ago, all these species were so rare they would have attracted a crowd of eager twitchers. Today, everyone – including my own teenagers – takes them for granted. Going back to my own childhood, the now ubiquitous little egret – that Persil-white apparition featuring at a wetland near you – was incredibly scarce. When, at the age of 10, I stumbled across one on Brownsea Island in Dorset, it was the highlight of my birding life for many years afterwards. And it’s not just birds. When it comes to unexpected new arrivals, butterfly and moth enthusiasts have enjoyed a bumper year. First came the news in August that an invasion of long-tailed blue butterflies was occurring all the way along the south coast, from Cornwall to Kent. This unusual looking butterfly – which really does have a tiny “tail” protruding from the back of each wing – was turning up in the most unexpected places: Sussex butterfly expert Neil Hulme even found one laying eggs on pea plants in a pub garden. Thanks to Hulme’s guidance, even I managed to catch up with them, in the equally unlikely setting of a patch of waste ground next to Brighton racecourse. Meanwhile, that group of nocturnal activists known as “moth trappers”, of which I am one, have been attracting some real beauties to their light traps. The greatest prize this summer has been the wonderfully named Clifden nonpareil – literally meaning “beyond compare”. One of our largest and most spectacular moths, with a 12cm wingspan and a bright blue flash on its underwings, it was once considered extinct in Britain. Yet this summer, after an absence of many years, the Clifden nonpareil has been turning up in moth traps all over southern England and Wales. Its day-flying counterpart, the hummingbird hawkmoth, has also had a good year, as has one of our most mysterious and sought-after species, the death’s-head hawkmoth. Made famous – or perhaps that should be infamous – by the novel and film The Silence of the Lambs, several death’s-head caterpillars and pupae have been found in potato patches in the Somerset village of Westbury-sub-Mendip. Brought indoors by local naturalists, they were successfully hatched out, the adult moths revealing the sinister skull pattern on the back of the thorax that gives the species its name. When I went to see this extraordinary insect, it emitted its famous “squeak”, which adds to its terrifying reputation. It’s not just these new arrivals that indicate the effects of climate change – or as we now more correctly call it, the climate emergency. Many resident bird species are rising in numbers; as are short-distance migrants such as the blackcap and chiffchaff. These small, neat warblers are now overwintering in Britain (instead of Spain and north Africa), thanks to milder winters, and the consequent wider availability of their insect food. So, in Voltaire’s ironic comment, all is surely for the best, in the best of all possible worlds. For the moment, that may indeed be true. Yet as long ago as 1990, the German ornithologist and migration expert Peter Berthold warned that during the initial warming period many bird species would benefit from “heavenly conditions”. This, he explained, was a kind of honeymoon period in which warmer springs and summers, and milder winters, would allow them to expand their numbers and range. But if the global climate becomes hotter still, with more frequent and extreme weather events such as droughts, storms and floods, reality will inevitably begin to bite, and all but the most adaptable species will start to decline. Their fall might also be hastened by an increase in populations of parasites and diseases, which flourish in warmer climates. Ironically, the long-tailed blue butterfly I watched sunning itself in August cannot survive Britain’s winters – at least not yet. As Neil Hulme explains, it would need a rise in average temperatures of several degrees, enough to banish winter frosts that kill their larvae, to colonise Britain permanently. But if that did happen, we would have reached a climatic tipping point, and probably lose not just much of our wildlife, but even jeopardise our own long-term existence on the planet. Rapid environmental change is likely to hit some creatures harder than others. On a recent edition of the Radio 4 series The Life Scientific, Professor Anne Magurran of St Andrews University talked about what she calls “the shopping mall effect”. She noted that wherever you go in the world nowadays, from London to Los Angeles, Madrid to Melbourne, shopping centres tend to have the same outlets – well-known international brands whose names we all recognise. Likewise, in response to a panoply of environmental pressures, ecosystems are tending to become more homogenous, with a few highly adaptable species beginning to dominate to the exclusion of less successful ones. As Magurran warns, if environmental conditions become more and more extreme, homogenisation will start to occur, and there will inevitably be species loss. However, as Magurran points out, there is still time for us to take action to help safeguard the earth’s biodiversity. At the moment, she says, the dominant signal is change rather than loss. But unless we take swift and decisive action to mitigate climate change, while at the same time preventing habitat destruction, the rate of extinction will start to accelerate. Given that many governments appear to be heading in the opposite direction, with increased deregulation and a weakening of environmental protection back on the agenda, this is a very real concern. If we fail to act, the consequences for Britain’s wildlife are that successful generalists will do well, while specialists will not. When it comes to making predictions, we also need to take into account the unusual nature of the British Isles, which stretch from Shetland, just a few degrees of latitude short of the Arctic Circle, to Scilly, which has its own – almost subtropical – microclimate. So, while we enjoy the short-term benefits of climate change in the south, problems are already beginning to occur at the other end of Britain. On the Cairngorm plateau, our sole example of the arctic-alpine biome, the ptarmigan – the only British bird that turns white in winter – is gradually declining, with just a few thousand pairs remaining. Until the start of the 19th century, the ptarmigan could be found across a wide swathe of northern Britain, south to the Lake District; but today it survives only in the Highlands. Its decline has been caused by a number of factors, including crows attracted by the rubbish left by visitors, which prey on the ptarmigan’s eggs and chicks. But a more long-term factor is the warming climate, which is altering the habitat and food supply of these highly specialised birds. Should the climate emergency continue to worsen, and temperatures keep rising, the ptarmigan – along with other highland specialists such as the dotterel and snow bunting – looks set to disappear as a British bird in my lifetime. I recall many years ago hearing someone talk about saving the planet “for our children, and our children’s children”. At the time, this felt like an abstract notion; even a rather sanctimonious platitude. Now that I have children and step-grandchildren of my own, who may well live to witness the 22nd century, that phrase feels far more relevant and urgent. If the worst predictions for the climate emergency come true, with devastating consequences for human and animal life on this planet, then I do not envy them living that long. So, much as I enjoy seeing cattle egrets on my local patch, or catching up with a new species of butterfly on the south coast, my pleasure is more than ever tinged with concern. My fear is that these pioneering colonists are not something to be celebrated, but a phenomenon to warn us of impending disaster in this new age of extinction. • Stephen Moss is a naturalist and author based in Somerset, where he is president of the Somerset Wildlife Trust; he also runs an MA in travel and nature writing at Bath Spa University"
"
Share this...FacebookTwitterNew York Times journalist Erica Goode misses a mountain of polar bear research, instead lets herself get swept up by alarmist polar bear activism.
The New York Times recently published an article penned by Erica Goode on the controversial Harvey et al paper, where 14 scientists (sophomorically) attacked polar bear researcher Susan Crockford and climate science skeptics.
If the Harvey publication makes anything clear, it is that its authors are deeply frustrated by the large share of the public who reject their alarmist climate science. But instead of looking at themselves and the mountain of blunders they have made in the past to see what they could improve, the Harvey scientists chose to lash out and blame their woes on mean-spirited “deniers”. The inconvenient reality, however, is that alarmist climate and polar bear science (and journalism) has not been clean, and at times it’s been outright sloppy, deceptive and shrill. That’s the real big reason skeptics have been so successful.
Sloppy biased journalism
So it is no surprise that Erica Goode at the New York Times sided up with the 14 scientists of the Harvey publication to attack the so-called climate “denialists” in her most recent article. Unfortunately Goode made the fatal journalistic error of failing to keep a healthy distance from the alarmist side and as a result was blinded from seeing the glaring mountain of scientific research showing polar bears are in fact doing fine.
As a result Goode’s work couldn’t have been sloppier.
 A mountain of recent scientific publications gets missed
The reality is that there are many polar bear scientists out there who have produced a considerable body of recent scientific findings, which show that the polar bear populations are in reality stable or even thriving. How could Goode have missed it?
Whatever the reasons, it appears to be to a classic case of journalistic negligence.
Had the seasoned New Times journalist done just the minimum of research one expects of even a beginner journalist, she would have discovered, for example, two very recent papers on polar bears published in the journals Ecology and Evolution and Polar Record, and many others. According to expert polar bear scientists (other than Dr. Susan Crockford) there is no evidence to support recent claims polar bears as a species are in grave danger due to climate change and thinning sea ice.
Somehow Goode allowed herself to be talked into the absurd idea that Susan Crockford is the only skeptic polar bear scientist out there, and so did not bother to check for others, so it seems. And the only crises we find are those from dubious computer-modelled 2050 scenarios.
1) York et al 2016
One scientific publication by York et al in 2016 found that given the paleoclimate record of a much warmer (+4 to + 7.5 °C) Arctic, there was much more reduced sea ice thickness and extent in the past relative to today. They concluded: “it seems unlikely that polar bears (as a species) are at risk from anthropogenic global warming.”
The authors wrote in their summary:
Considering both [observations from native populations] and scientific information, we suggest that the current status of Canadian polar bear subpopulations in 2013 was 12 stable/increasing and one declining (Kane Basin).”
We do not find support for the perspective that polar bears within or shared with Canada are currently in any sort of climate crisis.”
Why didn’t Goode contact these scientists and present their results? There are many other scientists who share Crockford’s view.
2) Wong et al 2017
Another published scientific paper by Wong et al., 2017, “Inuit perspectives of polar bear research: lessons for community-based collaborations”, the authors investigated Inuit observations. Here’s an excerpt of their findings:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Wong, a researcher at the Department of Ecology and Evolutionary Biology, University of Toronto, and her team also found in early 80s, and mid 90s: “there were hardly any bears” and “there’s too many polar bears now”.
Also they noted: “Bears foraging for land-based foods have been reported in the literature prior to recent concerns over climate change (Russell 1975; Derocher and others 1993; Gormezano and Rockwell 2013a).” Also: “Observations of bears consuming garbage are not uncommon (Russell 1975; Lunn and Stirling 1985; Gormezano and Rockwell 2013b)”
More fuel for skeptics
One has to wonder if the activist Harvey team of scientists and the New York Times live in an alternative universe. It is precisely that kind of gross omission and one-sidedness that has been fuelling the skeptics over the years.
And there’s much more that they ignored.
Laforest et al., 2018
A publication by Laforest et al titled Traditional Ecological Knowledge of Polar Bears in the Northern Eeyou Marine Region looked at the perception of communities in Quebec on the prevalence of problem polar bears. Results: One-third of participants reported that polar bears will be unaffected by, or even benefit from, longer ice-free periods. A majority of participants indicated that the local polar bear population was stable or increasing.
Moreover they cited the fact that polar bears are capable of hunting seals in open water as a factor contributing to the stable body condition of the bears. and that none of the participants explicitly linked the effects of a warming climate to specific impacts on polar bears.
The publication also states that a recent aerial survey of the Southern Hudson Bay subpopulation found that the abundance of polar bears has remained steady since 1986 (943 bears; SE: 174) (Obbard et al., 2015).
11 more recent papers show bears survive without ice
Not long ago Kenneth Richard reported on almost a dozen papers showing that polar bears easily survived ice-free and far warmer conditions than those seen today or those expected by mid century.
Even more research shows that polar bear population is up 42% since 2004.
Russia “scientists know little or nothing” 
Goode’s non-researched article also mentions that “scientists know little or nothing” about the situation in Russia and other remote areas (and so it’s got to be bad?). If it is unknown, then how can one be either rationally alarmed or relieved about the situation there? Yet, given the positive situation from Canada and Alaska, there is no rational reason to assume all is bad in Russia.
New York Times’ image of bias
So what can we take home from this? Why did Goode ignore so much polar bear research, and why has she unconditionally lapped up everything handed down to her by the alarmist clique? We can only speculate it’s about activism.
Erica Goode and New York Times again shot themselves in the foot on this one and reaffirmed their reputation for bias.
Had Goode resisted getting distracted from the “us” versus “them” narrative and actually dug a little into the actual scientific results –  and the scientists behind them – like honest journalists do, she would not have produced such a piece of journalism.
Share this...FacebookTwitter "
"Australia’s bushfire crisis started much earlier than normal in August 2019, with thousands of fires in Queensland and New South Wales. Despite the evidence a claim persists that a major contributing factor of Australia’s devastating fire season – and the deaths, loss of homes and environmental devastation they have caused – is not climate change but a conspiracy by environmentalists to “lock up” national parks and prevent hazard reduction activities such as prescribed burning and clearing of the forest floor. On Saturday the prime minister, Scott Morrison, said after visiting fire grounds: “The most constant issue that has been raised with me has been the issue of managing fuel loads in national parks.” He claimed that people “who say they are seeking those actions on climate change” could also be the same people who “don’t share the same urgency of dealing with hazard reduction”. Prof David Bowman, the director of the fire centre research hub at the University of Tasmania, said: “It’s ridiculous. To frame this as an issue of hazard reduction in national parks is just lazy political rhetoric.” On Sunday Morrison said he wanted to know “what the contribution of issues” around hazard reduction were, but repeated that it had been an issue raised often with him. He also said “without the planning, without the preparations” of state agencies, “I fear what has really been a terrible tragedy would have been far worse.” Hazard reduction is the management of fuel and can be carried out through prescribed burning, also known as controlled burning, and removing trees and vegetation, both dead and alive. Hazard reduction is carried out by fire authorities, national park staff and individual property owners who can apply for permits to clear areas around their buildings. Coordination of activities happens through local bushfire management committees. There are 120 committees in NSW. The claim of a conspiracy by environmentalists to block hazard reduction activities has been roundly rejected by bushfire experts, and experts say it is betrayed by hard data on actual hazard reduction activities in national parks. Prof Ross Bradstock, the director of the centre for environmental risk management of bushfires at the University of Wollongong, has previously told Guardian Australia: “These are very tired and very old conspiracy theories that get a run after most major fires. They’ve been extensively dealt with in many inquiries.” Former fire chiefs who have been calling strongly for action on climate change, and who have been trying to meet Morrison for months, have also been calling for increased funding for hazard reduction. The Australian Greens say they want “an effective and sustainable strategy for fuel-reduction management that will protect biodiversity and moderate the effects of wildfire for the protection of people and assets, developed in consultation with experts, custodians and land managers”. A federal government factsheet on bushfire management outlines how state agencies and people can carry out a range of hazard reduction activities that have been exempted from national environmental law, even if they “have the potential to have a significant impact on nationally protected matters”. In the last full fire season of 2018 and 2019, the National Parks and Wildlife Service in NSW told Guardian Australia it carried out hazard reduction activities across more than 139,000 hectares, slightly above its target. There are two major restricting factors for carrying out prescribed burning. One is the availability of funds and personnel, and the second is the availability of weather windows. The 2018-19 annual report of the NSW Rural Fire Service says: “The ability of the NSW RFS and partner agencies to complete hazard reduction activities is highly weather dependent, with limited windows of opportunity. Prolonged drought conditions in 2018-19 adversely affected the ability of agencies to complete hazard reduction works.” The RFS said 113,130 properties had been subject to hazard reduction activities, which was 76% of its target. The 199,248ha covered was 106% of its target. A former NSW fire and rescue commissioner, Greg Mullins, has written that the hotter and drier conditions, and the higher fire danger ratings, were preventing agencies from carrying out prescribed burning. But as well as climate change narrowing the window to carry out prescribed burning, Mullins said some fires have become so intense they have burned through areas that had been subject to hazard reduction. Mullins has been fighting fires in NSW for months. Speaking to the ABC on Friday, he said he witnessed a fire in Grafton in an area that had burned only two weeks previously, but “the burnt leaves were burning again”. He said: “There has been lots of hazard reductions done over the years – more by national parks than previous years – but the fires have burned through those hazard reduction areas.” Mullins dismissed suggestions that the bushfires were down to “greenies” preventing hazard reduction activities.“This is the blame game. We’ll blame arsonists, we’ll blame greenies,” he said. “When will the penny drop with this government?” The National Parks Association of NSW’s president, Anne Dickson, has also responded to the attacks on environmentalists. In November 2019, she said: “The increasing intensity and frequency of fire is one of the greatest threats to biodiversity and natural landscapes. It may be politically expedient to pretend that conservationists exercise some mythical power over fire legislation and bushfire management committees, but it is not so. “Such wild and simplistic claims avoid the very real and complex challenges of protecting our communities and the healthy environments that support our quality of life.” Bowman said that separate to the “lazy political rhetoric” of blaming environmentalists, there should be an examination of the benefits and limitations of hazard reduction. But he said there was also a reality to consider: “A lot of people are thinking that hazard reduction burning stops fire. It doesn’t, but what it does do is to try and change its behaviour. “But let’s say you embarked on the biggest fire reduction program the world has ever seen. What’s the budget for that? Who will pay for it. Of course there is a place for hazard reduction but if you have massive increases, where does the money come from? The reality is that you can’t treat everything.” The 2019-20 bushfire crisis coincided with Australia’s hottest year on record. On a state level, NSW easily experienced its hottest year, with temperatures 1.95C above the long-term average, beating the previous record year, 2018, by 0.27C. Climate experts have said not all of that heat came from climate change, as two climate systems were also working to push up temperatures and fire danger. Fire authorities are guided on a daily basis on the risk of fires through the Forest Fire Danger Index, a combined measure of temperature, humidity, wind speed and the availability of dry fuel. Spring 2019 had been the worst year on a record going back to 1950 for bushfire risk. A 2017 study of 67 years of FFDI data found a “clear trend toward more dangerous conditions during spring and summer in southern Australia, including increased frequency and magnitude of extremes, as well as indicating an earlier start to the fire season”. A study of Queensland’s historic 2018 bushfire season found the extreme temperatures that coincided with the fires were four time more likely because of human-caused climate. On Sunday Morrison claimed the government had “always made this connection” between climate change and impacts on Australia’s weather. Advice shared with authorities around the country earlier this year from the National Environmental Science Program said: “These trends are very likely to increase into the future, with climate models showing more dangerous weather conditions for bushfires throughout Australia due to increasing greenhouse gas emissions.” There are also fears that large pulses of carbon dioxide emissions from Australia’s bushfires may not be reabsorbed through regrowth of forests as they have in the past. The fire season has seen several reports of bushfire-generated thunderstorms. Guardian Australia has reported that 2019 would likely be a “stand-out” year for storms known as “pyroCBs” that generate their own lightning and influence the atmosphere at heights of up to 15km. A study in 2019 published in the journal Scientific Reports found that adding more greenhouse gases to the atmosphere would create more dangerous conditions favourable to pyroCB events in the future, particularly for the southern parts of Australia."
"The night of New Year’s Eve was a kind of slow torture. I spent it in Vincentia on the New South Wales south coast, lying with my seven-year-old son, unable to breathe or sleep as thick brown smoke filled the house. As I listened to my child coughing, calling out from the depths of his nightmares words that sounded like “don’t die”, I prayed for the Princes Highway to reopen. I write this not because I believe for one minute that what I went through compares to anything people further south on Australia’s east coast experienced that night, or will this weekend, but because friends and family who live outside the region – whether in Sydney or other, unaffected parts of the country, such as Perth – asked me to. They simply cannot believe it when I tell them what horrors are unfolding down there. There is a way to understand, I tell them – tune into ABC Illawarra local radio. Then you’ll hear about the power outages, the food, fuel and water shortages, the stories of locals bringing water to families with children and babies trapped in cars fleeing Ulladulla and its surrounds, of supermarket staff at Milton guiding shoppers around darkened stores with head torches to find dried food because the refrigerated goods have all spoiled. But in all likelihood they won’t, so let me tell you what it was like, the final day of 2019, for my family. We were at a village on Jervis Bay, where we had planned to see in 2020 with my brother-in-law and his wife. We knew there was fire around but we didn’t understand the threat – who did? Everything changed at precisely 1.57pm, when the NSW Rural Fire Service emergency bushfire warning text message came through on our mobile phones – “people nth of Ulladulla & in Bay & Basin & Nowra areas – seek shelter as fire arrives”. “Where is Bay & Basin?” asked my sister-in-law, who is from Melbourne. “That’s here, where we are,” my husband said. They were at the shops, buying food for our celebration dinner, a meal we never cooked, as the night was spent formulating a fire plan, getting ready to evacuate, via the sea in kayaks if it came to that. It was hard to keep a level head as our hearts raced, our panic escalated, as ash fell, the sky blackened and night fell hours before actual sunset. Local ABC radio was our lifeline – and surely, after this summer, the federal government will increase the ABC’s funding? – and it was how we learnt the fire had reached Sussex Inlet on the southern side of St Georges Basin (12km away), where we heard that power and telecommunications would be lost during the night, that people in Lake Conjola were jumping into the lake to escape raging fires (30km away). What did we do? We gathered up woollen blankets, towels and bottled water and placed them outside on the deck. We assigned lifejackets (we had enough for the women and child). We opened all the gates, pulled out the kayaks. We filled the bath, readied the hoses. We dressed in the most appropriate clothes we had, inadequate though they were. We bought batteries from the service station for the radio and torches (the local Coles closed an hour after the RFS text message came through). We found Ziploc bags for our mobile phones, in case they fell into the sea. My husband and his brother organised shifts to stay awake throughout the night, to monitor the radio and sky either side of the house for the orange glow that we hoped would never come. Our plan, if it did, was to don lifejackets, take the women, child and dogs to the beach, and then the men would come back for the boats. Meanwhile my son clutched his little bag of crystals and two small soft toys. His uncle and aunt tried to distract him with a card game but, by 8pm, he was holding his hands to his ears, begging us to turn off the radio – the emergency warnings were upsetting him so – and that’s when I took him to bed. About 1am the RFS dropped the threat level to our area and, when in the morning the Live Traffic App informed us the road to Sydney had reopened, we threw our things into the car and fled. I feel guilty being so safe in Sydney, while the locals we left behind stay to defend their houses and their lives. Politics has to change forever as a result of this summer because our country has – there is simply no turning back now. We, on Australia’s east coast (and beyond) have seen what the consequences of not acting on climate change look like and it is terrifying. How many people will have died and lost their houses when this immediate crisis has passed? How many farmers will have lost their livelihoods? How many animals will have perished? How many species will have been brought closer to the brink of extinction? How many children will have lost their innocence? I am haunted by Cormac McCarthy’s The Road, a book I read only a year ago, never imagining how soon I would see photos in the Australian media of the post-apocalyptic world he described, of refugees fleeing blackened landscapes, parents leading their children through the smoke, carrying their belongings in their arms, hoping for rescue on military convoys. We have no use for politicians who continue to pursue agendas that ignore the reality of our warming climate, that place our suffering planet in ever-greater jeopardy. It is time for a new generation of leaders to stand up. • Cynthia Banham is a Sydney-based author and journalist"
"
Share this...FacebookTwitterGreen energy opposition becoming formidable force in Germany
As Germany’s established CDU and SPD “mainstream” parties find themselves imploding, the smaller parties who oppose Germany’s out-of-control Energiewende (transition to green energies) are rapidly becoming a formidable force and making their presence felt in Germany’s national parliament like never before.
For example Germany’s FDP Free Democrats, who refused to forge a coalition government together with CDU/CSU and Green parties, have become increasingly vocal critics of Germany’s green energy scheme.
Politicians ignoring the concerns of its citizens
Last month in her first speech ever in the German Parliament, FDP parliamentarian Sandra Weeser slammed the struggling Energiewende and the latest signals to promote it even further.

In her speech Weeser points out that despite the rapidly growing green energy capacity being installed, the effort to reduce CO2 has failed, and what’s left is an unpredictable power grid that often produces energy when it is not needed (waste energy) and thus costing Germans hundreds of millions annually.
She also accuses the established politicians of ignoring citizens as they ruin Germany’s landscape with wind parks.
Interestingly it is often Green party voters who we find themselves among wind park protesters. In their daily lives these people are recognizing that what is being sold as green electricity in fact has nothing to do with being green. They are rejecting the industrial turbines in forests.”
Weeser then tells that the expansion of the green energies is totally out of proportion with the existing power infrastructure, and that even the most perfect grid will not be able to handle the volatile wind and solar energies.
Electricity “outrageously expensive”
Weeser also dismisses claims by the Green Party that wind energy is “the most inexpensive” on the market, asking them directly: “If that is really true, then why do they need subsidies? Why are we paying 25 billion euros annually for their feed-in?”
Green engineering debacle
Finally she mentions that an array of expert panels have determined that wind energy is not leading to more climate protection, but rather is only making electricity outrageously expensive. In her final comment, Weeser says:
Policymakers should set up the framework conditions, but please leave the engineering to engineers.”
Anti-wind/solar energy AfD soars to 15% in polls


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Also Dr. Rainer Kraft of the Germany’s newly minted rightwing AfD party recently demolished the Energiewende in his first speech before Parliament in Berlin:

According to Kraft, the Parliamentary session on renewable energy requested by the Greens is welcome because it exposes their “incapability to comprehend the factual and physical interrelationships” of the subject.
Policy of a fool…eco-socialist economy
Kraft slams the government’s climate-protection approach of spending “15 euros to avoid 1 euro of damage” as apolicy one would expect from “a fool”. Adding: “there just couldn’t be less scientific understanding than that.”
Echoing Donald Trump’s ideas on international treaties, Kraft also sees them as being ruinous to German industry, and that the ultimate target of climate protection is to establish “an eco-socialist centrally-planned economy” and that climate protection is the “instrument” to bring it about.
He then labeled the Greens’ energy policy as “eco-populist voodoo”.
With so much going wrong with the Energiewende, the FDP and AfD today are having an easy time capitalizing politically on the issue and portraying the government and the Greens as inept.
Vocal green energy critics make up 25% of Parliament
According to recent polls, the FDP and AfD now combine to make up a quarter of Germany’s voters. And now that this anti-Energiewende voice is finally being democratically heard in Parliament and viewed by millions on television screens nationally, expect the traditional established parties to continue seeing the unheard of erosion among their disenchanted voter bases. Never has postwar Germany seen a political shift on such a massive scale.
Tipping point
Though 25% may not sound impressive, it is amazing when one considers that only a decade ago there was virtually universal parliamentary support for green energies. Those days are over.
And now as the failure of the Energiewende becomes ever more glaring, reaching the political tipping point on the issue of the Energiewende is just a question of a few more years.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
A new scientific study says surface temperatures in the Northeastern U.S. (Appalachian Mountains) have undergone a significant long-term cooling trend since the early 20th century, complicating the detection of a clear anthropogenic global warming (AGW) signal for the region.
According to Eck (2018), the two coldest Appalachian winters since 1910 were recorded in recent years (2009-’10 and 2010-’11), and 9 of the 10 warmest winters occurred prior to 1960.
In the early 1930s, Appalachian winters were 4.7°C warmer than they have been during the last 30 years (1987-2017).
Several other recently-published papers also reveal a long-term cooling trend not only for the Northeastern U.S. (Eck, 2018), but the Southeastern U.S. (Rogers, 2013; Christy and McNider, 2016), the Central U.S. (Alter et al., 2017), and the Southwestern and Northwestern U.S. (Loisel et al., 2017; Steinman et al., 2016).
In other words, the regions in the continental United States that are less affected by urbanization biases and artificial instrumental heating may not be responding to “global” warming or to the rise in anthropogenic CO2 emissions as climate models have suggested.

Eck, 2018
“[A] majority (12/14) of the regions within the SAM [Southern Appalachian Mountains] have experienced a long-term decline in mean winter temperatures since 1910.   Even after removing the highly anomalous 2009-2010 winter season, which was more than two standard deviations away from the long-term mean, the cooling of mean winter temperatures is still evident.”
“Higher winter temperatures dominated the early 20th century in the SAM [Southern Appalachian Mountains] with nine of the ten warmest winter seasons on record in the region having occurred before 1960.”
“The 1931-1932 winter season, the warmest on record, averaged 8.0°C for DJF [December-February], nearly 4.7°C higher than the 1987-2017 normal mean winter temperature of 3.3°C.”
“Despite the 2016-2017 winter season finishing with the highest mean temperatures (5.7ºC) observed in the SAM [Southern Appalachian Mountains]  since 1956-1957, there have been several years of anomalous negative temperature anomalies, with the 2009-2010 (0.3ºC) and 2010-2011 (1.2ºC) winter seasons finishing as two of the coldest on record for all regions.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->







Central U.S. Cooling (-0.35°C) Since 1910
Alter et al., 2017
“In the central United States … observational data indicate that rainfall increased, surface air temperature decreased, and surface humidity increased during the summer over the course of the 20th century concurrently with increases in both agricultural production and global GHG emissions.”
“From 1910- 1949 (pre-agricultural development, pre-DEV) to 1970-2009 (full agricultural development, full-DEV), the central United States experienced large-scale increases in rainfall of up to 35% and decreases in surface air temperature of up to 1°C during the boreal summer months of July and August … which conflicts with expectations from climate change projections for the end of the 21st century (i.e., warming and decreasing rainfall) (Melillo et al., 2014).”
“Thus, it seems that GHG emissions do not contribute greatly to the regional changes in summer climate that have been observed in the central United States.”


Southeastern U.S. Cooling Since 1890s
Rogers, 2013

Christy and McNider, 2016


Long-Term Cooling Trend In The Western U.S.
Loisel et al., 2017

Steinman et al., 2016

Share this...FacebookTwitter "
"You may have missed it among all the talk of minimum wages and welfare cuts, but as part of its summer budget announcements the UK government also abolished the requirement for new homes to be “zero carbon” from April 2016. A commitment in place since 2006 and supported through successive governments, now thrown into a bonfire of supposed “red tape” holding back new building projects and the productivity of the UK economy. It’s an appalling act of policy vandalism. I heard the news on my way back from a big international conference in Paris on Our Common Future under Climate Change, a prelude to the next round of climate negotiations to take place later this year. Listening to speaker after speaker stressing the urgency of climate action – and the attempts by at least some of those present to be optimistic about what might be agreed – I deluded myself into thinking that maybe the carbon question would now be taken seriously, even in the UK with a government demonstrating at every step its now true-blue ideology.  The zero-carbon homes policy was properly ambitious (at least in its original form). It focused on radically reducing the emissions from housing through a combination of energy-efficient building design and use of low or zero-carbon energy generation, such as solar panels. More recently forms of carbon offsetting were allowed as part of the “zero” calculation so that carbon could be mitigated away from the immediate development site. The Conservative government has now scrapped both this allowable solutions policy and the increase in on-site energy efficiency standards, taking away the foundations of zero-carbon compliance.  The meaning of the “zero” had already been diluted, stripped of any sense of entailing new ways of ongoing low-carbon living – and the closely-related Code for Sustainable Homes had been got rid of. But even so, at least the zero-carbon requirement was still in place in some form.   Not now. Not after nine years of intensive collaborative work by the Zero Carbon Hub, set up after the obligation was first put in place to work out exactly what the zero would mean, how it would be calculated and to provide guidance to housing industry on all sorts of detailed aspects of compliance. This is what makes it policy vandalism and a damaging breach of trust that can only undermine attempts at collaborative initiatives in the future.    It’s not just those trying (increasingly desperately) to make the case for action on climate change that have protested, the British Property Federation, the Chartered Institute of Building the UK Green Building Council and some (but not all) other industry bodies have registered their protest at the loss of a long-term commitment to improving the energy and carbon efficiency of new homes.  The government’s argument is that scrapping the zero-carbon obligation will stimulate house building and help reduce house prices. But the evidence is lacking for both claims, with high house prices in particular far more a function of the dysfunctional way that property markets work in the UK and the lack of a proper regional policy to distribute jobs and growth more evenly across the economy. More fundamentally, a decision that can only serve to increase our carbon emissions projected into the future sends absolutely all the wrong signals, including to those governments in the Global South that quite rightly point out our historic and contemporary responsibility for carbon accumulation.   Maybe house builders will still take up some of the innovation and capacity for building in new low-carbon ways that have been developed over the past nine years. But without the regulatory push it is hard to imagine that things will not level out at a lower standard.  There is now an open invitation to build less carbon-efficient houses, for profit-making at the expense of our deep moral responsibility to act now to mitigate future climate impacts. Yes new homes are needed (in some places), but not at this cost, and not in a way that destroys even the limited sense of what “zero carbon” had become."
"The beach at Muncar on the island of Java was revolting. The 400-yard wide, mile-long stretch of sand was feet deep in foul-smelling sauce sachets, shopping bags, nappies, bottles and bags, plastic clothes and detergent bottles. Bulldozers had cleared away and buried some of the huge mat of plastic and sand two years ago, but every tide since then had washed up more rubbish from the ocean, and every day tonnes more plastic was washed down the rivers from upstream towns and villages. Now it was fouling the fishing boats’ propellers. “We fear for the future,” one elderly woman said. She remembered Muncar only a decade ago as one of the most picturesque towns in Indonesia and a tourist hotspot. “If it carries on like this we will be buried in plastic. We have no choice but to throw plastic into the rivers. Now we are angry. Something must be done,” she said.  That was January 2019. One year later, the beach heaves with plastic but the local government, working with well-funded international advisers, a recycling company and an army of volunteer collectors have worked to stem the tide of plastic reaching its beaches. It will cost millions of dollars and take years but Muncar may soon have its sand back. But this small Indonesian town is the exception. 2019 was, for most of the world, the year the petrochemical industry and giant food, drink and beauty companies locked the world even further into fossil fuels, creating mountains of plastic for communities and future generations to deal with and making it almost too late to keep global temperatures in check. Ultra-cheap shale gas from the decade-long US fracking boom continued to fuel a surge of billion-dollar investments in new cracking plants that separate ethane from gas to produce ethylene, the building block of most plastic. Since 2010 the petrochemical industry has invested about $200bn, and with $100bn more planned to be spent, plastic production is expected to grow 40% by 2030. The implications for countries struggling to cope with climate change and thousands of communities fighting tides of plastic are only now being understood. From having little impact on the climate just 20 years ago, the production and disposal of plastic now uses nearly 14% of all the world’s oil and gas. Plastic production is expected to grow to 20% by 2050 by which time the industry’s climate emissions could rise to 2.75bn tonnes a year and plastic could be driving half of all oil demand growth. Plastic, says the International Energy Agency, could take up to 15% of the remaining annual carbon budget and make the fast-growing industry the equivalent of the world’s fifth largest climate heating country, emitting more than Germany or the UK, twice as much as all African countries and nearly as much as shipping and aviation combined. Even as anger mounted in 2019 against rich countries’ reluctance to act on climate change, it became clear that plastic was big oil’s great hope for expansion, and one of the world’s leading drivers of climate change. Shell’s giant $6bn ethane-cracking plant being built near Pittsburgh, will produce 1.6m tons of plastic a year but is just one of dozens of similar size plants planned for the US, India, China and the Middle East. Despite UN hand-wringing and corporate pledges, demand for plastics grew a further 3.5% in 2019 and up to 16% in much of Asia. Latest figures suggest 359 m tonnes were produced in 2018. Nearly one-third went to single-use packaging and less than 10% was recycled. The rest went to landfills, was burned in incinerators adding to emissions and increasing air pollution, or was left uncollected, with approximately 8m tons making its way to the sea via rivers. But 2019 was also the year the worldwide revolt against plastic pollution translated into political and corporate action; when going plastic-free in Europe became trendy and giant food, drink and health companies were shamed. It was the year governments pledged new laws and when hundreds of potential solutions and initiatives were initiated. Great steps were taken by the public to clean up beaches and seas but in Britain the size of the task was underlined in November when a sperm whale was found on a Scottish beach. An examination of its stomach revealed a 100kg ball of plastic rope, fishing nets, cups, shopping bags, gloves, packing straps, tubing, sachets, bottles and all the waste of the global consumer society. Such beachings were common in 2019, with plastic-filled whales and cetaceans washed up in Wales, the Philippines, Indonesia, Italy and the US. Rattled by public disgust at the sight of choked animals and soiled coastlines, the packaging industry was forced to respond. Food and drink firms including Unilever, Mars, Danone, Pepsico and Coca-Cola pledged to reduce the amount of virgin plastic they used by 2025 and to increase the amount of recycled plastic. The global commitment on plastic, introduced in late 2018 to get corporations to pledge to use less and recycle more, grew to more than 400 of the world’s biggest companies. Together they are responsible for more than 20% of all the plastic packaging produced. The UK supermarkets Tesco, Sainsbury’s, Asda, Morrisons and Waitrose raced to ditch hard-to-recycle “black” plastic from their ranges and to accelerate the amount of recycled material they use. Asda stated that nearly one-third of its plastic packaging would come from recycled sources by the end of 2020 and all should be recyclable by 2025. Waitrose said it had removed 90% of the 2,291 tonnes of black plastic. Some initiatives were eye-catching: Tesco pledged to remove 1bn pieces of plastic from products for sale in UK stores by the end of 2020. Sir David Attenborough detected a cultural change, telling the Glastonbury crowds that the world was changing its habits on plastic. But he may have been wrong. Greenpeace and the Environment Investigations Agency showed that more plastic than ever was put on shop shelves in 2019 and only Waitrose, Tesco and Sainsbury’s of the 10 biggest chains marginally reduced the amounts they used. Plastic water bottle sales, indeed, soared. Academic research, too, confirmed that pollution was worse than ever in 2019 and that the fishing industry was considerably responsible. The Dutch Ocean Cleanup project, working in the Great Pacific garbage patch, found more than half came from discarded plastic nets and rope, fish aggregating devices [FADs], buoys, long lines, crates and floats. French researchers showed how plastic litter at the bottom of the Mediterranean had tripled since 1990 and the Ellen MacArthur Foundation estimated that there would be more plastic than fish in the oceans by 2050 if business was allowed to continue as normal. Wherever researchers looked, they were horrified. One study found an estimated 1.8m pieces of plastic, old tyres and fishing gear on the sea floor of the Bay of Fundy between Nova Scotia and New Brunswick in Canada; the WWF calculated that 570,000 tonnes of plastic went into the Mediterranean each year – the equivalent of 33,800 plastic bottles every minute and plastic was found widely in the food chain and in human bodies. Under pressure from governments but unwilling to produce less, the industry turned in 2019 to bioplastics, which convert the sugar present in plants and crop residues into plastic. Big manufacturers such as BASF, Dow, Huhtamaki, Plantic, Mondi, and Amcor ramped up research into plastic from corn, wheat, potatoes, soyabean and cotton. The market is still small but is expected to grow 20% annually into a $70bn a year industry by 2024. But critics said bioplastics were not the answer. Not only can they take up land needed for food production, but most bioplastics need high temperature industrial composting facilities to break them down. With few local authorities able to handle them, the result is most must go to landfills where they are likely to release methane, a greenhouse gas 23 times more potent than carbon dioxide. Industry attempts to appear green mostly ended in confusion. Products were increasingly classed as compostable, biodegradable, recyclable, reusable or bio-based. But most of these terms meant little. Biodegradable plastic was found to be intact after years at sea; not all compostable materials, it was found, could be composted at home; and recyclable depended on the local waste stream; with few standards and no timescale attached to bioplastics, many were described as false solutions. Faced with heavily polluted coastlines, a hostile media and angry tourists, the EU launched its plastics strategy in 2019 . This aims to ensure all plastic packaging is reusable or recyclable by 2030. It also calls for 90% of all plastic bottles to be recycled by 2025. The new UK government has pledged to ban the export of plastic waste to poor countries, and to introduce a tax on plastic packaging with less than 30% of recycled content from 2022. It also said it would stop by April 2020 the use of 4.7bn plastic straws, the 316m plastic stirrers and the 1.8bn plastic cotton buds used each year. Asian countries, faced with massively polluted coastlines and a swiftly growing plastics market, promised to act. India and Peru planned to eliminate all single-use plastic by 2022 and the Maldives said it would phase out all its non-biodegradable plastic. By the end of 2019, more than 120 countries had banned plastic bags and 60 more countries said they would impose taxes. Many US states banned or said they were planning to phase out plastic bags. The industry fought back. Companies may have promised publicly to stop using certain types of plastic, but their trade bodies lobbied strongly in 2019 against new laws and argued to be allowed to continue to produce more. Industry and supermarket trade groups lobbied against proposed deposit return schemes, bans and new recycling targets. The US industry responded with threatening lawsuits against local authorities and cities who tried to introduce bag bans. Instead of waiting for governments and industry, coalitions of global and local NGOs, international banks, conservation groups and some plastic producers volunteered to clean up rivers and beaches, and help governments collect and recycle waste. The UK-based Common Seas NGO worked with islands and resorts in the Maldives and Greece, and with city authorities in Indonesia to prevent plastic getting to the ocean. Volunteers cleared millions of pieces of plastic from beaches in the Mediterranean, Middle East, Latin America, China and India beaches. Novel ways to collect plastic from rivers and oceans were introduced. The Ocean Cleanup project launched the Interceptor, a barge-like vessel theoretically able to harvest up to 100,000kg of plastic waste a day from heavily polluted rivers. Waternet, which manages Amsterdam’s canals, introduced a “bubble barrier” to catch floating debris. New Naval adapted oil-spill technology to invent a mesh barrier system to collect river plastic; and Mr Trash Wheel scooped rubbish out of the Jones Fall River in Baltimore with waterwheels. By the end of 2019, the war between the petrochemical companies and those who would stem their tides of plastic was fully engaged, but was still being largely won by the petrochemical industry. 2020 is widely seen to be critically important. In June the UN will host an oceans conference in Portugal at which worldwide progress will be assessed, and countries will pledge to prevent plastic pollution. Many proposed government bans should also come into force and hundreds of smaller initiatives to recycle more and reduce pollution should start to grow and make a difference. What is certain is that calls for a reduction in plastic use will grow louder and the industry will resist. But unless ways are found to use less, most of the efforts to stem the flood of plastic entering the environment are likely to prove temporary and insufficient. • A version of this article appears at commonseas.com"
"The Australian, Rupert Murdoch’s flagship newspaper, has defended itself against criticism it downplayed unprecedented bushfires by failing to put a picture of the disaster on the front page of an edition, even as newspapers across the world featured the harrowing scenes. Many of the world’s leading mastheads featured pictures of the devastation of the Australian bushfires on page one on Thursday. But the Australian’s first edition ran an upbeat picture story about the New Year’s Day picnic races at Hanging Rock.  Sources at the newspaper said the newsroom was short-staffed over the holidays, however it was noted that resources were found to attack the ABC with gusto over its New Year’s Eve concert. Singer Tex Perkins has upset some ABC viewers after his obscene gesture directed at the PM during his Sydney New Year's Eve performance https://t.co/1hngOWcVyn “Our readers have been fully informed across the nation both online and in paper all week,” editor John Lehmann told Guardian Australia. New masthead. pic.twitter.com/ke7lT9yRcm The national broadsheet’s lead story on Thursday was about a secret proposal by police to ban alcohol in Indigenous communities in Western Australia – a story deemed more important than the bushfire report, which said eight people were dead and mass evacuations were underway. Police push for remote booze ban in WA’s north after 13 youth suicides put a spotlight on rampant alcohol abuse, child neglect and violence. This is really bold and opinion is not uniform ⁦@australian⁩ https://t.co/82oboEuqO8 There wasn’t a single photo of the catastrophic bushfires until page 4. Meanwhile here in Australia the Oz WA edition didn’t have a single bushfire pic until page 4. They went with a pictorial coverage of the picnic races at hanging rock in vic. https://t.co/tUVp7MARZl Before readers got to that coverage, they were given an exclusive interview with “rebel marine scientist Peter Ridd” who has challenged reef scientists to test whether or not human actions have caused a collapse in the growth rate of corals on the Great Barrier Reef. The later editions of the paper dropped the racing story and replaced it with photographs of bushfire victims surveying the damage. The Australian is not the only Murdoch-owned newspaper that has been accused of downplaying the bushfires. On New Year’s Eve, Melbourne’s the Herald Sun also relegated the bushfires to page 4, even as thousands of Victorians faced a serious bushfire threat. For the past 62 years our own ""Onion Oracle"" Halwyn Hermann has been predicting rainfall using a humble onion, and this year we all hope he's spot on, because he says rain is a coming https://t.co/y5hG7LZoQf On the same day, Sydney’s Daily Telegraph blamed the Bureau of Meteorology for inaccurate weather predictions, which may have “lulled residents into a false sense of security about conditions”. But it was the Courier Mail’s story about the “Onion Oracle” that had some readers wondering what was going on at News Corp. The Queensland tabloid carried the optimistic news that “Onion Oracle” Halwyn Hermann was predicting rain using an old German tradition. They even compared the Onion Oracle’s predictions to those of the bureau of meteorology. uhhhh yeah sure man pic.twitter.com/WVXI4a2v0v The Australian has been consistent on one front. Throughout the bushfire season it has kept up its coverage of climate denialism. Before Christmas, the Australian attempted to smear Greg Mullins and his Emergency Leaders for Climate Action group as “largely a vehicle for Tim Flannery”. Flannery is a leading environmentalist and chief counsellor at the Climate Council. The former fire and emergency chiefs from multiple states and territories say Australia is unprepared for worsening natural disasters from climate change and governments are putting lives at risk. The Australian says they are a front for Flannery who is an “alarmist” for urging that coal-fired power stations be shut down. On New Year’s Eve, the paper led with another “exclusive” report that pushed the line Australia should not speed up its response to global warming. EXCLUSIVE | Energy Minister @AngusTaylorMP has warned ""top-down"" pressure from the UN to address climate change will fail and better technologies — not tougher ­government imposts — are needed to meet emissions-reduction targets. https://t.co/Ifz1nllItg Climate pressure was “doomed to fail”, wrote environment editor Graham Lloyd about claims by the energy minister, Angus Taylor, who warned that “top-down” pressure from the UN to address climate change would fail. As communities in Victoria and New South Wales faced devastating weather conditions on the weekend the Australian assured its readers that there was nothing unusual going on. A double-page spread about the history of fires in Australia painted the national disaster as a run-of-the-mill crisis: “History of disasters shows there is nothing new about nation’s destructive blazes.” “While there is no doubt these bushfires are bad and may get worse, fuelling more talk of the nation battling an unprecedented fire threat this summer, the blazes that continue to plague the eastern states and Western Australia are nothing new,” the report said. “Climate change or no, these are some of the costs of being in one of the most fire-prone regions of the world. And those costs have been paid since well before Federation.” “Indeed, of the entire list of official inquiries detailed in the AIDR’s bushfire and natural hazards database, just two make recommendations about factoring in climate change as part of the response to future fire risks.”"
"People associate wasps with memories of picnic invasions, BBQs under siege, and painful stings. There is a lot more to these much-maligned insects though, and with more than 100,000 different species, their life histories range from the quietly unobtrusive to the bizarre and gruesome. A new study in the Journal of Experimental Biology documents one such disturbing example of wasp larvae that takes control of their unfortunate spider hosts. The Japanese scientists behind the study thought the host-parasite relationship between the wasp Reclinervellus nielseni  (most wasps have only a scientific name) and its orb-weaver spider host Cyclosa argenteoalba could help us understand how parasitic organisms alter their host’s behaviour. The adult wasps lay an egg on the outside of the spider’s body. The wasp larva hatches out and attaches itself to the spider’s abdomen, where it feeds on the fluids within, while the spider goes about its normal life. At a certain point though, the larva causes the spider’s behaviour to change. It’s as though the larva takes control of the spider and forces it to create the perfect environment for the wasp larva to transform (or “pupate”) into an adult. Under normal circumstances, this species of spider spins two different types of web: a “normal orb web” that looks like a typical spider’s web with a spiral of sticky thread that is used for catching prey, and a “resting web” which lacks the sticky spiral that is spun just before the spider moults its old exoskeleton.  But the parasitised orb-weavers spin a web just before the wasp larvae transform into adults and kill the spider. This “cocoon web” looks very similar to the resting web. In fact, the wasp larvae had induced the spiders to build a modified resting web as it would create a safer environment for the larvae to pupate – just as a resting web creates the perfect conditions for the spider to moult.  To test their theory the researchers observed spiders building webs with and without wasps for company, they examined the structures of the webs and tested the strength of the silk fibres within them. The wasp cocoon webs had similar strength and structure as the regular resting web. They even had similar “decorations” of tiny fibrous threads which reflect UV light which may help to prevent other insects and larger animals disturbing the web, thus increasing the larva’s chances of pupating successfully. They also found that the cocoon webs have extra reinforcement to make them stronger, further increasing the likelihood of the wasp’s survival. The spiders are forced to abandon their normal behaviour to create the cocoon web, either by altering their normal orb web or by creating one from scratch. The spiders then sit in the middle of the web motionless, until the larvae kill it.  The scientists suggest that this control over the spider could be caused by the wasp larvae injecting hormones into the spider which mimic hormones that control the spider’s moulting behaviour. In effect, the spiders have been drugged by the wasps into doing their bidding. These “zombie spiders” are particularly spectacular victims of behaviour that is actually fairly common among wasps. The classic picnic-ruiners represent just a small group: the social wasps, those that live in a colony with a queen and workers. But, as with bees, most wasp species are rather different from the ones we normally encounter.  Most wasps are solitary, they are almost all predatory, and many tens of thousands of species are parasites or parasitoids. The difference here is that a true parasite doesn’t usually kill its host or render it sterile (like a flea or tick), whereas a parasitoid always does, and often consumes it too. Almost all adult wasps feed on nectar, but larvae need protein to grow and develop, and so the adults prey on invertebrates like other insects and spiders to feed their young. Some solitary wasps are kleptoparasites – parasites through stealing – like the cuckoo or jewel wasps. These beautiful wasps lay their eggs in the nests of other wasps or bees. The eggs of the parasite hatch before those of the host, so the parasite larvae can eat the provisions that the host parent left for their offspring, before they get the chance – sometimes they also eat the host egg or larvae. Parasitoid wasps lay their eggs on or inside the adults, larvae or eggs of host species. Some of these wasps also inject venom into the host organism to immobilise it, some also inject chemicals that protect their eggs from the host’s immune system. Most parasitoid wasps prey on other insects, but many are also specialised to parasitise spiders. Some parasitoids are even used commercially for agricultural pest control – the tiny Trichogrammatidae  family attack the eggs of nuisance moths, for instance."
"
Share this...FacebookTwitterPIK alarm story fails the test of science: Jet Stream will also meander as usual in the future
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated by P Gosselin)
Almost one year ago the Potsdam PIK Institute put out a press release, which warned of stalling Jet Stream waves. Due to man-made climate warming weather extremes would remain stuck in a position longer. Among the messengers of the alarm were Stefan Rahmstorf and hockey stich fabricator Michael E. Mann.
Next on February 20, 2018 the horror scenario suffered a setback at the University of Missouri. Using model simulations it was determined that the Jet Stream would also meander in the future as well. Climate alarm shut off once more. This is not the first time that Rahmstorf’s extreme claims have been dispelled in short order by his colleagues. See here, here, here, here, and here.
The University of Missouri press release follows:
Weather should remain predictable despite climate change
Simulations of jet stream behavior in a warming climate suggest ranges of forecasts in the mid-century will be similar to those in present day.
According to the Intergovernmental Panel on Climate Change, temperatures are expected to rise between 2.5 and 10 degrees Fahrenheit over the next century. This warming is expected to contribute to rising sea levels and the melting of glaciers and permafrost, as well as other climate-related effects. Now, research from the University of Missouri suggests that even as rising carbon dioxide levels in the atmosphere drive the climate toward warmer temperatures, the weather will remain predictable.
“The jet stream changes character every 10 to 12 days, and we use this pattern to predict the weather,” said Anthony Lupo, professor of atmospheric science in MU’s School of Natural Resources, which is located in the College of Agriculture, Food and Natural Resources. “We were curious about how this would change in a world with higher carbon dioxide levels. We found that in that warmer world, the variability of the jet stream remained the same.”
Lupo and Andrew Jensen, who earned his doctorate at MU, used an existing climate model to simulate jet stream flow in the Northern Hemisphere. The simulation monitored a variable that responds to jet stream flow changes and can indicate global-scale weather instability. Researchers used this variable to determine when the jet stream altered its flow. Since meteorologists can only accurately predict weather within the 10 to 12 days between jet stream flow changes, a shift in this time frame would directly impact weather predictability.
Over the course of a simulated 31 years, their observations indicated the jet stream would change its character about 30 to 35 times per year, a number that is consistent with current jet stream patterns. As the time frame used to predict weather did not change, the researchers concluded that weather would likely remain as predictable in a warmer world as it is today. The results do not address the effects of climate change on the nature or frequency of weather events but instead focus on the range of predictability afforded by the jet stream. In addition, the researchers did not extend the simulation past the mid-century to ensure their data was as accurate as possible. “Climate change will continue to create a lot of ripple effects, but this experiment provides evidence that the range of forecasting will remain the same,” Lupo said.
The study, “The Dynamic Character of Northern Hemisphere Flow Regimes in a Near-Term Climate Change Projection,” was published in Atmosphere. Other researchers involved in the study were Mirseid Akperov of the Russian Academy of Sciences, Igor Mokhov of Lomonosov Moscow State University and Fengpeng Sun of the University of Missouri-Kansas City.”
Share this...FacebookTwitter "
"The sky over Cobargo in New South Wales was still tainted yellow on Thursday afternoon when Australia’s prime minister arrived. For the past month, the country had been ablaze, and the village 240 miles south of Sydney and home to 776 people, had been hit hard. Standing in the crowd, Zoey Salucci McDermott, 20, eyed Scott Morrison coolly. She and her young daughter had lost her home in the fires, so when he extended his hand in greeting, she did not reciprocate. “I’ll only shake your hand if you give more funding to the RFS [Rural Fire Service],” McDermott said, holding back tears. “So many people here have lost their homes. We need more help.” The prime minister turned away. Days before, two separate firefronts had swept across much of southern NSW and eastern Victoria with unprecedented ferocity, wiping entire towns from the map. When the flames arrived in Cobargo, they tore through the main street, roaring like the ocean, incinerating lives and livelihoods. Robert Salway, 63, and his son Patrick, 29, died when they stayed behind to defend their property. Patrick’s wife, Renee, who is pregnant with the couple’s second child, found their bodies. As the flames retreated, a white hot anger smouldered. “You’re not welcome, you fuckwit,” a man yelled after Morrison as he retreated under a barrage of insults. Referring to the affluent Sydney suburb where the prime minister has an official residence, he said: “I don’t see Kirribilli burning after the fireworks.” The scene, caught on video, has become symbolic of a nation at odds with its leadership as it has endured a week of horror in a rolling, months-long national emergency that has yet to reach its climax. The scale of the destruction is hard to overstate. When the Amazon rainforest caught fire last January, 906,000 hectares burned. And last July, 2.6 million hectares were turned to ash across the Siberian steppe. Since the first fires began in Australia in August, more than 5 million hectares have been set aflame, fanned by unusual weather patterns and lower-than-usual humidity that has allowed firefronts to spread rapidly across a bone-dry landscape. The country’s volunteer firefighting forces are exhausted, outgunned and overwhelmed. The fires are behaving in unpredictable ways, spreading at night and even returning to areas that have already burned. Conditions on the ground have seen walls of flame, spot fires coalescing into fire tornados and some firefronts burning so hot they have formed their own weather systems. The ensuing lightning strikes have gone on to ignite yet more fires. The direct death toll stands at 23, with more expected. Some species have been pushed to extinction, and more than half a billion animals are estimated to have been killed. Farmers have reported running out of bullets as they work to end the suffering of half-dead livestock. Of all the states, New South Wales has been hardest-hit, with 3.41 million hectares scorched over the past few months and Sydney, at one point, finding itself encircled by active firezones. Around the same time, fire ripped through the Adelaide Hills and Kangaroo Island in the central state of South Australia. In the Adelaide Hills in South Australia, flames swallowed 25,000 hectares of prime agricultural land, leaving a third of the wine industry in the area “smashed”. The state of Victoria in the southeast, meanwhile, greeted the first week of the new decade in horror as it watched new firefronts bloom in East Gippsland before quickly building into an inferno which blackened 700,000 hectares in days. Wherever the fires rise, their approach has been foreshadowed by falling ash and the dimming of light as blue skies turn either nicotine yellow, glowing orange or, in some cases, blood red. That was the scene in Mallacoota, a tourist town 260 miles east of Melbourne in the middle of a Unesco biosphere. As the rest of the world readied to bid goodbye to 2019, locals spent their New Year’s Eve watching the flames approach. Residents woke to find skies blackened by ash and temperatures rising to 49C at 8am. As daybreak turned to night, the sky grew red as the flames drew near. With the only road out of town soon cut off by fire, 4,000 people were forced to flee towards the beach. When traffic backed up, people abandoned their cars. Soon after, the emergency services ordered people to wade into the sea to escape the blaze. Over the next two days, as images of the destruction began to emerge on social media, an evacuation order was given for some 14,000 sq kms between Nowra in New South Wales and the border of Victoria. Across the state lines, Victorian state premier Daniel Andrews declared an official state of disaster in Gippsland on Thursday night, enacting sweeping powers that have never been used. Weeks after an advertising campaign began in the UK to attract tourists to Australia, tens of thousands of holidaymakers were evacuated from coastal NSW and Victoria, the largest peacetime evacuation in the country’s history, with the navy deploying to rescue those trapped in Mallacoota. Authorities in those states which have so far escaped the devastation have been left to watch on nervously. Peak fire season typically hits with the height of summer, leaving those states so far unaffected to wait their turn – with far fewer resources. With bushfires flaring so early in the year, volunteers have been sequestered from across the country to assist on the east coast. Their absence means states like Western Australia are reliant on ex-volunteers in the event of emergency.Even regions relatively unaffected by the fires have been unable to escape the consequences. Smoke drift has stained glaciers as far away as New Zealand. In Canberra, the nation’s capital, air quality has been so bad that the postal service has stopped delivering mail. Liz Bashford from Doctors for the Environment Australia said the smoke has probably already caused deaths. Preliminary statistics show mortality rates, ambulance callouts and hospital admissions all increasing since the smoke settled over Sydney, but the precise impact won’t be known ubntil at least the end of this month. “Bushfire smoke will increase the incidence of death, but to say it was responsible for a particular death is much harder,” Bashford said. “It’s a bit like smoking cigarettes. If someone dies of respiratory problems and they’re a smoker we can clearly say it contributed to their death, but it’s very hard to put the finger on the only thing that caused their death.” “All this has been predicted for decades by scientists but it’s happening in a far quicker and in more dramatic way this fire season than we expected.” Morrison has shrugged off criticism of his government’s climate change policies. Speaking at the UN in New York last September he insisted Australia would meet its emissions reductions targets “in a canter”. That same month, his government was being warned about the catastrophic fire risk presented by climate change. Former New South Wales fire chief Greg Mullins and 22 other former emergency services chiefs wrote to Morrison outlining the potential crisis and asking for more specialised equipment to deal with hotter and longer bushfire periods. They were ignored. Emergency services have been asking for resources since 2016, when the National Aerial Firefighting Centre asked for a “national large air-tanker fleet” to support firefighting operations but were rebuffed. The consistent refusal to stump up the cash or even engage with a chorus of experts warning about a crisis has defined the conservative government’s policy since it took power under Tony Abbott in 2013. Now, as the country faces one of the worst natural disasters in its history, a short-term, transactional austerity politics has collided with the long arc of climate change in a way that is clearly visible on the ground. Firefighters in some areas have been forced to crowdfund for basic equipment while until recently the federal government remained steadfast in its refusal to back-pay volunteers for their time, even as the prime minister praised their “spirit”. It took sustained public pressure to drag the government to compensate volunteers, with Morrison announcing last Saturday that they would receive up to $6,000. The denial of reality was seemingly reinforced on New Year’s Day, when Morrison held a reception for a professional cricket team at Kirribilli House, the official residence.In a throwback to an earlier scandal when Morrison was photographed on holiday in Hawaii as the first homes were lost in New South Wales, As the country burned, the prime minister was pictured playing backyard cricket.“Whether they’re started by lightning storms or whatever the cause may be, our firefighters and all of those have come behind them to support them, whether they’re volunteering on the front line or behind the scenes in a great volunteer effort, it is something that will happen against the backdrop of this test match,” Morrison said. These words might have been of little comfort to locals huddled together on a beach in Mallacoota against the approaching inferno on Tuesday morning and who were, on Saturday afternoon, again bracing for “another round”. Brendan, a Mallacoota local who asked that his last name not be printed, told the Observer how three branches of his extended family were now living under one roof as the fires had destroyed the homes of friends and family. “We chose to live here. We love this part of the world, and we’re really quite devastated at the destruction that’s taken place,” Brendan said. “We had a fire plan, we went over it at Christmas, all together. We still didn’t know how big the burn would be.” While they weren’t in any imminent danger, Brendan said the firefront had remained active around the town as of noon and an expected change in weather conditions threatened to make the situation unpredictable. A few hours later Brendan posted to social media another image showing the eerie sky over Mallacoota. It carried the ominous caption: “I don’t think we’re getting light back today. We’re relaxed enough that we’re going to make some dinner. I believe the risk that today’s weather posed has passed, for us at least.”"
"Brexit may well be the government’s immediate priority but the most critical task of its first year will be its ability to secure an ambitious and effective deal to tackle the climate emergency. From the hundreds of people forced from their homes by the Yorkshire floods that dominated the early part of the election campaign, to the bushfires sweeping Australia, the evidence of our own eyes shows us that climate crisis isn’t just a threat to future generations – its devastating effects are playing out right now.  Climate-related disasters are already the biggest cause of internal migration – forcing someone from their home every two seconds. Today, 52 million people in 18 countries across Africa are facing crisis levels of hunger because of drought, flash-flooding and other extreme weather events. In Latin America, Guatemalans facing a sixth year of crop-destroying drought are among the many for whom climate change is now an existential threat – put bluntly, it is starving their children. There is currently no greater test of Boris Johnson’s commitment to the ideal of a post-Brexit-global Britain. In November, Glasgow will host the most important international climate talks in years. Can Johnson and his government persuade world leaders to put aside their own short-term economic interests and do what is necessary for people and planet?  The stage is set for the UK to take a lead. Our parliament has declared a “climate emergency”. We are already the first major industrial nation to commit to reaching net-zero carbon emissions by 2050; other nations, cities and companies are beginning to follow suit. But if we’re to maximise this opportunity, we – the British people, business and our government – need to do more. We know that tackling climate crisis will require changes to our high-carbon lifestyles. Oxfam has calculated that carbon emissions produced by the world’s wealthiest 10% are equivalent to those of the poorest half. Today, we publish new research showing that the average Brit will emit more carbon in first two weeks of 2020 than the citizens of seven African nations emit in an entire year. The good news is that there are increasing signs that the public is ready to act. As many as four in five Britons said they are likely to take one of a number of actions this year to reduce their carbon footprint. More than two-thirds (68%) said they were likely to use energy-efficient products or utility providers and 79% of people said they were likely to recycle more. In September, tens of thousands of people took Oxfam’s #SecondHandSeptember pledge not to buy new clothes for a month, saving carbon equivalent to driving round the world 200 times. But people also need help to adapt. Six out of 10 people in Britain want the government to do more to tackle climate change and solutions are available – improving public transport, introducing schemes to make greener homes more affordable or tax incentives to encourage lower-carbon lifestyles. There are no shortcuts – we can’t argue our way out of the climate emergency by using statistical tricks or clever rhetoric. Greta Thunberg has accused the UK of “very creative carbon accounting”, because our official figures exclude ‘imported’ emissions from goods and services we use that are produced outside our borders, such as electronic goods made in Asia or overseas flights. Climate crisis doesn’t end at our coastline: our shared, international targets on climate action are called “global goals” for good reason and government policy needs to account for that fact. We, and other wealthy industrialised nations like us, have been responsible for the majority of emissions over the past century and a half and therefore have a responsibility to support poorer nations in reducing their own emissions and adapting to the brutal impacts of a climate crisis they did little to cause. Expecting that we can simply “offset” our carbon emissions through schemes overseas, such as paying poorer countries to grow forests instead of food, risks pushing people already on the frontline of climate crisis even deeper into hunger and poverty. Wealthy nations have pledged to provide $100bn (£89bn) in climate finance every year by 2020. The UK should use its position as host of this year’s climate talks to push other countries to follow its lead in helping to reach this target and beyond while ensuring that funding doesn’t come from cuts to medicines, schools and other overseas aid commitments. After the disappointing climate talks in Madrid last month, a bold move is needed to inject energy and optimism into the next round. The prime minister should take charge of this himself, committing to attend and inviting other heads of government to do the same. Then putting the policies and investments in place to get us on track to reach net zero well ahead of 2050 could be a game-changer, showing that Britain is serious about net zero and how to achieve it. Not many governments have the chance to set the world on a truly different course. This one does and for the sake of all, whether in Guatemala, Australia or, indeed, Yorkshire, they must grasp it. • Danny Sriskandarajah is chief executive, Oxfam GB"
"Fares for long-distance rail travel in Germany have dropped for the first time in 17 years, as climate protection measures aimed at making train travel more attractive came into effect with the new year. Travellers taking trips of more than 50km (31 miles) on Deutsche Bahn’s Intercity Express trains can look forward to fare decreases of 10%.  The company is also cutting prices on special offers and additional services, such as transporting bicycles. The trend in Germany stands in contrast to the situation in the UK, where millions of commuters face a 2.7% rise in ticket prices from 2 January. The cheaper tickets are a result of Deutsche Bahn passing on to customers the government’s cut in value-added tax on rail travel, from 19% to 7%. The UK does not charge VAT on rail fares. The company said it believed the price drop would bring in another 5 million passengers per year. Germany’s main provider of rail services is a private company in which the state is the single shareholder. Plans to sell off up to 49.9% of the company to private providers were abandoned with the onset of the 2007-08 financial crisis. Not all commuters in Germany will get cheaper fares in 2020. Fares for short-distance travel and public transport in regions such as Berlin, Hamburg, Bremen, Brandenburg and the Rhineland are set to increase, the news agency dpa reported this week. Fares for regional trains in the Bonn area are due to rise by 2.5%, while people in Berlin and Brandenburg face a 3.3% increase in the cost of tickets for bus, tram and subway travel. Public transport providers say the fare increases are due to rising wages and higher prices of diesel and electricity and were agreed before the government passed its climate protection measures."
"
Share this...FacebookTwitterMore Wind Turbines,
More Habitat Harm, Loss
Scientists (Krekel and Zerrahn, 2017 ) report that the installation of wind turbines near human populations “exerts significant negative external effects on residential well-being” and a “significant negative and sizable effect on life satisfaction” due to “unpleasant noise emissions” and “negative impacts on landscape aesthetics”.
“We show that the construction of wind turbines close to households exerts significant negative external effects on residential well-being … In fact, beyond unpleasant noise emissions (Bakker et al., 2012; McCunney et al., 2014) and impacts on wildlife (Pearce-Higgins et al., 2012; Schuster et al., 2015), most importantly, wind turbines have been found to have negative impacts on landscape aesthetics (Devine-Wright, 2005; Jobert et al., 2007; Wolsink, 2007). … We show that the construction of a wind turbine within a radius of 4,000 metres has a significant negative and sizeable effect on life satisfaction. For larger radii, no negative externalities can be detected.”
If human well-being and life satisfaction is seriously compromised by the nearby presence of a wind turbine, imagine the physiological effects on birds, bats, and land-dwelling mammals in general.
Six new papers expose the systematic destruction of natural wildlife habitats via the installation of wind turbines.
1. A 20-Fold Loss Of Bat Habitat At Wind Turbine Sites … A ‘Worldwide Phenomenon’

Millon et al., 2018
“Wind turbines impact bat activity, leading to high losses of habitat use … Island bats represent 60% of bat species worldwide and the highest proportion of terrestrial mammals on isolated islands, including numerous endemic and threatened species (Fleming and Racey, 2009). … We present one of the first studies to quantify the indirect impact of wind farms on insectivorous bats in tropical hotspots of biodiversity. Bat activity [New Caledonia, Pacific Islands, which hosts nine species of bat] was compared between wind farm sites and control sites, via ultrasound recordings at stationary points [A bat pass is defined as a single or several echolocation calls during a five second interval.] The activity of bent winged bats (Miniopterus sp.) and wattled bats (Chalinolobus sp.) were both significantly lower at wind turbine sites. The result of the study demonstrates a large effect on bat habitat use at wind turbines sites compared to control sites. Bat activity was 20 times higher at control sites compared to wind turbine sites, which suggests that habitat loss is an important impact to consider in wind farm planning. …  Here, we provide evidence showing that two genera of insectivorous bat species are also threatened by wind farms.  … To our knowledge, this is one of the first studies quantifying the indirect negative impact of wind turbines on bat activity in the tropics. … The lower attractiveness of the foraging habitat under wind turbines, both in a tropical and in a temperate climate, indicates that the indirect impact of wind turbine is a worldwide phenomenon.”
2. A ‘Distinct Physiological Response’ (Stress) Caused by Wind Turbines’ ‘Disturbance Factors’
Lopucki et al., 2018
“Living in habitats affected by wind turbines may result in an increase in corticosterone levels in ground dwelling animals … Environmental changes and disturbance factors caused by wind turbines may act as potential stressors for natural populations of both flying and ground dwelling animal species. The physiological stress response results in release of glucocorticoid hormones. … The common vole showed a distinct physiological response − the individuals living near the wind turbines had a higher level of corticosterone [physiological stress affecting regulation of energy, immune reactions]. … This is the first study suggesting impact of wind farms on physiological stress reactions in wild rodent populations. Such knowledge may be helpful in making environmental decisions when planning the development of wind energy and may contribute to optimization of conservation actions for wildlife.”
3. Wind Farms’ ‘Known Impacts’: Mortality Increase, Habitat Destruction, Enhanced Human Interference, Reduced Breeding Opportunities
Ferrão da Costa et al., 2018
“According to a review by Lovich and Ennen (2013), the construction and operation of wind farms have both potential and known impacts on terrestrial vertebrates, such as: (i) increase in direct mortality due to traffic collisions; (ii) destruction and modification of the habitat, including road development, habitat fragmentation and barriers to gene flow; (iii) noise effects, visual impacts, vibration and shadow flicker effects from turbines; (iv) electromagnetic field generation; (v) macro and microclimate change; (vi) predator attraction; and (vii) increase in fire risks. … Helldin et al. (2012) also highlighted that the development of road networks associated with wind farms could promote increased access for traffic related to recreation, forestry, agriculture and hunting. The consequence, particularly on remote places, is the increase in human presence, affecting large mammals via significant disturbance, habitat loss and habitat fragmentation. These negative effects are expected to be particularly relevant for species that are more sensitive to human presence and activities, such as large carnivores. Large carnivores, such as the wolf, bear, lynx or wolverine, tend to avoid areas that are regularly used by humans and—especially for breeding—show a preference for rugged and undisturbed areas (Theuerkauf et al. 2003; George and Crooks 2006; May et al. 2006; Elfstrom et al. 2008; Sazatornil et al. 2016), which are often chosen for wind power development (Passoni et al. 2017). … Results have shown that the main impact of wind farms on wolves is the induced reduction on breeding site fidelity and reproductive rates. These effects, particularly when breeding sites shift to more unsuitable areas, may imply decreasing survival and pack viability in the short term.”
4. Installation Of Wind Turbines Have ‘Population-Level Effects’ For Rare, Endangered Species
Watson et al., 2018
“The global potential for wind power generation is vast, and the number of installations is increasing rapidly. We review case studies from around the world of the effects on raptors of wind-energy development. Collision mortality, displacement, and habitat loss have the potential to cause population-level effects, especially for species that are rare or endangered.”
5. An ‘Urgent Concern’: ‘Wind Power Has Negative Effects On Proximate Wildlife’ (Collision Fatalities, Habitat Loss)
Naylor, 2018
“While wind energy provides a viable solution for emission reductions, it comes at an environmental cost, particularly for birds. As wind energy grows in popularity, its environmental impacts are becoming more apparent. Recent studies indicate that wind power has negative effects on proximate wildlife. These impacts can be direct—collision fatalities—and indirect—habitat loss (Fargione et al. 2012; Glen et al. 2013). Negative impacts associated with operational wind farms include collision mortalities from towers or transmission lines and barotrauma for bats. Habitat loss and fragmentation, as well as avoidance behavior, are also consequences resulting from wind farm construction and related infrastructure. The potential harm towards protected and migratory bird species are an urgent concern, especially for wind farms located along migratory flyways. In terms of mortality, wind turbines kill an estimated 300,000 to 500,000 birds, annually (Smallwood 2013). The high speed at which the fan wings move and the concentration of turbines create a gauntlet of hazards for birds to fly through. … [T]he height of most wind turbines aligns with the altitude many bird species fly at (Bowden 2015). Birds of prey— raptors—are of particular concern because of their slow reproductive cycles and long lifespans relative to other bird species (Kuvlesky 2007).”
6. Wind Farms Negatively Affect Waterfowl Via Habitat Loss, Disturbance Displacement, Compromised Foraging Opportunities
Lange et al., 2018
“Results from our surface water extractions and aerial surveys suggest that the wind farm has negatively affected redheads through altered hydrology and disturbance displacement. Our surface water extraction analysis provides compelling evidence that the local hydrology has been greatly affected by the construction of the wind farm. … Our results suggest the occurrence of direct habitat loss and disturbance displacement of redheads from the wind farm along the lower Texas coast. Although our study was directed solely toward redheads, it is likely that this wind farm has affected other species that use these wetlands or migrate along the lower Texas coast (Contreras et al. 2017). Studies in Europe investigating the effects on waterfowl by wind turbines have reported similar results, showing that turbines have likely compromised foraging opportunities for waterfowl through disturbance displacement (Larsen and Madsen 2000).”
Share this...FacebookTwitter "
"Millions of people worldwide can’t afford to keep their homes warm, but few realise the heat wasted in our energy system could provide the answer.  We need to do more to prevent valuable energy being lost to the environment as heat. It’s not just draughty buildings – power stations lose a vast amount of heat through their cooling towers or dumped into waterways, equivalent in the UK to a third of final energy use, while UK industry wastes enough heat to warm more than two million households. Storing this heat can even help us manage renewable energy – at lower cost than batteries. A 2013 study by Buro Happold showed that tapping into the waste heat rejected into London’s environment could provide enough warmth for the whole city. What’s needed is a strategy to “join the dots” between waste heat sources and demand for heat using new infrastructure. Early initiatives are currently underway, looking to capture waste heat from the London Underground and from transformers on the power network to heat homes.  In Scandinavia and Eastern Europe, communities often share their heat sources, with customers connected to a “heat network” carrying hot water in well-insulated pipes. Instead of having boilers in individual buildings, they have heat exchangers which pass heat from pipes buried under the street outside to heating systems inside.  For example, in Warsaw individual boilers were replaced with a network during post-war reconstruction leading to big reductions in local air pollution.  In the UK, cities such as Sheffield and Nottingham have pioneered these networks to distribute heat from waste incinerators. Burning off household waste produces a lot of heat, and putting this energy to use helps the cities to tackle fuel poverty and reduce their carbon footprints. Sheffield already has 50km of heat pipes in its city centre, and a new power station fuelled with locally sourced waste wood will generate renewable electricity and also energy to feed into an extended heat network. Industrial processes rarely produce heat at the right time to meet demand, but energy can be stored in these heat networks by using large, well-insulated hot water tanks that can hold the energy for several days. Boreholes deep underground could store heat between whole seasons. After all, energy stored as heat costs far less per unit than electricity stored in batteries. Energy storage would be part of any plan for Sheffield to make use of industry’s wasted heat, but the benefits could extend much wider than the city itself. As increasing amounts of intermittent renewable energy are fed into the national grid, large heat stores for power stations with a heat network allow for flexible electricity outputs. At times of excess electricity production from renewables, this energy could be taken from the grid and stored as heat. Since heating uses up 44% of the UK’s energy, and a similar amount in the US, heat networks with energy storage can play a major role in making national energy systems more efficient and sustainable. Even in warmer climates, there is a growing market for district cooling systems which operate on similar principles. People working in energy policy are only just beginning to think in a more holistic way by considering how best to provide heat and electricity. So much energy is needed for heating that we won’t meet our emissions targets without a joined-up policy. A more efficient energy system, where heat is valued, preserved and put to use, can lower people’s bills while at the same time reducing carbon emissions and air pollution."
"
Share this...FacebookTwitterThe online fuldainfo.de here reports of mores woes in the German offshore wind industry. It’s turning out that offshore wind power is expensive, and often plagued by technical difficulties.

The offshore Trianel Borkum wind park severely hampered by spiraling costs, lower than expected winds. Photo credit: Trianel
Just days ago I wrote here of another recent technical folly suffered by the North Sea Riffgat wind park, where its power transmission underwater cable worked its way out of the seabed to become exposed and thus at risk of becoming ensnarled with anchors or fishing nets.
“Rosy wind projections”
The fuldainfo.de now writes of “high losses” incurred by aanother nearby wind park: the Trianel Windpark operated by Rhönenergie. This is “not surprising” to FDP Free Democrats Party Chairman Mario Klotzsche:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




We brought up our concerns again and again in the committees, and also in public, because the economic precariousness was foreseeable at a very early stage. That’s why the city of Flensburg left the project already in 2014. That’s what we also wish to do so that Rhönenergie can avoid getting saddled with additional burdens.”
Offshore installation costs more than doubled
A major reason for the losses seen by the Trianel Borkum park today, according to Klotzsche, were the “rosy wind projections”, which he reports was also the case for “many other wind projects“. He is quoted in the fuldinfo.de:
Originally 80 turbines with 400 megawatts of capacity should have been installed for 1 billion euros. In the end only 40 turbines and 200 megawatts of capacity were built for 1.1 billion euros.”
Multiple delays
Klotzsche also spoke of “repeated delays” with respect to hook up to the power grid, and even after the park was put into operation.
Moreover, the winds that were projected never materialized. “There was less wind than what was assumed,” according to Klotzsche. “The responsible persons calculated the project using rosy numbers.”
Share this...FacebookTwitter "
"How do we go about designing buildings today for tomorrow’s weather? As the world warms and extreme weather becomes more common, sustainable architecture is likely to mean one major casualty: glass. For decades glass has been everywhere, even in so-called “modern” or “sustainable” architecture such as London’s Gherkin. However in energy terms glass is extremely inefficient – it does little but leak heat on cold winter nights and turn buildings into greenhouses on summer days. For example, the U-value (a measure of how much heat is lost through a given thickness) of triple glazing is around 1.0. However a simple cavity brick wall with a little bit of insulation in it is 0.35 – that is, three times lower – whereas well-insulated wall will have a U-value of just 0.1. So each metre square of glass, even if it is triple glazed, loses ten times as much heat as a wall.  While the climate is changing, so too is the weather. Climate is expressed in terms of long-term averages, whereas the weather is an expression of short-term events – and the weather is predicted to change by much more than our climate. This creates challenges. A 0.5℃ increase in monthly temperature can made a difference to farmers, or the energy used by an air-conditioning system, but a peak temperature of 38℃ or a vicious cold snap can be far more serious. Buildings are designed to handle extremes, not just averages. Architects and building engineers around the world are now having to struggle with this issue, especially since buildings last so long. At Bath we have recently been awarded a grant to look at long-term weather forecasting and how building design will have to change. After all, you can’t move buildings to a better climate. One obvious possibility, for UK designers at least, is that they pick a place where the weather currently is similar to what the Met Office suggests the UK will have in 2100, and simply put up buildings like the ones they have there.  The problem is this ignores the low-carbon agenda. Many hot countries have spent the past 30 years designing buildings similar to those found in more temperate countries, while leaving enough space for monster air-conditioning systems. The air-conditioned skyscrapers in Las Vegas and Dubai, for instance, look just like buildings you might see in London or Boston, despite being built in the middle of a desert.  As an experiment, type “Dubai Buildings” into Google images and take a look at what has been built and, more worryingly, artist’s impressions of what is on the drawing board. You can even see this inefficiency in cultures that one might expect more of, for example the famous energy-guzzling glass towers of Vancouver.  Buildings will have to be simplified. Heating, lighting, energy supply, air con, escalators, IT networks and so on – all these “building services” will have to be stripped right back. Those services which do remain must use almost no energy – and possibly generate the energy they require on site. Cutting back on glass would be an easy win. Windows need to be sized, not glorified, and sized for a purpose: the view, or to provide natural light or air. Windows also need to be shaded. Many would argue that we need to re-invent the window, or the building. We need to build buildings with windows, rather than buildings that are one big window. Maybe we should look to the Mediterranean. People have mainly lived in countries such as Greece, for example, without air-conditioning – and it is true that such heavyweight, thick-walled buildings with small openings are capable of moderating external conditions very well.  However they don’t offer the climate control we are used to, especially if you pack them with people and computers. The people of the Mediterranean also had generations to adapt themselves and their working arrangements to fit with the climate. We don’t have this luxury: the weather is changing too fast. We have yet to invent architecture ready for whatever happens to the climate, but it is clear that we need to take lessons from the past – and from other cultures. We can’t simply air-condition our way through global warming."
"The Open Championship has returned to St Andrews, one of the world’s oldest and most prestigious golf courses and one that has been recognised for its commitment to sustainability. Last month’s men’s US Open was held at Chambers Bay in Washington state, a course built on reclaimed land in what was once a sand and gravel pit. This transition from “pit to prince” has also earned Chambers Bay recognition from the environmental organisation Audubon International.  You might think this all reflects a shift in the golf industry and a growing ease among fans and players towards more “natural” – and environmentally-friendly – courses. From the US Open’s first day onwards, however, the playing conditions at Chambers Bay elicited harsh reviews from players and commentators alike. Top pro Henrik Stenson said the greens were “borderline laughable”, tantamount to broccoli and the surface of the moon. Rory McIlroy injected some humour into the conversation: “I don’t think [the greens are] as green as broccoli … I think they’re more like cauliflower.” Having studied the relationship between golf and the environment, we find these two sides to golf’s environmental “story” to be telling. They reflect, respectively, the reasons why some are optimistic about the golf industry’s professed environmental stewardship and why others continue to express concern. Our research on golf and the environment has focused largely on the Canadian and American contexts. To borrow a phrase from University of Michigan professor Andrew Hoffman, what we have found is that, in the postwar years, environmentalism in the golf industry has effectively gone from heresy to dogma. For much of its history, golf was played on quite rugged terrain. The original coastal links-style courses were subject to the natural shape of the land and, as late as the last decades of the 1800s, inland Scottish courses were characterised by their extreme muddiness.  With golf’s “migration” across the Atlantic, however, key figures in the industry aimed to professionalise course design and maintenance by making these tasks into matters of science and precision. For example, in the eyes of Alister MacKenzie – the British-born designer of the Augusta National golf course, where the annual Masters tournament is played – the “modern” golf architect was one versed in disciplines such as chemistry, botany and geology, and one capable of carefully sculpting the land. Judging from industry trade publications, this “modern” inclination lived on into the postwar years. By this point, however, golf architects had the capacity to radically manipulate development sites. At the same time, those responsible for golf course maintenance had potent synthetic chemicals, most famously the pesticide DDT, at their disposal in the task of keeping the golf course (literally) green. The postwar years, and especially the 1960s, were also a time when the environmental movement was afoot. Thus, what we find in these same publications from this time is both passionate advocacy for chemicals such as DDT and rather stern condemnations of environmentalists like Rachel Carson, famed author of the 1962 treatise Silent Spring. In this context, environmentalism was effectively heretical. Fast-forward 20 years though, and things were far less antagonistic. Through investment in research and the implementation of new “best practices” – for example, Integrated Pest Management, which in theory lessens pesticide usage through the adoption of non-chemical means – golf industry representatives could credibly make the claim that they themselves had become true stewards of the Earth. At present, then, pro-environment rhetoric has seemingly become a matter of dogma for key golf industry representatives.  Can golf really claim to be environmentally-friendly?  Certainly those protesting against the new Olympic golf course in Rio de Janeiro and Donald Trump’s development in Scotland have expressed strong and negative opinions about golf’s “friendliness” in those contexts. Indeed, golf still has environmental costs. In California, golf courses have earned criticism – even “drought-shaming” – for their water consumption in the midst of a severe drought.  Golf’s version of environmentalism is one underpinned by the idea of “sustainability”, which itself puts social, environmental, and economic development alongside one another. Yet it is not evident that the first two “lines” of this triple bottom line can always stand up to the third. Donald Trump’s group wanted a new course on the Scottish coast. Local residents and environmental experts worried that this would “freeze” the dynamic coastal sand dune ecosystem, a Site of Special Scientific Interest. With government support, Trump won out in the end. At the same time, the highly manicured course evidently still holds a place of high prominence. We can infer from complaints about Chambers Bay that a worthy golf course is one that is predictable, consistent, and literally green.  One might well say in response that the best players deserve the best conditions. Yet it has long been a concern – even within the golf industry – that the game’s most famous courses can set an unrealistic standard for the industry as a whole. Indeed, this phenomenon has even been given a name: Augusta National Syndrome, a condition whereby golfers come to expect the “perfect” conditions they see each year during broadcasts of the Masters.  Thus, at the same time researchers and environmental groups have expressed concerns over the chemicals that have come to replace the likes of DDT, Augusta National Syndrome is an issue to the extent that it rationalises the heavy use of water and pesticides in golf course maintenance. As golf returns “home” to St Andrews, we would do well to remember that broccoli – even cauliflower – is a long way from extreme muddiness. The standards we have made for golf are relatively new.  However there are alternative visions of environmentalism in the industry that go even further beyond the Audubon-certified way of being “green”. In our work on the greening of golf, we looked at the (admittedly sluggish) emergence of “organic golf”, a style of course management that often involves eschewing synthetic chemicals completely. We do not romanticise organic golf. It has many struggles and problems of its own, not least its occupation of land for a leisure activity not accessible to everyone. But the organic golf practitioners we have spoken with have been open to blemishes here and there, even if they still hoped to provide a challenging and rewarding experience for golfers in the end. Thus, organic golf holds the potential to subtly change the perception of how a “proper” golf course should appear. It is one thing to go from “pit to prince”. It would be another thing entirely to presume the prince’s appearance need not be perfect."
"British populations of butterflies, including some of the most familiar countryside species, will begin disappearing within decades unless we take action. This is the alarming conclusion of new research published in Nature Climate Change by a group of British scientists.  Butterflies are naturally sun-loving creatures, and with the UK sat on the northern edge of many species’ ranges, previous studies have forecast possible benefits to UK populations from a warming climate. However, as the climate changes, extreme weather events including droughts are expected to become more common. Droughts can be a problem for butterflies, especially if they harm the plants upon which caterpillars rely for food. With less food around, populations can crash, and may take several years to recover to pre-drought levels. The new study used models to predict the frequency of droughts like that of 1995 under different scenarios of greenhouse gas emissions, and examined factors affecting the likelihood and speed of recovery for populations of six species of butterflies that experienced population collapses after the 1995 drought.  While droughts as severe as 1995 have previously only occurred as little as once in 200 years, allowing plenty of time for butterfly populations to recover, the study found that they may become far more frequent. If greenhouse gas emissions continue to increase at current rates, they might even occur on average once every 1.29 years (effectively every summer). Under “business as usual” scenarios, the research forecasts the widespread extinction of local colonies of butterflies as soon as 2050. So, what can be done to conserve our butterflies? Here is my simple, three-step guide: Clearly, reducing the impacts of climate change will be important. Delegates from around the globe will meet in Paris later this year for the 2015 UN Climate Change Conference, hoping to reach the first deal on reducing emissions since Kyoto 1992. Under the study’s best case scenario for emissions, 1995-like droughts might occur only every six to seven years, giving butterfly populations much more opportunity to recover in between. Ensuring the availability of suitable habitats for butterflies can also make a big contribution. The researchers found butterfly populations were more likely to persist through droughts and recovered more rapidly if situated in areas with larger, less fragmented patches of semi-natural habitat, such as grassland. Larger areas are likely to contain more abundant and diverse food-plants, helping more species of butterfly, and can also better resist edge effects associated with drought, such as moisture loss from woodland. Highly fragmented habitats have more edge relative to their area, and therefore experience more severe edge effects. Well connected habitats, through which butterflies can easily mingle and locate breeding sites, could add decades on to the survival of certain populations as the climate warms.  While large-scale habitat management programmes, such as the establishment of nature reserves, are an important means to preserve semi-natural habitat, the restoration of connectivity is where butterfly enthusiasts can help at home.  According to Richard Fox from the charity Butterfly Conservation, many drought-prone species can be encouraged to breed in gardens by leaving grass to grow long. “You don’t have to let your prize lawn go to rack and ruin, you can just leave a strip along the fence”, Fox told me me. Depending on how much is left, this could provide breeding habitat for species including the speckled wood, ringlet, meadow brown and large skipper. Meanwhile, other species can be helped by choosing garden flowers with care, or letting them choose themselves. “Large and small white will breed on Nasturtiums and love to nectar on flowers like buddleia and perennial wallflower,” advises Fox, while “green-veined white caterpillars can feed on lots of weeds, so not being too tidy can help”. If you have a garden, why not plant some butterfly-friendly plants of your own?  So while butterfly lovers will be among those waiting with bated breath for the outcome of the Paris summit, they may also be able to help closer to home. Habitat availability will be vital to the survival of butterflies when drought strikes, and by providing such refuges in back gardens anybody can help them survive and flourish."
nan
"Indonesia carried out cloud seeding to try to prevent further rainfall over the capital, Jakarta, and surrounding areas as the death toll reached 47 on Saturday amid flash floods and landslides.  Two small planes had earlier been readied to drop sodium chloride to break up potential rain clouds in the skies above the Sunda Strait, Indonesia’s technology agency said. Tens of thousands of Indonesians were crammed in emergency shelters waiting for floodwaters to recede in and around Jakarta after the massive new year’s flooding, officials said. Monsoon rains and rising rivers submerged a dozen districts in greater Jakarta and caused landslides in the Bogor and Depok districts on the city’s outskirts, as well as in neighbouring Lebak, which buried a dozen people. National Disaster Mitigation Agency spokesman Agus Wibowo said the fatalities included those who had drowned or been electrocuted since rivers broke their banks early on Wednesday after extreme torrential rains throughout new year’s eve. Three elderly people died of hypothermia.It was the worst flooding since 2007, when 80 people were killed over 10 days. “The waters came very fast, suddenly everything in my house was swept away,” said Dian Puspitasari, a mother of two. Four days after the region of 30 million people was struck by flash floods, waters have receded in many middle-class districts but conditions remained grim in narrow riverside alleys where the city’s poor live. Wibowo said about 397,000 people had sought refuge in shelters across the greater metropolitan area. Those returning to their homes found streets covered in mud and debris. Cars that had been parked in driveways were swept away, landing upside down in parks or piled up in narrow alleys. Sidewalks were strewn with sandals, pots and pans and old photographs. Authorities took advantage of the receding waters to clear away mud and remove piles of wet garbage from the streets. Cloud seeding or shooting salt flares into clouds in an attempt to trigger rainfall is often used in Indonesia to put out forest fires during the dry season. Authorities on Thursday used hundreds of pumps to suck water out of residential areas and public infrastructure like railways. President Joko Widodo has blamed delays in flood control infrastructure projects for the disaster. Widodo announced in 2019 that he will move Indonesia’s capital to East Kalimantan province on Borneo island to reduce the burden on Jakarta, which is overpopulated and sinking. Associated Press and Reuters contributed to this report"
"​It’s hard to know what to write in the midst of a national apocalypse.​​ I’m like most Australians, feeling every shade of human emotion each day as we see this living tragedy unfold before us. Each morning comes with a dull thud as we wake to the awful realisation that the new day could still be worse than the last.  The fear on people’s faces is palpable. It reminds me of Black Saturday. There the horror was quick, although the scars, still deep, remain. Remember those survivors today as the fires of recent weeks reignite the living hell of trauma a decade ago. ​​ Then there’s the helplessness we feel as we sit, watch and wait. Often the best we can do is stay glued to the ABC, ring people we know in harm’s way, and then give to charity. ​​ Then there’s pride in our firefighters, the unsung men and women who, without fanfare train week in week out, for years on end. Although no training can prepare you for war like this. They’re our new Anzacs. In the line of fire, literally, before the nation’s eyes. ​​ Of course there’s anger and rage as well. Much of it justified. Some of it not. Our national government will have much to account for once the current crisis has passed. The uncomfortable truth is the government’s response just doesn’t pass the pub test. It’s been evasive, tepid, tone-deaf and, above all, too late. It’s been conducted as an exercise in “issue management”, rather than a substantive response to one of the worst natural disasters in our history, with every shoulder to the wheel. And the Australian public can spot a fraud at a thousand paces. So in the midst of all this, what can be said that’s in any way productive for the future? ​​First, the feds should be taking their marching orders from the state fire chiefs each day. It’s just not good enough when the New South Wales Rural Fire Service chief says he first heard of the call-out of the army reserve through the media. Canberra’s job is to help provide whatever financial and physical resources firefighters and other emergency services need there and then. And on the question of “who’s going to pay”? I remember it well during the Victorian fires. The answer should simply be: “Whatever it takes. Just get it done.”​​ Second, the National Bushfire Recovery Agency announced on Sunday should be underpinned by national legislation, jointly with the states, and empowered to slice through red tape. There should be a national bushfire appeal – the Black Saturday appeal raised more than $400m – and its disbursement should be coordinated by new agency to avoid waste and duplication. The taxable 13-week disaster recovery allowance should immediately be extended to 26 weeks and be exempted from tax, as it was in Victoria. The disaster relief payment of $1,000 has also lagged inflation, meaning its real value has fallen substantially since 2009. Third, provide proper permanent funding for the nation’s bushfire services. The public will not tolerate any longer a discretionary “top-up” by the feds, or the usual buck passing between the various levels of government. Each brigade needs to be confident of their long-term funding. The formula should be hammered out and rigorously implemented. ​​ Fourth, the nation needs the biggest, best national aerial fire-bombing fleet in the world. We are the driest inhabited continent on Earth. It will get worse. Therefore we need a standing capability the likes of which the world hasn’t seen before. Whenever and wherever a fire breaks out, we then have a fighting chance of containing it at its earliest stages. Bill Shorten was right to take this to the last election. ​​It will cost. There will be accusations of waste if it remains idle for a while. Just like we were accused of waste when we co-funded Adelaide’s desalination plant – until everybody realised we needed it. Fifth, what more warning does Australia need on the absolute imperative of accelerated action on climate change? Not enough it seems for Scott Morrison, who says there will be no change in policy whatsoever. Nor for the high priest of climate change denial himself, Tony Abbott. Indeed, in the midst of the fires, there was Abbott on Israeli radio telling a global audience the real problem for Australia was that we had been taken over by a “climate change cult”! Abbott! He who famously proclaimed climate change was “absolute crap”. The political opportunist who stopped my government imposing a carbon price by toppling Malcolm Turnbull and revoking the deal we’d struck to pass it. The partisan thug who played cheap politics, ridiculing Australian efforts with our partners to broker a global deal at Copenhagen to keep temperatures within 2C. ​The political cynic who ran the biggest fear campaign in recent memory against our carbon price in order to become prime minister in 2013. Yup. The very same Abbott who destroyed Turnbull all over again in 2017 over climate policy – this time the national energy guarantee. So why does Abbott do it? The truth is he doesn’t give a damn about policy. Abbott has always been 100% politics. He’s always seen climate as the perfect political wedge against Labor among working families, deploying fear campaigns based on wildly exaggerated projections about jobs and the cost of living. He’s done the same internally, using it to divide and conquer his moderate opponents in the Liberal party. Pretty tawdry when now we see half the country going up in smoke!​​ But here’s the rub. The Abbott denialist cult has taken over the entire Coalition. It continues under Morrison and, when they oust him soon, it will continue under Peter Dutton. It’s become the battle cry of the far right which now runs the entire conservative show in Canberra. ​​ And yes, before the Murdoch media leap to Abbott’s defence, I know he is a firefighter. Good on him. The problem is most of the fire chiefs just don’t agree with him on the impact of climate change. Nor does the CSIRO. Nor does any credible climate scientist in the world. In Australia, as in America, the conservatives’ strategic partner in climate change denial has been the Murdoch media. Rupert Murdoch, feeling the heat of public opinion, claimed recently there were no climate deniers at News Corp! The Murdochs, senior and junior, must believe the Australian people are total fools. Murdoch’s papers remain a command centre for the entire mission of climate policy obstruction. Just look at their climate coverage over the last four federal elections. In the midst of today’s tragedy, we still see the old denialist trope trotted out that Australia, with only 1.3% of global emissions, can have no influence, and shouldn’t bother trying. ​​What pathetic nonsense. If other middle-sized economies did the same – there are about 20 with a similar share of emissions – that’s a quarter of the global total. We cannot work globally to get the biggest emitters – the US, China and India – to act unless we are also acting to clean up our own backyards. ​​ Our national interest dictates that Australia becomes once again a global climate change leader, not a follower. Unless we lead, and convince others to follow, Australia has a bleak future indeed. ​​ ​​​​​​​​​​​ The Australian people are angry. The Liberals and Nationals are now reaping what they have sown for more than a decade – through climate inaction at home, sabotaging climate negotiations abroad and a continuing pathology of poisonous fear mongering. The melancholy truth is the only policies restraining Australian emissions today were taken under our government a decade ago. Principal among these is our legislated mandatory renewable energy target for 20% of electricity supply to be renewables by 2020. The conservatives said it would destroy the economy. It didn’t. As a result, renewables are now 21%, up from 4% when we started.​​ But this is just the foundation stone of what must now become a bigger, bolder plan of national and international action. I stand by what I said a decade ago: climate change represents the greatest economic, environmental and moral challenge of our time. Moral because it’s about what’s right and wrong for the nation. Moral because it’s about intergenerational justice. The Liberals won’t change on climate. Denial is now their DNA. They may start pretending to care. Scotty from marketing is good at that. But we all know it will be paper thin. That’s why this lot have to go. Before it’s too late for us all. Kevin Rudd is a former Australian prime minister"
"On 3 August 2014, residents of Toledo, Ohio, woke to the news that overnight their water supply had become toxic. They were advised not only to avoid drinking the water, but also touching it – no showers, no baths, not even hand-washing. Boiling the water would only increase its toxicity while drinking it could cause “abnormal liver function, diarrhoea, vomiting, nausea, numbness or dizziness”, read a statement from the City of Toledo, warning residents to “seek medical attention if you feel you have been exposed”.  Toledo sits on the shores of Lake Erie, one of North America’s five great lakes. About half a million residents of the city and surrounding area have relied on Lake Erie for water for hundreds of years. After the news broke on 3 August bottled water quickly vanished in concentric circles around the city. Eventually, a state of emergency was called and the national guard arrived with drinking water. Toledo’s water crisis lasted for nearly three days. But the water wasn’t toxic due to an oil spill or high lead levels, as in Flint, Michigan. Toledo’s water was tainted by something altogether different: an algae bloom.Toledo is not alone. According to scientists, algae blooms are becoming more frequent and more toxic worldwide. A 14-month long algae bloom in Florida, known as the “red tide”, only ended earlier this year, after killing more than 100 manatees, 127 dolphins and 589 sea turtles. Hundreds of tonnes of dead fish also washed ashore. In 2018, there were more than 300 reported incidents of toxic or harmful algae blooms around the world. This year about 130 have been listed on an international database, but that number is expected to increase.Recent reports of a new ‘‘red tide’’ emerging in Florida and more dead wildlife have put the tourist and fishing industries on alert, braced for further devastation. The causes of the blooms vary, and in some cases are never known, but in many parts of the world they are being increasingly linked to climate change and industrialised agriculture. Algae includes everything from micro-algae, like microscopic diatoms, to very large algae, such as seaweed and kelp. Algae are not officially a taxonomic group of creatures (they don’t fit into general groups like plants, animals or fungi), but the name is generally used to describe marine or freshwater species that depend on photosynthesis. An algae bloom occurs when a single member of these species – because of certain conditions – suddenly becomes dominant for a time. Algae are vital to our survival. It’s estimated that at least half of the planet’s oxygen comes from these unsung creatures, who produce it through photosynthesis before releasing it into the water. Algae, like land plants, also sequester carbon dioxide; scientists have explored their potential to draw carbon dioxide out of the atmosphere. They have been used as fertiliser, food sources (such as seaweed), and could be a promising source of biofuel in a more sustainable world. However, some algae blooms can also be harmful – even lethal. Harmful algae bloom (HAB), as scientists have come to describe the phenomenon, often manifest by forming a kind of scum over a body of water that can be green, blue, brown or even red. But others are completely invisible. The problem has become increasingly widespread and the impact can be deadly to marine life. Off the eastern coast of the US, a dinoflagellate – a type of marine plankton named Alexandrium catenella – has the potential to make shellfish lethal. Its appearance routinely shuts down fisheries, crippling local economies. And it’s not just in the US: the same species has shut down mussel farms and recreational collecting of shellfish as far away as New Zealand. Other blooms wipe out marine life. In 2015, a bloom of various dinoflagellates off the coast of South Africa led to low-oxygen conditions, known as eutrophication, killing 200 tonnes of rock lobster. Freshwater blooms, like those in Lake Erie made up of cyanobacteria or blue-green algae, have not only shut down local water sources but have also been blamed for the death of dogs that had been swimming in them. It’s difficult to make generalisations about harmful algae blooms since specific species have different causes and impacts. Scientists have identified about 100 toxic bloom species in the oceans. Dozens of potentially harmful species of cyanobacteria are known to affect bodies of fresh water. During most of the past century, harmful algae blooms were rarely headline news, inspiring little scientific study beyond ecological curiosity. That has changed. Algae blooms are notoriously difficult to predict, but a global monitoring group known as HAEDAT is tracking them across the world as they occur. Harmful algae blooms, such as the one that hit Toledo’s water supply in 2014, are becoming more common and more toxic – and scientists say humans are to blame. “There’s no question that the HAB problem is a major global issue, and it is growing,” said Donald Anderson, director of the US National Office for Harmful Algal Blooms and a lab director at the Woods Hole Oceanographic Institute. “We also have more toxins, more toxic species, more areas and resources affected, and higher economic losses.”  The toxic bloom that took over Lake Erie in 2014 was formed by a cyanobacteria known as Microcystis Aeruginosa, for which farming is at least partly to blame. “You have people that still to this day will only use bottled water,” says Dr Timothy Davis, an expert in plankton ecology at Bowling Green University, five years after the water crisis and even after Toledo spent $132 million (£101 million) on improving its water treatment plant to handle the blue-green algae. Lake Erie, the shallowest of North America’s Great Lakes, has seen such events in the past. During the 1950s and 60s algae blooms were common, most likely, say researchers, due to poor domestic and industrial wastewater treatment. “At one point, Lake Erie was considered a dead lake,” Davis says. But by the early 1970s, the “dead lake” was resurrected, due to new regulations from the Clean Water Act and the Great Lakes Water Quality Agreement that capped phosphorus loads into the lake at 11,000 tonnes. Phosphorus provides nutrients to plants and is commonly found in manure and produced for fertiliser. Then in the late-1990s, blooms began to reappear. A cyanobacteria bloom requires two things: nutrients and heat. In the case of Lake Erie, nearby farms have become increasingly reliant on large inputs of synthetic fertiliser. “We went from agriculture that was small farms [and a] variety of crops to larger commercial farms that were harvested for essentially two row crops, corn and soya beans,” says Davis. Today, corn and soya beans are Ohio’s top crops. Employing more fertiliser to feed a global market, the farms’ excess phosphorus and nitrogen, another plant nutrient, washed out during storms and into the river and streams that feed Lake Erie. About 80% of the nutrients running into Lake Erie are from sources around the Maumee River, which in this case means agricultural runoff from the surrounding farmland. “If you have an agricultural system where the farmer can only survive by polluting Lake Erie, then there’s something fundamentally wrong with that system,” says Dr Thomas Bridgeman, director of the Lake Erie Center. Since the 1990s, Lake Erie has seen a bloom every year – and they appear to be lasting longer and getting larger. This year’s bloom in Lake Erie was the fifth largest since 2002 – when monitoring began in earnest. It was 620 square miles at its largest after growing throughout August, before dissipating in September. Meanwhile, climate change has heated up our planet substantially. Nearby Lake Superior, the most northerly of the Great Lakes and the world’s largest, has had its first documented cyanobacteria blooms over the past decade. Before climate change, the lake simply would have been too cold for a long-lasting bloom. It’s now almost a certainty that blooms will continue to appear every summer, say researchers, unless Ohio changes its agricultural practices and the global community finally tackles the climate crisis. “We have to look around and say, ‘Look, what do we grow here?’” says Bridgeman. “We grow corn and soya beans. Where does the corn go? It goes into our gas tanks. Where do the soya beans go? They go to China, they go to hogs. Is that really what we want to be doing with our watershed?” Algal blooms are also becoming more common and severe in many parts of our oceans, harming wildlife and posing potentially dangerous health impacts for local communities. Scientists say the “red tide” that stuck around the Florida coast from 2017 through to this year may now be a semi-normal part of the ecosystem. These blooms are pumping poison into the air, known as brevetoxin, which may be harmful to humans if inhaled. Anyone breathing it in can suffer from uncontrollable coughing and a sore throat. “It doesn’t make for a pleasant day at the beach,” says Malcolm McFarland, a researcher into algae blooms with the Harbor Branch Oceanographic Institute in Fort Pierce, Florida. It may have long-term health implications as well – one study found that brevetoxin attacked the DNA of lungs in rats, but further research is needed to understand the impact on human health. Scientists are less certain about the causes of these red tide marine blooms, but both nutrient runoff and climate change may play a role. “The red tide seems to initiate and peak in the rainy season when runoff from the land is highest, and nutrient inputs to freshwater and coastal water bodies spike,” says McFarland. Meanwhile, on the other side of the north American continent, a different red tide is attacking a different species: California is seeing more sick sea lions taken in by rescue centres; pups and adults are dying. Scientists believe they are suffering from eating fish tainted by Pseudo-nitzschia australis algae. The highly toxic algae are fatal at high doses, both to sea lions and humans. Unlike Florida’s red tides, those in California appear to be a very recent arrival. Until the turn of the millennium, large-scale toxic blooms were rare off the coast of California. Then something changed. “From [2000] forward, we had a very significant bloom every single year with ecosystem impacts in California, and that has never stopped. Not only that, it seemed as though things were getting more and more toxic,” says Clarissa Anderson, the executive director at Southern California Coastal Ocean Observing System, nothing that in less than 20 years of research, scientists have seen toxin numbers multiply by 200 – from 500 to 100,000 nanograms per litre of sea water. Anderson says the current best working theory is that increasing carbon sequestration by the oceans – due to the huge increase in greenhouse gas emissions since the industrial revolution – is behind the sudden regularity of these deadly blooms and an increase in their toxicity. She says the study of these events and their toxins is so new that there may be incidents of illness from eating affected fish or shellfish that are misdiagnosed because these poisons are not on the radar of many health organisations. Europe has had its own experience of deadly algae blooms that now threaten the future of its fisheries. Last year, the Baltic Sea experienced a bloom so large it could have encompassed Manhattan, and it closed beaches from Finland to Poland. Finland has been systematically sampling its area of the Baltic since 1979, giving us a clearer idea of the spread and growth of the problem, and what’s to blame. In that time, blooms have become larger and longer-lasting, creating dead zones and depleting Baltic fisheries. Like the example in Lake Erie, the Baltic bloom is caused by an influx of nutrients from agriculture and warming waters.Scientists are regularly tracking nutrient loads from Finland’s rivers into the sea. Data from 2014 in the HELCOM Pollution Load Compilation database, the best currently available, found that more than three-quarters of the nutrient load coming into the Archipelago Sea is from agriculture. The number is surprisingly similar to the proportion coming from industrialised agriculture in Ohio. The Baltic is a brackish water body, thus supporting blooms typical of both fresh and salt water. But, as in Lake Erie, of real concern are cyanobacteria: several species have been known to produce blooms here. Below the sea’s surface there has been a decline in the more nutritious phytoplankton – and food for fish – and an increase in the potentially toxic species in the more southerly parts of the sea since the early 1980s.Milder winters and increased rainfall pushing more nutrients into the sea, along with higher surface water temperatures – all due to the climate crisis – are also exacerbating factors, say researchers. Blooms usually begin in July and disappear by August or September. But last year a species particularly resistant to coldremained until November. “The ice was blue-green because of the cyanobacteria under it,” says Sirpa Lehtinen, an expert on plankton for the Marine Research Centre with the Finnish Environmental Institute, who adds that scientists are still trying to work out what this all means for the marine ecosystem, and whether fisheries in the Baltic are in serious long-term peril. So how can we solve a problem like algae? The answer, says Davis, will be part-regional, part-global solutions. For Lake Erie, it will require agricultural changes – including regulations to reduce the nutrient load – and tackling the climate crisis. But solutions elsewhere may be different, for example, blooms in developing countries might require better wastewater treatment. The 2014 water crisis in Ohio forced the issue politically which hasn’t happened in many other places. Governor Mike DeWine recently announced an initiative called H2Ohio, which is expected to include hundreds of millions of dollars for Lake Erie and other Ohio water bodies over the next 10 years. However, scientists say this is not enough. “It’s going to take a lot more money and a lot more political will than what’s happening right now,” says Bridgeman. At the Ohio Department of Agriculture,director Dorothy Pelanda said the department was primarily looking at voluntary programmes based on marketing and education for potential solutions such as cover crops and smarter use of fertiliser. In 2014, Ohio passed new regulations on fertiliser use for farms near the lake: such as not spreading before a storm or on frozen fields. “We know from science that there is not one solution to every farm … It’s about education, it’s about being sensitive to what works, what doesn’t work,” she said. She’s hoping to provide increased access for farmers to use high-tech, but often expensive, equipment that can give them a better idea of what parts of their land may need fertiliser and how much. Pelanda said she’s also seen interest in diversifying crops beyond corn and soya beans, to grapes, chestnuts and maple sugar. Asked if voluntary programmes will go far enough, Pelanda says: “That’s our challenge. We have to get beyond. We’re doing these things … but we’re not doing enough of these things. We need to really increase the voluntary adoption of these practices.” Others are more sceptical of voluntary approaches. “We have a long history in this country of a farmer does what he wants on his land. You can choose to take advantage of a programme or something, but you can also choose not to,” says Bridgeman, who believes local and federal governments can no longer afford to ignore the climate emergency. “We need to do something about climate change and we’re either going to be paying for it by reducing greenhouse gases or we’re going to be paying for it by additional treatment of water,” says Bridgeman, adding that most of the blooms around the world have a human element to them. One thing is certain. Algae blooms aren’t going away but are yet another sign – like ocean acidification, vanishing Arctic sea ice, and mass extinction of the Anthropocene – “of an ecosystem that is out of balance,” says McFarland. • This article was amended on 8 January 2020 to remove a reference to “toxic cryptophytes”. Cryptophytes are not toxic. Also, the text was changed to clarify that baltic bloom in Lake Erie is caused by a range of nutrients, not just nitrogen from farming."
nan
"
Share this...FacebookTwitterMid-Ocean Seismicity Portends Global Cooling

Image Source: Viterito, 2016
Since the peak of the 2016 El Niño warming event, global temperatures have fallen by a little more than 0.3°C.

Image Source: WoodForTrees.org
According to a new paper published in Environment Pollution and Climate Change by Dr. Arthur Viterito, changes in seismic activity from the Earth’s high geothermal flux areas (HGFA) are “a significant predictor of global temperatures (p<0.05) but CO2 is not (p>0.05) (Table 1).”

An Overview Of The HGFA→Climate Link
Last year, Dr. Viterito succinctly explained the processes connecting high geothermal heat flux areas to the climate system.
 Viterito, 2017
“Namely, increased seismic activity in the HGFA (i.e., the mid-ocean’s spreading zones) serves as a proxy indicator of higher geothermal flux in these regions. The HGFA include the Mid-Atlantic Ridge, the East Pacific Rise, the West Chile Rise, the Ridges of the Indian Ocean, and the Ridges of the Antarctic/Southern Ocean.”
“This additional mid-ocean heating causes an acceleration of oceanic overturning and thermobaric convection, resulting in higher ocean temperatures and greater heat transport into the Arctic. This manifests itself as an anomaly known as the “Arctic Amplification,” where the Arctic warms to a much greater degree than the rest of the globe.”
“[J]umps in HGFA seismic activity can amplify an El Niño event, a phenomenon referred to as a SIENA or a Seismically Induced El Niño Amplification.  Accurately predicting two of these amplified El Niños (i.e., the 2015/2016 event plus the1997/1998 episode) is an important outcome of the HGFA seismicity/temperature relationship.”

New Paper: By 2019, Global Temps Will Drop To Mid-1990s Levels
In a new paper, Dr. Viterito has continued using seismic pattern analysis to formulate a very precise near-term temperature prediction: Global temperatures will continue their ongoing descent to about -0.47 °C below the 2016 peak by the year 2019.
Viterito, 2018
“A striking development for this experiment is that 2017 marks the first three-year decline in HGFA seismic activity since 1979 (Figure 2).  Furthermore, the 2017 HGFA seismic count is 49% lower than the study period’s peak frequency in 2014, the year of the last “Super El Niño”. When viewed within the context of the entire time series, the 2017 dropoff mirrors the jump in HGFA seismic activity experienced in 1995, albeit in the opposite direction. The 1995 “tipping point” was significant as global temperatures spiked in lockstep two years later, followed by a 21-year ‘plateau’ in both global temperatures and HGFA seismicity, a.k.a. ‘The Pause’.”

“It is important to note that a two-year lag is factored into the analysis: The 1979 HGFA seismic frequency is paired with the 1981 global temperature, the 1980 HGFA frequency is paired with the 1982 temperature, and so forth, for the entire series.”
“It is reasonable to conclude that this recent “gapping down” may be a tipping point towards cooler global temperatures. Using HGFAseismic frequencies as the sole predictor of global temperatures going forward, there is a 95% probability that global temperatures in 2019 will decline by 0.47°C ± 0.21°C from their 2016 peak. In other words, there is a 95% probability that 2019 temperatures will drop to levels not seen since the mid-1990s.”

Image Source (Top): WoodForTrees
Share this...FacebookTwitter "
"We begin a new decade swamped by visions of our planet in peril. Australia is in flames; Greenland and Antarctic ice shelves are crumbling; thousands of species face extinction, and millions of humans are at risk of losing their homes as sea levels rise and deserts spread. At the same time, amounts of carbon dioxide in the atmosphere – the cause of the global heating that threatens to ravage our world – continue to increase unabated. Our future is being threatened in a manner that would have seemed unthinkable only a couple of decades ago.  It may therefore seem odd at this time for scientists to look away from our afflicted world and to take a renewed interest in issues that lie beyond Earth – in robot probes and vehicles that will take human beings beyond our atmosphere to the moon, Mars and the rest of the solar system. Yet this renewed interest in extraterrestrial matters is real as we make clear in our survey of forthcoming space missions. Not since the heyday of the space race to the moon in the 60s has so much space activity been planned, though this time missions will not be dominated by America and Russia but will also involve China, India and Japan as well as private companies such as SpaceX and Boeing, which plan to launch their own manned spaceships. For good measure, the European Space Agency, of which Britain is a major, active participant, has also decided over the past few weeks to step up its commitment to space exploration with a €12.5bn (£10.7bn) package of projects. Some of these missions will have a bearing on our planet’s present plight, of course. For example, Europe is planning a new fleet of satellites that will monitor carbon dioxide emissions at every point on Earth and so create the first global system for tracking key polluters. Many other observation satellites are planned and should help scientists contain the ecological threats of global heating. However, there is another aspect of interplanetary travel that is relevant to the woes afflicting Earth. From space, we get a proper appreciation of our world and its vulnerability. Until we sent probes to Mars and Venus, we thought our nearest planetary siblings could easily support life. Instead, spacecraft showed that Venus is an acid-drenched, scorching vision of hell while neighbouring Mars was found to have lost most its atmosphere aeons ago. Exactly why these worlds went wrong, in terms of their abilities to support life, is not clear but the matter certainly merits further research. The special perspective of our world that is provided by space missions was summed up by the late astronomer Carl Sagan when he described an image of Earth that had been beamed back by the Voyager 1 probe from a distance of 4bn miles in 1990. In that photograph, our world appeared as a tiny, single point of light. “That’s here. That’s home. That’s us,” said Sagan of this pale blue dot. “Our posturing, our imagined self-importance, the delusion that we have some privileged position in the universe, are challenged by this point of pale light. Our planet is a lonely speck in the great enveloping cosmic dark. In our obscurity, in all this vastness, there is no hint that help will come from elsewhere to save us from ourselves.” And that, ultimately, is what space exploration really tells us. It says there is no Planet B and no chance of starting over again if we continue to make a mess of this world. The view from above shows Earth is precious and needs a lot more care and attention than it is getting at present."
"Just hours after saying it was “still the plan” to go to India later this month for trade and defence talks, Scott Morrison now says he is “inclined not to proceed” with the visit. Australia’s coal exports were expected to feature heavily on the Indian trip agenda, but shortly after telling media he still planned on attending, depending on the fire conditions, Morrison reversed course and said he now did not believe he would go. “The national security committee is going to hook up in the morning on this,” he said. “I’m inclined not to proceed on that visit. There are issues I need to resolve formally when working through issues of that nature. That is my inclination on that issue. We’ll make a further announcement and arrangement on that accordingly.” Morrison was due to travel to India on 13 January, before heading on to Japan during the five-day trip. Speaking to Melbourne radio 3AW on Friday morning, Morrison said it was an “important meeting”, and that the plan to attend was “still in place.” “But, you know, when you are dealing with these issues, you need to consider the relative merits of the choices,” he said. The prime minister announced he had accepted Indian prime minister Narendra Modi’s invitation to visit back in October, where he was also due to deliver the inaugural Raisina Dialogue address, which aims to discuss the biggest challenges to the global economy. For Australia, one of those challenges is its fractious relationship with China, with coal exports seen as one of the flashpoints. Australia has increasingly looked to India as a potential buttress against any economic fallout with China, with Morrison making strengthening his relationship with Modi one of his priorities since becoming prime minister. The Coalition has also been an unwavering supporter of the Adani Carmichael mine in central Queensland, with minister for resources and northern Australia Matt Canavan a vocal supporter. Canavan attended a lunch with Adani executives  during an official visit to Calcutta in August last year. The government has often pointed to the 1.3% of global carbon emissions Australia is responsible for, when answering criticisms over its climate policies. A report by the Australian Conservation Foundation, released mid last year, found Australia was responsible for at least 5% of global greenhouse gas emissions, if the pollution from the nation’s fossil fuel exports was included. Once the pollution from proposed projects was factored in, which included the Adani mine, that number had the potential to jump to 17% by 2030. Morrison has held firm to his view the government had its climate policy settings right, despite admitting the link between climate change and worsening bushfire seasons. “Let me be clear to the Australian people: our emissions reductions policies will both protect our environment and seek to reduce the risks and hazards that we are seeing today and at the same time, it will seek to ensure the viability of people’s jobs and their livelihoods all around the country,” he said on Thursday. “What we will do is ensure that our policies remain sensible, that they don’t move towards either extreme and stay focused on what Australians need for a vibrant and viable economy, as well as a vibrant and sustainable environment. Getting the balance right is what Australia, I think, has always been able to achieve.” The Labor leader, Anthony Albanese, who has also been supportive of Australia’s coal industry, said the decision of whether to go to India or not was one for the prime minister. “The prime minister will have to weigh up whether it’s appropriate for him to go or not,” he said. Albanese said he believed people were now seeing the warnings scientists had issued about the worsening impacts climate change would wreak against Australia, and wanted action. “One of the reasons why we have seen, I think, some frustration expressed by people on the ground, they don’t want to be told it’s a natural disaster,” he said. “Yes, Australia’s had natural disasters in the past. We haven’t, in my lifetime, had people on beaches waiting to be evacuated in life jackets, sending boats out to sea like it’s a peacetime version of something that we have seen during wartime. We have not seen that. “This is not business as usual. And it requires national leadership and response. This is a national emergency and it’s important that the response be appropriate to the scale of this emergency.”"
"No doubt, you heard the good news. Barack Obama has announced the US is pushing through plans to reduce emissions of greenhouse gases. Rejoice! Rejoice! We’ve got this climate problem licked – hurrah! Hold the champagne – and not just because it’s full of bubbles of carbon dioxide – while we do a reality check. This is a distinctly underwhelming development. Let’s pick apart the spin from the reality. First, the way the story has been told – the US commits to a 32% reduction in emissions of greenhouse gases by 2030. This is being pushed through by tightening the rules governed by the Environmental Protection Agency (EPA) – a federal agency that the US president can instruct, without the need to get past those pesky filibusterers in the dysfunctional, Republican-dominated houses of Congress. The EPA is confident that its rules have a firm legal footing and will be able to withstand the inevitable court challenges.  The effect of the rules will be to clobber the production of electricity using coal. This is certainly “a good thing”. Quite apart from coal’s high carbon-intensity as a means of producing power, it is dirty in other ways – resulting in pollution that is harmful to human health as well as to the environment. With this commitment, the US can enter the climate negotiations in Paris with its head held high and can push for a global deal to head off dangerous climate change. Whoo-hoo! The reality – it’s a development that is both fragile and feeble. Fragile, because unless every occupant of the White House between now and 2030 is a Democrat, it can be unpicked. Remember the bit about the EPA being a federal agency that the US president can instruct? Well, if the president happens to be a climate-denying Republican (the two words are almost, but not completely, interchangeable), he or she could countermand the previous instruction. Of course, the ruling now will inform business decisions and will have a long-lasting effect, regardless of whether the rules are subsequently reversed, but believing that this announcement sets in stone the target of a 32% reduction in emissions requires a degree of optimism that lies somewhere between the heroic and the delusional. It’s feeble too. A 32% reduction by 2030 sounds quite impressive until you realise it is baselined on 2005 figures. By 2013 (the latest data available) it had already fallen by 15% so the rate of improvement required in the next 15 years is actually slower than what has already been achieved. From 2005-2013, emissions fell at a rate of 2.0% per year – to meet the commitment, emissions would need to fall by just 1.3% per year between 2013 and 2030. And the 32% reduction figure only relates to the emissions from power generation, which makes up less than a third of total US emissions. How does the rate of committed reductions compare with what is actually required to achieve temperature rises of less than 2°C above pre-industrial levels? According to trillionthtonne.org – a website that tracks these things – to have a better than 50% chance of avoiding such dangerous climate change would require emissions to decrease by more than 2.6% per year. For the rest of time. Globally. Not that the US should come in for special criticism – the commitments from the EU and from China are similarly insufficient to head off the threat of dangerous climate change. So why hasn’t this been reported? I think what is going on here is partisanship and a well-intentioned desire to boost the prospects of a meaningful deal in Paris. Climate-denying Republicans hate this plan (of course), therefore all good climate realists see it as a triumph. But it is a tiny, tiny step in the right direction and climatically immaterial. Ah yes, you say, but it’s politically important – the world’s hegemonic power has made a commitment, and that creates a foundation upon which greater progress can be made. Let’s not be pessimistic – this could be the start of a global deal. Well, this emperor has no clothes. The pronouncement reminds me of the words of Neville Chamberlain on his return from the Munich Conference in 1938: “I believe it is ‘peace for our time’. Go home and get a nice quiet sleep.”"
"The prime minister, Scott Morrison, has announced at least $2bn for bushfire recovery, as the government steps away from its pledge to deliver a budget surplus amid the ongoing crisis. Warning that the fires would keep burning over the coming months, Morrison said further government funds may yet be forthcoming as the economic toll from the horror fire season continued to rise.  “The fires are still burning, and they will be burning for months to come,” Morrison said. “If further funds are required, further funds will be provided.” He said that across government “significant and massive” financial commitments were being made, with the final cost likely to rival the $5.6bn paid out in disaster recovery assistance over six years following cyclone Yasi and the Brisbane floods. After meeting on Monday morning, cabinet signed off on an initial $2bn for a national bushfire recovery fund to be used to support the rebuilding of community infrastructure and to help affected farmers and businesses. The fund will be overseen by the newly established National Bushfire Recovery Agency, led by the former Australian Federal Police commissioner Andrew Colvin. This would include funding for roads and telecommunications, the restocking and replenishing of livestock for primary producers, mental health support, funding to attract tourists back to the regions and environmental restoration. The $2bn is in addition to disaster recovery payments and allowances for those affected, which have so far totalled more than $100m. The government also announced 20 Service Australia pop-ups would be set up to help people access government disaster payments, while mutual obligation and debt recovery for welfare payments in nominated areas would also be suspended. “Today’s cabinet was one of great resolve; it was one where we stood together and said, ‘whatever it takes, whatever it costs, we will ensure the resilience and future of this country’, and we will do it by investing in the work that needs to be done,” Morrison said. When asked if the economic impact of the fires could jeopardise the $5bn surplus forecast for the 2019-20 year – the first in 12 years and a key election promise – Morrison said the government was not focused on the financial cost. “The surplus is of no focus for me, what matters to me is the human cost and meeting whatever costs we need to meet,” he said. “I can tell you this: being in the position of strength we are in now enables us to give what is one of the most significant, if not most significant, response to a crisis of this kind the country has seen.” Morrison argued that the government was putting the surplus “straight to work” to meet the needs of Australians, without having to put in place extra levies or make cuts. Does climate change cause bushfires? The link between rising greenhouse gas emissions and increased bushfire risk is complex but, according to major science agencies, clear. Climate change does not create bushfires, but it can and does make them worse. A number of factors contribute to bushfire risk, including temperature, fuel load, dryness, wind speed and humidity.  What is the evidence on rising temperatures?  The Bureau of Meteorology and the CSIRO say Australia has warmed by 1C since 1910 and temperatures will increase in the future. The Intergovernmental Panel on Climate Change says it is extremely likely increased atmospheric concentrations of greenhouse gases since the mid-20th century is the main reason it is getting hotter. The Bushfire and Natural Hazards research centre says the variability of normal events sits on top of that. Warmer weather increases the number of days each year on which there is high or extreme bushfire risk. What other effects do carbon emissions have? Dry fuel load - the amount of forest and scrub available to burn - has been linked to rising emissions. Under the right conditions, carbon dioxide acts as a kind of fertiliser that increases plant growth.  So is climate change making everything dryer?  Dryness is more complicated. Complex computer models have not found a consistent climate change signal linked to rising CO2 in the decline in rain that has produced the current eastern Australian drought. But higher temperatures accelerate evaporation. They also extend the growing season for vegetation in many regions, leading to greater transpiration (the process by which water is drawn from the soil and evaporated from plant leaves and flowers). The result is that soils, vegetation and the air may be drier than they would have been with the same amount of rainfall in the past. What do recent weather patterns show? The year coming into the 2019-20 summer has been unusually warm and dry for large parts of Australia. Above average temperatures now occur most years and 2019 has been the fifth driest start to the year on record, and the driest since 1970. Is arson a factor in this year's extreme bushfires? Not a significant one. Two pieces of disinformation, that an “arson emergency”, rather than climate change, is behind the bushfires, and that “greenies” are preventing firefighters from reducing fuel loads in the Australian bush have spread across social media. They have found their way into major news outlets, the mouths of government MPs, and across the globe to Donald Trump Jr and prominent right-wing conspiracy theorists. NSW’s Rural Fire Service has said the major cause of ignition during the crisis has been dry lightning. Victoria police say they do not believe arson had a role in any of the destructive fires this summer. The RFS has also contradicted claims that environmentalists have been holding up hazard reduction work. The treasurer, Josh Frydenberg, said it was “too early to tell” what the full economic cost of the bushfires would be, but emphasised the government had never seen the surplus as an “end in itself”, despite it being a prominent feature of this year’s budget. Frydenberg said he would be meeting with the Australian Insurance Council, regulators and company chiefs on Tuesday to ensure insurance payments flowed to affected individuals as quickly as possible, with 6,000 payments totalling almost $400m already paid out. The treasurer also said the Australian Taxation Office had agreed to a two-month deferral for the tax obligations of people living in fire-affected areas, and banks were also assisting. “People should not be concerned about their tax affairs at this time,” he said. Earlier, Greg Mullins, who chairs the Emergency Leaders for Climate Change group, welcomed extra resources from the federal government, but said they had been snubbed when a request was first made in April. “It’s great to see things finally moving but I hope in the future this government will learn to listen to people on the front line,” Mullins said. He also criticised the government’s inaction on climate change, saying it was a “load of rubbish” that the Coalition was taking strong action, with its ability to meet the Paris emission reduction targets based on its earlier “weak” Kyoto targets. “I worry for my grandchildren, their grandchildren. If this is how it is now, this is driven by climate change, imagine what future generations are up against.” Morrison was again asked on Monday about the Coalition’s climate change policies, which the former Liberal deputy leader Julie Bishop had criticised for lacking in global leadership. “We should be showing leadership on the issue of climate change. I attended a number of international conferences and countries do look to Australia for direction, for guidance and leadership. And I believe we should be showing leadership on the issue of climate change,” Bishop told Nine’s Today show. Morrison said his focus was on the $2bn package. “The government will continue to work to meet and beat the commitments we have made for emission reductions,” Morrison said, emphasising that Bishop was part of the cabinet that signed off on the Coalition’s policy. The opposition leader, Anthony Albanese, supported the funding for the recovery agency, saying Labor had been calling for greater federal assistance. “It’s good that the government is now making a number of announcements that we have argued for, including the need for a national response, including the economic compensation for volunteer firefighters, including the upgrade of our aerial firefighting capacity, and the increased use of the defence force,” Albanese said."
"
Share this...FacebookTwitterNote: This post will remain an extra day…
=======================================
More than 70 recent scientific publications show that there is absolutely nothing unusual about the magnitude and rapidity of today’s sea level changes. These academically peer-reviewed papers show that sea levels were on average 2 meters higher earlier in the Holocene than they are today.
Before the advent of the industrial revolution in the late 18th to early 19th centuries, carbon dioxide (CO2) concentrations hovered between 260 to 280 parts per million (ppm).

Within the last century, atmospheric CO2 concentrations have risen dramatically.  Just recently they eclipsed 400 ppm.
Scientists like Dr. James Hansen have concluded that pre-industrial CO2 levels were climatically ideal.  Though less optimal, atmospheric CO2 concentrations up to 350 ppm have been characterized as climatically “safe”.  However, CO2 concentrations above 350 ppm are thought to be dangerous to the Earth system.  It is believed that such “high” concentrations could lead to rapid warming, glacier and ice sheet melt, and a harrowing sea level rise of 10 feet within 50 years.
To reach those catastrophic levels (10 feet within 50 years) predicted by proponents of sea level rise alarmism, the current “anthropogenic” change rate of +0.14 of a centimeter per year (since 1958) will need to immediately explode into +6.1 centimeters  per year.  The likelihood of this happening is remote, especially considering Greenland and Antarctica combined only contributed a grand total of 1.54 cm since 1958 (Frederiske et al., 2018).
70+ Papers: Sea Levels 2+ m Higher 9,000-4,000
Years Ago While CO2 Levels Were ‘Safe’ (265 ppm)
(Click the link above or at the right side bar)
• Are Modern ‘Anthropogenic’ Sea Levels Rising At An Unprecedented Rate?  No.
Despite the surge in CO2 concentrations since 1900, the UN’s Intergovernmental Panel on Climate Change (IPCC) has concluded that global sea levels only rose by an average of 1.7 mm/yr during the entire 1901-2010 period, which is a rate of just 0.17 of a meter per century.
During the 1958 to 2014 period, when CO2 emissions rose dramatically, a recent analysis revealed that the rate of sea level rise slowed to between 1.3 mm/yr to 1.5 mm/yr, or just 0.14 of a meter per century.
Frederiske et al.,2018  “Anthropogenic” Global Sea Level Rise Rate (1958-2014): +0.14 of a meter per century
“For the first time, it is shown that for most basins the reconstructed sea level trend and acceleration can be explained by the sum of contributors, as well as a large part of the decadal variability. The global-mean sea level reconstruction shows a trend of 1.5 ± 0.2mm yr−1 over 1958–2014 (1σ), compared to 1.3 ± 0.1 mm yr−1 for the sum of contributors.”
In the past few thousand years, in contrast, sea levels in some regions rose and fell at rates of + or – 0.5 to 1.1 meters per century., which is 4 to 7 times greater than the change since 1958.
Hansen et al., 2016
“Continuous record of Holocene sea-level changes … (4900 years BP to present). … The curve reveals eight centennial sea-level oscillations of 0.5-1.1 m superimposed on the general trend of the RSL [relative sea level] curve.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




•Other regions have also undergone profound sea level oscillations in the last few thousand years that far exceed modern changes.



Image Sources: Bracco et al., 2014   Whitfield et al., 2017    Strachan et al., 2014 
  Hein et al., 2014    Miguel et al., 2018
•Modern changes aren’t even detectable on graphs of long-term sea level trends.
  

Image Sources: Dura et al., 2016   Bradley et al., 2016
 Scheffers et al., 2012  Kane et al., 2017
 • ~15,000 – 11,000 Years Ago, Sea Levels Rose At Rates Of +4 to +6 Meters Per Century
Cronin et al., 2017   Global Sea Level Rise Rate: +4 meters per century (14,500 to 14,000 years ago)
“Rates and patterns of global sea level rise (SLR) following the last glacial maximum (LGM) are known from radiometric ages on coral reefs from Barbados, Tahiti, New Guinea, and the Indian Ocean, as well as sediment records from the Sunda Shelf and elsewhere. … Lambeck et al. (2014) estimate mean global rates during the main deglaciation phase of 16.5 to 8.2 kiloannum (ka) [16,500 to 8,200 years ago] at 12 mm yr−1 [+1.2 meters per century] with more rapid SLR [sea level rise] rates (∼ 40 mm yr−1) [+4 meters per century] during meltwater pulse 1A ∼ 14.5–14.0 ka [14,500 to 14,000 years ago].”
Abdul et al., 2017   Global Sea Level Rise Rate: +4 meters per century (11,450 to 11,100 years ago)
“We find that sea level tracked the climate oscillations remarkably well. Sea-level rise was fast in the early Allerød (25 mm yr-1), but decreased smoothly into the Younger Dryas (7 mm yr-1) when the rate plateaued to <4 mm yr-1here termed a sea-level “slow stand”. No evidence was found indicating a jump in sea level at the beginning of the Younger Dryas as proposed by some researchers. Following the “slow-stand”, the rate of sea-level rise accelerated rapidly, producing the 14 ± 2 m sea-level jump known as MWP-1B; occurred between 11.45 and 11.1 kyr BP with peak sea-level rise reaching 40 mm yr-1 [+4 meters per century].”
Ivanovic et al., 2017  Northern Hemisphere Sea Level Rise Rate: +3.5 to +6.5 meters per century (~14,500 years ago)
“During the Last Glacial Maximum 26–19 thousand years ago (ka), a vast ice sheet stretched over North America [Clark et al., 2009]. In subsequent millennia, as climate warmed and this ice sheet decayed, large volumes of meltwater flooded to the oceans [Tarasov and Peltier, 2006; Wickert, 2016]. This period, known as the “last deglaciation,” included episodes of abrupt climate change, such as the Bølling warming [~14.7–14.5 ka], when Northern Hemisphere temperatures increased by 4–5°C in just a few decades [Lea et al., 2003; Buizert et al., 2014], coinciding with a 12–22 m sea level rise in less than 340 years [3.5 to 6.5 meters per century] (Meltwater Pulse 1a (MWP1a)) [Deschamps et al., 2012].”
Zecchin et al., 2015 Regional Sea Level Rise Rate: +6 meters per century (14,500-11,500 years ago)
“[M]elt-water pulses have punctuated the post-glacial relative sea-level rise with rates up to 60 mm/yr. [6 meters per century] for a few centuries.”
It has become more and more apparent that sea levels rise and fall without any obvious connection to CO2 concentrations.  And if an anthropogenic signal cannot be conspicuously connected to sea level rise (as scientists have noted), then the greatest perceived existential threat promulgated by advocates of dangerous anthropogenic global warming will no longer be worth considering.
70+ Papers: Sea Levels 2+ m Higher 9,000-4,000
Years Ago While CO2 Levels Were ‘Safe’ (265 ppm)
(Click the link above or at the right side bar)
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSchneefan at German weather and climate analysis site wobleibtdieerderwaermung.de here brings us the latest on atmospheric temperatures.
First we note that the middle troposphere (7,500 meters) as measured by NASA has seen recently a sharp cooling off since the start of April:

The chart shows the daily mean temperature at about 7,500 meters altitude, i.e. middle troposphere (400 mb/hPa). Here we see that temperatures have dived (pink curve) and reached a near 17-year low for this time of the year. Source: https://ghrc.nsstc.nasa.gov/amsutemps/
An enlargement shows a comparison to last year, last updated April 9, 2018.

Temperature at 7,500 m altitude have dived steeply since early April. Source: https://ghrc.nsstc.nasa.gov/amsutemps/
Near surface temperatures sharply down
Also the global 2m surface temperature is showing a strong downward trend:

The plotted data have already been adjusted (falsified?) with the NASA/GISS factor, and so may actually be even lower. Source: http://www.karstenhaustein.com/climate.php
Should the cold temperatures persist, April, 2018, could fall below the zero anomaly for the first time since 2012, foremost with the UAH  satellite data. The following UAH chart shows lower tropospheric temperatures (1500) continuing their decline after the warm peak caused by the natural El Niño phenomenon:

Source: UAH Global Temperature Update for March, 2018: +0.24 deg. C


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In March, 2018, lower tropospheric temperatures (1500m) over the oceans (71% of the earth’s surface) also saw a further drop:

Source: climate4you.
More cooling over the coming months
The following chart shows the El Niño Southern Oscillation (ENSO) 3.4 plot, i.e. the ocean surface temperature anomaly of the western equatorial Pacific region, since July 2016.

Source: climexp.knmi.nl/start.cgi
Much of the last 2 years has been in the globe-cooling La Niña phase (blue). And as satellite instrument temperatures tend to lag the El Niño temperature anomalies by some 4 months, further surface cooling is expected to show up in the satellite data over the coming months.
ENSO indicates more cooling ahead
The Southern Oscillation Index (SOI) is an indicator for the development of the easterly trade winds at the equatorial Pacific and thus tells us what’s ahead for the ENSO. Recall that the ENSO has a powerful impact on global surface temperatures. SOI values over +7.0 indicates La Niña conditions 2 months ahead, while an SOI under -7.0 points El Niño conditions.
Currently the following chart shows the SOI is at +13.7, which means the globe-cooling La Niña should continue on two months from now, and thus means cooler satellite measurements showing up 6 months later.

The Southern Oscillation Index (SOI) is currently at +13,7, thus pointing to La Niña conditions 2 months from now. Source: www.bom.gov.au/climate/enso/
Recently some scientists have postulated that the ENSO is impacted by solar activity, which currently is at a low (earth-cooling) level. The next solar cycle is expected to be a weak one, thus boding more cooling and tough winters ahead.
It’s got nothing to do with trace gas CO2.
Share this...FacebookTwitter "
"Once again the summer holidays have arrived and many people will be jetting off to the beach. However, few tourists will notice the tonnes of sand and gravel that weren’t there the previous year. Each spring, an army of bulldozers gets to work fixing storm and tidal damage on many of the world’s most famous beaches. Fresh sand or gravel (a term encompassing everything from tiny pebbles to chunky stones) is placed where necessary, allowing waves and tides to redistribute the material. It can be dumped in the right spots by bulldozers, or shipped in on barges. It can also be pumped in through pipes, as seen in the video below; the mixed-in water is allowed to drain off and the remaining sand is shoved into the right places. All this is partly driven by the influx of visitors and their rocketing expectations of perfect sand. But beaches aren’t just eye candy for tourists – they themselves have an important role in combating erosion through soaking up wave energy before the sea smashes into the cliffs or seawall. So despite the expense, there’s more demand than ever for what’s known as “beach nourishment”.  If this seems artificial, as though something pristine was being unnecessarily tampered with, then don’t forget beaches weren’t always there. In fact most are relatively new, formed during the past 5,000 or so years after the modern sea level was established. However in recent decades rising sea levels and more frequent storms have led to rapid beach erosion. By the 1990s just 10% of the world’s beaches were still growing, while more than 70% were eroding – with the world still warming and sea levels rising, things will only have got worse since then. To combat this, beaches such as Venice’s Lido or a number along Italy’s north-west coast are “re-nourished” each spring to repair the winter damage. Over the years this adds up. One analysis of the famous beach in Nice, south France, found 558,000 cubic metres of gravel was added during the 30 years to 2005 – that’s enough gravel to fill up Big Ben’s clock tower 119 times over. Along the Costa Brava, on Spain’s north-east coast, entirely artificial beaches have been created, sustained by a combination of breakwaters, groynes (structures built out from the shore to prevent the movement of sediment) and a dump of fresh sand each year. Perhaps the most famous example of all is the artificial beach in Barcelona, which has been nourished with sand from offshore over the past two decades. The loss of the sediment here is only partially due to storms, with the normal action of the waves causing slow erosion – the area simply isn’t meant to have a massive sandy beach. In contrast to many other parts of the Mediterranean, the coastline in our home country of Croatia managed to remain more or less natural. Its rocky coastline isn’t ideal for the creation of large sandy beaches, and political upheavals in the 1990s interrupted the growth of tourism. Now the country has once again become a popular tourist destination, and the beauty of its small and well-hidden gravel beaches are a valuable part of its attraction.  Many beaches have therefore been extended or created from scratch, and our current research is focused on the resilience of artificial gravel beaches in Croatia. Their sustainability depends on factors including a continued supply of sediment, and how well they stand up to stormy weather. Understanding the behaviour of natural and artificial beaches in different environmental conditions is crucial for their maintenance. A number of techniques are used to detect beach changes including advanced GPS surveys, laser scanning, or images from fixed cameras and drones  Our work in Croatia, for instance, uses a simple digital camera combined with advanced computing methods to understand the changing shape of the beach. We also study our nearby coastline in Fylde, Lancashire. With our help, both day trips and holidays to the beach should remain a pleasant feature of our lives into the future."
nan
"
Share this...FacebookTwitterIt’s the food, stupid!
Something off topic today, and intended as food for thought. It’s my infrequent post on nutrition. Yes, I also would like my readers to be healthy and happy.
Stress, lifestyle, pollution are over-rated factors
In western societies, when asked why so many people are getting sick with chronic diseases today, and thus die prematurely, too many medical experts like to blame it on stress!, genetics, pollution, lifestyle, or just plain bad luck. So take my pills!
However, these often cited reasons are all too often bogus explanations designed to get you to accept horrendously costly treatments instead of opting for effective prevention. Prevention and cure, after all, are bad for Big Pharma’s bottom line. The big money is in lifetime treatment.
And in western societies, far too little is being done to drive home the point that the junk-food contaminated Western nutrition is the root cause of many chronic diseases and thus our food supply needs to be revamped radically and rapidly. If this were done, much misery and high costs could be spared.
Life-shortening disease often food-related
What a lot physicians won’t tell you is that many of these diseases are in fact nutrition-related and gradually emerge after years of poor quality (low-nutrient) diets. Many common chronic diseases could be prevented, or at least delayed by years, simply by eating high-nutrient foods. The most important thing you can do to live longer and healthier is to eat correctly, and to start doing so immediately.. Your doctor can tell you to reduce stress and to go for walks all he wants, but unless you wean yourself off the junk food, you’ll very likely end up chronically ill and forever connected to the miserable Big Pharma lifeline.
High stress Japan has highest life expectancy!
To illustrate how stress is an over-rated factor in causing chronic illness, one only needs to check out the countries with the highest life expectancies. Many happen to be high stress environments, like Japan and Europe. Of course stress is generally to be avoided, but is it really the big silent killer everyone makes it out to be? Statistics show us the answer is no. The big killer is junk food.

High stress, urbanized Japan No. 1 in life expectancy. Source: WHO. 
Anyone who has ever visited Japan will tell you that most people there live in high-stress, urban environments and work among the longest number of hours annually. Most Japanese in fact do not spend their time meditating in harmonious Zen rock gardens.
Japanese and Mediterranen diets lead to long lives


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Arguably the most important factor to Japan’s excellent collective health is its nutritional culture. Whereas in western culture many people stuff themselves with sugary, processed junk foods, snacks, sodas and sweets and bad oils, the Japanese diet is rich in vegetables, high-nutrient carbs, fish, fermented foods, antioxidant super-foods and green tea to name a few.


American (sick) lives simply dragged out by Big Pharma
But what about USA’s relatively high life expectancy? First, it really isn’t that high, and actually ranks a lowly 31st on the WHO list above!
And although the American diet is among the world’s most notorious, American’s do live about 80 years, and so food can’t be the big factor one might argue. Though Americans live relatively long, we need to keep in mind that huge numbers of them are plagued by chronic disease, and many are simply kept alive in a state of limited health or outright misery for years by Big Pharma. The average American today spends some $10,000 annually on health care alone.
Here’s what some countries spend on health care per capita:

The USA spends the most by far on health care, yet does not even make the Top 30 on the list for life expectancy. On the other hand, high stress, urbanized Japan spends near the OECD average on health care, yet has the highest life expectancy. Italy also sees a good life-expectancy-to-healthcare-spending-ratio, arguably in large part due to its health Mediterranen diet. Chart: OECD Data: Health resources – Health spending.
A longer life at a fraction of the healthcare cost
Also we note that poorer Mediterranean countries such as Greece, Cyprus, Spain and Malta spend a mere fraction on healthcare of what Americans spend, yet live longer. It’s the food that makes the difference.
Big Junk driving Big Pharma
According to statista, the U.S. pharmaceutical market represents over 45 percent of the global pharmaceutical market, valued at around 446 billion U.S. dollars in 2016.
With that kind of spending, the country should be way up the top of the list for life expectancy, but at a lowly 31st place it’s not even close to the top. One reason is because bad American junk food is creating sickness and thus a big demand for health care. Big Junk is feeding Big Pharma.
To live longer and healthier, good food is the key. Eat healthy, and the rest will take care of itself.
Share this...FacebookTwitter "
"It is not just the lack of timely action by Scott Morrison but also his lack of instinct that has become so apparent over the past few weeks. From refusing to listen to urgent pleas by fire chiefs several months ago, to taking an overseas family holiday, to contemplating leaving the country for an international meeting at such a time, and most recently endorsing a social media video slapping himself on the back – it is all wrong.  He also seems unable to accept responsibility for his poor judgment, instead blaming state and federal systems, etc. These are not the traits of a strong leader, more of someone desperate to hold on to his popularity. Scott Morrison was in the right place at the right time against a poor opponent when he received the mantle of commander in chief. Tragically he appears to be the wrong man to lead our country through this most terrible crisis now and into the future.Luella Brookes-InglisGlen Osmond, South Australia • Well said, Katharine Murphy (Some political leaders find their natural authority in a crisis – not Scott Morrison, 2 January). We have seen the achilles heel of Scott Morrision: in the pay of the likes of Rupert Murdoch and the coal industry, unable to escape from the extreme right of the Liberal party, he has proven useless as a leader. Instead of action, he offered his prayers for people affected by the fires. He seems incapable of learning from new facts and sticks doggedly to his mantra: God exists, climate change doesn’t. Well, maybe his god is stuck on the toilet and can’t hear him. Everyone in Australia can see the impact of climate change, and the accounting dodges his government makes to avoid any real action under the Paris agreement. He makes us ashamed to be Australian and must resign.Linda PhillipsNarrogin, Western Australia • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
nan
"
Share this...FacebookTwitterJosef Kowatsch and Stefan Kämpfe at the European Institute for Climate and Energy (EIKE) here have been looking at temperatures in Central Europe, foremost Germany, over the past 30 years.

 Heavy snow blankets Germany in January, 2018. Photo: Stefan Kämpfe
The German media like to say that Germany has been warming rapidly due to global warming, especially winter. Yet a look at the data tells a different story. Although January, 2018 was a mild one at a mean of 3.8°C, as measured by the German DWD national weather service, the overall January trend is COOLING.
The warm January, 2018, did little to curb Germany’s overall January cooling trend, as data from the DWD show. Kowatsch and Kämpfe have plotted the January data over the past 31 years along with the computed linear trend line:

Figure 1: January mean temperatures for Germany have been cooling over the past 31 years. Chart: Josef Kowatsch, based on data from the DWD.
This winter’s mild Central European weather has been attributed to a series of lows that have pumped in mild air from the Atlantic and kept much of Europe out of the ice box. Also heavy precipitation has been associated with the lows, and higher elevations have seen heavy snowfalls as a result — especially in the mountain regions and Alps.
Trend contradicts the CO2
Looking at different locations in Germany, the East German station of Erfurt/Weimar shows the same January cooling trend despite rising CO2 concentrations.

Figure 2: January temperature trend (blue) over the past 31 years  in Erfurt (316m elevation) compared to CO2 concentrations (green). Chart: Stefan Kämpfe.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




This cooling has been occurring despite urbanization and added waste heat. Currently 100 hectares of building and asphalt are being added daily.
Substantial cooling at the high elevations
Getting away from urban areas, Kowatsch and Kämpfe looked at the mean January temperature atop Germany’s highest peak, the Zugspitze, and at Amtsberg in the East German Erzgebirge near Chemnitz.
The following chart shows the 31 year trend for the Zugspitze, some 2960 m above sea level:

Figure 3: January’s mean temperature on the summit of Germany’s highest mountain, Zugspitze, has trended significantly downward over the 31 years: from -8.3°C in 1988 to over -11°C in 2018 (using the linear trend). That’s about 1°C per decade! Chart source: Josef Kowatsch.
Urban heat island likely skewing the real cooling
Next we look at the station Amtsberg at the foot of the Erzgebirge in East Germany. Here over the past 30 years the mean January temperature has fallen modestly and shows no signs at all of any warming.

Figure 4: Rural station Amtsberg (blue curve) near Chemnitz is similar to the trend observed across Germany (red curve). Chart source: Josef Kowatsch.
Kowatsch and Kämpfe write that they believe the urban heat island (UHI) effect has not been adequately accounted for in the DWD data, and thus the cooling may actually be even stronger.
So if you’re looking for warming, you won’t find it in Central Europe — despite all the fake climate news you might be hearing.
Share this...FacebookTwitter "
"﻿From space, the Amazon rainforest resembles a giant dark-green lung veined with blue rivers that is steadily succumbing to the disease-like spread of grey fires, orange roads and square-cut farms. What the satellite images cannot show is how most of the remaining bands of verdant, healthy foliage are defended on the ground by forest dwellers who act as antibodies to drive out malignant invaders. Among the most impressive of these is the Tapajós-Arapiuns Extractive Reserve in the state of Para in northern Brazil, where residents are trying to bolster their economic resistance with a series of new agro-forestry and solar power projects.  The 74 traditional riverine communities who live in the area fought hard to win protected status for the region, which is 110 times the size of Manhattan. Some activists were murdered by loggers and others received death threats until their home was recognised by the state as an extractive reserve in 1988. This gives them the right to live sustainably on the land, free from intrusion by large-scale business interests. Today, however, their region is once again under threat as the government of the far-right president, Jair Bolsonaro, encourages commercial development of the Amazon. This has put greater pressure on the residents to find alternative forms of income so the forest around them is worth more than it would be if they sold up to cattle ranchers or soya farmers. Among the projects that aim to do this is a new solar-powered fruit pulping facility at Surucua village. Run as a cooperative by the largely women-led residents association, it is part-funded by Global Greengrants Fund UK, one of the Guardian and Observer’s climate emergency appeal charities. The mini-factory provides residents with an economic incentive to protect and replant the forest with a wide variety of trees that provide fruit, nuts, oil, medicine and other products they can use and sell. Surucua is idyllic. Pellucid waters lap against deserted beaches of fine white sand, bordered by palms and rubber trees. The village comprises three dirt roads, several dozen wooden homes, a school, a church, a football pitch and clusters of trees of little-known indigenous fruits such as acerola, piquia and tucumã to global favourites such as mango, pineapple and banana. “It’s a food forest,” says Mayá Schwade, a biologist who works with the community. “The basic idea is to avoid monocultures.” The new pulping centre is a small concrete building with solar panels on the roof that was built by a cooperative of 16 local women with technical support and funds from a mix of institutions and charities. Its goal is to protect the forest and raise living standards by pushing village production up the value chain. Instead of quickly selling low-cost produce before it rots, villagers can process, package and freeze fruit, allowing them to wait for the best market price.  With help from Guardian and Observer readers, their next step will be to build a new facility that can turn the fruit into alcohol and cordials, jams and confectionery. “Our economy is very weak so this project is very important for us. We can make enough to feed ourselves and earn a little more to buy things,” Maria Aranjo, one of the founders of the co-op, explains. “It’s also fun to work together for a better life.” Surucua is intended as a model for other communities. If living standards in this remote village can be raised with native fruit forests and renewable power, then people living in similar conditions elsewhere in the Amazon will have hope they too can generate enough money and electricity to buy and use computers, mobile phones, TV sets and refrigerators without sacrificing the natural wealth – fresh water, abundant food, clean air – provided by the forest and river. The village hopes the small-scale project will inoculate it against the more destructive industries that are moving ever closer. “On the borders of our territory we face a lot of pressure from loggers,” says Angelo Sousa, a forest engineer who was born in the village. Pressure is also coming from the authorities, who are weakening rainforest protections. “The municipal government wants to expand production of soya and other monocultures. In the coming 10 years, they plan to allow cultivation of these crops in the [protected] reserves. The politicians are all big landowners. There is a proposal in congress to reduce the area of many reserves, including ours,” Schwade says. Elsewhere, the impact is already apparent. In the year to July, deforestation of supposedly protected areas of the Amazon – the world’s largest terrestrial carbon sink – hit 5,054 sq km, up 39% from the previous 12 months. To fortify forests against this, Brazilians are increasingly focusing on economic protections such as the project at Surucua.  Rather than the destructive extraction of beef, soya or gold, the agro-forestry project at Tapajós-Arapiuns aims to strengthen the forest rather than run it into the ground. The Guardian and Observer climate emergency charity appeal closes at midnight on 12 January. Please donate here."
"
Share this...FacebookTwitter A Disgraceful Chasm Between Real-World
Observations & Climate Science Reporting

Injecting frightening scenarios into climate science reporting  has seemingly become a requisite for publication.
In a new Nature Geoscience editorial, a common scare tactic is utilized by the (unidentified) author so as to grab readers’ attention.
Nature Geoscience, 2018
The East Antarctic ice sheet is currently the largest ice mass on Earth. If it melted in its entirety, global sea levels would rise by more than 50 metres.
Wow.  50 meters.  That would be catastrophic.
But then we read about real-world observations for East Antarctica.  And they don’t even come close to aligning with the catastrophic scenario casually tossed into the editorial.
First of all, East Antarctica is not losing mass and adding to sea levels.  The ice sheet is gaining mass and thus removing water from sea levels. The surface mass gains have been occurring not only since 1800 (Thomas et al., 2017), but for the recent decade (2003-2013) too (Martín-Español et al., 2017).  Even the author of the Nature Geoscience editorial acknowledges this.
Nature Geoscience, 2018
“The East Antarctic ice sheet may be gaining mass in the current, warming climate. The palaeoclimate record shows, however, that it has retreated during previous episodes of prolonged warmth.”
Not only has East Antarctica been gaining mass, the author goes on to say that it would take 100s of thousands to millions of years for Antarctica to even exhibit partial retreat.  So much for the “if it melted in its entirety” warning we read earlier.
“In terms of immediate sea-level rise, it is reassuring that it seems to require prolonged periods of lasting hundreds of thousands to millions of years to induce even partial retreat.”
So if the editorial department at Nature Geoscience realizes that it would take 100s of thousands to millions of years to even witness a partial retreat of the ice sheet, is there any scientific justification for the inclusion of the sea-levels-would-rise-50-meters-if-East-Antarctica-melted commentary?  Since when do imaginary scenarios pass as science?
A ‘Staggering’ 9 Trillion Tons Of Greenland’s Ice Has Been Lost Since 1900!  That’s A Sea Level Contribution Of Less Than 1 Inch


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




It’s frightening to learn that the Greenland Ice Sheet has lost a “staggering” 9 trillion tons of ice since 1900, which is what the Washington Post warned us about in 2015.
It’s not frightening to learn that 9 trillion tons of ice losses actually amounts to less than 1 inch of sea level rise contribution from Greenland meltwater in 115 years.

Since a total sea level rise contribution of 1 inch in 115 years from the Greenland ice sheet isn’t scary, the author of the Washington Post article (Chris Mooney) finds it necessary to offer his readers a macabre thought experiment: What if that additional 1 inch of water sitting atop the world ocean were to be collected somehow and then dumped onto all the United States interstate highways?   Now that would be scary.  It would mean that 1 inch of sea level rise turned into 98 feet of sea levels rise (63 times over) in very same imaginary world where additional sea water is dumped onto U.S. interstate highways.
This is how the modern version of climate science works.
Below are a few more examples of glacier melt and sea level rise observations from recently-published papers casting doubt on the tragic, alarmist, and attention-seeking headlines that are so prevalent today.

1. ‘Pine Island Glacier Is The Largest Current Antarctic Contributor To Sea Level Rise’ – But Has ‘Not Shown Any Clear Trend Over 68 Years’ (1947-2015)
Arndt et al., 2018
“Pine Island Glacier is the largest current Antarctic contributor to sea level rise. Its ice loss has substantially increased over the last 25 years through thinning, acceleration and grounding line retreat. However, the calving line positions of the stabilizing ice shelf did not show any trend within the observational record (last 70 years) until calving in 2015 led to unprecedented retreat and changed alignment of the calving front. … Despite the thinning and flow acceleration of PIG [Pine Island Glacier], and sustained, rapid thinning of the ice shelf over at least the past 25 years the position of the ice front had not shown any clear trend over 68 years of observations prior to 2015 (Bindschadler, 2002;MacGregor et al., 2012;Rignot, 2002).”

2. More Land Area Above Sea Level In 2014 Than In 1971 In The Tropical Pacific
Kench et al., 2018
“We specifically examine spatial differences in island behaviour, of all 101 islands in Tuvalu, over the past four decades (1971–2014), a period in which local sea level has risen at twice the global average (Supplementary Note 2). Surprisingly, we show that all islands have changed and that the dominant mode of change has been island expansion, which has increased the land area of the nation. … Using remotely sensed data, change is analysed over the past four decades, a period when local sea level has risen at twice the global average [<2 mm/yr-1] (~3.90 ± 0.4 mm.yr−1). Results highlight a net increase in land area in Tuvalu of 73.5 ha (2.9%), despite sea-level rise, and land area increase in eight of nine atolls.”


3. More Land Area Above Sea Level In 2015 Than In 1985 For The Entire Globe
Donchyts et al., 2016
“Earth’s surface water change over the past 30 years [1985-2015] … Earth’s surface gained 115,000 km2 of water and 173,000 km2 of land over the past 30 years, including 20,135 km2 of water and 33,700 km2 of land in coastal areas.”
 (press release)
Coastal areas were also analysed, and to the scientists’ surprise, coastlines had gained more land – 33,700 sq km (13,000 sq miles) – than they had been lost to water (20,100 sq km or 7,800 sq miles).
“We expected that the coast would start to retreat due to sea level rise, but the most surprising thing is that the coasts are growing all over the world,” said Dr Baart.  “We were able to create more land than sea level rise was taking.”

4. Greenland And Antarctica Combined Contributed A Total Of 0.59 Of An Inch To Sea Level Rise Between 1958-2014
Frederiske et al.,2018


5. ‘Recent Lack Of Any Detectable Acceleration In The Rate Of Sea-Level Rise’
Parker and Ollier, 2017
“The loud divergence between sea-level reality and climate change theory—the climate models predict an accelerated sea-level rise driven by the anthropogenic CO2 emission—has been also evidenced in other works such as Boretti (2012a, b), Boretti and Watson (2012), Douglas (1992), Douglas and Peltier (2002), Fasullo et al. (2016), Jevrejeva et al. (2006), Holgate (2007), Houston and Dean (2011), Mörner 2010a, b, 2016), Mörner and Parker (2013), Scafetta (2014), Wenzel and Schröter (2010) and Wunsch et al. (2007) reporting on the recent lack of any detectable acceleration in the rate of sea-level rise. The minimum length requirement of 50–60 years to produce a realistic sea-level rate of rise is also discussed in other works such as Baart et al. (2012), Douglas (1995, 1997), Gervais (2016), Jevrejeva et al. (2008), Knudsen et al. (2011), Scafetta (2013a, b), Wenzel and Schröter (2014) and Woodworth (2011).”
“[T]he information from the tide gauges of the USA and the rest of the world when considered globally and over time windows of not less than 80 years […] does not support the notion of rapidly changing mass of ice in Greenland and Antarctica as claimed by Davis and Vinogradova (2017). The sea levels have been oscillating about a nearly perfectly linear trend since the start of the twentieth century with no sign of acceleration. There are only different phases of some oscillations moving from one location to another that do not represent any global acceleration.”
“The global sea-level acceleration is therefore in the order of + 0.002  ± 0.003 mm/year², i.e. + 2 ÷ 3 μm/year², well below the accuracy of the estimation.”

Share this...FacebookTwitter "
"I felt like putting a bullet between the eyes of every panda that wouldn’t screw to save its species
– “Narrator”, Fight Club Though Edward Norton’s unnamed movie character was no conservation biologist he was actually pretty close to the solution. Giant pandas don’t choose not to “screw” out of spite, of course, or because they have no natural urge to reproduce – in the wild they have perfectly good sex drives. However, just as Tyler Durden and co felt they needed to turn to violence in order to find meaning in their lives, so it is becoming apparent that male pandas also need to fight – in order to mate. To save their species, captive pandas may need a fight club of their own. The breeding problems are particularly apparent in Edinburgh, where the zoo has announced once again that its female giant panda Tian Tian has conceived through artificial insemination, but is not yet pregnant. That is, a sperm has entered an egg, which has been placed inside her; but crucially this fertilised egg has not yet implanted. Unfortunately, these attempts at artificial reproduction often don’t work. Some scientists say giant pandas are so hard to breed that they shouldn’t even exist in nature. Females often don’t accept males, and even if a female is interested in a male this sexual interest is not reciprocated.   None of this makes sense. The meaning of life, as all biologists know, is passing your genes on to the future and to do this you need to mate. But we have arrived at our conclusions on panda reproduction based on our observations of zoo-housed giant pandas and not from data on wild individuals. I suspect herein lies the problem – zoos don’t offer the same sexual opportunities as life in the wild. The panda situation reminds me of another species, which despite being held in captivity for thousands of years had only bred once before the 1950s: the cheetah.  Now the captive cheetah population is growing rapidly.  To understand how zoos have solved this problem with cheetahs and where the problem with giant pandas comes from we need to look back in time. The first modern zoo, in London, was founded in the Victorian era, a time when animal collectors had no qualms about going around the world to gather new species by any means necessary. The animals were housed in a monogamous family unit, in accordance with Victorian standards of morality. Even today zoo visitors explain to their children which animal is the mummy or the daddy and any inconvenient other adults are explained away as aunties or uncles. This situation has been reinforced by zoos describing themselves as modern arks, creating the image of animals entering two-by-two. But once scientists started to study animals in the wild it quickly became obvious that monogamy is not the norm. And even in species that are monogamous there is considerable mate choice or, to be more accurate, reproductive partners are chosen by females. Just like humans, most animals chose their reproductive partners according to their strength and good looks, or the resources they control, as these characteristics affect the perpetuation of their genes. Captive female cheetahs finally started breeding once they were offered a range of suitors rather than being housed with just one male. This replicated their behaviour in the wild, where female cheetahs like to give several males the once over before choosing who to breed with.  It may be that the first male that caught the female’s eye will be the one that she will eventually choose, but confirming he is the best available in the breeding pool seems to be crucial. Zoos who imitate this situation are successful at breeding cheetahs. Giant pandas are no longer housed in pairs. Instead, males and females are typically kept in adjacent enclosures and the male is introduced to the female during the one to three days a year when she is fertile. But it is just one male. What if he is ugly? Or maybe the female panda wishes suitors would strut their stuff on a mating catwalk, like cheetahs do.   Perhaps males need to impress females with shows of strength, by beating up or chasing off other males. It could also be that males need some competition to put them in the mood – studies of wild pandas show their testosterone levels are low except at mating time. Female giant pandas advertise their readiness to breed by scent marking around the edges of their territory, leading to the simultaneous arrival of several males who will chase off or beat-up their competition until only the strongest remains. So, the victor gets the opportunity to propagate its genes.   If all of this is correct it suggests zoos wanting to move away from artificial reproduction might be better off instead focusing on panda fight clubs. Alternatively, it may be possible to dupe females into believing certain males are worthy suitors as has been done with pygmy lorises by making them appear to be winners of fights."
"I was walking in Budongo forest one day, years ago, when my Ugandan friend Geresomu pointed out a patch of grey soil on the forest floor. “What’s that?” I asked. “The chimps sometimes eat it,” he replied. I promptly forgot about it – it was of no interest at that time. Now, it’s the central focus of my research. So what’s happened in the meantime? Back in the late 1980s, baby chimps from the Budongo Forest were being taken by poachers to Entebbe airport and illegally smuggled to Dubai and other places. I decided to set up a field station to protect the chimps, and spent years looking for funds to do so. In 1990, I founded the Budongo Conservation Field Station, and we hired a team of assistants to help us find and track the chimps. Geresomu was one of our first field assistants, and he’s still with us today. He knows more about chimps than any Westerner.  In the early 90s, Geresomu showed me a raffia palm tree, growing in a swampy area of the forest, which had a carefully made hole in the trunk. He told me that the hole had been made by chimps. “They put in their hands and pull out the dead wood and chew it – then they spit out the wood, but they swallow the juice,” he said. “Why would they do that?” I asked. No one knew.  I lived with that question for years, then one day I read a paper about gorillas, which said that they ate dead wood for its sodium content. I live near Brighton, and the Dean of Science at Brighton University – Andrew Lloyd – runs a lab that measures mineral elements. He offered to analyse the raffia wood. On my next visit to Budongo, I collected some samples and sent them to him. They turned out to be rich in sodium.  Sodium is an essential mineral for all mammals, and many find it easily in their diet. But chimps mainly eat fruit and leaves, which contain little or no sodium. So, they need to supplement their diets. Besides the sodium, there was a cocktail of other minerals present in the raffia samples: iron, manganese, magnesium, aluminium, and others. It seems the dead raffia palms suck water from the swamp forest, which then evaporates, leaving the minerals behind in the decaying pith. We published this discovery in PLoS ONE, in 2009.  Just at the time we published our findings, we found to our dismay that the raffia trees were disappearing fast. Their leaves were being cut down and used by local tobacco farmers to make raffia string, which they used to hang up their leaves in the smoking sheds. The tobacco trade was booming, and soon the last raffia trees were gone. The dead ones that remained were used so much by chimps that soon, all the pith was taken out and there was nothing left. But the chimps turned out to be ingenious. That low level of clay eating Geresomu had told me about so many years ago suddenly became more important. At any one time we have a number of research students at Budongo doing PhDs and Masters degrees. One by one, they reported finding chimps feeding on clay, or using leaf sponges to remove clay-rich water from the waterholes under the trees. They would congregate around these trees, pull the leaves off surrounding undergrowth and chew them a little. Then, they would use the leaves as sponges to soak up the clay-water, chew and suck the leaves in their mouths, and dip them in the water again. This was seen and filmed by Cat Hobaiter, Brittany Fallon and Caroline Mullins of St Andrews University, Anne-Marijke Schel of Utrecht University, and Noemie Lamon of Neuchatel University. I was in the UK and the students wrote me emails describing this new behaviour, and collecting information about it and photographing and videoing it. The field assistants also recorded it when they came across it in the course of their normal work, so their records went into the archives too. Naturally, I could not wait to get out to Budongo myself and see the clay pits, the waterholes, and the clay-eating and drinking behaviour itself. Meanwhile, all I could do was speculate that this might be a new way for the chimps to get sodium and all the other minerals, which they used to source from the raffia palms. In due course, I visited Budongo and came back armed with a set of samples of clay and clay-water, as well as some control samples of forest soil and rainwater for comparison. We ran them in Andrew Lloyd’s Brighton laboratory. They were mineral rich, yes, but disappointingly low in sodium. We discovered that the grey clay was kaolinite – a particularly rich source of aluminium, which people also use to treat upset stomachs. The samples also contained high quantities of iron and all the other minerals that we had found in the raffia pith. So we concluded that the clay was being eaten by our chimps as a mineral supplement, as well as for its digestive properties. And interestingly, when the clay-water was sponged up using leaves, it contained more minerals than when it was taken without the leaves. So the leaves and the clay were interacting with each other. Just how the chimps knew to use the clay as a mineral supplement is still a  mystery. Probably, it’s a habit passed from adult to juvenile: we see the young ones watching as the adults do it, and then doing it themselves. Or perhaps it may be that, back in evolutionary time, the chimps who took the supplements lived longer, healthier lives than those that didn’t, and so the habit got passed on, either through learning or as an inherited tendency. Such questions are hard to answer. But sometimes even the smallest clue – like that patch of grey soil Geresomu showed me all those years ago – can hold the key to a fascinating story."
"
Share this...FacebookTwitterHurricane activity trend declines significantly over the past 65 years
Dr. Sebastian Lüning and Prof. Fritz Vahrenholt posted here yesterday results showing that  hurricane activity has decreased over the past decades, despite all the hysteria we’ve been hearing from the usual suspects.

Data and studies show that Potsdam Institute thinly veiled claims that hurricanes are connected to man-made CO2 are spurious. Photo: Hurricane Isabel, NASA (public domain).
Taking a look at the recent literature, we find a paper authored by Ryan Truchelut and Erica Staehling appearing in the Geophysical Research Letters on December 8, 2017. They looked at the development of American hurricanes based on accumulated cyclone energy (ACE).
CO2 and hurricanes are not connected
The two authors found a statistically significant reduction in hurricane activity over the past 65 years. The relative inactivity of the past years (except for the very active 2017 season) was the most inactive phase of the examined time period. The abstract (emphasis added):
An Energetic Perspective on United States Tropical Cyclone Landfall Droughts
The extremely active 2017 Atlantic hurricane season concluded an extended period of quiescent continental United States tropical cyclone landfall activity that began in 2006, commonly referred to as the landfall drought. We introduce an extended climatology of U.S. tropical cyclone activity based on accumulated cyclone energy (ACE) and use this data set to investigate variability and trends in landfall activity. The drought years between 2006 and 2016 recorded an average value of total annual ACE over the U.S. that was less than 60% of the 1900–2017 average. Scaling this landfall activity metric by basin-wide activity reveals a statistically significant downward trend since 1950, with the percentage of total Atlantic ACE expended over the continental U.S. at a series minimum during the recent drought period.”
As CO2 in the atmosphere continuous to rise unabated, hurricane activity is decreasing. Obviously the two trends have little to do with each other.
Experts advise caution in assigning blame
Looking at the very clear body of facts, it is little wonder that the NOAA (via the Geophysical Fluid Dynamics Laboratory, GFDL) cautioned against linking the greenhouse gases and hurricanes in an official statement:
It is premature to conclude that human activities–and particularly greenhouse gas emissions that cause global warming–have already had a detectable impact on Atlantic hurricane or global tropical cyclone activity. That said, human activities may have already caused changes that are not yet detectable due to the small magnitude of the changes or observational limitations, or are not yet confidently modeled (e.g., aerosol effects on regional climate).”
Shrill in Potsdam
However in Germany, scientists scientists at the Potsdam Institute for Climate Impact Research (PIK) don’t accept the facts for what they are. For them t’s more important to be shrill and to set off alarms. For example in the wake of Hurricane Harvey, PIK scientist Anders Levermann gave a radio interview at Radio Eins on September 1, 2017. He said that when it’s warmer, more water vapour ends up in the air, and thus more rain and a hurricane with a flooding catastrophe in Houston. It’s just that simple, right? Then later in the interview Levermann added a “maybe”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




What Levermann committed here of course was an irresponsible misleading of the listeners. The clear decrease in hurricanes over the past 65 years contradicts his extraordinarily simplistic claims.
Poor urban planning
At the BBC the journalists were more serious with the subject, and did not stay silent regarding the complexity that is involved as it is known that a vast number of factors are at play. In Houston, for example, a blocking pattern was at work and thus led to a heavy rainfall over an urban area for a protracted time period. Anyone who claims that a part of the disaster can be attributed to man is unrealistically simplifying the system and ought to know better.
The answer to the question as to what the problem in Houston was is provided by an article by the BBC:
Climate change did not make people build along a vulnerable coastline so the disaster itself is our choice and is not linked to climate change.”
On ARD German public television, they too have gotten much more careful. TV meteorologist Donald Bäcker flatly dismissed the shot from the hip from Potsdam.
Forecasts thanks to link to AMO
In June, 2017, at the start of the hurricane season, Judith Curry and CFAN published a prognosis for the hurricane season. Here they anticpated an above-average hurricane activity season. They were right. If they are successful next year as well, then we’ll have an important forecasting method that will be of great use for society.
Other prognoses: Hurricanes have a certain development. Satellite photos allow the creation of storms to be tracked. But not all West African hurricane babies make it across the Atlantic and reach America. Tel Aviv University developed a model that allows us to determine which storms pose a risk and which ones will die off. Read the press release here.
Over the mid-term, hurricane activity can be forecast quite well because it is closely coupled to the Atlantic Multidecadfal Osciallation (AMO) ocean cycle, which has a periodicity of about 60 years. Michel de Rougemont reminds us in an essay appearing at WUWT.
Building in flood-prone areas is negligent
In Germany’s leading political daily FAZ of August 31, 2017, Winand von Petersdorff pointed out an important damage factor related to Hurricane Harvey. It was a man-made disaster in the sense that many homes and buildings had been built in classic flood-prone areas.

The enormous costs were foremost caused by the fact that the booming Houston metropolitan area, with its 6.5 million inhabitants, permitted building in grand style in areas where flooding and high water would occur.”

Share this...FacebookTwitter "
nan
"A relationship that lasted 93 years has hit the rocks. The UK’s Met Office is not on the shortlist for renewal of the contract it has held since 1922 to provide weather forecasts to the BBC. This is unlikely to affect the visible face of the weather forecast dramatically, but is the underlying change in the data provider a good idea? The Met Office has its origins in a service for mariners, set up in 1854 under the leadership of Robert FitzRoy, who had previously captained HMS Beagle on Darwin’s famous voyage. The organisation developed as part of the Ministry of Defence, with an important role to play in both world wars. Weather prediction helped the 1944 D-Day landings succeed, but equally armies have often waited for bad weather to attack, such as during the Ardennes counter-offensive later that year. For most of the 20th century, the Met Office provided a public service in supplying weather forecasts to the BBC and conducting atmospheric science research. It has acquired an obligation to generate commercial revenue, however, and in 2011 it became part of the Department for Business, Innovation and Skills.  The Met gets its income through providing a range of specialised forecasts, for example on behalf of the aviation and insurance industries, but the BBC contract remains a key part of its work. At a time when government is reducing spending, it is natural that the Met Office should seek to maximise income and the BBC should seek to cut costs, leading to the current schism. The clichéd conversational opener about the state of the weather is invariably followed by the comment that it wasn’t predicted correctly. Yet anecdotal evidence is misleading. The “skill” of a weather forecast is determined by measuring the correlation between a forecast weather map and what actually happened. This can be judged against the skill of a forecast based on statistical summaries of past records, known as climatology.  Since the 1980s, computer-based forecasting has steadily improved at a rate of about one forecast day per decade. This means that a five-day forecast made now is about as skillful as a two-day forecast was in 1985. The World Meteorological Organisation compares all national services and the UK’s forecast quality ranks among the very best, despite the notorious unpredictability of the country’s weather.  This notable improvement is a result of two related factors. First, the data from a vast network of surface and satellite observations is shared and distributed to national services. This is vital: knowing what the whole atmosphere is doing right now is the first step to predicting how it might change. Second, the weather models that project that information forward in time have been improved. This requires supercomputers, which are becoming increasingly accessible. In principle, any meteorological service that runs a global model of the atmosphere could offer a forecast for any region of the world. Global models are needed to forecast more than a few days into the future, but models that focus on a smaller area are also required to account for local factors, such as hills and valleys. For UK forecasts, a large-scale model of the North Atlantic and a still smaller-scale model of the UK and Ireland alone can be embedded into the global picture, each working down to finer scales. Other meteorological services can run similar local-area models focused on the UK, but it is not a trivial task and requires computing resources roughly equivalent to those for the global model. There is also a human aspect. Computer results are rarely presented raw, but are first interpreted by a human forecaster with local knowledge and experience. Different audiences also understand weather information communicated in different ways and we’re still not sure if forecasts are best presented as a single, most-likely case or as a range of probabilities. It is a brave move to change format, and impossible to please everyone. The BBC has an obligation to find the best value. But value should not be confused with price, and cheaper bidders must provide a forecast of comparable quality. Viewers may be reassured by retaining the same presenters and graphical presentation; subtle changes in forecast quality and communication will be more difficult to assess. Then there are strategic issues for the country. The Met Office will inevitably lose income, a net loss to the British economy, as well as public recognition. Since the 19th century, the UK has built world-leading atmospheric science expertise, of vital importance in applications ranging from defence to pollution and climate monitoring. Any erosion of capability in these areas may later be a cause for regret."
"Edgar Allan Poe wrote a brilliantly sinister short story about a man who wakes up in the night and sees a shadow against the curtains that looks just like a knife‑wielding murderer come to kill him in his sleep. The twist: it really is a knife-wielding murderer come to kill him in his sleep. The murderer has a plan for this. He freezes, knowing his victim will convince himself he is simply looking at a shadow, that something this frightening can’t actually be happening, that your worst fears never really come true. Steadily the murderer starts to creep closer, hour after hour, a millimetre at a time. By the end of the story he’s stood over the bed as early morning light floods the room, knife raised, staring into the face of his victim, who’s too far gone by now to break the illusion or admit that death really is standing in his eyeline. I mention this because something similarly frightening and equally hard to grasp is happening in Australia, and happening in plain sight too. Imagine an area three times the size of Yorkshire on fire. This is the scale of the disaster in New South Wales. Homes have been lost. Half a billion animals have been killed. New Zealand’s glaciers have turned brown from the smoke 2,000 miles away. All this in a country experiencing its hottest recorded summer, where the disaster minister “doesn’t have an opinion” on whether man-made climate change really exists, even as the horizon burns behind him. How close does it have to get? How far does that shadow need to creep? How long before we admit that death is now in the room? These are not the observations of a renowned climate activist. They are simply the facts, albeit facts that are still hard to grasp for those of us whose brains work slowly, whose concerns remain – let’s face it – essentially solipsistic. It is perhaps a question of scale, of finding a way to respond that isn’t simply panic or despair. With this in mind here’s another aspect, a detail that has been reported insistently this week in the background of all this macro-destruction and terror. There is now a clear and obvious danger this might start affecting the cricket. For those who think it’s frivolous to be concerned with cricket right now, to worry about disruption to cricket caused by symptoms of the impending apocalypse: stick around. Take, as they say in America, a step back. Because details are important here. Grade and Shield cricket has already been affected. Last month a Big Bash game in Canberra was abandoned due to smoke over the Manuka Oval, a ground that is already hotter than the exposed reactor core at Chernobyl on any given summer’s day. Right now there are fears the third Test between Australia and New Zealand at the SCG might be threatened, with temperatures due to hit 45C on Saturday afternoon and a suggestion play may be halted if the air quality index rises above a reading of 150. “This is a challenge on two metrics: visibility and breathing,” a Cricket Australia spokesperson has said. And he’s right. Those are two very important metrics. At which point it is tempting to write a classic sport-style column about this. The standard form is to declare that sport really must do something, that sport must set an example, carry the message, become a model of sustainability. Presumably it was once credible to talk like this, to suggest professional sport might be some kind of force for collectivism and universal good. It might even have been true. It isn’t true now. Let’s face it, Big Sport simply isn’t concerned with issues like this. There are nice people and nice gestures within it. Various Aussie cricketers have already promised help and donations. Sam Stosur will give $200 to the fire relief fund for every ace she serves this summer (all the while flying around the world on the absurdly carbon-heavy tennis circuit). But in reality sport cares only about growth, profit and consumption. There will be platitudinous noises and pledges. But at the elite level sport is run, funded and used as a reputation-garnish by the world’s greatest carbon-gorgers. There will be no rainbow coalition of Fifa-ICC-IOC junketers holding hands to save the planet, not unless the people of the earth can crowdfund a sufficiently tempting “special payments” fund. So what can we do about this now? Send our love, support and hard currency to one of the relief funds, and of course to the firefighting services charged with containing the revenge of nature. As Nathan Lyon said this week: “We just play a game, the real heroes are the firefighters out there fighting fires” – which is of course arguable from the GOAT. How many firefighters have taken a Test seven-for? How many firefighters have chased down a score on a crumbling Dubai deck in front of 300 Pakistani taxi drivers? But you can and should still give to them here. As for sport, it is still pretty useful as a way of shining some light. For one thing, here we are talking about climate emergency and destruction of the natural world because the Test match might be affected. There are details here you can grasp. That thing you love is in peril. Plus there is something painful and indeed strangely beautiful in the fact cricket is caught up in this, if only because cricket is so vital to the way Australia perceives itself: those dreamy white figures out there in all that pastoral green, a vision of Australia’s own youth and strength and righteousness. For now that great outdoors has become strange, licked by flames and fogged with smoke. The shadow is beginning to clarify. One thing is certain. We will, from here, have a front-row seat."
"
Share this...FacebookTwitterHey, we just saw something similar from Japan. 
===============================================
On Spitzbergen it was as warm 70 years ago as it is today
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated by P Gosselin)
Newspapers like to write about heat and melt records in the Arctic, which supposedly had never happened before. That really sparks fear among the citizens. However an examination of the facts regularly brings amazing things to light, for example weather records from a German station on Spitzbergen during World War 2 for the period of 1944-1945.
In the journal International Journal of Climatology Rajmund Przybylak and his colleagues evaluated the data. Summary: Back then it was similarly warm as it is today. Abstract:
Air temperature conditions in northern Nordaustlandet (NE Svalbard) at the end of World War II
This article presents the results of an investigation into air temperature conditions in northern Nordaustlandet (NE Svalbard) based on meteorological observations made by German soldiers towards the end of World War II (1944/1945) and 4 months after its end. Traditional analysis using mean monthly data was supplemented by a detailed analysis based on daily data: maximum temperature, minimum temperature and diurnal temperature range. The latter kind of data made it possible to study such aspects of climate as the number of “characteristic days” (i.e., the number of days with temperatures exceeding specified thresholds), day‐to‐day temperature variability, and duration, onset and end dates of thermal seasons. The results from Nordaustlandet for the warmest period of the early 20th century warming period (ETCWP) were compared with temperature conditions both historical (the end part of the Little Ice Age) and contemporary (different sub‐periods taken from the years 1981–2017) to estimate the range of warming during the ETCWP.
Analysis reveals that the expedition year 1944/1945 in Nordaustlandet was, in the majority of months, the warmest of all analysed periods, that is, both historical and contemporary periods. The study period was markedly warmer than 1981–2010 (mean annual −6.5 vs. −8.4 °C) but colder than the periods 2011–2016 (−5.7 °C) and 2014–2017 (−5.8 °C). The majority of mean monthly air temperatures in the ETCWP lies within two standard deviations of the modern 2014–2017 mean. This means that values of air temperature in the study period lie within the range of recent temperature variability. All other thermal characteristics show changes in accordance with expectations associated with general warming of the Arctic (i.e., a decrease in diurnal temperature range and number of cold days, and an increase in number of warm days). The latter days were most common in the ETCWP.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNever mind the severe cold hitting the Super Bowl this year, or scientists lecturing us on global warming while their host resort Davos got buried in snow.
There’s been a lot of cold gripping all over the northern hemisphere this winter – much more than many of us expected. Europe has also joined in on the freeze-fest as the harsh winter spreads across the old continent and even into Africa:

Cold is forecast to keep Europe shivering this week. Image cropped from wetter.online.de.
Cooling globe
One reason for this could be due to the rapidly falling global surface temperatures  as recorded by satellite data. In January the global mean temperature anomaly dropped to +0.26°C, with the tropics (where most of the heat is found) posting a nippy -0.12°C anomaly, according to Dr. Roy Spencer.
Other cooling factors include the current La Nina and possibly the low solar activity playing a role. IceAgeNow here reported last July that solar activity was at its most rapid decline in 9300 years.
Europe
In Northern Europe cold winter are normal, but the recent forecast for the Finnish region of Lapland warned of temperatures down to -40°C. This Finnish website here writes:
Temperatures have been low all winter in Finnish Lapland, but the cold dip expected this week could see record-breaking extremes.”
Snow and cold are also forecast across UK as the Express here reports: “Britain set for FOOT of heavy snow NEXT WEEK in COLDEST freeze for decade.”
Spain, North Africa get frostbitten and snowed on
The wintry conditions will likely impact agriculture and the European food markets. Fruitnet.com here writes: ” The cold snap gripping much of the Spanish peninsula is likely to reduce the availability of vegetables and salads on the European market during the coming weeks.”
The extreme cold has even extended beyond southern Europe and into Africa! For example Southern Morocco saw snow for the first time. And so has the Canary island of Tenerife seen its landscape get blanketed with the white stuff.
Stunning Sahara snow
Also The Mail here reports snowfall in the Algeria – the Sahara Desert. Up to December 2016 it had not snowed there in 37 years. Now according to The Mail it has snowed 4 times since, and it’s the second time this year already. “Locals were stunned to see snow on the sand dunes in the Sahara Desert yesterday.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Records in Japan
Japanese blogger Kirye here tweeted that minimum temperature dropped to -17.2 ℃ on February 2, 2018, in Ikarigaseki, Aomori Prefecture. “It is the coldest daily minimum temperature since records began on November 24, 1976! The previous record low was -16.6 ℃, set on January 18, 2014.”
Kirye also tweeted: “The minimum temperature in Fuchu, Tokyo dropped to minus 8.4 ℃ on January 25, 2018. It is the lowest daily minimum temperature since records began on December 15, 1976. The previous record low was minus 8.2 ℃, set on February 8, 1984.”
Moreover, Japan’s mean temperature anomaly for January 2018 was a chilly -0.22 ℃. Kirye writes that there’s been no warming trend for January from 1986 to 2018.
The English language NTV of Japan writes: “This winter’s harshest cold wave continues in Japan with freezing temperatures in central Tokyo recorded two days in a row for the first time in 55 years.”
Kirye adds: “The minimum temperature dropped to -3.1℃ on January 26 in Tokyo. It is the coldest daily minimum temperature for January 26 since 1965.”
Russian Snowmageddon…minus 67°C
As I already highlighted here earlier, a number of locations across the northern hemisphere are seeing surprising brutal winter conditions. Another example: media outlets have reported widely that Moscow just saw a record snowfall. Also read here.
And in the Siberian region of Yakutia, the temperature fell as low as minus 67 Celsius.
Australia and New Zealand
Even the southern hemisphere has not been spared. The weatherzone.com.au here reports “many towns in south-east Queensland have experienced their coldest February day on record”  and that “Archerfield managed only 21°C and Coolangatta on the Gold Coast 21.6°C”.
According to a local meteorologist: “These are the coldest February days that we’ve ever experienced in those places and some of those records date back quite some time.”
Finally Ice Age Now here writes that Tasmania even recorded a “summer blizzard.”
That’s a lot of winter, snow and cold for a planet that is supposedly warming rapidly.
 
Share this...FacebookTwitter "
"The BBC is under attack again, but not from its usual right-wing opponents.  This time the charge comes from those concerned about the amount of unchallenged air time the BBC gives to climate change sceptics.  The current controversy centres around an episode of the Radio 4 programme What’s the point of …, presented by Daily Mail columnist Quentin Letts, in which the work of the UK’s national weather service the Met Office is subjected to unsubstantiated criticism. Leading the attack is one of the BBC’s former environment correspondents, Richard Black. He has blasted the editors of the programme for allowing Letts to play fast and loose with the BBC editorial guidelines.  Black contends that the material in the programme, contrary to the guidelines, was not “well sourced and based on sound evidence”.  The programme is worth a close listen as it raises important questions about the presentation on air of minority views on climate change, the ubiquitous presence of non-specialist opinion in the British media, and its possible effect on audiences. The programme’s sub-title is “expensive liability or essential?”, but much of it is an attack on the Met Office over its mainstream position on climate change.  One of the first witnesses Letts introduces to attack the Met Office is Piers Corbyn, a well-known sceptic of mainstream climate science. His scientific credentials to speak on the issue are never established. A little later comes Graham Stringer, a Labour MP, who casts doubt on the link between climate change and the 2013/2014 UK flooding:  …the chief scientific officer [at the Met Office] said that this was undoubtedly due to climate change, but most of the scientists even in the Met Office looked askance at that, because there’s no scientific evidence whatsoever that rain was related to climate change. However, it turns out there is evidence to link the two, according to Dr Friederike Otto from the Environmental Change Institute at Oxford University. “I would say that Stringer is wrong”, she tells me. “We do have scientific evidence that the likelihood of these kinds of floods occurring has increased.” She and her colleagues have studied the UK floods as part of their wider research on individual extreme weather events becoming more (or less) likely as a result of climate change.   Stringer is followed by Conservative MP and self-described “luke-warmist” Peter Lilley. He is allowed to put the case for the so-called “climate pause” since 1998 without any challenge. More significantly, there is no mention that both Stringer and Lilley sit on the board of trustees of the sceptic campaigning organisation, the Global Warming Policy Foundation.  Omitting the interests of interviewees in this way does not give the listener enough context to understand their views.  You can argue that in the name of pluralism it’s desirable to have minority views on air, but they must be clearly labelled and fairly challenged. In this instance, Letts laughs along with Stringer and Lilley; only the Met Office representative is confronted. As the host of a “personal view” programme, Quentin Letts may enjoy more editorial latitude than most. But the BBC editorial guidelines are clear, stating that authored pieces, “particularly when dealing with controversial subjects, should be clearly signposted to audiences in advance”.  I may have missed it, but I did not hear Letts’ programme presented as such. Such pieces should also “retain a respect for factual accuracy”, and “fairly represent opposing viewpoints when appropriate”.  Letts could have kept the wit in his text and still have been true to the guidelines.    The wider picture in the UK media’s coverage of climate change is that in recent years it has often been non-specialist opinion that gets disproportionate time or space.  A recent study of the presence of sceptical voices in the UK print media concluded that such voices were more likely to be included in pieces written by in-house non-specialist columnists than by environment editors or correspondents. It would be worrying if the BBC was going down a similar path of giving exaggerated space to non-specialists.  Despite the recent revolution in the way people, and particularly younger age groups, consume news, the BBC is still a very well used and trusted source. Research shows that the promotion or presence of uncertainty in media reporting of climate science can act as an obstacle to public understanding and lead to disengagement, so it is critically important that the BBC provides proper context when covering such an important issue.  In one of his final comments, Letts describes the Met Office as following a “politically risky intervention on climate change said by some fellow scientists to be plain wrong”. Which scientists say this, and why weren’t they invited onto the programme? Much of the BBC’s coverage that relies on the expertise of its correspondents and editorial guidelines is first class, but problems arise when handing over airtime to others to make assertions like this without due scrutiny. Maybe it’s time for the BBC editors to dust off their handbooks."
"
Share this...FacebookTwitterGovernments promote biofuels as renewable, carbon-neutral resources that serve to reduce CO2 emissions.  Meanwhile, scientists have determined that biomass burning generates more CO2 emissions per kWh than burning coal does, and the projected rapid growth in biofuel use will only serve to ‘increase atmospheric CO2 for at least a century’. 

Sterman et al., 2018
“[G]overnments around the world are promoting biomass to reduce their greenhouse gas (GHG) emissions. The European Union declared biofuels to be carbon-neutral to help meet its goal of 20% renewable energy by 2020, triggering a surge in use of wood for heat and electricity (European Commission 2003, Leturcq 2014, Stupak et al 2007). … But do biofuels actually reduce GHG emissions?”
“[A]lthough wood has approximately the same carbon intensity as coal (0.027 vs. 0.025 tC GJ−1 of primary energy […]), combustion efficiency of wood and wood pellets is lower (Netherlands Enterprise Agency; IEA 2016). Estimates also suggest higher processing losses in the wood supply chain (Roder et al 2015). Consequently, wood-fired power plants generate more CO2 per kWh than coal. Burning wood instead of coal therefore creates a carbon debt—an immediate increase in atmospheric CO2 compared to fossil energy—that can be repaid over time only as—and if— NPP [net primary production] rises above the flux of carbon from biomass and soils to the atmosphere on the harvested lands.”
“Growth in wood supply causes steady growth in atmospheric CO2 because more CO2 is added to the atmosphere every year in initial carbon debt than is paid back by regrowth, worsening global warming and climate change. The qualitative result that growth in bioenergy raises atmospheric CO2 does not depend on the parameters: as long as bioenergy generates an initial carbon debt, increasing harvests mean more is ‘borrowed’ every year than is paid back. More precisely, atmospheric CO2 rises as long as NPP [net primary production] remains below the initial carbon debt incurred each year plus the fluxes of carbon from biomass and soils to the atmosphere.”
“[P]rojected growth in wood harvest for bioenergy would increase atmospheric CO2 for at least a century because new carbon debt continuously exceeds NPP.”
“[C]ontrary to the policies of the EU and other nations, biomass used to displace fossil fuels injects CO2 into the atmosphere at the point of combustion and during harvest, processing and transport. Reductions in atmospheric CO2 come only later, and only if the harvested land is allowed to regrow.”

Fanous and Moomaw, 2018
“These nations fail to recognize the intensity of CO2 emissions linked to the burning of biomass. The chemical energy stored in wood is converted into heat or electricity by way of combustion and is sometimes used for combined heat and power cogeneration. At the point of combustion, biomass emits more carbon per unit of heat than most fossil fuels. Due to the inefficiencies of biomass energy, bioenergy power plants emit approximately 65 percent more CO2 per MWH than modern coal plants, and approximately 285 percent more than natural gas combined cycle plants.”
“Furthermore, the Intergovernmental Panel on Climate Change (IPCC) states that combustion of biomass generates gross greenhouse gas (GHG) emissions roughly equivalent to the combustion of fossil fuels. In the case of forest timber turned into wood pellets for bioenergy use, the IPCC further indicates that the process produces higher CO2 emissions than fossil fuels for decades to centuries.”
 

Share this...FacebookTwitter "
"Cars are one of the biggest threats to the planet. The transport sector accounts for more than 60% of global oil consumption and about a quarter of energy-related carbon emissions, and it’s seen as harder to decarbonise than other parts of the economy. Typical forecasts of future world vehicle ownership point to substantial increases, particularly in the developing economies. But the problem of transport-related greenhouse gases may be less than generally thought. There is emerging evidence that individual car use, as measured by the average annual distance travelled, has ceased to grow in most of the developed economies, starting well before the recent recession. In some countries, it may already be declining, a phenomenon known as “peak car”.  A number of factors could could contribute to this trend. Suggestions have included a decline in younger people holding driver’s licences, changes to company car taxation and technological constraints that stop us travelling faster on roads. And it may be we have simply sufficient daily travel to meet our needs. There has also been a shift away from car use in urban areas. This could be particularly important in a world where future population growth will be mainly urban and densely populated cities are seen as a driver for economic growth. For example, over the past 20 years the population of London has been growing and incomes have been rising, but car use has held steady at about 10m trips a day. This is mainly because the city has not increased road capacity but instead has invested in public transport. Most importantly, rail offers speedy and reliable travel for work journeys compared with the car on congested roads. This gets business and professional people out of their cars, which makes the city a less congested and more agreeable place to be. With a growing population but static car use, London has seen a marked decline in the share of journeys by car, from 50% of all trips in 1990 to 37% currently. With continued population growth projected and more investment in rail planned, the share of trips by car could fall to 27% by mid-century. There is every reason to suppose that London will continue to thrive as car use declines – and perhaps because car use declines. This decrease in car use from 1990 was preceded by a 40-year period of growth from 1950, the result of rising incomes leading to increased car ownership – and, at the same time, a falling population as people left an overcrowded damaged city for new towns, garden cities and greener surroundings. So we see a marked peak in car use at around 1990, the time when the population of London was at a minimum, which was when attitudes to city living began to change. This phenomenon of peak car in big cities is not unique to London, although this is the city for which we have the best data. There is evidence for something similar happening in Birmingham, Manchester and other British cities as well as those in other developed countries. The shift in economies from manufacturing to services is an important driver, as is the growth of higher education located in city centres, attracting young people for whom the car is not part of their lifestyle. If car use has really peaked, both in the sense of national per capita figures and the share of trips in cities, it should help mitigate greenhouse gas emissions from transport. I have estimated that these changes in behaviour, taken together with expected developments of low-emission vehicles, could by 2050 reduce UK surface transport greenhouse gas emissions by 60% compared with 1990. This falls short of the overall target of an 80% reduction, but is a good deal better than conventional projections. Peak car is not just an emerging phenomenon to be investigated. It is a helpful trend to be encouraged, to achieve both successful, sustainable cities and national reduction of transport greenhouse gas emissions."
"
Share this...FacebookTwitter“We now seriously need a Schellnhuber timeout. […] We do hope the new PIK leadership will correct the extreme direction the institute is currently on and rapidly puts an end to the flow of climate-alarmist press releases.“
At their Die kalte Sonne site here, Dr. Sebastian Lüning and Prof. Fritz Vahrenholt comment on Prof. Hans-Joachim Schellnhuber’s stepping down as director of the alarmist Potsdam Institute for Climate Impact research (PIK).

Prof. Hans-Joachim Schellnhuber stepping down as head of the Potsdam Institute (PIK). Photo: PIK.
Schellnhuber is often worshipped by the fringe-element climate alarmists as a sort of Climate Pope, whose every uttered word is to be regarded as infallible.  Now he may be paying the price for his entrenched, radical positions on climate change.
========================================
From Die kalte Sonne here, by Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(Translated by P Gosselin)
Hans-Joachim Schellnhuber is stepping down later this year in autumn and consequently will relinquish his position as director at the Potsdam PIK Climate Institute. The successors have already been named. Over the past years Schellnhuber had increasingly become a burden for the institute. Parts of the German political spectrum had already requested his removal from the “Scientific Advisory Council for Environmental Change” (WBGU) for representing a direction leading to a green dictatorship. In the end it was likely a direct decision by the Chancellor that saved him. Recently there had been a mysterious spree publications by Schellnhuber appearing in the journal of the National Academy of Science. The suspected secret is that he was allowed to choose his peer reviewers himself as a member of the society.
Parts of the press also reported what many already suspected. Spiegel on Hans-Joachim Schellnhuber: “One is getting the impression that he has become more activist than physicist”. Here his role as a ghostwriter for the Pope fits very well as he basically put all the words of his choice into the Pope’s mouth. He almost totally ignored all the uncertainties climate science is afflicted by. His aim: The unconditional destruction of the fossil fuel industry. And as a direct advisor to the chancellor, he pushed this message to the highest levels. History over the coming years and decades will be decided by Schellnhuber’s role in the climate debate and the overly hasty rush into renewable energies. We now seriously need a Schellnhuber timeout. We do hope the new PIK leadership will correct the extreme direction the institute is currently on and rapidly puts an end to the flow of climate-alarmist press releases. What really is now needed is a balanced and rational presentation of the results, without the constant pressure of having to do missionary work.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterCO2 emissions exert no detectable effect on Arctic, Antarctic temperatures. The Arctic region is no warmer in recent decades than it was some 80 years ago, or before CO2 emissions began rising significantly.

Graph Source: Mikkelsen et al., 2018
According to the IPCC, the Arctic and Antarctic regions warm more than the rest of the globe — a phenomenon branded as polar amplification.
Further, it is conclusively stated (with “high confidence”) that this enhanced polar warming occurs largely in response to increases in atmospheric CO2 concentration.

Image Source: IPCC AR5 
A 2015 Scientific Paper Affirms CO2 Forcing Is ‘Weak’ To Negligible At The Poles
In late 2015, four climate scientists published a groundbreaking paper (Schmithüsen et al.,[2015]) in the highly-regarded Geophysical Research Letters scholarly journal.
Although obligatorily insisting their research did not undermine the main tenets of anthropogenic global warming (AGW) theory at one turn, the authors nonetheless landed a devastating blow to the conceptualization of a CO2-amplified polar climate – and thus to the narrative that says the ice sheets and sea ice are melting primarily due to increases in anthropogenic CO2 emissions.
Schmithüsen and colleagues reached the conclusion that CO2-forcing is “rather small” and even “weak“ at the poles.  They found the planet’s tiniest warming signal from CO2 occurs for central Antarctica; they characterized the CO2-forcing for the Arctic region as “comparatively weak”.    For example, quadrupling CO2 concentrations over the Antarctic Plateau is poised to yield a net radiative forcing value of just 1 W m-2.
The authors even assert that increasing CO2 concentrations causes atmospheric cooling in some areas above the Antarctic continent.  They characterize this as a “negative greenhouse effect” due to the “increased long-wave energy loss to space, which cools the Earth-atmosphere system”.
Key points from the paper are highlighted below.

Schmithüsen et al., (2015)
 

 

Warming From Increased CO2 Is ‘Comparatively Weak‘ For The Arctic Region


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





‘Polar Amplification’ From Increased CO2 Not Detectable For Antarctica
Consistent with the conceptualization that “polar amplification” from increasing human CO2 emissions has gone unrealized, the temperature records for the Antarctic continent do not suggest warming has occurred in recent decades.

Graph Sources: Climate4you, Miles et al., 2013, Turner et al., 2016
Increasing CO2 Emissions Has Exerted No Detectable Effect On The Arctic Region
Consistent with the conceptualization that “polar amplification” from increasing CO2 has gone unrealized, the temperature records for the Arctic region also do not suggest a discernible net warming has occurred in response to the rapid increase in anthropogenic CO2 emissions since the mid-1940s.  The Arctic region is no warmer in recent decades than it was ~80 years ago, or before CO2 emissions began rising significantly.  This would support the conclusion that CO2 emissions increases have exerted no detectable effect on the Arctic region’s temperatures.

Graph Source: Hanhijärvi et al., 2013

Graph Source:  Hanna et al., 2011
‘Weak’ To Negligible CO2 Forcing At The Poles Lands A Devastating Blow To AGW Alarm
If the warming effect from increasing CO2 concentrations is only “weak” to negligible for both the Antarctic and Arctic regions, then the justification to endorse the most alarming tenets of the anthropogenic global warming conceptualization may be thoroughly undermined.
For example:
1. The decline in Arctic sea ice since the late 1970s may no longer be predominantly attributed to CO2-induced Arctic warming.
2. Mass ice losses for both the Antarctic and Greenland ice sheets in the modern era may no longer be predominantly attributed to CO2-induced polar warming.
3. The net ice melt contribution to sea level rise from the Antarctic and Greenland ice sheets in the modern era may no longer be predominantly attributed to CO2-induced polar warming.
4. The post-1980s temperature warming for the Arctic region (that has significantly affected the overall global warming trend) may no longer be predominantly attributed to CO2-induced Arctic warming.
In sum, affirming the Schmithüsen et al.,(2015) analysis leaves little room for continued insistence that rising CO2 emissions are a profound and existential planetary threat.

Update: A just-published paper, Flanner et al., 2018, cites the negative CO2 greenhouse effect conceptualization introduced by Schmithüsen et al.,(2015).  At no time do the authors challenge the relatively quite weak radiative forcing values (~1 W m-2) for the CO2 greenhouse effect in the polar regions as depicted in the colorized graph above.  Instead of challenging these very small CO2-forcing values for polar regions, the authors only challenge the less consequential concept of whether or not a cooling would occur at the poles in response to increases in greenhouse gases (GHGs) in general, and not CO2 in particular.   It would appear the weak CO2 forcing (W m-2) values for the polar regions as determined by Schmithüsen et al., (2015) are accepted by mainstream climate science.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterCO2 as the major climate driver looks shakier than ever.
Scientists confirm clouds and their changes have a huge impact on the earth’s surface temperature…

Anna Possner’s research shows clouds and their changes have a real impact on earth’s surface temperature, a Goethe University press release confirms. Photo source: annapossner.com, Carnegie Science.
According to Germany’s Goethe University, Carnegie Institution for Science climatologist Anna Possner’s research on layered clouds in the lower atmosphere shows that clouds “act as a semi-transparent parasol” and “reflect a significant portion of incoming sunlight” and “have a cooling effect on Earth’s surface.” …and that cloud changes “can result in significant changes to Earth’s surface temperature”.

Clouds like a semi-transparent parasol
Released at: Wed, 09 May 2018 13:40:00 +0200 (024)
FRANKFURT. Following the Paris Climate Agreement, Germany and France created the program “Make Our Planet Great Again,“ to promote climate change research. One of 13 researchers selected by an expert jury of the German Academic Exchange Service (DAAD) is coming from the USA to the Goethe University in a few months.
The climate change researcher Dr. Anna Possner is leaving the renowned Carnegie Institution for Science in Stanford and will join the Department for Atmospheric and Environmental Sciences at the Goethe University. Thanks to a one million euro grant, she will start her own research group in Frankfurt. This group will cooperate with the Frankfurt Institute for Advanced Studies (FIAS), where it will also be located.
Anna Possner’s research focuses on layered clouds in the lowest kilometres of the atmosphere, which act as a semi-transparent parasol for Earth’s surface. They reflect a significant portion of incoming sunlight, but only marginally affect Earth’s heat emission. They thus have a cooling effect on Earth’s surface. Any sheet of low-level cloud may span hundreds of kilometres and all together they span around one fifth of Earth’s oceans. Changes in their areal extent or reflective properties can result in significant changes to Earth’s surface temperature.
In some regions of the globe, the mid-latitudes and the Arctic, these clouds consist not only of water drops, but may contain a mixture of ice particles and water drops. The proportion of water drops to ice crystals affects the clouds’ reflective properties. “While we have hypotheses about how the radiative properties may be affected within a single cloud,” Anna Possner explains, “we are limited in our understanding of how the presence of ice crystals impacts the areal coverage and reflective properties on the scale of an entire cloud field.” She will use satellite retrievals and sophisticated numerical models to help answer this question.
Since completing her doctoral dissertation at the ETH Zurich, Anna Possner, who was born in Jena, has studied the impact of particles on the reflective properties of clouds. During this time she focused in particular on low-lying clouds over the oceans, where she quantified and evaluated the impact of ship emissions on clouds. During her postdoc years at the ETH Zurich and the Carnegie Institution for Science in Stanford, she extended her analyses to include mixed-phase clouds.
The German-French program “Make Our Planet Great Again“ seeks to support the creation of solid facts as a basis for political decisions in the fields “climate change”, “earth system research” and “energy transformation”. Of the 13 scientists selected for Germany, seven are in the US, two were most recently working in Great Britain and one each is in Switzerland, Canada, South Korea and Australia. They were selected during a two-stage process out of approximately 300 applications.
Further Information: Prof. Joachim Curtius, Department for Atmospheric and Environmental Sciences, Faculty for Geosciences / Geography, Riedberg Campus, Tel.: +49 (0) 798-42058, curtius@iau.uni-frankfurt.de.
Share this...FacebookTwitter "
"Talking to a fourth-generation grazier west of Townsville a few years ago, Prof Stephen Williams says he “made the mistake” of mentioning climate change. “He said it was bullshit, but we kept talking,” the James Cook University ecologist says. Later the grazier admitted the property was much more difficult to manage than in his great-grandfather’s time because “the weather has gone to shit”. That chat with the grazier, Williams says, is one example of a “social barrier” that gets in the way of Australians taking action on climate change. “One side of his personality denied climate change was real, yet he fully recognised the climate had changed.” Analysis from Australia’s now defunded National Climate Change Adaptation Research Facility has ranked research priorities based on their urgency, cost-effectiveness and technical feasibility. The conclusion is that research into social barriers should be given the highest priority to help save the country’s ecosystems from climate change impacts. Williams was the co-ordinator of the facility’s natural ecosystem network, covering climate impacts on land, in freshwater systems and in the marine environment. The analysis, published in the journal Global Change Biology, drew on eight years of consultations with about 2,000 scientists and stakeholders, at more than 50 workshops. “They all recognised that the only way we were going to get anything important done was to get the whole of society on board,” says Williams, the lead author of the analysis. “Social barriers came out as the most highly ranked question to answer. There are all sorts of social barriers to us adapting to climate change. “Some are purely the psychological make-up of people that don’t want to acknowledge a problem, some of it is a government more interested in elections every three years, and some is the vested interests of industry that undoubtedly confuse the issues. They are all barriers. “We are a group of physical scientists and biologists,” Williams says, “but we came up with this reasoning that we need to do some social research. “We’ve had highest temperatures ever, and the longest and most intense heatwaves geographically, and we’ve had floods happening at the same time as the biggest drought, and have seen rainforests burning. “What’s the social resistance against something that is so in your face, yet people still want to stick their heads in the sand and deny it? It is the social barriers that are stopping us and it is incredibly frustrating.” Adaptation is going to be critical to Australia. Mitigation has to be global, but adaptation can be local Climate adaptation looks at ways to reduce the impacts of climate change that are unavoidable, and is distinct from mitigation, which focuses on reducing emissions. “Climate change mitigation is about avoiding the unmanageable,” says Dr Alistair Hobday, a research director at CSIRO Oceans and Atmosphere and a co-author of the analysis. “Adaptation is about managing the unavoidable. Adaptation is going to be critical to Australia. Mitigation has to be global, but adaptation can be local.” Hobday says that as well as understanding why some might see climate change as a lower priority, another barrier is public resistance to translocating species that are not able to adapt or move as temperatures and rainfall change. “These are situations where people resist doing something despite the evidence that the animal’s world is changing,” he says. The only example of a project like that in Australia is a pilot study that has moved 35 captive-bred western swamp turtles to new sites in south-west Western Australia. Prof Lesley Hughes, of Macquarie University, and also an author on the analysis, says there has been resistance to “interventions” like translocation, but this needs to change. Despite 30 years of research looking at how climate change would affect habitats, she says, very little work has been done to protect species. Other priorities identified by the analysis are to make environmental and planning laws more proactive, and to improve understanding of the effects of extreme events on ecosystems. NCCARF was launched in 2008 with $47m of federal government funding over five years, and then a further $8.8m to 2017. A final $300,000 of funding ran out in June 2018, and the facility is now vastly scaled-down and operating through Griffith University. Williams says it is “frustrating” that NCCARF has not received continued funding when it has built a foundation of research that could be exploited. “We had got to the stage where in the next five or 10 years we were really going to start to achieve things, and that’s when it got chopped.”"
"The furore over Cecil the lion clearly demonstrates that the public are passionate about conserving wildlife – wherever it is. Yet conservation spending in richer nations is still trapped in a parochial “home first” mindset. Given most plants and animals, and particularly endangered species, are found in poorer countries where money goes further, why are we worrying about hedgehogs, squirrels or wild boar? Last year, around £571m of public sector funding was spent on UK biodiversity. However only £60m was earmarked for international biodiversity, barely 10% of the total budget. From a global perspective, the UK contains only a tiny proportion of the world’s biodiversity. In terms of diversity of species, it ranks 89th in the world, and that’s despite the country’s wildlife being recorded far better than most.  If we are really serious about conserving biodiversity then perhaps those two budgets should be reversed. We’re likely to get far greater “biodiversity for our buck” on every pound spent abroad, especially if we focus on the world’s poorest developing countries, many of which are in global biodiversity hotspots. The government’s flagship Darwin Initiative has been striving to achieve exactly this. Since 1992 it has received just £113m, but supported 943 projects in 159 countries, and its achievements speak for themselves. Projects have ranged from supporting the only national herbarium in Papua New Guinea, developing a conservation action plan for the mammals of Tanzania and conservation for critically endangered species such as the spoon-billed sandpiper and sociable lapwing. Those projects averaged only £200,000 apiece. In contrast, our domestic concerns couldn’t appear more mundane. Take, for example, the iconic red squirrel, that bastion of British conservation. In a rearguard action to slow their decline, we are spending at least £1.2m from both public and private sources on their conservation. The government recently approved a scheme to fund population control of invading grey squirrels at £100 per hectare over five years, with a cost likely to run into the millions. In 2012 we even helicoptered five reds to Tresco on the Isles of Scilly to establish a new population (three died shortly afterwards).  Reds are listed as “least concern” by the main conservation body, IUCN. Their population is widespread and non-threatened in Europe. Meanwhile, in southern Africa, critically endangered black rhinos are being airlifted to establish insurance populations against the very real threat of extinction, and the Northern white rhino will shortly become extinct because we acted too late. In an ideal world maintaining our native squirrel would be a justifiably worthwhile thing to do. But in the face of global biodiversity loss, does the colour of our squirrels really matter? If there is even a tiny chance that our limited biodiversity funding could be better spent, then this is a debate that must be had; but only if we are clear that biodiversity and conservation is our aim, rather than locally emotive projects. Public spending is one way of understanding the priority that is given to different issues in a democracy. These figures suggest an inward-looking nation, at precisely at a time when we need to propel biodiversity issues to the world stage if we hope to encourage meaningful commitments at the Paris climate talks later this year. The outcome will have far reaching repercussions for global biodiversity and for us all. But it need not be a black and white choice; perhaps we could invest internationally and reap the benefits at home. Perhaps protection of critical habitats abroad might actually improve UK biodiversity. Birds such as nightingales, cuckoos and turtle dove all migrate from Africa, but numbers have dropped 73% since the late 80s, probably due to habitat loss in both the UK and sub-Saharan Africa. Could it be more cost-effective to conserve migratory species in other parts of their range? Would we then see larger populations returning to British shores? More importantly, would the public support it? There is yet another opportunity for compromise in the form of the UK’s Overseas Territories; these small islands such as Bermuda, the Turks and Caicos or Saint Helena represent proverbial jewels in the country’s biodiversity crown. Just 7,000 square miles (excluding British Antarctic Territory) supports an estimated 90% of UK biodiversity. This includes around 180 endemic plants (there are just 12 on the UK mainland) and 517 globally threatened species. The territories are home to 23 endemic birds, with at least 14 having already become extinct, largely due to humans.  The UK spends around £3m per year on environmental protection in these territories, but this still falls far short of the estimated £16m needed to meet international biodiversity commitments. Finally, to give us some perspective, it’s worth remembering that in 2013/14 the £571m spent on biodiversity amounted to just £3 for every £10,000 of GDP. So all things considered, we really can have our cake and eat it. We could support biodiversity at home while increasing spending abroad and barely cause a ripple in GDP. Our investment to date is but a drop in the ocean."
"The army has been called in to help firefighters deal with a huge wildfire on Saddleworth Moor, Greater Manchester, where residents have been forced to evacuate. Wildfires are also blazing across Northern California while the issue of bushfires in Australia calls for constant vigilance from the emergency services there. These fires are becoming more common and one of the reasons for this is climate change. Warmer temperatures in the summer and associated drier conditions desiccate plant materials and create more vegetation litter, providing more fuel for these fires. Several studies have linked the increase of wildfires with climate change in various parts of the world, such as North America and Southern Europe. For example, a study in California from 2004 found that the warmer and windier weather (brought about by an atmosphere with higher levels of CO2) produced fires that burned more intensely and spread faster in most locations. Despite enhanced firefighting efforts, the number of escaped fires (those exceeding initial containment limits) increased by 51% in the south San Francisco Bay area, 125% in the Sierra Nevada. It has also been demonstrated that increases in rainfall during winter and spring – which are also known consequences of climate change – provide more favourable conditions for plant growth and therefore more potential fuel for the fires later in the summer. Even though climate change increases the vulnerability of dry environments to wildfires, a source of ignition is still required. In the UK, it can be natural (such as bolts of lightning) or caused by man either deliberately or accidentally. Various studies have shown that the number of recreational visits to “risky” sites, such as the English Peak District, increase the occurrence of wildfire. Human activities have shaped heathlands and moorlands in the UK over the centuries, keeping them open and slowing down the natural succession towards more closed forest habitats. Despite the human impact on their origin, moorlands represent important ecosystems for numerous endangered species including reptiles, insects and birds.  But historic poor management has caused a lot of damage in moorland habitats. The introduction of non-native species for the moor, such as Rhododendron or planted conifers, has affected biodiversity. Overgrazing and drainage has increased the risks of erosion and flooding by reducing vegetation cover and limiting the ability for the soil to absorb precipitations. This, in turn, as lead to an increase in aridity of the habitat – which is the perfect environment for wildfires. Nowadays, most of the UK’s moorlands are associated with red grouse shooting and are managed in relation to that activity. Procedures include rotational burning and control of predators. Some of these processes are controversial with some environmentalists claiming it can turn the moorland into a  “monoculture” of low heather which can be highly susceptible to wildfires. But the evidence on this is not clear and a report by the RSPB found little proof of the negative effect of grouse moor management on biodiversity, flooding and wildfires. Landscapes and their plant and animal communities are not fixed in time. They are under the influence of dynamic processes that can be recurrent (such as marine tides and seasonal flooding) or catastrophic (volcanic eruptions or storms). Fire – whether natural or man-made – is an important factor that will drive the structure and wildlife composition of ecosystems. Some areas, such as the Mediterranean region or the African savannah, have been shaped by fire for thousands of years. Plants and animals have evolved to cope with the periodic perturbations due to it. For example, some seeds can only germinate after they have been burnt.  There are even some plants and animals that are contributing in the propagation of wildfires. In Australia, some raptor birds have been observed picking up burning sticks and dropping them in unburned areas to force potential prey out of their burrows. Despite its destructive power, fire is an important ecological process that can benefit several endangered species by maintaining their habitat. It is an important tool in the management and preservation of heathlands and moorlands in the UK when used appropriately and in a controlled way. But climate change and human activities increase the vulnerability of those habitats to uncontrolled wildfires and higher population densities near these areas will potentially put more people and houses at risk. In addition to the global battle against climate change, appropriate management procedures are necessary to maintain those habitats and ensure the risks of uncontrolled fires are minimised and the potential spread of them reduced."
