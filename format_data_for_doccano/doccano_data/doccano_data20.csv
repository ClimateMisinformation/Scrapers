"
Share this...FacebookTwitterBy Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German excerpts translated/edited by P Gosselin)

On February 27, 2017, the DWD German National Weather Service concluded in its February report:


February 2017 was much too warm and with only average sunshine


Offenbach, 27 February 2017– At the beginning of February 2017, it was still cold in the north-east due to the influence of high pressure. However, low pressure troughs bringing milder air were already reaching into the south and west of the country. Then, from the middle of the month onwards, all parts of the country were exposed to a powerful westerly airflow that brought much precipitation. These conditions culminated on 23 February with storm gusts, particularly in the west, and spring-like temperatures in the south. Overall, February was much too warm and precipitation and sunshine were almost balanced. This is what the initial analysis by the Deutscher Wetterdienst (DWD) of data from its around 2,000 weather stations shows.”


Continue reading at DWD.
The recent February was much too warm! One can easily imagine as follows: A wild temperature peak standing out well above the otherwise usual temperatures. Once again more proof that for years things have been going in only one direction: only hotter and hotter and hotter.
However the DWD does not provide any chart along with its press release. Wouldn’t many people certainly like to see the February heat trend as a chart? It’s a pity that the DWD chooses not to show charts here.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Thankfully Josef Kowatsch stepped in for the DWD and produced a chart using the official DWD data to show the February mean temperature curve for the last 30 years:

Figure: Chart of the February mean temperature over the past 30 years in Germany, data from the DWD, chart: Josef Kowatsch.
The sense of wonder is large: What do they mean by “much too warm”? The climate trend over the past 30 years for February shows a clear downward movement. This year’s uptick is nothing unusual and has happened regularly over the past 3 decades. nach.
This is truly a poor showing by the DWD, which misled the citizens. There is absolutely no reference made to the last 30 years, no chart, no context. This is a most dubious politicization of the weather report…
Moreover what follows is the trend of the North Atlantic oceanic heat, which shows a very clear cooling trend has taken hold since 2007:

Figure: Trend of the North Atlantic heat down to a depth of 700 meters over the past 60 years. Chart: Climate4You

Share this...FacebookTwitter "
"Vultures are nature’s garbage disposers. They’re perfectly adapted to keep the environment clean and healthy by efficiently locating and consuming carcasses, recycling energy through the food web and preventing the spread of diseases. It’s an unpaid role. However it’s about time we did start repaying vultures for their services, by giving them the protection they deserve. A new study published in the journal Genome Biology illustrates just how finely-tuned these birds are. The researchers perform a whole genome analysis of the Eurasian cinereous vulture (Aegypius monachus) and reveal a unique genetic make-up that explains vultures’ strongly acidic digestive system and their ability to resist infection from pathogens present in the rotting carcasses on which they feed. It’s even possible vultures are able to exploit the flesh-eating properties of some bacteria to aid with the digestion of soft tissues and bones, while the secretion of corrosive gastric acids and specialised immune responses allow them to resist infection from, and potentially even destroy, highly infective pathogens such as anthrax and brucellosis. This unusual tolerance of natural toxins doesn’t protect vultures from man-made contaminants however, which explains why 69% of vulture and condor species are listed as threatened or near-threatened, most of which are classed as “endangered” or “critically endangered”. The California condor (Gymnogyps californianus), for instance, was declared extinct in the wild in 1987 when the last remaining individuals were removed and placed in captivity to protect them from lead poisoning from ingesting shot and bullet fragments from hunted carcasses. Although captive-breeding and release programs have allowed the wild population to increase to more than 200 individuals, lead poisoning continues to cause fatalities. Across Asia the big problem is accidental poisoning by diclofenac, an anti-inflammatory used to treat cattle. In vultures and some eagle species, tiny traces of the drug can lead to fatal kidney failure within 48 hours. In just 15 years, cow carcasses contaminated with diclofenac nearly wiped out three of Asia’s vulture species. This had a big knock-on effect. With less competition at carcass disposal dumps, where people once let vultures pick dead animals clean, India’s feral dog population exploded. This caused higher rates of rabies transmission at an estimated additional cost of US$34 billion to the country’s healthcare between 1993 and 2006. Although some populations have started to recover following the ban of diclofenac in India in 2006, a logic-defying 2013 approval to licence the drug for use in Europe now threatens vultures there too, particularly in Spain and Italy. In Spain, replacing the natural carcass disposal service provided by vultures with vehicle transport to processing plants would result in the equivalent of an additional 77,344 metric tons of CO2 being emitted to the atmosphere and US$50m of additional payments to insurance companies each year, according to a 2014 study in Nature. The situation in Africa is just as grim – “another continental vulture crisis”, as one group of researchers described it earlier this year. Populations of seven species have declined by more than 80% in three generations, giving rise to calls for six of those to be listed as “critically endangered”.  Once again man-made toxins and illegal activities are to blame. Poisoning accounts for 61% of vulture deaths, 29% are attributed to the trade in vulture heads and brains for local cultural beliefs# and 9% of fatalities are caused by electrocution or collision with power lines. Widespread poisoning is certainly the most immediate threat. Usually this happens after farmers target lions, leopards or hyenas that have been attacking their livestock. Vultures consume the poisoned predators or the baited carcass itself and subsequently become secondary, inadvertent victims. However the booming illegal trade in ivory and rhino horn is also bad news for them, as poachers don’t want hundreds of circling vultures pointing authorities towards recently-killed elephants or rhinos. Poachers are therefore deliberately targeting the birds by lacing carcasses with poisons – even after they’ve left with the tusks or horns. More than 500 vultures were poisoned at a single poached elephant carcass in Namibia in July 2013, and the recent discovery of at least 26 elephants poisoned at cyanide-laced water holes in Zimbabwe will also likely result in many vulture deaths. Why isn’t this a bigger scandal? After all, as many, if not more vultures are being killed in southern Africa each year as rhinos or elephants. Perhaps these big, bald, flesh-eating birds are perceived as sinister and lacking enough “cute factor”. But while vultures don’t share the good looks of penguins or puffins, the ecosystem services they provide are irreplaceable. They compete with – and control – populations of blowfly larvae, rats, feral dogs and other scavengers, many of which are disease vectors. They ultimately make the world cleaner and healthier. In fact, the ecological niche occupied by today’s vulture species is so specialised that two unrelated groups evolved on opposite sides of the world to become the primary scavengers in their ecosystems. “Old World” vultures from Eurasia and Africa and “New World” vultures and condors from the Americas might look and act the same but as the latest study highlights they don’t share a recent common ancestor, having diverged in evolutionary terms more than 60m years ago.  This is a classic example of “convergent evolution” – while Old World vultures share a common ancestry with eagles and New World species are more closely related to storks, they independently evolved similar specialisations to fulfil the important role of recycling carrion. It’s time for us to appreciate these unique and highly-specialised birds. We must restrict harmful veterinary drugs, control illegal poisoning, provide uncontaminated sources of food and reduce the impact of power lines and wind farms. This must happen immediately to avoid a worldwide vulture crisis – and all of the negative implications for our own health and well-being."
nan
"The Paris agreement was a diplomatic triumph. The nations of the world spoke with one voice of their desire to limit the damage of climate change. But there is a distinct disconnect between the ambition and the action required to achieve that goal. Going into the talks, countries had indicated what they would do to contribute towards cutting back on greenhouse gas emissions. Totting up these promises would lead to a world warming by about 2.7°C – far more than the 2°C threshold of “dangerous” climate change. The fine words of Paris, reaffirming the commitment to avoid crossing 2°C – and indeed aiming towards a 1.5°C limit – are at odds with what has happened in the past, what is currently planned to happen and even what is achievable in the future. The simple truth is that stabilising the climate will require net emissions to fall to essentially zero, and we are nowhere near close to that. To have a good chance of avoiding the 2°C threshold we’d have to limit the total amount of carbon burnt (over all time) to less than a trillion tonnes. So far we have burnt about 600 billion tonnes and will use up the remainder before 2040. For a 1.5°C limit, we have only 100 billion tonnes of burnable carbon left, which will be used well within the next decade. Nations seem to be mouthing the “make me virtuous, but not just yet” prayer of Saint Augustine. Globally, emissions will accelerate at least up to 2030 when they need to begin heading rapidly in the other direction. Even with the most ambitious mitigation efforts it seems inevitable that we will overshoot the level of carbon dioxide in the atmosphere that is compatible with a stable climate.  To salvage the situation from such an overshoot would require that emissions go negative – that we remove more carbon dioxide from the atmosphere than we emit. There are certainly plenty of ideas. We could use biological methods like planting more trees or managing soils in such a way that they hold more carbon. Then there are the chemical methods. We could find a way to accelerate the rate at which minerals naturally weather and draw carbon out of air. Or we could set up “artificial trees” that suck carbon dioxide from the air.  Proponents have produced fancy artist’s impressions of what such artificial trees might look like. But the key point to note is that no such system has been built at anything like this scale. Getting the concept off the drawing board and into the real world is going to take a lot of time and money, and even then may turn out not to be feasible.  None of these is a get out of jail free card. They may be a get-out-of-jail-at-vast-expense card, but even that we cannot be certain of. All of the proposed methods have side-effects that may well balance out the good points. Planting trees sounds wonderful, but to make a material difference to the climate it would have to happen on such an enormous scale that it would severely restrict the ability for us to grow food and protect biodiversity.  And artificial trees would use vast amounts of energy and money – resources which humanity has alternative uses for.  We do not know which, if any, of the proposed techniques could be a deployed at a material scale. We need to understand whether these proposed techniques are technically possible, environmentally sound and socially acceptable. While the ambition to avoid dangerous climate change has been stated and the recognition that negative emissions will be required to achieve that objective is understood, there is a disconnect between what is being done and what is required. There is an implicit reliance on a suite of techniques that are essentially science fiction and a negligible evidence base with which to determine whether they could be transmuted into scalable fact. It’s as if a new disease was discovered and governments around the world committed to its eradication, but failed to provide any of their own resources, or provide incentives to anyone else to mobilise resources, to develop a cure. There’s a story about a man who has fallen on hard times. He prays to God: “Please, God, let me win the lottery”. Week after week he fails to win the lottery and his situation deteriorates. Eventually he climbs to the top of a cliff and cries out “God, if you don’t let me win the lottery, I’m going to kill myself”. A crash of thunder and a booming voice rings out “For goodness sake! Meet me halfway. Buy a ticket!”"
"
Share this...FacebookTwitterThe Sun In February and Arctic Sea Ice
Von Frank Bosse und Fritz Vahrenholt
(Translated and condensed [due to time constraints] by P. Gosselin)
The star at the center of our solar system was also very inactive last month. The determined sunspot number SSN of 26.1 was only 50% of what is normal.
Fig. 1: Mean solar activity (blue) compared to the activity of the current cycle (red) and the very similar solar cycle 5 (black).
A comparison of all the cycles:

Fig. 2: The activity of all cycles 1 to 24. Depicted is the deviation from the mean. The current cycle began in December 2008 and is the 3rd quietest since systematic observations began in 1755.
The behavior of the solar polar fields also indicate that the upcoming solar cycle 25 could be as weak as SC 6. According to the current conditions, we could experience a solar minimum that is similar to that experienced during the Dalton Minimum (SC 5, 6 and 7) of 1790 – 1830. The strongly decoupled polar fields is a phenomenon that has yet to be observed since systematic observations began in the 1970s – a time when the solar activity was stronger than at any time ever observed.
Antarctica: So little ice as never observed before! 
Last month we saw plenty of headlines about this. The German ARD remained rather factual, but others were dramatic and even employed photo-shopped images suggesting climate alarm. First the facts: This year’s ice extent is at a record low, as is referenced by the NSIDC in its report. Here’s the chart:


Fig. 3:  Sea ice extent around Antarctica in February compared to 1979 (in %). Source.
The dashed line depicts the overall trend, and it remains strongly upward. The long-term trend is what counts when it comes to climate. Yearly fluctuations are related to weather. A look at the GISS temperatures across Antarctica shows no relevant trend.

Fig. 4: Antarctic surface temperature as to GISS.
What follows are the sea surface temperatures (SST). Here we see where the sea ice loss is coming from:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Fig. 5: Temperature anomaly of the ocean surrounding Antarctica. 
Here we recognize the downward trend since the 1990s, followed by a sharp upward spike at the end. Certainly much of this has to do with the weather at the end of 2016, more precisely since September.  There is no real information on what is behind the spike.
One suspicion is the very powerful El Nino of 2015/16, but such a spike did not follow the El Nino 1997/98. It must be kept in mind that there were some real global differences between the last powerful El Nino and the one from the late 1990s, see study here. One suspects that a chain of events may have unfolded which led to a warming of the water around Antarctica. Next year will likely tell us if this is only a temporary powerful warming spike, or if it is the start of a trend reversal.
Media reports that global warming is now catastrophically reducing sea ice around Antarctica are however, wild speculation. In a recent study here on the AMOC, it is determined that a powerful heat transport towards the North causes a special pattern: The sea surface temperature (SST) cools and the depths get warmer. The deeper water at the edge of the continent down to 700 meters shows a warming trend. Here’s a look at the lower depths there:

Fig. 6: Ocean temperature anomalies down to 700 meters deep around Antarctica.
The divergence between the lower layers and its surface can be clearly seen. In Fig. 5 we see the sudden positive spike in SST, but the ocean down to 700 meters cannot of course follow along due to its high thermal inertia.
In the North Atlantic we do see, however, a retreat in heat transport since about 2012:

Figure. 7: The surface temperature anomalies in the sub-polar North Atlantic since 1980.
It may very well be that the El Nino is in part causing the “see-saw” effect: A stronger northward directed heat transport (strong AMOC) cools the water at the sea surface of the ocean (the sea ice grows) around Antarctica while it gets warmer in the water depths. A weaker AMOC (Fig. 7 favors a diminishment compared to the years after 1998) reverses the condition in the south: it gets warmer on the sea surface (sea ice melts) and the depths get colder.
We await with suspense the measurements around Antarctica to see whether this is the case. These are all natural processes, and whether man-made warming plays a role — if yes, how much of a factor it really plays — is completely unclear.
It is far too early to start blaring out that man is melting the Antarctic. Propaganda and science do not go well together. The internal variability of the currently cooling North Atlantic is simply “nature at work”.

Share this...FacebookTwitter "
"If we cannot figure out how to properly test car emissions, we might as well give up on regulating forests, factories or garbage dumps. After all, cars ought to be ideal targets for environmental regulators. They’re largely standardised – most look and act more or less the same – and they’re produced by the thousand or million. Test one Volkswagen Polo and you should have tested them all. In theory. Yet it hasn’t worked like that in practice. A month after the VW scandal broke most eyes are still on the German carmaker and its plunging shares, the desk clearing in management, and its hectic efforts at retrofitting. Fewer people are reflecting on what the scandal means for our system of environmental governance. This is missing the bigger story. In a way, the emissions scandal shows there is a difference between clever cheating and dumb cheating. By its own admission, Volkswagen tampered with the car’s software in order to get good emission figures in testing mode. This is dumb cheating, especially if you get caught: it’s clearly against the rules. But what if car manufacturers and regulators agree on a set of rules for testing that could deliver good figures for fuel efficiency? It is widely known that cars achieve notably better mileage per gallon on the test stand than in everyday practice. In fact, the difference has increased dramatically in recent years: according to the International Council on Clean Transportation, the NGO whose emission tests led to the fall of Volkswagen, the gap between official and actual carbon dioxide emissions in new European cars grew from 8% in 2001 to 40% in 2014. Such a divergence is clearly misleading customers and the general public, but it’s not illegal. That’s smart cheating. Standard setting on environmental matters is a murky area that few people bother to enter. Scientific results may provide some guidance, but there is always room for interpretation, and many rules and regulations are negotiated behind closed doors. The botched numbers for fuel efficiency are a good occasion to take a closer look. Is this the power of the automobile industry at work? Is this about lazy bureaucrats whose principal aim in life is to be out of the office at five? Or maybe it is about a third party such as the facilities that do the actual testing? Negotiations over test procedures are inherently boring, but they matter a lot. If the upcoming Paris climate summit finally seals a deal on global warming, it will all be about numbers, and there will be endless worries if we can no longer trust them. Thanks to standardised mass production, cars should be one relatively simple part of a global system of emissions regulations. If we cannot secure reliable numbers here, we are in trouble when it comes to forests, soils, and other parts of the biosphere. The trouble with test procedures is particularly disturbing since there really is not much room for debate. It is obvious that numbers should be accurate and that tests should reflect the real world. It’s also clear that an independent authority should certify the rules. The Volkswagen scandal indicates the industrial economies of the West cannot sustain that kind of independence anymore. When today’s framework of environmental governance evolved in the 1970s, the general idea was that environmental ministries and other government bodies would serve as a counterweight to the vested interest. Now it turns out that the presumed watchdog is curiously reluctant to bark. A lot has been written over the last month about the loss of trust, but it’s really a matter of institutions rather than morals. Maybe we need a watchdog for the watchdog? Volkswagen has shown the huge toll of dumb cheating, but the scandal also suggests the risk of getting caught was not significant. The story only broke because of a study that worked with a grand total of three cars, two of which happened to be Volkswagens. A cash-strapped NGO could not afford to cast a wider net, and it was a matter of luck that it made the right choices. No system of environmental governance can rely on these kinds of coincidences. Volkswagen’s managers are red-faced, but that will be a temporary thing. They will either change their corporate culture, or there will be no more Volkswagen managers. Whether regulators are red-faced is anyone’s guess, but they certainly should be embarrassed. The question is whether anyone bothers to look them in the face."
"There is nothing as awe-inspiring as watching the brutal power of a lion capturing its prey. At close range, their throaty roars thump through your body, raising a cold sweat triggered by the fear of what these animals are capable of doing now, and what they once did to our ancestors. They are the most majestic animals left on our planet, and yet we are currently faced with the very real possibility that they will be functionally extinct within our lifetime. In fact, lion populations throughout much of Africa are heading towards extinction more rapidly than previously thought, according to new research by Oxford biologist Hans Bauer and colleagues, published in PNAS. The team looked at 47 sites with credible and repeated lion surveys since 1990, and found they were declining everywhere in Africa aside from four countries: Botswana, Namibia, South Africa and Zimbabwe.  West and Central African lion populations have a 67% chance of halving in size in just two decades, and East African populations a 37% chance. Almost all large lion populations that once exceeded 500 individuals outside of southern Africa are declining. These declines in Africa’s apex predator occur at the same time that the continent’s mega-herbivores are also plummeting. Governance problems are less severe in the southern regions. These countries have also recognised the sad reality that large dangerous wildlife often come off second best when interacting with people. Consequently, these countries often fence their conservation areas. Where lions are free to wander in and out of East Africa’s flagship reserves like the Serengeti or the Masai Mara, their cousins in South Africa’s Kruger National Park are fenced in. This is a sad acknowledgement that our existing conservation actions aimed at living alongside wildlife are failing, but a robust analysis conducted recently points to the value of fences. Though they fragment habitats, potentially lead to genetic isolation and require costly upkeep (some say too costly) smaller, fenced reserves may be lions’ best hope. It takes a lot of hard work to maintain the fences and keep the animals in – and poachers out. Bauer and colleagues caution that lions “may no longer be a flagship species of the once vast natural ecosystems” across much of Africa. Research I’ve carried out with colleagues just published in the same journal reinforces the devastating implications this will have on their wider ecosystems.  We predicted what the mega-predators of the Pleistocene (2.5m to 11,700 years ago) would have killed. These predators, including sabre-toothed cats, cave lions, dire wolves and Homotherium (scimitar-toothed cats), were substantially larger than their modern day equivalents and were faced with a lot more competition from rival carnivores.  The largest of these would have regularly killed prey up to the size of juvenile mammoths and mastodons. This is likely to have meant some degree of top-down limitation on numbers of mammoths, giant sloths and other mega-herbivores, protecting the landscape and keeping ecosystems balanced. When the mega-predators died off – over the past 10,000-40,000 years or so – this control was lost. And this same lack of top-down limitation of herbivores by predators is likely to happen again as today’s lion populations are lost.  We can get a sense of these changes from the fact lion pride sizes are getting smaller. Lion pride sizes averaged about 24 between 1885 and 1950, and have declined dramatically to about nine since then. Human hunting seems likely to be the driver of this decline where larger prides were easier to detect and therefore hunt, which led to artificial selection against large prides.   Given cooperation between lots of lions is needed to successfully hunt an elephant, smaller prides mean smaller prey. These days only a few sites with unusually large prides have lions that actively hunt the biggest species, including elephants. Such a change in impacts of apex predators is likely to lead to fundamental changes in the ecosystems in which they live. There will be less control of herbivore numbers, so overpopulation may become an issue. Indeed controlling overabundant herbivores such as kudu antelopes has been the primary driver behind reintroducing large predators in Africa. With dense bushes near rivers and other obvious ambush spots no longer being so risky, vegetation will change. Those bushes will be eaten away. This may benefit some species at the expense of others and will have cascading effects throughout the ecosystem. As they sit at the top of Africa’s food chain, declining lion numbers highlight a wider conservation crisis. Learning more about lions and funding on-ground action to protect them, coupled with improved and open governance of states in which they live, could help to avert this crisis."
"
Share this...FacebookTwitterAt this point last year global warming alarmists and global socialism politicians were as giddy and as optimistic as ever. Everything was falling into place as it looked as if nothing would prevent them from imposing their green regime. The Pope was on their side, global temperatures had been near record highs (thanks to an El Nino event) , and Hillary Clinton would surely go on to become President of the USA.
Warmist agenda now getting torpedoed
With Clinton at the helm, the US would wholeheartedly commit to Paris and to strict decarbonization. Never did the green dream look so promising. But then came the mother of torpedoes, President Donald Trump.
And now there’s yet another torpedo about to slam into the already badly damaged warmunista ship: a rapidly approaching La Nina. In the wake of last year’s El Nino event, global temperatures had already been falling. A La Nina will only cause the globe to cool further. This is surprising because just months ago experts had predicted El Nino conditions to return.
La Nina powers in
The global warming alarmists are in sheer desperation and panic, as made evident by their hysterically shrill reactions to the recent hurricanes. The latest forecast shows a return to La Nina conditions (and a global cool-down).
Source: http://www.cpc.ncep.noaa.gov/shtml
The above chart shows La Nina conditions expected to persist into spring, 2018. This cooling will make itsself evident in satellite data with a lag of about 6 months. This means global temperature will fall even further next year, which means the warming pause will go beyond 20 years.
Note the intensifying La Nina conditions forecast for the end of the here in the following NCEP chart for the rest of the year:

 
This oncoming La Nina development led meteorologist Dr. Ryan Maue to comment on Twitter:

La Niña means extreme winter weather — colder global temperatures — and all sorts of interesting things.  Are you prepared for it?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




— Ryan Maue (@RyanMaue) September 14, 2017

Not only La Nina is serving to cool global surface temperatures, but so are the powerful hurricanes as well. Yesterday at the Weatherbell Daily Update, Joe Bastardi showed the effects of hurricanes Irma and Jose on sea surface temperature (SST).

Note the band of cool water through the Caribbean and a substantially cooled down Gulf of Mexico. Just a week ago reports abounded on how the waters there surface had been “bathwater warm”. So quickly can weather change. True, there remains considerable amounts of heat at the ocean surfaces.
Frigid winter projected for Europe
The recent winter projection for Europe issued by Meteociel below shows Europe possiby being gripped by a frigid winter. If the prognosis holds, it could be one of the coldest in years:

Meteociel/CFS prognosis from 30 August 2017,  850 hPa temperature deviation from the mean (about 1500m) in Europe for the 2017/18 winter. For Europe very icy conditions are expected (from left to right: December, January, February). Source: www.meteociel.fr/php
Arctic sea ice rebound
Also the Arctic has shown recovery over the past years. This year’s Arctic sea ice for mid September is about a full 1 million sq. km. over the record low set 5 years ago.

Overall Arctic sea ice has remained stable for the past 10 years, surprising global warming scientists. Source: National Snow and Ice Data center (NSIDC).
 
Share this...FacebookTwitter "
"Rural communities in the Amazon rainforest live alongside an incredibly diverse set of animals. When some of those animals damage and eat farmers’ crops (“crop-raiding”), it creates a challenge for conservationists, who need to understand the lives of the people who coexist with that wildlife. My colleagues and I recently spent a year in the Médio Juruá region of Amazonas, Brazil, using motion-activated camera traps to take photos of the many animals that live on or near Amazonian farms. Along with interviews of farmers, this enabled us to study which animals cause the most crop damage, how this affects the livelihoods of rural Amazonians and how these communities respond to crop raiders. Our hope was to understand how this issue might affect attempts to preserve wildlife and to offer support to local farmers if they wanted it. The Médio Juruá region is a vast area of staggeringly biodiverse lowland tropical forest inhabited by river-dwelling communities, who descend from a mix of indigenous Amerindians, European colonists and former slaves from Africa. Our research team (comprising myself, my colleague Professor Carlos Peres, and Hugo Costa from the State University of Santa Cruz) travelled using small boats and dug-out canoes along the sinuous waterways and through the flooded forests. The region experiences a massive ten metre-high annual flood, which has wide-ranging impacts on the local ecosystems and the livelihoods of the human inhabitants. In the year we spent living and working with the communities of the Juruá, we were fortunate enough to participate in many aspects of life, including learning to harvest the fruit of the acai palm. Many Juruá communities are the descendants of rubber tappers (seringueiros) who were drawn to this region during the rubber boom of the late 1800s. Many still depend on the natural resources of the forest and river for their livelihoods. The incredibly hospitable communities of the region frequently hosted and fed us as we travelled.  Most of the carbohydrates in rural Amazonian diets come from manioc (also known as yucca or cassava). This tough plant grows well on infertile tropical soils and has powerful chemical defences which make it pest-resistant. Farmers grow manioc using so-called “slash-and-burn” agriculture in fields called “roçados”, which are created by burning down a section of forest. They peel, grind, soak, drain and toast the manioc to remove the toxic cyanide which protects the plant from pests. The result of this process is delicious coarse flour called “farinha”, which is commonly eaten with fish soup.   Despite high levels of toxins in raw manioc, some wild animals such as large rodents, deer and pig-like peccaries are able to eat it. These crop raiders can have devastating impacts on human livelihoods, destroying an average of around 8% of each farmer’s crop each year. Farmers estimated that if they did not protect their crops, their losses would be roughly ten times higher. In other parts of the world, large herbivore crop raiders such as African and Asian elephants also endanger the lives of farmers. Of course, these wild and often endangered species are merely trying to survive in an increasingly human-modified landscape. Poor farmers sometimes resort to killing crop raiders to protect their lives and livelihoods and can end up resenting the conservation organisations who want to protect these species.  To study crop raiding, we set up 132 camera traps in areas next to local roçados, helped by more than 45 people living in the nearby communities. We captured more than 60,000 photographs and detected over 30 species. We detected everything from fearsome predators such as pumas, to secretive nocturnal giant armadillos, to birds of prey and even primates such as capuchin monkeys.  One of the most feared predators in the area is the jaguar, locally known as “onça-pintada”. We were fortunate to detect this species in several locations. Somewhat unnervingly, we occasionally saw their large fresh prints on the trail as we returned to the community, indicating that we had unwittingly been followed. Many local residents assured us that this species is “very cunning. They see us, but we don’t see them”. We were also told a local legend that when a jaguar follows in the tracks of a human, it will sniff their tracks to decide whether or not to attack. We can only presume that we smelled so bad at that point that even our footprints were unappealing.  In only one location, our cameras detected a rare red-billed ground cuckoo. This was an unexpected treat. Our colleagues were among the first to photograph this elusive species when they worked along the Xerua river a few years ago.  Some species seemed to rather enjoy the limelight, while others took exception to being monitored. Razor-billed curassows frequently paraded themselves in front of the cameras, whereas a short-eared dog took it upon himself to tear a camera from the tree.     Spending long periods hiking through tropical forests surrounded by an exuberance of living things does come with certain drawbacks. For one thing, there is a bewildering array of tiny lifeforms for whom humans are mere prey. The foot sores in this image are caused by a bacterial infection known locally as “hoi hoi”. We also conducted 157 interviews with local people, who overwhelmingly identified five species as the most burdensome crop raiders. These were, in order of importance, the large rodent agouti, collared peccary, paca (another large rodent), red brocket deer and, to a lesser degree, the spiny rat. These species were some of the most frequently detected by our camera traps. They were also among the most heavily hunted species. None of these crop raiders are considered highly endangered (though the International Union for the Conservation of Nature doesn’t have enough data on red brocket deer to classify them). Other studies have also found that these species can tolerate a moderate level of being hunted for food. We were encouraged to find that, despite the costs of crop-raiding to rural Amazonian communities, it did not seem to constitute the bitter “human-wildlife conflict” that other researchers have identified. In fact, because the most damaging crop-raiding species are fairly common, crop protection methods including hunting may not be a major threat to wildlife in this region. Rural tropical communities are often encouraged by people from other countries to conserve their biodiverse surroundings and are criticised for hunting that helps them survive. We hope that our study has shed some light on the challenges faced by Amazonian communities who attempt to coexist with wildlife. They could use our results as the basis of a plan to manage the species that they hunt, just as they have implemented plans for sustainable rubber tapping and fishing in partnership with international organisations. "
"Clothing brand Patagonia gives 1% of its sales “to support environmental organisations around the world”. Carpet-maker Interface takes an “aggressive approach” to reach its goal to source 100% of its “energy needs from renewable sources by 2020”. Nudie Jeans meanwhile, repairs, reuses and recycles its denim products, as well as using organic cotton to produce them in the first place. So, what’s going on? After decades of activists campaigning against companies’ poor environmental records, are companies suddenly becoming environmental activists themselves? Normally, companies are challenged by environmental activists from the outside. That is, NGOs, charities and community groups hold companies to account for their often negative impact on the environment. Think VW – it was an NGO that outed the car manufacturer for gaming the emissions testing system. Remember too last year’s Greenpeace campaign against the Lego-Shell partnership? It was a textbook example of environmental activists using clever social media and protest techniques to raise the public’s awareness about the environmental dangers involved in drilling for oil in the Arctic. And it worked. But increasingly companies have become environmental activists themselves. Take Ecotricity, for example, one of Britain’s biggest renewable energy companies, founded by the “travelling hippy” Dale Vince. The company takes an activist stance against fracking in the UK, producing campaign videos that don’t look too dissimilar from those produced by environmental activists. In fact, Ecotricity has teamed up with Friends of the Earth, one of the largest and most influential green NGOs, in its campaign to oppose fracking in the UK. Cosmetics brand Lush is another successful company that has been very vocal and explicit about opposing fracking in the UK. The company’s co-founder and managing director Mark Constantine (a major baker of Frack Off) is explicit about the fact that campaigning is part of the company’s core culture. Lush’s head of global campaigns, Tamsin Omond, coordinates Lush’s involvement and financing of a number of environmental groups, some of which use quite radical direct action tactics to make themselves heard. She herself is a well-known activist who was arrested in 2013 while protesting in West Sussex. The activist ethos of the company is underpinned by the fact that its own employees – “who are more likely to be drawn from the world of radical politics than business schools” – often play a central role in the environmental causes Lush supports. This is all a far cry from the questionable attempts by large corporations to green their image. Remember when, about a decade ago, BP tried to tell us that it is now “beyond petroleum”? Its global, multi-million pound marketing campaign spectacularly backfired when the company’s attempt to “think outside the barrel” was quickly named and shamed by Greenpeace and other environmental groups as a classic case of “greenwashing”. Why? Because it was mostly talk, and very little walk, which became all too real when BP became responsible for one of the biggest environmental disasters of modern times – the explosion of the Deep Horizon oil platform in the Gulf of Mexico in 2010. So, why do companies like Lush, Ecotricity and others take such an activist stance for environmental issues? Here are three main reasons: 1. Companies have always been activists  Business has always been about convincing customers, policymakers, employees and the like that companies can be trusted to provide goods and services that contribute to the wider good of society. Henry Ford could be seen as an activist; he wanted to bring automobility to the masses – and he even paid his employees a decent wage so that they could afford his Model T car. So, when Dale Vince founded Ecotricity in the mid-1990s to bring renewable energy to the people of Britain, he, in some ways, is today’s Henry Ford. 2. Capitalism is about competition  Activism is also implanted into the doctrine of capitalism because of competition in the market. Shareholder activism has been around for a long time; it’s a concept used to depict the attempts by some shareholders to get the most out of their investment, making companies more profitable and competitive.  What is new is that environmental issues are used to increase competitive advantage. So, when Ecotricity campaigns against fracking, then it also campaigns against its competitor, British Gas, which has invested significantly in fracking. It’s about engaging customers and making them choose one company and business model over another. 3. Motivating employees Environmental issues can also be a good motivating factor for employees. Human resource managers constantly think about new ways to keep employees engaged, motivated and loyal.  So when Lush encourages its employees to campaign against fracking, the managers will have at least one eye on the motivation, retention and performance of staff. Companies are becoming environmental activists because it makes good business sense. But we must scrutinise whether everything that corporate environmental activists tell us is green is indeed green. Employees can function as the litmus paper of corporate green activism. Once we have understood how green activism is reconfigured when it enters the corporate world, we can begin to scrutinise the environmental claims made."
"
Share this...FacebookTwitterAt the online Die Welt Prof. Josef Reichholf penned a commentary on climate science and the abuse by a German government attempting to act as a ministry of truth: “Quickly one gets labeled ‘climate denier’“.

Leading German zoologist Prof. Josef Reichholf slams data manipulations, German government acting as “Ministry of Truth”. Photo credit: Josef Reichholf, here. 
The former Technical University of Munich zoologist/evolutionary biologist is considered among the top of his field. In his piece he first casts climate models into doubt, pointing out that temperature observations in fact diverge from the model projections. He sharply criticizes scientists who hold climate models as the truth and who fudge or cherry-pick the data so that they fit a predetermined outcome: “The data that fit are the right ones!”
Objective commentary “hardly possible”
He reminds that science entails skepticism, and if that is scorned, then something has to be very wrong with the science. Reichholf blasts the hostile environment in which skeptical journalists find themselves in Germany whenever they look at the data objectively. He writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




An objective journalistic commentary here is hardly possible. Anyone who dares to do so risks being labelled a climate skeptic‘ or even a ‘climate denier’.”
Ministry of Truth
Reichholf slams Germany’s Ministry of Environment, which in 2013 defamed skeptical science journalist Michael Miersch (and other) in a government information brochure, where the Ministry wrote that they could not be trusted with climate science, portraying them as “spreaders of half-truths and misinformation“. He asks:
“Are we on the way to a Ministry of Truth?”
Reichholf concludes:
No office, also no federal ministry, can posses the dictatorial power over the progress of science. Critical journalism is needed here. Very much so!”
 
Share this...FacebookTwitter "
"Twenty years ago, in the last year of the old millennium, a book about “wild swimming” became a surprise bestseller. Subtitled A Swimmer’s Journey Through Britain, Waterlog combined the classic quest narrative with a new way of writing about the natural world, the product of author Roger Deakin’s lifelong passions for swimming and nature. Waterlog helped to turn wild swimming from a niche interest into a nationwide obsession. It also kick-started the movement that would come to be known as “New Nature Writing”. New (as opposed to Old) Nature Writing is not easy to define; but it usually puts the author at the centre of the experience, by celebrating what the cultural historian Joe Moran calls “our everyday connections with the natural world”. Twenty years on, and every bookshop has prominent displays of the latest crop of books, which this year include Robert Macfarlane’s Underland, Brigit Strawbridge Howard’s Dancing with Bees, and my own modest offering, The Twelve Birds of Christmas. Despite the success of this publishing phenomenon, there are undercurrents of discontent bubbling beneath the surface. The world of nature writers may not seem the obvious place for arguments about gender, race and politics to play out but all these issues are being fought over behind the scenes. This matters because for people to engage with nature, as all authors surely want their readers to, those readers need to feel a connnection with the subject matter and how the story is told. One perennial issue is about whether the genre is being colonised by white middle-aged men at the expense of other voices. In the last decade many books with the greatest impact and highest sales have been written by women. They include H is for Hawk, a moving memoir of grief by Helen Macdonald, and The Outrun, Amy Liptrot’s powerful account of how nature’s redemptive powers helped her overcome her substance addiction. Both titles were not just critically successful, but commercial hits too. But even if the gender balance is improving, most nature writers still come from a close-knit group who, with a few notable exceptions, are mainly middle-class, middle-aged and white.  Yet browse YouTube, or check out social media, and you’ll soon discover that young writers are writing about nature: but mostly via blogs and videos, as you might expect from this generation. And, in a welcome about-turn, social media is now proving a gateway into book publishing. One 15-year-old from Northern Ireland, Dara McAnulty, has just been commissioned by the independent publisher Little Toller to write his first book: Diary of a Naturalist. Based on his blog, which has attracted praise from TV presenter and activist Chris Packham, the book will chronicle the unique way Dara – who is on the autistic spectrum – experiences the natural world. You can't write poems about the natural world now unless it's in an environmental context At the same time, Mya-Rose Craig, the 17-year-old British Bangladeshi known as Birdgirl is fighting hard to redress the lack of visible minority ethnic (VME) writers . Mya-Rose points to the barriers these writers face when trying to gain access to the industry: “Mainstream publishers need to allow VME nature writers to write honestly and in their own voice. Too often the expectation is they must conform to the norms of current nature writing, in terms of both content and style.” One exciting new voice is that of Zakiya Mackenzie, a young woman born in London and raised in Jamaica, who earlier this year became one of Forestry England’s first two writers-in-residence. Meanwhile, The Willowherb Review – named after a particularly tenacious wildflower – now provides an online platform for emerging writers of colour, including Craig, who featured in the first issue. A greater diversity in nature writing, whether through gender, age, ethnicity or class, is both welcome and essential. But all writers, whatever their background, must now grapple with another issue – the question of how far should they engage in the environmental catastrophe. In 2015, two of the big beasts of nature writing – Mark Cocker and Macfarlane – clashed in the pages of the New Statesman. The debate was whether writers have a duty to engage with the very troubling environmental reality or whether it was OK to keep the context of nature writing as something personal and private, rather than political. The poet laureate, Simon Armitage, recently entered the debate, stating that poems about the natural world need to tackle climate change face on. “You can’t write poems about the natural world now unless it’s in an environmental context,” he said. In my view, writing about the natural world can still be approached in very different, yet equally valid, ways. The Lost Words, Robert Macfarlane and Jackie Morris’s stunning, large-format volume, celebrates the vocabulary of nature through poetry and paintings. At the other end of the scale, my favourite book of the year is Benedict Macdonald’s Rebirding: a clear and detailed vision on how to bring back Britain’s lost wildlife, while at the same time restoring rural economies. Both The Lost Words and Rebirding – one from an established writer and well-known artist, the other by a young newcomer – can and should be able to co-exist, if New Nature Writing is to remain a broad church. Waterlog appeared at a time when classic travel writing, which had dominated non-fiction for so long, was on its way out, because readers no longer needed privileged authors to take them on journeys to places they could visit and experience for themselves. If New Nature Writing is not going to go the same way, and decline into irrelevance, it must continue to adapt to the new challenges. But in doing so, we all need to remember one thing. That in an increasingly polarised and intolerant world, the real fight is not among ourselves, but against those who, in pursuit of privilege, wealth and power, seek to destroy everything we hold so dear. • Stephen Moss is a naturalist and author, whose latest book, The Twelve Birds of Christmas, is published by Square Peg. He is course leader on the travel and nature writing MA at Bath Spa University"
"As the world races toward a projected 9 billion inhabitants, the failings of dominant food systems are impossible to deny. Current food production methods are severely polluting. They are the cause of malnutrition. They are also inequitable, and unjustifiably wasteful. And they are concentrated in the hands of few corporations. Entangled in the multiple crises humanity is facing, establishing global food security is considered a key challenge of our time. Against the backdrop of climate change, resource shortages and urbanisation, the question of how to ensure adequate food supply for everyone looms rather large. The usual response emphasises intensifying the output of agriculture through the common model of petrochemical, large-scale, one-crop, intensive farming. But business as usual is no longer an option for food and agriculture. The global agriculture system will have to be radically transformed to avoid further environmental and social problems, as was concluded by a three-year study commissioned by the UN and the World Bank involving more than 400 scientists. This report, as well as subsequent international studies by the UN Conference on Trade and Development and the UN Special Rapporteur on the Right to Food, have convincingly demonstrated that agroecology – farming that imitates natural ecosystems – is the most promising pathway to sustainable food systems on all continents.  Agroecology is based on the idea that farms should mimic the structure and functioning of natural ecosystems. In ecosystems, there is no “waste”: nutrients are recycled indefinitely. Agroecology aims to close nutrient loops – returning all nutrients that come out of the soil, back to the soil. In the case of vegetable farming, for example, this could be achieved through composting of vegetable scraps, human and farmyard manure.  Agroecology also harnesses natural processes to control pests and build soil fertility. Agroecological practices include integrating trees with livestock and crops (agro-sylvo-pastoral farming), producing food from forests (agroforestry), growing several crops together in one plot (polyculture) and using locally adapted and genetically diverse crops and livestock. Throughout the world, small-scale farmers are uniting under the banner of agroecology. They do so not only to produce healthy and nutritious food, enhance biodiversity and adapt to climate change, but also to improve their income and working conditions by developing short food chains and local markets. Local ecologies and economies are being regenerated from below through an insistence on food sovereignty (community control over the way food is produced, traded and consumed) and transformative agroecology (as opposed to more watered down versions of agroecology, such as “climate-smart” or “conservation” agriculture). But changes also need to be made on a larger scale. Some bodies recognise this. Faced with the growing social and environmental costs of industrial farming, the European Union adopted a New European Consensus for Development in June 2017. This commits the EU to: Support agro-ecological practices and actions to reduce post-harvest losses and food waste, as well as to protect soils, conserve water resources, halt, prevent and reverse deforestation, and maintain biodiversity and healthy ecosystems. But opening up agroecological pathways to sustainable food systems in the EU is a major challenge. Radical changes in funding priorities and research agendas are necessary. Similarly, a total overhaul of overseas aid programmes is urgently needed to support crucial transitions to agroecology in Africa, Asia and Latin America.   However, this is not currently happening. Our recently published research shows that very little overseas aid is directed at agroecological research and development. Since January 1 2010, no funds at all have been directed at or been committed to projects with the main focus on development or promotion of agroecological practices.  It is true that minor funds have been directed at projects which promote resource efficiency in farming. But this is a very basic agroecological principle. Based on the most generous interpretation of available figures, our study shows for the first time that aid for agroecological projects is less than 5% of aid given for agricultural purposes and less than 0.5% of the total UK aid budget. By largely supporting industrial agriculture, UK aid priorities contribute very little to the transition towards global socio-ecological sustainability.  Despite the obscure nature of available information, it is reasonable to assume that there is a similar lack of funding for agroecology in the overseas aid priorities of other so-called developed countries. There is, after all, a chronic lack of internal investment in agroecology within these nations. Business as usual may rhetorically no longer be an option in food and agriculture. But it will be, as usual, practically the only option as long as these stark funding asymmetries remain. In April 2018, government representatives from around the world will travel to Rome to discuss how to scale up agroecology. This UN Food and Agriculture Organisation International Symposium on Agroecology is a unique opportunity to rethink priorities for agricultural development worldwide. Among the many actions needed, we urgently need to see a substantial increase in public funding for agroecology – both within and between nations."
"The Netherlands’ supreme court has upheld a ruling ordering the country’s government to do much more to cut carbon emissions, after a six-year fight for climate justice. The court ruled that the government had explicit duties to protect its citizens’ human rights in the face of climate change and must reduce emissions by at least 25% compared with 1990 levels by the end of 2020. The non-profit Urgenda Foundation, which brought the case, welcomed the “groundbreaking” judgment. The original judgment in 2015 was seen as a landmark in the then nascent field of climate litigation, and inspired similar cases across the world, from Pakistan to New Zealand. David Boyd, the UN special rapporteur on human rights and the environment, said it was “the most important climate change court decision in the world so far, confirming that human rights are jeopardised by the climate emergency and that wealthy nations are legally obligated to achieve rapid and substantial emission reductions.” The Dutch government had previously said it would comply with the substance of the ruling, but it repeatedly appealed over the legal basis for the decision. The latest national statistics show the Netherlands is very unlikely to meet the 2020 emissions target.  The Netherlands passed its first piece of national climate legislation in 2018, it has published a more ambitious carbon plan for 2030, and it is closing its first coal plant next year. According to the supreme court, individual nations have direct obligations under articles 2 and 8 of the European convention on human rights, covering the right to life and the right to private and family life. Dennis van Berkel, a member of the legal counsel for Urgenda, said: “The enormous importance of this case is not just that the Netherlands is obliged to act but that these principles are universal. No court outside the Netherlands is bound by this decision but the influence that this court has and the inspiration that it will give to others are really big.” Van Berkel said that if the government did not comply with the ruling, Urgenda could start separate legal proceedings against it. The Dutch climate minister, Eric Wiebes, said the government had “taken note” of decision and would issue a full response in January. He said the Netherlands had announced an “ambitious” set of measures this year to implement the judgment, although campaigners think it could go much further. As well as inspiring cases against other national governments, Urgenda’s success has encouraged campaigners to take up legal arms against corporations. In April a group of social and environmental justice groups led by Friends of the Earth Netherlands began the process of suing the oil firm Shell, arguing that its business model threatens international climate goals and endangers human rights. In a formal reply in November, Shell denied it was liable. A month earlier the company’s CEO said it had “no choice” but to invest in oil and claimed it was “entirely legitimate” to do so. Nine de Pater, a climate and energy campaigner at Friends of the Earth Netherlands, said the supreme court decision set an important precedent for the Shell case because they used similar legal arguments. “It is a huge decision for all current climate litigation cases,” she said."
"
Share this...FacebookTwitterNatural Forcing Of Arctic Climate
 Increasingly Affirmed By Scientists

Gajewski, 2015

Three years ago a cogent paper was published in the prestigious scientific journal Nature that was surprisingly candid in its rejection of the position that the substantial warming and sea ice reduction in the Arctic occurring since the late 1970s should be predominantly attributed to anthropogenic forcing.
Dr. Quinhua Ding and 6 co-authors indicated in their paper that internal processes — natural variability associated with planetary waves and the North Atlantic Oscillation — are drivers of the recent Arctic warming and sea ice reduction, concluding that “a substantial portion of recent warming in the northeastern Canada and Greenland sector of the Arctic arises from unforced natural variability.”

Ding et al., 2014
“Rapid Arctic warming and sea-ice reduction in the Arctic Ocean are widely attributed to anthropogenic climate change. The Arctic warming exceeds the global average warming because of feedbacks that include sea-ice reduction and other dynamical and radiative feedbacks.  We find that the most prominent annual mean surface and tropospheric warming in the Arctic since 1979 has occurred in northeastern Canada and Greenland. In this region, much of the year-to-year temperature variability is associated with the leading mode of large-scale circulation variability in the North Atlantic, namely, the North Atlantic Oscillation.”  
“Here we show that the recent warming in this region is strongly associated with a negative trend in the North Atlantic Oscillation, which is a response to anomalous Rossby wave-train activity [planetary waves related to the Earth’s rotation] originating in the tropical Pacific. Atmospheric model experiments forced by prescribed tropical sea surface temperatures simulate the observed circulation changes and associated tropospheric and surface warming over northeastern Canada and Greenland. Experiments from the Coupled Model Intercomparison Project Phase 5 models with prescribed anthropogenic forcing show no similar circulation changes related to the North Atlantic Oscillation or associated tropospheric warming. This suggests that a substantial portion of recent warming in the northeastern Canada and Greenland sector of the Arctic arises from unforced natural variability.”

Since 2014, there have been several more scientific papers that have been published documenting the significance of natural forcing processes in the Arctic and how they may override a clear detection of an anthropogenic influence.
But 2017 already seems to be an exception.  Papers that document the dominance of natural forcing — or that don’t even mention anthropogenic forcing as a factor in the Arctic climate processes — keep on rolling in.
As a case example, in a paper discussing the mechanisms involved in “Arctic amplification” and sea ice loss, Kim et al. (2017) never once mention anthropogenic forcing, or carbon dioxide, as mechanisms affecting the Arctic climate.  In fact, in citing several other authors, they acknowledge that the physical processes involved in the forcing of Arctic climate are “subject to debate” and remain “an open question.”   In other words, not only is the position that humans exert a dominant influence on the Arctic climate not “settled science”, the anthropogenic influence may be so muted a factor that it is not even worth mentioning in a paper discussing forcing mechanisms.

1. Kim et al., 2017
Understanding the Mechanism of Arctic Amplification and Sea Ice Loss
“Sea ice reduction is accelerating in the Barents and Kara Seas. Several mechanisms are proposed to explain the accelerated loss of polar sea ice, which remains an open question. … Previous studies have proposed the physical mechanisms of Arctic amplification, which involve the effect of atmospheric heat transport (Graversen et al., 2008), oceanic heat transport (Årthun et al., 2012; Chylek et al., 2009; 10 Spielhagen et al., 2011; Onarheim et al., 2015), cloud and water vapor changes (Francis and Hunter, 2007; Schweiger et al., 2008; Park et al., 2015a; Park et al., 2015b), and/or diminishing sea ice cover (Serreze et al., 2009; Screen and Simonds, 2010a; Kim et al., 2016). The accurate physical process of the Arctic amplification, however, is subject to debate.”
“Despite the general consensus that heat transfer between the ocean and atmosphere is a crucial element in the physical mechanism of Arctic amplification and sea ice reduction, a quantitative understanding of individual contributions of heat flux components is still controversial. Further, the role of upward and downward longwave radiations in Arctic amplification is vague and not fully understood. Accurately quantifying the contribution of these different mechanisms, therefore, is required for a complete understanding of the Arctic amplification.”
[CO2 is not mentioned as a mechanism responsible for Arctic amplification or sea ice loss.]

Two months ago, Dr. Ding delivered another Nature paper — this time with 10 co-authors — that once again emphasized the Arctic’s natural variability, specifically the internal processes involved in the substantial reduction in Arctic sea ice since 1979.  The scientists concluded that as much as 50% of the Arctic sea ice decline in the satellite era has been natural, and that anthropogenic forcing may play a much smaller role than has previously been assumed in climate models.
Many other newly-published papers advance the position that natural, non-anthropogenic processes are significant or even dominant factors in shaping the Arctic climate.  A total of 15 are cited here categorically.

A ‘Substantial Chunk’ Of Sea Ice Loss/Warming Due To Internal/Natural Variability

2. Ding et al., 2017 (press release) 
“The Arctic has seen rapid sea-ice decline in the past three decades, whilst warming at about twice the global average rate. …  Internal variability dominates the Arctic summer circulation trend and may be responsible for about 30–50% of the overall decline in September sea ice since 1979. … [A] substantial chunk of summer sea ice loss in recent decades was due to natural variability in the atmosphere over the Arctic Ocean.”

3. Fan and Yang, 2017
“The wintertime Arctic temperature decreased from 1979 to 1997 and increased rapidly from 1998 to 2012, in contrast to the global mean surface air temperature [which] increased between 1979 and 1997, followed by a hiatus… A recent study suggests a possible role of the Pacific Ocean decadal oscillation in regulating wintertime climate in the Arctic (Screen and Francis 2016).”
“The ‘greenhouse effect’ of water vapor and clouds [CO2 not mentioned as contributing to the GHE] may amplify the effect of winds on Arctic winter climate.”
“The objectives of this study are to assess how much natural–internal variability has contributed to climate changes in these [Arctic] regions from 1979 to 2012 … In summary, the correlation analyses presented in this paper shows a natural mode of Arctic winter variability resulting from the Nordic–Siberian seesaw of meridional winds […] is associated with two-thirds of the interannual variance [cooling-warming] of winter-mean Arctic temperature between 1979 and 2012, and possibly contributed a substantial fraction of the observed Arctic amplification [1998-2012 warming] in this period.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






4. Seviour, 2017
“Weakening and shift of the Arctic stratospheric polar vortex: Internal variability or forced response? … By comparing large ensembles of historical simulations with pre-industrial control simulations for two coupled climate models, the ensemble mean response of the vortex is found to be small relative to internal variability. There is also no relationship between sea-ice decline and trends in either vortex location or strength. Despite this, individual ensemble members are found to have vortex trends similar to those observed, indicating that these trends may be primarily a result of natural internally-generated climate variability.”

Natural Planetary Waves Forcing

5. Baggett and Lee, 2017
“The dynamical mechanisms that lead to wintertime Arctic warming during the planetary-scale wave (PSW) and synoptic-scale wave (SSW) life cycles are identified by performing a composite analysis of ERA-Interim reanalysis data. The PSW life cycle is preceded by localized tropical convection over the Western Pacific. Upon reaching the mid-latitudes, the PSWs amplify as they undergo baroclinic conversion and constructively interfere with the climatological stationary waves. The PSWs [planetary scale waves] flux large quantities of sensible and latent heat into the Arctic which produces a regionally enhanced greenhouse effect that increases downward IR and warms the Arctic two-meter temperature. The SSW life cycle is also capable of increasing downward IR and warming the Arctic two-meter temperature, but the greatest warming is accomplished in the subset of SSW events with the most amplified PSWs. Consequently, during both the PSW and SSW life cycles, wintertime Arctic warming arises from the amplification of the PSWs [planetary scale waves].”

6. Gong et al., 2017
“During the past three decades, the most rapid warming at the surface has occurred during the Arctic winter. By analyzing daily ERA-Interim data, we found that the majority of the winter warming trend north of 70°N can be explained by the trend in the downward infrared radiation (IR). This downward IR trend can be attributed to an enhanced poleward flux of moisture and sensible heat into the Arctic by poleward propagating Rossby waves, which increases the total column water and temperature within this region. This enhanced moisture flux is mostly due to changes in the planetary-scale atmospheric circulation rather than an increase in moisture in lower latitudes.”

Solar Forcing Of Arctic Climate, Sea Ice Trends

7. Li et al., 2017
“Correlations between paleotemperature records from the North Atlantic and solar activity suggest that changes in solar output may cause significant shifts in the climate of the North Atlantic region. To test the role of solar activity on summer SST at our study site in West Greenland, we conducted a cross-correlation analysis between our reconstructed summer SST record and a total solar irradiance (TSI) series. The results indicate that the maximum correlation coefficient (0.284) of summer SST [sea surface temperatures] and TSI [total solar irradiance] records is obtained at nearly zero time-lag (-6 time-lag), which means that variations in solar activity affected the summer SST variability in the study area. … A significant positive relationship between summer SSTs on the North Icelandic shelf and solar irradiance reconstructed from 10Be and 14C records during the Holocene was also demonstrated by Jiang et al.  … Spectral analyses indicate that significant centennial-scale variations are superimposed on the long-term orbital trend. The dominant periodicities are 529, 410, and 191 years, which may be linked to the well-known 512- and 206-year solar cycles. Cross-correlation analyses between the summer SSTs and total solar irradiance through the last 5000 years indicate that the records are in phase, providing evidence that variations in solar activity impacted regional summer SST variability. Overall, the strong linkage between solar variability and summer SSTs is not only of regional significance, but is also consistent over the entire North Atlantic region.”


8. Stein et al., 2017
“The causes that are controlling the decrease in sea ice are still under discussion. In several studies changes in extent, thickness and drift of Arctic sea ice are related to changes in the overall atmospheric circulation patterns as reflected in the North Atlantic Oscillation (NAO) and Arctic Oscillation (AO). The NAO and AO are influencing changes of the relative position and strength of the two major surface-current systems of the Arctic Ocean. … The increase in sea ice extent during the late Holocene seems to be a circum-Arctic phenomenon, coinciding with major glacier advances on Franz Josef Land, Spitsbergen and Scandinavia.  The increase in sea ice may have resulted from the continuing cooling trend due to decreased solar insolation and reduced heat flow from the Pacific. … The increase in sea ice extent during the late Holocene seems to be a circum-Arctic phenomenon as PIP25-based sea ice records from the Fram Strait, Laptev Sea, East Siberian Sea and Chukchi Sea  display a generally quite similar evolution, all coinciding with the decrease in solar radiation … The main factors controlling the millennial variability in sea ice and surface-water productivity are probably changes in surface water and heat flow from the Pacific into the Arctic Ocean as well as the long-term decrease in summer insolation, whereas short-term centennial variability observed in the high-resolution middle Holocene record was possibly triggered by solar forcing.”

9. Sha et al., 2017
“The reconstruction indicates warm conditions with reduced sea-ice cover, associated with the Holocene Thermal Maximum, from ca. 6700 to 5000 cal. yr BP. … A distinct increase in sea-ice cover began at 1750 cal. yr BP, with absolute maximum values during the last millennium.  … In order to assess the contribution of different potential forcing factors to sea-ice conditions off West Greenland, we evaluated the relationship between our sea-ice reconstruction and solar activity, as well as with the strength of ocean circulation. The observed agreement between the sea-ice record and solar activity suggests that solar forcing may have been an important trigger for sea-ice variability off West Greenland during the last 5000 yr.”


Pacific Decadal Oscillation (PDO) Forcing

10. Lapointe et al., 2017
“This paper investigates an annually-laminated (varved) record from the western Canadian Arctic and finds that the varves are negatively correlated with both the instrumental Pacific Decadal Oscillation (PDO) during the past century and also with reconstructed PDO over the past 700 years, suggesting drier Arctic conditions during high-PDO phases, and vice versa. These results are in agreement with known regional teleconnections, whereby the PDO is negatively and positively correlated with summer precipitation and mean sea level pressure respectively. This pattern is also evident during the positive phase of the North Pacific Index (NPI) in autumn. Reduced sea-ice cover during summer–autumn is observed in the region during PDO− (NPI+) and is associated with low-level southerly winds that originate from the northernmost Pacific across the Bering Strait and can reach as far as the western Canadian Arctic. These climate anomalies are associated with the PDO− (NPI+) phase and are key factors in enhancing evaporation and subsequent precipitation in this region of the Arctic.”

Cloud Radiative Forcing

11. Solomon et al., 2017
“A number of feedbacks are found that damp the warming effect of the clouds. Thin mixed-phase clouds increase the downward longwave fluxes by 100 W m−2, but upward daytime surface longwave fluxes increase by 20 W m−2 (60 W m−2 at night) and net shortwave fluxes decrease by 40 W m−2 (partially due to a 0.05 increase in surface albedo), leaving only 40 W m−2 available for melt. This 40 W m−2 is distributed between the turbulent and conductive ground fluxes, so it is only at times of weak turbulent fluxes (i.e., at night or during melt) that this energy goes into the conductive ground flux, providing energy for melt. From these results it is concluded that it is the integrated impact of the clouds over the diurnal cycle (the preconditioning of the snowpack by the clouds at night) that made melt possible during this 3-day period. These findings are extended to understand the pattern of melt observed over the GIS. … Mixed-phase clouds are common at Summit (Shupe et al. 2013) and play a critical role in the Arctic surface energy balance (Shupe and Intrieri 2004), radiatively warming the highly reflective surface at Summit year-round (Miller et al. 2015).”

Most Of The Arctic’s Net Warming Occurred Before 1950

The instrumental record (HadCRUT) for Arctic temperatures indicates that there has been no significant net warming in the Arctic during the last ~80 years.  Newly published papers also affirm that much of the warming of the Arctic occurred before 1950, or before humans began emitting CO2 in large quantities.

12. Werner et al., 2017
“During the MCA [Medieval Climate Anomaly], the contrast between reconstructed summer temperatures over mid- and high-latitudes in Europe and the European/North Atlantic sector of the Arctic shows a very dynamic expression of the Arctic amplification, with leads and lags between continental and more marine and extreme latitude settings. While our analysis shows that the peak MCA [Medieval Climate Anomaly] summer temperatures were as high as in the late 20th and early 21st century, the spatial coherence of extreme years over the last decades seems unprecedented at least back until 750 CE. However, statistical testing could not provide conclusive support of the contemporary warming to supersede the peak of the MCA in terms of the pan-Arctic mean summer temperatures.”


13. Fernández-Fernández et al., 2017
“The abrupt climatic transition of the early 20th century and the 25-year warm period 1925–1950 triggered the main retreat and volume loss of these glaciers since the end of the ‘Little Ice Age’. Meanwhile, cooling during the 1960s, 1970s and 1980s altered the trend, with advances of the glacier snouts.”
“The trend in Western Tungnahryggsjökull during the first half of the 20th century was a more rapid retreat, showing the highest average rates of the whole period (19.5 m yr−1). By 1946, this glacier had retreated almost 90% of the total recorded between the LIA maximum (1868) and 2005.”


14. Vachula et al., 2017


15. Krawczyk et al., 2017


Share this...FacebookTwitter "
"Scientists fear climate change will drive a surge in the number of supersized and dangerous bushfires that become coupled with the atmosphere and create their own violent thunderstorms. Guardian Australia can reveal 2019 is likely to be a “standout year” for the number of bushfires that generate giant thunderstorm clouds known as pyrocumulonimbus, or pyroCBs.  PyroCB storms are feared by firefighters for the violent and unpredictable conditions they create on the ground. PyroCBs are able to generate their own lightning strikes, mass downdrafts of air, gusty winds and even hail blackened with soot. The plumes generated from pyroCBs can influence the atmosphere at heights of up to 15km. Embers still hot enough to start new fires can be shot out of a pyroCB at distances of 30km from the main fire. The 411,000 hectare Gospers Mountain fire in the Blue Mountains, still burning out of control on Thursday, is likely the latest bushfire to have generated a pyroCB storm on 22 November. Nicholas McCarthy, who has just completed a Phd at the University of Queensland on why bushfire thunderstorms form, said watching one develop was a “grounding experience”. “Once you hear that first clap of thunder, you know there’s not a lot you can do,” he said. “There shouldn’t be anyone on the ground at that point. All of a sudden [the fire] loses a whole level of predictability.” PyroCB fires can have devastating and dramatic consequences. Victoria’s deadly Black Saturday conflagration in February 2009 created its own lightning that caused fires 100km ahead of the main fire front. Research scientist Rick McRae, who is the custodian of a register of Australian pyroCB events, said 2019 was a “standout year”. In March, there were 15 pyroCBs detected in the Victorian high country, including a cluster of 12 in just four days – an unprecedented grouping on McRae’s register. “This is the standout year but we are still analysing them,” he said. Dr Andrew Dowdy, a meteorologist at the Bureau of Meteorology, has published several studies on pyroCB fires and their underlying conditions. Research led by Dowdy and published in the journal Scientific Reports has found that adding more greenhouse gases to the atmosphere will make more dangerous conditions favourable to pyroCB events in the future, particularly for the southern parts of Australia. Dowdy said an examination of conditions in the atmosphere and on the ground between 1979 and 2016 that are conducive to pyroCBs had already found a “statistically significant” trend in southern Australia. He said: “We found that in summer in southern Australia and spring time, there have been large changes towards more dangerous conditions.” Dr Simon Heemstra, manager of planning and predictive services at the New South Wales Rural Fire Service, said: “What’s happening now is that we are noticing an increase in incidence of these sorts of events. With a changing and heating climate, you are going to expect these effects.” He said pyroCB fires were characterised by violent “mass flaming” that “puts lives at risk, whether those are firefighters or the community in the path of these events”. The advice given to firefighters in NSW before and during a pyroCB event is to “make sure they have a safe refuge”. He said: “It instills fear – the thought of a fire creating a thunderstorm that’s throwing embers and lightening in front of it. It creates a dangerous situation and we take them very seriously.” In response to a rising number of pyroCBs, he said the NSW Rural Fire Service was using weather balloons to take atmospheric measurements during times it is feared that pyroCBs could form. New communications material for firefighters has also been produced. Heemstra said one warning sign was a smoke column that rises to about 5km and forms a white top as moisture turns to ice. If the column continues to rise, a warning is sent to firefighters and communities on the ground. As well as creating dangerous weather conditions, Heemstra said pyroCBs prevent the fire service from using aircraft either to take measurements, or to drop water or fire retardant. Associate professor Jason Sharples, of the University of New South Wales, said pyroCBs needed two basic elements to form – an intense and expansive fire and an unstable atmosphere above it. He said: “Think of it like a really bad thunderstorm with all the winds and the rain but then take out the rain, and put in embers.” Dr Mike Fromm, of the US Naval Research Laboratory at the Department of Defence, told Guardian Australia that to identify pyroCB events scientists used satellites to examine images and also detect aerosol particles. “They generally will punch a hole through the boundary between the troposphere and stratosphere,” he said. “They create a huge blanket of cloud that turns day into night.” He said globally there was no evidence of a trend towards more pyroCBs but he also said the record was relatively short. PyroCB storms typically lasted between one and eight hours, Fromm said. There was evidence of embers being shot out from the fire at distances of up to 30km. “What we know about pyroCB conditions is summarised as ‘hot, dry, windy’,” he said. “If these factors intensify with climate change, it is reasonable to anticipate additional risk of such firestorms. “The pyroCB is the most dramatic manifestation of fire weather and behaviour from the standpoint of the views from space.” He said observations from the deadly Black Saturday fires of February 2009, where 173 people died, illustrated the dangers posed by pyroCBs. “Black Saturday’s Kilmore East fire didn’t even exist until late morning of that fateful day; by mid-afternoon it generated a full-fledged, devastating pyroCB.”"
"Donations to the Guardian and Observer charity appeal, aimed at planting trees and protecting forests and woodlands to slow the damage of the climate emergency, have passed the £500,000 milestone just halfway through the campaign. The appeal is supporting four charities that promote environmental and social justice through natural climate solutions, ranging from safeguarding the Amazon rainforest to rewilding parts of the Scottish Highlands, to planting trees in Britain’s towns, cities and countryside.  The charities are: Woodland Trust, Trees for Life, Trees for Cities and Global Greengrants Fund UK. Responding to the milestone, Darren Moorcroft, the chief executive of Woodland Trust, said: “On behalf of the trust, trees and woods, we’d like to thank everyone for their generous donations. The money raised will help us to create a better environment, help to fight back against climate change, create new habitats to tackle nature decline, to combat air pollution in our towns and cities, and simply to make a greener, healthier world to live in. “These generous donations will also help children learn about the vital role trees play in keeping us and the planet healthy. Trees and woods can enrich peoples’ lives and it is so important to give people the opportunity to experience, planting and enjoying them first hand.” Messages of support left by online donors showed many felt compelled to give because elected politicians were failing to take seriously what they considered to be the most important issue affecting the planet. As one put it: “I often feel powerless in the fight against climate change. This is an opportunity to do something and make a difference.” The appeal received a boost last weekend when the annual Guardian and Observer charity telethon raised more than £42,000. A team of journalists and editors, including George Monbiot, Owen Jones, Gary Younge, Marina Hyde, John Crace, Jonathan Freedland and Sali Hughes, were on hand to take phone pledges from readers. Introducing the appeal earlier this month, the Guardian editor-in-chief, Katharine Viner, said although the onus was on governments and corporations to take major steps to avoid global climate catastrophe, this year’s charity appeal “highlights ways we as citizens can support practical, natural solutions to climate change”. • The appeal continues until midnight on Sunday 5 January. Readers can donate online here or send a cheque (payable to the Guardian and Observer charity appeal 2019) to: The Guardian and Observer charity appeal 2019, Charities Trust, Suite 20-22, Century Building, Tower Street, Liverpool, L3 4BJ."
"Antarctica. The name evokes images of bitter extremes, an environment unkind to humans. Stories of polar explorers battling with the weather and perishing on their way back to safety. Why would astronomers choose to go there? To get the best views of space, space itself is the best place to be. Here on Earth, one can escape the grip of our zest for luminescence and seek out a remote corner of the world where nights are still black except for the distant stars. Or one can climb a mountain, to leave below much of the bubbly air that blurs images of space, and especially humid air that blocks our view of space altogether.  This is where you can find the most powerful telescopes, on the summits of mountains, islands in desert or ocean. Chile. Hawaii. But Antarctica? Surely not? In fact, the continent is ideal. And one of its coldest and most remote spots of all, a featureless place named “Ridge A” that sits near the high point of a vast polar desert, might just be the best place on Earth to look into space. The area has exceptionally clear skies. While the “Roaring Forties” are the nightmares of round-the-world sailors, and the Furious Fifties and Screaming Sixties loudly announce a point of no return, the South Pole itself is in actual fact an overwhelmingly calm place. It’s highest recorded wind speed is just 58mph, barely even a gale. Weather systems – a euphemism typically reserved for ugly storms – are powered by relatively warm air and the rotation of the Earth. The vast ice cap that covers the Antarctic continent means the South Pole is far from any warm ocean waters. And, if you are standing still at the South Pole proper, you would rotate around your own spine, and it would take you 24 hours to do so. Hardly a wild whirlwind. Antarctica is of course cold. How cold? The lowest temperature ever recorded on Earth was experienced near the South Pole: -89.2℃. This is the result of the total absence of sunlight for nearly six months in a row. While such conditions pose severe risks to humans, and to the lubricants used to keep mechanical parts operating, they also carry a great benefit for astronomers: moisture freezes.  Water vapour is the main greenhouse gas in the Earth’s atmosphere, and it is removed almost entirely at such prolonged, exceedingly low temperatures. This clears up the air, rendering it more transparent – especially to infrared light. The cold conditions higher up in the atmosphere lead to a depletion of ozone molecules, which block ultraviolet light. The upshot is that Antarctic skies are also more transparent to ultraviolet light. For astronomers like me, the South Pole is already halfway to space. You can climb a high mountain in the Himalayas or the Andes, and leave half the air below you. But the air pressure drops too, which makes residential life above 6km altitude impossible. The low temperatures on Antarctica, and its general flat – if elevated – expanse, cause the atmosphere to sink, forming a heavy blanket near the surface that has a higher pressure than would be expected on mountain summits of that height elsewhere. It is thus more bearable to humans, at least in that regard.  The low humidity does, however, cause problems to both humans and electronics alike, not the least in the form of electrical shocks. Such collapsed atmosphere makes it also much easier to climb above it. Topping at just over 4000m, Ridge A is a mere 8 degrees away from the South Pole, which is at 2800m altitude. It thus combines all the benefits of cold, thin and calm air and months of pitch-black skies. After a series of experimental telescopes have been deployed at other polar stations, astronomers have now set their eyes on Ridge A. The site is a superb base for “traditional” telescopes operating at optical and the adjacent ultraviolet and infrared frequencies, and also for telescopes operating at the highest radio frequencies. But the ability to stare at the same spot for months on end also offers unique possibilities for seeing farther out into space than ever before.  While conditions are not for the faint-hearted, the calm weather and easy terrain of Ridge A relieve some of the construction difficulties and operational challenges one encounters on steeper mountains – and certainly those one would face in space. This makes the site relatively accessible – by air at least.  And while it is steadily becoming cheaper to go into space, it will never beat the economics of staying on Earth. It is just a matter of time until a multi-national research organisation, a university consortium, or a wealthy benefactor bites the bullet and decrees that one of the most powerful telescopes on the planet shall be built on Ridge A, to bring space down to Earth."
"
Share this...FacebookTwitterFrank Bosse and Prof. Fritz Vahrenholt present their monthly solar activity report at their Die kalte Sonne site.
In May the sun was very quiet as sunspot number was a mere 18.8, which is only 36% of what is typical for the month this far into the cycle. Seven days saw no sunspot activity at all.
The following chart shows the current cycle, Solar Cycle 24 (red), compared to the mean of the previous cycles (blue) and the similarly behaving SC 5 (black).

It’s clear that the current cycle is significantly weaker than the mean and far weaker than the cycles we saw throughout most of the warming 20th century. So far there have been a number of signs indicating that upcoming SC 25 will also be a weak one. Historically periods of weak solar activity are associated with cooler periods and altered weather patterns.
The current cycle SC 24 has been so quiet that it is in fact the weakest since SC 6, which took place close to 200 years ago.

The above chart shows the accumulated monthly anomaly for each cycle this far into the current cycle. Bosse and Vahrenholt write that SC 24 has a chance, though a very small one, to overtake SC 5 and become the second weakest cycle since observations began in 1755.
Arctic sea ice remains stubbornly thick
Arctic sea ice has been surprising many observers lately because it has so far refused to melt like some predicted it would. Tony Heller here writes that the Northwest Passage is “blocked by very thick ice in the Beaufort Sea“. Latest sea ice extent chart shows sea ice extent being back into the statistical pack. There are even forecasts that point the melt season may be a slow one, see Weatherbell Weekend Summary.
Ice blocks Arctic study
Little wonder that a scientific global warming expedition to the Arctic had to be cancelled – due to excessive ice! James Delingpole at Breitbart reports: “Ship of Fools III – Global Warming Study Cancelled Because of ‘Unprecedented’ Ice“.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Dr. David Barber, lead scientist on the study, insisted that all the unexpected ice was caused by “climate change” — sort of like blaming obesity on a lack of calories.
Northern hemisphere snow cover well over normal
Also surprising in these times of “global warming” is that northern hemisphere snow cover is well above normal as of June 15, according to Environment Canada:
Snow cover over the northern hemisphere remains more than 1 standard deviation above the mean. Source: Environment Canada.
Greenland is also defying global warming. Kirye at Twitter tells us accumulated surface mass balance as computed by the Danish Meteorological Institute (DMI) is far above the mean:

Accumulated surface mass balance from September 1st to now (blue line, Gt). Source: DMI. 
El Nino 2017 disappearing before arriving
At Weatherbell meteorologist Joe Bastardi reports that the forecast El Nino for 2017 has weakened considerably over the past few months. As what appears to be a curve from Scripps, the curve has gone from a powerful projected El Nino to a La Nina in just over the course of a couple of months (watch Joe’s Weekend Summary for the details).

Source: Cropped from Weatherbell Weekend Summary.
If the revised forecasts hold, a cooling globe over the coming months is likely.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
New papers show clear impact by solar activity on the earth’s climate. Images: NASA Earth Observatory.
Solar activity fluctuations control the climate: sea level in Venice, tropical storms in Australia, Amazon discharge rates
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated by P Gosselin)
It’s been claimed time and again that solar activity cycles for the most part can be neglected climatically. They hardly have any impact. Therefore it is all the more amazing when almost every month a new scientific study comes out that documents the exact opposite.
One example comes from November 2016 when the Geophysical Research Letters published a paper by Adrián Martínez-Asensio et al on the impact of solar activity on sea level. The scientists documented that the autumn sea level extreme in Venice and Triest are in fact controlled by the 11-year solar cycle.
In the wintertime the sun’s impact is seen at other coastal locations, namely Marseille, Ceuta, Brest and Newlyn. What follows is the paper’s fascinating abstract:
Decadal variability of European sea level extremes in relation to the solar activity
This study investigates the relationship between decadal changes in solar activity and sea level extremes along the European coasts and derived from tide gauge data. Autumn sea level extremes vary with the 11 year solar cycle at Venice as suggested by previous studies, but a similar link is also found at Trieste. In addition, a solar signal in winter sea level extremes is also found at Venice, Trieste, Marseille, Ceuta, Brest, and Newlyn. The influence of the solar cycle is also evident in the sea level extremes derived from a barotropic model with spatial patterns that are consistent with the correlations obtained at the tide gauges. This agreement indicates that the link to the solar cycle is through modulation of the atmospheric forcing. The only atmospheric regional pattern that showed variability at the 11 year period was the East Atlantic pattern.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Another example is found in March, 2016. Jordahna Ellan-Ann Haig and Jonathan Nott reconstructed the tropical cyclone history of Australia for the past 1500 years. Here they discovered that the observed variability was mostly controlled by solar activity over decades and centuries. Haig and Nott hope that future tropical storm forecasts can benefit from the important solar factor.
The paper’s abstract follows:
Solar forcing over the last 1500 years and Australian tropical cyclone activity
Accurate seasonal and decadal predictions of tropical cyclone activity are essential for the development of mitigation strategies for the 2.7 billion residents living within cyclone prone regions. The traditional indices (Southern Oscillation Index and various sea surface temperature indices) have fallen short in recent years as seasonal predictors within the Australian region. The short length of these records (i.e., <50 years) has meant that our current knowledge of larger-scale drivers at interdecadal, centennial, and millennial scales is limited. The development of a new tropical cyclone activity index spanning the last 1500 years has enabled the examination of tropical cyclone climatology at higher temporal resolution than was previously possible. Here we show that in addition to other well-known climate indices, solar forcing largely drives decadal, interdecadal, and centennial cycles within the tropical cyclone record.”
Lastly there’s a fairly recent example from South America. Andrés Antico and Maria Tores examined the discharge rate of the Amazon for the last 100 years in an article published in 2015. They discovered that the development is very closely coupled to solar fluctuations. The paper’s abstract follows:
Evidence of a decadal solar signal in the Amazon River: 1903 to 2013
It has been shown that tropical climates can be notably influenced by the decadal solar cycle; however, the relationship between this solar forcing and the tropical Amazon River has been overlooked in previous research. In this study, we reveal evidence of such a link by analyzing a 1903–2013 record of Amazon discharge. We identify a decadal flow cycle that is anticorrelated with the solar activity measured by the decadal sunspot cycle. This relationship persists through time and appears to result from a solar influence on the tropical Atlantic Ocean. The amplitude of the decadal solar signal in flow is apparently modulated by the interdecadal North Atlantic variability. Because Amazonia is an important element of the planetary water cycle, our findings have implications for studies on global change.”
 
Share this...FacebookTwitter "
"Australians are far less split on partisan lines than Americans on whether they accept the need to act on climate change, and are far more likely regardless of party allegiance to be willing to pay a carbon tax to cut fossil fuel use, a study has found. The research by the US Studies Centre at the University of Sydney found a majority of both Australians and Americans said climate change was happening at least in significant part due to human activity, and they would support a plan to cut fossil fuel use by raising taxes, including a carbon tax.  For all questions, support for acting on the climate crisis was greater in Australia. Researchers found 78% of Australians supported reducing fossil fuel use and 64% raising taxes to help do that. Among people who voted for the Morrison government at this year’s election, 62% said they backed cutting fossil fuel use and nearly half, 48%, supported higher taxes. There was overwhelming support to both questions from people who voted for Labor (88% and 79% respectively) or the Greens (96% and 88%). The divide in the US between people who voted for Donald Trump and those who backed Hillary Clinton at the 2016 presidential election was much greater. Across all voters in the US, support for reducing fossil fuel use was at 68%. That fell to 54% when people were asked if they would support a plan that required higher taxes. There was overwhelming support on both counts among those who backed Clinton, the failed 2016 Democrat candidate (95% and 82% respectively). But only 29% of people who voted for Trump supported reducing fossil fuel use. The proportion of Trump voters prepared to pay a carbon tax to address the issue was just 24%. Across all parties in both countries, including a category counting non-voters and other minor party voters, Trump supporters were the only group in which a majority did not think that climate change had been occurring either mostly due to human activity or equally due to human activity and natural causes. Just 30% of Trump supporters thought humans were significantly contributing to climate change. Among Coalition voters in Australia, it was 60%. A slim majority of Coalition voters (between 52% and 58%) said they believed climate change would cause more droughts and water shortages, increasingly severe storms and harm to wildlife. Trump voters (between 26% and 29%) disagreed. Shaun Ratcliff, a political science lecturer with the centre, said the survey results showed there was a significant difference between Australia and US politics on the right. While Clinton voters were similar to Australian Labor and Greens voters on climate change, Trump voters “looked nothing like” Coalition voters, he said. “Republican voters are much more ideological than Coalition voters are on this issue,” he said. Ratcliff said polarisation in the US was not a result of Trump but started decades ago. He may have exacerbated it but was not the cause. This was true on a range of issues, including climate change. He said it was evidence a Trumpian approach to politics was less likely to have sustained success in Australia. “The Liberal party is very different to the Republican party and there is a lot of concern in the Australian public about climate change,” Ratcliff said. “People say they want action.” He said Labor’s failure to win government with a more ambitious platform on climate change may have in part been due to how that was handled. “If you’re making major changes, voters have to have confidence you have the ability to do it well and won’t make things worse. If they fear that, you may not win their support.” The surveys were collected in both countries by YouGov, a global opinion and data company, over a week in late July, before Australia’s ongoing bushfire crisis. They are part of a broader study called Public Opinion in the Age of Trump. Different parts of the survey were released to different media outlets ahead of the report’s publication on Wednesday. Ratcliff said it was unclear whether concern about bushfires that have engulfed Sydney and other centres in smoke would change public opinion, and if it did whether that change would last. “If the public does come to see the fires and the smoke and the destruction we’re seeing along the east coast as being exacerbated by climate change and believe the Coalition is not doing enough that could have an impact,” he said. The sample size was 1,800 in the US and 1,820 in Australia; the margin of error 2.3% in Australia and 2.8% in the US."
"
Share this...FacebookTwitterUrban farming seems to be one of the latest trends among activists obsessed with environmental-footprints, and is being billed by some as the solution for all the world’s ills.
In the following video urban farmer Curtis Stone is just the latest example of how people can get intoxicated by a dogma, become blind to their own hypocrisy, and be unable to even begin to grasp the complex socio-economic system we live in and rely on for our prosperity.

Of course there are a lot of positive points with what Stone preaches: short supply chains, fresh and nutritious produce and effective use of resources. But he makes the mistake of viewing his lifestyle as the world-saving religion that needs to be imposed onto everyone else. If only everyone became urban farmers like him, all the world’s ills would surely go away. The reality, however, is that nothing could be more naive.

“Urban farmer” Curtis Stone despises the “destructive” global economy, yet gladly relies on fossil-fuel powered equipment, petroleum-based attire, modern eyewear, and computers. Image cropped here.
Like so many artsy-activist types, Curtis fails to realize that his current lifestyle is made possible only by the free-market, industrialized global system itself. In the video he says:
Every action you take in the global economy is destructive to the environment, it is destructive – it causes social inequity, wipes out indigenous cultures, forests – you name it. Everything we do, whether it’s buying a can of Coke, driving your car, or whatever we do is destructive. I’m really excited about getting to the point where everything we do is a reflection of what happens in nature. Everything creates more life, creates more soil fertility, purifies the air.”
He then adds that we need to get away from the growth-based economy. His answer: “If we have things we can trade and we grow food and everybody is fed, that sounds like a good economy to me.”
Well, that just happens to be the free market economy, the very one he criticized just moments earlier. But Stone’s free-market version is one that resembles the Flintstones: scaled back with only limited small technology. It’s backwards, and it could never feed 8 billion people.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




I’m OK, you’re not okay
Stone’s problem is that he still does not have an inkling of how the modern economy works and where the very tools, equipment and technical foundation he (obliviously) relies on come from.
Note how early in the video he recommends a 2-stroke-engine-powered rototiller. He also uses hundreds of square yards of plastic film, made from fossil fuel petroleum, to protect the plants from nature. The bicycle he rides neither fell from the sky nor grew from a tree, but is one that was produced by today’s modern, free market industrial economy, with its parts coming from all over the world. He wears sweat-shop-made clothing and footwear, and not fig leaves and ferns. His spectacles are probably made using European-ground lenses and frames made from wire drawn in Mexico. Early in the video he talks about how his “business” is run and how to earn money. He doesn’t pack his fresh produce in a sack made of hide, rather in plastic commercial food bins. Stone also uses his PC notebook to make his presentations across the country.
His view of today’s global economy is as narrow as it is hypocritical.
he fails to realize that it is the growth-based economy that allowed humans to go from clubs and stone wheels to a foot-propelled bicycle and plastic vegetable tubs. And had it not been for the rampant human stupidity and dogma getting in the way over the eons, mankind would surely have reached bicycles and rototillers hundreds of years earlier.
Clueless ingrate
If you want to convince anyone your philosophy is the real thing, then do what you are doing with nothing more than sticks and stones, and be successful at it. If you pull that off, then we’d believe you. Don’t preach like Al Gore does, and then hop on fossil-fuel powered private jets to spread your gospel. Travel to your speeches bare-footed, donning your best fig leaf. And never mind using a notebook and projector.
It’s wonderful Stone enjoys what he is doing and that many people appreciate all the fresh produce he grows and markets. Yes, some of his ideas are good and worth applause. Unfortunately, some people get a good idea and suddenly believe they are God’s Gift to mankind.
There are lots of other people out there doing good things; you’re not the only one. Stone, you need to climb down from your high horse and say thanks to those who made it possible for you, and not deplore them like a clueless ingrate jerk would do.
 
Share this...FacebookTwitter "
nan
"Ants are scary. They have a remorseless quality, seemingly indifferent to their individual welfare, their whole lives submerged in the collective. And that’s just the small ones. Super-sized versions are the stuff of classic horror, radioactively enhanced, famously threatening American cities from down the storm drains in Them! to terrorising Joan Collins up the jungle in Empire of the Ants. Try watching a single ant and you’ll soon lose sight of it the scurrying horde. The very best we have to say of them is their worthy but unlovely penchant for hard work, which is noted in the Bible. Even the fable of the ant and the grasshopper suggests a mean spiritedness by the hard working ant, who turns away the desperate grasshopper at the end of summer. But researchers at the University of Würzburg in Germany recently looked at one of Africa’s most implacably ferocious ants, and their work revealed a startling tale of possible battlefield comradeship and care. Matabele ants, aka Megaponera analis, are centimetre-long raiders who specialise in attacking and eating termites, in particular the family Macrotermitinae – aka the fungus-growing termites.  These ants are fast and agile, with a bite and sting that even humans do well to avoid. When looking for termites, the Matabele ants first send out scouts to locate a vulnerable nest, and the scouts then summon a raiding party of several hundred comrades. The ants target entrances to the termites’ nest, the largest piling in to rip open the entrance so that the raiders can storm through.  Termites are not defenceless though. The 3,000 or so species display a remarkable variety of weapons primarily to fend off ants: huge jaws to crush or pierce, nozzle-like heads to squirt noxious glue, even some species where older workers, worn out and not much use, can explode themselves, showering the attacker and martyr with cloying goo.  Macrotermitinae termites rely on soldiers with massive, muscled heads powering fearsome jaws. As the Matabele ants attack the nest, soldier termites rush to the breach and battle is joined. The ants seldom try to overrun the termites’ whole nest, instead pulling back once they have killed enough termites to carry back home as booty. But termite soldiers sell their lives dearly. There are fatalities among the ants and many are left with legs or antennae lopped off, struggling to stand. It is the fate of these casualties that is startling: the German researchers found that wounded ants can be rescued by their fellow workers. Injured ants release a chemical signalling for help, and change their behaviour if nest mates are nearby, in particular moving slowly as if to highlight their incapacity. (If the would-be helpers do not respond, the limping ant soon speeds up, often fast enough to rejoin the raiding party.)  Ideally, the wounded ant can be carried back to its nest – if worker ants find an injured nest mate, they may pick her up. This rescue depends partly on the casualty helping the rescue by adopting an easy positon for carrying. Injured stragglers hobbling back by themselves are much more vulnerable to predators keen to ambush a disabled meal. Once back at their nest, the injured ants are checked over and their wounds groomed, often for up to an hour. Survival of ants that received this care was markedly higher than ants that that were not treated.  Battlefield rescue of a fallen comrade? Tender, loving care? These are not the ants we know and fear.  Sadly, there is a catch. Checking the worker ants in Matabele colonies revealed a few with one, two or even three legs missing, but none with worse injuries. There seems to be a threshold for rescue. Wounded ants on the battlefield are triaged carefully by their comrades. Ones with one or two legs missing are often rescued, but the severely injured are seldom retrieved. The ants do not seem to be counting legs directly, instead badly damaged ants may not be able to adopt the correct position for battlefield rescue. And even if they can get back home, severely injured ants are removed from the nest, cast out to their doom. The ants’ comradeship has its limit: at least three working legs."
"Fires are raging across the Amazon right now, while deforestation in the region is speeding up. As deforestation is the second-largest contributor to carbon emissions after fossil fuels, a forest deal will be crucial. What Brazil agrees to at the Paris climate talks – and what it does over coming decades – will affect us all. During the opening days of the Paris conference, virtual forests were projected onto the Eiffel Tower in recognition of their importance to the environment. Prince Charles joined in, warning that: “We must save our forests, for there is no Plan B”. And, on the first day,  Norway, Germany and the UK pledged US$5 billion to reduce deforestation in Brazil and other countries with large tropical forests.  If the world is to effectively combat climate change then it’s no surprise Brazil is considered a major player. The country has the third most trees in the world and – unlike Russia and Canada’s taiga – most Brazilian forests grow on fertile ground that could otherwise make good farmland. This means they’re disappearing – fast.  Only weeks before the climate talks began, embarrassing news emerged that deforestation in the Amazon had increased by 16% over the past year, suggesting that Brazil’s efforts to combat climate change in this area may already have peaked.  The country is aiming for zero net emissions from deforestation by 2030 yet this remains a huge challenge. A recent report by the Brazilian Institute of Space Research concluded that the government needs to make stronger efforts to enforce forest protection and to restore forests in areas that have already been cleared. With El Niño also leading to unusually intense forest fires in the Amazon rainforest, the government’s climate policy therefore seems less ambitious than it should be.  It will need to do this, as reducing deforestation remains a cornerstone of Brazil’s commitment to reduce carbon emissions from 2005 levels by 37% in 2025 and 43% by 2030. To be fair, the country does deserve some praise – since 2004 deforestation rates have been reduced by an impressive 70%. However forest clearances may need to end entirely for the country to meet its own targets. The Paris agreement is likely to tackle deforestation through REDD+, a form of “carbon offsetting” where rich countries pay poorer forested nations to keep their trees and effectively “offset” emissions made in the industrialised world. Critics have questioned whether this form of carbon market tackles the real causes of deforestation. They point out that offsetting simply allows developed countries to continue polluting rather than recognise their historical responsibilities. This is exactly why the Brazilian government decided to ban international trading of its REDD+ credits just ahead of COP21, while continuing to use bilateral funding against deforestation. While environmental movements welcomed this announcement, they also point out that the Brazilian government weakened forest protection legislation in 2012, threatening to undermine recent progress.  A more fundamental question is whether forests can be bought and sold without considering the communities who live there, as indigenous groups have had very little effective participation in the negotiations.  Even at COP21, the voices of people who actually experience the effects of deforestation first-hand only tend to be heard on the fringes. Latin American indigenous groups provided examples of effective forest management at side events but many of them could not get accreditationfor the official negotiations.  As one Guatemalan indigenous leader pointed out: “We are nations but we are not part of the negotiations.” Indigenous leaders claim that they are the guardians of the forest, able to offer alternative ways to protect the rainforest. Indeed, evidence from Brazil points to lower levels of deforestation in their territories – indigenous rights must be included in the Paris agreement. Despite the billions of dollars devoted to forests, there isn’t much evidence of this commitment within the conference buildings. Temporary structures housing the main negotiations and side events dominate the site, with two solitary “wind trees” generating renewable energy. Surrounded by colourful animal sculptures, visitors can also attach their messages about climate change to a lone wooden tree in the Climate Generations area. But while trees have made only a symbolic and virtual appearance in a battered Paris, they remain as important as ever – as does the vexed question of Brazil’s forest policy."
"
Share this...FacebookTwitterBy Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
On March 1st Arizona State University reported on Antarctica’s record high temperature. Surprisingly the record was set not this year, or even this decade, rather it was set in the year 1982:
World Meteorological Organization verifies highest temperatures for Antarctic region
ASU climate expert, WMO rapporteur talks about importance of such verification
The World Meteorological Organization announced Wednesday new verified, record high temperatures in Antarctica, an area once described as “the last place on Earth.” The temperatures range from the high 60s (in Fahrenheit) to the high teens, depending on the location they were recorded in Antarctica. Knowledge and verification of such extremes are important in the study of weather patterns, naturally occurring climate variability and human-induced change at global and regional scales, said Randy Cerveny, an Arizona State University professor of geographical science and urban planning and the Rapporteur of Climate and Weather Extremes for the WMO. “The temperatures we announced today are the absolute limit to what we have measured in Antarctica,” Cerveny said. “Comparing them to other places around the world and seeing how other places have changed in relation to Antarctica gives us a much better understanding of how climate interacts, and how changes in one part of the world can impact other places.”  Because Antarctica is so vast (it is roughly the size of the United States) and varied the WMO committee of experts, convened by Cerveny, provided three temperature measurements for the Antarctic.
The highest temperature for the “Antarctic region” (defined by the WMO and the United Nations as all land and ice south of 60-deg S) of 19.8 C (67.6 F), which was observed on Jan. 30, 1982, at Signy Research Station, Borge Bay on Signy Island. The highest temperature for the Antarctic Continent, defined as the main continental landmass and adjoining islands, is the temperature extreme of 17.5 C (63.5 F) recorded on Mar. 24, 2015 at the Argentine Research Base Esperanza located near the northern tip of the Antarctic Peninsula. The highest temperature for the Antarctic Plateau (at or above 2,500 meters, or 8,200 feet) was -7 C (19.4 F) made on Dec. 28, 1980, at an automatic weather station site D-80 located inland of the Adelie Coast.
The Antarctic is cold, windy and dry. The average annual temperature ranges from -10 C on its coasts to -60 C (14 F to -76 F) at the highest points in the interior. Its immense ice sheet is about 4.8 km (3 miles) thick and contains 90 percent of the world’s fresh water, enough to raise sea levels by around 60 meters (200 feet) if it were all to melt. Cerveny said that observing the extremes of what the Polar Regions are experiencing can provide a better picture of the planet’s interlinked weather system. “The polar regions of our planet have been termed the ‘canary’ in our global environment,” Cerveny said. “Because of their sensitivity to climate changes, sometimes the first influences of changes in our global environment can be seen in the north and south polar regions. Knowledge of the weather extremes in these locations therefore becomes particularly important to the entire world. The more we know of this critically important area to our environment, the more we can understand how all of our global environments are interlinked.”  Cerveny said an additional benefit is understanding how those extremes were achieved. “In the case of the Antarctic extremes, two of them were the result of what are called ‘foehn’ winds — what we call Chinook winds — very warm downslope winds that can very rapidly heat up a place. These winds are found even here in the United States, particularly along the front range of the Rockies. The more we learn about how they vary around the world, the better we can understand them even here in the United States. Full details of the Antarctic high temperatures and their assessment are given in the on-line issue of Eos Earth and Space Science News of the American Geophysical Union, published on March 1, 2017
==============================

PS: Happy Easter everybody! -PG
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhat follows later, below, is a short commentary by Prof. Fritz Vahrenholt and Dr. Sebastian Lüning recently appearing at Die kalte Sonne site here. Indeed, it’s truly mind-boggling how a single person or a trace gas now gets all the blame for every weather problem. The hysteria-filled Dark Ages of the Inquisition are back.

Torches and pitchforks.
For example, The Mail here just reported how a team of scientists led by Professor James Hansen, NASA’s former climate science chief, even proposes a sort of final solution: immediately removing CO2 from our societies altogether, and then removing it from the atmosphere.
This is hysteria. Blaming 0.01% of the atmosphere (CO2) for bad weather is truly as insane as blaming all the world’s problems on 0.6% of the population (Jews) in the 1930s.
Manmade catastrophic climate change is a grotesque hysteria propagated by state-sponsored activist scientists and hundreds of billions a taxpayer money (99% wasted).
As a whole climate is a highly complex system involving almost countless variables. Singling out just one of these (a tiny one) and blaming all weather ills on it is an intellectual and scientific folly of breathtaking proportions.
Atmospheric CO2 concentrations are in fact at a geologically-historically puny 400 parts per million (and 100 parts per million of that may be attributed to man, i.e. 0.01% of the atmosphere). Historically the earth still finds itself at the very low end in terms of CO2 in the atmosphere. An honest look at the entire body of science shows us that CO2 is in fact a bit player at best, and at the current juncture catastrophic manmade warming science is entering the realms of mass fraud.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Historical “nearsightedness”
What follows is Vahrenholt’s and Lüning’s report in English. I’m glad to see that there are at least two German scientists (there are in fact others) who opted to stay off the loon bandwagon and want nothing to do with all the madness.
=============================
By Prof. Fritz Vahrenholt and Dr. Sebastian Lüning
In the “Blog der Republik” on June 9, 2017, the current drought in South Africa, no time was wasted with connecting it to climate change. No question about it, Trump is to blame for the water shortage!

Even that US-President Trump denies climate change, Capetown is suffering under dramatic drought.
The South African metropolis of Capetown is suffering from one of the worst drought in 113 years. Drastic emergency rules will force water saving. To do this drastically increased prices and much communication work will contribute to the effort. Just a drop in the bucket and too late? Even though the drama had been foreseen years ago, policymakers relied solely on winter rains – which have not appeared once again. Now the citizens and economy are suffering […] And even as US President Donald Trump denies climate change, in South Africa the consequences cannot be ignored.”


Read more at Blog der Republik
It never ceases to amaze how little the commentators know about the history of the climate. Because of this historical nearsightedness, they construct adventurous interrelationships. Indeed the first question to be asked is whether winter rains had always been steady, or if there have been variations in the past. If the rain fluctuated, what was the driving mechanism behind it? Once again that brings us to our Project on Medieval Climate Anomalies, which records historic precipitation changes in addition to the temperature changes. One click on the project map is all it takes to identify the studies on winter rains of Capetown.
Studies of the offshore sediment boring GeoB 8323 as well in Lake Verlorenvlei, Princessvlei Lake and Katbakkies Pass show that winter rains were reduced over 200 years, 1000 years ago. These are the yellow-colored dots on the map (as well as a nearby red point). When you click on the dots, you can even open the most important diagrams that show the documented historical fluctuations in winter rain.

Share this...FacebookTwitter "
"Josie Douglas sits on a verandah overlooking a ridge of red rocks and earth, scrubby with saltbush and spinifex near the centre of Alice Springs. It’s late afternoon and only 31C – a reprieve from a run of days in the high 30s and 40s. But Douglas knows that from now on it will only get hotter. Last summer was the hottest on record, and the driest in 27 years in central Australia. Five per cent of the town’s street trees died. A heat monitoring study showed that on some unshaded streets the surface temperature was between 61C and 68C. “We can’t keep going on the way we’re going,” says Douglas, who is manager of policy and research at the Central Land Council. “Central Australian Aboriginal people are very resilient. They have evolved to cope with the harsh and variable desert climate, but there are limits. “Without action to stop climate change, people will be forced to leave their country and leave behind much of what makes them Aboriginal. Climate change is a clear and present threat to the survival of our people and their culture.” Across central Australia, people are bracing themselves for another scorching summer of drought. At least nine remote communities and outstations are running out of water. A further 12 have reported poor quality drinking water as aquifers run low and the remaining supply is saline.  Temperature records have already been broken. In the year to July 2019, Alice Springs had 129 days over 35C, and 55 days over 40C. It wasn’t meant to be like this – at least, not yet. The national science agency, the CSIRO, predictedthat these temperatures would not arrive until 2030. As the Northern Territory’s environment minister, Eva Lawler, said last September: “If we don’t do anything, the NT will become unliveable.” The problem is where to start. In Alice Springs opinion is divided among local politicians about the impact climate change is having on life in the desert. Sitting on the grassy lawn outside the council, Jimmy Cocking of the Arid Lands Environment Centre talks openly about climate refugees: those who have already come into town, and those who will have to come in the near future. “We’re going to end up with a whole bunch of internally displaced people within the Northern Territory in remote Australia, if we’re not planning for that,” he says. “If regional centres like Alice Springs and others aren’t planning to be able to deal with the influx of climate refugees internally within our region, we’re going to be left flatfooted and unable to deal with any of the challenges and social consequences that will come from that.” Cocking is on the town council and has sought to pass motions to declare a climate emergency. But the mayor, Damien Ryan, is reluctant to sound the climate alarm. “In local government speak, when you have an emergency, you close it down,” Ryan says. “I have not had any of the people who talk about an emergency say what is the next step. So you declare an emergency, what do you do then the next day? That’s never been made clear to me.” At its October meeting, the council did not agree on the word “emergency” but voted unanimously to say there was an “escalating urgency for climate action”. Douglas and the CLC say Aboriginal communities are doing what they can. “People are already mitigating climate change through traditional burning and they are investing their income from land use agreements to install solar power, plant bush tucker gardens in communities and operate swimming pools, but all that counts for little in the face of the lack of climate leadership from the government,” she says. The NT government says it has allocated $15m to “revitalising” the Alice Springs city centre. Some of those funds will go towards shade and landscaping to help cool the streets, and to public water stations. Ryan says the council is encouraging local schools to plant more trees. The Territory government says it has a climate change response strategy and is working with other governments and the Bureau of Meteorology to “develop national guidelines for the development of a warning system for extreme heat events”. In the meantime, Douglas says, people are living in houses that are “unbearable”. “During our summers you can sometimes see people in communities hosing the outside of their Besser brick walls with garden hoses to keep cool despite the water shortages – that’s how desperate they are.” About 3ookm north-west of Alice Springs is Yuendumu, the largest remote community in central Australia. Its 900 or so residents are facing summer without a reliable supply of adequate drinking water. The NT government has stopped building new housing because there isn’t enough water in the dwindling aquifer to accommodate more people. Yuendumu is not alone. The Central Land Council’s chief executive, Joe Martin-Jard, says that at every regional meeting, water security is top of the agenda. “Between Alice Springs and Mount Isa, there’s probably only one major community with a decent water supply,” Martin-Jard says. “We’re not getting the rain we used to, to recharge the aquifers. So as water is drawn out of the aquifers it becomes more saline and less potable [drinkable]. “It’s a really horrible dilemma.” The NT’s Power and Water Corporation, which is responsible for essential services in 72 remote communities and outstations, says most communities in the arid region are “faced with some level of water stress” and emergency planning is under way, but there are “rarely any simple solutions”. “The difficult reality is that many communities originally developed historically in locations where there was never any secure, reliable, high quality water resources in close proximity,” a spokesperson said. “As those communities have grown … and expectations of improved levels of service have appropriately increased, the challenges also continue to increase.” Power and Water says more drilling programs are planned but “finding new water sources is very challenging and often these drilling programs have moderate prospects for success”. “Without large or extended rainfall … the water security risks will progressively increase in some centres, with an increased likelihood that source supply capacity at some could fail.” At least 12 communities have reported poor quality drinking water. At Laramba, Willowra and Wilora, nitrates and uranium are at levels exceeding health guidelines. NT Power and Water says it is “investigating alternative technology options”. It has already installed treatment plants at Kintore, Ali Curung and Yuelamu to reduce high levels of nitrates, uranium and fluoride.  Sorry your browser does not support audio - but you can download here and listen https://audio.guim.co.uk/2019/12/17-41001-FS_HEATWAVE.mp3  In Alice Springs’ 18 town camps, where people from out bush often end up, houses are commonly built from Besser bricks – hollow concrete blocks which are cheap, but which trap the heat. There’s a lack of tree cover or other kinds of shade. Houses bake in the sun and, while the majority have solar panels, they often have only an evaporative air conditioning unit, known locally as a “swampy”, to cool the house. A “swampy” uses a lot of water and can struggle on hot days, especially when there are a lot of people sharing a house, which is common in town camps with big families and fluctuating populations. “Air conditioning is an essential item in the desert, not a luxury,” the CLC’s Josie Douglas says, “but it does not come standard.” When remote community and town camp tenants are offered housing, there is “a hole where the aircon unit should be and they are told to buy it themselves”. “Many can only afford to ‘close the gap’ with a piece of wood, or run expensive reverse-cycle aircon very sparingly,” she says. “Some places don’t have enough water to use a cheaper swampy.” Houses that don’t cool down overnight create big health and social problems. “People resort to sleeping outside, or cramming everybody into the coolest room of the house, with all the well-known consequences for the spread of diseases that whitefellas only know from medical textbooks. “It’s also common for people to sleep in shifts, with young people roaming the streets at night where they get into trouble, and sleeping during the day when they should be at school.” This is at odds with the NT government’s view of the quality of town camp and remote community housing. A government spokesperson tells Guardian Australia that homes are designed with weather conditions and regional climate in mind, and they include external shading, natural ventilation and insulation. “Investment into housing in town camps has included the installation of louvres, sunscreens, verandas and insulation,” the spokesperson said. “The Department of Housing and Community Development has also upgraded some key community infrastructure including improved shading and the installation of fans.” Douglas is calling on the government to “stop building concrete hotboxes”. “More than a decade ago, the government and the CLC were partners [in research] that came up with really solid recommendations about how to make desert houses more energy-efficient and communities more resilient. “Some measures, such as making sure houses are built with the right orientation … and have passive cooling and a white roof, cost almost nothing. We would like to know how many of these expensive research findings have been implemented in our region.” Shirleen Campbell is a Warlpiri and Arrernte woman who grew up at Hoppy’s Camp, or Lhenpe Artnwe. She told the Alice Springs climate rally in October that town campers were very worried about climate change. “This is our place,” she said. “If it gets too hot, if we suffer through endless droughts or we spoil our water, then we don’t have another place to go. “We want houses that are right for this place and right for our people. We want to invest in renewable energy, like solar.” Campbell is a co-coordinator of the women’s family safety group at Tangentyere council, which delivers services to and advocates on behalf of town camp residents. “Most of all we want people to treat this place as a legacy to be handed down to our children and grandchildren. It is not a speculative commodity and it is not something to be sold or exported. “We have been here for a long time and want to look after this place for those that come after.” There are few public places in Alice Springs to cool off. The Yeperenye shopping centre has security guards at the doors and, according to Douglas and Campbell, Aboriginal people are regularly moved on. The library is a popular, free cool space. There’s a widescreen TV rigged up with headphones, showing movies. Westerns are popular, as are replays of AFL grand finals. The Saltbush room down the hall is a haven for older folk, while little mobs of kids hang out among the young adult stacks or cluster around the phone-charging station. “We found there’s a gap in after-school care services from about 2.30 to 4.30, the hottest time of the day,” says the head librarian, Clare Fisher. “The kids can come to the library, cool off, have fruit and sandwiches.” “Libraries are for connection and relaxation as well as knowledge. We make everyone welcome – but we explain how to use the library and how to behave as well. We very much believe in come and be who you are.” In January footage of dead and dying horses in a dry creek bed at Ltyentye Apurte, 80km south-east of Alice Springs, flashed around the world. The Ltyentye Apurte rangers had the unenviable task of dragging more than 100 dead horses from the creek bed and disposing of their bodies. In June the CLC conducted an emergency cull of more than 1,400 feral horses, donkeys, camels and cattle from a waterhole near Lajamanu. The animals were thirsty and dying, congregating around the last remaining springs and water sites. The CLC has eradicated 6,279 feral animals in preparation for summer. Traditional owners don’t usually support animal culls, the CLC says, but there were no alternatives, with so many animals dying or in poor condition. Feral animals damage community infrastructure and housing. Thirsty camels, for example, will attack air conditioning units because they smell water, and lay waste to water tanks, bores, fences, pipes and taps. In town, Tangentyere council wants to measure exactly how well houses are functioning. Tangentyere’s social policy and research manager, Michael Klerk, is in discussions with the CSIRO to install temperature data loggers in people’s houses, to build a case for improvements that are taken for granted elsewhere: solar power, insulation, better air conditioning, wide awnings, more shade. “Last summer – which was a very hot summer, soon to be repeated – a lot of anecdotal feedback was that people’s evaporative air conditioners weren’t cooling the houses sufficiently,” Klerk says. “This probably reflects the reality that evaporative air conditioners are not good at cooling houses when the external temperatures are in the mid-40s. “You might drop the temperature of a house to mid-30s, but that’s not an optimal internal ambient temperature for comfort or for health.” Most people living in town camps and remote communities, and some in suburban public housing, have pre-paid electricity meters. Residents are issued a power card, which they top up with their welfare payments or income. Once the credit is spent, they have to top it up again, or go without electricity. Klerk says that happened a lot in the last quarter of 2018. In Alice Springs, 420 of 570 households with prepaid electricity meters had at least one self-disconnection, which lasted, on average, 7.5 hours. Of the 570 Alice Springs meters, 285 are in town camp dwellings. In effect, more than half the town campers ran out of money to pay for electricity. “When the power goes off, it is bad for our health, the food gets spoiled, we can’t wash our clothes and we can’t wash our kids,” Shirleen Campbell told the rally. “In summer, when our houses are hot or when we don’t have electricity, our people look for comfort in air-conditioned public places. We are not always welcome in these places and sometimes there are problems. We are thankful for places like the library and the pool.” Klerk says low-income residents shouldn’t have to go broke trying to keep their houses cool. “It’s not acceptable that people’s houses are making them sick, and something really needs to be done about it. It shouldn’t all be passed on to the consumer. “If it’s the case of people having to spend more money to keep the houses at a temperature that delivers health outcomes, then we have to rethink the levels of income support that are available to people, particularly in these regions where it’s so hot.” Predictions by the Central Australian Aboriginal Congress for the health impacts of heat are dire. In its submission to the NT government’s climate change policy discussion paper, it outlined some of them: “Increased sickness and mortality due to heat stress, increased food insecurity and malnutrition, increased risk from infectious disease, poorer mental health and an increased potential for social conflict.” The Pintupi-Luritja artist Irene Nangala was among the first to return to her home country at Kintore in the western desert, near the border with Western Australia, in the early 1980s. Until then, Pintupi people had been living a long way from home at the mission at Papunya, and they were homesick. Nangala helped set up the Kintore school. It was a “windbreak school” at first, she says: just a tarp to keep the sun and the rain water out. “Then we got a few teachers. It was hard work. We’ve got a proper good school now, proper shop. Nice clinic and aged care, child care.” Nangala says she doesn’t have an air-conditioner. On hot days the family puts blankets on the windows. Other elders whose aircon units break down have to wait for a repairer to come from Alice Springs, more than 10 hours’ drive away. “It’s really hot in Kintore. We can’t go and sit outside. We have to go at night to sit down with the families.” Nevertheless, Nangala says she does not want to leave. “We built up Kintore,’ she says. “People are really enjoying going back to their grandfather’s land. That’s the right thing to do. And it’s good for them to go back, the old people, good for the heart and the spirit. “When they went first, they cried, they missed that place for a long time.” Nangala says people don’t want to come into town, where life might be worse. “Climate change is true,” Nangala says. “They [politicians] got the map and weather things, they should see the temperature what is happening around Australia, it’s so hot.” Jimmy Cocking says: “We are walking blindly into the new climate reality. We’ve moved beyond hope, and we can’t be running on hope alone. “The only thing that is going to get us over the line is action. And the antidote to despair is action. “So there’s a lot of things that we need to be looking to change so that we aren’t going to be putting people’s lives at risk.”"
"
Share this...FacebookTwitter
Future Global Warming Scenarios ‘Potentially Beneficial’, Cooling May Cause Ecological ‘Declines’
Fan et al., 2017
“Our data suggest that future global warming scenarios would potentially be beneficial for the hydrological and ecological conditions of the EASM [East Asian Summer Monsoon] margin, while small decreases in the precipitation and temperature superimposed on the long-term deteriorated climate  may cause large declines in the hydrology and ecology in the semi-arid regions of northern China.”
Human Health Risks ‘Extremely Sensitive’ To Temperature, With Cold Temperatures More Dangerous
Wang et al., 2017
“Numerous previous studies have reported that human health risk is extremely sensitive to temperature. … At the community level, the mean value of relative extreme cold risk (1.63) of all 122 communities was higher than that of extreme high temperature (1.15). … A prolonged impact of low temperature [cold] on human health was observed in China”
Mass Extinctions Caused By Cold Temperatures (Ice Ages), Not Global Warming
Baresel et al., 2017
“The Earth has known several mass extinctions over the course of its history. One of the most important happened at the Permian-Triassic boundary 250 million years ago. Over 95% of marine species disappeared and, up until now, scientists have linked this extinction to a significant rise in Earth temperatures. But researchers have now discovered that this extinction took place during a short ice age which preceded the global climate warming. It’s the first time that the various stages of a mass extinction have been accurately understood and that scientists have been able to assess the major role played by volcanic explosions in these climate processes.”
Warming Leads To Less Extreme, Unstable Weather, Cooling Does The Opposite
Zhang et al., 2017
“Based on continuous and coherent severe weather reports from over 500 manned stations, for the first time, this study shows a significant decreasing trend in severe weather occurrence across China during the past five decades. The total number of severe weather days that have either thunderstorm, hail and/or damaging wind decrease about 50% from 1961 to 2010. It is further shown that the reduction in severe weather occurrences correlates strongly with the weakening of East Asian summer monsoon which is the primary source of moisture and dynamic forcing conducive for warm-season severe weather over China.”
Kawamura et al., 2017
“Numerical experiments using a fully coupled atmosphere-ocean general circulation model with freshwater hosing in the northern North Atlantic showed that climate becomes most unstable in intermediate glacial conditions associated with large changes in sea ice and the Atlantic Meridional Overturning Circulation. Model sensitivity experiments suggest that the prerequisite for the most frequent climate instability with bipolar seesaw pattern during the late Pleistocene era is associated with reduced atmospheric CO2 concentration via global cooling and sea ice formation in the North Atlantic, in addition to extended Northern Hemisphere ice sheets.”
Heller, 2017
“The hurricane analysis conducted by Burn and Palmer (2015) determined that hurricane activity was subdued during the [warm] Medieval Climate Anomaly (MCA) (~900-1350 CE) and became more produced during the [cold] Little Ice Age (LIA) (~1450-1850 CE), followed by a period of variability occurred between ~1850 and ~1900 before entering another subdued state during the industrial period (~1950-2000 CE). In general, the results of this study corroborate these findings.”
“[W]hile hurricane activity was greater during the LIA, it also had more frequent periods of drought compared to the MCA (Burn and Palmer 2014), suggesting that climate fluctuations were more pronounced in the LIA compared to the MCA. The changes in the diatom distribution and fluctuations in chl-a recorded in this study starting around 1350 also indicate that variations in climate have become more distinct during the LIA and from ~1850-1900. … [C]limate variability has increased following the onset of the Little Ice Age (~1450-1850 CE), however it is difficult to distinguish the impacts of recent anthropogenic climate warming on hurricane activity from those of natural Atlantic climate regimes, such as ENSO.”
Warming Leads To Fewer And Less Intense Hurricanes
Chen et al., 2017
“Results indicate that the midlatitude summer cyclone activity over East Asia exhibits decadal changes in the period of 1979–2013 and is significantly weakened after early 1990s. …  Moreover, there is a close linkage between the weakening of cyclonic activity after the early 1990s and the nonuniform surface warming of the Eurasian continent. Significant warming to the west of Mongolia tends to weaken the north–south temperature gradient and the atmospheric baroclinicity to its south and eventually can lead to weakening of the midlatitude cyclone activity over East Asia.”
Choi et al., 2017
“This study analysed the time series of tropical cyclone (TC) frequency during October–December (OND) for 32 years (1980–2011). There was a strong decreasing trend of TCs [tropical cyclones] until recently, and the TC sharply decreased from 1996 after the statistical change-point analysis was applied to this time series.”
Wellford et al., 2017
“Since the late 1800s, in contrast to much of the Southeastern USA, the Georgia coast has experienced infrequent hurricane landfalls, particularly in recent decades. As a result, coastal storm preparedness complacency appears to be rampant along the Georgia coastline. Both local and state governments were unprepared for shadow evacuation during Hurricane Floyd in 1999. The study described here includes an examination of temporal and spatial trends in hurricane landfall along the Georgia coast from 1750 to 2012. Since 1750, 18 of the 24 recorded hurricanes that made landfall along the Georgia coast occurred between 1801 and 1900, yet the hurricane intensities have declined since 1851.”
Stable Or Decreasing Trends In Drought And Flood Frequency With Warming
McAneney et al., 2017
“[A] 122-year record of major flooding depths at the Rarawai Sugar Mill on the Ba River in the northwest of the Fijian Island of Viti Levu is analysed. … It exhibits no statistically significant trends in either frequency or flood heights, once the latter have been adjusted for average relative sea-level rise. This is despite persistent warming of air temperatures as characterized in other studies. There is a strong dependence of frequency (but not magnitude) upon El Niño-Southern Oscillation (ENSO) phase, with many more floods in La Niña phases. The analysis of this long-term data series illustrates the difficulty of detecting a global climate change signal from hazard data, even given a consistent measurement methodology (cf HURDAT2 record of North Atlantic hurricanes) and warns of the strong dependence of any statistical significance upon choices of start and end dates of the analysis.”
McCabe et al., 2017
“In this study, a monthly water-balance model is used to simulate monthly runoff for 2109 hydrologic units (HUs) in the conterminous United States (CONUS) for water-years 1901 through 2014. … Results indicated that … the variability of precipitation appears to have been the principal climatic factor determining drought, and for most of the CONUS, drought frequency appears to have decreased during the 1901 through 2014 period.”
Higher CO2 Concentrations Are Greening The Earth, Reducing Desert Area And Drought Stress
Bastos et al., 2017
“The sustained increasing vegetation activity trend (greening) in the Northern Hemisphere (NH) has been a prominent feature in satellite observations since the 1980s and is consistently simulated by models. The trend in vegetation greenness has been linked to increasing growing season length at high latitudes and enhancemed terrestrial CO2 uptake in northern ecosystems. The greening pace has been associated with asymmetric effects of climate trends in vegetation activity or variations in the climate forcing. It has also been shown that regional greening trends are further attributed to land use change, land management, CO2 fertilization, and nitrogen deposition”
Li et al., 2017
“[M]aternal CO2 environment modulated the response of wheat plants to drought stress in terms of biomass production, [such that] plants reared from seeds harvested from the e[CO2] maternal growth environment eliminated the negative impact of drought stress on DM [dry biomass]. … [T]ransgenerational exposure to e[CO2] also attenuated the negative impact of drought on evapotranspiration in wheat plants. … [T]ransgenerational exposure of wheat plants to e[CO2] [elevated CO2] could attenuate the negative impact of drought stress in terms of DM and WUE [water use efficiency].”
Brandt et al., 2017
“Here we used a passive microwave Earth observation data set to document two different trends in land area with woody cover for 1992–2011: 36% of the land area (6,870,000 km2) had an increase in woody cover largely in drylands, and 11% had a decrease (2,150,000 km2), mostly in humid zones. Increases in woody cover were associated with low population growth, and were driven by increases in CO2 in the humid zones and by increases in precipitation in drylands, whereas decreases in woody cover were associated with high population growth.”
(press release)
“Africa has become greener in the last 20 years … [M]ore CO2 in the atmosphere together with a wetter, warmer planet, provides conditions that help trees and bushes to grow.”
Bastin et al., 2017
“We show that in 2015, 1327 million hectares of drylands had more than 10% tree-cover, and 1079 million hectares comprised forest. Our estimate is 40 to 47% higher than previous estimates, corresponding to 467 million hectares of forest that have never been reported before. This increases current estimates of global forest cover by at least 9%.”
Regional Sea Level Changes Unremarkable…Land Area Above Sea Level Expanding
Mörner, 2017
“Coastal morphology, stratigraphy, radiocarbon dating, archaeological remains, historical documentation, and tide gauge records allowed us to establish a very firm and detailed record of the changes in sea level in Goa over the last 500 years. It is an oscillation record: a low level in the early 16th century, a ~50-cm high[er than now] level in the 17th century, a level below present sea level in the 18th century, a ~20-cm high level in the 19th and early 20th centuries, a ~20-cm fall in 1955–1962, and a virtually stable level over the last 50 years. This sea level record is almost identical to those obtained in the Maldives and in Bangladesh. The Indian Ocean seems to lack records of any alarming sea-level rise in recent decades; on the contrary, 10 sites analyzed indicate a sea level remaining at about 60.0, at least over the last 50 years or so.”
Watson, 2017
“The analysis in this paper is based on a recently developed analytical package titled ‘‘msltrend,’’ specifically designed to enhance estimates of trend, real-time velocity, and acceleration in the relative mean sea-level signal derived from long annual average ocean water level time series. Key findings are that at the 95% confidence level, no consistent or compelling evidence (yet) exists that recent rates of rise are higher or abnormal in the context of the historical records available across Europe, nor is there any evidence that geocentric rates of rise are above the global average. It is likely a further 20 years of data will distinguish whether recent increases are evidence of the onset of climate change–induced acceleration.”
Donchyts et al., 2016
Earth’s surface water change over the past 30 years [1985-2015]  … “Earth’s surface gained 115,000 km2 of water and 173,000 km2 of land over the past 30 years, including 20,135 km2 of water and 33,700 km2 of land in coastal areas.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




(press release)
Coastal areas were also analysed, and to the scientists’ surprise, coastlines had gained more land – 33,700 sq km (13,000 sq miles) – than they had been lost to water (20,100 sq km or 7,800 sq miles).  “We expected that the coast would start to retreat due to sea level rise, but the most surprising thing is that the coasts are growing all over the world,” said Dr Baart.  “We’re were able to create more land than sea level rise was taking.”
Warming, ‘Acidification’ Not Harming – Even Benefiting – Marine Species
Toyofuku et al., 2017
“Ongoing ocean acidification is widely reported to reduce the ability of calcifying marine organisms to produce their shells and skeletons. Whereas increased dissolution due to acidification is a largely inorganic process, strong organismal control over biomineralization influences calcification and hence complicates predicting the response of marine calcifyers. Here we show that calcification is driven by rapid transformation of bicarbonate into carbonate inside the cytoplasm, achieved by active outward proton pumping. Moreover, this proton flux is maintained over a wide range of pCO2 levels. We furthermore show that a V-type H+ ATPase is responsible for the proton flux and thereby calcification. External transformation of bicarbonate into CO2 due to the proton pumping implies that biomineralization does not rely on availability of carbonate ions, but total dissolved CO2 may not reduce calcification, thereby potentially maintaining the current global marine carbonate production.”
(press release)
“[A] group of scientists discovered to their own surprise that some tiny unicellular shellfish (foraminifera) make better shells in an acidic environment. This is a completely new insight.”
Ollier, 2017
“The coast contains ‘carbonate sand factories’ where organisms produce vast amounts of sand by fixing carbon dioxide as carbonates. Far from dissolving carbonate by acidification, carbon dioxide is an essential part of carbonate production and the continued maintenance and growth of coasts and reefs. Government policies to adapt renewable energy are unlikely to affect the system.”
McElhany, 2017
“Documenting an effect of OA [ocean acidification] involves showing a change in a species (e.g. population abundance or distribution) as a consequence of anthropogenic changes in marine carbonate chemistry. To date, there have been no unambiguous demonstrations of a population level effect of anthropogenic OA [ocean acidification], as that term is defined by the IPCC. … [I]t is important to acknowledge that there are no studies that directly demonstrate modern day effects of OA [ocean acidification] on marine species.”
Mardones et al., 2017
“Exposure of the toxigenic dinoflagellate Alexandrium catenella to variations in pCO2/pH, comparable to current and near-future levels observed in Southern Chilean fjords, revealed potential functional adaptation mechanisms. Under calculated conditions for pH(total scale) and pCO2 ranging from 7.73–8.66 to 69.7–721.3 μatm, respectively, the Chilean strain Q09 presented an optimum growth rate and dissolved inorganic carbon (DIC) uptake at near-equilibrium pCO2/pH conditions (∼8.1). … We suggest that A. catenella Chilean strains are highly adapted to spatio-temporal pCO2/pH fluctuations in Chilean fjords, becoming a resilient winner from expected climate change effects.”
Glandon et al., 2017
“No effect of high pCO2 on juvenile blue crab, Callinectes sapidus, growth and consumption despite positive responses to concurrent warming … Our study is the first to examine the effect of multiple climate stressors on blue crab and therefore basic responses, including the growth per molt (GPM), inter-molt period (IMP), and food consumption, were quantified. GPM [growth per molt] was not affected by either increased temperature or pCO2.”
Poulton et al., 2017
“For the first time, this study investigated the independent and combined impacts of elevated carbon dioxide (CO2) and anthropogenic noise [produced by shipping, seismic surveys, and pile-driving] on the behaviour of a marine fish, the European sea bass (Dicentrarchus labrax).  … Elevated CO2 did not alter the ventilation rate response to noise. Furthermore, there was no interaction effect between elevated CO2 and pile-driving noise, suggesting that OA [ocean acidification] is unlikely to influence startle or ventilatory responses of fish to anthropogenic noise.”
Cooper et al., 2017
“We determined tolerances of E. pacifica to prolonged exposure to pH levels predicted for 2100 by maintaining adults at two pCO2 levels (380 and 1200 µatm) for 2 months. Rates of survival and moulting were the same at both pCO2 levels. High pCO2 slowed growth in all size classes.”
Hassenrück et al., 2017
“Our results suggest that on mature settlement surfaces in situ, pH does not have a strong impact on the composition of bacterial biofilms. Other abiotic and biotic factors such as light exposure and interactions with other organisms may be more important in shaping bacterial biofilms on mature surfaces than changes in seawater pH.”
Lee and Kim, 2017
“High atmospheric CO2 dissolves into the surface of the ocean and lowers the pH of seawater and is thus expected to pose a potential threat to various marine organisms. We investigated the physiological and behavioural responses of adult Manila clams, Venerupis philippinarum (n = 96, shell length 25.32 ± 1.66mm and total wet weight 3.10 ± 0.54 g), to three levels (400, 700, and 900 μatm) of CO2 partial pressure (pCO2) for 48 days. There were no significant differences in mortality, growth, respiration rate, or emergence from the sediment between the three levels, indicating that near future atmospheric levels of CO2 do not seem to have a serious effect on the physiology and behaviour of adult Manila clams.”
Page et al., 2017
“Here, we test the hypotheses that elevated pCO2 will differently impact the relative concentrations of divalent cations (Ca2+, Mg2+, Sr2+, and Mn2+) in four closely related species of porcelain crabs … Overall, the effect of reduced pH/elevated pCO2 on exoskeleton mineral composition was muted in mid-intertidal species relative to low-intertidal species, indicating that extant adaptation to the variable intertidal zone may lessen the impact of ocean acidification (OA) on maintenance of mineralized structures.”
Kienzle et al., 2017
“Rising temperatures increased recruitment of brown tiger prawn (Penaeus esculentus) in Moreton Bay (Australia)”
Long et al., 2017
“In this study, we determine the effects of decreased pH on the morphology, growth, and survival of juvenile blue king crab, Paralithodes platypus. Crabs were reared at three pH levels: ambient (control, pH ∼8.1), pH 7.8, and pH 7.5, for 1 year and monitored for morphological changes, survival, and growth. Exposure to seawater at pH 7.8 had no effect on morphology or mortality and had only a minor effect on growth compared with the ambient treatment.”
Comeau et al., 2017
“Here, we tested the response of net photosynthesis, gross photosynthesis, dark respiration, and light-enhanced dark respiration (LEDR) of eight coral taxa and seven calcified alga taxa to six different pCO2 levels (from 280 to 2000 µatm). Organisms were maintained during 7–10 days incubations in identical conditions of light, temperature, and pCO2 to facilitate comparisons among species. Net photosynthesis was not affected by pCO2 in seven of eight corals or any of the algae; gross photosynthesis did not respond to pCO2 in six coral taxa and six algal taxa; dark respiration also was unaffected by pCO2 in six coral and six algae; and LEDR did not respond to pCO2 in any of the tested species. Overall, our results show that pCO2 levels up to 2000 µatm likely will not fertilize photosynthesis or modify respiration rates of most of the main calcifiers on the back reef of Moorea, French Polynesia.”
Bailey et al., 2017
“Early life stages of the Arctic copepod Calanus glacialis are unaffected by increased seawater pCO2 … In this study, we investigated the effect of increased pCO2 on the early developmental stages of the key Arctic copepod Calanus glacialis. Eggs from wild-caught C. glacialis females from Svalbard, Norway (80°N), were cultured for 2 months to copepodite stage C1 in 2°C seawater under four pCO2 treatments (320, 530, 800, and 1700 μatm). … All endpoints were unaffected by pCO2 levels projected for the year 2300. These results indicate that naupliar development in wild populations of C. glacialis is unlikely to be detrimentally affected in a future high CO2 ocean.”
Schaum et al., 2017
“Here, we use a decade-long experiment in outdoor mesocosms to investigate mechanisms of adaptation to warming (+4 °C above ambient temperature) in the green alga Chlamydomonas reinhardtii, in naturally assembled communities. Isolates from warmed mesocosms had higher optimal growth temperatures than their counterparts from ambient treatments. Consequently, warm-adapted isolates were stronger competitors at elevated temperature and experienced a decline in competitive fitness in ambient conditions, indicating adaptation to local thermal regimes. Higher competitive fitness in the warmed isolates was linked to greater photosynthetic capacity and reduced susceptibility to photoinhibition. These findings suggest that adaptive responses to warming in phytoplankton could help to mitigate projected declines in aquatic net primary production by increasing rates of cellular net photosynthesis.”
Polar Bear Populations Not Declining, Sea Ice Loss Is Not Connected To Survival
Crockford, 2017
“Data collected between 2007 and 2015 reveal that polar bear numbers have not declined as predicted and no subpopulation has been extirpated. Several subpopulations expected to be at high risk of decline have remained stable and at least one showed a marked increase in population size over the entire period. Another at-risk subpopulation was not counted but showed marked improvement in reproductive parameters and body condition with less summer ice. As a consequence, the hypothesis that repeated summer sea ice levels of below 5 mkm2 will cause significant population declines in polar bears is rejected. This result indicates that the ESA and IUCN judgments to list polar bears as threatened based on future risks of habitat loss were hasty generalizations that were scientifically unfounded, which suggests that similar predictions for Arctic seals and walrus may be likewise flawed, while the lack of a demonstrable ‘sea ice decline = population decline’ relationship for polar bears invalidates updated survival model outputs that predict catastrophic population declines should the Arctic become ice-free in summer.”
York et al., 2016 
“Subpopulation growth rates and the probability of decline at current harvest levels were determined for 13 subpopulations of polar bears (Ursus maritimus) that are within or shared with Canada based on mark–recapture estimates of population numbers and vital rates, and harvest statistics using population viability analyses (PVA). … Considering both TEK [traditional ecological knowledge] and scientific information, we suggest that the current status of Canadian polar bear subpopulations in 2013 was 12 stable/increasing and one declining (Kane Basin). We do not find support for the perspective that polar bears within or shared with Canada are currently in any sort of climate crisis.”
 
Share this...FacebookTwitter "
"Domestic dogs and cats might be a phenomenal evolutionary success story but we still know remarkably little about how, why and when these animals first became part of our human world. Archaeologists have been on the trail of these human-animal relationships for decades, searching for clues in the bones excavated from sites around the world.  Geneticists are now helping to address these questions, and adding to a picture that is both changing rapidly and becoming more confusing. The dog has a very special (and unique) history with humans. Remains from Israel, Germany and central Russia clearly document that they were already part of our lives as early as 15,000 years ago. This makes the dog the only domestic animal to have existed before the agricultural revolution – one of the most fundamental shifts in our own evolutionary history. We know the Eurasian grey wolf (Canis lupus) is the ancestor of all modern dogs. Early genetic studies (using “molecular clock” calculations now refuted) controversially pushed its domestication history back to more than 100,000 years ago, while more recent morphological studies have claimed that dog domestication began around 32,000 years ago – during the last Ice Age.  Where this first occurred remains equally problematic, with both the archaeological and genetic evidence indicating single or multiple places in Europe, the Near East,  Russia or China. The latest study, by researchers at Cornell, suggests the original dogs could be found in Central Asia. Zooarchaeologists and geneticists (including myself) from across the world are currently working together to test these many claims and counter-claims. We used to think that dogs were the result of direct human intervention, with wolf cubs being caught, tamed and eventually bred. However, the now generally accepted view is that wolves essentially “self-domesticated”. This involved a more long-term relationship, driven initially not by direct human intervention but by the local ecological conditions they created. In this scenario, human leftovers drew certain wolves closer to campsites and perhaps led some individuals or even small packs to follow human hunters in search of easy pickings. The presence of wolves so close to human settlements perhaps also had the effect of preventing other dangerous carnivores from straying too close – creating a loose but mutually-beneficial partnership. Over time, these wolves became more and more accustomed to humans until eventually new selection pressures changed them from wolves to dogs. Biologists would call such a relationship “commensal” – that is, where one organism benefits from another without causing any harmful side-effects. Archaeologists have since borrowed the term to describe the path to domestication in wolves, cats and even some other farmyard animals like the pig.  However, the reality of what some term “proto-domestication” is often more complex. The transition from wolf to dog, or boar to pig, involves the acquisition of a new and important capability to exploit or totally rely on the human environment.  Broad commensal relationships between humans and carnivores certainly do exist – some wolves enjoy scavenging rubbish, for instance. Likewise, carnivores such as cats may well have been highly dependent on predating other commensal (pest) species, such as mice and rats, which may have been infesting human grain stores. But commensal animals rarely have a neutral effect on humans, since they consume crops, steal food and provide a reservoir for disease. Because humans have such a big impact on local ecosystems, and there are so many different ways other organisms living in and exploiting new human-made environments can interact with us (and vice versa), perhaps we need to change how we think about this.  We need a way of talking about the early phases of animal domestication that fully integrates both the biological and cultural factors involved. You won’t find messy Palaeolithic eating habits listed as a textbook “evolutionary pressure”, but without them it’s possible we wouldn’t have dogs today. Assessing key human-animal relationships during the early phases of proto-domestication is an immense challenge, but one that will be important in establishing if those relationships were simply opportunistic, or involved a true commensal pathway whereby species became dependent on humans before being domesticated. Living as I do with my own dogs and cats, I know that I can at least be sure of two things: dogs are ecstatically happy that they managed to domesticate themselves, while cats are utterly indifferent about their remarkable skills at domesticating humans."
"
Share this...FacebookTwitterModern Polar Bear Habitat Among
Coldest  Of The Last 10,000 Years


Image Source: slideshare.net

The habitat range for polar bears extends across the circumpolar boundaries of the Arctic Ocean, primarily inclusive of North America (Canada), coastal Greenland, and northern Russia (Siberia, Northern Europe).  However, about 70 percent —  13 of 19 subpopulations — of the Earth’s polar bears reside in Canada.  And Canada not only has not been warming to any unusual degree in the last few centuries, modern temperatures are still colder now than they have been for most of the last 10,000 years.

A Benighted Short-Term Climate Perspective
The media-popularized viewpoint that insists polar bears are sweltering under an imminent threat of extinction due to global warming in general and Arctic warming in particular is benighted by a lack of appreciation or understanding of a long-term geological context.
For most advocates of the position that climate changes in the Arctic are predominantly caused by the explosive rise in anthropogenic carbon dioxide emissions since the mid-20th century, there is a conspicuous hyper-focus on the climate monitoring period beginning in the 1950s…or the late 1970s, when the satellite era began (and polar sea ice could be monitored).  The problem with this short-term perspective, of course, is that the 1950s to 1980s were a cold period in the Arctic, so any trend line beginning in those years will skew towards the point of view that more recent warming is unusual, if not unprecedented.  As the graphs below illustrate, the 1920s to 1940s were a relatively warm period in the Arctic — similarly as warm as the most recent decades.  The willful selection of the coldest decades of the last 100 years as the prerequisite starting point for examining modern climatic trends is reflective of the tendentious narrow-mindedness afflicting most advocates of the position that we humans pose a dangerous threat to the biosphere.  Expanding one’s perspective and focus beyond the last 60 or 70 years, or even a cursory look at the long-term climatic context as presented in the scientific literature, severely undercuts the perspective that recent climate changes in the Arctic are unusual, remarkable, or unprecedented.

Yamanouchi, 2011 (Arctic)



  Graph adapted from Climate4you, HadCRUT4 data

Using A Long-Term Context, Canada Has Not Been Warming

A few million years ago, the Canadian Arctic’s mean annual temperatures were about 18°C warmer than they are now.  During the summers many regions of the Arctic Ocean were sea-ice-free.  And yet polar bears survived these balmy, sea-ice-free climates anyway.

Cronin and Cronin, 2015
“Pliocene Arctic Ocean summer SSTs were appreciably warmer than modern and seasonally sea-ice free conditions existed in some regions. … At Lake El’gygytgyn (Lake ‘‘E’’) in Siberia summer temperatures were 8°C warmer than modern and at Ellesmere Island, Canada, summer and MAT [mean annual temperatures] were 11.8°C and 18.3°C higher than today.”
“[A] seasonally ice-free marginal and central Arctic Ocean was common … regionally during the early Holocene [6,000 to 10,000 years ago]. … Some species thought to be dependent on summer sea ice (e.g., polar bears) survived through these periods.” 

Although not as warm as a few million years ago, the polar bears’ Canadian habitat was nonetheless multiple degrees Celsius warmer than now as recently as a few thousand years ago.  Not only that, but the “reconstructed temperatures [for the Canadian Arctic] do not indicate a warming” during the last 150 years.  In other words, the (1) modern day Arctic temperature trends, the (2) sea ice loss trend observed via satellites since the late 1970s, and the (3) modern seal-hunting practices of the “endangered” 21st century polar bear…are all well within the range of what has occurred naturally, or without human interference, for the last several thousand years.  Polar bears have survived much warmer temperatures than this in the past, and the likelihood they will continue to survive in today’s relatively cold Arctic climate is high too.
Below are samples of available climate reconstructions for Canada and other locations (Siberia, Greenland, Northern Europe) where polar bears live.  Each demonstrate that there is nothing unusual about the modern day Arctic climate…other than it may be colder than most of the last 10,000 years.  And each demonstrate that the hand-wringing about polar bear species extinction potentialities due to today’s non-global warming is, to put it bluntly, much ado about nothing.

Fortin and Gajewski, 2016 (Canadian Arctic)
“Biological production decreased again at ~ 2 ka and the rate of cooling increased in the past 2 ka [2,000 years], with coolest temperatures occurring between 0.46 and 0.36 ka [460 and 360 years ago], coinciding with the Little Ice Age. Although biological production increased in the last 150 yr, the reconstructed temperatures do not indicate a warming during this time. … Modern inferred temperatures based on both pollen and chironomids are up to 3°C cooler than those inferred for the mid-Holocene.”


Moore et al., 2001 (Canadian Arctic)
“Summer temperatures at Donard Lake [Canadian Arctic] over the past 1250 yrs averaged 2.9 °C.  At the beginning of the 13th century, Donard Lake experienced one of the largest climatic transitions in over a millennium. Average summer temperatures rose rapidly by nearly 2 °C from 1195–1220 AD [+0.80 °C per decade], ending in the warmest decade in the record (~4.3 °C).“
[The 19th century average was higher than the 20th century average, and the 20th century average was lower than the average of the last 1,250 years.]


Cook et al., 2009  (Canadian Arctic)


Renssen et al., 2009 (Canada, Eastern)




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Viau and Gajewski, 2009 (Canada, Central)


Naulier et al., 2015  (Canada)

 

Polar Bears’ Siberian Habitat Is Colder Now Than Most Of The Last 10,000 Years

Hantemirov and Shiyatov, 2002 (Siberia, Northwestern)


Tarasov et al., 2009 (Siberia, Southern)


Polar Bears’ Greenland Habitat No Warmer Now Than In The 1920s, 1930s

Zhao et al., 2016   (Greenland Ice Sheet)


Hasholt et al., 2016 (Southeast Greenland)
“We determined that temperatures for the ablation measurement periods in late July to early September were similar in both 1933 and the recent period [1990s – present], indicating that the temperature forcing of ablation within the early warm period and the present are similar.”


Greenland Is Colder Now Than Most Of The Last 10,000 Years

Lecavalier et al., 2013 (North Greenland)


Thomas et al., 2016 (Greenland, West)
“Paired climate and ice sheet records from previous warm periods can elucidate the factors influencing GrIS mass balance on time scales longer than the observational record [Briner et al., 2016]. During the middle Holocene, temperature on Greenland was ~ 2°C higher than present [Cuffey and Clow, 1997; Axford et al., 2013].”


Aizen et al., 2016 (Asia, Greenland Ice Sheet)
“[P]eriods warmer than modern periods occurred for ∼6.5 ka [6,500 years] including during the HCO [Holocene Climate Optimum] and Medieval Warm Period.”


Northern Europe Is Colder Now Than Most Of The Last 10,000 Years

Esper et al., 2014 (Northern Europe)

Share this...FacebookTwitter "
"
Share this...FacebookTwitter
What follows is another example climate-scare prediction turned folly.
The NOAA’s and the University of Nebraska (Lincoln) National Drought Mitigation Center’s (NDMC) US drought monitor map that follows now shows extraordinarily little drought conditions across the USA, despite earlier predictions of permanent drought and misery over vast regions.


Meteorologist Paul Dorian of vencoreweather.com here in fact writes that moisture conditions across the US are now “about as good as it gets“.
He reports that “severe”, “extreme” or “exceptional” drought conditions are limited to a puny 1.6% of the continental US. Going back to the year 2000, only February and March of 2010 had similar limited drought conditions on a nationwide basis that we are enjoying today.
In fact the news may actually get better with the next drought monitor update as the numbers cited in today’s posting reflect only precipitation data registered through last Tuesday, April 4th and does not include the substantial rainfall that fell late last week in California and across the southern and eastern US.




&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img src=”https://static1.squarespace.com/static/56530521e4b0c307d59bbe97/t/58eb89ac29687f93406289b7/1491831225102/”  alt=”Western US drought conditions from one year ago (left) to current (right); courtesy NOAA/CPC”  /&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;


Western US drought conditions from one year ago (left) to current (right); courtesy NOAA/CPC








Discussion on current and recent conditions
In recent years, much of the western US was suffering through widespread and deep drought conditions, but that has changed dramatically in recent months; especially, in the state of California. One year ago, much of California was in the midst of an “exceptional” drought – the worst category of drought as classified by NOAA – but all of that has changed dramatically this winter season with a tremendous amount of rainfall throughout the state.
Today nowhere is California classified by NOAA/NDMC as experiencing “exceptional” (D4) or “extreme” (D3) drought conditions and less than one percent of California is currently experiencing “severe” (D2) drought.






&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img src=”https://static1.squarespace.com/static/56530521e4b0c307d59bbe97/t/58eb89e5197aea9c4041392a/1491831271942/”  alt=”Sierra Nevada Mountains provide more than 60% of California’s developed water supply”  /&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;


Massive Sierra Nevada snowpack
Figure right: Sierra Nevada Mountains provide more than 60% of California’s developed water supply








In addition to the recent rainfall in California, there has been an extreme amount of snow this winter season in the higher elevations of the Sierra Mountains across eastern California.  Snowpack in the Sierra Nevada region plays a critical role in California’s water supply as a natural form of water storage. More than 60% of California’s water originates in the Sierra Nevada region.
There has actually been so much snow this winter in some of the higher elevation locations that the National Guard has been called out to help with the removal of the snow. Another 3 or 4 feet of fresh snow piled up in the Sierra Nevada Mountains on Friday of last week in the latest major storm to affect California with significant rain and snow.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Now “as good as it gets.”
Also much of the south-central and eastern US experienced dry weather during the fall and winter seasons and this led to the declaration by NOAA/NDMC of “abnormally dry” (D0) or “moderate” (D1) drought conditions in many areas. But like California, recent significant rainfall events during a very active weather pattern have improved overall conditions in many regions across the south-central and eastern US.






&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img src=”https://static1.squarespace.com/static/56530521e4b0c307d59bbe97/t/58eb8a4e17bffc10a3b36417/1491831390837/”  alt=”The Palmer drought index, sometimes called the Palmer drought severity index and often abbreviated PDSI, is a measurement of dryness based on recent precipitation and temperature. The Palmer Drought Index is based on a supply-and-demand model of soil moisture. Drought conditions were extremely widespread and severe in July 1934 during the midst of the “Dust Bowl” era.&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;nbsp;”  /&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;


The Palmer drought index shows that drought conditions were extremely widespread and severe in July 1934 during the midst of the “Dust Bowl” era, far worse than what was experienced over the past years. Chart: NOAA








The worst heat and drought conditions by far occurred in 1930s
Meteorologist Dorian explains that any drought talk of recent years really pales in comparison to what happened in this country during the decade of the 1930’s. In the “The Grapes of Wrath”, John Steinbeck vividly captured the plight of millions of Americans whose lives had been crushed by what is referred to as the “Dust Bowl” era – a time when “climate gas” CO2 levels were far lower.
The 1930’s still ranks as the hottest and driest in US recorded history and the “Dust Bowl” was truly a significant event in our national history.






&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img src=”https://static1.squarespace.com/static/56530521e4b0c307d59bbe97/t/58eb8a8417bffc10a3b3765e/1491831938455/”  alt=”The figure on the left shows the annual values of the U.S. Heat Wave Index from 1895 to 2015 for the contiguous 48 states. An index value of 0.2, for example, could mean that 20 percent of the country experienced one heat wave, 10 percent of the country experienced two heat waves, or some other combination of frequency and area resulted in this value. &amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;nbsp;Data source: Kunkel, 2016 (EPA). &amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;nbsp;The figure on the right shows the number of all-time maximum temperature records at USHCN weather stations that reached extreme heights in 1936 – far and away above any other year.”  /&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;


The figure on the left shows the annual values of the U.S. Heat Wave Index from 1895 to 2015 for the contiguous 48 states. An index value of 0.2, for example, could mean that 20 percent of the country experienced one heat wave, 10 percent of the country experienced two heat waves, or some other combination of frequency and area resulted in this value. Data source: Kunkel, 2016 (EPA).
The above figure on the right shows the number of all-time maximum temperature records at USHCN weather stations that reached extreme heights in 1936 – far and away above any other year.
Tens of thousands of “climate refugees”








Conditions were so dry in such a widespread part of the country that dust storms formed numerous times in the Central Plains as loose soil turned to dust which the prevailing winds blew away in huge clouds that blackened the skies – even as far away as the east coast. The drought came in three waves during this decade, 1934, 1936 and 1939-1940, and tens of thousands of families had to abandon their farms.
Dorian summarizes today’s conditions:
Yes, these are pretty fortunate times we are currently living through across the US.”
See Vencore meteorologist Paul Dorian’s full report here.
 


Share this...FacebookTwitter "
"It is too simplistic to say that cutting livestock numbers everywhere is the most efficient way of reducing emissions, as your article suggests (Governments urged to set deadlines for cutting livestock production, 12 December). The world’s livestock systems differ too significantly for them to be generalised, and doing so hinders the countries that are practising sustainable farming methods and which have an ambition to do even more. Compared with the mass-scale intensive systems in the US or Brazil, our livestock systems are unrecognisable. British farmers do not clear rainforest to make way for beef production. Our meat does not come from the ashes of the Amazon. We value our carbon sinks.  Grazing cattle is the most sustainable way to use the 65% of UK farmland that is unsuitable for growing any other crop. It is hugely beneficial for the soil, helps lock up carbon, and is the best way to turn inedible grass into highly nutritious protein for a growing population to enjoy. What’s more, British farmers have an ambition to become net zero by 2040. We want to lead the way in climate-friendly meat and dairy and pave the way for others to follow. This needs to be recognised.Stuart RobertsVice-president, NFU  • Damian Carrington is correct that people in wealthy countries need to eat less meat. But to make targets for reductions in meat consumption is to put the cart before the horse. Excessive meat production is a symptom, not a cause, of the problem. Once we start to eliminate the use of fossil fuels, economic forces will reduce livestock numbers to sustainable levels because there will be increased demand for land for biomass, and because artificial fertilisers will almost certainly be in short supply. Until that happens there is a danger that focusing on meat and livestock will be a futile distraction from the task at hand which is to put an end to the use of fossil fuels. Simon FairlieThe Land magazine • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"Boris Johnson has been urged to follow in the footsteps of Margaret Thatcher by taking to the world stage to lead international action on the climate emergency – but to put the UK’s own emissions-cutting efforts back on track first. The prime minister was told on Wednesday that the UK had so far “fallen short” on its commitments to tackle greenhouse gases, in a letter from the committee on climate change (CCC).  To succeed, Johnson must bring forward new policies across the board as a matter of urgency, “demanding ambitious policy from all departments to ensure homes, businesses, industry, transport and land are helping to deliver net zero”, according to a letter to Downing Street from the government’s statutory advisers on how to achieve the UK’s long-term goal of reaching net-zero carbon by 2050. The UK is to host crunch UN talks on the climate emergency in Glasgow next November, at which nations will be asked to update their commitments on emissions under the Paris agreement. Lord Deben, the chair of the committee and a former Conservative environment minister under Thatcher, wrote: “We marked recently the 30th anniversary of Margaret Thatcher’s 1989 speech to the UN general assembly. That speech described accurately the science of human-induced climate change and the scale of its economic impact. The prime minister advocated a strong global response then; but what followed was too little. You have the opportunity to lead a better international effort. But first, we must get our own house in order.” Renewed economic policies and new regulations will both be vital, the committee said. There should also be more work on helping the UK adapt to the likely impacts of global heating, including more resources for flood prevention and planning for long droughts, such as the UK drought that caused widespread problems two years ago. Buildings, transport, electricity, industry and agriculture must be the five key areas of focus, the CCC said, and action on all fronts must begin urgently. “It has been nearly seven months since the net-zero target became law. Every day of inaction makes the challenge of cutting emissions harder and costlier. Technological innovation is only part of the answer. We must not wait for future technologies to solve the problems we can already tackle with known solutions,” the committee said. Campaigners urged Johnson to make following the committee’s advice a priority. “Aside from being crucial to life and wellbeing, action on climate change makes economic sense. It brings significant benefits for public health, UK jobs, and industries,” said Mike Childs, the head of science at Friends of the Earth. “The prime minister was alarmingly quiet on the climate crisis during his election campaign – failing to attend the televised debate on climate, and giving little attention to the issue in his party manifesto. “We can’t afford any more lost time where science is ignored and ministers dawdle over climate action. It’s time that the government listens to its own advisers and stops the climate crisis worsening.” A government spokesperson said: “In the manifesto, which delivered a majority for the prime minister, he clearly set out his vision to ensure Britain has the most ambitious environmental programme of any country on Earth. This government will deliver on our science-led target of net zero by 2050. “From increasing tree planting rates to bringing forward the phase out date for petrol and diesel cars, we will provide the policies needed to ensure we are on track to hit our world-leading climate targets and demonstrate our global leadership in advance of the crucial COP26 talks in Glasgow next year.”"
nan
nan
"
Share this...FacebookTwitterThe Arctic and the Northern Hemisphere surprise experts with impressive snow and ice gains, decade-long stability.
Reader David at Facebook brought my attention to the fact that Greenland this year has in fact been increasing in ice mass.
The National Snow and Ice Data Center (NSIDC) was forced to admit:
Overall, however, reduced melting and heavy early springtime snowfall may result in a net increase in Greenland’s ice mass this year for the first time this century.
The 2017 melt season has been less intense than recent years, and is below average melting for the 1981-to-2010 reference period. Surface melting has been low in the southeast, and has been limited to coastal regions at low elevations. “
What follows is the chart provided by the NSIDC:

Greenland’s ice melt this season has been well below normal, the NSIDC reports, and may end up seeing a net increase this year for the first time this century. Chart: NSIDC.
Above average snow extent
Meanwhile the University of Rutgers reports that Northern Hemisphere snow extent in August, 2017, was above normal at 2.915 million square kilometers, some 118,000 square kilometers above the mean.
Surprising Arctic sea ice stability


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Arctic sea ice, unquestionably in decline since satellite measurements began in 1979 – which was a peak period for sea ice cover – has shown surprising stability over the past 10 years despite all the claims “the Arctic is melting rapidly“.
 

Arctic sea ice extent stable since 2007. Source NSIDC.
The plot of Arctic sea ice shows that extent did not even come close to setting a new record, which many alarmist experts had predicted earlier this year. Indeed the following chart shows Arctic sea ice has already begun to increase – some 7 – 10 days earlier than normal:
 

Chart courtesy of Ice Age Now.
Just as we discussed the situation on Greenland above, the sea ice surrounding the Danish island has been extraordinarily high this year, thus extending a stable ice extent plateau of the past 17 years.
It’s no surprise that the ever more desperate climate alarmists have decided to chase hurricanes this year. The Arctic is not cooperating with the warming, “death spiral” scenarios any longer.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterOne of the founders of Germany’s modern environmental movement and a former renewable energies executive has publicly announced that President Donald Trump’s rejection of the Paris Accord is the right thing to do.

 Prof. Fritz Vahrenholt, a founder of Germany’s modern environmental movement, supports rejection of Paris Accord. Photo credit: Die kalte Sonne.
USA starts the CLEXIT
At his climate science critical website, Die kalte Sonne, Prof. Fritz Vahrenholt says the USA has de facto “begun the exit out of the Paris Climate Accord“, or CLEXIT, and that among world leaders at least Donald Trump comprehends that natural factors are at play in climate.
Moreover, Vahrenholt notes that upon really reading the Paris Accord for the first time, it is only now that the media have become surprised that it is not even a binding agreement, but instead one that only involves intentions by the rich countries to transfer cash to developing nations to the tune of $100 billion annually beginning in 2020.
He wonders why “neither Obama nor Merkel, Juncker or Macron have found it necessary so far to explain to their citizens the agreement burdens their own citizens to the benefit of no. 1 emitters China, and India“.

Vahrenholt calculated the 2030 per capita emissions China would be allowed by the Paris Accord:
In 2030 Europeans would have to lower their emissions to 4 tonnes per capita, while China’s would be allowed to rise to 14 onnes per capita and the USA would have to fall to 10 tonnes per capita. One has to ask, who signed, cheered and celebrated such an agreement and welcome it with tears of joy?”
Vahrenholt describes an agreement that is totally in favor of China, a country that plans to construct 368 coal power plants by 2020 while India plans to build 370. In his view the Paris Accord is a free ride for China.
Overall the Paris Accord will hardly have any effect on total emissions.
We can be happy that the American President Trump has seen this anachronism, and what on earth moved his predecessor to such a disadvantageous agreement?”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In Vahrenholt’s view the agreement is neither about the climate nor the environment, and that its real intention was made clear by Prof. Ottmar Edenhofer of the Potsdam Institute in 2010:
Through climate policy we will de facto redistribute global wealth… One has to free himself of the illusion that international climate policy is environmental policy.”
Also the German professor of chemistry writes that European leaders cannot expect Trump to simply defraud his voters by not keeping his campaign promises, as controversial as some may be.
Vahrenholt, a member of the SPD socialist party, says Trump’s decision is nothing to criticize, and those who do criticize “either do not understand the mechanism of Paris, or have an interest in deindustrializing Germany and the bad USA.”
Vahrenholt also questions Germany’s Ministry of Environment (UBA) proposals to tax privately driven kilometers so that German citizens will finally stop driving and ride their bicycles more often, remarking: “There was once such a society: China 25 years ago.”
Overall Vahrenholt sees the Paris Accord as “practically dead” because “Trump’s most important announcement is a stop of all finances to the green climate fund, which was to be supplied with $100 billion beginning in 2020.” The USA’s share is 22%.
Vahrenholt also blasts the IPCC climate conference circuses of Cancun, Bali, Durban, etc..
The USA gave $55 million annually for this travelling climate circus to go to the most exotic locations of the world so that the Schellnhubers and Edenhofers of the globe could act like they were doing important things on the taxpayers’ dime.”
He cites Prof. Judith Curry. She wrote earlier this year (2017) that the IPCC climate models are not suitable to explain the causes of the 20th century warming or to forecast regional and global climate changes over decades, let alone a hundred years, and that they are not adequate for acting as a base for policymaking. Curry adds:
There’s growing evidence that the climate models are running too warm.”
Prof. Vahrenholt concludes his piece by advising EPA chief Scott Pruit to heed Curry’s recommendations.

Share this...FacebookTwitter "
"What characteristics would your ideal home have? A sauna? Lots of natural light? An open-plan kitchen?  Whatever your answer, you probably didn’t consider how the things you wanted would affect the energy you use. The link between comfort and energy is not something that troubles most people, but actually it’s very important. In the UK, our houses consume up to 27% of the energy we produce.  Governments encourage us to save energy through things such as turning off the lights and taking shorter showers; better insulation and boiler upgrades; and installing renewable energy sources like solar panels in the home. But none of this pays attention to the comforts we expect, and how they have changed over time. To give one example, indoor temperatures in the UK rose from 12°C to 17.5°C between 1970 and 2010. Despite all our efforts to bring it down, the amount of energy we use at home is not much different to 40 years ago. As the world digests the outcome of the Paris climate talks, it’s time our desire to be more comfortable came under the spotlight.  Until the 18th century, comfort was far less about physical pleasure than spiritual satisfaction, well-being and consolation. Seating was designed to aid sitting respectfully with a refined posture. The equivalent of today’s La-Z-boy chair was created on medical grounds for invalids, pregnant women, and men with gout (see image below) – what we think of as comfortable was not even intended for normal able-bodied people.   The shift in our expectations happened for a couple of reasons. There was a consumer revolution between 1700 and 1850, which saw people filling their homes with objects – clothes, accessories, furnishings and so on. And humanitarian reformers began to see comfort as one of our basic human needs, and gave it more of a physical emphasis. Basic standards of comfort came to be seen as a benchmark for social equality – elevating an adequately heated home to a human right, for example.   The trouble is that once one basic need is met for everyone, there is always scope for improvement. Turn comfort into a commodity and it becomes part and parcel of a high-consumption society. With the best of intentions, this is what has happened to us.  In Glasgow in 1850, for instance, each person used an average of 3.73 litres of water per day for drinking, bathing and so forth. Today’s average is roughly 150 litres. This reflects how social conventions have evolved alongside technical innovations, such as the development of the bathroom and new hygiene standards.  In the UK, the years between 1890 and 1920 marked a dramatic transformation in our expectations of home comfort with the arrival of central heating, indoor plumbing, running hot and cold water, electric light and power. Connecting homes to these networks of water, sewage, gas and electricity unsurprisingly transformed domestic life and the layout of homes. Alongside these changes, our energy requirements skyrocketed.  The past few decades have seen further crucial changes. The pie charts below give a flavour of them. You can see a big rise in appliances, reflecting all the mobiles, tablets, consoles and so forth in modern homes. Energy for home computing more than doubled between 2000 and 2014, for instance.   Energy use in UK homes, 1970-2011  We also use more hot water, having shifted from weekly bathing to daily showering, and more light bulbs. But the energy shares of water and lighting are down thanks to more energy-efficient technology. Cooking is down too, but don’t be fooled here. We are eating more takeaways and ready meals, so the energy for preparing them has just been outsourced. On the other hand, we now actually use more energy to heat space. This is despite the fact that central heating has become very common since the 1970s. It is a more efficient way of making a room warm, but we heat more rooms and to higher temperatures.  Where householders were once brought together by the warmth of the fireplace in the living room, it became possible for them to do individual activities in individual rooms. Hence individual privacy became a fundamental expectation of home comfort, meaning that more rooms needed to be warm enough to spend time in. One consequence has been that the amount of living space per person in the UK has been rising. And house and household size are some of the biggest determinants of energy demand. The change in our view of what constitutes a normal indoor temperature in the past 20 years is down to the spread of air conditioning, central heating and thermal regulations. Which is an example of why we need to be aware that changes in technology and improvements in efficiency don’t always reduce consumption in the ways we might expect. Indeed, many researchers have been led to suggest that the 5.5°C rise in 40 years is grounds for switching our focus to indoor climate change.  In short, governments and academics need to pay much more attention to what people want from their homes. They need to think about how these expectations of “normal” home comforts have been changing, and the influence of improvements in efficiency and low-carbon technologies. What we see from the Paris climate talks is that governments are focusing on technical fixes to our carbon problem, rather than challenging the richest 10% of the population to question the sustainability of their desire for more and more comfort. Since they are responsible for half the world’s carbon emissions, we won’t succeed until that finally changes."
"
Share this...FacebookTwitterRenowned Princeton physicist William Happer told New York Times science journalist Andrew Revkin in an online video conference that he believes the world has got it all wrong when it comes to the implications of CO2 emissions into our atmosphere.

 
Happer told Revkin that “any dispassionate weighing of the facts would give you a negative cost of carbon” and that “more CO2 is good for the world“.
Moreover Happer believes that the whole climate issue has “distracted people from real problems” like massive pollution in places like China and India.
Happer adds that he thinks “enormous damage has been done to the environment by diverting money from real problems to completely made up problems.”
He tells the New York Times journalist that he absolutely sees CO2 as a “non-problem” and that he even sees the trace gas “as good“. He reiterates: “Let me be clear: It think it’s not a problem. I think it’s a good thing.”
 
Share this...FacebookTwitter "
"It’s all change at the most important climate science body in the world, the Intergovernmental Panel on Climate Change (IPCC). Hoesung Lee of South Korea was named the new chair – and it’s fair to say he is much less well-known than his European and American rivals. Raising his profile will be one challenge, but much more important will be improving the way the IPCC communicates with its many audiences. Lee has promised to do exactly that, but so far he has been short on specifics and new ideas. He will have to get up to speed quickly as the crucial Paris summit is almost upon us. In the run-up to the last (potentially) breakthrough UN summit in Copenhagen in 2009, the IPCC was very slow to rebut the challenges to mainstream science launched by sceptics. As the president of the Copenhagen meeting, Connie Hedegaard, was quoted as saying: “Millions were put into international campaigns, yet when Climategate emerged the IPCC had almost no one employed to take care of communications.  They did not even have a communications team.” The IPCC has come a long way since its inept handling of the Climategate and Himalayagate controversies.  For a start, it now has professional communications staff, but it has an equally long way to travel. Academics and others have identified some of the obstacles to more effective IPCC communication – a lack of resources, over-reliance on technical language, and failure to take advantage of new media have all been identified. To his credit, Lee did mention in his first press conference as chair one area of communication he wants to develop: he will increase the amount of outreach work directed at a wider audience around the world. This is one of the recommendations coming out of a recent survey of users of the IPCC’s blockbuster volumes known as the assessment reports, which the IPCC publishes every five or six years. In this survey (to be published soon as part of a research project analysing how the IPCC reports inform policy making) my colleagues and I interviewed 30 representatives of the groups identified by an independent review of the IPCC as their target audiences – policy makers, the business sector, NGOs, higher education and the media. We wanted to know their views on the usefulness of the IPCC reports, their language and clarity, and recommendations for the future. One of the recommendations is that one highly effective way of communicating the science is when IPCC authors talk directly to local, regional or sector-specific users, particularly when they combine their own expertise and scientific rigour to communicate the findings clearly. But another clear message from the research is that although the IPCC reports sets the standard for high-quality science, overall they still suffer from low-quality communication. Part of the problem is that the often impenetrable or jargon-ridden language used by the scientists may be fine for other scientists in their peer group but not for policy makers and other non-expert groups. Many of the interviewees recommended bringing in specialist writers (who are familiar with the science) early in the writing process. Another issue is the appropriate level of resources for communication. The IPCC rightly parades the large numbers of scientists (running into the thousands) who write and review its reports. But it is not as widely known that the communications team consists of just one head, former Reuters journalist Jonathan Lynn, backed up by one or two colleagues. It may not be the best use of IPCC funds to substantially increase its permanent media staff as demands on them peak mostly at the time of publications. However, a strong case can be made for increasing selected funding in the following areas: outreach work, building an online and social media strategy, graphics development, learning good practice from other reports and developing better metrics for assessing how widely the IPCC reports are used. Lee wants more input from the finance and business sectors into the IPCC reports. He’s right, but how should he do it? Again, our survey recommends that policy makers and businesses should have more input into the early stages of scoping the reports to help ensure that policy concerns are flagged more clearly in the final reports. More so-called “derivative products” would also be very helpful. These are reports aimed at specific audiences that take parts of the IPCC reports and communicate them in formats that work for those audiences. Those produced by the Cambridge Institute for Sustainability Leadership are a good example. The challenge is to adapt the IPCC process to allow more deployment of IPCC authors to work with these types of reports, perhaps instead of devoting so much effort to the mammoth assessment reports. The IPCC could provide some accreditation and recognition to authors and universities for participating in this manner. A huge body of climate science is now agreed upon by the large majority of scientists. Of course, the most important knowledge gaps need to be identified and reduced – but just as much intellectual energy needs to be directed at the thorny challenge of how best to communicate the science, particularly in a digital world."
"Many bat species suffered severe population declines in the UK and elsewhere during the 20th century mainly due to their habitats being fragmented, damaged and destroyed, particularly in woodland areas. Though many species have stabilised or even increased slightly in the past couple of decades, numbers are still much lower than they were in the early 1900s.  The woodland destruction has made it harder for many bats to hunt and now they are also having to deal with other emerging threats such as wind turbines, artificial lighting and in North America, a disease known as white nose syndrome. One of the difficulties for many bats is that they don’t necessarily like to feed where they roost. This is because they need very different things from each environment. Bats can roost in small places such as a tree crevice or an attic in a house, the main requirement being that they provide a stable micro-climate with optimum humidity and little variation in temperature.  But they need much bigger spaces to get enough food to keep their fast metabolisms functioning – flight requires lots of energy. Good foraging areas don’t need that stable micro-climate, but do need to provide lots of invertebrate prey such as moths and midges, plus a conducive hunting environment – areas without much vegetation are little use to species like the brown-eared bat, for instance, since they glean their food from it.  You might think that being able to fly makes bats highly mobile animals that would find commuting to good hunting ground easy, but it’s not that simple. The mobility of bats very much depends on the shape of their wings. Species with long narrow wings such as noctules are usually well adapted to fly fast across open spaces, while others such as the common pipistrelle forage in moderately cluttered areas such as woodland edges. It can also commute long distances and catches its insect prey in the air.   Bats with shorter wider wings, such as the brown long-eared bat, are better suited to being highly manoeuvrable. This comes in very handy for getting hold of your dinner off vegetation in a cluttered woodland, but not so much when it comes to getting from habitat patch to hunting ground.  Roosting preferences also play a role in how species respond to environmental changes. While species like the brown long-eared bat are quite fussy about their requirements and only roost in or near trees, the likes of the common pipistrelle quite happily use human-made structures such as houses or bridges as their homes. More adaptable species are more comfortable with changes to their environment – most bats are not. The upshot is that some bat species find the prospect of commuting long distances more severe than others. Slow and highly manoeuvrable fliers like the brown-eared bat don’t travel long distances to their foraging sites and are often reluctant to fly across open spaces. So they are very sensitive to woodlands being destroyed and fragmented.  Even species like the highly mobile common pipistrelle suffer from insensitive human development. It is less affected by deforestation, but still influenced by both the quality of the woodlands in which it forages and what is in their surroundings too. Landscapes which include tree lines, rivers and grasslands make it easier for these bats to commute than intensively farmed areas with nothing more than crops. We humans are making efforts to restore woodlands, having recognised how much bats depend on them – not to mention many other species, including ourselves. One promising mechanism for reversing or at least slowing down the damage is woodland creation and management schemes. These typically involve governments providing financial incentives for farmers to increase the amount and quality of woodland on their land. They are most common in certain European countries and Australia – for example in the UK, they have helped increased woodland cover from a low of 5% in 1900 to 13% today.  Unfortunately newly planted woodland areas are often of limited value for biodiversity. They tend to benefit highly mobile species, but not the fussier woodland specialists, since they don’t have the sort of good-quality undergrowth that develops over time in wooded areas. This means for example that they are not very attractive to moths, which are the preferred food for many bat species, including the brown long-eared bat, compounding its restricted mobility.  How to get around this problem? We should be using our knowledge of bat ecology to inform these interventions. We need to include efforts to increase undergrowth, for example, and recognise that most bat species like big old trees. Even for more flexible species, we also need to increase habitat connectivity by creating wooded corridors between woodland areas.   The same thing applies on a smaller scale to the likes of beetles and voles, and even lichens and mosses. They depend on high-quality local habitat too, as well as connections between wooded areas. Get these actions right and we will be far more successful at helping bats and other species. Get them wrong and our efforts to protect biodiversity and maintain the populations of bats and other creatures will not make much difference."
"
Share this...FacebookTwitterThe Vice President of the Germany-based European Institute for Climate and Energy (EIKE) Michael Limburg wrote that the recent ice chunk breaking off the Antarctic ice shelf has everything to do with natural cyclic calving, and that the media reporting has been mostly alarmist hype. EIKE writes:
Antarctic ice shelf breaking is a totally normal process – the Antarctic has in fact gotten colder over the pst 30 years.
Germany’s number one tabloid, Bild, blared out the headline on July 13: “South Pole Breaking Apart!” and quoted alarmist climate scientist Mojib Latif: who warned it is a “warning shot to mankind”.

Bild Leipzig July 13, 2017, thanks to Dietmar Ufer

Climate scientist Mojib Latif called it a “warning shot for mankind”. Source: Bild
Mostly drama and hype
However, EIKE writes that such media reports are mainly drama and hype, and that natural mechanical forces and oceanic currents are behind the calving. EIKE cites facts from the Bremen Germany-based Alfred Wegener Institute.

Antarctic sea ice extent has in fact been growing over the past 4 decades, defying global warming. Source: Die kalte Sonne.
EIKE reminds that the recent ice mass breaking off will have no effect on sea level at all because the ice had already been floating on the ocean surface, and that even if the broken off mass had fully displaced the sea water, the magnitude of the resulting global sea level rise would not have been detectable.
Compared to the total Antarctic ice mass, the broken ice chunk with its 1 trillion-ton mass is only 1/26,000 of the entire ice mass at the South Pole.
Sea level rise not accelerating
Moreover, sea level over the past years has slowed down, and not accelerated, EIKE writes:

Slowing sea level rise from 1993 to 2012, Chart: K.E. Puls


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Sea level rise stable
Granted the EIKE chart used above is somewhat outdated, and sea level rise has not been slowing down. Paul Homewood here takes an objective look at sea level rise and writes that alarmists use “two tricks” to back up claims of accelerating sea level rise:
1) They splice the satellite record, which only started in 1993, onto the tidal gauge records.
According to satellites, sea levels have been rising at 3.4mm/yr. Whether this figure is right or not, no half competent scientist would dream of splicing two totally different sets of data together in such a way.
Worse still, their banner figure of 3.4mm includes what is known as glacial isostatic adjustment (GIA), which accounts for the fact that the ocean basins are getting slightly larger since the end of the last glacial cycle.
In other words, if the basins were not
1) They splice the satellite record, which only started in 1993, onto the tidal gauge records.
According to satellites, sea levels have been rising at 3.4mm/yr. Whether this figure is right or not, no half competent scientist would dream of splicing two totally different sets of data together in such a way.
Worse still, their banner figure of 3.4mm includes what is known as glacial isostatic adjustment (GIA), which accounts for the fact that the ocean basins are getting slightly larger since the end of the last glacial cycle.
In other words, if the basins were not getting larger, sea levels would rise more. To account for this, they add 0.3mm a year to their sea level figures.
This is all well and good, if it were not for the fact that tidal gauges do not include such an adjustment, so the comparison of satellites and gauges becomes incompatible.
2) They compare recent sea level rise with the 20thC average.
However, sea levels were not rising at an even pace during the last century. There were times when it was rising at rates similar to today, and others, notably between 1950 and 1980 when global temperatures were falling, which saw a lower rate of rise.
As the IPCC stated in its 2013 AR5 report:
It is very likely that the mean rate of global averaged sea level rise was 1.7 [1.5 to 1.9] mm/yr between 1901 and 2010 and 3.2 [2.8 to 3.6] mm/yr between 1993 and 2010. Tide gauge and satellite altimeter data are consistent regarding the higher rate during the latter period. It is likely that similarly high rates occurred between 1920 and 1950
http://ar5-syr.ipcc.ch/topic_observedchanges.php#node11
So, the current rate of rise is not unprecedented, and does not “prove” that the rise will continue to accelerate. Indeed, if the 20thC record is anything to go by, it could well slow down again, as part of a natural cycle.”
Moreover a recent analysis of tide gauges, where people actually live, sea level was shown to be stable or falling at half of the locations.
Share this...FacebookTwitter "
"Bond villains have always been interesting characters: sophisticated, intelligent and supremely well-equipped with futuristic and cutting-edge toys.  Aptly, the new official car of evil, a Jaguar C-X75 driven by henchman Mr Hinx in the latest Bond movie Spectre, is as advanced as it gets. A 850-horsepower hybrid with four electric engines and diesel-fuelled micro turbines, it can reach a top speed of more than 200mph. The prototype was too costly to go into full production but has been dusted off specially for the movie. It can cover the first 60km of any journey in purely electric mode, and only ever emits 89g of carbon dioxide per kilometre – comparable to the emissions of even the greenest petrol-powered family hatchback. On the other side of this is James Bond, who need only load up a conventionally-powered Aston Martin or Bentley with Q’s best clandestine technology in order to vanquish evil. And in Spectre, Bond’s back driving a silver Aston Martin with an unashamedly petrol V8 engine.  It is called the DB10 – and you won’t find it in any show rooms as it was designed specifically for the film. Why would this kind of car be all it takes for Bond when the bad guys are clearly choosing their wheels with higher ideals in mind? The underlying message of this is perhaps supposed to be that “British values will stand” – but are the makers of the film missing something important? The Jaguar C-X75, notwithstanding its sinister driver, is actually a “green car” – while Bond’s is anything but. Perhaps henchman Hinx is really a kind-hearted environmentalist who lovingly maintains extensive hydroponic hobby gardens and supports the cause of the African rhino when not murderously chasing protagonists down the streets of Rome? I haven’t seen the film yet, but I already like Mr Hinx a little more than Bond when I imagine this. Alas, I don’t think we are supposed to side with the henchman.  Instead, the fact that fast electric vehicles are being used by the ultimate baddies shows we are ready to take them seriously. As recently as 2008, when Quantum of Solace was filmed, the only electric sports car was the friendly-looking Tesla Roadster, which was quick, but not menacing enough to stir James Bond and his audience. The grunt of the C-X75 is taking electric capability and street cred to a whole new level. A slightly different question might be why off-the-shelf cars no longer seem to be good enough for the transport needs of good and evil now. Both Bond’s Aston Martin DB10 and Hinx’s Jaguar C-X75 are bespoke vehicles. As an old Bond veteran, this rubs me up slightly the wrong way, as these films historically always used to showcase the cutting edge at its most dramatic and advanced, but always seemed to say: “this technology is coming your way, folks. One day, you will be using stuff like this yourselves.”  But it doesn’t seem that way now. You may like the Aston Martin DB10, and you may like the Jaguar C-X75, but they can never be yours. They are cars for the demi-gods of good and evil now.  But clearly the future is electric. Though you might never get to drive that eco-Jaguar, a Tesla is still realistic enough. So, when are we going to see James Bond electrified? The coming film will raise questions as to why henchmen should get a fancy hi-tech hybrid-turbine, while Bond still makes do with a Victorian steam engine that does nothing for the survival of those rhino. If Bond wants to hold the continued respect of his audience, a conversation with Q will be required to stuff some batteries into the DB11. But that’s still one movie away."
nan
"One of the final obstacles in the way of a binding agreement at the Paris climate talks comes down to a simple number: 1.5. Limiting warming to a 1.5℃ temperature rise above pre-industrial levels is one of three potential targets on the table as negotiations approach the crucial final days. The other options are a firm limit of 2℃ and a limit of 2℃ with an aspiration to reduce to 1.5℃ in the coming years. Releasing the latest draft text on Wednesday afternoon local time, the summit’s president Laurent Fabius listed the target as one of three outstanding major issues, alongside finance and the question of how to differentiate the responsibilities of developed and developing countries. Many industrialised countries have surprised the world at the talks with a new-found fondness for 1.5℃. The target has long been a key demand of most poor nations, particularly small island states and least-developed countries.  Scientists consider that as 1.5℃ is breached, we will risk passing critical tipping points. In particular, sea level rise associated with that level of temperature increase poses an existential threat to low-lying island states.  Despite more than 100 developing nations being firmly in favour of a 1.5℃ limit, countries came to a political agreement in 2010 to collectively set themselves a 2℃ threshold. If a temperature limit of 1.5℃ is fixed in the new Paris agreement, that raises the question of what countries will need to do to stay below that level of warming.  The UN’s top climate science body has shown that carbon dioxide (CO2) emissions are cumulative, with residence times in the atmosphere of thousands to tens of thousands of years. Temperature rise has a linear relationship with carbon emissions, so we can estimate the remaining amount of CO2 that can be emitted before we risk passing any temperature limit with some probability. For a 50% probability of staying below 1.5℃, there was a remaining carbon budget of 550-600 gigatonnes CO2 in 2011. At current annual global emissions of around 36 gigatonnes CO2, this budget will be used up in less than two decades. What does staying below 1.5℃ mean in practice? Nothing less than full decarbonisation of the global economy by 2050. We must stop burning all fossil fuels before the middle of the century, along with a massive effort to keep forests standing and protect biodiversity.  That is no small feat. While some say limiting warming to less than 1.5℃, or even 2℃, is out of reach, ultimately 1.5℃ is a political signal for greater ambition, and a more serious global engagement in addressing climate change. Late in the day as this signal might be, it is important that a new international agreement does not include a temperature limit that even the UN has recognised is not a safe guardrail. But what does this mean in real terms – if a temperature goal is agreed that requires rapid decarbonization: who must do what, and by when? At the heart of the standoff in the climate talks are fundamental differences over who has more responsibility to act, and what a fair approach to drive greater ambition looks like. A broad coalition of NGOs set out to define a methodology to answer that question, taking into consideration the remaining carbon budget, historical emissions (as impacts on temperature are cumulative, historical emissions matter), and differing capacities between countries.   Their numbers show that the ambition – UNFCCC jargon for emission reduction efforts – of all developed countries falls well below their fair share of what is needed to stay within the remaining budget. Top of the list of offenders are Russia and Japan who are making little to no contribution to what would be considered their fair share of effort, while the US and the EU have pledged around a fifth of their fair share.  In this context, we start to understand why many developing countries might not want to commit to a 1.5℃ limit without clear rules on how to divide up the effort. The current emissions trajectories of developed countries will take up far more than their fair share of the remaining budget, seriously impeding the poverty alleviation and sustainable development aspirations of developing countries. But development trajectories that exceed the global carbon budget will not work for the planet – regardless of who has done what historically, all countries are now bound by the very limited carbon budget remaining. This means that even for countries who have pledged what is basically their fair share of global action, such as China or India, they will need to do a lot more to keep the world anywhere near a 1.5℃ pathway.  For poorer countries (India ranks 135 on the Human Development Index), committing to do more than their fair share needs to be in the context of international commitment to support.  In the end, the 1.5℃ conversation is not the real debate. The real challenge in Paris is to agree on language for emissions reductions that is even remotely compatible with achieving whatever temperature goal is set. This is referred to as the “collective global goal”. Options for a global goal include peaking emissions, zero emissions, or decarbonisation or climate neutrality. But without a differentiated long-term goal – one that puts increased ambition in the context of more support for developing countries – whether the goal is for peaking or zero, 2050 or 2100, all becomes meaningless. Ultimately, the call for 1.5℃ must not become a distraction from the real challenge: agreeing a collective goal that includes both ambition and equity. Without a clear sense of who needs to take the lead, who needs support to do more than their fair share, and how this will collectively keep global emissions within a carbon budget – everyone will lose."
"Our colleague, the archaeologist Santiago Rivas, recently made a remarkable discovery. On a small plateau above the outskirts of Iquitos, a town in the northern Peruvian Amazon, he found a layer in the soil which contained small pieces of ceramic pottery, that were around 1,800-years-old. Digging deeper, he found another layer of soil, this time containing pottery that was about 2,500 years old. This is the archaeological site at Quistococha which has been occupied for at least the past 3,000 years. The pottery fragments are beautifully decorated, sometimes with subtle geometric scratch marks or boldly painted with bright red patterns. Not all of the fragments are small: erosion revealed the rim of a large cooking pot that would have been 40cm across when it was intact. Large pots were supported on an open fire by “elephant feet”: small clay pot rests also found in the archaeological layers. As a place for people to live, Quistococha would have had many advantages. It is located on a terrace above a fertile floodplain of the Amazon which is ideal for growing maize, while the surrounding palm swamp provides fruits and fibres. Just below the terrace, fresh water flows out of a spring. Researchers know that indigenous communities have had profound and complex relationships with Amazonian forest landscapes for thousands of years. However, it is still far from clear just how much deforestation took place before European colonisation in the 16th century.  Quistococha is an ideal place to search for answers – and we recently published a research article based on our work there. The site has an unusually good record of past environmental change thanks to a nearby floodplain lake and swamp. These preserve the remains of plants that grew there, and the charcoal from fires lit by people – both in the prehistoric period as well as during the expansion of Iquitos over the past two centuries. This combination allowed us to explore the relationship between ancient people and the extent of the surrounding forest. Charcoal in the sediment core from the nearby lake – an indicator of fire use – was abundant from about 2,500 years ago until the 1800s: people were, therefore, continuously present at that time. However fossil pollen from smaller trees that make up “secondary forest” growing on deforested land only became abundant over the past 150 years, when the nearby city expanded. Prior to that, for thousands of years, indigenous communities apparently had little impact on forest cover. Such new knowledge about ancient Amazonians is highly relevant for conservation today. For indigenous groups it provides historical context to their fight for land rights and recognition. Studies like ours also show that traditional uses of the landscape should be valued highly, and that Amazonian communities can support themselves without extensive deforestation. This philosophy is the basis for the work of our partners, the Instituto de Investigaciones de la Amazonia Peruana (IIAP), which promotes sustainable management of these floodplain forests. Last but not least, these discoveries are an opportunity to engage with the expanding urban populations of Amazonia: an important voice in the decision-making process. Iquitos is the largest city in the world not connected to a national road network. Recently, the Peruvian Congress has declared an ambitious range of road building projects in Amazonia as national priorities. The planned connection between Iquitos and the rest of Peru promises lower prices for food and other imports. But activists who warn of the adverse consequences of poorly planned development are struggling to be heard. The new road would represent a “first-cut” through indigenous territories and the most diverse and carbon-rich forests of Amazonia. And as these are issues of low importance to the urban majority, the only way to challenge it would be by engaging city dwellers in debates about the implications of future transport networks and of other options for land use. Locals and tourists alike throng to Quistococha on hot weekends to swim in the lake and relax in waterside cafes. Above and in sight of all of them, but now silent, there is a site that records thousands of years of humans living in a continuously forested landscape. The landscape and the stories it tells are an opportunity to reflect on how we might choose to continue the relationship between people and forests in the future."
"As the area burned across Australia this fire season pushes beyond five million hectares, an area larger than many countries, stories of destruction have become depressingly familiar. At the time of writing, nine people have been killed. Balmoral, in the New South Wales southern highlands, is the latest community affected in a state where up to 1,000 homes have been destroyed. A third of the vineyard area and dozens of homes were razed in the Adelaide Hills. It is too early for a thorough examination of the impact on wildlife, including the many threatened species in the fires’ path. Does this qualify as unprecedented? Plenty of experts say yes, but not all politicians and newspaper columnists are convinced. Last week the acting prime minister, Michael McCormack, assured the nation that “we’ve had these smoke hazes before. We’ve had bushfires before.” After returning from Hawaii, Scott Morrison, acknowledged the fires were severe, but also adopted a familiar line: Australia has always had bushfires. That’s true. But a key question is whether it has always had bushfires like this. The firefighting agency in the state worst affected, for starters. The NSW Rural Fire Service says the scale of what has burned in that state is unprecedented at this point of the fire season. By Monday, 3.41 million hectares had burned. “To put it in perspective, in the past few years we have had a total area burned for the whole season of about 280,000 hectares,” RFS spokeswoman Angela Burford said. A slightly larger area burned across the 1974 calendar year, but those fires were of an entirely different nature: above-average rainfall before the fire season meant fuel in the outback was unusually plentiful, and fire burned through well-grown grasslands in the state’s far west. By comparison, this year’s fires are further east, where people live, and have been fuelled by a vast bank of dry fuel following the country’s record-breaking drought. Soil moisture is at historic lows in some areas, and rainfall in the first eight months of the year was the lowest on record in the northern tablelands and Queensland’s southern downs. David Bowman, director of The Fire Centre at the University of Tasmania, says the most striking thing about this fire season is the continent-scale nature of the threat. The damage in each state is explained here. To deal with these sort of fires the first step is to acknowledge the scale of the problem “The geographic range, and the fact it is occurring all at once, is what makes it unprecedented,” Bowman says. “There has never been a situation where there has been a fire from southern Queensland, right through NSW, into Gippsland, in the Adelaide Hills, near Perth and on the east coast of Tasmania.” He says one of the less explored issues, though it has begun to receive some attention in recent days, is the economic impact of having prolonged fires that affect so many Australians. “You can’t properly run an economy when you get a third to a half of the population affected by smoke, and the media completely focused on fires,” he says. “I’m not quite certain why anybody would want to be claiming fires have been like this before. It’s concerning as it is a barrier to adaptation. To deal with these sort of fires the first step is to acknowledge the scale of the problem.” Ross Bradstock, from the University of Wollongong’s Centre for Environmental Risk Management of Bushfires, points to the Gospers Mountain fire, which started in a lightning strike north-west of Sydney in late October and has now burned about 500,000 hectares, as evidence of how this season differs from what has come before. The fire has now combined with others on the NSW Central Coast to create a mega-blaze, but Bradstock says it was almost certainly the largest single ignition-point forest fire recorded in Australia and, for mid-latitude forests, possibly the world. He says it is bigger than any in California and Mediterranean Europe. A large fire in those conditions is usually about 100,000 hectares. “We can find no evidence of forest fires of that size anywhere,” he says. “You just don’t see fires of this size in these parts of the world because you do not usually get the extreme dryness and unrelenting nature of the weather.” Two months in, Bradstock says the Gospers Mountain is a monster, “just unimaginably big” and near impossible to contain unless there is substantial rain. Some certainly have, but this season has also seen the loss of rainforests, wet eucalypt forests, dried-out swamps and banana plantations that do not usually burn because they are too wet. Damage to the Gondwana rainforests in 40 reserves between Brisbane and Newcastle prompted the Unesco world heritage centre to last month express their concern to Australian authorities. The reserves include the largest areas of subtropical rainforest on the planet, some warm temperate rainforest and nearly all the world’s Antarctic beech cool temperate rainforest. They are considered a living link to the vegetation that covered the southern supercontinent Gondwana before it broke up about 180m years ago. There are also fears critically endangered Wollemi pines have burned in the fires tearing through the Blue Mountains. They were thought extinct until discovered by bushwalkers in 1994. Their whereabouts had been kept secret from the public to keep them safe. Authorities say the smoke that has smothered Sydney, Canberra and other centres and towns in recent weeks has produced pollution up to 11 times greater than the hazardous level for human health. In Sydney, the air pollution has been hazardous for at least 30 days. NSW’s director of environmental health, Richard Broome, last week told reporters the state was enduring “an unprecedented emergency from a smoke point of view”. “We haven’t seen conditions like this in Sydney, certainly in anyone’s memory that I’ve spoken to,” he said. Broome said there is early evidence that the number of people turning up at hospital emergency departments needing help is higher than usual. Dr Kate Charlesworth, a fellow of the Royal Australasian College of Physicians, said there was no safe level of air pollution, and that the most vulnerable in the community – babies, children, the elderly and people with pre-existing disease – were the most likely to be affected. The explanation should be familiar by now: greenhouse gas emissions do not cause bushfires, but they play a demonstrated role in increasing average and particularly extreme temperatures and contribute to the extraordinarily dry conditions afflicting eastern Australia. Scientists cite the near absolute lack of moisture in the landscape as a key reason the fires have been so severe. Multiple studies, here and overseas, have found the climate crisis is lengthening the fire season. In the past, the season started in spring in NSW before moving south to Victoria, South Australia and Tasmania in the new year. Just as Australia’s fire season is more overlapping with that in California, making resource-sharing more difficult, it is also running simultaneously across the country. Among other issues, that is putting greater strain on volunteer firefighting brigades. It is an issue that firefighters and some experts say the country needs to acknowledge and address. The Morrison government appeared to make an initial, qualified step in this direction on Christmas Eve. • This article was amended on 2 January 2020 to augment the brief description of the 1974 fires."
"Even the best-case scenario following the Paris climate agreement will still lead to rising sea levels, harsher droughts and more destructive storms – all of which will hit those with least protection the hardest. So are we going to see waves of “climate refugees” pushing on affluent countries’ gates? Will hordes of climate change victims jeopardise international security, exacerbating existing crises and spurring armed conflicts? One would think so, at least judging from the way the media talks about the overlap between climate change and migration. Time after time, again and again, climate refugees are mobilised to provide dangerous global warming with a human face.  Usually this is to highlight the security implications of climate change. Recently, this narrative has surfaced in relation to the Syrian tragedy and the way that the conflict and the related displacements have been attributed to climate change by research papers – and even Prince Charles. Such alarmism might be appealing, but it’s at odds with most of the research on how climate change will interact with migration. The figures of hundreds of millions of climate refugees have been widely echoed in the media but the headline numbers are at the least controversial if not outright scientifically unsound. In any case, the entire concept of “climate refugees” is evocative but misleading. Let’s begin with the obvious: people migrate for lots of different reasons and, in most cases, it is impossible to single out environmental degradation. When people do move in response to a sudden storm or flooding, they usually stay in the same region and return home as soon as they can. A growing number of interventions point out that migration, in presence of the right conditions, can also represent a proactive strategy to cope with stress or adapt to change. Finally, there’s no simple link between climate change, displacement and security. Environmental stress can exacerbate tensions, but also increase cooperation. And we should not conflate things playing out at different scales: the idea that food stress (and the poor) cause war is very problematic – a quarrel over a loaf of bread is not the same as an armed conflict between states. None of this means the issue is unimportant. Climate change will have the biggest impact on the weakest and most exposed – whether they are migrants or those without the means to move. Indeed, (im)mobility will be one of the currencies through which vulnerable people will pay the price of the international community’s failure to avoid climate change. The Paris agreement establishes a “task force” to “develop recommendations” on displacement. Some hoped for stronger wording – an earlier draft included the creation of a “coordination facility”, presumably with more powers. This was only removed in the last days of the summit. Yet in order to keep the issue on the table, a mention in the treaty is a step in the right direction. However, I am not sure we can expect too much from the UN’s climate process. An emissions deal was clearly the highest priority for this phase of diplomacy. With a “refugee crisis” shaking European institutions and the reaction to the terror attacks in Paris adding to the international tension over migration, the topic was just too controversial. In this context, it wasn’t exactly realistic to expect states in Paris to accept any legally-binding obligations to facilitate the movement of vulnerable people.  But, on top of the question of political feasibility, it is also worth asking whether UN climate policy should even be addressing migration at all. Environmental discourse has always been haunted by a fear of dangerous, unruly populations in the “global south” – a spectre that arguably  still lingers in climate politics. This leads to apocalyptic talk, usually with a strong racial undercurrent, of hordes of refugees threatening “our” security. Not exactly a good starting point. The idea we should “solve” climate migration is rooted in a view of mobility as pathological, as the result of a failure to develop, to adapt to climate change, or to be more resilient. But in reality, migration is an ordinary social, economic, and political process. It’s neither inherently good nor bad. Of course, it would be naive to overlook the divisive questions that migration brings to the surface. And we should always remember that people on the move (or stuck somewhere they don’t want to be) can suffer and are often exposed to many wrongs.  Relying on the UN’s climate governance machinery to sort these matters out only obfuscates their inherently political character and will lead to poor policies. To make a provocative comparison: would we ever expect the UNFCCC to “solve poverty”? Yes, it is important that migration was mentioned in the Paris agreement. And we should talk more about it in the climate change arena. But more as a matter of climate justice than one of security. And not as a contingent problem to be solved (or that can be solved) – rather as one of the ways in which we deal with the highly political question of the kind of mobility and society we want for the decades to come."
"Amazon Prime Air famously used a drone in the run-up to Christmas 2016 to deliver a streaming stick and a bag of popcorn to a customer in Cambridge, just 13 minutes after the order was placed. The use of drones to deliver goods is slowly becoming a reality, as numerous retail giants and postal services are conducting trials across the globe. In the not so distant future, they may even deliver takeaway food.  Drones may be the future, but are they a more environmentally-friendly way for us to receive ordered goods? A group of US-based researchers say they are, but only when small drones are used. Joshuah Stolaroff, Constantine Samaras and their colleagues have recently published a study in the journal Nature Communications, in which they show that a delivering a small package (0.5kg) by a regular quadcopter drone leads to lower carbon dioxide emissions per package than delivery by diesel, gas or even electric truck. On the other hand, results are less flattering for large “octocopter” drones, whose carbon footprint per package is generally higher than that of trucks.  Both small and large drones are assumed to be charged using electricity from the grid at the location where they operate. Therefore, whether drone delivery is more environmentally-friendly than its alternatives primarily depends on the means of producing electricity locally. For example, the researchers consider a large drone charged in California, where much of the electricity is renewable or relatively low-carbon. There, this large drone would yield lower carbon dioxide emissions than a diesel or natural gas vehicle. However, if an electric vehicle is used (charged from the same low carbon grid), large drone delivery emissions are higher.  Things are rather different in the state of Missouri, where 70% of electricity comes from coal. There, delivery by gas or diesel trucks remains the environmentally-friendly option, with notably lower carbon footprints than an electric van or large drone. Yet in all cases considered, delivery by a small drone led to minimum carbon emissions. The study looks at the life cycle of a small drone, accounting for the environmental footprint of everything from the raw materials and energy used to make it, through to the resources that keep it running day to day. The researchers found that the electricity actually used to fly the drone accounts for just 10% of its overall greenhouse gas emissions. Most of its emissions can be attributed to the electricity consumption of the warehouse the drone has to visit for package collection and charging. For larger drones, however, the equation changes and transportation electricity becomes more significant, comparable to the carbon footprint of the warehouse. Nonetheless, medium and large drones are an attractive option for numerous industries. Boeing, for instance, has recently unveiled a prototype able to carry 200kg. In China, online shopping giant JD.com is already delivering packages up to 30kg by drone, and the company is even working on a 1,000kg delivery drone (the weight of a small car).  If drones are to progress into the freight industry mainstream, battery power remains the major obstacle. Small drones currently use lithium polymer batteries, but Stolaroff and colleagues forecast significant development in this area due to ambitious targets set by the US Department of Energy, as the delivery range is likely to increase in coming years. In addition, gas-powered drones and those utilising hydrogen fuel cell technology, as well as hybrid solutions, are emerging on the market. Drones are a relatively new technology but they’ve already been made significantly lighter and more efficient. And at the smaller end of the scale, they may already be the greenest option. The latest research reaches roughly the same conclusion as a 2017 study from the University of Washington, Seattle, which found that small drones reduce CO₂ emissions for deliveries a short distance from the warehouse, or where only a few stops are required.  As things currently stand, large drones do not reduce the energy used in the freight sector. But this depends on how electricity is generated locally (cleaner electricity means greener drones), and trucks remain a more climate-friendly option when the delivery route has multiple stops. Perhaps unsurprisingly, driving to pick up a parcel from the shop yourself appears to be the most harmful option for the environment."
"Thursday’s Queen’s speech is Boris Johnson’s second in just over two months. The more than 30 pieces of legislation will be the basis of his political agenda for the year. Described as “radical” by the prime minister, it leads on his law to formally take the UK out of the EU. There are also plans to overhaul immigration and put into law investment in the NHS.  The European Union (withdrawal agreement) bill will ratify the deal the prime minister struck with EU leaders in the autumn and which was voted down by parliament repeatedly. He is set to put this bill to MPs on Friday and hopes to have this passed by 31 January. This legislation also includes an implementation period where the UK remains aligned with the EU until 31 December 2020. An agriculture bill will result in Britain leaving the EU’s common agricultural policy. Direct payments to farmers will be phased out. The fisheries bill removes the UK from the common fisheries policy and means foreign fishing boats will not be able to have automatic access UK waters. The immigration and social security co-ordination (EU withdrawal) bill proposes an Australian-style points based system that would end free movement in UK law. Also, from 2021, EU citizens arriving in the UK will be subject to the same immigration controls as non-EU citizens. This is the first time a government has enshrined in law its spending on the NHS, which is £33.9bn in cash terms by 2023-24. Their NHS long-term plan also includes delivering 50,000 more nurses, which was a controversial part of Johnson’s manifesto messaging. There is no specific social care bill, but a section of the speech was dedicated to reform and how they want to find a “cross-party” consensus on devising a strategy. They pledge to modernise the Mental Health Act and improve processes for detention. And there is a pledge to remove hospital parking charges. The sentencing bill includes tougher sentences for those who commit violent and sexual offences and terrorism. The automatic release point for prisoners will be moved from half of their sentence up to two-thirds. Johnson said he would bring in legislation on this in November following the London Bridge terror attack, where the killer, Usman Khan, had been automatically released after serving half of his 16-year term. The most serious terrorist offenders will receive a 14-year minimum sentence. The speech also reaffirms the earlier commitment to recruiting an additional 20,000 police officers. An employment bill is promised that will protect and enhance workers’ rights when the UK leaves the EU. The government will create a new single enforcement body that gives workers being treated unfairly the right to redress. A renters’ reform bill is also set out with the promise of giving tenants more security by removing “no-fault” evictions and reforming the grounds for possession. A lifetime deposit scheme that can be moved between properties is intended to stop tenants having to save up every time they move house. . The government says it plans to expand the national living wage to those aged between 21 and 25 over a five-year period but does not set out legislation to do so. A pensions scheme bill includes a “pensions dashboard” so people can access information on schemes online and there will be protection of the triple lock. There is no provision for Waspi women set out in the speech. The science, space and research bill sets out plans to boost funding for research to tackle the UK’s contribution to climate change. An environment bill will set legally binding targets, including a commitment to improving air quality and banning the export of plastic to countries outside the OECD. There will be tougher sentences for animal cruelty of up to five years. It will also be enshrined in law that animals are sentient beings and the government has a duty to protect them from harm.  The government will not raise rates of VAT, income tax or national insurance, which they claim will help working families. A new no-fault divorce category will end one spouse having to make an allegation about the other’s behaviour to end the marriage. The government will stop public institutions, including councils and universities, from imposing their own views on international relations with boycotts and sanctions. The prime minister said he wants to end institutions developing their own “pseudo-foreign policy” against countries that, “with nauseating frequency, turn out to be Israel”. There are proposals to significantly beef up existing espionage laws in the aftermath of the novichok nerve agent attack in Salisbury. One plan under consideration is to adopt a form of registration for foreign agents, updating the Official Secrets Act and treason laws. This is to make it tougher for adversaries operating in the UK. This bill is a legacy from the Theresa May era as it was constantly beset by delays. It makes it easier for the courts to prosecute for domestic abuse by creating a statutory definition that means harm caused is not just physical or sexual, but can also involve emotional, and economic abuse, and controlling behaviour. "
"
Share this...FacebookTwitterThe sun in January 2017, and: a “pause” or not?
By Frank Bosse and Fritz Vahrenholt
Translated/condensed by P Gosselin)
In the previous month our sun was very quiet. A month earlier there had been little activity at first, but then picked up some later in the month. On average the sunspot number SSN was 25.8, which was 47% of what is normal 97 months into the cycle – calculated from the previous 23 solar cycles. 
Figure 1: The monthly activity of solar cycle 24 since December 2008 (red) compared to the mean solar cycles 1-23 (blue) and the very similar SC 5 (black).
A comparison to solar cycle 5 (the second weakest solar cycle so far) shows that the current cycle has been much weaker over the past 23 months. Indeed during this particular period no solar cycle was ever as weak as solar cycle 24 now is. An overall comparison of the activity of all solar cycles, 98 months in, is as follows:

Figure 2: A comparison of all observed solar cycles. SC 24 is safely in 3rd place for low activity. Cycle No. 19 (1954…1964) had 2.5 times more sun pots than the current cycle thus far.
In our last solar report we wagered a look into the future by looking at the gradually growing solar polar fields. The fundamental data has been corrected slightly downwards (a normal quality management step) and we wish to present here once again the updated comparison of all the cycles for this observed magnitude:

Figure 3: The polar fields of solar cycles 21…24 (clockwise) each up to 1400 days after the zero-point (black) for the sun’s southern pole (red) and of the northern pole (blue).
We’ve already seen the maximum on average. You’ll find the best website here when it comes to solar data. The behavior of SC 24 is so far very remarkable!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Pause or no pause?
A controversy erupted in early February: A retired former NOAA employee – John Bates – wrote in a lengthy post at Judith Curry’s blog about how NOAA head Tom Karl used unclean data in a study from the year 2015. The study supported the position that a “pause”, i.e. a considerably slower rise in global temperature after 1997, hadn’t occured. A rather tumultuous quarrel then ensued, as the claims made by John Bates have since been refuted. Fuel was added to the topic, when an article appearing in the “Mail on Sunday”, which contained some inaccuracies.
Apparently whistle blower John Bates had found some NOAA data quality management deficiencies. First it was determined that a computer program that had been used to compute the temperature was lost and thus the calculations were no longer reproducible. The study had a huge impact on the political discussion during the run-up to the Paris Climate Treaty. Bates later stated that data manipulation could not be shown.
In the course of this heated discussion, a new “official” sea surface temperature series dubbed ERSSTv5 was released. Here a small part of the warming of the previous series was recalculated beginning in the year 2000. A great amount of controversy has swirled about the new series, so it is important to keep the focus on where it really counts.
All decisions made today are based on models from the IPCC AR5. Let’s compare what the models projected to the the ERSSTv4 series – the current warming of the global ocean surface:

Figure 4: Comparison of ERSSTv4 series (blue) to the model mean 1979…2016 (red).
The global trend of the temperatures for the ocean surface is over 70% too high!
ERSSTv4 shows 0.109°C per decade warming while the model is far more generous, showing 0.154°C/decade over the time period 1979-2016.
Here it has to be taken into account that in the real world an El-Nino occurred at the end of the measured period, which skews the trend upwards. In two or three years the deviation between the real world and the model world will grow. The models are calculating excessive warming and overstating the effect by CO2. That is the core of the truth that you can take away from this.
 
Share this...FacebookTwitter "
nan
"Scott Morrison has claimed climate change is “as important now” amid an extended bushfire crisis and a record-breaking heatwave as it was at the election and denied that the government is split over whether to improve Australia’s policy response. In a series of interviews on Monday Morrison cited family commitments as the reason for his decision to holiday in Hawaii during the crisis, comparing himself to a plumber forced to choose between a Friday afternoon job or seeing his family.  Morrison returned to work on Sunday, cutting short the holiday by a day after the deaths of two volunteer firefighters on Thursday, but insisted he would not “panic” by increasing Australia’s ambition to fight global heating. Asked about his judgment in taking the holiday, Morrison said the fires had been going since September – citing his earlier visits to bushfire areas – and “still have a time to run yet”. “We all make decisions … we all seek to balance our work-life responsibilities and we all try and get that right,” he said. “We can all make better decisions on occasions, and I was pretty upfront about that with the Australian people yesterday. “Whether it’s on a Friday afternoon and you decide to take that extra plumbing contract and you said you were going to pick up the kids, or something at my level, these are things you juggle as parents.” Ahead of a visit to Mudgee on Monday, Morrison told Channel Seven’s Sunrise the issues around climate change were “as important now as they were” at the time of the May election. Morrison said Australia was on track to meet its Paris target of 26% emissions reduction by 2030, about half of which will be achieved using carryover credits from meeting earlier targets and not from practical emissions reduction. Morrison said emissions “on average under our government are 50m tonnes lower than under the previous government” – which Guardian Australia revealed on Monday is a claim based on accounting changes which have raised estimates of emissions under Labor. “I don’t think panicking is the way to manage anything, and the urge for panic that has come from some, often politically motivated to pursue a particular agenda, is not something I’m ever intimidated by or ever distracted by.” Speaking later on 2GB, Morrison denied there was a difference of opinion in the government, after acting prime minister Michael McCormack said on Saturday that he “absolutely” agreed that “further action” to combat climate change was needed. “We’re saying the same thing … Our existing policies have increased efforts, that’s the point,” Morrison said. At a press conference in Sydney, Anthony Albanese accused Morrison of “not listening to the science when it comes to climate change”, nor to former fire chiefs who have called for more action. Albanese said Australians were “scared of what is going on around them” and suggested Morrison was showing “stubbornness” by refusing to change course on climate change. He said it was “extraordinary” for Morrison to suggest those who wanted a better policy were engaged in “political intimidation”. Albanese called on the prime minister to immediately meet former fire chiefs, compensate firefighting volunteers and bring forward a meeting with states and territories, scheduled for March, to discuss emergency services, climate and disaster mitigation. In Mudgee, Morrison told reporters that fire commissioners and state premiers were able to raise operational issues with him at any time, and “are very comfortable with the arrangements that we have”.  Asked about possible compensation for volunteer firefighters, Morrison left the door open to “resources that enable the commissioners to be able to turn out the volunteer force”. “There are no recommendations coming to us from fire chiefs about those issues at this time.” Earlier the former deputy prime minister Barnaby Joyce told Sunrise that Australia could not “single-handedly” influence emissions from China and India. He suggested that China’s imprisonment of 1m Uighurs demonstrated that environmentalists were “naively overreaching” by suggesting Australia could influence global superpowers. Earlier on Sunrise, Morrison said he had been “very focused on things back here” while in Hawaii and was “heartbroken” at the deaths of the firefighters, Geoffrey Keaton and Andrew O’Dwyer. Morrison said he was glad he had come home to personally convey condolences to their partners Melissa and Jess, describing Sunday as “a hard day”. Morrison denied the holiday was a secret because he had texted Labor leader Anthony Albanese before the trip and “everybody knew I was [away]”. Although several journalists reported that the prime minister’s office had denied he was in Hawaii, Morrison deflected a question about the lack of transparency by claiming it was an “issue the media’s got very excited about and my political opponents are seeking to exploit”. The federal and New South Wales governments have committed a total of $63m in emergency relief funding and the federal government has delivered an extra $11m for aerial firefighting. On Monday the captain of of the rural fire brigade in the NSW village of Balmoral, which has been devastated by the bushfires, said the community felt let down by all levels of government. Brendon O’Connor told Radio National that “well over 90%” of the bushland in the area had been destroyed. At least 18 homes have been lost in the village. “The community itself is rallying behind us,” he said. “Other than one of our local members we haven’t heard from anyone – we’ve not had the local council, we’ve had no members of government come to our village.” “They’ve all gone well away from where any of, as they’re calling it, ground zero is, none of them have been here on the ground.”"
"We asked Guardian readers around the world to tell us what you think of our climate coverage, and what you’d like to see more of. We received several hundred responses from readers in India, the UK, Japan, the US (everywhere from Maryland to Alaska), Mexico, Istanbul, Spain, Canada, Malaysia, Switzerland, New Zealand and Wales - to mention just a few. Here is a small sample of what we heard. The rising human population needs to be addressed. There are too many of us; we are living longer, therefore something needs to be done to encourage smaller families, choosing to adopt, or to remain child-free. The exploding population is an ecological emergency.Tanya, 41, Yorkshire, UK  I was onboard already. But the Polluters series helped focus my attention on what needs addressing first - systemic changes are much more critical right now, but governments and corporations are trying to shift the focus and blame onto consumers. It’s vital we hold them to account.Pritam, 49, Jaipur, IndiaI think the Guardian is doing a fantastic job on reporting the climate emergency - you’re really leading the field!Pamela, 54, Southern AustriaI’d like to read about calls for government investment in research and development of technologies that can help ameliorate the climate crisis and its effects, such as gene editing of plants to resist drought and solar radiation management.Brittany, 29, Georgia, USThe pollution and lack of resilience of the value chain of electronics, including the choice of most nations to consume more electronics in the year to come.Elie, 33, Strasbourg, FranceI’d like to see more coverage of mass climate migration happening now and in the future, with a focus on solutions to the problem.Karolina, 23, Copenhagen, DenmarkI hope the Guardian will continue to cover deforestation – especially the Amazon. This needs to be covered enough to continue pressure on Bolsonaro. As you’ve reported, we cannot combat global warming with the ‘carbon bomb’ that is continued Amazon deforestation. Leah, 36, CanadaOverpopulation is such a key issue. It should be curtailed by women’s emancipation, education and free family planning advice and contraception.Nile, 58, London, UKI’d like to see more in depth coverage of global harvest fluctuations, and food security in different regions.Matthew, 33, Wales Local councils are still making climate unfriendly development decisions such as ripping up much loved parks to expand airports, for example, or investing in massive roads and car-dependent estates at a time when we should be banking on there being fewer planes and cars. If each branch of local government really cared about their green environment, they’d respect and value established wild spaces. What would it take to properly protect our green estate, so local government acts as guardians rather than vandals?Bekki, 42, Luton, UK The elephant in the room is how we can make sweeping changes without provoking economic collapse. I live in Japan where the media is politically controlled and climate change is only rarely mentioned. Even when the subject of single-use plastic finally made the news this summer, the idea of buying less was not highlighted. How can we have an economic system based on growth whilst also stopping or slowing down climate change?Helen, 49, Japan The climate crisis needs dealing with right now. And declaring a climate emergency means that the government ought to be making every decision, including Brexit decisions, through the lens of how this affects the climate. I hope they will be held to account. Mika, 40, Switzerland Education is key. We need coverage that helps prepare young people for an uncertain future - more focus on employment opportunities for the future outside of those generated by the fossil fuel-oriented market place.Mel, 80, Costa Rica Making the link to impacts on human health, both globally and locally, may engage more people. Furthermore, drawing more of a focus on climate solutions and the co-benefits in terms of tackling other public health concerns such as lung disease, obesity, cancer rates, mental health disorders, social isolation etc helps people to see how combating climate change need not be all about negative impacts on their quality of life.Dr Hayley Pinto, 51, Norfolk, UK I would like to know more about the issue of land ownership (and land grab) . How the lands are used and who owns them is directly linked to the carbon emission of the land and social equity.A reader, Kuala Lumpur, Malaysia The species becoming extinct or facing future extinction. Australia has lost 11,000 bats that were adapted to high temperature which could not survive the heat.Christopher, 32, Aberdeen, Scotland I think the Guardian does well in this area. I’d like to read more details of the way the pesticides work … and their very widespread presence in our food chain.Sue, 79, Munich, Germany I think the role of human overpopulation in the current climate (and ecological) crisis is often neglected. The means to achieve a reduction in population are simple and humane: empower women and girls; improve access to and acceptance of contraception (inc vasectomy); alleviate poverty; improve education worldwide and help people to understand the obvious link between population and carbon emissions.Helen, 56, Melbourne, Australia I think it would be so useful to highlight that the average person can cast their vote for the society they want to live in by opting to only buy from companies that are making an effort, and celebrating companies that make it easy to shop low waste (unpackaged vegetables, bulk bins of grains etc.). I think a lot of people feel overwhelmed by the information being broadcast to them, especially when they have busy lives, so we need to make sustainable lifestyles feel accessible.Rose, 23, Sheffield, UK Voters should have an opportunity to assess the carbon footprint of those who are standing for election in the same manner as their financial involvements. It would give voters, particularly the younger ones, an incentive both to vote and to prioritise the issues that concern them. It would identify the individuals and also, when aggregated, the parties, whose behaviour reflects their stated environmental aspirations.A reader, 77, Dublin, Ireland I’d like to hear more on climate refugees - the people who are displaced because of the climate crises.Yusuf, 22, Istanbul, Turkey I’d love to hear the true story of carbon offsets. There is a whole network of brokers and accreditation actors and others in this market. What makes a good offset and which offsets are ultimately not helpful?A reader, 35, Nairobi, Kenya I think reporting on how the climate emergency affects all aspects of Australian society, and capturing the views and perspectives from those parts of society that do not see this as an issue, or at least not one that is more important than their job security or other concerns, would be really important.A reader, 35, Sydney, Australia An issue I feel passionately about is the connection between pollution and health. I’m part of a recently-formed group of Irish doctors aiming to bring attention to the climate crisis from our patient’s perspectives. We believe that environmental health is human health. We are the air we breathe, the water we drink, and the food we eat. We feel that our patients’ underlying pathologies can be worsened by pollution in our cities.Dr Vincent Wall, 32, Ireland, Irish Doctors for the Environment (www.ide.ie) I’m interested in the disproportionately damaging effects of short trips by cars, especially SUVs. As someone who does not own a car, it is incomprehensible why so many people automatically take their car for short trips that could easily be done on foot, by bicycle or public transport.Mark, 58, Hamburg, Germany I’m interested in knowing more about how the arts can raise awareness and help humans reduce their ecological footprints.Indran Amirthanayagam, 58, Maryland, US I want to keep being informed about: how to improve one’s consumption, the best ways to recycle, what to do locally, in your community, interviews with local people who act to make their city greener.Manon, 27, London, UK "
"We might have a new energy superpower to talk about. Guyana, the former British colony on the northern edge of South America, apparently controls vast amounts of offshore oil and gas. That, at least, is Exxon-Mobil’s view. In May 2015 the American major announced it had discovered huge potential reserves at its Liza-1 well in the Stabroek Block – some 120 nautical miles off the Guyanese coastline. Exxon-Mobil claims 700m barrels of oil might be recoverable and, even despite depressed oil prices, analysts have spoken about the Stabroek Block being worth US$40 billion. With fewer than a million Guyanese citizens, such a windfall could go a long way. If shared evenly it would work out to around US$60,000 each – in a country where per capita income is currently just US$4,170. But sudden oil wealth is rarely distributed smoothly or equitably, and ordinary Guyanese worry their nation will become the latest victim of the resource curse. Guyana also has a long-running border dispute with its larger, wealthier neighbour Venezuela. Not long after the oil discovery, Venezuelan president Nicholas Maduro issued a decree reiterating a historic claim over western Guyana and large parts of Guyana’s Atlantic waters – including much of the Stabroek Block. Nonetheless, Guyana’s government is naturally upbeat. Raphael Trotman, minister of governance, described the find as “transformational” – a common view when such news is released, nourishing a bonanza political-economic model of hydrocarbon exploitation and development. You would have heard similar terms being bandied about back when the Falklands were being described as a “South Atlantic Kuwait” or Equatorial Guinea was set for an “economic explosion”. Guyana’s president has reassured Exxon Mobil that its operations wont be disrupted by talk of disputes and controversies involving Venezuela.  The international boundary between Guyana and Venezuela remains a source of tension for the latter. An 1899 arbitration panel in Paris settled the current borders but, as any visitor to Venezuela will attest, you can easily find maps and even tea towels that depict the country’s borders extending into a significant portion of Guyana to the east. The spat has even made it onto the internet – Guyana recently protested Google Maps’ choice of Spanish (Venezuelan) place names in the disputed Esequiba region. Since 1899, international law including the Law of the Sea Convention has granted additional sovereign rights to coastal states. And international maritime boundaries can take on added significance when potentially thousands of square miles of sea and seabed are at stake. The Guyanese government is eager to ensure oil and gas exploration continues without controversy and has initiated a new round of diplomacy designed to garner support for the international status quo. After a meeting at the UN in New York on September 29 the leaders of the two countries agreed to resume diplomatic relations, though we can expect a great deal more presidential speech making and backroom diplomacy at the UN and regional summits. The two nations have plenty of history. The Guyanese government will be mindful of an incident in 2013 when the Venezuelan navy detained a survey ship operating in what it considered to be disputed waters. The ship was owned by Malaysia and operated on behalf of an American company.  At home, Maduro is under pressure to be seen as defending the “fatherland”. He also faces elections in December and Venezuelan voters may not be in a forgiving mood given food shortages and chronic inflation. The end result is what we might describe as “hot nationalism”, a situation where political leaders talk grimly about the dangers facing their countries, or conversely talk about the historic opportunities to make a notable difference to their countries. Either way, “oil talk” can and does inflame the passions, especially when at least one party thinks the discovery was made in disputed waters."
"The Guardian asked its New Zealand readers to put questions to prime minister Jacinda Ardern, as she and her government gear up for an election in 2020. Here are her responses: Q. New Zealand will find it difficult to reduce carbon emissions to our agreed targets. Also, our impact on global emissions will be small. What can NZ do to help make significant reductions on other countries, especially those without resources to do so? Could NZ could lead an alliance of smaller countries to achieve this? Cliff Turner, 72, Wellington  A. Right now, the minister for climate change, James Shaw, is leading a delegation from New Zealand at the annual international climate change negotiations. Whilst there, he has been sharing with other countries the huge progress we have made here at home, not least with our historic Zero Carbon Act. There is still a lot of work to do, as you suggest, but after decades of inaction we are finally leading New Zealand on a journey that we must all take together to solve climate change. Our Pacific neighbours are among those most uniquely at risk from the changes we are forcing on the climate. Rising sea levels, ocean acidification and disruptive weather patterns, are just some of the consequences threatening Pacific peoples’ livelihoods and ability to provide for their families. This is exactly why at least two thirds of New Zealand’s $300m of climate-related support between 2019 and 2022 will be provided to Pacific nations. Back in September, I was proud to announce that we would start negotiations with four other small countries - Norway, Iceland, Fiji and Costa Rica – to remove tariffs on environmental goods such as solar panels or wind turbines, and curb fossil fuel subsidies. Minister Shaw is reaffirming that commitment at the international negotiations. We have also contributed $15m over four years to the first replenishment of the Green Climate Fund, which supports the efforts of developing countries to respond to the challenge of climate change. Q. Do you think that the current view on the climate crisis has become too affiliated with the left/right spectrum of politics? Gideon Bickler, 16, Auckland A. I don’t think most people view their lives in terms of the left/right political divide – and I hope we don’t see climate change that way either. I think most New Zealanders just want to see us take action on the issues that matter most to them, including environmental issues. Recently our new Zero Carbon Act passed through parliament unopposed. In other words, every political party has sent a clear message to New Zealanders that no matter who is in government we are all committed to significant domestic greenhouse gas emissions reductions. The Zero Carbon Act was conceived of by a movement of young people as a way to depoliticise climate change policy so that we can actually start to make some progress. That’s exactly what we have done. Q. May I know what will be your immigration policy going forward now that New Zealand will meet the 5 million population mark soon? Will your policy be more welcoming to international students like me who might opt to stay on to contribute to your country and will you formulate an attractive policy to lure in more international students whose parents may or will have spent millions to support their children’s education in New Zealand (this is also a way to boost your country’s GDP)? Ballerina Chong, 19, Wellington A. We have a range of different things our immigration policies are designed to achieve. We want to ensure that: New Zealand businesses can get the workers they need where skill shortages exist Our immigration settings respond to regional differences Migrants are not exploited New Zealand meets its international and humanitarian commitments If students have the skills we need they will be able to work here. But we also want to make sure that the courses provided for international students are quality courses that will give them good skills for their future careers wherever they may go. Q. Will NZ change its name to Aotearoa when the Queen dies? John Irving, 77 A. Te Reo is an official language of this country so Aotearoa is one of the names we are lucky to have already. Q. When is your government going to make the transformational change to child poverty that you promised? Douglas, 75, Porirua A. We have committed to reducing child poverty by at least half within 10 years. The Child Poverty Reduction Act requires the government to set targets and report on child poverty every year. This is huge as it creates a framework for ongoing action and accountability by this and all future governments. Achieving our targets will mean our child poverty rates are amongst the lowest in the world. Every step we take to get closer to our targets represents a tangible improvement in the day-to-day lives and future opportunities of those families and children who are no longer in poverty. Our first two budgets have included actions to significantly reduce child poverty and material hardship. The most significant of these was our $5.5bn families package, which increased the family tax credit and accommodation supplement, and introduced the best start and winter energy payments. In Budget 2020, we indexed benefits to wages, and increased the amount that beneficiaries can earn before their benefit reduces. These changes are expected to lift between 42,000 and 73,000 children out of poverty. We have also taken action to ease the financial pressures felt by low-income families, by reducing health, education and other costs. The impact of many of these investments isn’t captured in current child poverty reporting the release of new Statistics NZ data in early 2020 will be the first indication of the progress we’re making in reducing child poverty. Q. How will Labour address the persistent wealth gap in Aotearoa/New Zealand and allow our children to aspire to own their own homes? Rachael Findlay, 57, Te Whanganui-a-Tara, Wellington A. This government views the economy as a means to an end, not as an end in itself. A strong, healthy economy is vital to New Zealand but only is as much as it means we can share the benefits more widely among all New Zealanders and their families. Our Wellbeing Budget was a big step towards making this a reality. When we came into office budgets measured the wealth and success of New Zealand on just the narrow metric of economic growth – GDP. We have fundamentally changed the way budgets are put together and how they are delivered. The result is budgets now reflect what New Zealanders value including how many children have been lifted out of poverty, how much cleaner our environment is and how we are future proofing the economy. Innovations such as this will help narrow the wealth gap that exists in New Zealand and, accordingly, will put home ownership within reach of more people. Major investments will continue to be made in health, education, housing and social programmes to address New Zealand’s long-term challenges. And we have also created more jobs and raised wages, made it cheaper to pay the bill (via the winter energy payment), made it cheaper to visit the doctor and to send kids to school. We have also banned foreign speculators from purchasing property in New Zealand. Q. What are you doing/will you do to ensure free, independent journalism in New Zealand? Sincerely, a recently graduated, jobless journalist. Gordana Rodden, 23, Wellington A. As we all know, the media industry has changed hugely in recent years as traditional advertising revenues are increasingly diverted to online social media platforms. This has created a real issue for an industry that is now struggling to make the money to pay journalists. Free, independent journalism is a core part of any democracy and something we must guard jealously. In New Zealand, the government funds Radio New Zealand and TVNZ in order to ensure it continues. But even then, there are funding problems and the organisations are hampered in what they can do with limited resources. This is why broadcasting minister, Kris Faafoi, is currently looking for potential alternatives to ensure the ongoing strength of independent local journalism. He is hoping to announce some more details soon. Q. How can we stop the “culture wars” growing in NZ? Guns, abortion, water, climate change and the planned referendums have the potential to split NZ just like Brexit has split the UK. Ian Andrews, 55, Wairarapa A. I agree no one wants to see division, but I do think New Zealanders have shown they can live happily side by side while holding strong and varying views. Yes these can be emotional decisions but I trust that New Zealanders will have the debates while remaining respectful of one another and of differing views. In fact I think that’s one of the things that sets us apart. Q. Do you think that NZ could take an even stronger lead on accepting refugees to Australasia (including possible climate refugees from the South Pacific nations), particularly in light of Australia’s continual refusal to take a fair quota? Nigel Dowdeswell, 57, Hamilton A. We have made a significant increase in our refugee quota this term and we are working hard to ensure that we are ready for that increase. New Zealand’s refugee programme includes: a high quality refugee resettlement programme that is internationally acclaimed and provides up to a year of support once in the community increased the refugee quota up to 1,500 each year, which will be in place by 2020 and a significant amount of work is underway to support this we have announced new regional settlement plans for six new regions we are making improvements to the Mangere Refugee Resettlement Centre to support our refugees for their 6 week induction programme Q. What practical plans does Arden and her government have to resolve the housing issues experienced by many New Zealanders - whether it be overpriced, poor unsuitable rentals, the lack of real social housing options, the price of ownership being un-affordable for many New Zealanders, or the lack of temporary beds for those in acute need? Jamie Lynch 34, Wellington A. After significant neglect in housing, we’re starting to make progress on several fronts. So far we have stopped the previous government’s sell-off of state houses, and have added over 3,600 additional houses to the stock. There are currently 2,400 state houses under construction and 13,000 in the pipeline in total. We know we have an ever-growing waiting list, but it is possible to meet that demand. If the National government had built state houses at the pace of our targeted 1,600 per year we’d have an additional 14,400 state houses – that’s the entire waiting list gone. In terms of homelessness, we’re rolling out Housing First across New Zealand, and as at the end of October there were over 1,000 individuals and families engaged. I recognise that KiwiBuild homes will be out of reach for some families which is why we’re building state houses and making life better for renters by banning letting fees, and modernising rental laws. We’ve recently put $400m into progressive home ownership which will both lower deposits and mortgage repayments. We expect this will help thousands of families to buy their own homes. We’ve also made changes to the First Home Scheme, lowering the deposit required for a government-backed mortgage to 5%, and allowing family and friends to combine their $10,000 First Home Grant to buy their first home together. These changes will make a significant difference in helping families who have been locked out of the housing market. Q. How are you going to safeguard democratic freedoms in New Zealand in terms of overseas and internal lobby group interests funding election campaigns? Jennifer Ashby, 52, Dunedin A. We’ve already taken action to protect New Zealand from foreign interference in our elections by banning foreign donations to political parties and candidates. The Electoral Amendment Bill (No 2), which passed in early December, bans foreign donations over $50. This will reduce the risk of foreign money influencing our election outcomes. The bill also extends the requirement to include name and address details on election advertisements to apply to election advertisements in all mediums. This means that if someone wants to advertise online they need to say who they are, the same as if it was published in a newspaper. The minister of justice has also signalled a wider review of the Electoral Act after the 2020 general election. Q. While China funds and influences New Zealand and Australian politics, burgles and intimidates a critical academic, and keeps a million people in gulags, your government continues to snuggle up to the panda. I fully concede that the opposition would cheerfully do more than snuggle. Isn’t there a more principled path you could take? Paul Kiely, 39, Wellington A. Forgive me for pushing back on you there Paul! Although we have a solid and growing relationship, New Zealand and China are very different countries. There is a significant asymmetry in size, we have fundamentally different political systems and values, and on some issues we have quite different approaches. It is only natural that there are areas where we do not see eye-to-eye and when that occurs, we raise it. For example, New Zealand regularly discusses human right issues with China, including the situation in Xinjiang. New Zealand closely follows human rights issues in our region, and we share international concerns regarding the treatment of Uighurs. This is why I raised New Zealand’s concerns about the situation in Xinjiang with President Xi Jinping and Premier Li Keqiang during my visit to China in April. I also raised concerns with Premier Li during our meeting in Bangkok in November this year. New Zealand also joined a statement alongside 22 other countries expressing our concerns. The statement was delivered at a United Nations general assembly meeting in New York, and in in July, we signed a letter alongside 24 other countries, addressed to the president of the Human Rights Council and the UN High Commissioner for Human Rights. We will continue to raise our concerns directly with China and use these opportunities to explain the importance that New Zealand attaches to human rights standards. New Zealand also takes any allegations of foreign interference in New Zealand seriously. Some media speculation has focused on China, but we do not single out any specific actor. The important thing is that we have flexible and adequate protections. We have robust measures in place to protect our values, institutions and economy. Q. What is one thing you want to accomplish in your second term if you get re-elected in 2020? Justin Lindsay A. We haven’t set our policy agenda for the next election yet but the plan is to continue to build on the work we have done in the first term to deliver a better New Zealand for more people. But as finance minister, Grant Robertson, said when releasing the budget policy statement foreshadowing the direction of travel for the government, we will continue our focus on tackling the long-term challenges facing New Zealand while also investing to future proof the economy. The Budget 2020 priorities – which would carry work over into the next term - are: Just Transition:Supporting New Zealanders in the transition to a climate-resilient, sustainable, and low-emissions economy Future of Work: Enabling all New Zealanders to benefit from new technologies and lift productivity through innovation Māori and Pacific: Lifting Māori and Pacific incomes, skills, and opportunities Child Wellbeing: Reducing child poverty and improving child wellbeing Physical and Mental Wellbeing: Supporting improved health outcomes for all New Zealanders Q. Young women are so commonly treated with such disdain and in blatant forms of sexism amongst male school peers and teachers too. How will you battle New Zealand’s misogynistic culture that’s so very rampant in our schools? William B, 49, Auckland A. Rebel against it! We have to do what we can to call out bad behaviour, but also to have plenty of role models too. I can’t say I’ve been told our schools are any worse than anywhere else, but there’s almost always more to do to make sure our young women are treated fairly. Q. Why is New Zealand risking 1080 invading our food chain? Kris Davies, Otago, 33 A. We’re using all the tools we’ve got in the box to restore the dawn chorus and save Aotearoa’s precious kiwi, kākāpō, and whio from the predator crisis. 1080 is the best tool for large scale predator control and it dissolves quickly in the environment into harmless substances. We do want alternatives, but until we find them it’s the best we’ve got to combat predators. Q. What’s the best way to batter snapper, and how long do you deep fry it? Ian, 52, Tuakau A. What a controversial question Ian! Pan fried is best for delicious fresh snapper (in my opinion) but if you like a wee coating, I’m a big fan of a bit of panko crumb (dip in flour, then egg, then panko). Either way, when you come to cook it, use a rice bran oil (it takes higher temperatures well) and a dollop of butter. Go well! Simon Bridges, the leader of the opposition, was invited to answer readers’ questions but declined."
"
Share this...FacebookTwitterAt Twitter hurricane expert Philip Klotzbach recently tweeted a couple of charts which are certainly worthy of mentioning again.
The first one helps to tell us why some people may think Atlantic hurricanes have become more frequent. Today the detection and monitoring technology allows constant, 100% coverage, and so every single storm gets picked up.

Years ago a storm lasting less than two days probably did not get acknowledged and thus went unnamed before disappearing completely. Today, as the chart shows, many short-lived disturbances get a name and thus forever have a place in the 2named storm” statistic.
Gore’s hurricane hype is all fraud
Next there are all the claims of rapidly increasing damage from hurricanes, like Al Gore often hypes up. Of course as population and property grow along coastal area, the net dollar amount in damages indeed grows. But when the damage gets normalized, the trend looks very different, as shown by the following chart:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Above we see no increase total economic damage. Things are not getting worse as con-man Mr. Gore likes to claim.
Next Climate Depot here brings us another chart from Prof. Roger Peilke Jr of the University of Colorado in Boulder. It shows global weather-related disaster losses as a proportion of GDP:

Well, look at that! The chart above clearly tells us losses as a percent of GDP have halved over the past 27 years! Not something you’d expect after listening to the end-of-world rantings of Al Gore and the climate alarmist media.
According to Professor Pielke Jr.
The world is presently in an era of unusually low weather disasters. This holds for the weather phenomena that have historically caused the most damage: tropical cyclones, floods, tornadoes and drought. Given how weather events have become politicized in debates over climate change, some find this hard to believe…The US has seen a decrease of about 20% in both hurricane frequency and intensity at landfall since 1900…Data on floods, drought and tornadoes are similar in that they show little to no indication of becoming more severe or frequent…”
In fact the real damage so far inflicted by the (lack of) storms over the years has been to the climate alarmism and destruction industry itself.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany appears poised to make a fundamental course correction in its climate and energy policy.
Germany has long been a steadfast and influential proponent of “climate protection”. Also the country’s Potsdam Institute for Climate Impact Research (PIK), directed by climate doomsday professor Hans-Joachim Schellnhuber, has been one of the most influential European players in underpinning the science that has shaped Europe’s stringent  climate policy. The PIK has worked relentlessly in close partnership with the UN and North American climate institutes.
That construct, however, may soon be dealt a serious blow as one of Angela Merkel’s closest ministers, Peter Altmaier, told a group of industry leaders that Germany’s days of “going-it-alone on climate protection” are about to end — this according to the highly reputable online Die Welt here.
As Germany’s power industry reels from massive multi-billion euro record losses and power consumers get left in the dark by the hundreds of thousands as power supply gets cut off, the German government may finally be realizing that its climate and energy policy has only wrought tremendous pain and no benefit.
Daniel Wetzel of Die Welt writes:
In climate protection Germany has always played the roles of a front-runner and a model pupil. This now appears to be over.”
Last Friday at the ritzy Hotel Adlon in Berlin, Chancellery Minister Peter Altmaier spoke before a group of business leaders and CEOs, and reportedly reaped thunderous applause when he signaled “the expensive climate-political go-it-alone” by Germany “may soon be over“.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to Die Welt, Altmaier said: “I am totally convinced that the path of national targets is false” and what’s needed in the near future are “European and international targets“.
So far Germany’s approach has not worked, and has been sharply criticized by industry and environmental economists, who say it “has not saved one extra gram of CO2 under the roof of the European Emissions Trading.”
Whether Altmaier’s views get implemented by the Merkel government remains to be seen. However, the movement to relax the country’s draconian climate protection policies appear to be gaining steam. Die Welt writes that Altmaier’s position are also in agreement with the recently minted “energylab 2030” energy concept by leaders of Merkel’s CDU party:
Special national targets for climate protection are counter-productive and thus fundamentally should be dropped.”
Die Welt writes that the German government finally may have realized that its grandstanding target of reducing CO2 emissions twice as fast as the rest of Europe had been “over-ambitious”.
What could have led to these signals of fundamental course change? Die Welt’s Wetzel ends the article by writing:
Among experts it is sure that the federal government’s bold promise made in 2010 of cutting back CO2 emissions 40% by the end of the decade will be significantly missed.”
 
Share this...FacebookTwitter "
"The animal kingdom contains a huge diversity of colour patterns, from the near-perfect camouflage of the cuttlefish to the extravagant displays of birds of paradise. Evolution has shaped this diversity, but exactly which selective pressures are at work is still controversial.  While some theories propose that such patterns evolved specifically for camouflage, other theories link them to things like attracting mates, regulating body temperature and giving off warning signals.  One common pattern of animal colouration that has been the subject of this kind of debate is called countershading. Found across air, land and water on many different animals – from tigers to tuna – it features a darker skin or fur on the surface of the animal’s body that faces the sun, and a lighter colour on their underside.  Countershading has typically been considered beneficial for protection against ultraviolet. This is because the dark colour of the skin or fur is due to melanin, a pigment that strongly dissipates potentially damaging ultraviolet radiation. A dark body colour also often helps animals to gain more heat from sunlight.  Yet it has also long been suggested that this pattern of colouration evolved to enhance visual camouflage. This goes back to one of the oldest theories in the evolution of camouflage, originally put forward in the late 19th and early 20th centuries by the British evolutionary biologist Sir Edward Bagnall Poulton and the American artist/naturalist Abbott Thayer. They suggested that shading might counteract the effects of light and make animals harder to see.  But how could the countershading pattern contribute to visual camouflage? That was the question that we sought to answer in two recently published papers. To understand our work, start by considering how light interacts with objects and viewers.  In nature, more light comes from above than from below. It doesn’t matter whether we are talking about open country, below a dense canopy of trees or underwater. Three-dimensional objects with a uniform colour are brighter on the top and darker on the parts that are exposed to less light.   This interaction between shape and light provides a source of 3D information for our visual systems known as shape from shading. It is a powerful visual cue, exploited for centuries in art. Leonardo Da Vinci’s drawings of 3D figures show us just how sensitive we are to this kind of information, for example. In the picture on the right, Lady of Dishevelled Hair, notice how the forehead and top of the nose are bright, while the areas under the eyes, lips and chin are dark. It is the shading, using a technique called sfumato, that allows us to perceive the graceful shape of the woman’s head on the two-dimensional plane of the drawing.  Shading is also an important cue for animals. Predators can potentially use shape from shading to reveal the 3D shape of their prey, even if this victim is patterned or coloured to match their background.  Countershading is a possible defence. If an animal is darker on top and lighter below, this can offset shading from light and make it harder for predators to detect them. To give you an example, below are two photographs of an Actias luna caterpillar feeding on birch leaves. The first shows it back-uppermost, a position it does not favour, while the second shows it hanging below the branch, its most common pose.  The caterpillar is harder to spot in the second image because the effects of shading are counteracted by the countershading. It happens to be the very example that Abbott Thayer used to illustrate his theory more than 100 years ago. In reverse of the usual countershading rule, the caterpillar’s back is paler than its belly. This is because in its most common pose, hanging below the branch, its belly is uppermost.  A key question is what countershading pattern is the best for evading detection. The answer is complex, because it depends on the three-way interaction between object shape, the quality of light and the location of the viewer. Our interdisciplinary group of researchers from the universities of St Andrews, Abertay and Bristol developed a computational model to predict optimal shading in a given situation.  We simulated a three-dimensional world in which we could place an animal of our choice, and choose the location of the viewer. To take account of different habitats and lifestyles, we used realistic sun and sky lighting conditions which could be set up to emulate sunny or cloudy weather at any latitude, time of day or year.  We duly demonstrated that the best pattern to choose depends on weather, time of day and where in the world the animal is located. For example in a sunny location, an animal should have a sharp transition between their light and dark regions with a dark strip down the spine. The axis deer or chital (pictured), found across the Indian subcontinent, carries a good example of this kind of dark strip, which our work suggests might optimise camouflage in open grassland.  This is different to animals that live in woodland or under cloud and therefore experience less direct sunlight. They should have a more gradual transition between the light belly and dark back. A study from 2012 that looked at the coat patterns of ruminant animals supported this prediction. Our model should now allow experimenters to test just how specific camouflage needs to be to prove effective in different environments.  Finally a word on the other theories about the evolutionary reasons for countershading that we mentioned near the beginning, in relation to a related problem: why some animals turn to orient their bodies in a particular direction. Much has been made of the benefits of this for both regulating body temperature and protecting against ultraviolet light. Our model showed that all three theories make predictions that lead to similar animal orientations. This suggests that camouflage could be a crucial evolutionary explanation for how animals orient themselves as well."
"
Share this...FacebookTwitterAfter a record of more than 10 years without a major hurricane strike on the US, the NOAA must be getting hurricane desparate. The US climatology agency perhaps is demonstrating once more that records are not made by natural events occurring but rather by counting them differently.
At yesterday’s WeatherBell Daily Update, veteran meteorologist Joe Bastardi accused the NOAA of going out in the “middle of nowhere” to name anything that moves. Joe also discusses this further at today’s Daily Update.
It used to be that the NOAA stayed within certain Atlantic regions to count hurricanes – regions that positioned the hurricane for a possible US strike, or having an impact along the coast,  and with water surface temperatures 26°C and higher. But now Joe notes that they are looking at “eyesores near the Azores”, which have no chance of ever impacting the US coast and where water temperatures are just over 20°C.

Image cropped from Weatherbell Daily Update, April 18, 2017.
The veteran meteorologist suspects the NOAA may have abandoned the conventional hurricane counting standards, perhaps in order to sex up the statistics. Joe calls it “climate paranoia where every little thing that goes on turns into something bigger than it actually is.”
One could speculate: perhaps the NOAA wants to produce an awesome hurricane statistic this year in the hopes putting political climate science pressure on Washington. Politicized science unfortunately is something that has been going on quite some time at the US climate and weather agencies, critics say.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Bastardi calls the naming of a disturbance way out “in the middle of nowhere” over water that is 5°C under traditional hurricane-temperature waters “ridiculous”.
If the agency is just going to throw convention out the window, it might as well just start naming every North Atlantic storm that occurs every fall and winter off Europe. Why wait until April and stop at the Azores? Might as well include the North Sea and its heavy storms, too.
While the NOAA scurries to name any wind anomaly it can find, the situation in Europe continues to be bitter cold and nothing of sort you’d expect from global warming.
Some say that yesterday was the coldest April 18 on record, as snow and freezing temperatures gripped wide swaths of Central and Eastern Europe and Scandinavia.
The 5-10 day forecast shows no let-up in the frigid conditions.

Joe adds that the Alps will continue to be pounded my heavy snowfalls, thus defying predictions of the end of skiing at European ski resorts due to global warming. This year they’ll be skiing well into May.
 
Share this...FacebookTwitter "
"Corporations and governments around the world increasingly stand accused of causing or failing to prevent the damaging effects of climate change. Test cases are being filed in many countries to establish who is responsible and what action should be taken.  In 2016, after a series of particularly violent typhoons hit the Philippines, a group of Filipino citizens and civil organisations, including Greenpeace, accused 47 corporations of having significantly contributed to climate change, and called for them to be held accountable. Dubbed the “Carbon Majors”, these included the likes of Shell, BP and Chevron. The group asked the Philippines Human Rights Commission to investigate the Carbon Majors’ responsibility for alleged breaches of Filipinos’ human rights to “life, health, food, water, sanitation, adequate housing and self determination” that are associated with climate change. The Carbon Majors petition bases its claims on a study by climate expert Richard Heede which attributes “the lion’s share of cumulative global CO2 and methane emissions since the industrial revolution” to the world’s largest producers of crude oil, natural gas, coal and cement. In an unprecedented move, in December 2017, the commission agreed to investigate the Carbon Majors petition. Its powers are relatively modest: the commission can only make recommendations to the Filipino authorities and those found to have breached human rights, but it cannot award damages and it has no enforcement powers. Still, its decision could be a game changer for climate change litigation. In 2005, a group of Inuit petitioned the Inter-American Commission on Human Rights to assert the United States’ responsibility for human rights violations associated with climate change in the Arctic. But the petition was dismissed on procedural grounds. So what has changed since then? In recent years, a long string of United Nations Human Rights Council resolutions has emphasised the role of human rights in tackling climate change. The most recent international climate change treaty – the 2015 Paris Agreement – explicitly links human rights and the obligations of climate change law. These developments seem to have emboldened efforts to use human rights law as a means to tackle climate change.  Far from being an isolated complaint, the Carbon Majors petition is part of a global upsurge in climate change litigation. Yet, there are complex legal obstacles to attributing responsibility for breaches of human rights caused by climate change. First, applicants have to demonstrate that the obligations of corporations encompass human rights violations associated with the adverse effects of climate change. Second, they have to prove that a specific corporation has contributed to climate change, in such a way that amounts to a breach of human rights.  But a balance has to be struck between environmental protection and other legitimate interests, such as providing energy for consumers. However, John Knox, the United Nations Special Rapporteur on human rights and the environment, has pointed out that this cannot result in unjustified, foreseeable breaches of human rights. He has also suggested that improved scientific knowledge, such as that used to identify the Carbon Majors, has made it easier to trace the links between particular emissions and resulting harm. All of these elements come together in the Carbon Majors petition, which concerns harm caused by corporations that was largely foreseeable. Recent research suggests that corporations have long known about climate change and its likely consequences, but have failed to act on it. So the petition can be likened to ground-breaking litigation for harm caused by smoking tobacco or by driving cars. Before successful court cases were brought, liability for either of these hazardous activities was hard to establish. It was only when courts started to attribute responsibility that victims were provided with redress, and dedicated insurance schemes and liability regimes were created.  The decision of the Philippines Human Rights Commission to investigate the Carbon Majors petition is, then, potentially revolutionary. In 2018, the commission will carry out a series of fact-finding missions and public hearings in the Philippines, London and New York to establish whether multinational corporations can be held responsible for human rights violations associated with climate change and, if so, recommend ways to mitigate them. Far from being a symbolic gesture, this acknowledgement of multinationals’ role in causing climate change would be a primer, and could potentially spark a domino effect in climate change litigation elsewhere. Corporations are already being brought to court in the US, where the cities of New York and San Francisco are seeking to hold the world’s biggest oil companies responsible for present and future damage caused by climate change. All eyes are now on the Philippines to see what conclusions its Human Rights Commission will draw; for many, it has already made history by deciding to investigate the Carbon Majors petition in the first place."
nan
"
Share this...FacebookTwitterComprehensive Analysis Crushes
100% Renewable Energy Fantasy


While fully accepting the perspective that fossil fuel energy production and consumption must be dramatically reduced to save the planet from dangerous CO2-induced global warming, four Australian researchers have compiled a comprehensive rebuke of the premise that renewable energies (wind, solar, biomass, etc.) can feasibly supplant fossil fuels to become the dominant power source for the world.
The authors’ analysis zeroes in on the devastating conclusion that each and every one of the 24 previous attempts to substantiate the claim that a 100% renewable energy grid is achievable have failed to satisfy even the most basic feasibility criteria.
Further, a commitment to all-renewable energy sources means there will need to be a massive and unprecedented increase in grid extensions (for new power distribution systems), as well as realized plans for extreme and unrealistic land-use expansion (for biomass production especially) that would threaten ecosystem preservation, biodiversity, and land conservation efforts.
From a humanitarian standpoint, it is conceded that attempts to “decarbonize” energy sources seriously hampers efforts to provide electricity generation to the world’s most impoverished people. In fact, Heard and colleagues conclude that a commitment to renewable-only energy supplies “appears diametrically opposed to [the] eradication of poverty … and social justice for indigenous people.”
Again, these damning conclusions have been advanced by researchers avidly committed to reducing or eliminating fossil fuel energy production for the sake of mitigating global warming.  And yet even staunch renewable energy advocates cannot find a way to substantiate the claim that 100% renewable power generation is feasible.
A very brief summation of the highlights from the analysis — as well as the link to the full paper — is provided below.

Heard et al., 2017
Burden Of Proof: A Comprehensive Review Of The
Feasibility Of 100% Renewable-Electricity Systems

Of 24 Analyses Of The Prospects Of Achieving 100% Renewable Energy, Zero Met Basic Feasibility Criteria

“While many modelled scenarios have been published claiming to show that a 100% renewable electricity system is achievable, there is no empirical or historical evidence that demonstrates that such systems are in fact feasible. Of the studies published to date, 24 have forecast regional, national or global energy requirements at sufficient detail to be considered potentially credible. We critically review these studies using four novel feasibility criteria for reliable electricity systems needed to meet electricity demand this century. [N]one of the 24 studies provides convincing evidence that these basic feasibility criteria can be met. Of a maximum possible unweighted feasibility score of seven, the highest score for any one study was four. … On the basis of this review, efforts to date seem to have substantially underestimated the challenge and delayed the identification and implementation of effective and comprehensive decarbonization pathways.”

Reducing Fossil Fuel Consumption Will ‘Raise Problems’ For ‘Poverty Alleviation’

“Our review of the 100%-renewable-scenario literature raises substantial concerns. The widespread assumptions of deep cuts in primary energy consumption defy historical experience, are generally inconsistent with realistic projections, and would likely raise problems for developing countries in meeting goals of poverty alleviation.”
“[E]conomic growth and poverty reduction in developing countries is crucially dependent on energy availability. A reduction in primary energy is an unlikely pathway to achieve these humanitarian goals. To move beyond subsistence economies, developing nations must accumulate the necessary infrastructure materially concentrated around cement and steel. That energy-intensive process likely brings with it a minimum threshold of energy intensity for development. Across a collation of 20 separately modelled scenarios of primary energy for both India and China, Blanford et al. found a range of energy-growth pathways from approximately +50 to +200% from 2005 to 2030. None of those scenarios analyzed for these two countries — with a combined population of almost 2.5 billion people — suggested static or reduced primary energy consumption.”

100% Renewable Energy Demands Unrealistic Grid Extensions, Land-Use Commitments

“The remaining feasibility gaps lie in the largely ignored, yet essential requirements for expanded transmission and enhanced distribution systems, both to transport electricity from more sources over greater distances, and to maintain stable system operations. Fürsch et al. suggested that a cost-optimized transmission network to meet a target of 80% renewables in Europe by 2050 would demand an additional 228,000 km of transmission grid extensions, a +76% addition compared to the base network. … Rodríguez et al. [83] concluded that to obtain 98% of the potential benefit of grid integration for renewables would require long-distance interconnector capacities that are 5.7 times larger than current capacities. Becker et al. found that an optimal four-fold increase in today’s transmission capacity would need to be installed in the thirty years from 2020 to 2050. An expansion of that scale is no mere detail to be ignored.”
“Perhaps our most concerning finding relates to the dependence of 100% renewable scenarios on biomass. The British scenario is a typical example; even with the assumption of a 54% reduction in primary energy consumption, biomass requires 4.1 million ha [hectares] of land to be committed to the growing of grasses, short-rotation forestry and coppice crops (17% of UK land area). … The WWF scenario demanded up to 250 million ha [hectares] for biomass production for energy, along with another 4.5 billion m3 of biomass from existing production forests to meet a scenario of an absolute reduction in primary energy from today.”
“[I]n applying so many assumptions to deliver changes far beyond historical precedents, the failure in any or several of these assumptions regarding energy efficiency, electrification or flexible load would nullify the proposed supply system. As such, these systems present a fragile pathway, being conceived to power scenarios that do not exist and likely never will.”

Wind-Watch.Org Image “Steel Winds“

Summarizing Statements:  Proposition Of 100% Renewable Energy Must Be…’Discarded’

1.      “To date, efforts to assess the viability of 100% renewable systems, taking into account aspects such as financial cost, social acceptance, pace of roll-out, land use, and materials consumption, have substantially underestimated the challenge of excising fossil fuels from our energy supplies. This desire to push the 100%-renewable ideal without critical evaluation has ironically delayed the identification and implementation of effective and comprehensive decarbonization pathways. We argue that the early exclusion of other forms of technology from plans to decarbonize the global electricity supply is unsupportable, and arguably reckless.”
2.      “The realization of 100% renewable electricity (and energy more broadly) appears diametrically opposed to other critical sustainability issues such as eradication of poverty, land conservation and reduced ecological footprints, reduction in air pollution, preservation of biodiversity, and social justice for indigenous people.”
3.     “The evidence from these studies for the proposition of 100% renewable electricity must therefore be heavily discounted, modified or discarded.”
 
Share this...FacebookTwitter "
"Wartime shipwrecks such as the USS Juneau – recently discovered in the Pacific Ocean by philanthropist Paul Allen and his team – are of great interest to both military historians and the general public. The USS Juneau was holed by a Japanese torpedo off the Solomon Islands in November 1942, and sank in more than 13,000 feet of water with the loss of 687 lives. Its discovery offers a hugely valuable insight into the fate of both the ship and its crew. Many such wrecks lie in extremely deep, relatively clear waters and are the legacy of naval battles fought far out to sea. But some of the technologies and methods that are being used to locate and identify such sites are now being employed by scientists in shallower, sediment-rich UK waters for similar – and very different – purposes.  During both world wars, Britain relied heavily on shipping convoys to supply the nation via well-established maritime routes into major ports such as Liverpool, Cardiff and Bristol. But these busy marine “corridors” were also well known to enemy forces, and losses due to German U-boat attacks, mines and collisions due to enforced “blackouts” in the Irish Sea were significant throughout both conflicts. There are more than 200 such wreck sites around Wales and many have yet to be examined in any great detail. Since 2014, via the SEACAMS project funded by the Wales European Funding Office (WEFO), scientists from the School of Ocean Sciences at Bangor University have been using their research vessel Prince Madog – which is equipped with state-of-the-art multibeam sonar technology – to locate and survey vessels from both world wars. And in the Irish Sea alone, there are plenty to choose from.  The modern multibeam sonar systems on the Prince Madog generate very high resolution, three-dimensional models of the seafloor as the research vessel moves through the water over it. Depending on conditions and the specific systems used, these models can allow surveyors and scientists to identify objects at near centimetre scale. In water depths of 100 metres, typically found in the Irish Sea, researchers are generating models and images of wrecks that can help marine archaeologists to confirm their identity and even provide evidence of their demise. So far, more than 70 individual sites have been studied and it’s hoped that the project will survey around 100 new wreck sites this year.  While these wartime relics can provide valuable information to historians and archaeologists, they may also help lead to the birth of a new industry. The data being collected are providing scientists with unique insights into how these wrecks influence physical and biological processes in the ocean and this information is now being used to support the ambitions of the marine renewable energy (MRE) sector via research and development projects with developers such as Minesto in North Wales and Wave Hub in Pembrokeshire.   A number of MRE projects –– some being planned, some already underway – aim to capitalise on Wales’ excellent wave and tidal resources to create a sustainable energy supply. To assist in this, scientists at Bangor are now using shipwrecks as models and laboratories for predicting what will happen when key MRE-related infrastructure, such as foundations, turbines and cabling, are placed on the seabed at various locations.   Wrecks provide information on how the tide and currents have removed or deposited sediments and how the presence of these structures on the seabed have influenced these processes over time. Researchers are also looking at how these structures can act as artificial reefs, potentially increasing the number of fish in an area and attracting whales, dolphins and diving birds. Through repeat sonar surveys, the research is also examining how different wrecks are degrading and how these vessels may ultimately pose a risk of pollution to nearby coastlines. The data gathered will be hugely useful to those behind MRE projects, allowing them to better predict how green energy infrastructure will effect – and be affected by – their undersea locations. As with the surveys underway in the South Pacific, such as the one that discovered the USS Juneau, the research being conducted in the Irish Sea is also driven by a desire to improve our understanding of past conflicts.  The Heritage Lottery funded project, Commemorating the Forgotten U-boat War around the Welsh Coast, 1914-18, for example, is being led by the Royal Commission on the Ancient and Historical Monuments in Wales in partnership with Bangor University and the Nautical Archaeology Society. It aims to highlight the fact that not all World War I battles and losses occurred along the Western Front – indeed, many raged within sight and sound of the UK coastline.  They were also truly international incidents. Many of the ships sunk were British, French, Irish, Norwegian, Portuguese and Russian – with crews from all over the world. Many German vessels were sunk, too. The surveys are also solving scores of mysteries. Of the shipwreck sites in the Irish Sea examined so far, we have found that 40% of the vessels have been incorrectly identified on maps and charts. Using the detailed models produced by the sonar technology – as well as naval archives, shipyard records and a little detective work – we hopefully can ensure these mistakes are corrected and that we know exactly what was sunk where. This will give us a far clearer picture of what now lies beneath the waves – and what such wrecks can tell us about the turbulent past of these oceans."
"Plants have become an unlikely subject of political debate. Many projections suggest that burning fossil fuels and the resulting climate change will make it harder to grow enough food for everyone in the coming decades. But some groups opposed to limiting our emissions claim that higher levels of carbon dioxide (CO₂) will boost plants’ photosynthesis and so increase food production.  New research published in Science suggests that predicting the effects of increasing CO₂ levels on plant growth may actually be more complicated than anyone had expected. To understand what the researchers have found out requires a bit of background information about photosynthesis. This is the process that uses light energy to power the conversion of CO₂ into the sugars that fuel plant growth and ultimately provide the food we depend on. Unfortunately, photosynthesis is flawed. Molecules of CO₂ and oxygen are similar shapes and the key mechanism that harvests CO₂, an enzyme with the catchy name of RuBisCO, sometimes mistakes an oxygen molecule for one of CO₂. This wasn’t a problem when RuBisCO first evolved. But about 30m years ago CO₂ levels in the atmosphere dropped to less than one-third of what they had been. With less CO₂ around, plants began mistakenly trying to harvest oxygen molecules more often. Today this is often a substantial drain upon a plant’s energy and resources. As it gets hotter, RuBisCO becomes even more prone to errors. Water also evaporates faster, forcing plants to take measures to avoid drying out. Unfortunately, stopping water getting out of their leaves also stops CO₂ getting in and, as RuBisCO becomes starved of CO₂, it wastes more and more of the plant’s resources by using oxygen instead. At 25°C, this can consume one-quarter of what the plant produces – and the problem becomes more extreme as temperatures rise further. However, some plants developed a way to avoid the problem by pumping CO₂ to the cells where the RuBisCO is located to turbocharge photosynthesis. These are known as C4 plants, as opposed to normal C3 plants which can’t do this. C4 plants can be much more productive, especially under hot and dry conditions. They came to dominate Earth’s tropical grasslands from 5m to 10m years ago, probably because the world became drier at this time and their water use is more efficient. Maize (corn) and sugar cane are C4 plants but most crops are not, although a project initially funded by the Bill and Melinda Gates Foundation has been seeking to improve yields in rice by adding C4 machinery to it. Most models of how plant growth and crop yields will be affected by the CO₂ released by burning fossil fuels have assumed that regular C3 plants may perform better. Meanwhile, the RuBisCO in C4 plants already gets enough CO₂ and so increases should have little effect on them. This has been supported by previous short-term studies. The new Science paper reports data from a project that has been comparing C3 and C4 plants for the past 20 years. Their findings are surprising. As was expected, for the first ten years, C3 grasses grown under extra CO₂ did better – but their C4 equivalents did not. However, in the second decade of the experiment the situation reversed, with the C3 plants producing less biomass under higher levels of CO₂ and the C4 plants producing more. It seems that this perplexing result may be because as time went by, less nitrogen was available to fertilise growth of plants in the C3 plots and more in the C4 plots. So the effect was not just due to the plants themselves but also to their interactions with the chemistry of the soil and its microbes. These results suggest that the way that changes in CO₂ affect established ecosystems are likely to be complex and hard to predict. They may hint that, as CO₂ in the atmosphere increases, C4 tropical grasslands could perhaps absorb more carbon than expected, and forests, which are predominantly C3, might absorb less. But the exact picture is likely to depend on local conditions. What this means for food production may be more straightforward and less comforting than at first glance. These results are from grasses that survive and continue to grow year on year. But current cereal crops are “annual plants” that die after one season and have to be replanted. As a result, they don’t have the opportunity to build up the soil interactions that seem to have boosted growth of the C4 plants in the experiment. We can’t expect that our food security problems will be solved by C4 crop yields increasing in response to CO₂ as they did in the experiment. Similarly, the eventual fall in biomass seen in the C3 plots shouldn’t happen in C3 annual crops. But, as we know, C3 plants waste a lot more resources at higher temperatures, so any increase in photosynthesis from rising CO₂ levels seems likely to be at least cancelled out by the effects of the global warming it will cause. And that’s without factoring in changes to rainfall patterns such as more frequent droughts. Solutions that seem to be too good to be true generally are – and, for the moment, that still seems to be the case for the idea that CO₂ enhanced crop yields will feed the world."
"Temperatures in the Arabian Peninsula, Iraq and Iran could soar to uninhabitable levels during the course of this century, according to a new study.  Already, places such as Al Ain and Kuwait can experience temperatures of up to 52℃. But the study predicts that the effects of global warming and the increase in greenhouse gases could push the average temperature up to the mid 50℃s or lower 60℃s.  Currently, many residents of the gulf can find refuge in air-conditioned homes, shopping centres and cars. But as temperatures increase, so does the need for cheaper, more sustainable, less energy-intensive ways of staying cool. Fortunately, the region’s past offers a rich source of architectural inspiration.  Historically, the inhabitants of the Gulf were either farmers living near oases in agricultural villages, Bedouins living in tents in the desert, or urban dwellers living in cities. Given the global trend toward urbanisation, it makes sense to take a closer look at how the latter group coped with the heat.  Traditional buildings in the gulf’s cities and villages are designed to maximise shading, reduce thermal gain of the sun radiation, regulate building temperature and enhance air circulation. These effects are achieved through a clever combination of building materials, placement and design. Natural materials such as limestone and mud – in some cases mixed with local desert plants – provide a construction material with the capacity to regulate building temperatures. The material itself is capable of absorbing moisture in humid conditions, which can later evaporate during hot and sunny days to provide a slight cooling effect. And the sandy texture and colour of the buildings reduces both the absorption and emission of radiating heat.  Traditional buildings are placed adjacent to one another, with narrow roads and alleyways in between. This means that the ratio of the area exposed to the sun relative to the building’s total volume is minimised, which in turn limits heat increases during the day time.  Many traditional structures feature an internal courtyard, often containing trees and a water well. The courtyard is typically surrounded by rooms or walls on all sides, maximising the area in shadow throughout the day and creating a space for socialising in the evenings. When the sun bears down at midday, the courtyard works as a chimney for the hot air to rise and be replaced by cooler air from the surroundings rooms – this promotes air circulation and creates a cooling effect. Glass is not a common material in traditional buildings. A typical room has two external windows: one very small window, located high up the wall, which is kept open to allow air to circulate and let in natural light. The second is larger, and closed by wooden shutters, with grooves to allow the flow of air inside the room while maintaining privacy. Rooms also have windows towards the internal courtyard for improved cooling. Finally, a mushrabiya – a projecting window with carved wooden latticework, typically located on the upper stories of a building – allowed for better air circulation and a view.  Some buildings also have a wind tower, which creates natural ventilation by circulating cool air. The narrow streets allowed them to be covered in most cases by light material from date palm trees to avoid direct sun light. This allowed for better air circulation between streets and courtyards of buildings, via the rooms. All of these features helped to keep traditional buildings cool. But the question remains, how can we apply them in today’s cities?  Modern buildings in the Gulf are built predominantly from reflective glass, concrete and asphalt, which means that temperatures really soar during day time, due to high reflection or high absorption and emission of radiated heat.  But with research and improvements in building and pavement materials, designs, urban planning, insulation and the use of renewable energy, cities in the Gulf could maintain a comfortable lifestyle, with a lower level of carbon emission and fossil fuel use.  For example, Masdar city in the United Arab Emirates has attempted to combine some of the lessons learned from the past with modern technologies by increasing shaded areas, creating narrow streets and constructing a wind tower.  The use of insulation would also reduce the need for air conditioning and lower electricity consumption. Meanwhile, natural or new materials which absorb moisture and increase thermal capacity (meaning the material can maintain lower temperatures in higher heats) could regulate heat gain and facilitate the natural cooling process.  I have developed a new patented technology to regulate building temperatures in extremely hot conditions using a heat sink in the ground. The heat sink will allow the ground to exchange heat with the envelope of the building, thereby reducing its thermal gain on hot days.  In recent years, the Gulf countries have sat up and paid attention to renewable energy and sustainability measures. Research and development is expected to progress further in this area if people are to live comfortably at the expected high levels of temperature, while reducing their dependency on fossil fuel consumption and carbon emissions. Read more: Adrian Pitts, professor of sustainable architecture at the University of Huddersfield, looks at the impact on cities."
"Over the past few years there has been exponential growth in clean energy investment – while fossil fuel assets are increasingly considered to be risky. Yet, on February 6, the European Investment Bank, the EU’s long-term lending institution, voted to provide a €1.5 billion loan to the controversial Trans Adriatic Pipeline (TAP). The TAP is the Western part of a larger Southern Gas Corridor proposal that would ultimately connect a large gas field in the Caspian Sea to Italy, crossing through Azerbaijan, Turkey, Greece and Albania. And while gas might be cleaner than coal, it’s still a fossil fuel.  So how does the EU’s support for this major project fit in with its supposed goal of addressing climate change? A key problem is the message this sends to the private sector, where renewable energy is increasingly seen as a good investment. Technologies once perceived as too risky and too expensive are now delivering worthwhile returns thanks to reduced costs and breakthroughs in energy storage. The price of electricity generated by solar, wind or hydro is now comparable with the national grid. Over the past decade, investor meetings have shifted from discussing whether the transition to a low carbon economy will start before 2050, to whether it will be completed in the same period.  But there is still not enough money being spent on renewables. While clean energy investment in 2017 topped US$300 billion for the fourth year in a row, this is far short of what is needed to unlock the technology revolution necessary to tackle climate change. There is clearly a gap between what is required and what is being delivered.  The private sector will continue to invest significant capital into energy projects over the next few decades, so one issue facing policy makers is how to influence investors away from fossil fuels and towards renewable projects. To really scale up investment into renewable infrastructure, long-term and stable policy is required – which investors see as clearly lacking.  By funding the Trans Adriatic Pipeline, the EU’s investment bank is hardly signalling to the private sector that governments are committed to a green energy transition.   If Europe really was to follow through and successfully switch to green energy – and such a transition is partially underway – then the pipeline project may even represent a risk to public finances. Studies on climate change point to the need for a greater sense of urgency and ambition and, to stay within its “carbon budget” under current agreed emissions targets, the EU needs to be fossil fuel free by 2030.  So any large oil and gas infrastructure projects with investment returns beyond 2030 are saddled with risk. In just a decade or two, super-cheap solar and wind power could mean that gas pipelines such as TAP would no longer make financial sense and would become worthless “stranded assets”. Yet TAP backers are touting economic benefits for countries such as Albania extending to 2068 – well beyond the date when Europe must entirely ditch fossil fuels. The EU’s official stance is to hail natural gas as a cleaner “bridge fuel” between coal and renewables. But high leakage rates and the potent warming impact of methane (the primary constituent of natural gas) means that the Southern Gas Corridor’s climate footprint may be as large, or larger, than equivalent coal. Abundant natural gas is also highly likely to delay the deployment of renewable technologies.  For the first decade of this century Europe prided itself on leading the political debate on tackling climate change. Now, it appears to be losing its boldness. To drive through a new technology revolution, the public sector needs to lead from the front and take bold decisions about its energy strategy. A gas pipeline is not a technology of the future. If California can release YouTube videos describing the importance of considering stranded assets during this energy transition, and New York City can announce plans to divest from fossil fuels, then maybe it is time for the EU to turn off the TAP."
"
Share this...FacebookTwitterAnd here I don’t mean the frosty atmosphere created by fat boy, Big Kim in NoKo.
Our skeptic in Japan, Kirye, informs us at Twitter that Tokyo saw its coldest August 11 in almost 60 years. She writes:

Not only Japan, Western Europe and USA are seeing cold weather, but New Zealand as well has been having unusually cold weather. According to the sott.net here, “New Zealand is currently experiencing its coldest winter since 2009” as the island country has been hit by heavy rainfall.
Typhoons trending downward over past 66 years
Kirye also brought up another interesting fact which once again contradicts all the climate alarmism hysteria. According to the Japanese Meteorological Association (JMA), the number of typhoons since 1951 has been trending DOWNWARD.

You can view a much better image here.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Meanwhile the number of typhoon landings for Japan is dead flat. There’s been no change despite the rise in atmospheric CO2 concentration.
All this is right in line with hurricane activity in the Atlantic, and especially those hitting the USA:

The above graph shows the number of hurricanes that formed in the North Atlantic Ocean each year from 1878 to 2015, along with the number that made landfall in the United States. The orange curve shows how the total count in the green curve can be adjusted to attempt to account for the lack of aircraft and satellite observations in early years. All three curves have been smoothed using a five-year average, plotted at the middle year. The most recent average (2011–2015) is plotted at 2013. Source: here. 
Global tropical cyclone activity falling over past 25 years
Tropical storms as measured by the Accumulated Cyclone Energy (ACE) globally also shows no trend, and thus flat out contradict claims that high CO2 concentrations in the atmosphere lead to higher cyclone activity:

Seasonal global accumulated cyclone energy (ACE) from 1972 – 2015. Black dots are for the Northern Hemisphere only. Each dot represents a 24 month running sum. Source of chart: Atmo 336.
If anything, the trend for the past 25 years has been significantly downward. Overall this all tells us that cyclone activity is linked far more to ocean cycles than to trace greenhouse gases – and is so by one or two orders of magnitude.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Germany-based European Institute For Climate and Energy (EIKE) alerts here that it is now obvious nobody really knows what the real mean global temperature is, and that claims that the planet is the hottest it’s been since measurements began are not making any sense.
In 1995 it was 15.4°C. Today we are told it is 14.8°C – a new record!
For decades it had been assumed that the globe’s normal 20th century mean temperature was 15°C. But suddenly this year it is reported all over the media that 2016 reached a new record: 14.8°C!

ZDF weather moderator Benjamin Stöwe announced in January, 2017, that at 14.8°C 2016 had been the “hottest year” since measurements began. It’s no typo. Image: ZDF
14.8°C in 2016?
In 1995 Spiegel and many others, citing James Hansen, reported that the global temperature had reached a “record” 15.4°C!
This led EIKE Vice President Michael Limburg to write: “The warmest year since the start of measurements is revealed to be significantly cooler than the 1995 mean value, which was 15.4°C.”
Readers by now are certainly asking themselves what the hell is going on here!
“Something astonishing”
It turns out that researchers of the Klimamanifestes von Heiligenroth put out a video that examines the absolute temperature value of the globe instead of the anomaly. And what they found in the literature, Limburg writes, “is something astonishing“:
The hottest year ever 2016 (14.8°C) is in fact 0.6°C cooler than 1995 (15.4°C)!
The video here sums up the history of the normal absolute global mean temperature, which for decades had been in fact assumed to be 15°C. Here’s the chronology of what literature kept stating in the past:
1896: Svante Arrhenius, 15.0°C
1975: Stephen H. Schneider, 15.0°C
1979: Christian Schönwiese, 15.0°C
1981: James Hansen, 15.0°C
1986: Spiegel, 15°C
1988: Hansen, NYT, 15°C
1988/1989: Der Spiegel, James Hansen, 15.4°C
1995: no publications found under 15°C.
1995: Spiegel, citing James Hansen, 15.4°C (see image below)

1995 global temperature: 15.4°C. Image cropped from Spiegel 
2017: WMO, ZDF, Spiegel, 14.8°C (“record high”)
Up to 1995 the normal global mean temperature had always been assumed to be 15°C and its rise to 15.5°C was considered a sign of rapid warming.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Spiegel’s tangled web
After 1995 the chaos surrounding the determination of the absolute mean global temperature seems to begin, and no one knows what happened. Today the WMO and ZDF German television are suddenly telling the public that the global temperature in 2016 was 14.8°C, “a new record”!
Earlier in 2002, Spiegel reported a northern hemisphere mean temperature of 15.7°C. That was the last time Spiegel printed the absolute global mean temperature.
With all the confusion since 1995, Spiegel in its print edition in 2015 dropped altogether the absolute temperature and switched to using the mean temperature anomaly, and this time from a whole new data source: Japan Meteorological Agency. The main thing was to show readers a rapidly increasing temperatures, details and contradictions be damned.
Then on January 18, 2017, the online Spiegel too suddenly switched to the new 14°C base, proclaiming a new all time record of 14.8°C (in 1995 they reported 15.4°C)!

Image cropped from Spiegel online.
Unwittingly, Spiegel has in effect exposed the widespread confusion concerning absolute global mean temperature and the fact that it seems to have been rolled back 1°C, from 15°C to 14°C. It seems no one knows what it really is.
After Spiegel editor Marco Evers had been asked repeatedly by e-mail to explain what was going on, he tersely wrote back (see below) that he saw “no reason to pursue the correspondence further” and that they relied on “peer-reviewed literature, consensus documents from institutions like the IPCC, as well as NASA and the WMO“.

Obviously there’s complete confusion as to what the globe’s absolute mean temperature should be. Depending on the source, it is either 14.8°C (WMO), or 15.8°C (NASA). Here we are talking about a whole degree difference from institutions that claim the ability to measure global temperature down to a few hundredths of a degree.
Would the real temperature please stand up!
It’s such a mess that in its April 1, 2017, edition Spiegel even stopped showing a temperature chart altogether when reporting on the “new 2016 record”, choosing instead to simply bang on about the “hottest year ever”, the Klimamanifest video tells us.
Faking fake news
It’s little wonder some readers recently have been intensively questioning Spiegel over the huge discrepancy, especially at Twitter, where the German weekly refuses to provide an answer. Obviously the matter is highly embarrassing for Spiegel.
The climate reporting situation obviously has gotten so bad that when the media start faking fake news, the truth comes out!
Clearly Spiegel had been led around by the nose by a bunch of sloppy scientists for decades.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterUPDATE 4: See animation here.
UPDATE 3: Dr. Roy Spencer thinks Miami may have averted disaster.
UPDATE 2: Euro model shows Irma eye tracking along Florida west coast. The NAM model showing eye moving along OFF west coast.
UPDATE 1: Levi Cowan of Tropical Tidbits reports at Twitter that the forecast path has shifted westward, something he calls “some good news for the Miami area”. Let’s hope for more positive developments.
====================================
All the models agree that Irma will almost certainly hit Florida directly and that it would take a miracle to divert the storm away. It’s going to hit.
A number of factors could have prevented Irma from reaching the proportions and magnitudes that it has grown to, but unfortunately luck has played against Floridians and others in the region.
The steering troughs from the High out in the Atlantic and the Low plunging down across the southeast USA could have directed the storm out to sea, if only they had been positioned just a few dozen miles differently.
Shearing could have been stronger and weakened the storm, or the storm might yet track closer to Cuba, causing it to weaken some. But that is all not to be, and this time the die came up snake eyes. Instead, all factors unfolded in total favor of Irma in almost every way possible. The result: a very powerful hurricane, one we don’t see very often.

Levi Cowan at Tropical Tidbits here explained late Thursday evening the factors driving the storm, and the likely path in the days ahead. It really couldn’t be worse and more unfortunate.
The damage is going to be great. Hurricane conditions could extend up into southern Georgia. High winds and storm surges will be widespread along all coastlines on both sides of the Florida peninsula where many metropolitan areas happen to be sitting.

Map as per 2010 US Census showing cities with a population greater than 150,000, and their respective metro areas. Image by: Comayagua99 at English Wikipedia, CC BY-SA 3.0
Damage per square mile
Florida’s area is some 65,700 square miles and has a population of nearly 19 million, most of whom living in coastal areas. Property and infrastructure are naturally concentrated there and thus the state’s metropolitan areas will see tens of millions of dollars in damage per square mile, with some places possibly seeing damages in the hundreds of millions per square mile. Like Houston did.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Especially the areas along the coast, with their ports, harbors, high-rises, transportation facilities and extensive infrastructure, will see severe damage from high winds and storm surges. Rural areas of course will see less damage per square mile.
If half (conservative) of Florida’s area (32,000 sq mi) gets hit hard by surge and/or wind conditions with an average damage of $20 million per square mile (rough estimate), then we are looking at a potential of more than $600 billion in damage for Florida alone.
Now add the damage already done in the Caribbean, plus what will happen in Georgia and beyond. We are getting close to the astronomical sum of a trillion dollars.
There is still some time to get property out of harm’s way, but it’s just about run out. Residents need to focus on getting the hell out of the way and saving their lives.
Expect hysterical and irrational demands
Expect global warming alarmists to seize on the final damage tally, no matter what it turns out to be. They’ll be hysterical, and will irrationally demand that leaders implement multi-trillion dollar “climate protection” measures mostly aimed at reducing greenhouse gases, especially CO2 emissions from burning fossil fuels.
The problem with these measures, however, is that there is no evidence that they would have any impact on future hurricanes – none! Hurricanes have always occurred, and always will no matter how ecologically pious we may become.
In fact a look at the past shows that hurricane activity trends have been decreasing over the past 140 years while CO2 emissions rose:

Hurricane activity has been falling over the past 140 years. CO2 curve added by NoTricksZone (not necessarily to scale).
If climate and hurricanes are indeed related to CO2, as alarmist and activist scientists insist, then the data are telling us to emit more and not less. Of course the CO2-hurricane-activity-relationship is silly, and is no solution.
Complacency after 12 years of low activity
The best advice here would be to invest the money into better infrastructure and more sensible urban planning. That lesson was learned long ago, but obviously got forgotten along the way.
Twelve years of no major hurricane strikes and decreasing activity likely led to just a little too much complacency.
 
Share this...FacebookTwitter "
"The Persian Gulf is already one of the hottest parts of the world, but by the end of the century increasing heat combined with intense humidity will make the region too hot for habitation, according to research published in Nature Climate Change. Heating and air conditioning currently permit humans to live everywhere from Siberia to the Sahara. However the extreme heatwaves predicted for the Gulf, where temperatures will regularly hit 50℃ or even 60℃, will reach the limits of the thermal adaptation that buildings can provide.  Our ancestors lived without the sophisticated thermal control systems we typically use in modern buildings; they implicitly used different “bioclimatic designs”, such as natural ventilation or south-facing windows, and these skills are still valuable in many climates today. But the latest data suggest this will not be enough.  So is there a future for habitation in the hottest regions of the world? It seems mass migration is less likely than staying put and taking on the challenge. However figuring out how to live comfortably and sustainably while it’s hot enough to fry an egg on the sidewalk may provide a fillip for environmentally sensitive design and urban development throughout the world. The climate is a problem but does offer some opportunities. The amount of sunshine available means there should be no shortage of solar electricity, though we need to develop efficient storage systems too. We could also take advantage of day-to-night ambient temperature variations using “thermal mass” techniques to even out temperature fluctuations. We will have to make significant changes to building design – highly glazed structures that soak up heat will become architectural dinosaurs. Traditional ideas from hot regions of the world will resurface: thick walls giving thermal stability (but enhanced with smarter materials such as composites with layers of insulation or perhaps embedded “phase-change” materials), used together with small windows. Building surfaces will need to be coated with smart materials that reflect heat gain – these already exist and researchers have looked at their perfomance in the hot summers of cities such as Athens.  We’ll need to optimise where and when we occupy buildings, to seek out the coolest spots and take advantage of less intense night time conditions. We may find ourselves living partly underground in order to benefit from lower and more stable temperatures to be found a few metres below the Earth’s surface.  In intense heat, finding some shade becomes essential. Buildings, streets, services and even entire transportation systems need to be entirely shaded or even fully underground. Some of these features are already showcased in the Masdar City development in Abu Dhabi, though the project (which had significant design input from Norman Foster and partners) is not yet fully operational. Expect an air conditioning boom. This will cost a lot both to build and to operate, and we’ll have to come up with systems specially designed for extreme temperatures. The thermodynamics of current designs which rely on temperature differences between heat absorption and heat rejection mean it would be very difficult to achieve sufficient and efficient heat removal as these change and narrow.  One opportunity would be to use the Earth or the sea/rivers as “heat sinks”, rather than the external air, as these will be at lower temperatures and have the ability to absorb the heat, though perhaps with as yet unknown long term effects. It is also likely that air conditioning might most effectively be used during the night-time to pre-cool the building; night-time air temperatures will allow more efficient refrigeration. Urban design and the ways in which cities are used at time of extreme heat will also need to be considered. Moving around outdoors without protection could become as unimaginable as walking unprotected from a polar research station in winter.  This obviously causes significant problems for those who must work outside: places of refuge may need to be constructed and the very act of building may need to be restricted to the “winter” (or rather slightly cooler) months. Construction products will also be obliged to change in order to cope with more extreme thermal stresses and expansion effects. The shape of cities and the massing of their major buildings will change so that groupings offer a degree of self-protection. Streets will be designed to optimise shading and, when available, cooling air ventilation. The spaces between buildings will need to be carefully designed and uses (such as what might happen underground) considered alongside services provided to citizens. Shopping malls could be submerged and used as links between areas, just as the underground streets found in northern latitude cities like Montreal are used in winter. Cities themselves may shift away from coastal to inland zones due to the problematic combination of high temperatures with high humidities near to water masses. In drier atmospheres, technologies such as evaporative cooling (in their simplest form fountains and water sprays) can be used to reduce temperature.  A technological alternative to this might be the use of moisture absorbing materials (regenerated desiccants) to dehumidify the atmosphere, but this would be a significant and complex task on the scale required. Moving whole cities can only be a long term plan but its something worth thinking about now, while there is time.  Read more: could turning to traditional techniques provide a solution? Amin Al-Habaibeh, professor of intelligent engineering systems at Nottingham Trent University, thinks so."
"A “lifeline” for the planet that “will steer the world towards a global clean energy transition”, was how European Commission president Jean-Claude Juncker hailed the Paris agreement. He also claimed it to be “a success for the European Union” itself. The EU’s demand for a legally binding document was realised. However the agreement carries less weight than a full treaty (though a Kyoto-style treaty wouldn’t be approved by the US Congress). Ahead of the summit the EU had called for global average temperatures to be kept below 2°C above pre-industrial levels and it will be satisfied with the revised 1.5°C goal. This unexpectedly ambitious target is not accompanied by clear emissions reductions targets and therefore does not reflect the three main targets in the EU’s 2030 climate and energy framework: to cut greenhouse gas emissions by at least 40% from 1990 levels; for renewable energy to compromise at least 27% of electricity generation; and an “indicative” target of at least 27% more efficient energy use. The framework contains a flexibility clause that allows the EU to reconsider the 40% target. In the absence of clear targets in the agreement it is likely that eastern European countries such as Poland that are heavily dependent on fossil fuels will seek to renegotiate this commitment downwards. The previous UK government accepted the 40% target but current government policies are incompatible with it. In typically vague language, the Paris agreement calls for global greenhouse gas emissions to peak “as soon as possible”. The EU wants this to occur by 2020 but that’s not going to happen. It also wants global emissions reductions of at least 50% by 2050 compared to 1990 levels, but that would require unprecedented levels of global cooperation. Even within Europe, member states will have to move smartly to accomplish the EU’s aim of 95% emissions reductions by 2050.  To have any chance of success, energy policy will have to be driven by Germany, Scandinavian and other greener nations, rather than the likes of the UK and Poland. If the Paris agreement truly marks the end of the fossil fuels era, as some commentators have claimed, the EU will have to send clear signals that continued investment in coal, oil and gas is counterproductive and business as usual is no longer possible. During the summit the EU formed an alliance with 79 African, Caribbean and Pacific countries that effectively endorsed its negotiating position, a grouping that later expanded to 134 countries and doubtless facilitated the agreement. The alliance pushed for a legally binding, inclusive and fair deal to be reviewed every five years, and a strong transparency and accountability mechanism to track whether each country is hitting its targets. The EU agreed to provide €475m to support adaptation in partner countries before 2020, far less than needed. The EU secured provisions that require countries to ratchet their adaptation and mitigation commitments upwards every five years and to have clear stringent transparency and accountability. However the agreement appears to be mainly enforced through simple naming and shaming – which doesn’t inspire confidence. The agreement reflected the EU’s willingness to contribute its share of a minimum of US$100 billion that developed countries have pledged to make available to developing countries every year from 2020 from public and private sources. It will have to find these funds in a period of slow growth to put its money where its mouth is, and the time has surely arrived to stop all fossil fuel subsidies and consider an EU-wide carbon tax.  Under pressure from small island states and other developing countries suffering from climate change through no fault of their own, the EU accepted the inclusion of an article on loss and damage caused by global warming. However it then conspired with the US to insist that the article does not provide a basis for liability and compensation. The EU continued its historically positive role as a major actor in climate negotiations in Paris. Its ability to act collectively facilitated agreement and contributed to France’s diplomatic success.  But the agreement is long on ambitious rhetoric and short on detail. It makes no mention of fossil fuels and is weak on corporate accountability and human rights. It is a step in the right direction but a decade too late. To place itself on the right side of history, the EU must now demonstrate that aspiration can be turned into achievement through action rather than words."
"On September 28, The Conversation published an article: “Don’t fall for the deep-sea scaremongers – wild fishing is healthy and sustainable” by Magnus Johnson, a senior lecturer in Environmental Marine Biology at the University of Hull. The article criticised a paper by marine biologists at the University of Glasgow and Marine Science Scotland on the regulation of deep-sea fishing. The lead authors of the study, David Bailey and Francis Neat, respond here. Since publishing our study on “A scientific basis for regulation deep-sea fishing by depth” we’ve been subjected to criticism online and in print from fisheries organisations and most recently on this website in an article by Magnus Johnson. Johnson makes general points about the benefits of sustainable fisheries, that we agree with, but his specific critique of our work falls well wide of the mark. Our work suggests that stopping deep-sea trawling at a depth of around 600m makes sense, because deeper than this the proportions of total and elasmobranch bycatch species (sharks and rays) in the assemblage increase significantly. At the same time indices of biodiversity are still increasing and the value of the species present falls.   Fisheries leaders and the author of the article claim that our study, being based on research survey data, is not representative of the effects of commercial fishing and, because bycatch is a “nuisance”, fishermen are able to avoid it. But what does the actual evidence say for deep-sea trawling? Our previous work showed that deep-sea fishing is unselective in its impacts on deep-sea fish. Unusually for a fishery, we were able to compare before and after deep-sea fishing in an area off Ireland. Fish numbers were cut in half in less than 20 years – and non-target species were just as likely to be depleted as targets. Any fish species whose depth range reached into the fishing grounds was affected.  As for the selectivity of recent catches, a collaborative project between the French fishing company SCAPECHE and the French government research organisation IFREMER looked at the options for being selective through changes to gear and by identifying areas of high discarding which could be avoided. They had little success in this endeavour. The modified trial gears caught as much bycatch as the normal gear and the authors dismissed as unfeasible the sort of work required to design the highly-selective gears used in shallow fisheries. There was little spatial pattern in most elasmobranch bycatch species, so no feasible avoidance strategy was possible for these species. The authors concluded that a depth-based avoidance strategy was as likely to succeed as other more complex spatial measures.  For now at least there is little evidence that deep-sea trawling is highly selective. As a result, any method that shows trends in what species were available to be hit by the trawls would provide a fair representation of the trends in impact of commercial fishing at different depths. Remember, it is the trends with depth that are the issue, not whether one net catches more than another. To disprove our study our critics would need to show that not only is commercial fishing very much more selective than surveys, but that they get relatively more selective with depth. Neither Johnson nor our other critics has provided any evidence for this. Johnson further argues that our study was flawed because we failed to analyse any effect of time over the period of the study. Actually we have already done temporal studies in both the Irish and Scottish datasets that indicate following the initial depletion of stocks, the populations have been generally stable, thus showing little sign of recovery. The criticism that we used “pseudo-commercial nets rather than data from fishing boats” – and that this invalidates our results – would be extremely weak in any case. The scientific trawls are modified commercial nets with finer mesh in the cod end (the part where the fish are ultimately collected after being herded into the net) and therefore catch a wider range of fish sizes than commercial nets. This will influence indices of biodiversity, but will not affect retention of the larger species that contribute most to the biomass indices or catches of sharks for instance.  One of the gears (Jackson Trawls of Peterhead model BT195) is identical to commercial fishing gears used by Scottish vessels targeting monkfish. The Scottish monkfish survey was specifically developed together with the fishing industry so that direct comparisons between survey vessels and fishing vessels could be made. Despite variation in gear type the trends in the indices were not significantly different. This is all set out in the paper or the many works underpinning it. It is little surprise then that our study also shows a very similar pattern of species richness with depth to those recorded from commercial trawls by on-board observers. It is also worth noting at this point that the Scottish and French fishing industries had already agreed to an 800m limit before our paper came out – so now the question is whether this was the appropriate depth to choose. Our paper suggests not, because it demonstrates that trawling at depths beyond 600m the detrimental impacts on the fish community become increasingly adverse; an 800m limit would not be precautionary and risks continued ecosystem degradation.  A common argument put by industry is that this will be the “thin end of the wedge” and that NGOs will soon be back asking for the 200m and 400m limits for which they originally campaigned. We can say now that our study would not support the ban being moved shallower than 600m and would argue strongly against any NGO that proposed this. We follow the evidence – supported by the methodical collection of research data going back decades. Now we just want the science to be used. This article was co-authored by Dr Francis Neat of Marine Sciences Scotland."
" The devastation from Australia’s bushfire crisis became clearer on Sunday, as the South Australian premier said 72 homes had been destroyed and his New South Wales counterpart revealed there was “not much left” of the town of Balmoral, south-west of Sydney. It is feared the figures for homes lost may get much worse as authorities continue to assess the damage from Saturday, and with dozens of fires still active.  Conditions eased in NSW, Victoria and South Australia on Sunday, allowing fire-threatened areas some respite. But the NSW Rural Fire Service commissioner, Shane Fitzsimmons, said an estimated 100 buildings could have been lost in Balmoral, where Gladys Berejiklian said there was “not much left”. “The toll is significant,” Fitzsimmons said. The Green Wattle Creek fire tore through the town on Saturday for the second time in three days. Residents have not been allowed to return to see if their homes are still standing, with expert teams on the ground assessing whether it was safe to do so. A man who was reported missing during the Grose Valley fire in the NSW Blue Mountains was found safe in an evacuation centre, but another elderly man from Bell near the town of Lithgow was missing as of Sunday afternoon. The area was engulfed in flames on Saturday. By Sunday evening there were only two fires in NSW at watch and act level: Gospers Mountain and Grose Valley. Fitzsimmons said the “relentless nature” of this fire season was taking a toll on firefighters. Despite the easing conditions, Fitzsimmons warned that didn’t mean the situation would improve considerably without substantial rainfall. “We’ve got to keep in mind that we’re not expecting any rainfall to make any meaningful difference to these fires until January [or] February,” he said. “That’s still a way to go. We’re still talking four to six weeks at best before we start to see a meaningful reprieve in the weather.” Conditions also eased in South Australia, but the premier, Steven Marshall, confirmed 72 homes had been destroyed in the Cudlee Creek fire in the Adelaide Hills, up from 15 reported on Saturday. A total of 404 outbuildings and 227 vehicles were destroyed in that fire. The smoke from the Adelaide Hills reduced the city’s air quality rating to poor. In Victoria, conditions for the fires in Victoria’s East Gippsland eased, with watch and act warnings in place for a fire in Tambo Crossing, Wattle Creek and Stirling, and another at Marthavale-Barmouth Spur. Fires burning in the state since 21 November flared up on Saturday after the cool change brought with it dry lightning strikes. Smoke from the NSW fires made its way up to Queensland, where another day of severe fire danger was forecast for Monday. The prime minister, Scott Morrison, returned to Australia from his holiday in Hawaii on Saturday night.  Morrison spent Sunday touring the RFS headquarters in NSW, before visiting an evacuation centre in Picton and an emergency fire control centre in Wollondilly. The prime minister met the widows of the two firefighters, Geoff Keaton and Andrew O’Dwyer, who died in a truck rollover last week. At a press conference on Sunday morning, Morrison  apologised to people who were upset for him going on holiday during the bushfire crisis. He said the secrecy surrounding the trip was because it was family leave, and tried to draw a line under the criticism of his decision to take the trip. “The time for that discussion is over. We need to focus on what is going out there today. Let me finish by saying this … it is time to be kind to each other. This is not a time for division, it is not a time for argument, it is not a time for partisanship, it is not a time for point scoring,” he said. The prime minister acknowledging that climate change was having an impact on weather events, but indicated there would be no change to government policy, including Australia’s controversial policy of using carryover credits for meeting targets in the Paris agreement. Morrison said a council of Australian governments meeting would be convened in March to discuss the response to the fires and how to plan more effectively.  The opposition leader, Anthony Albanese, praised emergency management minister David Littleproud for providing updates to him about the bushfires, but said he had not been able to secure a tour of the RFS headquarters Morrison visited in the morning, despite requests."
"
Share this...FacebookTwitterIf we can believe Spiegel, it looks like the German political-climate blitz, led by Chancellor Angela Merkel, aimed at isolating and humiliating the United States, particularly President Donald Trump, appears to have run aground.
The Paris Climate Accord may be having its D-Day.

Image cropped from Spiegel here
According to the online English version of Der Spiegel, “The German chancellor had been hoping to isolate Donald Trump on climate issues at the upcoming G-20 summit in Hamburg“, but a number of longtime US allies have decided that the overall relationship with America is more important than the flakey, UN-manufactured “climate crisis”.
Merkel’s international defeat
Spiegel writes that Merkel led the charge to try to get 19 countries of the G20 to turn against America and “make Trump a bogeyman of world history. A score of 19:1“.
Japan, in part due to obvious North Korean factors, is also hardly ready to upset its longstanding crucial Pacific ally.
No sooner did Merkel launch her climate anti-Trump campaign at the G7 summit did it begin to crumble, first because of pragmatism out of Canada, and then Great Britain. Merkel was not able get the six other countries of the G7 to make a statement against Trump. Spiegel sums up: “Climate policy is great, but when it comes to national interests, it is secondary.”
What’s left of the G7 attempt to isolate Trump is a lonely gaggle of Germany, Italy and France.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Spiegel summarizes it is “a defeat for Merkel” when it comes to climate policy and international leadership.
No mention of “climate” in G20 draft statements
Concerning the G20 meeting in Hamburg in July, there are already signs that the climate issue will also be secondary there as well. Spiegel writes how several drafts for joint statements have circulated and: “There isn’t a single mention of the climate in the document.”
Now that Merkel realizes her strategy to isolate Trump is not working, Spiegel writes that German government officials are now “eager to avoid turning the climate statement into an instrument of power politics” and that Merkel will likely to “retreat” to a role of mediator.
But it’s an election year and the race to bash and “to stand up to” Trump is as intense as ever. In polls Merkel’s CDU/CSU party currently holds a huge lead over the crumbling SPD socialist party, led by Martin Schulz. Merkel probably could even afford softening her anti-Trump stance.
Germany CO2 emissions reductions an embarrassment
Another factor that Spiegel did not bring up is that Germany’s climate charges against America in fact look ridiculous. How can anyone take Germany seriously on leadership in climate protection? This is a country that has not cut back its greenhouse gas emissions in 8 years and will completely miss its 40% reductions target by 2020.
Moreover, led by the Merkel government, Germany has massively slashed subsidies on green energies and the Chancellor’s pledge to put a million electric cars on the road by 2020 remains light years away.
Germany preaching America on cutting greenhouse gases is nothing short of a bad joke.
 
Share this...FacebookTwitter "
"The Peruvian government has a clear development agenda for its Amazon rainforest regions. Oil extraction is already happening on a large scale. That will be supported by significant investment in new gas pipelines, proposed hydroelectric dams and other large transport projects. But what do people who actually live in the region make of all this? In my research, I have shown that Peru’s development plans are deliberately restricting the ability of local citizens to provide consent for these projects. This is no accident. Most people living in Peru’s Amazon regions are indigenous, a group of people who remain excluded and discriminated against. According to one former president, indigenous people are an obstacle to development, “artificial communities that own 200,000 hectares on paper but only farm 10,000 hectares while the rest is idle property”. Peru is a young democracy which has only properly held elections since 2001. Its constitution sets out significant rights for its citizens including the “freedom of information, opinion, expression” and the right to their “own voice and image”. Peru is also a member of several important regional human rights bodies and has signed relevant international treaties such as the International Covenant on Civil and Political Rights. Together, these further enshrine citizen rights and the state’s obligations. On paper at least, Peruvians have an open political environment in which to make their voices heard. However, Peru’s democracy is not perfect and has been evaluated as “flawed” and “defective” by international studies. While citizens have rights, the country’s weak state institutions mean that it can fail to uphold or implement them. More troublingly, a closer look at Peru’s freedom of voice surrounding development projects finds a far more restrictive political environment for citizens. Research has found that governments across Latin America have routinely tried to criminalise social protest, especially in relation to large development projects.  This is evident in Peru. Its broad terrorism law has been criticised due to the way it has been applied to non-terrorist acts like protests against development projects or over indigenous issues. Other laws have built on this. For example, a 2008 decree removed a requirement for the government to declare a state of emergency before deploying the army. Equally, in September 2010, a new law permitted the armed forces to be used against protesters and regulated the use of lethal force against “hostile groups”. None of this seems to have worked: according to Peru’s human rights ombudsman, social conflicts which turn violent have resulted in 271 deaths since 2006, while Global Witness says 50 environmental and human rights defenders were killed in Peru between 2010 and 2015. Other groups that campaign on these issues have also been attacked by the state to discredit them. For example, anti-mining groups have been labelled “anti-mining terrorists” by the state, a term used deliberately to associate them with the Shining Path, a Maoist terrorist insurgency that ravaged Peru in the 1980s and 1990s. Peru has two main mechanisms through which the public can be consulted: a law of prior consultation, and environmental impact assessments. Both have improved things, but serious flaws remain. The law of prior consultation was developed to ensure discussions with indigenous people ahead of any natural resource development. Crucially, the law itself is only consultative and does not give people a veto over any development projects. Environmental impact assessments are now being approved by the state faster than ever. Workshops and public hearings for local people – in theory, part of the impact assessment process – often occur after the government has signed oil and gas agreements. Affected citizens are therefore the last to know about these developments. The Amazon rainforests of Peru are still considered an untapped resource. The government’s aggressive pursuit of development is designed to change this at the expense of local, predominantly indigenous people who are still seen as obstacles to Peru’s ongoing development. State-led consultation mechanisms and wider laws have been designed to ignore local peoples’ voices and attack environmental and human rights defenders. However, Peru’s high levels of social conflict surrounding mining and oil development projects are not only caused by ongoing environmental pollution issues and the overlapping of indigenous lands but also these consultation issues. This must change. The Peruvian state must listen to and respect the voices of its indigenous citizens."
"
Share this...FacebookTwitter
75% Of Total Modern Glacier Melt Occurred Before 1950

“[T]he retreat of the glaciers after about 1925 became rapid.  It was almost entirely during the [pre-1950] twentieth century warming that the Alpine glaciers disappeared from the valley floors up into the mountains.  Similarly great retreats occurred in Scandinavia, Iceland, Greenland, in the Americas, and on high mountains near the equator.”  — H.H. Lamb  Climate, History, and the Modern World (1982), pg. 248

A new scientific paper indicates that the pronounced warming that occurred during the years stretching from the 1920s to the 1940s melted Northern Iceland glaciers much more extensively and at a far more rapid pace than has been observed in recent decades.
During the 1960s to 1980s, glacier melt rates not only decelerated relative to the 1920s to 1940s, the ice actually advanced in some cases due to decades of cooling.   It has only been since about the mid-1990s that glaciers have consistently begun melting again — but with far less alacrity than they did in the first half of the 20th century.
Fernández-Fernández and co-authors (2017) indicate that the Icelandic glaciers they studied melted by more than 1,000 meters (1,062) on average between the late 1800s and 1946.  But from 1947 to 2005, these same glaciers only retreated by an average of 272 meters more.  In other words, about 75% of the total glacier melt production since the end of the Little Ice Age (the late 19th century) occurred prior to the mid-1940s.
Below are some key points and graphs from the paper.

Fernández-Fernández et al., 2017
Summary:
“The abrupt climatic transition of the early 20th century and the 25-year warm period 1925–1950 triggered the main retreat and volume loss of these glaciers since the end of the ‘Little Ice Age’. Meanwhile, cooling during the 1960s, 1970s and 1980s altered the trend, with advances of the glacier snouts. Stötter et al. (1999) indicate that the coldest period after the LIA was from the early 1960s to the mid-1970s, when temperatures fell to levels equivalent to the warmest recorded in the 19th century. This cooling is the reason given by Caseldine (1983, 1985a, 1985b, 1988) to explain the advance of the Gljúfurárjökull between the mid-1970s and the mid-1980s  … Studies of aerial photographs and satellite images show that the glacier snouts have retreated by more than 1300 m on average since the LIA maximum (considered to be AD 1898 in Gljúfurárjökull and AD 1868 in both Western and Eastern Tungnahryggsjökull), with an altitudinal rise of more than 100 m. The retreat accelerated rapidly (15.3 m yr−1) during the first half of the 20th century.  In the second half of the 20th century, the retreat decelerated considerably, reflected in the lowest values around 1985 (5.2 m yr−1) and a trend shift in 1994, with an advance observed in Gljúfurárjökull. … The retreat rate intensified in the period 2000–2005 compared with 1994–2000, but did not reach the rates recorded before 1946.”

Gljúfurárjökull, West Tungnahryggsjökull, and East Tungnahryggsjökull Glaciers:
1. During the period 1898–1946, the snout of Gljúfurárjökull retreated 635 m, almost two-thirds of the total distance from the LIA maximum (1898–1903) to 2005, at an average rate of 13.2 m yr−1. 
2. The trend in Western Tungnahryggsjökull during the first half of the 20th century was a more rapid retreat, showing the highest average rates of the whole period (19.5 m yr−1). By 1946, this glacier had retreated almost 90% of the total recorded between the LIA maximum (1868) and 2005.
3. Just as in the glaciers described above, the retreat of the Eastern Tungnahryggsjökull from its LIA position was more intense during the first half of the 20th century, and in 1946 its snout was only 200 m from its current position. … The 2000 aerial photograph shows that an advance of at least 41 m had taken place since 1985. Nevertheless, between 2000 and 2005, the snout retreated 17 m, even more slowly than Western Tungnahryggsjökull. 



No Net Warming In North Iceland Since 1920s-1940s



Similar Or Less North Iceland (Arctic) Sea Ice During 1920s-1950s

Ran et al., 2010


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Holocene Icelandic Climate 4-5°C Warmer, Changing 2-3°C Per Century 

Andersen et al., 2004 
“Our results show that the Nordic Seas circulation system is highly sensitive to the large-scale insolation [surface solar radiation] changes as the general Holocene climate development follows closely the Northern Hemisphere insolation. … Century-scale surface current variability for the Holocene is shown to be 1 – 1.5°C for the Vøring Plateau and East Greenland shelf, and 2.5– 3°C on the North Ice-land shelf. … The first cooling [East Greenland Shelf SSTs] from 2400 to 2000 cal years BP was introduced by a 1.5°C temperature drop starting at 3000 cal years BP which culminated in an SST low around 2100 cal years BP. The second cooling occurred around 300 cal years BP and preceded a rapid warming [during the 1700s A.D.], where SSTs rose with more than 1.5°C within 70 years. The third cooling took place in the second half of the last century. Until the last three centuries, SST variability at this site has been 1°C, while SSTs varied with amplitudes of 1.5– 2°C during the last 300 years.”


Not Just Iceland: Global Glacier Melt Rates More Rapid, Pronounced 1920s-1950s

Gregory et al., 2013


Globally, glaciers melted 69% more rapidly from 1921-1960 (12.5 meters/year) than from 1961-2000 (7.4 meters/year).

Leclercq et al., 2014  A data set of worldwide glacier length fluctuations
“The data set contains the glacier length records for 471 [global] glaciers and it covers the period 1535–2011. There are glacier length records from all continents and at almost all latitudes.   For the observed glaciers, the 20th century retreat was strongest in the first half of the 20th century.”
“[T]he retreat is strongest in the period 1921–1960 rather than in the last period 1961–2000, with a median retreat rate of 12.5 m yr in 1921–1960 and 7.4 m yr in the period 1961–2000.”

A Significant Non-Correlation Between CO2 Emissions And Glacier Melt

Advocates of the position that humans exert a profound and dangerous influence on the Earth’s temperatures, glacier melt, sea level rise, extreme weather patterns . . . point to the rapid increase in human CO2 emissions (purple trend line) as the condemnable culprit.



But consider that the trend in anthropogenic CO2 emissions was essentially flat and very low (averaging just 1 gigaton of carbon [GtC] per year) from about 1900 to 1945, when most modern glacier recession occurred.  Also consider that explosive growth in human emissions occurred after 1945, when a significant deceleration in glacier melt (and even decades of advancing glaciers) occurred.  This historical evidence would not appear to support the position that anthropogenic CO2 emissions drive warming, glacier melt, and sea level rise.
Share this...FacebookTwitter "
"Human society has come to rely on superior gadgets being produced every year. Each year, new phones or laptops are faster, sleeker and have even more capabilities. However, electronics are rarely recycled, and the carbon footprint of the internet already exceeds that of air travel. The internet also relies on “rare earths” and heavy and noble metals, leading to pollution and socio-economic problems associated with mining these scarce and often noxious materials.  Maintaining this information network across the world requires more energy than the whole of the UK – and energy demand from data centres is expected to treble over the next decade. Three google searches are equivalent to a 60 watt bulb being switched on for a minute and produce 0.6g of CO₂. And computers already generate so much wasted heat that companies like Facebook are now placing new data centres in the Arctic to keep them cool. Given all this, the capability to fulfil our computing needs while producing negligible heat waste and reducing our power needs would have momentous consequences. Indeed, to avoid a technological and societal collapse, we’ll need a massive shift towards low-carbon computing. Even if we ignore the environmental impact, we are still faced with the problem that current computing technologies are inching closer to their fundamental limits in size and processing speed. More transistors are being packed on to computer chips and they will eventually, within the next decade or so, reach the smallest possible size at which we can reliably transmit charge or information. This is why progress depends on developing new fabrics using eco-friendly materials and low power electronics. To justify the huge industrial and public investment associated with replacing production lines, infrastructure and working methods, this new technology would have to be not only better for the environment, but simply much better in all aspects. Imagine computers that operate orders of magnitude faster, do not need fans to cool down, can operate for longer on a single battery charge or can store vast amounts of information with near immediate access.  For now, conventional hard disks (magnetic domain storage) and silicon-based technologies still dominate. Scientists have come up with lots of alternatives, but many, such as molecular electronics, have so far failed to deliver fully on their original promise. Others, such as quantum computers or superconducting devices, are highly specialised or lie in the long-term future. There are other options to continue our progress and minimise the ecological impact. Within my own field of “spintronics”, we explore how to transmit information through measuring an electron’s “spin” rather than its movement or charge. This loses very little energy when transmitting electricity. Spintronics is currently used mostly in sensing and computing, for example in the read-heads of hard disks (without it we couldn’t store/read so much information in so little space). In the future, it could be used to convert wasted heat back into electricity, or in car sensors or biomedicine. In all of this, carbon-based molecules can play a critical role. These environmentally friendly materials can carry a charge or store information. But they can also be applied as a very thin layer of molecules on top of a thin layer of metal which means they share electrons (hybridise), thus changing the properties of both materials. This can be used to, for instance, generate magnetism in non-magnetic materials such as copper. This will allow technological progress while reducing both the power needed and the use of rare earth metals, which are expensive and environmentally damaging. Many of these technologies may not make it out of the lab in our lifetimes. Rather than becoming common in personal devices, they’ll remain a plaything of scientists, confined to experiments. However, even if only some of them were to be successful, it would lead to a step change on how we interact with our virtual environment and what it can do for our environment, health, politics, or transport. The future of the Homo technologicus will depend on it."
"
Share this...FacebookTwitterGerman electrical power analyst Verivox here issued a press release announcing that electricity will be more expensive in the coming months for many German households: 75 primary utilities are increasing their electricity prices by an average of 3.4% in February alone – this according to a study by Verivox experts.
For a family of four with an annual consumption of 4000 kWh, that means extra costs of 42 euros per year. Already tens of thousands of households are living in energy poverty.
At the start of the year some 354 power utilities cranked up the prices. This means that about half of all utilities have increased their power prices during the first months of 2017.
Rising feed-in charges, grid fees and costs
One reason for the increased prices is the higher renewable energy feed-in charges, reports Verivox. At the start of the year they climbed to a record 6.88 cents per kilowatt-hour. Verivox writes that the prices for power are now at “record levels”.
Wind and solar power disappeared in January
Meanwhile the online Die Welt N24 here reports how wind and solar power practically completely disappeared over a period of weeks during the dead of winter in Germany — as a high pressure system with fog and windless days persisted over much of central Europe — and “brought Germany’s power supply at the limit“.
The German site writes that renewable energy lobbyists prefer to be silent during the long and dark winter months, adding: “In January the German green energy systems as power suppliers went almost totally AWOL weeks long“:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Chart above shows Germany’s total power consumption in January (upper curve) compared to solar (yellow) and wind (blue) energy. From January 16 to January 26 wind and solar power almost disappeared entirely. Chart source: Agora here.
Over the past years Germany has taken a number of conventional power plants offline, and now officials worry that there is no longer sufficient steady base load available, and that there thus needs to be an incentive to install new gas power plants. Currently no power companies are investing in such new plants, and are in fact taking more and more offline due to a lack of profitability. This is increasingly putting the grid at risk. The consequences? Die Welt N24 reports:
The lack of controllable power plants put the grid operators during the January doldrums already under heavy stress.”
According to Stefan Kapferer, Head Director of the BDEW German Association for Energy and Water Management: “The German government itself sees that that the current market system is not adequate to guarantee supply security. Otherwise it would not be keeping different power plant reserves on the market and adding new ones.“
In summary, Germany is still taking more conventional power plants offline, but ordering them to remain on standby (at a loss) as reserves for cases like those we saw last month. Policymakers are playing Russian Roulette with Germany’s power grid.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterModern Solar Grand Maximum Ends
‘Little Ice Age’ Cooling On The Way


During the 20th and early 21st centuries, Earth’s inhabitants have enjoyed an epoch of very high solar activity that is rare or unique in the context of the last several thousand years.  The higher solar activity and warmer temperatures have allowed the planet to briefly emerge from the depths of the successive solar minima periods and “Little Ice Age” cooling that lasted from the 1300s to the early 1900s.  Unfortunately, solar scientists have increasingly been forecasting a return to a solar minimum period in the coming decades, as well as the concomitant cooler temperatures.
In several newly published (2017) papers, scientists have suggested that a substantial deterioration into solar minimum conditions and global cooling may be imminent (see, for example, here and here and here).  What follows is a collection of dozens of other papers that have also projected a solar minimum-induced “Little Ice Age” climate for the foreseeable future.
The analysis concludes with references to recently published papers that indicate the North Atlantic region has already begun cooling rapidly within the last decade.  Scientists have long suggested that what happens in the North Atlantic may have global-scale implications, and thus the observed North Atlantic cooling trend may be a harbinger of the climate that is to come.

The Modern Grand Maximum Of Solar Activity A ‘Rare’ Or ‘Unique’ Event

Usoskin et al., 2014     “[T]he modern Grand maximum (which occurred during solar cycles 19–23, i.e., 1950–2009) was a rare or even unique event, in both magnitude and duration, in the past three millennia. Except for these extreme cases, our reconstruction otherwise reveals that solar activity is well confined within a relatively narrow range.”


Lockwood et al., 2009     “[T]he Sun has been unusually active over recent decades (Solanki et al. 2004; Vonmoos et al. 2006; Muscheler et al. 2007; Steinhilber et al. 2008). Solanki et al. (2004) used the 14C isotope abundance found in tree trunks and concluded that the Sun has been more active recently than at any time in the previous 8000 years and that it was as active as in recent decades for only 10% of the past 11000 years.”

Chen et al., 2015     “We explored the sources and characteristics of each pigment, reconstructed an 800-year record of ultraviolet radiation (UVR) and total incoming light intensity, and identified the possible factors that may have influenced historical UVR changes in this region. The results indicated at least four UVR [ultraviolet radiation] peaks during the past 800 years, corresponding to c. AD 1950–2000, 1720–1790, 1560–1630 and 1350–1480, with the intensity from the most recent [1950-2000] sediments being the highest.”



The Modern Grand Maximum Of Solar Activity Has Recently Drawn To A Close

Wang et al., 2010      “It is seen that a very active period that began in 1920, the so-called ‘current grand solar maximum’, will probably end during 2011-2027, since a variety of indices related to solar activity have significantly shifted since 1987. … [T]he current grand solar maximum has already lasted for eight 11-year solar cycles and might end in the coming one/two 11-year cycles; a grand solar minimum might prevail in the next 100–200 years.”

Zharkova et al., 2015     “The longest direct ervation of solar activity is the 400-year sunspot-number series, which depicts a dramatic contrast between the almost spotless Maunder and Dalton minima, and the period of very high activity in the most recent 5 cycles [1950s – 2000s], prior to cycle 24. … The records show that solar activity in the current cycle 24 is much lower than in the previous three cycles 21–23 revealing more than a two-year minimum period between cycles 23 and 24. This reduced activity in cycle 24 was very surprising because the previous five cycles were extremely active and sunspot productive forming the Modern Maximum.”
“We predict correctly many features from the past, such as: 1) an increase in solar activity during the Medieval Warm period; 2) a clear decrease in the activity during the Little Ice Age, the Maunder Minimum and the Dalton Minimum; 3) an increase in solar activity during a modern maximum in 20th century. .. We note, in particular, a decreasing activity for solar cycles 25 and 26 coinciding with the end of the previous 350–400-year grand cycle and then increase of the solar activity again from cycle 27 onwards as the start of a new grand cycle with an unusually weak cycle 30. Hence, cycles 25–27 marks a clear end of the modern grand period that can have significant implications for many aspects of solar activity in human lives including the current debate on climate change.”

press release     A new model of the Sun’s solar cycle is producing unprecedentedly accurate predictions of irregularities within the Sun’s 11-year heartbeat. The model draws on dynamo effects in two layers of the Sun, one close to the surface and one deep within its convection zone. Predictions from the model suggest that solar activity will fall by 60 per cent during the 2030s to conditions last seen during the ‘mini ice age’ that began in 1645. … Results will be presented today by Prof Valentina Zharkova at the National Astronomy Meeting in Llandudno. … Zharkova and her colleagues derived their model using a technique called ‘principal component analysis’ of the magnetic field observations from the Wilcox Solar Observatory in California. They examined three solar cycles-worth of magnetic field activity, covering the period from 1976-2008. In addition, they compared their predictions to average sunspot numbers, another strong marker of solar activity. All the predictions and observations were closely matched. “Combining both waves together and comparing to real data for the current solar cycle, we found that our predictions showed an accuracy of 97%,” said Zharkova. “Effectively, when the waves are approximately in phase, they can show strong interaction, or resonance, and we have strong solar activity. When they are out of phase, we have solar minimums. When there is full phase separation, we have the conditions last seen during the Maunder minimum, 370 years ago.”

‘All Proponents Of Planetary Forcing Have Forecasted A Solar Grand Minimum For The Upcoming Decades’

Sánchez-Sesma, 2015     “Solar activity (SA) has non-linear characteristics that influence multiple scales in solar processes (Vlahos and Georgoulis, 2004). For instance, millennia-scale solar oscillations have been recently detected, like those of about 6000 and 2400 years, by Xapsos and Burke (2009) and Charvátová (2000), respectively, with important and interesting influences in the near past and future climate. These millennial-scale patterns of reconstructed solar activity variability could justify epochs of low activity, such as the Maunder Minimum, as well as epochs of enhanced activity, such as the current Modern Maximum, and the Medieval Maximum in the 12th century. Although the reason for these solar activity oscillations is unclear, it has been proposed that they are due to chaotic behavior of non-linear dynamo equations (Ruzmaikin, 1983), or stochastic instabilities forcing the solar dynamo, leading to on-off intermittency (Schmittet al., 1996), or planetary gravitational forcing with recurrent multi-decadal, multi-centennial and longer patterns (Fairbridge and Sanders, 1987; Fairbridge and Shirley,1987; Charvátová, 2000; Duhau and Jager, 2010; Perry and Hsu, 2000). It should be noted that all proponents of planetary forcing have forecasted a solar Grand Minimum for the upcoming decades, but one of them has also forecasted a Super Minimum for the next centuries (Perry and Hsu, 2000). In addition, during recent decades, statistical forecasts (with physically-based spectral information of reconstructed records) of solar magnetic activity predict a clear decrease in solar activity, reaching a minimum around AD 2100 (Steinhilber et al., 2013; S13, hereafter, Velasco et al., 2015)”

Liu et al., 2011     “Climate events worldwide, such as the MWP and LIA, were seen in a 2485-year temperature series. The largest amplitude and rate of temperature both occurred during the EJE [Eastern Jin Event (343–425 AD)], but not in the late 20th century. The millennium-scale cycle of solar activity determined the long-term temperature variation trends, while century-scale cycles controlled the amplitudes of temperature. Sunspot minimum events were associated with cold periods. The prediction results obtained using caterpillar-SSA showed that the temperature would increase until 2006 AD on the central-eastern Plateau, and then decrease until 2068 AD, and then increase again.”


Steinhilber and Beer, 2013     “Our methods are able to predict periods of high and low solar activities for a few centuries in the past. However, they are less successful in predicting the correct amplitude. Then, the methods were used to predict the period 2000–2500. Both methods predict a period of low activity around 2100 A.D. Between 2100 and 2350 A.D., the results are inconsistent regarding the duration of the low-activity state in 2100 A.D. and the level of activity until 2250 A.D.”


Lüdecke et al., 2015     “The Earth’s climate shows a rather regular oscillation of ∼ 200 year period during the last millennia. However, frequency, phase, and strength of the oscillation are found to vary in different time series of temperatures and for different times (see Figs. 4–6, and 5 8). Nonetheless, the relative historic stability of the cycle suggests that the periodic nature of the climate will persist also for the foreseeable future. Disregarding other conceivable forcings e.g. anthropogenic influences, an approximate prediction of the climate for the next 100 years suggests itself. Figure 9 shows the Tsine representation from AD 1800 to AD 2100 derived from the ∆Tsine representation by a π/2 phase shift.  It gives correctly the 1850–1900 temperature minimum and shows a temperature drop from present to ∼ AD 2080, the latter comparable with the minimum of 1870, as already predicted in the studies (Steinhilber and Beer, 2013; Liu et al., 2011) on the grounds of solar activity data alone.”

Herrera et al., 2015     “Of particular interest now is the fact that the behavior of the solar cycle 23 minimum has shown an activity decline not previously seen in past cycles for which spatial observations exist: this could be signaling the start of a new grand solar minimum.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Evans, 2016     “Four manifestations of unconventional climate influences are identified, each with at least as much effect on surface temperature as the direct heating effect of changes in total solar irradiance (TSI): external-driven albedo; countervailing cooling during TSI peaks, implied by the absence of corresponding peaks in the surface temperature record (the “notch”); the long-term sensitivity of surface warming to TSI increases; and the delay of ∼11 years between changes in underlying or smoothed TSI and the corresponding changes in surface temperature. We hypothesize these are all manifestations of a single force whose exact mechanism is unknown but whose crucial properties can be deduced: “Force X” modulates the Earth’s albedo, and lags TSI by one sunspot cycle or half the ∼22-year cycle of the Sun’s hydromagnetic dynamo. A second, alternative hypothesis is of “force N” for the notch and “force D” for the delayed force causing the other three manifestations. The notch-delay solar model can explain the global warming of the last few decades and centuries in terms of force X/D. Several solar indicators including TSI peaked ∼1986, but surface warming continued until ∼1998, which is explained by the delay. The notch-delay hypothesis predicts sustained and significant global cooling starting sometime in the period 2017 to 2022, of ∼0.3°C but perhaps milder (TSI estimates vary), as force X/D falls off in response to the marked decline in underlying TSI from around 2004—one of the three biggest and fastest falls in TSI since sunspot records began in 1610.”

Abdussamatov, 2015     “A long-term negative deviation of the Earth’s average annual energy balance from the equilibrium state is dictating corresponding variations in it’s the energy state. As a result, the Earth will have a negative average annual energy balance also in the future. This will lead to the beginning of the decreasing in the Earth’s temperature and of the epoch of the Little Ice Age after the maximum phase of the 24-th solar cycle approximately since the end of 2014. The influence of the consecutive chain of the secondary feedback effects (the increase in the Bond albedo and the decrease in the concentration of greenhouse gases in the atmosphere due to cooling) will lead to an additional reduction of the absorbed solar energy and reduce the greenhouse effect. The start of the TSI’s Grand Minimum is anticipated in the solar cycle 27±1 in 2043±11 and the beginning of the phase of deep cooling of the 19th Little Ice Age for the past 7,500 years around 2060±11.  … Thus, the long term variations of the solar constant (allowing for their direct and secondary impacts, with the latter being due to feedback effects) are the major and essential cause of climate changes because the Earth’s climate variation is a function of longterm imbalance between the solar radiation energy incoming into the upper layers of the Earth’s atmosphere and Earth’s total energy outgoing back to space.”


Yndestad and Solheim, 2016     “In 1890´s G. Spörer and E. W. Maunder (1890) reported that the solar activity stopped in a period of 70 years from 1645 to 1715. Later a reconstruction of the solar activity confirms the grand minima Maunder (1640-1720), Spörer (1390-1550), Wolf (1270-1340), and the minima Oort (1010-1070) and Dalton (1785-1810) since the year 1000 A.D. (Usoskin et al. 2007). These minimum periods have been associated with less irradiation from the Sun and cold climate periods on Earth. An identification of a three grand Maunder type periods and two Dalton type periods in a period thousand years, indicates that sooner or later there will be a colder climate on Earth from a new Maunder- or Dalton- type period. …. The result shows that the TSI variability and the sunspots variability have deterministic oscillations, controlled by the large planets Jupiter, Uranus and Neptune, as the first cause. A deterministic model of TSI [total solar irradiance] variability and sunspot variability confirms the known minimum and grand minimum periods since 1000. From this deterministic model we may expect a new Maunder type sunspot minimum period from about 2018 to 2055. The deterministic model of a TSI ACRIM data series from 1700 computes a new Maunder type grand minimum period from 2015 to 2071. A model of the longer TSI ACRIM data series from 1000 computes a new Dalton to Maunder type minimum irradiation period from 2047 to 2068.”

Torres and Guzmán, 2016     “Conclusions Based on our results, we propose the use of the Wolf’s Number Oscillation Index (WNOI) – as a more uniform alternative to the ONI – in the range over 30 and below -30. The analysis of the material presented and the arguments discussed allows us to define a possible relationship between phenomena related to Solar Cycle, the ENSO, climatic conditions, as well as some criteria for the establishment of public policies for preservation and remediation of the environment in the long run. We can conclude that solar activity oscillations impact the earth climatic conditions to such a extent that they become measurable only in the long run. The magnitude of the Solar Cycle – from 7 to 17 and a mean of 11.2 years – seems to support this statement. Based on the similarities of the Solar Cycles 5 and 24 we can expect a longer period of cold weather for the years 2022 y/o 2034, corresponding to the Solar Cycles 24 and 25.”

Sanchez-Sesma, 2016     “This empirical modeling of solar recurrent patterns has also provided a consequent multi-millennial-scale experimental forecast, suggesting a solar decreasing trend toward grand (super) minimum conditions for the upcoming period, AD 2050–2250 (AD 3750–4450). … Solar activity (SA) has non-linear characteristics that influence multiple scales in solar processes (Vlahos and Georgoulis, 2004). For instance, millennia-scale solar oscillations have been recently detected, like those of about 6000 and 2400 years, by Xapsos and Burke (2009) and Charvátová (2000), respectively, with important and interesting influences in the near, past and future climate. These millennialscale patterns of reconstructed SA variability could justify epochs of low activity, such as the Maunder minimum, as well as epochs of enhanced activity, such as the current Modern Maximum, and the Medieval maximum in the 12th century.  … We can conclude that the evidence provided is sufficient to justify a complete updating and reviewing of present climate models to better consider these detected natural recurrences and lags in solar processes.”

Riley et al., 2015     “[W]e suggest that the Sun evolved from a 2008/2009-like configuration at the start of the Maunder Minimum toward an ephemeral-only configuration by the end of it, supporting a prediction that we may be on the cusp of a new grand solar minimum.”

Abdusamatov, 2012     “The Earth as a planet will have a negative balance in the energy budget in the future as well, because the Sun is entering the decline phase of the bicentennial luminosity changes. … A deep bicentennial minimum in solar constant is to be anticipated in 2042 ± 11 and the 19th Little Ice Age (for the last 7500 years) may occur in 2055 ± 11.”


Solheim et al., 2012     “No significant trend is found between the length of a cycle and the average temperature in the same cycle, but a significant negative trend is found between the length of a cycle and the temperature in the next cycle. This provides a tool to predict an average temperature decrease of at least 1°C from solar cycle 23 to solar cycle 24 for the stations and areas analyzed. We find for the Norwegian local stations investigated that 25–56% of the temperature increase the last 150 years may be attributed to the Sun. For 3 North Atlantic stations we get 63–72% solar contribution. This points to the Atlantic currents as reinforcing a solar signal.”

Roth and Joos, 2013     “In contrast to earlier studies, periods of high solar activity were quite common not only in recent millennia, but throughout the Holocene. Notable deviations compared to earlier reconstructions are also found on decadal to centennial timescales. We show that earlier Holocene reconstructions, not accounting for the interhemispheric gradients in radiocarbon, are biased low. Solar activity is during 28% of the time higher than the modern average (650 MeV), but the absolute values remain weakly constrained due to uncertainties in the normalisation of the solar modulation to instrumental data. A recently published solar activity–TSI relationship yields small changes in Holocene TSI of the order of 1 W m−2 with a Maunder Minimum irradiance reduction of 0.85 ± 0.16 W m−2. Related solar-induced variations in global mean surface air temperature are simulated to be within 0.1 K. Autoregressive modelling suggests a declining trend of solar activity in the 21st century towards average Holocene conditions.”

Ahluwalia, 2014     “The Sun has emerged from a grand maximum for SSN cycles; it includes cycle 19, the most active cycle ever observed in 400 y. The grand minima are associated with cooler Earth temperatures (Eddy, 1976, 1981). The trend line indicates that we have entered a period of low solar activity; Ahluwalia and Jackiewicz (2012) suggest that we are at the advent of a Dalton-like minimum. The Earth was cooler then, made worse by Mt Tambora volcanic eruption on 5 April 1815.”

Salvador, 2013     “Using many features of Ian Wilson’s Tidal Torque theory, a mathematical model of the sunspot cycle has been created that reproduces changing sunspot cycle lengths and has an 85% correlation with the sunspot numbers from 1749 to 2013. The model makes a reasonable representation of the sunspot cycle for the past 1000 yr, placing all the solar minimums in their right time periods. The forecast is for a solar minimum and quiet Sun for the next 30 to 100 yr.”

Mörner, 2015     “By about 2030-2040, the Sun will experience a new grand solar minimum. This is evident from multiple studies of quite different characteristics: the phasing of sunspot cycles, the cyclic observations of North Atlantic behaviour over the past millennium, the cyclic pattern of cosmogenic radionuclides in natural terrestrial archives, the motions of the Sun with respect to the centre of mass, the planetary spin-orbit coupling, the planetary conjunction history and the general planetary-solar-terrestrial interaction. During the previous grand solar minima—i.e. the Spörer Minimum (ca 1440-1460), the Maunder Minimum (ca 1687-1703) and the Dalton Minimum (ca 1809- 1821)—the climatic conditions deteriorated into Little Ice Age periods.”

Duhau and de Jager, 2010     “[S]olar variability is presently entering into a long Grand Minimum, this being an episode of very low solar activity, not shorter than a century. A consequence is an improvement of our earlier forecast of the strength at maximum of the present Schwabe cycle (#24). The maximum will be late (2013.5), with a sunspot number as low as 55. … Solar activity is believed to be associated with climate change (De Jager and Duhau, 2009; De Jager et al., 2010; Miyahara et al., 2010). Sunspot activity can be concentrated in the two solar hemispheres and they appear to fluctuate for 11 year cycles. However, prolonged episodes of reduced sunspot activity, such as the Maunder Minimum, were clearly linked with an episode of extreme cooling and bitingly cold winters in Europe and North America, known as the ‘little ice age‘.”

Russell et al., 2010      “If we were to guess what the next solar cycle was going to be like from the behavior of the declining phase of solar cycle 23 to date, we would select solar cycle 4 beginning in 1785 as the analog of solar cycle 23 and solar cycles 5 and 6 as the analogs of the upcoming cycles 24 and 25. At this writing, the similarity of the inability of the new cycle to take hold with significant new cycle activity at high latitudes is striking. The epoch of cycles 5 and 6 has also been called the Dalton minimum, during which the sunspot number maximized at close to 50. It was also a period of global cooling.”


Miyahara et al., 2010     “Specifically, the “Little Ice Age” covers a cyclic period of cooling and glaciation which began in the 13th century and which continued into the 16th to 19th centuries, when glaciers began advancing southwards in Greenland and the North Atlantic, and perhaps worldwide. These episodes of global cooling appear to be linked to reduced solar activity. By contrast, the Medieval Warm Period occurred during a period of heightened solar activity. If these associations are valid, then future cyclic alterations would be expected to impact global temperatures including perhaps triggering another period of global cooling if sunspot activity is again reduced to a minimum. … The Sun is currently showing slightly different behavior compared with recent decades (Livingston & Penn, 2009). Consequently, concern has emerged regarding whether the Sun is approaching the next Maunder Minimum of reduced activity. Given this scenario, it has been suggested that global temperatures may decrease by about 0.3 °C as a result of a reduction in total solar irradiance (Feulner & Rahmstorf, 2010).”

Scafetta, 2012     “The model forecasts a new prolonged solar grand minimum during 2020-2045, which would be produced by the minima of both the 61 and 115-year reconstructed cycles. Finally, the model predicts that during low solar activity periods, the solar cycle length tends to be longer, as some researchers have claimed. These results clearly indicate that solar and climate oscillations are linked to planetary motion and, furthermore, their timing can be reasonably hindcast and forecast for decades, centuries and millennia.”

Archibald, 2007     “Our forecast for global average temperature to 2030 has been updated for the progression of Solar Cycle 23 and the contribution that will be made by increased carbon dioxide in the atmosphere. The increased length of Solar Cycle 23 supports the view that Solar Cycle 24 will be weak, with the consequence of increased certainty that that there will be a global average temperature decline in the range of 1° to 2° C for the forecast period [by 2030]. The projected increase of 40 ppm in atmospheric carbon dioxide to 2030 is calculated to contribute a global atmospheric temperature increase of 0.04°C. The anthropogenic contribution to climate change over the forecast period will be insignificant relative to natural cyclic variation.”

Landschiedt, 2003     “Analysis of the sun’s varying activity in the last two millennia indicates that contrary to the IPCC’s speculation about man-made global warming as high as 5.8° C within the next hundred years, a long period of cool climate with its coldest phase around 2030 is to be expected. It is shown that minima in the 80 to 90-year Gleissberg cycle of solar activity, coinciding with periods of cool climate on Earth, are consistently linked to an 83-year cycle in the change of the rotary force driving the sun’s oscillatory motion about the centre of mass of the solar system. As the future course of this cycle and its amplitudes can be computed, it can be seen that the Gleissberg minimum around 2030 and another one around 2200 will be of the Maunder minimum type accompanied by severe cooling on Earth. This forecast should prove skillful as other long-range forecasts of climate phenomena, based on cycles in the sun’s orbital motion, have turned out correct as for instance the prediction of the last three El Niños years before the respective event.”

The North Atlantic Region – Linked To Global Climate – Has Already Been Cooling Rapidly

Chafik et al., 2016       “The multidecadal variability of the North Atlantic Ocean has a strong signal in the sea surface temperature with many global climate linkages [Enfield et al., 2001; Knight et al., 2006]. An even stronger multidecadal signal can be found in the subpolar temperatures and salinities, where the Atlantic Water inflow variations constitute an essential part in the variability [Hátún et al., 2005; Häkkinen et al., 2011a; Reverdin, 2010]. The atmospheric forcing in the subpolar North Atlantic Ocean is dominated by the variability of the North Atlantic Oscillation (NAO), i.e., the leading mode of atmospheric variability in the North Atlantic sector, which modulates the atmosphere-ocean momentum and heat exchanges on a range of temporal scales. The subpolar ocean variability thus appears to be tightly connected to atmospheric forcing and associated basin-scale circulation changes, which together force the subpolar ocean properties toward extremes [Lozier et al., 2008, 2010], either to warm-saline or cold-fresh conditions on multidecadal scales. These regime changes [in the North Atlantic] have recently been argued to be important for global mean surface temperature warming acceleration and hiatus [Chen and Tung, 2014; Drijfhout et al., 2014].”


Duchez et al., 2016       “[C]old ocean temperatures were the most extreme in the modern record [since 1948] over much of the mid-high latitude North-East Atlantic. … we consider the exceptionally cold ocean surface anomaly that was already in place prior to the onset of the 2015 heat wave. The SST anomaly field for June 2015 shows temperatures up to 2 °C colder than normal over much of the sub-polar gyre with values that are the coldest observed for this month of the year in the period 1948–2015 indicated by stippling. The cause of this cold anomaly has been the subject of widespread interest in the media, we now show for the first time that it can be attributed to a combination of air–sea heat loss from late 2014 through to spring 2015 and a re-emergent sub-surface ocean heat content [cold] anomaly that developed in preceding years.”

Robson et al., 2016       “In the mid-1990s the North Atlantic subpolar gyre warmed rapidly, which had important climate impacts such as increased hurricane numbers and changes to rainfall over Africa, Europe and North America. Evidence suggests that the warming was largely due to a strengthening of the ocean circulation, particularly the Atlantic Meridional Overturning Circulation. Since the mid-1990s direct and indirect measurements have suggested a decline in the strength of the ocean circulation, which is expected to lead to a reduction in northward heat transport. Here we show that since 2005 a large volume of the upper North Atlantic Ocean has cooled significantly by approximately 0.45 °C or 1.5 × 1022 J, reversing the previous warming trend.”

Share this...FacebookTwitter "
"Never has a song epitomised conspicuous consumption so tellingly as the [Twelve Days of Christmas](https://en.wikipedia.org/wiki/The_Twelve_Days_of_Christmas_(song). And the gifts mentioned come at quite a price. Last year, Fortune’s Christmas Price Index estimated that the cost of all of the presents mentioned in the song – from the patridge in the pear tree to the gold rings – was $27,673 (£18,500), or $116,273 (£80,000) if you calculate the cumulative total of 364 gifts, taking into account all of the repetitions. So perhaps we should use this popular seasonal song to help us think specifically about our own choices and our planet’s future as we enter the festive period of bingeing and consumption. The “fowl”-heavy gift list would suggest that the recipient is a robust, game-eating omnivore. Partridge, hens and geese are traditional festive foods, but the rearing and consumption of all of these has an impact in terms of sustainability. Partridges are a red-listed species and need to be managed effectively in order to maintain their declining populations. Chickens are in no such immediate danger, but many live miserable lives, even with the new UK rules on husbandry. The choice of a goose for Christmas dinner is likely to be a more sustainable one, however, since most are bred in small flocks by small-scale farmers and their production has yet to be overly mechanised. Milk and cream consumption peaks at Christmas, but the milkmaids of the song hark back to a pre-mechanical era – and these days most milk is produced in high-tech dairies. The spectre of industrial mega dairies containing tens of thousands of cows is increasingly likely as farmers struggle to make a living out of small-scale production. We should also remember that milk is not produced without various unfortunate by-products, including calves.  Given the animal welfare, social and environmental impacts of festive fodder, perhaps the best, most sustainable choice would be to have a vegetarian or even vegan Christmas dinner. Failing that, we could all consider Arnold Schwarzenegger’s advice and eat less meat – not just at Christmas but throughout the year. Doves have been a Christian symbol of love and peace since biblical times and are universally associated with hope. It is almost impossible to put a price on peace, but the costs of unrest and war in 2015 have been estimated by the Institute for Economics and Peace at more than 13.4% of global GDP, or around £9.21 trillion. Turtle doves, like global peace are in decline – and there is a real fear for their extinction.  The blackbirds, the calling birds of the song, are common and their song is heard almost everywhere. Sadly, most of us don’t listen – one gift to ourselves would be to pay more attention so that we are more in tune with the natural world around us. The five gold rings are thought to refer to ring-necked pheasants or even goldfinches, but most of us think about jewellery when we hear this – and most of us would like to receive something precious as a Christmas gift.  Sadly, gold is rarely a sustainable choice and Stephanie Boyd’s film The Price of Gold, certainly makes disturbing viewing. Perhaps it should make us reconsider the desirability of giving or receiving this precious metal. A long running myth is that the Queen owns all the “swans-a-swimming” in England, but the story probably stems from old traditions such as swan-upping, the annual census of swan numbers on the Thames.  The notion of privilege is a strong theme in the song with “ladies dancing” and “lords a-leaping”, bringing a vision of old-fashioned privilege to our minds. Certainly privilege is apparent in the UK, the most unequal country in the EU – and few of us will ever reach Lord or Lady status, never mind enjoy the associated wealth or influence.  Instead of feeling marginalised and resentful about our own limited material wealth or power, however, perhaps we should reflect on our privilege. The Twitter hashtag #firstworldproblems, has possibly been overused of late, but the sentiments behind it are increasingly relevant. In a world of unrest, ill-health, war and disaster, there has never been a better time to count our blessings and use our emotional energies to find solutions. The finale of the song sees gifts of music from pipers and drummers. This year we may have something to make a noise about. The Paris Climate agreement gives the world hope that we can find solutions to climate change, and prevent the worst-case climate scenarios. The power of civil society in pressurising governments around the world to agree to ambitious targets has been demonstrated, and perhaps we, the public, are now calling the tunes. It’s time politicians the world over began marching to a different drum beat."
"Ask the average person what they know about Easter Island and those monumental statues with their inscrutable expressions would likely top the list. For many this is the sum total of their knowledge, for the excellent reason that Easter Island is a very small and exceptionally remote spec in the eastern Pacific.  Administered by Chile 3,600km to the east, and some 2,000km from its nearest inhabited neighbour, Pitcairn Island (a UK overseas territory), Easter Island is in fact one of the remotest inhabited places on Earth. Apart from statues and inaccessibility, the other notable thing about Easter Island is the ecological disaster that led society there to collapse into warfare and starvation several centuries ago. We still don’t know exactly what happened, but the classic and still convincing story says that Easter Islanders chopped down all their trees to erect statues. The result was soil erosion, loss of fertility and the collapse of food production. And with no trees to make boats, fish were hard to catch on the rugged wave-tossed, cliff-lined coasts and the people became cut off from the rest of the Pacific.  For a place surrounded by trackless seas, Easter Island’s stories have remained resolutely land-bound. But that may soon change. Plans are afoot to turn a vast area of neighbouring ocean into a marine protected area. An announcement from Chile’s president, Michelle Bachelet, is expected on October 5.  Conservationists who have spent years campaigning for protection, like the Pew Environment Group’s Global Ocean Legacy program, hope the protected area will be very large, and enforced by Chile’s navy. If current plans are realised, Easter Island will become one of the biggest marine protected areas in the world with industrial fishing by non-islanders banned for 200 miles in all directions.  Locals still haul their lines in by hand which limits their catch. Their fishing association supports the marine park as it will give them some protection from illegal competition – islanders will still be able to fish up to 50 miles offshore. But what is special about these seas? It is that isolation again. The island’s remote setting has so far spared its seas from the worst depredations of the world’s distant water fishing fleets. In places that are easier to reach, populations of big fish such as tuna, swordfish and sharks have been driven down by intensive industrial long-lining and purse-seine nets. Long-lines may be tens of kilometres long and can carry tens of thousands of hooks, while purse seine nets are used to surround whole schools of fish and anything else that happens to be with them, such as turtles and dolphins. Such fishing has led to losses of 90% or more in vulnerable species like oceanic whitetip sharks or leatherback turtles. Isolation also means that Easter Island, although not as rich in species as places further west in the Pacific, has a bevy of sea creatures found nowhere else in the world including colourful dwarf angelfish, hermit crabs, tiny starfish and a slipper lobster. It’s a tightly connected web – some of these endemic species feed mainly on other endemic species. If they disappear from here, they disappear everywhere, so safeguarding them is a priority.  If Easter Island’s waters receive the protection they deserve, this place will join a growing number of very large marine protected areas being set up today. There is a long overdue wave of conservation action going on in the sea that has parallels with pioneering efforts to create the national parks of North America and Africa in the late 19th and 20th centuries.  The UK established 640,000km2 of protection around its Indian Ocean Territory of the Chagos in 2010, and has promised an even larger area around Easter Island’s “neighbour”, Pitcairn. New Zealand has just announced a 620,000km2 protected area around the Kermadec Islands, halfway between Auckland and Tonga. Back in Britain the Conservative government has pledged to create a “Blue Belt” of protection around all 14 of its overseas territories during this government. Even with these welcome developments, we may still fall short of the 10% coverage of marine protected areas that the world agreed to establish by 2020 under the UN Convention on Biological Diversity. Nonetheless, at long last, we seem to be heading in the right direction. There is good news at last for embattled ocean life."
"Sweden has built the first smart road that will allow electric vehicles to charge as they drive. The eRoadArlanda pilot scheme, which covers two kilometres of road outside Stockholm, is an attempt to solve one of the biggest challenges that the transport industry faces. Namely, how to move freight and people in a way that neither damages the climate through greenhouse gas emissions nor the quality of air through nitrogen oxide pollution. The eRoadArlanda scheme is supposed to extend the range of electric vehicles beyond what was previously possible. Yet as an engineer, I have concerns about the durability of this road. Even more significantly, the cost of the technology and the disruption that building it causes is likely to restrict any mass scale replication. If this solution cannot be widely replicated then it is really no solution at all. Instead, a serious attempt to reduce hazardous emissions should focus on more practical solutions, such as the development of long-range batteries and the building of more electric charging stops. This new Swedish smart road will feel familiar to anybody who has played with slot car racing toys, such as Scalextric. Although, unlike slot cars, drivers will still have to steer vehicles. Instead, electric vehicles will collect power from charging rails set into the surface of the road. When on the road, a pickup arm attached to the bottom of the vehicle will extend downwards until it senses the rails, before slotting in and making electrical contact. This device is flexible, allowing the vehicle to move from side to side and the pickup can be retracted and reinserted in case a truck wants to overtake or turn off the road. But questions remain over the road’s durability. To prevent electrocution or damage by the elements, the live rails are hidden from view. This means that vehicles can only begin charging when the pickup is inserted into the rail slot. One can imagine the damage that might be caused to the road and the vehicle if the pickup fails to disengage cleanly before the vehicle attempts an overtaking manoeuvre.  An alternative technology that bypasses this problem is inductive transmission. Unlike eRoadArlanda, inductive transmission enables wireless charging. Conductors that are set into the road create an electromagnetic field, which then transmits energy to coils mounted to the bottom of vehicles. Such technology is already used by wireless phone chargers and can be adapted on a bigger scale for electric vehicles. Canadian manufacturer Bombardier has successfully demonstrated how this could work, and the US company Qualcomm has designed a system that has charged the racing cars of Formula E. Yet this technology, like eRoadArlanda, is particularly expensive and disruptive to install. Rail enthusiasts might claim that rail electrification has already solved the problem of clean, rapid movement of freight in a way that reduces road congestion. But rail transport can’t deliver goods from door to door and only the largest manufacturers are able to justify the operation of their own rail terminals. Even with rail electrification, there is a need to move freight between rail and road, just as we need to connect rail links with ferry ports and airports. Battery charging on the move seems an attractive solution, particularly at a time when we have too few electric vehicle charge points. But the cost of eRoadArlanda (£870,000 per kilometre) and the disruption it would cause if it were extended nationwide, makes other options more appealing. For example, long-range batteries and hydrogen fuel cell vehicles have the potential to overcome issues of price, disruption and durability. In fact, these options are already becoming cheaper. The price of lithium-ion batteries has fallen by 24% since 2016 and will fall further as more people adopt electric vehicles. As batteries improve and get cheaper, digging up our motorways seems an extreme solution. Even something as simple as building more electricity and hydrogen recharging truck stops would be preferable to vehicle-charging roads. All vehicles spend a large part of their lives stationary, so a far simpler and less disruptive solution is to charge vehicles at stops and destinations as electric cars currently do.  Whichever low carbon transport solution ends up dominating the market, we should not forget the options of transferring more freight to the railways or simply moving less of it around. This would require all of us to consume less and use products for longer. It might not be as exciting as building vehicle-charging roads, but extending the life span of products you already own, through recycling, refurbishment and remanufacturing is the cheapest and least disruptive way to reduce hazardous fumes."
"
Share this...FacebookTwitter
Graph Source Duchez et al., 2016
Contrary to expectations, climate scientists continue to report that large regions of the Earth have not been warming in recent decades.
According to Dieng et al. (2017), for example, the global oceans underwent a slowdown, a pause, or even a slight cooling trend during 2003 to 2013.  This  undermines expectations from climate models which presume the increase in radiative forcing from human CO2 emissions should substantially increase ocean temperatures.
The authors indicate that the recent trends in ocean temperatures “may just reflect a 60-year natural cycle“, the AMO (Atlantic Multidecadal Oscillation), and not follow radiative forcing trends.
Dieng et al., 2017    We investigate the global mean and regional change of sea surface and land surface temperature over 2003–2013, using a large number of different data sets, and compare with changes observed over the past few decades (starting in 1950). … While confirming cooling of eastern tropical Pacific during the last decade as reported in several recent studies, our results show that the reduced rate of change of the 2003–2013 time span is a global phenomenon. GMST short-term trends since 1950 computed over successive 11-year windows with 1-year overlap show important decadal variability that highly correlates with 11-year trends of the Atlantic Multidecadal Oscillation index. The GMST 11-year trend distribution is well fitted by a Gaussian function, confirming an unforced origin related to internal climate variability.

We evaluate the time derivative of full-depth ocean heat content to determine the planetary energy imbalance with different approaches: in situ measurements, ocean reanalysis and global sea level budget.  For 2003–2013, it amounts to 0.5 +/− 0.1 W m−2, 0.68 +/− 0.1 W m−2 and 0.65 +/− 0.1 W m−2, respectively for the three approaches.    Although the uncertainty is quite large because of considerable errors in the climate sensitivity parameter, we find no evidence of decrease in net radiative forcing in the recent years, but rather an increase compared to the previous decades.
We can note that the correlation between GMST [global mean surface temperature] trends and AMO trends is quite high. It amounts 0.88 over the whole time span. At the beginning of the record, the correlation with PDO trends is also high (equal to 0.8) but breaks down after the mid-1980s.  The GMST and AMO trends shown in Figure 6 show a low in the 1960s and high in the 1990s, suggestive of a 60-year oscillation, as reported for the global mean sea level by Chambers et al. (2012). Thus the observed temporal evolution of the GMST [global mean surface temperature] trends may just reflect a 60-year natural cycle driven by the AMO.
Subpolar North Atlantic Cooling Rapidly Since 2005
According to Piecuch et al. (2017) there has been no net warming of the North Atlantic Ocean in the last quarter century.  The warming that occurred in the 10 years from 1994-2004 has been completely negated by an even more pronounced cooling trend since 2005.   The predominant (87%) cause of the warming was determined to be of the same natural (non-anthropogenic) origin as the subsequent cooling: advection, the movement/circulation of heat via internal processes.   In fact, human CO2 emissions are never mentioned as even contributing to the the 1994-2004 warming.
Piecuch et al., 2017    The subpolar North Atlantic (SPNA) is subject to strong decadal variability, with implications for surface climate and its predictability. In 2004–2005, SPNA decadal upper ocean and sea-surface temperature trends reversed from warming during 1994–2004 to cooling over 2005–2015. … Over the last two decades, the SPNA has undergone a pronounced climate shift. Decadal OHC and SST trends reversed sign around 2004–2005, with a strong warming seen during 1994–2004 and marked cooling observed over 2005–2015. These trend reversals were pronounced (> 0.1 °C yr−1 in magnitude) in the northeastern North Atlantic (south and west of Iceland) and in the Labrador Sea. … To identify basic processes controlling SPNA thermal variations, we diagnose the SPNA heat budget using ECCOv4. Changes in the heat content of an oceanic control volume can be caused by convergences and divergences of advective, diffusive, and surface heat fluxes within the control volume.  [Advective heat convergence] explains 87% of the total [ocean heat content] variance, the former [warming] showing similar decadal behavior to the latter [cooling], increasing over 1994–2004, and decreasing over 2005–2015. … These results demonstrate that the recent SPNA decadal trend reversal was mostly owing to advective convergences by ocean circulation … decadal variability during 1993–2015 is in largest part related to advection by horizontal gyres.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Yeager and Robson (2017) also point out that, like it did from the 1960s to 1980s, the North Atlantic “has again been cooling”, a trend which they and others expect to continue.   Sea surface temperatures are no warmer today than they were in the 1950s.
Yeager and Robson, 2017    [W]hile the late twentieth century Atlantic was dominated by NAO-driven THC [thermohaline circulation] variability, other mechanisms may dominate in other time periods. … More recently, the SPNA [sub polar North Atlantic] upper ocean has again been cooling, which is also thought to be related to a slowdown in the THC. A continued near-term cooling of the SPNA has been forecast by a number of prediction systems, with implications for pan-Atlantic climate.


The Southern Ocean Has Been Cooling Since The 1970s, Contrary To Models
Latif et al., 2017    The Southern Ocean featured some remarkable changes during the recent decades. For example, large parts of the Southern Ocean, despite rapidly rising atmospheric greenhouse gas concentrations, depicted a surface cooling since the 1970s, whereas most of the planet has warmed considerably. In contrast, climate models generally simulate Southern Ocean surface warming when driven with observed historical radiative forcing. The mechanisms behind the surface cooling and other prominent changes in the Southern Ocean sector climate during the recent decades, such as expanding sea ice extent, abyssal warming, and CO2 uptake, are still under debate. Observational coverage is sparse, and records are short but rapidly growing, making the Southern Ocean climate system one of the least explored. It is thus difficult to separate current trends from underlying decadal to centennial scale variability.

Turney et al., 2017    Occupying about 14% of the world’s surface, the Southern Ocean plays a fundamental role in ocean and atmosphere circulation, carbon cycling and Antarctic ice-sheet dynamics. … As a result of anomalies in the overlying wind, the surrounding waters are strongly influenced by variations in northward Ekman transport of cold fresh subantarctic surface water and anomalous fluxes of sensible and latent heat at the atmosphere–ocean interface. This has produced a cooling trend since 1979.


Sea Ice Has Been Expanding For The Entire Southern Hemisphere Since The 1970s

Comiso et al., 2017    The Antarctic sea ice extent has been slowly increasing contrary to expected trends due to global warming and results from coupled climate models. After a record high extent in 2012 the extent was even higher in 2014 when the magnitude exceeded 20 × 106 km2 for the first time during the satellite era. … [T]he trend in sea ice cover is strongly influenced by the trend in surface temperature [cooling]. … A case study comparing the record high in 2014 with a relatively low ice extent in 2015 also shows strong sensitivity to changes in surface temperature. The results suggest that the positive trend is a consequence of the spatial variability of global trends in surface temperature and that the ability of current climate models to forecast sea ice trend can be improved through better performance in reproducing observed surface temperatures in the Antarctic region.


The Pacific Ocean Has Also Been Cooling Since The 1970s
Li, 2017    In the Southern Ocean, the increasing trend of the total OHC slowed down and started to decrease from 1980, and it started to increase again after 1995. In the warming context over the whole period [1970-2009], the Pacific was losing heat, especially in the deep water below 1000 m and in the upper layer above 300 m, excluding the surface 20 m layer in which the OHC kept increasing through the time.

Glaciers, Ice Sheets Stable, Even Gaining Mass
Goel et al., 2017    Ice rises are a useful resource to investigate evolution and past climate of the DML coastal region. We investigate Blåskimen Island ice rise, one of the larger isle-type ice rises at the calving front of the intersection of Fimbul and Jelbart Ice Shelves, using geophysical methods. … Using the Input-Output method for a range of parameters and column setups, we conclude that Blåskimen Island has been thickening over the past nine years [2005-2014]. Thickening rates cannot be determined precisely, but ensemble results show that thickening rate averaged over the ice rise varies between 0.07 m a−1 and 0.35 m a−1 [per year]. On longer timescales, we speculate that  the summit of Blåskimen Island has been stable within several kilometers at least in the past ∼600 years but no longer than several millennia.
Bader et al., 2017    Rather than reflecting major changes in ice flow path over time, the provenance changes are interpreted to indicate relative stability of the East Antarctic ice sheet.
Martín-Español et al., 2017    We investigate the mass balance of East Antarctica for 2003–2013 using a Bayesian statistical framework. … We apportion mass trends to SMB and ice dynamics for the EAIS, based on two different assumptions, different remote sensing data and two RCMs. In the first experiment, the model apportions about a third of the mass trend to ice dynamics, +17 Gt/yr, and two thirds, +40 Gt yr−1 to SMB, resulting in a total mass trend for the EAIS [East Antarctic Ice Sheet] of +57 ± 20 Gt yr−1.

Bolch et al., 2017    Previous geodetic estimates of mass changes in the Karakoram revealed balanced budgets or a possible slight mass gain since ∼ 2000. Indications of longer-term stability exist but only very few mass budget analyses are available before 2000. Here, based on 1973 Hexagon KH-9, ∼ 2009 ASTER and the SRTM DTM, we show that glaciers in the Hunza River basin (central Karakoram) were on average in balance or showed slight insignificant mass loss within the period ∼ 1973–2009.
Predictions Of Future Cooling, Ice Expansion
Årthun et al., 2017    Statistical regression models show that a significant part of northern climate variability thus can be skillfully predicted up to a decade in advance based on the state of the ocean. Particularly, we predict that Norwegian air temperature will decrease over the coming years, although staying above the long-term (1981–2010) average. Winter Arctic sea ice extent will remain low but with a general increase towards 2020.
Pittard et al., 2017    We suggest the Lambert-Amery glacial system will remain stable, or gain ice mass and mitigate a portion of potential future sea level rise over the next 500 years, with a range of +3.6 to -117.5 mm GMSL-equivalent.
Share this...FacebookTwitter "
"Plans to shift Europe’s coal plants to burning wood pellets instead could accelerate rather than combat the climate crisis and lay waste to woodland equal to half the size of Germany’s Black Forest a year, according to campaigners. The climate thinktank Sandbag said the heavily subsidised plans to cut carbon emissions would result in a “staggering” amount of tree cutting, potentially destroying forests faster than they can regrow.  Sandbag found that Europe’s planned biomass conversion projects would require 36m tonnes of wood pellets every year, equal to the entire current global wood pellet production. This would require forests covering 2,700 sq km to be cut down annually, the equivalent of half the Black Forest in Germany. The majority of wood pellets are imported from the US and Canada, “meaning that there’s a huge added environmental cost in transporting the wood from the other side of the Atlantic”, said the report’s author, Charles Moore. The planned biomass conversions – with Finland, Germany and the Netherlands leading the way – would emit 67m tonnes of carbon into the atmosphere, which would be unlikely to be reabsorbed by growing trees over the timescales relevant to meeting the targets set by Paris climate agreement, warned Sandbag. In return, the forest-hungry power plants would produce less than 2% of the EU’s electricity needs – the same generation capacity built in Europe every year by wind and solar farm developers. “It’s impossible to believe coal companies when they argue that the switch to burning forests could be good for the climate,” Moore said. EU regulators consider biomass as a carbon neutral renewable alternative, saying that the growth of new trees can absorb as much carbon as wood pellets release when they are burned to generate electricity. The Drax energy complex in North Yorkshire has used this logic to underpin its plan to become the world’s first “carbon negative” company within 10 years by burning biomass in conjunction with technology that can capture carbon from its power plant flues. Drax robustly defends the sustainability record of its biomass supply chain. Its wood pellets, shipped from the US, are made mostly from sawmill residue and forest overgrowth, which is carefully cleared to improve the quality of forests. Drax has pledged never to source biomass from farming practices that lead to deforestation. But Alex Mason, from WWF’s EU office, said burning forests was “literally the opposite of what we should be doing” to help tackle the climate crisis. “As 800 scientists pointed out last year, converting coal plants to biomass will increase emissions for decades, if not centuries. This new report is yet more evidence that the EU must use the new EU Green Deal to fix EU bioenergy rules before this ticking time-bomb of a policy does any more damage,” he said. Prof Michael Norton, a director at the European Academies Science Advisory Council, said large-scale forest removal to meet the demand for biomass would be “horrifying from a climate perspective” and already risks overshooting the Paris agreement targets. He said European countries were moving ahead with plans for giant biomass plants despite reports showing “the counter-productive nature of biomass” and the urgent need to stop deforestation. A Drax spokesperson said: “Drax only uses sustainable biomass sourced from managed forests that are replanted and stay as forests, absorbing carbon as the trees grow. Drax will not use biomass that drives harvesting decisions which would adversely affect the long-term potential of forests to store carbon. These commitments are central to our new biomass sustainability policy, launched in October. We also have a new advisory board – an independent group of scientists, academics and forestry experts, which will ensure our biomass sourcing meets the highest standards using the latest science and best practice.” This article was amended on 16 December 2019. Due to an editing error an earlier version suggested Drax was one of the planned biomass conversions referred to in the Sandbag report. Drax has already completed its biomass conversion works. This has been corrected. A statement from the company has also been added."
"
Share this...FacebookTwitterWhat follows is a list of reasons compiled by this German site here on why wind is a poor source of power.
There are eight disadvantages that cannot be ignored, the site writes. What follows are the eight reasons along with my own descriptions.
1. Unstable, erratic power supply
The wind doesn’t blow constantly, and so the supply is unstable and wildly fluctuating. In many locations the wind may disappear for days or even weeks at a time. Then in periods of high winds the power grid can become overloaded, or the turbines have to be shut down to avert serious mechanical damage. Overall wind turbines in Germany put out only a lousy 18% of their installed rated capacity.
2. Wind turbines are expensive
The ROI for turbines can take many years, and makes sense only in places where the wind blows often, e.g. coastal areas, offshore or hill tops. But that makes the installation far more expensive. Many investors have seen very disappointing results from wind projects. Moreover in Germany, electricity prices have skyrocketed over the past years in large part due to the mandatory feed-in of wind energy.
3. Excess power is extremely difficult to store
So far scientists and engineers are a long way from finding a solution for storing electricity. Batteries are expensive and heavy, and require massively extensive mining operations. Pump storage techniques are possible only in limited places, and they too are horribly inefficient. Converting wind-generated electricity into a gas such as hydrogen and then back into electricity when wind is calm is expensive and inefficient as well.
4. Destruction of natural habitat


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




As installing wind turbines in residential areas is problematic, wind parks often are located in rural or natural areas – even in the middle of forests. This entails the industrialization of natural habitats. Plants and wildlife lose their habitats, or are adversely affected. Areas are often deforested to make way for the turbines. Access roads rip though the forests, permanently damaging or even destroying the local biotope. The same is true for offshore turbines. Turbines often pose a hazard to endangered species.
5. Bird kill: death from turbine blades
If industrializing natural landscape were not bad enough, wind turbines are also a real hazard to migrating birds. Each year millions of birds are (unnaturally) killed by wind turbines worldwide. According to Nature, up to 440,000 birds are killed in the USA each year. Conventional power plants on the other hand, do not kill anywhere near as many birds. Wind turbines also kill many bats.
6. Danger from flying ice
In the wintertime, ice is known to form and build up on the blades, only later to dislodg and be thrown projectiles, posing a danger to people and property located nearby. Already near misses have been recorded.
7. Aesthetics and property values
In early times wind turbines were a fascination. But today they are much larger in size and people have grown tired of their ugliness. In North Germany, for example, it is often difficult to leave your home without having to see one. In Germany there have been literally hundreds on citizens initiatives against the construction of wind parks. People are fed up with the industrial blight in the middle of Natur that wind energy really is.
Ugly wind turbines seriously depress property values.
8. Wind turbines produce noise and infrasound
Wind turbines are not quiet. Moreover they produce infrasound: low frequency sound below the human threshold of hearing. However, infrasound is sensed by the inner ear as pressure pulses that have been scientifically found to make people ill and even damage their health.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSome years ago German warmist climatologist Mojib Latif complained over our changing climate, reminding us how in Germany we used to get snow sometimes for Easter.
Well this year, in mid April, Easter is relatively late, and the forecast is now calling for snow to hit large parts of Europe as a low pressure system (OTTO) centered over the Baltic sea will pump polar air across the continent — thus ushering in a nasty and possibly protracted spell of winter.

Germany’s DWD forecast for April 15. Otto’s cold front will pump in cold and moist polar air to kick off an unusual wintery April cold wave: Source: www.wetteronline.de/wetterfronten/europa.
German weather and climate site wobleibtdieerderwaermung.de here provides a good analysis of the situation. Ahead for the coming days are frost and snow. What follows are the GFS snow forecast charts from wetteronline.de for April 17, 18 and 19, which show widespread snowfall across Central Europe, even reaching down to the Mediterranean by Wednesday:



Chart sources: wetteronline.de
According to the WBDE site, temperatures in Europe will plummet by up to 12°C below normal.
NOAA caught by surprise, revise forecast
The April cold wave took the NOAA by surprise. The US weather and climate organization had predicted an outright balmy April back on March 22, 2017:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





CFSv2 April temperature prognosis of March 22, 2017. Source: www.cpc.ncep.noaa.gov/products/CFSv2/htmls/euT2me3Mon.html
Obviously the NOAA weather models had some major blind spots back in March (which is understandable), as much of Europe was projected to be 2°C warmer than the long-term mean.
But later on when the cold became obvious, the NOAA was forced to update its April 2017 forecast:

CFSc2 temperature forecast for April 2017. Much of the forecast was corrected significantly downward. Source: www.cpc.ncep.noaa.gov/products/CFSv2/htmls/euT2me3Mon.html
On the other hand March 2017 across Central Europe was very warm, and had a number of media outlets blaming it on global warming. Germany even saw a new warm record set for the month of March. Perhaps that skewed the forecasters into thinking the warmth would continue, all in line with their global warming beliefs.
Trend: spring in fact coming later and later
The German DWD then added that spring was starting earlier and earlier – due to climate change, but did not mention that you have to go back some 60 years to get an overall warming trend line. However over the past 30 years, German springs have in fact been starting later and later – a reality that the DWD conveniently omitted.
This year it appears winter will be pushing spring back to May. Midterm forecasts show the cold wave will persist at least another week.
Warmists will naturally be quick to point that late-April snow in Central Europe is really nothing that unusual, which is true — if the cold spell lasts only a matter of days. However, as Wetter24 here notes, what is about to hit the continent will persist and thus be indeed unusual. It writes of April weather in Germany:
On the other hand what is unusual is a longer-lasting phase with significantly below or above normal temperatures. And it is such a phase that is now approaching with an anticipated long period of below normal temperatures.”
The bottom line: “thing-of-the-past” snow and frost are still ignoring “global warming” and are still showing up in April. Earlier predictions that they wouldn’t are wrong.
Share this...FacebookTwitter "
"In the weeks before Christmas, the main street of Braidwood is quiet. Summer is ordinarily peak tourist season, with families from Canberra stopping in on the way to Bateman’s Bay, but the recent bushfires, which still burn nearby, have put an end to travel to and from the coast. Many businesses are simply closed, with handwritten signs taped to the windows— “closed today due to bushfire conditions” – as shopkeepers head out with the RFS or stay in their own homes to defend them if the fire front shifts. Hot, dry winds scatter ash and powdery topsoil over town, forcing locals inside, and the pub, when it’s open, is full of exhausted RFS volunteers, instantly visible in their bright yellow and soot-smeared faces. The town has been absolutely covered in smoke, thick smoke, for weeks The worst days of the fire have passed but there is a lingering feeling of suspended animation in town, with nobody able to predict when the danger will pass.  The town’s economic future is a major source of apprehension. Over the past few years, Braidwood, formerly nicknamed “Deadwood”, has become rejuvenated by a steady stream of young families and newcomers, who have moved for lower prices and to join the town’s long-established creative community. But many of the ventures which give Braidwood its particular flavour rely on passing trade; the Kings Highway closure has set businesses up for a very hard new year. The RFS is still being called out, and mosquito squads are travelling out to fight fires as well, with water barrels strapped to the back of utes. Those in town, left worrying about family and friends, are now beginning to contend with how life has changed since the bushfires began – a question that will occupy more and more people as the summer goes on. For Kelly Sturgiss, the bushfires came on the heels of a hard few months; her small business, Sturkella Music, has only recently launched, and she is still recovering from an injury sustained at her second job as a waitress. Broken glass severed a tendon in her hand, which required intensive surgery. Like many small business owners, the ongoing disruption has put her in a financially precarious situation. As a sole trader, her income is irregular, and contingent on the number of hours she works. School closures at St Bede’s primary school, where she teaches privately, have meant that she’s missed weeks of scheduled music lessons, and road closures have forced her to cancel the lessons she gives in Canberra. Like a lot of people, she mentions feeling guilty for worrying about her own problems when people are losing properties and homes. She knows that she is lucky, but her breathing is audible and her voice rasps; her lungs, affected by a chronic condition, have been struggling to cope with the polluted air. “I am using a lot of Ventolin. My lungs have been very affected. It’s a shame because I’d done a lot of recovery and now I feel like I’m back to square one.” To help pass the time, she has opened her house to local kids, holding impromptu jam sessions and giving pointers to anyone interested. “It was really nice to be able to provide that space for children to feel a bit normal, and maybe express their feelings as well.” “I think every man and his dog who’s not in the RFS wishes they could be out there fighting the fires right now,” Karuna Bajracharya says. “When they started, we sat down and thought about what we’re good at – and we’re good at events, so we decided to do a fundraiser.” Bajracharya and his wife, Karuna, run a Himalayan restaurant and bar, The Smokey Horse, which hosts a regular Sunday session. They advertised the event on social media, adding a note asking Canberrans to come patronise Braidwood businesses if they could. The response to this appeal was immediate. “People came to the fundraiser that I’d never seen before, who told us that they’d come because they wanted to support Braidwood,” Bajracharya says. “They went up and down the street buying their veggies and their Christmas presents. That was really touching.” The fundraising event raised $3,000, which he is planning to donate directly to various local RFS branches, alongside a percentage of the bar’s takings from the night. As well as running the venue, Bajracharya has been taking care of the children, while Garung commutes to Canberra for work. Snow was excited about the school closures, but Pema, his older sister, has been frustrated about missing the last few weeks. With telecommunications dropping out, she’s concerned about her friends on rural properties, and ongoing news coverage of the crisis hasn’t helped. “The news just makes everyone sad,” she says. “[The newsreaders] just make everyone scared and feel worse. I think I’m OK because I live in town, but one of my friends was really panicking on the day that got bad. She lives out on a farm and her pop lives out on a farm. I don’t know what’s happened to her now, but she was really worried.” Jacqui Singh moved to Braidwood a few years ago from the Blue Mountains in order to help care for her partner’s late father. Her kids go to school in town, and are both members of the 1st Braidwood Scouts, where at the last meeting of the year Santa takes a break from his work in the RFS to drive in on a fire truck and deliver presents. “I’ve definitely noticed that it’s been something that the whole community’s feeling,” she says, as children tear around. “I think a lot of people have pulled together, and are trying to make the best of a situation we have no control over.” Singh is the proud owner of new kidney, “Kareem”, which she received three months ago. Before the transplant, she had dialysis at home, using a machine that was ill-equipped to deal with extreme temperatures and which would have made evacuation difficult. She’s thankful that the timing worked out as it did, especially in giving her a period of respite. “One of the blessings of being off work for a period of time is that I have been able to focus on the children a bit more. Kids pick up on your anxiety, so I’ve been trying to manage that so that they’re not stressing out, trying to make school closures into something fun, like a pyjama day. It’s been difficult, though, because of the health concerns from the smoke.” Michelle Heaney and Norma Flack live across the road from each other, and spend their Fridays at the op shop, sorting through donations. Sitting at a table in the back room, they recount the anxiety of the past few weeks, prompting each other when need be. Anybody who denies climate change today needs their head read Flames had reached the tree line behind Flack’s house when helicopters arrived, “like something out of a western”, she says. Though the area has seen bushfires before, Flack had not experienced a fire as intense as this. The recent drought exacerbated the fire conditions, but Flack has witnessed the region become drier over her lifetime. “Our beautiful river is not like it should be,” she says. “It was magical in a good time. We used to say ‘aren’t we lucky?’ Now, all that water is gone.” Heaney, a long-time environmentalist, remembers Christmas beetles so thick she could scoop them out of the air. She’s spent decades trying to prevent a catastrophe like these fires, being sneered at “as either a greenie leftie ratbag or a latte-sipping elitist”, depending on the times. In the wake of the fires, she’s grappling with fury and grief, and the persistent sense that the world she knows will soon be gone. “What can you do?” she asks. “You can’t do anything. You can go out there and protest and they put you in jail, or hit you for $5,000 cause you go out there and speak truth, or what your version of the truth is … Anybody who denies climate change today needs their head read. It’s as real and as potent and as terrifying as they had predicted in the early 70s, and I know, because I was there.” “The clean-up is always hard, and ongoing,” Felicity Sturgiss says, steering her 60 Series Landcruiser down the burnt-out Little Bombay Rd. Almost every second day since the fires began she’s been loading up with hay as well as fruit and vegetables she’s collected from local IGAs, and navigating through bushfire-ravaged areas to deliver it to surviving animals. There are several wombats she is feeding, who emerged from their burrows to a devastated landscape. She’s seen a few joeys, photographing those with burns to provide information for animal rescue groups, and to her delight a water dragon has settled in a dry creek bed she’s lined with slices of watermelon. She’s also rigged up watering holes out of a combination of old barrels, lengths of pipe, plastic floats and blue-shell swimming pools, a system that is tiding over birds and insects, as well as (judging from animal trails in the ash) kangaroos, skinks, goannas and an echidna. “Coming out here is about caring for the country,” she says. “And the responsibility we have to look after it.” After leaving Braidwood to study and travel, she’s returned to make a life working with the environment she grew up in. “You don’t have to join a group … just push back a little,” she says. She pauses. “It always feels like you can never do enough. But it’s about learning to cope with the fact that you just do what you can.”"
"
Share this...FacebookTwitterMeteorologist Paul Dorian of Vencore Weather here presents an analysis of the just now ending winter of 2017. It’s nothing you’d expect from a world that is supposedly warming.
===========================
As the following Environment Canada chart shows, snow is running at well above normal levels across the Northern Hemisphere”

Europe had an extended period of colder-than-normal weather in April accompanied by lots of snow.
Now much of the US is experiencing an extended period of colder-than-normal weather as we transition from early-to-mid May.
Snowfall has been running at above normal levels this winter across the Northern Hemisphere and continues at those higher-than-normal levels as we head towards the middle of May.
Arctic now cooler than normal
In addition, temperatures in the Arctic region – which have been generally running at above-normal levels in recent weeks – have actually dropped to below-normal in recent days and, if this trend continues, it should prevent any chance for sea ice extent to reach record lows up there this summer.

Temperatures in the Arctic region (>80 degrees N) have fallen to below-normal levels (circled area) in recent days following several weeks at generally above-normal levels; map courtesy Weather Bell Analytics/Dr. Ryan Maue




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




One of the main factors contributing to this late season cold across much of the Northern Hemisphere is a blocking pattern in the upper part of the atmosphere centered over Greenland and Iceland and this tends to contribute to cold air outbreaks into the land mass areas on both sides of the Atlantic Ocean.
&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img src=”https://static1.squarespace.com/static/56530521e4b0c307d59bbe97/t/5911cbf79de4bbb96b923fae/1494338560165/”  alt=”Temperatures in the Arctic region (&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;80 degrees N) have fallen to below-normal levels (circled area) in recent days following several weeks at generally above-normal levels; map courtesy Weather Bell Analytics/Dr. Ryan Maue”&amp;amp;amp;amp;amp;lt;/p&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;p&amp;amp;amp;amp;amp;gt;During the month of April, Europe experienced a persistent colder-than-normal pattern and significant snow piled up in the Alps across the central part of the continent. &amp;amp;amp;amp;amp;nbsp;The air was so cold, in fact,&amp;amp;amp;amp;amp;nbsp;that many vineyards from England-to-Italy suffered serious losses as the battle with freezing conditions was relentless in many areas. &amp;amp;amp;amp;amp;nbsp;In the US, a colder-than-normal pattern has kicked in for much of the nation and should continue into the middle of the month and there has been some accumulating snow in the western US and across portions of the Northern Plains and interior Northeast. &amp;amp;amp;amp;amp;nbsp;In fact, the next ten days or so will see more in the way of accumulating snow in the western US and many ski resorts in that part of the country will have good conditions right into the month of June. &amp;amp;amp;amp;amp;nbsp;The Sierra Nevada Mountains of eastern California, for example, will get more substantial snowfall over the next ten days or so to add to the massive totals that they received this winter.&amp;amp;amp;amp;amp;lt;/p&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;/div&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;/div&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;div id=”block-yui_3_17_2_1_1494338383854_30669″ class=”sqs-block image-block sqs-block-image sqs-text-ready” data-block-type=”5″&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;div id=”yui_3_17_2_1_1494352393596_136″ class=”sqs-block-content”&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;div id=”yui_3_17_2_1_1494352393596_135″ class=”image-block-outer-wrapper layout-caption-below design-layout-inline”&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;div id=”yui_3_17_2_1_1494352393596_134″ class=”intrinsic”&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;div id=”yui_3_17_2_1_1494352393596_133″ class=”image-block-wrapper has-aspect-ratio” data-description=”&amp;amp;amp;amp;amp;amp;lt;p&amp;amp;amp;amp;amp;amp;gt;500 millibar height anomaly pattern with strong blocking (in red) over Greenland and Iceland and deep upper-level lows over the Northeast and Southwest US; map courtesy AER/Dr. Judah Cohen&amp;amp;amp;amp;amp;amp;lt;/p&amp;amp;amp;amp;amp;amp;gt;”&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;amp;lt;noscript&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img src=”https://static1.squarespace.com/static/56530521e4b0c307d59bbe97/t/5911cc58b8a79bdefbbf44fc/1494338658163/”  alt=”500 millibar height anomaly pattern with strong blocking (in red) over Greenland and Iceland and deep upper-level lows over the Northeast and Southwest US; map courtesy AER/Dr. Judah Cohen”  /&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;



500 millibar height anomaly pattern with strong blocking (in red) over Greenland and Iceland and deep upper-level lows over the Northeast and Southwest US; map courtesy AER/Dr. Judah Cohen





The upper-level pattern across the Northern Hemisphere is playing a big role in this late season cold. Indeed, blocking is now well established over Greenland/Iceland as indicated by the latest 500 millibar height anomalies (red region) and this type of pattern can force cold air southward from northern latitudes into land mass areas on both sides of the Atlantic Ocean.






&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img src=”https://static1.squarespace.com/static/56530521e4b0c307d59bbe97/t/5911ccb5cd0f680bde94f908/1494338748886/”  alt=”Arctic Oscillation (top) and North Atlantic Oscillation (bottom) index values for the current time and past few months (in black) and forecasted values are shown in red through the month of May; data courtesy NOAA”  /&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;


Arctic Oscillation (top) and North Atlantic Oscillation (bottom) index values for the current time and past few months (in black) and forecasted values are shown in red through the month of May; data courtesy NOAA








Two indices that meteorologists can track in order to monitor the pressure patterns over the northern latitudes are the Arctic Oscillation (AO) and North Atlantic Oscillation (NAO).  When these indices drop into negative territory for extended periods this time of year, the result is often an upper-level blocking pattern across the northern latitudes.
There is some hope that later this month this blocking pattern will fall apart and the computer model forecasts of the AO and NAO indices (shown in red) do suggest a return to positive territory in the near future.
Text by Meteorologist Paul Dorian, with some editing by NTZ.
vencoreweather.com
 


Share this...FacebookTwitter "
"Global demand for coal has fallen this year for the first time in two years as Europe and the US turn their backs on coal-fired power plants in favour of cheap gas and renewable energy. A report from the International Energy Agency (IEA) found that the world’s appetite for coal declined in 2019 after a two-year resurgence following the steepest ever drop in the use of coal-fired power plants.  The world’s energy watchdog said it is too soon to say whether the global appetite for coal would continue to decline because the fate of the industry rests largely in the hands of China’s policymakers. Coal remains the world’s single largest source of electricity generation, half of which is produced in China and used to power Chinese power plants. The IEA’s annual report on the coal industry revealed that the largest ever decline in the use of coal-fired electricity was led by steep cuts in coal demand from Europe and the US. Western countries are weaning their energy systems off coal power due to abundant cheaper alternatives such as renewable energy and gas, and flatlining energy demand. Keisuke Sadamori, a director at the IEA, said “this is not the end of coal” because Asia’s demand for electricity is continuing its steep ascent fuelled by strong economic growth and a growing number of homes with access to electricity. “The region’s share of global coal power generation has climbed from just over 20% in 1990 to almost 80% in 2019, meaning coal’s fate is increasingly tied to decisions made in Asian capitals,” he said. The IEA expects coal-fired electricity to rise only marginally between 2020 and 2024, at less than 1% a year, which should see its share of the global electricity mix fall to 35% in 2024 from 38% last year. “Coal is disappearing in many advanced economies, but it remains resilient and is even continuing to grow in developing Asia,” he said. But the forecasts could deviate widely, depending on China’s energy policy decisions in its next five-year plan, covering 2021 to 2025. The fossil fuel faces rising public opposition due to concerns over air pollution and the climate crisis. Many governments are now considering stronger climate and environmental policies as renewables and gas become cheaper to use. “If China changes – everything changes,” Sadamori said. India bucked the trend for rising coal use in Asia this year. The IEA said the fast-growing economy is expected to record its first drop in coal-fired power in the last 45 years. The low coal power generation in India this year was due to “unusually low growth in electricity demand and exceptionally high hydropower output,” according to Sadamori. “It is not at all clear that it will be repeated,” he said."
"Scott Morrison says this is not a time for division, or partisanship, or point scoring. He says we should unite in response to the current crisis. That’s certainly true. We have been. But prime minister, this is also time to stop pretending. Talking about Australia’s woefully inadequate climate policy at this time is not partisan, it is essential. And, with respect, the same same old talking points you rolled out on your return from Hawaii just don’t cut it any more.  As you acknowledged, we are facing Christmas with dread. The immediate losses – of loved people, homes, safety, breathable air, passable highways upon which to drive to holiday, blue summer sky – those are deeply unsettling and sad. But the realisation that this is how Christmas may often be for our children, not carefree like the long summers we remember, but orange-skyed, fearful, choking and desperate – that is dreadful in the truest sense of the word. As you said, we are all grateful for the firefighters’ selfless efforts, but you’re right, we need to ask whether we can really expect this from them year after year, and those questions become more urgent if we face up to the fact that this is now the way things are going to be more often. You ignored the desperate, and as it turns out prescient, warnings from the former fire and emergency chiefs in the lead-up to this season. Your acting prime minister, just this weekend, again dismissed those experts because they had been funded by the Climate Council. Surely it is now time to put those political talking points aside and start to listen. We know global heating is fuelling this unprecedented fire emergency; we’ve been warned this would happen for decades. We know it is also contributing to the drought. Not directly causing, but certainly exacerbating. Surely it is time for your government to face these facts, instead of reciting Dorothea Mackellar or diverting blame to self-combusting manure or falsely claiming “greens” are somehow to blame by preventing hazard reduction burning. They haven’t, just for the record, and those former fire chiefs you refused to meet actually had some advice about hazard reduction burns, had you chosen to listen. That requires something more than just agreeing there is a link between global heating and fires, as you now have done. This isn’t about an adjustment to your language, it requires an adjustment to your policy, it requires a credible policy, the kind of policy we know could benefit us economically, that business is begging you to enact so that they can invest. And we know that would mean we could fight for effective international action rather than continue to act as a hindrance. We know we can’t solve the heating that is exacerbating this crisis on our own, so please don’t insult our intelligence again with that “1.3% of global emissions” argument like you did at the start of this fire season. Given the consequences we are suffering, we should be doing everything we can, and we know that we are not. You’ve just kept pretending. We’ve watched your Coalition immobilised by its climate denialist faction for more than a decade, destroying repeated political efforts to do something. We watched it dispense with Malcolm Turnbull as prime minister to avoid implementing a policy that was supported by industry and green groups alike. We watched you, prime minister, hold up a coal-industry supplied lump-of-coal prop in the parliament and urge us all not to fear it, but then go to the election with a policy that was little more than a sham, enough to appease the electorate’s concerns but with fine print that didn’t promise to do anything much to reduce domestic emissions, and that didn’t offer any explanation of how you would do the things you did promise, like reduce vehicle emissions. We’ve watched our domestic emissions continue to rise, or flatline because of the terrible impact of the drought, according to the latest accounts. We’ve watched Angus Taylor act against reaching an agreement at the most recent climate talks in Madrid, by insisting – against howls of international protest – that Australia be allowed to continue using an accounting trick to meet our emission reduction obligations. Days later, there he was again, interviewed against the orange backdrop of his own burning electorate, still mouthing the same discredited talking points about Australia “meeting and beating” its emission reduction target by the use of that loophole. You just used the same line yourself. It’s too close now, too terrifyingly dangerous and loud in the fire regions, too unendurably long in the regions parched by drought, to keep pretending like this. We need to know how you’re going to transition our economy. We understand that’s a complicated long-term process, so don’t treat us like idiots, as your deputy did on Saturday with the straw-man argument that those concerned about climate change are asking for all coalmining to cease tomorrow and risking the lights going out. Katharine Murphy spelled out your political choices in her final column for the year –you could once again try to damp down our fears and hope the backlash from this summer of fires will ease when the skies do eventually clear, or you could change policy course. On your return from holidays you seemed to choose the former, which is a tragedy, because there really is no more time to waste. We are past the point where the absence of credible policy can be papered over with talking points and spin. Your predecessor knows it, your former departmental head knows it, business, unions and farmers know it, scientists and environmentalists have known it for decades. You asked us all to be kind to one another, and we certainly should be. One kind thing you could do now is to finally stop pretending. Lenore Taylor is Guardian Australia’s editor "
"Plastics in the world’s oceans are set to treble in the next ten years, according to a new UK government report. They are also contributing to a rubbish heap in the Pacific Ocean that is as big as France. These are the latest instalments of one of the most prominent environmental concerns of recent years.  It’s not surprising this has become a cause célèbre. Unlike many other human pollutants in the environment, plastic debris is very visible. Images of birds or fish entangled in plastic are highly emotive – as is the idea that we could be harming ourselves by eating seafood containing tiny pieces of the stuff.  To be sure, this is a big problem. Plastics degrade the environment and we are certainly finding them in increasingly large quantities in our seas and oceans. This may indeed harm marine life and their ecosystems, but when you look closely at the evidence, it turns out that we are far less sure than it might appear.  There are important gaps in our understanding about plastics. It’s not unreasonable for people to fill these with speculation to some extent – funding for research is limited and we cannot wait for scientific research to provide complete answers before taking action. On the other hand, unsupported speculation can lead to scarce resources being misdirected when they could be better spent on other environmental issues.  Certainly we produce large amounts of plastics each year. They continually end up as waste in the environment, and the polymers they comprise decompose extremely slowly. Large particles fragment into smaller pieces known as microplastics – technically 5mm in diameter or less. These are now recognised as one of the most prevalent human-made pollutants in marine environments across the world. Microplastics could be accumulating in some places to levels that somehow compromise ecosystems. Deep-sea regions are a likely candidate, for example, though they are also the areas where we have the least information about quantities and effects. We need to do more work to say with confidence whether this is a serious problem.  On the question of how much damage microplastics cause to marine life, we certainly know these particles are readily transported throughout our seas and oceans and there is considerable evidence that organisms ingest them. However, the polymers that make up plastics are of minimal toxicity to marine life.  The question is whether they may cause harm in other ways. It could be that organisms absorb these particles and they accumulate in internal tissues, though it’s not clear whether or not that might be harmful to them. Microplastics may also accumulate in the gut and potentially interfere with processes like nutrient uptake or the passage of waste – or they may just be expelled without any negative effects.  A few studies have shown microplastics being absorbed by marine life in very small amounts, but other studies have found the opposite. We don’t even know whether very small nanoplastics with diameters of less than 1,000 nanometres can be absorbed. The studies that do exist on nanoparticles suggest that such absorption is minimal. In short, the jury is still out on absorption.  If microplastics are not appreciably absorbed, their potential to accumulate in tissues and cause problems is very low. It would also mean they can’t be passed on in any significant way to a predator who eats that organism. If so, it puts microplastics in a different category to toxic substances that end up in the food chain after accumulating in the internal tissues of fish – mercury, say.  There is considerable evidence to suggest that plastic particles are readily released from the gut of organisms without negative effects – and note that researchers have tended to test for concentrations in considerably higher amounts than are found in the environment.  Certainly, questions do remain. Perhaps of greatest importance is whether specific shapes of microplastics – fibres, for example – present particular difficulties for waste moving through the guts of some organisms.  Another concern is around toxic substances like DDT or hexachlorobenzene sticking to microplastics and potentially ending up in places they wouldn’t otherwise reach. Scientists have already found considerable evidence of this. Some people are alarmed that these substances could end up being ingested by marine organisms and harming them as a result.  Yet most studies have shown that toxicants associated with plastics are either at concentrations too low to be toxic – or that the substances stick too strongly to the plastics to be released into organisms and cause problems.  In one study, the levels of toxic substances in the tissues of marine birds were actually lower when they had ingested plastics. The investigators suggested the toxic substances already present within the bird tissues were sticking to the plastics and being removed. If so, toxic substances attached to plastics might be less of a concern for toxicity to marine organisms than is feared. Then there are microplastics and the human food chain. We were intrigued by this possibility and conducted an experiment to check. While we cooked in our kitchens, we left open petri dishes with sticky tape to collect dust fallout in the surrounding air.  We compared the amounts of plastic fibres in this dust with the quantities we found in mussels collected around the Scottish coast. The results suggest that while a regular UK consumer might ingest 100 plastic particles a year from eating mussels, their average exposure to plastic particles during meals from household dust is well over 10,000 per year.  In sum, the evidence about the dangers of plastics and microplastics in the marine environment is far from conclusive. There are important gaps in scientists’ knowledge that need filled, particularly where plastic particles are likely to accumulate in large amounts over long periods and how this potentially affects ecosystems.   We must avoid undue speculation and overstating risks, and instead engage with the actual evidence. Otherwise it will detract from our ability to manage plastic pollution in the most effective way and have a clear sense of the right priorities."
"The UK is one of the leading countries in addressing climate change. As well as signing international agreements, the country has its own target to reduce greenhouse gas emissions by 80% from 1990 levels by 2050. And as part of the effort to meet that target, the government has added a series of charges to business and household energy bills. The average household energy bill is around £1,030 a year and the charges effectively act as a levy that costs households an average of £132 (2016 figures). The good news is that the levy is working. About 20% of the levy is spent on improving the efficiency of homes. This is done by funding schemes such as the Energy Company Obligation, which provides insulation and other energy-saving measures to low-income households. The average household energy bill would be £490 higher without these improvements. The money is also spent on research to improve renewable energy sources, such as wind and solar power, and help bring down their cost. But is this really a fair way to raise the money? Our new research shows that the poorest households not only are hit hardest by the levy but also receive less money back in the form of home improvements than they contribute in the first place. To study the levy, we divided the UK into “income deciles”, ten groups each representing 10% of the population, divided from the lowest to the highest income. We then looked at how much energy use they were responsible for, both directly through their electricity, gas and fuel use, and from the other goods, services and infrastructure they use. The levy is only raised on a limited number of these “energy service demands”, namely home heat and power. So if your overall energy demand is higher for heat and power and lower for other services, you’ll pay a proportionally higher amount of the energy policy costs. We found that, in a year, the richest households each consumed on average the same amount of energy that would be produced by 12.7 tonnes of oil, compared to 3.3 tonnes for the poorest households. But the poorest spent a much greater proportion of their income (10%) on energy than the richest (3%). And the energy used for heating and powering their homes – the part that their climate change levy bill is measured on – represented a much greater proportion of their overall energy use. This means that adding the climate change levy to household energy bills hits the poorest households hardest. Energy bills account for a much greater share of their household income and more of their energy use is charged. In fact, the levy only affects a quarter of the total energy consumption of the richest households, compared to 53% for the poorest households. As a result, the richest homes use nearly four times more total energy than the poorest but only pay 1.8 times more towards energy policy costs. One argument for the climate change levy is that poorer households benefit more because part of it is used to improve the efficiency of their homes. But we estimate that the poorest 10% of households currently pay £271m a year towards the levy, while the costs of the Carbon Savings Communities and Affordable Warmth schemes, which are designed to help the poorest homes, come to just £220m a year. We also compared the system of adding a levy to household bills to two other ways of funding energy policy. The first was adding a levy to the energy bills of businesses (including energy suppliers), at least some of which would be passed on to households who buy their goods and services. The second was paying for the policy with money raised from income tax.  We found that the household levy is the most regressive system. Costs are placed purely on household bills, with the richest households paying 0.16% of their income compared to the poorest paying 1.5% (over nine times more). Adding a levy to business bills is an improvement. Under this system, the richest homes pay 0.19% of their household income and the poorest pay 1.05% (still nearly six times more).  But funding energy policy from income tax would mean that the lowest income households wouldn’t contribute at all and the richest households would pay 0.5% of their income. Compared to a household levy, this approach would reduce costs for 70% of UK households, while the richest 30% would see an increase. The lowest income group would save £102 a year, at an additional cost of £410 for the richest households – which, at less than £8 a week, would make a relatively small difference to their lives. Our analysis shows that the more you earn, the greater your energy demand, yet this is not reflected in current energy levy policy. It’s important to make sure that the costs associated with low carbon transitions are met by the households that cause the problem and those who can afford it, instead of hurting poorer households. We see it as essential that climate policies are compatible with social justice. Our research demonstrates it is clearly possible to design a system that is both fair and effective. The headline of this article originally referred to charges on household energy bills as a climate change levy. This has been amended to avoid confusion with the government’s Climate Change Levy on non-domestic energy users."
"
Share this...FacebookTwitterSince 2014, 400 Scientific Papers
Affirm A Strong Sun-Climate Link

2017 – 80 Scientific Papers Linking Solar Forcing To Climate
2016 – 133 Scientific Papers Linking Solar Forcing To Climate
2015 – 95 Scientific Papers Linking Solar Forcing To Climate
2014 – 93 Scientific Papers Linking Solar Forcing To Climate

The 20 Latest Sun-Climate Papers
“We confirm the occurrence of upcoming Modern grand minimum in 2020-2053 … [and] extremely incorrect prediction of the terrestrial temperature growth in the next century.” – Zharkova et al., 2017

1.     Gray et al., 2017     “There are several proposed mechanisms through which the 11-year solar cycle (SC) could influence the Earth’s climate, as summarised by Figure 1. These include: (a) the direct impact of solar irradiance variability on temperatures at the Earth’s surface, characterised by variation in the total incoming solar irradiance (TSI); (b) the indirect impact of variations through the absorption of Ultra-Violet (UV) radiation in the upper stratosphere associated with the presence of ozone, with accompanying dynamical responses that extend the impact to the Earth’s surface; (c) the indirect impact of variations in energetic particle fluxes into the thermosphere, mesosphere and upper stratosphere at high geomagnetic latitudes; and (d) the impact of variations in the generation of ions by galactic cosmic ray (GCR) penetration into the troposphere. Although different in their nature, these four pathways may not work in isolation but their influence could be synergetic.”


2.     Zharkova et al., 2017     “Using a summary curve of two eigen vectors of solar magnetic field oscillations derived with Principal Components Analysis (PCA) from synoptic maps for solar cycles 21-24 as a proxy of solar activity, we extrapolate this curve backwards three millennia revealing 9 grand cycles lasting 350-400 years each. The summary curve shows a remarkable resemblance to the past sunspot and terrestrial activity: grand minima – Maunder Minimum (1645-1715 AD), Wolf minimum (1280-1350 AD), Oort minimum (1010-1050 AD) and Homer minimum (800 900 BC); grand maxima – modern warm period (1990-2015), medieval warm period (900-1200 AD), Roman warm period (400-10 BC) and others. We verify the extrapolated activity curve by the pre-telescope observations of large sunspots with naked eye, by comparing the observed and simulated butterfly diagrams for Maunder Minimum (MM), by a maximum of the terrestrial temperature and extremely intense terrestrial auroras seen in the past grand cycle occurred in 14-16 centuries.”
“We confirm the occurrence of upcoming Modern grand minimum in 2020-2053, which will have a shorter duration (3 cycles) and, thus, higher solar activity compared to MM [Maunder Minimum]. … One of the examples of fitting incorrectly the oscillating function with a linear regression approach is shown by Akasofu (2010) (see her Fig. 9), when explaining the modern era recovery of the Earth from the little ice period and the incorrect use of a linear part of the temperature variations for the extremely incorrect prediction of the terrestrial temperature growth in the next century.”

3.     Harde, 2017     “[A] naturally generated [CO2 emission] contributes more than 95% to the overall emission, and its generation rate and the respective absorption rate sensitively respond on global temperature variations. … [The] well known delayed response of CO2 and methane (CH4) to sea and air temperature changes (see, e.g., Petit et al. [2]; Monnin et al. [3]; Caillon et al. [4]; Torn and Harte [5]; Humlum et al. [6]; Salby [7]) are not considered in AR5. … As long as any natural variations in the CO2 concentrations are not accurately known, the ECS [equilibrium climate sensitivity to CO2 doubling] cannot be used as a reliable indicator only for an anthropogenic global warming.”
“The IPCC denies any noticeable solar influence on the actual climate, although strong evidence of an increasing solar activity over the last century exists (see, e.g., Hoyt & Schatten [8]; Willson & Mordvinov [9]; Shapiro et al. [10]; Ziskin & Shaviv [11]; Scafetta & Willson [12]; Usoskin et al. [13]; Zhao & Feng [14]; Soon et al. [15]). … From these studies we conclude that the measured temperature increase of 0.74∘ C over the time 1880–2000 and the observed cloud changes of −4% over the period 1983– 2000 can best be explained by a cloud feedback mechanism, which is dominated by the solar influence. Therefore, it seems quite reasonable to use a model mean of [climate sensitivity to doubled CO2] = 0.7°C, yielding a CO2 initiated warming of 0.3°C [1880-2000] and a solar contribution of 0.44°C [1880-2000].”

4.    Pande et al., 2017     “Ozone is a highly reactive, naturally occurring ingredient of the stratosphere that is produced from oxygen by sunlight.  It is one of the most important chemicals in both the stratosphere and troposphere.  Apart from absorbing the harmful ultaviolet radiation from the sun, it [ozone] also plays an important role in determining earth’s climate.  Solar variability affects ozone through radiative heating in atmosphere.  Solar UV radiation is absorbed by atmospheric ozone.  It is responsible for both the creation and destruction of ozone.  … The total ozone was found to be enhanced during magnetically disturbed conditions which are associated with peak solar activity periods.  Angell and Korshover (1976) concluded that there is nearly in-phase relationship between sunspot number and total ozone.”

5.     Le Mouël et al., 2017     [S]olar activity contains an important component that has undergone clear oscillations of  ≈90  years over the past three centuries, with some small but systematic longer-term evolution of “instantaneous” period and amplitude. Half of the variance of solar activity on these time scales can be satisfactorily reproduced as the sum of a monotonous multi-secular increase, a  ≈90 -year Gleissberg cycle, and a double-peaked (≈10.0  and 11.0 years) Schwabe cycle (the sum amounts to 46% of the total variance of the signal). The Gleissberg-cycle component definitely needs to be addressed when attempting to build dynamo models of solar activity. The first SSA component offers evidence of an increasing long-term trend in sunspot numbers, which is compatible with the existence of the modern grand maximum.

6.     Wen et al., 2017     “A warmer and wetter climate prevailed since ∼4800 a BP and was interrupted by a sharp cold reversal at approximately 3300 a BP that was likely caused by solar irradiance forcing, which resulted in a global cold climatic change and glacier advance.”

7.      Munz et al., 2017     “Decadal resolution record of Oman upwelling indicates solar forcing of the Indian summer monsoon (9–6 ka) … We use geochemical parameters, transfer functions of planktic foraminiferal assemblages and Mg /  Ca palaeothermometry, and find evidence corroborating previous studies showing that upwelling intensity varies significantly in coherence with solar sunspot cycles. The dominant  ∼  80–90-year Gleissberg cycle apparently also affected bottom-water oxygen conditions.”

8.     Allan et al., 2017     “Speleothem is now regarded as valuable archive of climatic conditions on the continents, offering a number of advantages relative to other continental climate proxy recorders such as lake sediments and peat cores. … [T]race elements in speleothems have the potential to provide high resolution insights into palaeoclimatic variability during the Holocene. A deeper analysis reveals several periods of significant rapid climate change during the Holocene (at 10.7-9.2 ka, 8.2-7.9 ka, 7.2-6.2 ka, 4.8-4.5 ka, and 3-2.4 ka BP), which are similar to the cold events detected from different natural paleoclimate archivers. A comparison between the geochemical analysis of Père Noël speleothem and solar activity (sunspot number) reveals a significant correlation. Spectral analysis methods reveal common solar periodicities (Gleissberg cycle, de Vries cycle, unnamed 500 year, Eddy cycles, and Hallstatt cycle). The geochemical analyses have the potential to prove that PN speleothem is sensitive to changes in solar activity on centennial and millennial timescales during the Holocene.”

9.     Woodson et al., 2017     “The last ca. 1000 years recorded the warmest SST averaging 28.5°C. We record, for the first time in this region, a cool interval, ca. 1000 years in duration, centered on 5000 cal years BP concomitant with a wet period recorded in Borneo. The record also reflects a warm interval from ca. 1000 to 500 cal years BP that may represent the Medieval Climate Anomaly. Variations in the East Asian Monsoon (EAM) and solar activity are considered as potential drivers of SST trends. However, hydrology changes related to the El Nino-Southern Oscillation (ENSO) variability, ~ shifts of the Western Pacific Warm Pool and migration of the Intertropical Convergence Zone are more likely to have impacted our SST temporal trend. …  The SA [solar activity] trends (Steinhilber et al., 2012) are in general agreement with the regional cooling of SST (Linsley et al., 2010) and the SA [solar activity] oscillations are roughly coincident with the major excursions in our SST data.”

10.     Li et al., 2017     “The main driving forces behind the Holocene climatic changes in the LYR [Lower Yangtze Region, East China] area are likely summer solar insolation associated with tropical or subtropical macro-scale climatic circulations such as the Intertropical Convergence Zone (ITCZ), Western Pacific Subtropical High (WPSH), and El Niño/Southern Oscillation (ENSO).”



11.    Chang et al., 2017     “The chironomid-based record from Heihai Lake shows a summer temperature fluctuation within 2.4°C in the last c. 5000 years from the south-east margin of the QTP [Qinghai–Tibetan Plateau]. … The summer temperature changes in this region respond primarily to the variation in the Asian Summer Monsoon. The variability of solar activity is likely an important driver of summer temperatures, either directly or by modifying the strength and intensity of the Indian Ocean Summer Monsoon. … We observed a relatively long-lasting summer cooling episode (c. 0.8°C lower than the 5000-year average) between c. 270 cal. BP and AD c. 1956. … The record shows cooling episodes occurred at c. 3100, 2600, 2100 and 1600 cal. BP.  This is likely related to the period defined as the Northern Hemisphere Little Ice Age (LIA; c. AD 1350–1850, equivalent to 600–100 cal. BP). These possibly relate to the 500-year quasi-periodic solar cycle. Cooling stages between c. 270 and 100 cal. BP were also recorded and these are possibly linked to the LIA suggesting a hemisphere-wide forcing mechanism for this event.”


12.     Lei et al., 2017     “The precipitation variability on decadal to multi-centurial generally always reflects changes in solar activity and large-scale circulation, e.g., the ENSO and the EASM [East Asian Summer Monsoon] (Chen et al., 2011; Vleeschouwer et al., 2012; Feng et al., 2014). [D]uring the MWP [Medieval Warm Period], the wetter climate in this region was consistent with more frequent ENSO events, stronger EASM and higher solar activity, whereas the opposite was found for the LIA. In particular, d13Cac fluctuations on multi-decadal to centennial scales is consistent with the changes in solar activity, with fewer dry intervals corresponding to periods of minimum solar activity within dating errors, which are referred to as the Oort Minimum (AD 1010-1050), Wolf Minimum (AD 1280-1340), Sporer Minimum (AD 1420-1530), Maunder Minimum (AD 1645-1715) and Dalton Minimum (AD 1795-1820). These results suggest that climate change in southeastern China is sensitive to ENSO and the EASM, which may be driven by solar activity.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






13.     Zhang et al., 2017     “The record suggests the summer temperature varies by ~2.5 °C across the entire period. A generally warmer period occurred between c.8500 and c.6000 cal yr BP and a cooling trend was initiated from c.5500 cal yr BP. The overall pattern broadly matches the summer insolation at 30N and the Asian Summer Monsoon records from the surrounding regions suggesting that summer temperatures from the southeast margin of the QTP respond to insolation forcing and monsoon driven variability on a multi-millennial time scale. Modifications of this overall trend are observed on the finer temporal resolution and we suggest that solar activity could be an important mechanism driving the centennial-scale variability. It may have a strengthened effect in the late Holocene when the monsoon influence weakened.”


14.     Luoto and Nevalainen, 2017     “Here,https://notrickszone.com/wp-content/uploads/2017/05/Holocene-Cooling-Greenland-Ice-Sheet-Zhang-2017.jpg we use completely synchronized paleolimnological proxy-based records of air temperature and effective precipitation from two Scandinavian lakes with ∼2000-year sediment profiles. We show that the relationship between air temperature and precipitation (T/P ratio) is synchronous in both study sites throughout the records suggesting warm and dry conditions at ∼300–1100 CE and cold and wet conditions at ∼1200–1900 CE. Owing to the significantly increased air temperatures, the most recent T/P ratio has again turned positive. During the first millennium of the Common Era, the T/P mimics patterns in Southern Oscillation index, whereas the second millennium shows response to the NAO index but is also concurrent with solar irradiance shifts.  [T]he causes for the LIA [Little Ice Age [1200-1900 CE], are not well defined owing to its highly variable nature (Wanner et al. 2011; Luoto and Nevalainen 2016; Zawiska et al. 2017). Yet, in addition to a persistent strongly negative NAO index phase during the LIA, it was most likely forced by decreased solar irradiance (including Spörer, Maunder and Dalton solar minima), increased volcanic activity (aerosols), and changes in Atlantic Ocean circulation patterns (Grove 2001; Goosse et al. 2005; Wanner et al. 2011).”



15.     Li et al., 2017     “Correlations between paleotemperature records from the North Atlantic and solar activity suggest that changes in solar output may cause significant shifts in the climate of the North Atlantic region. To test the role of solar activity on summer SST at our study site in West Greenland, we conducted a cross-correlation analysis between our reconstructed summer SST record and a total solar irradiance (TSI) series. The results indicate that the maximum correlation coefficient (0.284) of summer SST [sea surface temperatures] and TSI [total solar irradiance] records is obtained at nearly zero time-lag (-6 time-lag), which means that variations in solar activity affected the summer SST variability in the study area. … A significant positive relationship between summer SSTs on the North Icelandic shelf and solar irradiance reconstructed from 10Be and 14C records during the Holocene was also demonstrated by Jiang et al. This finding is also supported by recent climate model simulations using the Community Climate System Model version 4 (CCSM4). The model results show a strong positive correlation between SST and solar irradiance in the pathway of the IC, indicating that a reduced frequency of Atlantic blocking events during periods of high solar irradiance promotes warmer and saltier conditions in the pathway of the IC due to stronger circulation of the subpolar gyre. … Spectral analyses indicate that significant centennial-scale variations are superimposed on the long-term orbital trend. The dominant periodicities are 529, 410, and 191 years, which may be linked to the well-known 512- and 206-year solar cycles. Cross-correlation analyses between the summer SSTs and total solar irradiance through the last 5000 years indicate that the records are in phase, providing evidence that variations in solar activity impacted regional summer SST variability. Overall, the strong linkage between solar variability and summer SSTs is not only of regional significance, but is also consistent over the entire North Atlantic region.”


16.     Orme et al., 2017     “The north-south index shows that storm tracks moved from a southern position to higher latitudes over the past 4000 yr, likely driven by a change from meridional to zonal atmospheric circulation, associated with a negative to positive North Atlantic Oscillation shift. We suggest that gradual polar cooling (caused by decreasing solar insolation in summer and amplified by sea-ice feedbacks) and mid-latitude warming (caused by increasing winter insolation) drove a steepening of the winter latitudinal temperature gradient through the late Holocene, resulting in the observed change to a more northern winter storm track.”

17.     Serykh and Sonechkin, 2017     “The global climate is a quasi-periodically forced dynamic system [1, 2]. In addition to the annual cycle of the heat transport from the Sun and the diurnal cycle of the Earth’s rotation, other external periodical forces exist, which are potentially able to cause climate fluctuations. The lunar and solar tides are such causes on the time scales of the order of one day. On the decadal scale, these causes are 11-year variations in the Sun spots (the Wolf cycle) and its double period manifested in the changes in the heliospheric field polarity (the Hale cycle). The existence of secular solar cycles is also possible (Gleissberg and Suess cycles found in a number of Sun spots). Calculations indicate that an approximately 180-year cycle exists in the rotation of the Sun around the center of mass of the Solar system. The authors of [3] suggest that it is related to the sequence of significant decreases in the solar activity in the last millennium known as the Oort, Wolf, Spörer, Maunder, and Dalton periods. Paleoclimatic evidence of climate cooling during these periods exists. We can conclude on this basis that the ONI [ENSO index] dynamics [are] governed predominantly by two periodical external forces (the annual heat transport to the climatic system from the Sun and the Chandler wobble of the Earth’s poles) and that the system is not chaotic. This fact indicates that a principal possibility exists for long-term (many years in advance) ENSO forecasts.”

18.     Kitaba et al., 2017     “The weakening of the geomagnetic field causes an increase in galactic cosmic ray (GCR) flux. Some researchers argue that enhanced GCR flux might lead to a climatic cooling by increasing low cloud formation, which enhances albedo (umbrella effect). Recent studies have reported geological evidence for a link between weakened geomagnetic field and climatic cooling. … Greater terrestrial cooling indicates that a reduction of insolation [solar radiation reaching the surface] is playing a key role in the link between the weakening of the geomagnetic field and climatic cooling. The most likely candidate for the mechanism seems to be the increased albedo of the umbrella effect.”

19.     Perșoiu et al., 2017     “Throughout the Holocene, the subterranean ice block in Scărișoara Ice Cave responded sensitively to changes in both winter temperature and moisture source. During this time period, winter temperature in ECE [East Central Europe] was mainly controlled by insolation [solar radiation] changes. The interplay between insolation variability, SST changes in the North Atlantic, and the influence of the lingering Laurentide Ice Sheet modulated the dynamics of large-scale atmospheric circulation.”


20.     Luthardt and Rößler     “The 11 yr solar cycle, also known as Schwabe cycle, represents the smallest-scaled solar cyclicity and is traced back to sunspot activity (Douglass, 1928; Lean, 2000), which has a measurable effect on the Earth’s climate, as indicated by the Maunder minimum (Usoskin et al., 2015). Global climate feedback reactions to solar irradiance variations caused by sunspots are complex and hypothesized to be triggered by (1) variation in total energy input (Cubasch and Voss, 2000), (2) the influence of ultraviolet light intensity variation on composition of the stratosphere (Lean and Rind, 2001), (3) the effect of cosmic rays on cloud formation (Marsh and Svensmark, 2000; Sun and Bradley, 2002), and/or (4) the effect of high-energy particles on the strato- and mesosphere (Jackman et al., 2005). …  [L]ike today, sunspot activity caused fluctuations of cosmic radiation input to the atmosphere, affecting cloud formation and annual rates of precipitation“
Share this...FacebookTwitter "
"Like a one-man Google Earth, Swiss aviation pioneer Eduard Spelterini flew a gas-filled balloon from the French town of Chamonix to Switzerland on August 8, 1909 – a distance of 100 miles over the Alps. While the flight was extraordinary for being the first aerial crossing of the central Alps from west to east, it now holds a special significance of which Spelterini was unaware. The balloonist was also a photographer who captured a series of glass-plate images of the Mer de Glace (“sea of ice”) glacier that descends from the Mont Blanc Massif in a dramatic sweep. Spelterini’s interest in recording the alpine landscape was both scientific and aesthetic, and the results are striking. This collection of images survives today as a record of the glacier that is unique in its detail and antiquity. But crucially, they can be used to measure how much this landscape has changed in the intervening years. In 1909, no one could have guessed how significant these glaciers would become to environmental science, or just how rapidly they would be affected by rising temperatures in the century that followed. The flight over the Mer de Glace was unusual because Spelterini’s aerial photographs rarely focused on the glaciers, instead more often framing the peaks and other geological features. He was also unaware that the distribution of his photographs along the balloon’s flight path, pictured below, would make excellent material for digital analysis more than 100 years later. By identifying common features in the photographs, which can in turn be linked to surveyed features in the landscape, a 3D representation of both the balloon flight and the historical topography can be reconstructed using photogrammetry – the science of taking measurements from photography. While the oblique angle of the photographs limits the measurable accuracy of the resulting data, compared to the vertical mapping photographs taken in the decades that followed, they still provide a unique and compelling glimpse into a past landscape.  In Spelterini’s image below, the oblique aerial view taken at a sideways angle towards the horizon gives a sense of place that is part way between the familiar ground level view and the high vertical perspective like that of a map. In the foreground the newly completed Montenvers cogwheel railway is visible, perched over the voluminous Mer de Glace glacier which leads the eye to the spires of the Mont Blanc Massif in the background. The photographs are carefully composed, designed to serve as both record and artwork. Their oblique angle makes them less abstracted and more relatable, despite their height above the ground and the scale of the landscape they depict. All of these factors make them an ideal point of reference for visualising the changing nature of the alpine landscape. In October 2017, a team of photographers and researchers from the University of Dundee returned to Chamonix to replicate the path of the historic flight and  recreate the sequence of photographs using a helicopter. Spelterini’s balloon rapidly ascended to around 2,000m above the Chamonix valley before passing Mer de Glace. Such heights are virtually inaccessible to unmanned drones, meaning that a manned aircraft was needed. The results are documented in The 100-year Time-Lapse Project. GPS coordinates derived digitally from Spelterini’s photographs were used to return to the same locations to capture current-day equivalents of both his individual photographs and the 3D surface reconstruction. While the rate of change in the Mer de Glace glacier has been studied in great detail, using digital technology in this way allows for a visual comparison of the landscape then and now to reveal the staggering reduction in the ice surface that has taken place over the last century. Today, visitors alighting at the Montenvers railway station are no longer confronted with the Mer de Glace at close range, but instead look down upon a largely empty valley and debris-covered glacier far below. Here the ice surface has dropped around 100 metres compared to its height in 1909. Scientists have calculated that, overall, the glacier has lost around 700m cubic metres of water since the beginning of the 20th century. While the facts and figures alone should be enough to narrate the impact that the previous century of greenhouse gas emissions have had on our climate and environment, images like these help drive the point home. Eduard Spelterini was not just a pioneer of aviation but also of aerial photography as a way of better understanding the natural world. His images capture an emotive sense of place while providing insights into aspects of the landscape that are not available from the ground. Today, despite the heavy carbon footprint that comes with manned aviation, we continue to rely on aerial views to interpret our environment, from Landsat satellite imagery to low-level drone photography. By repurposing archival aerial photographs and continuing the legacy of photographers like Spelterini, with the help of current technology, we can explore new and compelling ways to visualise our rapidly changing glacial landscapes. As well as serving to convince hearts and minds in the present political debates surrounding climate change, these images will also form a poignant record of magnificent landscapes that will no longer be around for future generations to experience."
"
Share this...FacebookTwitterMuch has been written about growing power grid instability in Europe as more and more volatile wind and solar energy have come online over the years.
Earlier today European news outlets reported how Brussels, a major centre of the European Union, plunged into darkness late yesterday evening.
So far it’s not known what’s behind the outage. The New York Post writes that the cause  is a “mystery”, but according to the BBC here that “a spokesperson for Brussels’ power supplier, Sibelga, later told The Sun that the blackout was the result of an electric network distribution problem”.
City gripped by fear
It’s one thing if some rural area blacks out, but quite another when a center of political power like Brussels gets paralyzed and is left totally vulnerable. The UK Mirror wrote of a “security alert” after a “massive blackout” plunged the “entire centre of EU capital into darkness“, adding:
The loss of electricity across the Belgian capital has sparked terror attack fears, although the cause of the outage has not been confirmed.”
Brussels has been the target of terror attacks and is still considered a hotbed of potential terrorists. The Mirror writes that the blackout had Belgian security forces scrambling to boost their manpower at main sites around Brussels.
Volatile wind and sun wreak havoc on grid stability


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Although it may turn out that the Brussels blackout problem had little to do with the haphazard supply from wind and solar energies, the outage once again highlights the European power grid’s growing instability the since greater amounts of the volatile energy have been getting fed in.
The following chart, for example, shows just how irregular the supply from wind and sun can be in Belgium’s neighbor, Germany:

German wind and solar power supply compared to German total demand over the past 15 days. Source: Agora.
The upper curve depicts Germany’s total consumption. Keeping the grid stable is becoming an increasingly formidable challenge, and the likelihood of overloads is ever higher. Blackouts like the one in Brussels, and the disruptions they cause, will likely become a part of Europe’s future.
There’s one positive aspect about the blackouts: they could serve to help a bit to alleviate one big problem in Europe. The OE24 here writes:  “In the social media networks, jokes were made about a possible boost in the birthrate in 9 months.”
Strangely, Germany’s mainstream media is totally absent with the news of the blackout.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterLate last month a video of a discussion round featuring green energies was put up on Youtube.
The segment that follows below shows Dr. Detlef Ahlborn, President of the Wind Energy protest group Bundesinitiative Vernunftkraft (German Initiative for Sensible Power) telling us, without mincing words, why wind energy has been a flop in Germany.
Though the discussion round took place late 2015, it resonates just as loudly today.

On German MDR public television, the moderator asks Ahlborn just who profits from wind energy. According to Ahlborn:
The only one who profits from all the ones you mentioned is the landowner because he has a contractual right. All the others are losers.”
Ahlborn says that 80% of German wind parks are making losses. In the German state of Hesse, for example, “not a single newly installed wind park has yielded what was promised. These yields are up to 20% below what was forecast. And the biggest losers are all of us. All of us!”
The problem, Ahlborn elaborates, is that 25% of the wind energy that gets produced is “waste energy”, energy that cannot be used because there is no demand for it. This waste energy ends up getting dumped onto other foreign markets, so much so that neighboring countries have implemented measures to block it out. Ahlborn then says:
The real scandal is that this power gets sold at negative prices, or below market prices and needs to be disposed of at a fee.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The discussion round then puts up a graphic showing power demand by the German state of Thuringia (middle curve), the state’s wind power output (lower light curve), and the max. peaks of wind power (highest curve):

Chart cropped from MDR FAKT IST!
Ahlborn blasts this inefficient production of wind energy and the waste power that results, saying that wind park projects produce waste that “is a burden on the consumers, a burden on the economy, and a burden on all society – and with this they are destroying our landscape.”
Costs out of control…huge loss of prosperity
Little wonder that the director of Germany’s top economists, Christoph M. Schmidt, recently named Germany’s Energiewende (transition to renewable energies) as being among the top three programs in need of major reform in the country, saying that “the costs are way out of control” and that it will not succeed without a “huge loss in prosperity“.
Schmidt recently handed the latest annual recommendations over to Chancellor Angela Merkel.
Over the past years, led by strong personalities like Ahlborn, and leading environmentalists, resistance to wind energy in most parts of Germany has grown to formidable levels. Lately protest groups have been increasingly successful at blocking projects. Even the government has even rolled back subsidies.
 
Share this...FacebookTwitter "
"Australia’s fossil fuel industry would stump up for a national climate disaster fund levy to help cover the costs of escalating natural disasters, under a new thinktank proposal. The Australia Institute has released a plan to have some of the nation’s biggest polluters pay a $1 levy per tonne of carbon pollution from fossil fuel production, which it estimates would raise at least $1.5bn per year. Putting the nation back together again after flood, storm or fire is an increasingly costly exercise, as climate change exacerbates the strength and duration of events, draining local, state and federal coffers. Mark Ogge, the principal adviser at The Australia Institute, said with costs only forecast to increase, the nation needed to look at new ways to cover them, while also holding fossil fuel producers responsible. “The frequency and intensity of natural disasters such as bushfires and floods will keep increasing while we keep pumping more greenhouse gases into the atmosphere,” he said. “Australia urgently needs a dedicated, independently administered fund to cope with the ever-increasing costs of these disasters. A $1 per tonne levy would have virtually no effect on energy prices or coal jobs, but would be a huge help to everyone being affected by the damage these activities are causing.” Ogge said polling undertaken by the institute, as part of its Climate of the Nation report, found 62% of Australians supported the introduction of a fossil fuel levy. Last year, the International Federation of the Red Cross and Red Crescent Societies’ World Disasters report costed Australia’s damage bill over the past 10 years at $37bn. Various estimates have put Australia’s economic disaster recovery cost at between $13bn and $18bn a year, as the ongoing drought and extreme weather events hit the nation harder and with increased frequency. The Insurance Australia Group warned in 2017 the economic cost was forecast to grow by 3.4% a year, before doubling by 2038 and reaching $39bn a year in real terms by 2050. Ogge said the policy would help “communities to prepare for and recover from natural disasters, but it would also be great for creating jobs and boosting the economy”. A group of mayors, faced with steering their communities through the devastating impacts of the most recent and ongoing bushfire crisis, also lent their support to the proposal, including the Glen Innes mayor, Carol Sparks. “Every tonne of coal mined ends up as more greenhouse gas in the atmosphere, fuelling climate change and making catastrophes like these fires worse,” she said. “It is staggering that the coal and gas companies that profit from this don’t have to pay for any of the costs. Our communities are paying the price for their activities. It’s high time they started paying for the damage they are causing.” Sign up to receive the top stories from Guardian Australia every morning Bellingen mayor Dominic King said it was not fair that the burden of paying for communities to be prepared, and authorities to be properly resourced, fell on “ordinary people and our volunteers” while fossil fuel companies continued to profit “from the activities that are fuelling climate change”."
"As North Sea petroleum moves towards the end of its lifespan, the UK taxpayer is to spend some £25 billion to pay nearly half the cost of removing the offshore infrastructure.  This might sound like the right thing to do, but as I have argued before, it is probably not the best use of public money. The environmental benefits of decommissioning are questionable. If we instead spent the money on, say, building more renewable energy, it would create jobs for longer and you would generate carbon-free power for your trouble. Others might not share this view – my point is it’s a debate we’re not having.  I have repeatedly asked the relevant government agencies to outline the motivations that support the current plans. They have never given me straight answers. My latest move has been to submit a request for information to the government’s department for business, energy and industrial strategy. In my request, I once again expressed my concerns about value for money. I said my previous requests had been met with a stock response that offshore operators have to decommission installations at the end of a field’s economic life, and that in accordance with UK and international obligations this has to be safe, efficient and cost-effective to the taxpayer while minimising the risk to the environment and other users of the sea.  This, I told them, says nothing about the reasons behind the policy – neither the primary environmental motivation nor anything to do with society or economics. I asked for the environmental basis underpinning the policy.   I received a reply from the director of decommissioning at the department. It says: The UK’s international obligations on decommissioning are governed principally by the 1992 Convention for the Protection of the Marine Environment of the North East Atlantic (the OSPAR convention) and in particular decision 98/3 on the disposal of disused offshore installations. The UK is indeed one of 15 parties to the convention, all of them countries in western Europe. Paragraph 2 of decision 98/3 stipulates that disused offshore installations can’t be dumped or left “wholly or partly in place” at sea.  The competent authority can allow exceptions, but it’s quite narrow – covering certain concrete infrastructure; the base of large steel structures; and some other installations that are very damaged. It leaves little scope for what I am suggesting.  The response says that: We seek to achieve effective and balanced decommissioning solutions which are consistent with international obligations and have a proper regard for safety, the environment, other legitimate uses of the sea, economic and social considerations as well as technical feasibility … [The decommissioning process] entails an assessment of the environmental impact [by the operator, and] … it is one of the factors that influences the final decision [by them on whether to go ahead] … Ultimately if leaving the infrastructure in place would not have a significant detrimental effect on the environment then an operator may make a case to decommission in-situ. None of this says anything about overriding environmental benefits in removing these structures. Decision 98/3 is silent, and none of the government reports I have read address them either.  As for the operator’s environmental impact assessment, it is not their job to consider the taxpayer’s options. It is for the government, and it’s not happening. How does this therefore amount to the government achieving a balanced solution? Where is the evidence that the legislation is providing a positive outcome? If it can’t be provided then the legislation is not appropriate and should be challenged – however well intentioned it may be.  The response also informs me that a joint industry project called INSITE is aiming to “enhance scientific understanding of the effect of man-made structures on the North Sea and thus support decision-making [by operators]”.  I am familiar with INSITE and have met with the project manager and discussed the programme. INSITE is undertaking some first-class science but its very existence and government funding only serves to demonstrate the lack of evidence that supports removal.  The department’s response also addresses the cost to the taxpayer, which is being spent in the form of tax relief for operators who are decommissioning. It says:  North Sea operators have paid over £330 billion of tax since the 1970s at tax rates significantly higher than onshore companies, therefore allowing tax relief on decommissioning ensures a fair tax system that gives companies good incentives to maximise economic recovery. What is that justifying or explaining? Because oil and gas companies have paid due taxes on eye-watering profits in the past, the government can use taxpayers’ money for future decommissioning costs?  The response refers to these as an “unavoidable cost for industry”. Well plugging and abandonment is unavoidable but asset removal? Witness the rigs to reefs programme in the US.  The response says the government and industry are working on reducing decommissioning costs by 35%, but why spend the money in the first place? If a large proportion of costs can be removed, surely that would be a better incentive to maximise petroleum recovery? The UK, it concludes, remains committed to OSPAR and decision 98/3 and “there are no proposals to change the decommissioning process in operation”. The taxpayer, in other words, will be running up this huge bill to follow legislation without anyone having to demonstrate the case for it.  It is time that decommissioning policy be hastily re-examined in the UK. The government needs to commission a full evidence-based report into the environmental, social and economic benefits, comparing them to other options such as building more green energy stations and even spending the money on things like health or education.  If I am proven right about which will come out on top, the UK should renegotiate terms with OSPAR. Blindly going ahead with this policy is wrong. It is time to think again."
"
Share this...FacebookTwitterHere’s an addendum to what I wrote here about German electric power a couple of days ago. Apparently things are worse than we thought. The climate protection scam is truly a colossal cash-cow for the government and a narrow special interest.

German power now costing consumers tens of billions of euros. Chart above shows Germany’s average household price per kilowatt-hour. Image: BDEW.
According to manager magazin, power consumers are now paying 35 billion euros in taxes and feed-in tariffs annually:
Households in Germany are paying with their electric bills more than 35 billion euros for taxes, surcharges and feed-in tariffs this year. The biggest share is the EEG renewable energy feed-in tariff with 24 billion.”
The taxes, tariffs and surcharges represent 55% of the German power bill, almost double what it was in 1998. manager-magazin reports the average kilowatt-hour of electric power has now reached 29.16 euro-cents, and blames the feed-in act as the main price-driver.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




German households are currently paying over 100 euros a month just for their electric bills – a “record level”. The manager magazin reports that the average household now pays 1223 euros a year for power, up 2% from a year earlier.
The vast majority of analysts say the price spiral will continue, with no end in sight over the next few years.
Investing in Mexico
Not only electricity consumers are being hit, but so is Europe’s green power sector, which was once touted as a jobs creation machine for the future. German national daily Die Welt here reports that electrical engineering giant Siemens will close a wind energy production equipment facility in neighboring Denmark, thus costing 430 jobs. The closure comes at the heels of the company announcing the lay off 150 workers at its rotor blade facility in Aalborg. Siemens cites a streamlining of its operations and reports of record orders for wind turbine equipment this year.
The company also announced plans to invest some 200 million dollars in Mexico over the coming decade, which according to Chairman Joe Kaeser will create 1000 jobs.
It’ll be interesting to see if the equipment will be exported from Mexico and into the United States.
Share this...FacebookTwitter "
"The main drivers of species extinction are habitat loss and human-wildlife conflict, but it still takes a lot for these events to hit international headlines. They did recently, however, when the world famous Marsh Pride lions were allegedly poisoned by Maasai tribesmen.  These lions were the stars of the BBC’s Big Cat Diary TV series and a popular tourist attraction in the Maasai Mara National Reserve in Kenya. At least two lions were reported to have been killed and two local men have been arrested and could face life imprisonment if found guilty of harming them. The motive given was retaliation. It is thought that the men’s cattle had been grazing in the park the day before and were killed by lions. It was then easy to poison the carcass, knowing the lions would return to the kill.  Unfortunately though, this is not a rare event. People kill wildlife for similar reasons throughout this part of Kenya. My work on the western border of the Maasai Mara has recorded over 500 examples of crop raiding by elephants in the last two years. This led to at least two elephants being killed in retaliation last year alone. These acts are often heavily criticised by foreigners and city dwellers but sharing land with wildlife is not easy. Many of the people are poor and feel powerless when animals eat their crops or livestock. These feelings then turn to animosity towards wildlife when their concerns are ignored. So, the illegal and ruthless killing of the Marsh Pride lions sends a clear message that conservation in the Mara ecosystem is working neither for wildlife nor people. Part of the problem is human population growth. Kenya’s population size has tripled in the last 50 years and people’s lives are changing. In the Mara ecosystem many Maasai people are shifting from being pastoralists to farmers. They are converting their land to crops but still have strong economic and cultural links to cattle herding. This spread of farming reduces natural habitat and increases elephant crop raiding. It also reduces pasture land, so many people now take their cattle into the Maasai Mara Reserve. The fact that so many cattle are illegally grazing in the reserve shows that conservation management is also currently weak. Just as significantly, it also shows that many communities around the Maasai Mara Reserve do not see any benefits from the wildlife it contains. This is despite the law stating that these people should receive a percentage of the reserve revenue each year. At the moment, almost none of this money goes into the pockets of the poor, despite the land originally belonging to the Maasai before it was taken for conservation. Solving these problems can only happen with action at a higher level. A key component is better spatial planning that incorporates the needs for conservation. Potential options could involve zoning the landscape, so areas are set aside for settlements and farming but also for livestock and wildlife. In particular, we need to ensure that key wildlife areas and corridors are protected through effective management and enforcement. Finally, we need to improve park revenue sharing. It seems crazy that someone makes more money from growing a field of maize, or keeping a small herd of cows, than by living next door to one of the world’s most famous conservation areas. The poisoning of the Marsh Pride lions is indeed shocking but it is nothing new in the Maasai Mara or other parts of the world. Human-wildlife conflict is a grim reality which poses graver threats than many people realise. The story highlights an escalating problem but there will be many more “Marsh Pride” lion incidents unless we come up with long-term solutions."
"The ocean currents that help warm the Atlantic coasts of Europe and North America have significantly slowed since the 1800s and are at their weakest in 1600 years, according to new research my colleagues and I have conducted. As we’ve set out in a new study in Nature, the weakening of this ocean circulation system may have begun naturally but is probably being continued by climate change related to greenhouse gas emissions. This circulation is a key player in the Earth’s climate system and a large or abrupt slowdown could have global repercussions. It could cause sea levels on the US east coast to rise, alter European weather patterns or rain patterns more globally, and hurt marine wildlife. We know that at the end of the last major ice age, rapid fluctuations in the circulation led to extreme climate shifts on a global scale. An exaggerated (but terrifying) example of such a sudden event was portrayed in the 2004 blockbuster film The Day After Tomorrow. The recent weakening we have found was likely driven by warming in the north Atlantic and the addition of freshwater from increased rainfall and melting ice. It has been predicted many times but, until now, just how much weakening has already occurred has largely remained a mystery. The extent of the changes we have discovered comes as a surprise to many, including myself, and points to significant changes in the future. The circulation system in question is known as the “Atlantic Meridional Overturning Circulation” (AMOC). The AMOC is like a giant conveyor belt of water. It transports warm, salty water to the north Atlantic where it gets very cold and sinks. Once in the deep ocean the water flows back southwards and then all around the world’s oceans. This conveyor belt is one of the most important transporters of heat in the climate system and includes the Gulf Stream, known for keeping western Europe warm. Climate models have consistently predicted that the AMOC will slow down due to greenhouse gas warming and associated changes in the water cycle. Because of these predictions – and the possibility of abrupt climate changes – scientists have monitored the AMOC since 2004 with instruments strung out across the Atlantic at key locations. But to really test the model predictions and work out how climate change is affecting the conveyor we have needed much longer records. To create these records, our research group – led by University College London’s Dr David Thornalley – used the idea that a change in the AMOC has a unique pattern of impact on the ocean. When the AMOC gets weaker, the north-eastern Atlantic Ocean cools and parts of the western Atlantic get warmer by a specific amount. We can look for this pattern in past records of ocean temperature to trace what the circulation was like in the past. Another study in the same issue of Nature, led by researchers at the University of Potsdam in Germany, used historical observations of temperature to check the fingerprint. They found that the AMOC had reduced in strength by around 15% since 1950, pointing to the role of human-made greenhouse gas emissions as the primary cause. In our paper, which also forms part of the EU ATLAS project, we found the same fingerprint. But instead of using historical observations we used our expertise in past climate research to go back much further in time. We did this by combining known records of the remains of tiny marine creatures found in deep-sea mud. Temperature can be worked out by looking at the amounts of different species and the chemical compositions of their skeletons. We were also able to directly measure the past deep ocean current speeds by looking at the mud itself. Larger grains of mud imply faster currents, while smaller grains mean the currents were weaker. Both techniques point to a weakening of the AMOC since about 1850, again by about 15% to 20%. Importantly, the modern weakening is very different to anything seen over the last 1,600 years, pointing to a combination of natural and human drivers. The difference in timing of the start of the AMOC weakening in the two studies will require more scientific attention. Despite this difference, both of the new studies raise important questions regarding whether climate models simulate the historical changes in ocean circulation, and whether we need to revisit some of our future projections. However, each additional long record makes it easier to evaluate how well the models simulate this key element of the climate system. In fact, evaluating models against these long records may be a crucial step if we hope to accurately predict possible extreme AMOC events and their climate impacts."
"Plastics are incredibly useful materials with extremely diverse properties, allowing a multitude of different applications that benefit our lives.  Bottles and forks aside, in the medical field alone plastics have been used for artificial heart valves, medical implants and devices, controlled drug release, specialist surfaces and coatings that repel water, organic batteries – the list is endless.  But, with marine plastic debris estimated to reach 250m tonnes by 2025, governments across the globe are starting to think about how to overcome this significant problem.  A fundamental part of this issue is that non-sustainable, single-use plastics account for up to 40% of global plastic production. This equates to around 128m tonnes. The vast majority of these plastics have low recycling rates and do not biodegrade in an acceptable time span – polypropylene can take millennia to break down properly.  Worse still, if these plastics find their way into the marine environment, the motion of the sea along with sunlight can cause the plastics to fracture into small particulates called “microplastics”.  The presence of macro and microplastics in our oceans has been shown to have a detrimental effect on marine life. But the potential effect on human health is much less well understood.  A ban on the production of cosmetics and personal care products containing plastic microbeads came into effect at the beginning of the year. Though realistically, this only accounts for an estimated 680 tonnes of microplastics per year in the UK.  It is clear then that plastic waste is a complicated problem – spanning economics, sustainability, social pressures and recycling infrastructure in both developed and developing countries. But while it’s widely known that plastics can be an issue for the environment, what isn’t often known is that the persistence of plastics in the environment is actually closely linked to how they are made.  The overwhelming majority of plastics are made using oil-based materials, meaning that, by their chemical nature, many plastics have no oxygen content. This makes them very hydrophobic (water hating) and, as such, it is very difficult for common bacteria or enzymes to break them down if they enter the environment.  Over the past few decades, there has been increased awareness of our dependence on a limited oil supply and this has driven research into alternative, sustainable sources of chemicals. In particular, the concept of using bio-based materials as a resource rather than oil-based materials has really gained momentum. Sustainable bio-based material can be waste crops, waste wood, waste food – in fact, any waste biological matter.  Most importantly, these natural, bio-based materials can easily be broken down into smaller chemical building blocks – called “platform molecules” – which in turn, can be used to make other useful chemicals, including plastics. Using these platform molecules, the Green Chemistry Centre of Excellence at the University of York, has been working with the plastics industry to create a new generation of bio-based polyesters. These are often used to make fibres for clothing, as well as films and containers for liquids and foods. The resulting materials are entirely plant based, recyclable and – importantly – fully biodegradable. Aside from sustainability, the huge benefit of using biomass as a resource is the high quantity of oxygen that is incorporated into nature’s chemical structures (celluose, glucose etc). By using bio-based materials to make bio-based plastics, the oxygen content is kept in the material. The hope is that by having a high oxygen content, the bio-based plastics will have high, but controlled biodegradability. This means that the bio-based plastic can totally and safely break down into benign starting materials. But although this new generation of sustainable plastics is a huge step forward, and a compostable plastic is of huge benefit, this is by no means the end goal for all bio-based plastics. The circular economy is all about keeping resources in a constant loop, reusing and recycling them as many times as possible. This helps to minimise waste and reduce the need for brand new resources. Treating plastic waste as a resource rather than a problem is an important change than needs to happen over the coming decades. This will help to preserve our remaining chemical materials, as well as protect our environment.  Plastics are a fundamental part of modern society and they are here to stay. Ultimately, society has to move away from oil-based products towards sustainable bio-based alternatives. But regardless of whether a plastic is oil-based or plant-based, the biggest impact you can have on the life cycle of a plastic product is to reuse and recycle it. As a consumer, this means you have a choice and the power to make a positive impact. Find out where your nearest plastic waste recycling point is and look to promote home collection and the proper recycling of all types of plastic waste.  So next time you use the last of the ketchup, help to preserve our resources by making sure your plastic waste stays in the recycling loop."
"Do you walk the walk, or just talk the talk? Can you put your money where your mouth is, or are you all mouth and no trousers? According to a new study it seems that it’s mouth or trousers – we can’t have both.  In the animal kingdom evolution often provides males with beefy bodies, sexual weaponry such as big teeth, horns or antlers, or bold colours in order to attract a female’s attention and out-compete rivals. But as females often mate with multiple partners, males also need to generate numerous fast and healthy sperm to ensure that they are the most likely to sire offspring. So males are left facing competing demands, between finding a mate and fertilising eggs.  The problem is that these traits are costly, so males may be unable to invest in both.  There is evidence to suggest that species do face these “trade-offs” over reproduction, where it’s impossible to improve one trait without detracting from another. For example, in humans it’s thought that there may be a trade-off between growth and reproduction in women. Women who go through puberty earlier, or have children at an earlier age, are shorter as adults.  Similarly men may face a trade-off between investing in reproduction or resisting diseases. Those with higher levels of testosterone have been shown to have weaker immune responses. The same trade-off between investment in either bigger bodies and sexual weaponry or bigger testes and genitals is found in other animals, such as seals and sea lions, dolphins and whales, and many other birds, primates, ungulates and even insects. In a new study, published in Current Biology, we were interested in examining this evolutionary trade–off in howler monkeys. These monkeys, of which there are ten species distributed from Mexico to Argentina, live in a wide range of habitats and show big differences in social organisation.  Howler monkeys are among the loudest animals on the planet, yet they weigh just 7kg – about the size of a small dog, and lighter than a big Christmas turkey. They produce powerful, low frequency calls using a highly modified larynx, with extremely long vocal folds and a greatly enlarged cup-shaped hyoid bone. In most animals the hyoid is a very small, horseshoe-shaped bone that sits in the neck above the larynx and supports the tongue, but in howler monkeys it has evolved to become a large resonating chamber to amplify their roars. These evolutionary adaptations allow howler monkeys to produce extremely loud and incredibly low-frequency calls like those produced by animals ten times their size.  Remarkably, there is a huge amount of variation in the size of the hyoid bone among the howler monkeys species. Our new research aimed to try and describe this variation quantitatively, as well as understand both the evolutionary pressures that led to the observed variation, and the acoustic consequences of having large versus small hyoids.   We found that among males, hyoid volume varied widely among species – in fact the largest hyoid was 14 times the size of the smallest. We also found a large amount of variation in the size of the testes among species, with the largest testes 6.5 times bigger than the smallest. Overall, species living in small groups in which there tends to be just one male tended to have extremely large hyoids and very small testes. Those living in large groups, with many competing males, tended to have very small hyoids and very large testes. So it seems that males either invest in one reproductive trait or the other, but not both. We studied the acoustics of the howler monkey’s roars and found those with larger hyoids produced lower frequency roars that made them seem much bigger than they really are. Presumably this is important in those species where it’s common for a single male to reign over a harem of females, and needs to scare off rivals. In species where there are many males living in mixed groups there is perhaps less need for such vociferousness, but on the other hand the males need to produce more and faster sperm.  This is the first known example of a trade-off between investing in vocalising and increased sperm production, which opens the door to many other potential studies on the trade-offs between sexually-selected traits. It’s hard to say exactly how the trade-off works. Developing a large vocal organ and roaring may be so costly that there is simply not enough energy left to invest in testes. Alternatively, such a roar may be so effective at deterring rival males that there’s no need for capacious, hard-working testes to generate large amounts of quality sperm.  So it seems that, in howler monkeys at least, males are either all mouth and no trousers, or all trousers and no mouth. When it comes to sex and reproduction, evolution says you can’t have it all."
"Nigeria is experiencing a major conflict between nomadic herdsmen and indigenous farmers. In 2016, the conflict led to the death of 2,500 people, displaced 62,000 others and led to loss of US$13.7 billion in revenue. In January 2018 alone, the conflict claimed the lives of 168 people. The herdsmen are predominantly Fulanis, a primarily Muslim people scattered throughout many parts of West Africa. The farmers, meanwhile, are mostly Christian. Therefore, when violence erupts between the two groups, with symbolic results like churches being burnt down, it is unsurprising that the dominant narrative in Nigeria and abroad is that this is a conflict motivated by religion and ethnicity.  What’s missing is the environmental perspective. Nigeria spans more than 1,000km from a lush and tropical south to the fringes of the Sahara Desert in the north. And, in Nigeria, the Sahara is moving southward at a rate of 600 metres a year. At the same time, Lake Chad in the country’s far north-east has largely dried up. Fulani herdsmen who once relied on the lake have thus moved further south in search of pasture and water for their livestock. The further south you move, the more the population becomes Christian, hence when resource conflicts emerge they appear religious.   Such conflicts between herdsmen and farmers aren’t entirely new. A drought in the late 60s, for instance, kicked off struggles over land use across the Sahel, and the Fulanis do have a history of strategic annexation of territories. What’s new this time round is that the conflict has taken on an entirely different scale, as a problem once restricted to the north of Nigeria has become a major issue in the country’s south. This is because environmental devastation has necessitated widespread migration of Fulanis from all over West Africa to the south of Nigeria, which has been unable to prevent nomads from other countries from coming in along its long borders. The influx of new people has disrupted the existing dynamics and relationship between predominantly farming local communities and nomadic herdsmen. But environmental explanations are largely ignored in favour of talk of ethnic or religious conflict. Such talk quickly becomes highly emotive, preventing a full analysis of all the driving forces behind the conflict. The dominance of the “ethnic war” narrative therefore makes it harder to develop holistic and sustainable solutions and, in a country that is a mix of cultures and religions, puts national unity and peace-building at risk. The government’s response to all this has been near silence. In the vacuum, political explanations have emerged, often from people with a vested interest. For instance, elites and political leaders from affected regions suspect the president, Muhammadu Buhari, who himself is Fulani, of being complicit in the attacks (though they have stopped short of directly accusing him). There’s no evidence the president has anything to do with the conflict but, in a hierarchical society like Nigeria, the word of elites can be taken as gospel. The central government has proffered solutions such as cattle “colonies”, which take lands from indigenous farmers and give it to the Fulanis to graze. But among the farmers this only reinforces worries of an ethnic land grab.  The president has often spoken of “recharging” Lake Chad to its former size, perhaps using water diverted from the Ubangi River in the Congo basin, and he recently spoke on the subject at an African Union conference. Yet the lake still is not really built into the government’s strategy for the farmer-herder conflict.  So what would a sustainable and just solution to the conflict actually involve? Lake Chad certainly will need to be “recharged”, along with a massive programme of tree growing and sustainable water management. This will require the engagement of neighbouring countries – who have serious environmental problems of their own – and the support of international donor agencies, but it would go a long way towards stemming the migration southward and should reduce incidences of conflict. The government must also recognise, publicly, that this is at root a conflict over resources exacerbated by environmental problems. It must point this out when the need arises, rather than waiting until half-truths dominate public discourse. The Nigerian media, for its part, often thrives on emotive narratives. But this story of conflict between herders and farmers calls for less sensationalism and more investigative journalism that helps reveal further nuances to the complex issue. This isn’t a simple tale of ethnic conflict – the environment cannot be ignored."
"
Share this...FacebookTwitter
“[T]he absorption of incident solar-light by the atmosphere as well as its absorption capability of thermal radiation, cannot be influenced by human acts.”  – Allmendinger, 2017
“[G]lobal warming can be explained without recourse to the greenhouse theory.  The varying solar irradiation constitutes the sole input driving the changes in the system’s energy transfers.”  – Blaauw, 2017
“The down-welling LW radiation is not a global driver of surface warming as hypothesized for over 100 years but a product of the near-surface air temperature controlled by solar heating and atmospheric pressure.”  -Nikolov and Zeller, 2017

Allmendinger, 2017
The Refutation of the Climate Greenhouse Theory
“The cardinal error in the usual greenhouse theory consists in the assumption that photometric or spectroscopic IR-measurements allow conclusions about the thermal behaviour of gases, i.e., of the atmosphere. They trace back to John Tyndall who developed such a photometric method already in the 19th century. However, direct thermal measurement methods have never been applied so far. Apart from this, at least twenty crucial errors are revealed which suggest abandoning the theory as a whole. In spite of its obvious deficiencies, this theory has so far been an obstacle to take promising precautions for mitigating the climate change. They would consist in a general brightening of the Earth surface, and in additional measures being related to this. However, the novel effects which were found by the author, particularly the absorption of incident solar-light by the atmosphere as well as its absorption capability of thermal radiation, cannot be influenced by human acts.”

Blaauw, 2017
“This paper demonstrates that global warming can be explained without recourse to the greenhouse theory. This explanation is based on a simple model of the Earth’s climate system consisting of three layers: the surface, a lower and an upper atmospheric layer. The distinction between the atmospheric layers rests on the assumption that the latent heat from the surface is set free in the lower atmospheric layer only. The varying solar irradiation constitutes the sole input driving the changes in the system’s energy transfers. All variations in the energy exchanges can be expressed in terms of the temperature variations of the layers by means of an energy transfer matrix. It turns out that the latent heat transfer as a function of the temperatures of the surface and the lower layer makes this matrix next to singular. The near singularity reveals a considerable negative feedback in the model which can be identified as the ‘Klimaversta¨rker’ presumed by Vahrenholt and Lu¨ning. By a suitable, yet realistic choice of the parameters appearing in the energy transfer matrix and of the effective heat capacities of the layers, the model reproduces the global warming: the calculated trend in the surface temperature agrees well with the observational data from AD 1750 up to AD 2000.”


Nikolov and Zeller, 2017
“Our analysis revealed that GMATs [global mean annual temperatures] of rocky planets with tangible atmospheres and a negligible geothermal surface heating can accurately be predicted over a broad range of conditions using only two forcing variables: top-of-the-atmosphere solar irradiance and total surface atmospheric pressure. The hereto discovered interplanetary pressure-temperature relationship is shown to be statistically robust while describing a smooth physical continuum without climatic tipping points. This continuum fully explains the recently discovered 90 K thermal effect of Earth’s atmosphere. The new model displays characteristics of an emergent macro-level thermodynamic relationship heretofore unbeknown to science that has important theoretical implications. A key entailment from the model is that the atmospheric ‘greenhouse effect’ currently viewed as a radiative phenomenon is in fact an adiabatic (pressure-induced) thermal enhancement analogous to compression heating and independent of atmospheric composition. Consequently, the global down-welling long-wave flux presently assumed to drive Earth’s surface warming appears to be a product of the air temperature set by solar heating and atmospheric pressure. In other words, the so-called ‘greenhouse back radiation’ is globally a result of the atmospheric thermal effect rather than a cause for it. … The down-welling LW radiation is not a global driver of surface warming as hypothesized for over 100 years but a product of the near-surface air temperature controlled by solar heating and atmospheric pressure … The hypothesis that a freely convective atmosphere could retain (trap) radiant heat due its opacity has remained undisputed since its introduction in the early 1800s even though it was based on a theoretical conjecture that has never been proven experimentally.”

Huang et al., 2017
“Various scientific studies have investigated the causal link between solar activity (SS) and the earth’s temperature (GT). [T]he corresponding CCM [Convergent Cross Mapping] results indicate increasing significance of causal effect from SS [solar activity] to GT [global temperature] since 1880 to recent years, which provide solid evidences that may contribute on explaining the escalating global tendency of warming up recent decades. … The connection between solar activity and global warming has been well established in the scientific literature. For example, see references [1–10]. … Among which, the SSA [Singular Spectrum Analysis] trend extraction is identified as the most reliable method for data preprocessing, while CCM [Convergent Cross Mapping] shows outstanding performance among all causality tests adopted. The emerging causal effects from SS [solar activity] to GT [global temperatures], especially for recent decades, are overwhelmingly proved, which reflects the better understanding of the tendency of global warming.”

Viterito, 2017
“The Correlation of Seismic Activity and Recent Global Warming (CSARGW) demonstrated that increasing seismic activity in the globe’s high geothermal flux areas (HGFA) is strongly correlated with global temperatures (r=0.785) from 1979-2015. The mechanism driving this correlation is amply documented and well understood by oceanographers and seismologists. Namely, increased seismic activity in the HGFA (i.e., the mid-ocean’s spreading zones) serves as a proxy indicator of higher geothermal flux in these regions. The HGFA include the Mid-Atlantic Ridge, the East Pacific Rise, the West Chile Rise, the Ridges of the Indian Ocean, and the Ridges of the Antarctic/Southern Ocean. This additional mid-ocean heating causes an acceleration of oceanic overturning and thermobaric convection, resulting in higher ocean temperatures and greater heat transport into the Arctic. This manifests itself as an anomaly known as the “Arctic Amplification,” where the Arctic warms to a much greater degree than the rest of the globe. Applying the same methodology employed in CSARGW, an updated analysis through 2016 adds new knowledge of this important relationship while strengthening support for that study’s conclusions. The correlation between HGFA seismic frequency and global temperatures moved higher with the addition of the 2016 data: the revised correlation now reads 0.814, up from 0.785 for the analysis through 2015. This yields a coefficient of determination of .662, indicating that HGFA [high geothermal flux area] seismicity accounts for roughly two-thirds of the variation in global temperatures since 1979.”

Hertzberg et al., 2017
“This study examines the concept of ‘greenhouse gases’ and various definitions of the phenomenon known as the ‘Atmospheric Radiative Greenhouse Effect’. The six most quoted descriptions are as follows: (a) radiation trapped between the Earth’s surface and its atmosphere; (b) the insulating blanket of the atmosphere that keeps the Earth warm; (c) back radiation from the atmosphere to the Earth’s surface; (d) Infra Red absorbing gases that hinder radiative cooling and keep the surface warmer than it would otherwise be – known as ‘otherwise radiation’; (e) differences between actual surface temperatures of the Earth (as also observed on Venus) and those based on calculations; (f) any gas that absorbs infrared radiation emitted from the Earth’s surface towards free space. It is shown that none of the above descriptions can withstand the rigours of scientific scrutiny when the fundamental laws of physics and thermodynamics are applied to them.”

Song, Wang & Tang, 2016
A Hiatus of the Greenhouse Effect
“In the last subperiod [2003-2014], the global averaged SULR [surface upwelling longwave radiation/greenhouse effect] anomaly remains trendless (0.02 W m−2 yr−1) because Ts [global temperatures] stop rising. Meanwhile, the long-term change of the global averaged OLR anomaly (−0.01 W m−2 yr−1) is also not statistically significant. Thus, these two phenomena result in a trendless Gaa [atmospheric greenhouse effect]. …  [A]remarkably decreasing Gaa trend (−0.27 W m−2 yr−1) exists over the central tropical Pacific, indicating a weakened atmospheric greenhouse effect in this area, which largely offsets the warming effect in the aforementioned surrounding regions. As a result, a trendless global averaged Gaa [atmospheric greenhouse effect] is displayed between 1991 and 2002 (Fig. 2).  … Again, no significant trend of the global averaged Gaa [atmospheric greenhouse effect] is found from 2003 to 2014 (Fig. 2) because the enhanced warming effect over the western tropical Pacific is largely counteracted by the weakened warming influence on the central tropical Pacific.”


Manheimer, 2016
“[T]he actual data show that up to now fears of imminent climate catastrophe are not supported by data, or else involve processes occurring since long before excess CO2 in the atmosphere became a concern. Based on actual measurements and reasonable extrapolation of them, there is no reason why the responsible use of fossil fuel cannot continue to support worldwide civilisation. The argument to greatly restrict fossil fuel rests entirely on the theoretical assertion that at some point in the near future there will be a sudden and dramatic change in the very nature of the data presented here. If implemented, these would be sufficient to greatly upset the lifestyle of billions of people, and to further impoverish the already most impoverished parts of the world. …  [N]othing in the past suggests that future climate will be significantly different before mid century because of rising levels of CO2.”

Hertzberg and Schreuder, 2016


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“The authors evaluate the United Nations Intergovernmental Panel on Climate Change (IPCC) consensus that the increase of carbon dioxide in the Earth’s atmosphere is of anthropogenic origin and is causing dangerous global warming, climate change and climate disruption. The totality of the data available on which that theory is based is evaluated. The data include: (a) Vostok ice-core measurements; (b) accumulation of CO2 in the atmosphere; (c) studies of temperature changes that precede CO2 changes; (d) global temperature trends; (e) current ratio of carbon isotopes in the atmosphere; (f) satellite data for the geographic distribution of atmospheric CO2; (g) effect of solar activity on cosmic rays and cloud cover. Nothing in the data supports the supposition that atmospheric CO2 is a driver of weather or climate, or that human emissions control atmospheric CO2.”

Mikhailovich et al., 2016
About the Influence of the Giant Planets on
Long-Term Evolution of Global Temperature
“The observed variability of global temperature is usually explained through the decrease in the coefficient of the grayness of the Earth caused by increased content of greenhouse gases in the atmosphere, such as CO2, i.e. by the anthropogenically caused increase in the greenhouse effect. The validity of such views raises some doubts, as their validity is based either on the results of the climate simulation, or on the results of the regression analysis, in relation to which the fullness of the used set of regression does not seem certain. At the same time, just the results of climate modeling do not seem to be quite reliable … The effects associated with the displacement of the center of gravity of the solar system under the influence of giant planets (Jupiter and Saturn) are discussed. Based on the hypothesis of parametric resonance in the variation of global temperature with disturbances in the photosphere shape and the Earth-to-Sun distance due to the oppositions of said planets, a regression model that explains the observed long-term evolution of global temperature is built. It was shown that residuals of the model are close to white noise, i.e. the [influence of planets] hypothesis almost entirely explains the effect of temperature increase for the period presented in the vernacular crutem3 database [1850-present].”

 Vares et al., 2016
… Earth’s Magnetic Dipole Intensity … Geomagnetic
Activity … Causal Source for Global Warming
“Quantitative analyses of actual measurements rather than modeling have shown that “global warming” has been heterogeneous over the surface of the planet and temporally non-linear. Residual regression analyses by Soares (2010) indicated increments of increased temperature precede increments of CO2 increase. The remarkably strong negative correlation (r = -0.99) between the earth’s magnetic dipole moment values and global CO2-temperature indicators over the last ~30 years is sufficient to be considered causal if contributing energies were within the same order of magnitude. Quantitative convergence between the energies lost by the diminishing averaged geomagnetic field strength and energies gained within the ocean-atmosphere interface satisfy the measured values for increased global temperature and CO2 release from sea water. The pivotal variable is the optimal temporal unit employed to estimate the total energies available for physical-chemical reactions. The positive drift in averaged amplitude of geomagnetic activity over the last 100 years augmented this process. Contributions from annual CO2 from volcanism and shifts in averaged geomagnetic activity, lagged years before the measured global temperature-CO2 values, are moderating variables for smaller amplitude perturbations. These results indicated that the increase in CO2 and global temperatures are primarily caused by major geophysical factors, particularly the diminishing total geomagnetic field strength and increased geomagnetic activity, but not by human activities. Strategies for adapting to climate change because of these powerful variables may differ from those that assume exclusive anthropomorphic causes.”

Easterbrook, 2016
“CO2 makes up only a tiny portion of the atmosphere (0.040%) and constitutes only 3.6% of the greenhouse effect. The atmospheric content of CO2 has increased only 0.008% since emissions began to soar after 1945. Such a tiny increment of increase in CO2 cannot cause the 10°F increase in temperature predicted by CO2 advocates. Computer climate modelers build into their models a high water vapor component, which they claim is due to increased atmospheric water vapor caused by very small warming from CO2, and since water vapor makes up 90–95% of the greenhouse effect, they claim the result will be warming. The problem is that atmospheric water vapor has actually declined since 1948, not increased as demanded by climate models. If CO2 causes global warming, then CO2 should always precede warming when the Earth’s climate warms up after an ice age. However, in all cases, CO2 lags warming by ∼800 years. Shorter time spans show the same thing—warming always precedes an increase in CO2 and therefore it cannot be the cause of the warming.”

Chemke et al., 2016
The Thermodynamic Effect of Atmospheric
Mass on Early Earth’s Temperature
Observations suggest that Earth’s early atmospheric mass differed from the present day. The effects of a different atmospheric mass on radiative forcing have been investigated in climate models of variable sophistication, but a mechanistic understanding of the thermodynamic component of the effect of atmospheric mass on early climate is missing. Using a 3D idealized global circulation model (GCM), we systematically examine the thermodynamic effect of atmospheric mass on near-surface temperature. We find that higher atmospheric mass tends to increase the near-surface temperature mostly due an increase in the heat capacity of the atmosphere, which decreases the net radiative cooling effect in the lower layers of the atmosphere. Additionally, the vertical advection of heat by eddies decreases with increasing atmospheric mass, resulting in further near-surface warming. As both net radiative cooling and vertical eddy heat fluxes are extratropical phenomena, higher atmospheric mass tends to flatten the meridional temperature gradient.
An increase in atmospheric mass causes an increase in near-surface temperatures and a decrease of the equator-pole near-surface temperature gradient. Warming is caused mostly by the increase in atmospheric heat capacity, which decrease the net radiative cooling of the atmosphere.
[No mention of CO2 as a factor in warming the Earth-Atmosphere system]

Haine, 2016
“Notably, the three studies [Jackson et al., 2016;  Böning et al., 2016; Robson et al., 2016] report an absence of anthropogenic effects on the AMOC, at least so far: the directly observed AMOC weakening since 2004 is not consistent with the hypothesis that anthropogenic aerosols have affected North Atlantic ocean temperatures. The midlatitude North Atlantic temperature changes since 2005 have greater magnitude and opposite sign (cooling) than those attributed to ocean uptake of anthropogenic heat. The anthropogenic melt from the Greenland ice sheet is still too small to be detected.. And despite large changes in the freshwater budget of the Arctic, some of which are anthropogenic, there is no clear change in the delivery of Arctic freshwater to the North Atlantic due to human climate forcing.”

Ellis and Palmer, 2016
Conclusion: “[I]nterglacial warming is eccentricity and polar ice regrowth regulated, Great Summer forced, and dust-ice albedo amplified. And the greenhouse-gas attributes of CO2 play little or no part in this complex feedback system.”

Evans, 2016
“The conventional basic climate model applies “basic physics” to climate, estimating sensitivity to CO2. However, it has two serious architectural errors. It only allows feedbacks in response to surface warming, so it omits the driver-specific feedbacks. It treats extra-absorbed sunlight, which heats the surface and increases outgoing long-wave radiation (OLR), the same as extra CO2, which reduces OLR from carbon dioxide in the upper atmosphere but does not increase the total OLR. The rerouting feedback is proposed. An increasing CO2 concentration warms the upper troposphere, heating the water vapor emissions layer and some cloud tops, which emit more OLR and descend to lower and warmer altitudes. This feedback resolves the nonobservation of the “hotspot.” An alternative model is developed, whose architecture fixes the errors. By summing the (surface) warmings due to climate drivers, rather than their forcings, it allows driver-specific forcings and allows a separate CO2 response (the conventional model applies the same response, the solar response, to all forcings). It also applies a radiation balance, estimating OLR from properties of the emission layers. Fitting the climate data to the alternative model, we find that the equilibrium climate sensitivity is most likely less than 0.5°C, increasing CO2 most likely caused less than 20% of the global warming from the 1970s, and the CO2 response is less than one-third as strong as the solar response. The conventional model overestimates the potency of CO2 because it applies the strong solar response instead of the weak CO2 response to the CO2 forcing.”

Gervais, 2016
Anthropogenic CO2 Warming Challenged By 60-year Cycle
Conclusion: “Dangerous anthropogenic warming is questioned (i) upon recognition of the large amplitude of the natural 60–year cyclic component and (ii) upon revision downwards of the transient climate response consistent with latest tendencies shown in Fig. 1, here found to be at most 0.6 °C once the natural component has been removed, consistent with latest infrared studies (Harde, 2014). Anthropogenic warming well below the potentially dangerous range were reported in older and recent studies (Idso, 1998; Miskolczi, 2007; Paltridge et al., 2009; Gerlich and Tscheuschner, 2009; Lindzen and Choi, 2009, 2011; Spencer and Braswell, 2010; Clark, 2010; Kramm and Dlugi, 2011; Lewis and Curry, 2014; Skeie et al., 2014; Lewis, 2015; Volokin and ReLlez, 2015). On inspection of a risk of anthropogenic warming thus toned down, a change of paradigm which highlights a benefit for mankind related to the increase of plant feeding and crops yields by enhanced CO2 photosynthesis is suggested.”
Share this...FacebookTwitter "
"The UN climate talks in Paris have ended with an agreement between 195 countries to tackle global warming. The climate deal is at once both historic, important – and inadequate. From whether it is enough to avoid dangerous climate change to unexpected wins for vulnerable nations, here are five things to help understand what was just agreed at COP21. The most striking thing about the agreement is that there is one. For all countries, from superpowers to wealthy city-states, fossil fuel-dependent kingdoms to vulnerable low-lying island nations, to all agree to globally coordinate action on climate change is astonishing.  And it is not just warm words. Any robust agreement has to have four elements. First, it needs a common goal, which has now been defined. The agreement states that the parties will hold temperatures to “well below 2°C above pre-industrial levels and to pursue efforts to limit the temperature increase to 1.5°C above pre-industrial levels”. Second, it requires matching scientifically credible reductions in carbon dioxide and other greenhouse gas emissions. The agreement is woollier here, but it does state that emissions should peak “as soon as possible” and then be rapidly reduced. The next step is to: Achieve a balance between anthropogenic emissions by sources and removals by sinks of greenhouse gases in the second half of this century, on the basis of equity … Third, as current pledges to reduce emissions imply a warming of nearly 3°C above pre-industrial levels, there needs to be a mechanism to move from where countries are today, to zero emissions. There are five-year reviews, and “the efforts of all parties will represent a progression over time”, which means at each step countries should increase their levels of emission cuts from today’s agreements. Finally, this all means developed countries need to rapidly move from fossil fuel energy to renewable sources. But the challenge is larger for the developing world: these countries must leapfrog the fossil fuel age. They need funds to do so and a key part of the agreement provides US$100 billion per year to 2020, and more than that after 2020. There is a lot to like about this agreement: it gives a common goal to avoid the worst impacts of climate change, the overall emissions cuts stated are reasonably credible, there is a mechanism to increase national emissions cuts over time towards “net zero”, and there is funding secured to help poorer countries harness the power of the sun, wind and waves instead of coal, oil and gas. It provides a roadmap to get the world off its dangerous addiction to fossil fuel energy. What constitutes dangerous climate change is different for different people. For some poor people climate change is already beyond dangerous, it’s deadly. The threats escalate as the cumulative emissions of carbon dioxide in the atmosphere increase. Because this deal has been so long in arriving, the window of opportunity to limit temperature rises at 1.5°C is closing fast; this spells trouble for many low-lying areas. Even the most ambitious pathways to zero emissions in the coming decades for a carbon budget associated with a reasonable (66%) chance of keeping 2°C above pre-industrial levels are extremely challenging. Countries have a long way to go to get to these levels of reductions. Importantly, there are no penalties, except public shaming, for countries that do not meet their commitments to reduce emissions. To implement this deal the public, civil society organisations, opposition parties in politics and businesses will need to keep government policies in check. Essentially, it is the will of the people, most governments and enlightened businesses, pitted against the deep pockets of the fossil fuel industry. One future fear is that when the “global stocktake” happens in 2023, some countries may see that others aren’t doing their bit, and may themselves then stop reducing emissions and the agreement will fall apart.  The warming we see from greenhouse gas emissions is dominated by the cumulative emissions of carbon dioxide. Given the emissions so far, limiting warming to “well below” 2°C, and anywhere near 1.5°C means reducing CO2 emissions to near zero extremely quickly.  Then society will need to continue further, to negative emissions. That is, removing carbon dioxide from the atmosphere and storing it somewhere else. There are various options here, from planting trees and keeping restored forest in perpetuity, enhancing uptake in soils, or using biomass energy in power plants then storing the carbon dioxide underground (so-called Bio-Energy with Carbon Capture and Storage). Expect to hear a lot more about this. To get to zero emissions this century requires many policy changes. Fossil fuel companies must have their subsidies stripped. Investments in high-carbon emitting infrastructure must end, particularly World Bank loans and other regional multilateral bank support for countries. Zero emissions buildings will become the norm. Tropical forests will have to be protected to reduce and then eliminate deforestation.  Expect a greater push on the technological limitations on renewable energy, with big new investments, mostly improving how to store power, for when the wind is not blowing and the sun is not shining. Expect the cost of renewables to sink much further as these technologies are scaled up and implemented worldwide. Expect significant areas of the world to be given over to wind turbines and solar farms. Paris was a high-stakes game of geopolitical poker. Surprisingly, those countries with the poorest hand came out better than expected. The climate talks were subject to a series of shifting alliances going beyond the usual income-rich northern countries and income-poor global south countries. Central to this has been US-Chinese diplomacy, both agreeing to limit emissions, and more recently the new Climate Vulnerable Forum grouping of countries. From nowhere, the forum has forced keeping global temperatures to 1.5°C high on the political agenda.  We haven’t heard the last of this level of ambition – one of the decisions in the Paris agreement is to invite the Intergovernmental Panel on Climate Change to produce a special report on the impacts at 1.5°C, and emissions pathways consistent with this level of warming.  These countries didn’t get everything they wanted – the US would not accept liability in financial terms for states that may lose their territory to rising sea levels in the future. But they played their hand extremely smartly."
"The Labour party is reeling from a devastating election defeat in which many of its traditional voters turned their backs on the party. If it is to rebound, Labour must take the time to understand what went wrong. And its analysis must go beyond the defenders of Jeremy Corbyn arguing that it was solely down to Brexit, and his detractors pinning all the blame on the leader and “Corbynism”. It is also likely that the election result reflects a much longer and deeper trend, in which the party has lost the trust of communities it has long represented yet who have now lost faith in the political system to change their lives for the better. Without a radical policy platform Labour stands no chance of winning back voters Whatever the final verdict, the Labour party will have to change if it is to reconnect with the broad coalition of voters it needs to win back power. But as it does this, it must not lose sight of the one thing it got right in this election. Labour was right to grasp the scale of the economic and environmental challenge the country faces and offer ambitious solutions. Against the backdrop of the longest squeeze in living standards for generations, economic growth that has passed many communities by, entrenched poverty and a climate emergency, Labour offered a manifesto that began to rise to the challenge. It contained flaws, but it would have undoubtedly begun the process of transforming our economy. Those eager to reject Corbyn would be wrong to abandon this ground as well. But Labour must learn from this election. Policies that all the polling indicates are individually popular with voters simply did not cut through: 64% of people support significant increase in public spending to invest in the green economy; 66% believe companies should be required to share their profits with employees; and 61% believe that austerity has damaged vital public services. The manifesto should have resonated with many voters and yet it didn’t. In part, this was because an ambitious reform agenda was presented as a collection of giveaways that felt too good to be true. A 10-year economic agenda was shoehorned into a five-year programme for government and voters rightly questioned whether it could all be delivered. There was no attempt to prioritise or highlight key policies. And not enough groundwork was done in advance of the campaign to convince the public that this scale of change was not only desirable but deliverable.  Critically, too much of the change that Labour sought to achieve was top-down. Rather than pushing power out to communities, it sought change through an expanded national state with regional offices. The absence of a radical agenda on devolution was a striking omission in the manifesto. An ambition to democratise the economy too often boiled down to state ownership through renationalisation. For communities distrustful of promises from Westminster, Labour failed to tell the story of how it could deliver radical change by giving them more power and control. As Labour dissects what went wrong, the factions defending and attacking Corbyn must learn these lessons and build from here. Abandoning Labour’s entire policy programme – as some of those who reject Corbyn wish to – and replacing it with an agenda that seeks incremental changes to the status quo would be a big mistake. There is clear political consensus that for too many people the economy just isn’t working, and also that the threat of the climate crisis is real and imminent. Future elections will be fought and won on who has the answers to these seismic issues. Without a radical policy platform Labour stands no chance of winning back voters who despair of a system that is failing. But Labour’s response must be rooted in the people whose lives it seeks to change. The next election will be fought after we have left the European Union and the promise to “get Brexit done” has inevitably but tragically failed to deliver the positive change those who voted for it want. All the issues that are bubbling underneath the Brexit vote will have punched through the surface – as will the anger and frustration of millions who will feel let down. If Labour can go into that election having done the groundwork, and with a manifesto that offers real change, it may just find a route back to power.  • Miatta Fahnbulleh is chief executive of the New Economics Foundation"
"The revelation that Volkswagen deliberately circumvented emissions tests on many of its diesel vehicles has provoked a huge storm of controversy. This diesel deception has understandably angered car owners. And some have suggested that VW’s management either must have known about the scandal, or effectively lost control of the company. The allegations are severe. According to the Environmental Protection Agency, VW deployed a “defeat device” enabling its cars to meet emissions standards under official test conditions, even though they can release up to 40 times the legal level of nitrogen oxides (NOx) under normal driving conditions. Worse was to come though. VW went on to admit that 11m vehicles worldwide had been fitted with the device. An analysis by the Guardian puts the collective impact of this number of cars at nearly one million additional tonnes of air pollution per year. In the EU, it increasingly seems that there is more to this scandal than car manufacturers using underhand tactics to “hotwire” official emissions tests. Leaked documents have revealed that three powerful member states – the UK, France and Germany – have all recently lobbied for the inclusion of loopholes in a new emissions test planned for roll-out in 2017. Germany, it seems, even called for this new test to be conducted on a sloping downhill track. In Brussels itself, my own conversations with EU officials have exposed a tendency to accept carmakers’ behaviour as an unavoidable part of the regulatory “game”. On more than one occasion I have heard the argument that what vehicle manufacturers are doing can’t really be classed as cheating, because – after all – wouldn’t any rational economic actor seek to “exploit the flexibilities” in this kind of regulatory test to their advantage? All of this should give us serious pause for thought. Circumventing an emissions test is one thing. But if member states are actively calling for Brussels to enable the continuation of this behaviour, and EU officials themselves see it as a natural part of the “game”, then we must ask who – if anybody – is left to represent the interests of the public, or indeed the climate, in the development of the EU’s environmental agenda. The scandal in fact reveals deep-seated pathologies in the way the EU’s environmental policies are made. It is, crucially, the EU’s privileging of “expert”, industry-generated data on these emissions, produced by a supposedly objective, repeatable test, that has allowed VW to deceive its customers and the wider public. Yet these are the same industry experts who stifle debate about the sustainability of petrol and diesel carmakers’ contributions to the EU’s economy. This, even as Europe faces growing crises of urban air pollution, obesity, and of course climate change. Meanwhile, on-the-road emissions data, such as that painstakingly assembled by the International Council on Clean Transportation, is all too often dismissed as unscientific, and open to the corrupting influences of a messy and complex “real world”. These data are effectively crowdsourced from thousands of drivers and other road users, many with an economic interest in averting the depreciation of their vehicles. And it is these road users – and the wider public at large – who have no choice but to subject themselves to urban air pollution across Europe.  According to a recent Transport & Environment report, this “invisible killer” leads to 500,000 premature deaths a year. And diesel vehicles are the principal cause of those deaths. VW’s diesel deception doesn’t just point to an urgent need for a better vehicle emissions test; it highlights the requirement for a more open and inclusive approach to dealing with environmental problems in Europe. As the EU seeks to address and move on from this scandal, Brussels must break the stranglehold exerted over its vehicle pollutant emissions legislation by an inner circle of hubristic industry experts. Instead, it must embrace the ideas, concerns and knowledge of those who most suffer in the face of air pollution – the European public."
"A growing share of voters list climate and the environment as their top priority, according to a new poll from the Environmental Voter Project. Of the registered voters surveyed, 14% named “addressing climate change and protecting the environment” their No 1 priority over all other issues, compared with 2% to 6% before the 2016 presidential election. Climate and environment voters are also the most motivated to vote in 2020, saying they are willing to wait in line an average of an hour and 13 minutes at the polls. “There are almost 30 million climate voters out there who are already registered to vote. That’s a huge constituency,” said Nathaniel Stinnett, the founder of the project, which aims to identify inactive environmentalists and turn them into consistent activists and voters. “That’s like four times the number of NRA members. It’s enormous, and a lot of that growth has happened over the last two to three years.” In 2016, there were 200 million registered voters in the US. If 14% of voters care the most about climate and the environment, that would equal 28 million people. The poll compared survey responses to public voter file records and found that infrequent voters are more likely than frequent ones to assign a higher importance to climate and the environment. That suggests environment advocates could benefit from getting more climate-minded voters to the polls with some easy fixes, such as awareness campaigns for early and absentee voting. A quarter of infrequent voters were not aware they could vote early, and 29% weren’t aware they could vote absentee. Voting by mail could also increase environment voter turnout. The online poll of 1,514 registered voters also found that people dramatically over-report how often they vote – 89% of registered voters claimed to vote in every or almost every presidential election, but just 59% actually did. That over-reporting shows that people want to be seen as good voters and that social pressure could encourage them to turn out, Stinnett said. The poll also confirmed that while Donald Trump is unpopular with a majority of Americans, his supporters are the most reliable voters. The new numbers back up Democrats’ efforts to weave the climate crisis into their platforms, as was on display in the most recent debate. Nearly a third of self-identified “very progressive” voters called climate and the environment their top issue. On the stage last week, Bernie Sanders pivoted to climate change in a question about race. Elizabeth Warren said progress on climate won’t happen without reforms to address corruption. Joe Biden said displaced fossil fuel workers will be able to transition to high-paying green jobs. However, other matters still top climate change in most voters’ minds. When forced to choose, healthcare tops voters’ priority lists. Climate change falls fourth, after improving the economy and creating jobs, and fixing immigration. It ties with reducing gun violence and outpaces reducing taxes."
nan
"The Amazon, perhaps more than any other region of the globe, has consistently been idealised and mythologised. This is true both of its societies, often envisioned as “lost tribes in the forest”, and the “raw green hell” of its environment. Although it has been incorporated into the modern world system since the 16th century, Amazonia is still widely regarded as a lush, beckoning frontier of untapped natural resources. This matters because stereotypical images effect how the region continues to be treated in terms of international politics, commercial ventures, environmentalist interventions and developmental prescriptions. The modern reassertion of Amazonia as untapped nature, also currently wrapped in a globalist eco-package – lungs of the Earth, bio-diversity, carbon sink – offers license for rapacious commercial exploitation.  One of the implications of the “frontier still to be conquered” is that Amazonia offers the comparative advantage of “cheap nature” and is not seen as a social landscape. This is an idea that is captured in the subtitle of the archaeologist Betty Meggar’s influential book Amazonia: Man and Culture in a Counterfeit Paradise. This process of erasing the idea of a social landscape proceeds in part by denying the viability, or indeed history, of the numerous social landscapes of Amazonia, past and present.  We’re seeing the building of highly destructive roads and hydroelectric dam programs, such as those currently pursued in the Tapajós and Xingu basins. The region is also currently succumbing to little-regulated extraction of minerals and commercial foodstuffs, such as soybeans, as well as timber felling and cattle-ranching.  But the region does have a history, albeit one that is little understood. And one period of this history in particular demonstrates how such mythologising plays into the hands of non-Amazonian interests, rather than Amazonian constituents. The rubber industry, which flourished between 1820 and 1910, is perhaps the best-known historical epoch of the region. At its height, the industry attracted as many as 300,000 people, mainly immigrants from northeastern Brazil, and there were direct shipping lines between New York and Liverpool and the ports of Manaus and Belem. The Opera House in Manaus exemplified the cosmopolitan character of “rubber society”.  But it has been idealised, too. This 100-year-long extractive industry, upon which industrialisation in Europe and North America depended, is conventionally depicted as a “boom”, an unexpected and transitory event that transformed the region and promised much, only to be followed by an equally dramatic regional decline. But re-examination of the period challenges this portrayal. Amazonian rubber (primarily Hevea brasilensis) was extracted from trees that were naturally distributed in the forest, not from plantation cultivation. The growth of the industry was therefore dependent on increasing the number of tappers, not on technical changes that might enhance productivity.  With the development of vulcanisation in the mid-19th century, the uses to which rubber was put increased dramatically. So, therefore, did the range and intensity of extractive enterprise, including enslavement of Indian tappers, notoriously in the Putumayo. But change was incremental. The “boom” of the rubber industry applies better to the global growth of the range and volume of industrial applications of rubber than it does to the industry on the ground at the time. We might compare the output of Amazonian rubber at the height of the so-called boom with that of Southeast Asian plantations (initially, mainly Malaysian). In the chart below, output from Amazonia (which peaks in 1910-1912) is about 60,000 metric tons. (Some published figures would place it just under 90,000 tons – but in terms of the broad picture, this is an inconsequential difference.) This is a number that pales in the face of plantation output, which in just a few years overtook Amazonian output. But despite the precipitous collapse of the price of wild rubber in 1910, when plantation rubber came onto the market, Amazonians continued to produce rubber for decades (as the chart above indicates). They did so not as a central cash crop, but in combination with other autosubsistent and low-key market activities. And so to regard Amazon production as a “boom” that failed to be converted into a mature plantation industry utterly misrepresents it. The industry’s collapse was not the result of intrinsic Amazonian shortcomings, but because of the cheaper sourcing of rubber from Southeast Asian plantations, which were not susceptible to the leaf blight that plagued attempts at Amazonian cultivation.  Although the rubber period is hailed as an age of commercial success, it is also invoked as an example of the chronic failures of flawed South American enterprise. That failure is variously attributed to a shortage of entrepreneurial zeal, the fatal lassitude characteristic of “the tropics”, truculent peasants and “the Dutch disease”, among many other suggested flaws.  The collapse of rubber is cited as the immediate predecessor to the economic stagnation said to have characterised Amazonia throughout most of the 20th century. It is said that the rubber industry singularly failed to transform the region and provide a lasting basis for integration into the modern world economy. But none of this can be blamed for the local “bust”. The global character of the rubber industry is disregarded in these portrayals of a regional phenomenon. It is as though after the supposed industry “boom”, blossoming “Amazonian society” merely devolved back into, or was overwhelmed by, a natural regime. In light of this, it is not surprising that in the recurrent myth-making apparatus of “the lost world”, “the land people forgot”, “the last frontier” and so on, a general picture of “non-indigenous” Amazonia as a land of inept and barely coping colonists resurfaces.  Thinking of the rubber industry as a “boom” reinforces the notion that attempts to “tame the Amazon” are precarious because of the intractability of the forest. And now that the portrayal of Amazonia as fundamentally a natural and durable space, inimical to humans, has returned, the developmental emphasis is on the gross extraction of raw materials, not the supported settlement of Amazonian communities.  The renewed commercial extractive exploits in the region appeal to the same old “conquest of empty frontiers” and the rational exploitation of “natural wealth”. But these are actually being conducted against the existing, but ill-defended interests of Amazonians – indigenous, peasant, and colonist alike – who have occupied those “empty frontiers” for centuries, and whose voices and presence are too often overwhelmed by the iconography of a regal, Amazonian tropicalism."
"When I think about 2019, there is one scene that springs to mind, something that sums up the milieu so perfectly that it almost seems art-directed. There we were two weeks ago at Rose Bay on the water’s edge, waiting for a private boat to take us to a harbourside mansion for a wine tasting. It was one of those days when Sydney’s air quality was among the worst in the world. The boat emerged from the pea soup gloom with the words “VIP” on the side. We were all in our party dresses and chunky trainers, phones fully charged to maximise the Instagrammable location, only coughing a little bit although peoples’ eyes were red and I noticed some fellow guests pulling on Ventolin inhalers. Influencers posed by the swimming pool, seeing but refusing to see – this red-raw sun, that dirty brown sky At the mansion there was a DJ, sommeliers and a chef, who explained in great detail the origin of the scallops on the canapes and a recent, inspirational trip to Oaxaca. Later there was a wine tasting where we gathered around to swirl and spit. Every varietal had notes of bushfire. Various people wandered up to us and said “great day for it!” and “beautiful weather” without irony. How could they say that? The sun was (there was only one word for it) demonic, a burning red eye in a thick smoky sky. The Sydney Harbour Bridge and the Opera House were out there … somewhere, obscured in a brown haze. We stood near the pool, eating tiny food, drinking wine from large balloon glasses while ash flew from the sky, some of it landing in my drink. The DJ played on but the tunes – Tones and I, Mark Ronson – were nervy, jangly and strangely discordant. The smell of the smoke had an almost chemical taint, and in between trying the pinot and moving on to the tempranillo, I wondered about the alchemy at work in this commingling of the elements: the ancient forests and its animals turned to columns of ash, collapsed and drifting through the air, settling on the water and soil; and later in and on my body after swimming in the dirty sea that morning and now swallowing particles of ash floating in my wine at the party on the harbour’s edge. (“At the end of the world,” my friend and I nervously joked.) More wine was poured and more people commented on the great weather (except for a sommelier who confessed sotto voce that he felt afraid), and influencers posed in the gloom on the jetty and by the swimming pool, seeing but refusing to see what was all around them: this red-raw sun, that dirty brown sky. The cognitive dissonance would have been funny had I not been so scared. It brought to mind F Scott Fitzgerald, a writer who understood more than most that decadent parties prefigure societal collapse. Had his novel The Great Gatsby been written now, the scene that day in Point Piper would not be out of place. Returning to shore in the haze, we could have been excused for thinking we were crossing the Styx – the mystical Greek crossing into the Underworld – and in this heightened state the day seemed more than the sum of its parts. Instead it served as both an elegy for the lost world that had disappeared beyond the haze and a portent of the world to come. Sign up to receive the top stories from Guardian Australia every morning That is what 2019 has come to mean to me: not the landslide elections and the global protests and Fleabag season 2. But the year some undeniable bomb dropped and dispersed its truth all around us in the form of dark particles in the air that didn’t just sit around us – but entered our bodies in unholy communion, its fine matter an anti-sustenance that made us sick and afraid. The truth bomb came in various forms: in the form of a girl (Greta Thunberg) whose eloquent rage finally caught the world’s attention and inspired millions around the globe to strike for climate action. The truth also came in the form of heat, smoke and fire. Even then, some people tried to ignore it. Ernest Hemingway had this famous line from his 1929 book The Sun Also Rises, which speaks to me of where things washed up in 2019: “How did you go bankrupt?” Bill asked. “Two ways,” Mike said. “Gradually, then suddenly.” 2019 is the year of suddenly. Many of us were shaken awake from our cognitive dissonance this year as our weather patterns and climate conditions become ever more extreme. When wine turns to ash in your mouth, you can’t deny the new reality anymore. Yet some still live in a land of cognitive dissonance: the lump of coal brought to parliament; the haze over the city obscuring the flashing Christmas lights; dead bats falling from the sky because their sophisticated and highly evolved sonar systems are overheating and confused; beekeepers being traumatised and needing counselling after hearing the sounds of animals screaming as they burn to death; new types of megafires devouring entire ecosystems; the NSW premier opening a new zoo during these megafires with a commitment to “protecting wildlife”; and the prime minister disappearing without a word about the climate catastrophe – last seen boarding a business-class Jetstar flight bound for Hawaii; the Instagrammers posing on the jetty under the eye of Sauron, hoping that with the right filters, we can pretend the sky is blue. Cognitive dissonance is natural – it can make you feel safer, like the world is a more orderly, stable place than the reality, which is chaos. The end of this year makes me wonder how much during the years prior we have been engaged in unintentional acts of disassociation and dissonance. Maybe we had to, to survive the barrage of nonstop news – the dozen major scandals that emerge each week from Trump’s White House, the way that Brexit is important, boring and confusing all at once. It’s all too much so we just disassociate. It’s no wonder the hot illegal drug of 2019 – ketamine – is an anaesthetic, numbing your body and making you feel separate from your environment. People disappear, aptly, into the k-hole, the chemical equivalent of our political situation. “Like you’re watching your own life happen instead of living it,” said New York magazine, calling it “the party drug for the end of the world”. But 2019 was in many ways, for many of us, Year Zero. It was the year many of us stopped disassociating, woke up and realised the party is over."
nan
"UK banks and insurers will be forced to reveal how exposed they are to the climate crisis and how they would respond to the effects of a temperature rise of up to 4C under the Bank of England’s first climate stress tests. The Bank has put forward proposals to test the performance and health of the UK financial system for a range of climate-linked financial risks, including the failure of governments and consumers to take action. The tests are expected to uncover the extent of the financial sector’s exposure to climate risks, and gauge company responses that could cause spillover effects for the global economy. However, the Bank will not identify individual businesses through the tests and will release only aggregate results for the banking and insurance sectors. Threadneedle Street has, however, not ruled out releasing individual results in the future, and plans to use the initial reports to inform how it supervises each company. The tests, to be released for the first time in 2021, will cover the same UK banks subject to financial stress testing, including HSBC, Barclays, Standard Chartered, Royal Bank of Scotland, Santander UK, Lloyds and Nationwide. By 2021, CYBG – rebranded as Virgin Money – will also be included. About 39 insurers are expected be tested on their climate resilience. The testing will cover three scenarios, including “early policy action”, where the transition to a carbon-neutral economy is clear and decisive, resulting in the global temperature rise staying below 2C, in line with the 2015 Paris climate agreement. In a second “late policy action scenario”, global climate targets will also be met, but the transition will have been delayed by 10 years, leading to more drastic and immediate action that could cause an economic shock. In the final scenario, governments fail to introduce policies to address the climate emergency, and companies and consumers do not change their behaviour. Global temperatures increase “substantially” – by about 4C – by 2080, resulting in rising sea levels and more frequent, extreme weather events such as flash floods. Drastic environmental changes around the world would damage property, infrastructure and farmland, disrupt business supply chains, and lead to mass migration and deaths, the Bank said. “This reduces asset values, results in lower profitability for companies, damages public finances and increases the cost of settling underwriting losses for insurers,” it said. Spillover effects such as lower output and productivity would compound those problems. The environmental risks of climate change are already affecting financial companies in the UK, with about 10% of domestic mortgages exposed to properties in flood-risk zones. Some British banks are also exposed to regions extremely vulnerable to climate change, such as south-east Asia. Countries along the equator are expected to be uninhabitable for much of the year due to high humidity under a 4C-rise scenario. If temperatures increase to that level, rising ocean acidity would wipe out coral reefs, shellfish and plankton, starving the oceans of oxygen and leading to a decline in sea life, environmental experts have warned. Saharan deserts are expected to expand into southern and central Europe, while the vast majority of the global population would have to migrate to northern regions, where farming would be viable. According to a study by Solomon Hsiang and Edward Miguel of University of California, Berkeley, and Marshall Burke of Stanford University, unmitigated global warming would lead to a 23% loss in per capita earning globally by the end of the century. The Bank’s proposals will go out for consultation until March and it is requesting feedback from financial companies, climate scientists, economists and other industry experts. The Bank’s governor, Mark Carney, said the tests were a “pioneering exercise, which builds on the considerable progress in addressing climate-related risks that has already been made by firms, central banks and regulators. Climate change will affect the value of virtually every financial asset.” He added that the tests would “help ensure the core of our financial system is resilient to those changes”. Carney is taking on the role of UN special envoy for climate action and finance after he steps down from the Bank next month. His main focus will be on mobilising private finance to invest in schemes that will help achieve the Paris goal of limiting global temperature rises to 1.5C."
"
Share this...FacebookTwitterTranslated/edited from wobleibtdieerderwaermung.de. 
A huge hole in the magnetically hot corona of the sun in the coming weeks will lead to a powerful solar wind and initiate hefty polar lights in the earth’s magnetic field. This will be a brief pause in the solar activity slumber that has taken hold over the past year and thus allowed cosmic rays to penetrate almost freely into the earth’s atmosphere.
NASA writes: BIG CORONAL HOLE TURNS TOWARDS EARTH!

“Coronal holes are places–big places–where the sun’s magnetic field opens up and allows solar wind to escape,” NASA writes. “A wide stream of solar wind flowing from this coronal hole is expected to reach our planet on March 23rd. The impact of the solar wind should produce magnetic activity around Earth’s poles and could spark the first auroras of northern spring.“  Source NASA.
In the HMI magnetogram the coronal hole today appears as a large dark spot on the left side (east side) of the sun and over the coming days as the sun rotates (Bartel’s Rotation) will be aimed at the earth, see the following image:

HMI magnetogram from March 17, 2017 shows a large dark hole with little magnetic activity on the sun’s surface (CH/Coronal Hole). As the sun rotates the coronal hole will be aimed at the earth and a large solar wind of electrically charged solar plasma will strike our planet. Source: sohowww.nascom.nasa.gov/sunspots/
Even though there have not been any solar sunspot activity in 2 weeks, meaning galactic cosmic rays (GCRs) have been easily reaching into the earth’s atmosphere. Now these galactic cosmic rays will be deflected away temporarily from the earth by the expected powerful solar winds.

The SILSO chart from March 17, 2017 above shows the daily solar sunspot count over the past 30 days. In early March there was a plummet from 55 to zero on March 4 and March 6-17. The month’s average (blue line) has fallen below SN 10. Source: sidc.oma.be/silso/home
Whether this results in a so-called Forbush event, where a strong fall in high energy cosmic rays such as the sort of a solar eruption, coronal mass ejection(CME), remains to be seen.
The impacts can be monitored daily using the Finnish University’s OULU which measures galactic cosmic rays (GCR).


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Because of the unusually weak solar sunspot beginning in 2016, GCR intensity has increased significantly:

The above Oulu plot shows the daily strength of galactic cosmic rays (GCR) as a percent of mean value from January 2015 until March 17, 2017, top right. Due to the increasingly weaker solar sunspot activity galactic cosmic rays has increased significantly since 2015. The temporary large drop in June 2015 was caused by a so-called Forbush event, where powerful solar winds shielded the earth from cosmic rays. Source: cosmicrays.oulu.fi/
Wikipedia describes “Coronal Holes“:
Coronal holes are areas where the Sun’s corona is colder, hence darker, and has lower-density plasma than average because there is lower energy and gas levels. Coronal holes are part of the Sun’s corona and are constantly changing and reshaping because the corona is not uniform. The Sun contains magnetic fields that arch away from areas in the corona that are very thin due to the lower levels of energy and gas,[1] which cause coronal holes to appear when they do not fall back. Thus, solar particles escape at a rate great enough to create a lower density and lower temperature in that area.”

In the areas designated by A, the magnetic flied lines are closed and trap the plasma of the corona. In the area designated B (coronal hole) the magnetic flied lines extend out into space and plasma can escape.“ Source: Coronal Hole, Sebman81, CC BY-SA 3.0.
The shielding of the earth against cloud-initiating cosmic rays during the solar winds coming from the coronal hole will however be only temporary. Recall that CERN measured that cosmic rays enhances cloud formation by to 100 times.
The solar minimum of 2019/20 will bring extra cosmic rays, pink auroras, and much more.

“Dec. 26, 2016: Christmas Day 2016 brought a fantastic display of auroras to the Arctic Circle. A great many of them were pink. James Helmericks sends this picture from the Colville River Delta in northern Alaska.“ Source: pink auroras.
We will continue to watch how long the sun continues its sunspot strike, excluding coronal holes, as was the case in February 2017: Eastern Limb of Sun Feb 18th and 19th 2017 – YouTube.
Yours, Schneefan2015
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSoftware engineering expert Tony Heller has put out a video blasting recent claims made in report by U.S. government officials.
In the video below Heller, who also operates the influential Real Climate Science site here, says that there is an “extremely high probability of fraud by government climate scientists” regarding the recently “exclusively obtained” report written by scientists from 13 U.S. government agencies. Heller in fact says:
The level of fraud in this report is really quite sickening.”

Heller says some of the details in the report are “wildly fraudulent” and claims “the amount of misinformation in this report is overwhelming.” 
Heller demonstrates how the report’s authors manipulated their conclusions through the careful selection of dataset start dates, depending on what they were trying to show. 
The expert software engineer and data analyst shows how heat records in fact have been decreasing over the past 100 years in the USA – contradicting U.S. government scientists’ claims. In fact extreme heat and extreme cold overall have been declining since the 1930s, as the following chart shows:

U.S. cold and heat extremes have been declining. Image cropped here.
As garbage as garbage science can get
Tony Heller then explains how the scientists made a huge mathematical mistake, one that is tantamount to the computer programming error of dividing by zero. That error, Heller says, horrendously distorted the chart the scientists used to show how the ratio of heat records to cold records was growing. The question that now arises is: Was this an honest mistake, or done intentionally with malicious intent to deceive the public? Heller called the results produced by the methodology “meaningless garbage“….”I don’t know how you can do science any worse than this garbage.”
U.S. hot days have been falling for 100 years


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Another false point made by the report was the claim that the number of days with 90°F temperatures and higher was going to increase in the future “with very high confidence“. Yet Heller presents a chart showing that the number of hot days has in fact been trending significantly downward over the past century:

U.S. percentage of hot days have been declining! Image cropped here.
The U.S. government report also claims that temperatures have risen by 1.0°C since 1901. But that claim too is false, as Heller shows with the following chart:

U.S. average daily temperature has been declining! Image cropped here.
The fearless Heller says of the government scientists: “Their claim is completely fraudulent. The United States is not warming. It is actually cooling.”
Heller then shows a newspaper clipping from 1989 (8:00), where the NOAA itself stated that there had not been any warming over the past 100 years. This was once again confirmed by NASA’s James Hansen in 1999. So how can it be possibly be warming just 18 years later?
Heller explains that since 1989 NASA’s James Hansen and current NASA GISS director Gavin Schmidt have put the historical data through a series of alterations in order to fabricate a warming trend.
Heller concludes that the latest, leaked government report is far from trustworthy:
Everything in this report is based on fake data, manipulated data, bad mathematics and general junk science.”
Heller suspects that the report was a purely politically motivated attempt to pressure President Donald Trump to change his position on the climate change issue.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWeather and climate analyst Schneefan here writes of “early frost” in the Arctic and how Greenland snow and ice have grown after being hit by a “snow bomb”. This contradicts the expectations of global warming alarmists.
The polar summer this year appears to have ended prematurely. The mean temperature of the central Arctic above 80°N has remained under the long-term average over the entire summer and even dipped below the freezing point about a week earlier than normal (1958-2002 mean).

Source: http://ocean.dmi.dk/arctic/meant80n.uk.ph
Massive Greenland “snow bomb”
An unusually early and massive snowfall in northwest Greenland led to a record high surface snow and ice mass budget, despite the summer melt season. In one single day, 14 August 2017, the ice and snow grew by a whopping 6 billion tonnes.
The following DMI Greenland snow and ice mass budget chart clearly shows the “snow bomb” as the blue curve spikes sharply upwards. Such a spike has never been seen for this time of the year.

The upper DMI chart above shows the daily ice growth/loss since 1 September 2016 until 14 August 2017 in billions of tonnes. The lower chart shows the accumulated surface mass balance. Source www.dmi.dk/greenland-surface-mass-budget/.
Note the latest small step upward in the lower chart, which is unusual in August because it is supposed to be the melt season. The approximately 670 billion tonnes of accumulated ice mass reached last May is new record. Note that this year is some 450 billion tonnes of ice above the level of this time in 2012 (red curve).
The weather forecast for Hall Land in northern Greenland forecasts more snow on the way, after a few days of above freezing weather.
Strong Arctic sea ice growth
The Central Arctic sea ice extent this August is considerably greater than it was over the past years.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





The Maisie plot shows the central Arctic sea ice extent, 14 August. This year has by a large margin the greatest extent in five years. Source: nsidc.org/data/masie/masie_plots
Passages still closed
So far this year both the Northwest and Northeast passage in the Arctic are only passable by ice breakers, as the chart below shows:

Source: http://ocean.dmi.dk/arctic/icethickness/thk.uk.php
Arctic ice volume (chart, upper right) currently is within the normal range of the past years.
Southern hemisphere temperature plummeting
Globally especially the southern hemisphere 2m temperature anomaly has been in a free fall, as the following chart with 1 week projection illustrates.

 Source: karstenhaustein.com/climate.php
Poles stable over past decade
Overall, the recent early cold conditions in the Arctic of course are weather, but is weather that was not expected by many. In general the Arctic has shown unanticipated stability over the past 10 years. That’s been a real surprise to a number of global warming scientists.
 
Share this...FacebookTwitter "
"We tend to assume that travel today is fundamentally different from what it was half a century ago. We have easier access to faster forms of transport, and we expect to be able to move quickly and easily whenever we wish. But a recent overview of travel behaviour in England – celebrating 50 years of data from the National Travel Survey (NTS) – shows that while some things have certainly changed, much remains the same.  According to the authors of the report, the most striking change to our travel habits is that “we are travelling further but not more often”. In other words, though the individual trips we take are longer in terms of distance, the number of times we travel has remained much the same over the past 50 years. What’s more, there has been little change in the total time spent travelling, due to faster travel speeds. And the purposes of our trips have changed only slightly: the biggest change has been an increase in the number of journeys we take to escort others.  Predictably, we’ve seen an increase in car use, as a result of their greater availability and affordability. This has been accompanied by a decrease in travel by bus and bike. None of these trends will be surprising to anyone who has thought carefully about the nature of everyday travel in Britain. But if we dig behind the survey data, some less obvious patterns and trends are revealed. Although the NTS is an unparalleled set of data, even this has its limitations. As the authors recognise, walking trips tend to be under-recorded, and it is not possible to gain fully comparable data on walking as a means of everyday travel over the full 50 years. What is clear, however, is that our feet remain one of our most important forms of transport.  In 2014, according to the survey, 22% of all trips were made on foot, and walking constituted 76% of all trips under one mile. Though we walk less than we did in the past, travel on foot remains an important means of travel – but one that tends to be neglected in both official statistics and transport planning. All too often, the needs of the pedestrian are ignored.  And while there may not be data available beyond the 50 years covered by the NTS, it is possible to gain some insights into even longer-term travel trends by using oral history and survey techniques. Research using these methods suggests that the distance and time spent travelling has remained reasonably stable over the last century, and perhaps beyond.  Historically, most trips were over short distances, and the time that people have been willing to commit to travelling has remained much the same. Obviously faster forms of transport, especially the private car, have allowed longer distances to be covered, and there are more very long journeys than in the past, but for most people, most of the time, everyday travel takes place relatively close to home. Why have travel trends remained so similar over long periods of time? Answers to this question almost certainly lie in the nature of society and human relationships: something that cannot be revealed by statistics. In essence, human societies across the ages seek to fulfil certain aspirations: to provide income, food and shelter; to be near and protect family; to socialise and to be with friends. Most of these needs and aspirations can be met close to home, and therefore shape our travel behaviour.  Certainly, as families have become more dispersed and labour mobility has increased, this has led to some people making ever longer journeys. But most of us are still able (and indeed prefer) to fulfil most of our everyday needs close to home.  One other aspect that statistics such as the NTS cannot reveal is the experience of travel. What is it like to travel today and how has this changed over time? Arguably, this is one area where there has been significant change. The advent and widespread use of the private car has meant that comfortable, convenient and private transport has become the norm for most people.  A century ago, only an elite could travel privately and in relative comfort, with most using shared space on various forms of public transport. For those who walk or cycle, the experience of travel will have changed less, though increased traffic has probably made the experience less pleasurable for many.  Half a century of the NTS reminds us of the importance of travel in our lives, and challenges assumptions that everyday mobility has changed dramatically over time. But it also shows us that, when it comes to what’s important to us, some things never change."
"
Share this...FacebookTwitterThe summit of Germany’s tallest mountain, Zugspitze, located in the Bavarian Alps near the Austrian border, is 2,962 meters high and thus well isolated from any temperature data corruption sources, such as urban sprawl.

The weather station at the “Top of Germany” has measured 3°C of cooling for the month of January over the past thirty years. Photo cropped here.
The Zugspitze’s peak find itself at an elevation where global warming theory tells us the warming would really be most noticeable. However the January data over the past 30 years tell us a very different story. Instead of warming, the atmosphere at that location above Europe has been cooling, and doing so quite impressively.
Josef Kowatsch, a self proclaimed “active environmentalist and independent researcher” has crunched the data for January from Germany’s DWD National Weather Service himself and found the following for the Zugspitze station:
 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





January mean temperature at the summit of the Zugspitze over the past 30 years has plummeted over 3°C. Chart: Josef Kowatsch.
He comments that our supposedly independent media — the DPA and the AFP — have maintained that “winter has been continuously warming. But this is how the warming looks at the Zugspitze.”
Another interesting aspect about the Zugspitze is the movement of its Höllentalferner glacier. According to Wikipedia here, “the Höllentalferner reached its greatest around 1820 with an area of 47 hectares. Thereafter its area reduced continually until the period between 1950 and 1981 when it grew again, by 3.1 hectares to 30.2 hectares. Since then the glacier has lost (as at 2006) an area of 5.5 hectares and now has an area of 24.7 hectares.”
That means the glacier GREW during the 1950 to 1981 period – fully in line with the global cooling period of the 20th century, which NASA has recently been trying to fudge out. Also it tells us the retreat began well before the start of the industrial revolution, and thus natural factors are more at play.
 
Share this...FacebookTwitter "
"When the French entrepreneur Jacques Mouflier visited the remote Alpine village of Val d’Isère in 1935, he saw the future before him. “A miracle is going to happen,” Mouflier told his young son, as he gestured towards the mountains encircling the village. “Ski champions from every country will come to compete where we’re standing right now.” He was right. In 1948 Val d’Isère produced France’s first Olympic ski champion, and ever since, professional athletes have flocked to the village, which sits 1,850 metres above sea level, to train and compete. They are joined by tens of thousands of amateurs. Last year the resort sold 1.3m ski “days” to tourists, and more Britons visit Val d’Isère each year than any other ski resort in the world.  For a long time, the source of Val d’Isère’s enduring attraction – aside from its almost oppressively picturesque surroundings, five-star hotels and 300km of pistes, each one as groomed as a Surrey garden – has been that it is, in the parlance of the skiing industry, “snow certain”. Year in and year out, the arrival of the first snowfall, in mid-November, was as reliable as a Swiss watch. In 1955, when the resort began hosting an annual ski competition called the Critérium de la Première Neige (“the competition of the first snow”), its organisers boasted that Val d’Isère was the only French resort able to guarantee snow throughout December. Villagers claim to be able to predict the year’s coming snowfall by the berries on the local rowan trees. Plump clumps in summer promise deep snow in winter. For decades, the branches drooped under the berries’ weight. But in the mid-1980s, locals began to notice a change. The date of the first snowfall began to drift later. Patches of bare ground appeared on slopes that, in previous years, had been covered in an uninterrupted white drift. Some ski seasons would have an abundance of snow; others, a scarcity. More consistent was the retreat of the Pissaillas glacier, whose run-off water feeds the surrounding forests; each year it withdrew a little farther up the Pointe du Montet mountain, which dominates the jagged horizon. By 2014, snow was arriving so late to Val d’Isère that, for the first time in its history, the Critérium de la Première Neige was relocated, to a more snow-reliable resort in Sweden. For reasons scientists don’t fully understand, the Alps are warming faster than the global average. The 1.4C rise in the average global temperature since the end of the 19th century has translated into a 2C rise in the Alps. In the past hundred years, the number of hours that sunshine hits the mountains each year has increased by 20%. The heat and light cause snow to melt, or not to fall at all. In 2017 the Swiss Federal Institute for Snow and Avalanche Research recorded that less snow fell in the Alps during the winter months than in any year since 1874. In April a report by the European Geosciences Union showed that 90% of glacier volume in the Alps – an essential source of drinking water, crop irrigation and ski runs – could be lost by the end of this century. For the Alpine ski industry, which hosts 35% of the world’s ski resorts across eight countries, and serves an estimated 120 million tourists each year, this is potentially an extinction-level event. Val d’Isère is one of the mountain range’s highest resorts, so it will be one of the last to feel the full effects of the climate catastrophe. But farther down the mountains, the disappearance of snow has already begun to devastate the ski industry, as well as the communities that rely on it. Since 1960, the average snow season has shortened by 38 days, while “seasonal drift” has pushed the coldest weather from December to the early months of the year, throwing the ski season out of sync with the lucrative Christmas holidays. In November 2017 the EU launched the Prosnow project, whereby scientists advise Alpine resorts on how to “maintain the same season duration with 30% less snow”. Such efforts have not been entirely successful. According to some reports, as many as 200 ski resorts now stand abandoned across the Alps, where bankrupt hotels have been left unoccupied, and forsaken ski lifts dangle in the wind. The disaster encroaching on Val d’Isère has been obvious to Olivier Simonin, the director of tourism at the resort, since the infamous 2006-7 season, when a scarcity of snow caused a 7% decline in revenues across Alpine resorts. This September, for the first time, the French ski industry’s main union, Domaines Skiables de France, held an emergency meeting of directors from France’s most important resorts to discuss the existential challenges they face. Twenty-five directors attended the meeting, which was held in the valley of Chambéry. The mood, according to Simonin, was sombre. “This is now the main topic of conversation among us,” said Simonin. “Nobody wants to die.” Unlike the islanders of Kiribati, whose homes will be swallowed by the Pacific Ocean in the coming years, or the farmers of rural Bangladesh, whose crops fail whenever their fields are flooded by saltwater, the Alpine ski industry, which turns over billions of euros every year, is disproportionately well-equipped to fight for its survival. And resorts like Val d’Isère have invested tens of millions of euros in the most straightforward solution imaginable: when the snow stops falling, it’s time to make your own. “You need four things to make snow,” Pierre Mattis told me in September as we toured the control centre of the snow-making operation he runs in Val d’Isère. “Water, air, cold and talent.” One morning in 1995, Mattis, who was then a 28-year-old ski-lift engineer, was told he was being redeployed to look after the resort’s handful of snow machines. Four years later, he began building his snow-making factory, or atelier neige, installing a 70km network of pipes beneath the mountain that now, after years of expansion and improvement, can cover 65 sq km of slopes in artificial snow at the touch of a button. It is one of the most sophisticated snow-making operations in the world. The first snow-making machines in Europe appeared in Italy in the early 1980s, just before the locals in Val d’Isère began to notice the seasons shifting. (In 1963 snow-making equipment was installed at Mar Lodge in Scotland, but the project was abandoned after two seasons as the water kept freezing.) As winters with unreliable snow became more common in the Alps, so did the machines. Most were based on a design by a Pennsylvanian man named Herman K Dupré, who in 1968 had fitted a water sprinkler to an air compressor system he bought at a scrapyard. Dupré pumped the air and water at high pressure through a lance-like nozzle to create a fine spray that, at sufficiently low temperatures, turned to snow before it hit the ground. The HKD snowmaking system, as Dupré named his invention, became the industry standard. The first one arrived in Val d’Isère not long before the snow-scarce winter of 1986. Warm winters had occurred before the mid-1980s, Robert Steiger, an economist and tourism researcher at the University of Innsbruck, told me, “but at that time Alpine communities had not been so dependent on ski tourism.” Today, 95% of Italian, 70% of Austrian, 65% of French and half of Swiss ski resorts are reliant on snow machines for their continued survival, according to estimates from Claus Dangel, CEO of Bächler, a snow-machine maker that supplies more than 200 resorts across the Alps. It takes an awful lot of technology, water and energy to manufacture the amount of snow that might have naturally blanketed the Alps two or three generations ago. Mattis’s control centre in Val d’Isère is housed in a cavern chiselled into the mountainside, like the bunker of a Bond villain. It is large enough to house some 40 double-decker buses, and home to six 10ft tall pumps, water filters, and a phalanx of computer screens – all maintained by Mattis’s 12-member “snow team”. Using software developed in-house, the team controls a vast network of snow machines via a bank of 10 computers. Like the timer on a boiler, the software allows the team to set “on” and “off” periods for the snow machines, ensuring a consistent covering of snow throughout the season. Forecasts fed into the bunker from weather stations on the mountains help the team to adjust their schedules. During the ski season, three people monitor the system throughout the night, like security guards watching over a bank vault. They check the correct positions of the cannons in relation to the prevailing wind, watch the quality of snow, and ensure that the pump rooms are working satisfactorily. If a patch of ground appears in the melting snow, they can cover it before sunrise. The snow is shot on to the mountains at a speed of 250km/h via 650 snow cannons. Ten years ago the cannons could be spaced 80 metres apart from one another and still create an unbroken blanket of snow, but climate change has since forced Mattis to cut that distance in half. The system has to be continually upgraded to keep pace with the effects of climate change. The current iteration was completed in 2014 at a cost of €2m, and can produce 8,000 cubic metres of snow per hour – eight times the capacity of five years ago. The plant is one of the largest in the Alps, and differs from most of its rivals in that all of the equipment (bar HKD’s nozzles, which are imported from Quebec) was designed in-house. Mattis claims his system is unique as it allows the team to control the density of the snow on a sliding 10-point scale, enabling him to create a more compact, “faster” snow, ideal for professional competitions. This technology comes at a major financial and ecological cost. Today, one in every 20 euros spent anywhere in Val d’Isère goes into the snow factory, covering energy costs, staffing, maintenance and upgrades (a hidden “artificial snow” tax that is continually increasing). Although snow machines are becoming increasingly efficient, a typical snowmaker still uses about the same amount of energy as a boiler in a family home. When multiplied into the tens of thousands across the Alps, snowmakers become something of a self-defeating invention: they worsen and sustain the climate problems they’re supposed to solve. And yet, for life in the Alps as we’ve come to know it, they remain essential. Steiger’s most recent simulations suggest that unless every ski resort in the Alps installs state-of-the-art snowmaking facilities like the ones Mattis operates at Val d’Isère, by the 2050s up to half will no longer be able to sustain their businesses. Only the wealthiest resorts, like Val d’Isère – where chalets can sell for more than €23,000 per sq metre, five times the average cost of property in London’s most expensive borough, Kensington and Chelsea – are able to make the necessary investments to continually update and retool their snow-making facilities. Less-moneyed resorts rely on a cheaper source – snow farming, whereby snow is gathered or made in January and February, when manufacturing snow costs less than in warmer months. The snow is then placed under a 40cm layer of wood chippings, which absorb and release moisture and keep the snow cool, compact and manageable during the summer months. The wood chippings are then removed at the end of October, allowing the snow to be deployed on the slopes in time for the skiing season. Artificial snow, be it farmed or sprayed, is not only the would-be saviour of the ski industry, however. This is a region where, as the International Commission for the Protection of the Alps, Cipra, puts it, “there is an urgent need for innovative ideas and solutions”. One Dutch professor believes artificial snow may also hold the key to saving glaciers, in the Alps and beyond – along with the communities that rely on them for their food and water. On the morning of 11 July 2000, after a night of unexpectedly heavy summer snow, Hans Oerlemans went to check his weather station on the Morteratsch glacier, near the village of Pontresina, Switzerland, 400km north-east of Val d’Isère. The Morteratsch is one of the largest glaciers in the Alps, and a popular attraction for sightseers and thrill-seekers, many of whom come to ski along its 6km back. Since 1860, though, the glacier has shrunk by 2.5km – an average of nearly 16 metres per year. Oerlemans believes lessons learned by studying the Morteratsch can aid anyone interested in saving snow and ice across the Alps. A Dutchman who grew up in Utrecht, Oerlemans is tall and handsome, and wears the thin-rimmed glasses of a Hollywood therapist (studiously removing them for photographs). He has been studying glaciers since 1980, when he earned his PhD from Utrecht University, where he is an emeritus professor. His weather station on the Morteratsch, which he personally built in 1995, was one of the first in the world designed to measure the effects of climate change on glaciers. By monitoring the Morteratsch’s vital signs – fluctuations in the depth and temperature of its ice, as well as the ambient humidity – he hoped to solve a number of basic, yet unanswered, questions. “If the climate becomes one degree warmer,” he told me recently, “what happens close to the surface of a glacier: do you have 1 metre more of ice melt, or 10cm, or 10 metres? Nobody knew.” When Oerlemans crested the mountain that overlooks the Morteratsch that July morning two decades ago, he expected to see the glacier in its state of typical summer resplendence – a great frozen river, flowing in imperceptible slow-mo down the mountain. Instead, he saw nothing but snow, covering the glacier in a half-metre-deep drift. In the weeks that followed, he noticed something even more surprising in the weather station readings: the glacier’s thaw had halted almost entirely. Two processes melt ice: the transfer of heat from warm air, and solar radiation from the sun. Oerlemans’s readings suggested that the latter had a much greater effect than scientists previously understood. The covering of snow from the unseasonable summer storm had apparently acted as a reflective shield, fending off enough solar radiation that it was equivalent to dropping the air temperature by a full degree. He wrote up his findings in a paper published in 2004 by the International Glaciological Society. Then, for a while, he put what happened to the back of his mind. This autumn, as Oerlemans and I took a bobbing cable car up to a viewing station overlooking the glacier and mountain-top restaurant – home to “probably the most expensive plate of spaghetti in Europe,” he said – he explained what happened next. About five years after his paper was published, the villagers in Pontresina learned about an experiment in which polyester fleece has been used to cover snow to preserve it during warm weather. They laid the fleece on to the glacier in two-metre wide strips, like a blanket shorn from a massive sheep. “They put it out in the middle of May, and covered the ice till September,” he said. Not only did the fleece blanket stall the effects of melting, it actually reversed them: measurements showed that, over the course of the summer, ice in some of the areas under the fleece grew in thickness by up to two metres. When news of this ice reversal reached Oerlemans, he immediately thought of the weather station reports following the heavy snow drift in July 2000. If it were possible to cover a glacier in a protective barrier during the spring and summer months, might this counteract a century of decline? “The scale is totally different,” Oerlemans recalled. “You could not use fleece on a glacier the size of the Morteratsch, which moves, because it will be destroyed quickly. But, I thought: it might just be possible to use artificial snow.” To test the theory, in the summer of 2017 Oerlemans and his team sprayed a 2.5 metre-deep blanket of artificial snow over a small section of the Diavolezzafirn glacier, one of the Morteratsch’s diminutive neighbours. The experiment, which ran to the autumn, was successful: further melting was prevented, and in some places the ice even grew. With positive results in hand, Oerlemans and his collaborators began to consider the much greater challenge of how to blast a sufficient amount of artificial snow over the much larger expanse of the Morteratsch. Snow cannons such as those installed in Val d’Isère could not be placed on to the glacier, as they would be caught in the slow-moving current of the ice and torn from their pipes. Instead, Oerlemans and his colleague Felix Keller considered using a cable car equipped with a snow machine to travel above the glacier, dropping artificial snow as it went. (Oerlemans and Keller’s partnership is not short on creative thinking – the pair also play in a two-piece tango band called Tango Glaciar and often splice musical performances into their lectures on glacial retreat; once they even performed on a glacier, which one onlooker drolly likened to the musicians on the Titanic stubbornly playing while the ship sank.) This idea stalled when it came to supplying a moving cable car with the necessary water to make the snow. Finally, in a eureka moment, the team settled on an ingenious invention: a “snow rope”, stretched in a zigzag pattern across the width of the glacier, hundreds of feet across. Acting like a sprinkler system, the rope could deposit snow from altitude while the glacier trundled conveyor belt-like beneath it. After two years of preparatory studies, finding willing engineering partners and filing patents, on 1 October 2019 Oerleman received a 2m Swiss franc grant from the Swiss Innovation Agency to begin work on his extravagant snow blanket scheme. “We have passed the point of no return,” Oerlemans told me. “It’s no longer just theory; it’s happening.” On a warm morning this past summer, I hiked with Hans Oerlemans along a dirt path from the village of Pontresina up to the Morteratsch glacier. Perhaps to convince sceptical visitors of the scale of the Morteratsch’s retreat, the village council had erected 2.5 metre-tall markers along the path to show how far downhill the tip of the glacier stretched in certain years. With an accumulating sense of dread, we walked from the marker for 1865, which sits close to a car park at the base of the mountain, and past the ones for 1940, 1960, 1980. The farther we walked, the farther away the next marker was – the glacier’s retreat was accelerating over the decades. The effect was like trekking along a countdown to the oblivion of the glacier, or perhaps even our own. Along the steep-sided valley carved out by the glacier over millennia, the cliff walls most recently vacated by the shrinking floe are packed with “dead ice”, a dark grey substance that looks like granite. Dead ice poses a major threat to sightseers because it can cause massive rock falls; last summer a boy ignored a set of warning signs and wandered less than 50 metres from the main tourist path. He was crushed to death by a falling boulder. The villagers of Pontresina are distressed by the likely effects of the erosion of the ice on the village’s tourist economy, Oerlemans told me. But not everyone is convinced that his snow-blanket scheme is the best use of 2m francs. “I am sceptical of the entire project,” an employee from the local council said. “It’s such a huge amount of money, and it’s not clear what effect it will have.” Even if the scheme meets expectations, there is a sense that the funding behind the glacier-saving technology has essentially been awarded to prop up the skiing industry, the recreational embodiment of extreme privilege – just like the artificial snow operation in Val d’Isère. Oerlemans and his team argue, however, that if the wealthy ski resorts of the Alps can facilitate the development of these technologies, they will have a knock-on effect in the coming years, enabling poorer communities around the world to benefit from these advances. The professors’ snow rope system may provide a solution, ensuring the survival, not only of expensive tourist resorts, but also farming communities, such as those in India and Tibet, whose crops are reliant on glacial water. “There are 230,000 glaciers in the world, and it’s unthinkable that you could use our technique on a scale that would, for instance, stop glaciers from contributing to sea-level rise,” says Oerlemans. “But at a local level it could prove invaluable for local economies that depend on melt water from glaciers for their survival.” That technologies developed for the rich will one day help the poor is a familiar refrain among tech idealists – and a dubious one. “Assuming that western technologies can be easily implemented in developing countries is a bit naive,” said Robert Steiger, from the University of Innsbruck. “Poor regions in poor countries lack the institutional background that is required to implement new technologies and, even more importantly, to provide the knowledge and money to maintain this technology.” Besides, Claus Dangel, the CEO of the snow machine company Bächler, which is currently developing Oerlemans’ snow sprinkler, estimates that the company needs an additional 3.5m Swiss francs to fully develop the system – far more investment than is provided by the Swiss Innovation Agency grant. Dangel’s hope is to make the system as low-energy as possible, perhaps by using gravity to feed the sprinkler system from lakes high in the mountains, above the snow rope. “We want it to work without using energy,” he told me. “But this is very complicated because you need high water pressure, and the system will probably need to be heated in one way or another, to prevent it from freezing.” In the long term, it seems unlikely that artificial snow will save even the wealthy Alpine ski industry. Resorts are beginning to consider how they might make more fundamental changes to their businesses in order to adapt to, rather than stave off, the effects of the climate crisis. For many resorts, this means reorienting themselves around non-skiing activities: hiking, mountain bike-riding, nature-watching, sightseeing. “We can see what is coming for us,” said Olivier Simonin, the director of the resort at Val d’Isère. “There will need to be a complete change.” By 2050 Simonin hopes that 30% of the resort’s income will be derived from activities other than skiing. The number of tourists visiting the Alps during the summer is already increasing year on year, according to the World Wide Fund for Nature. Changes in climate are being matched by changes in what visitors, especially millennials, are looking for. But hiking and other summer activities are less profitable than skiing, so although tourism may endure, the stratospheric revenues of the heavy snow decades may not. “We may have a bit more time compared to others but, then again, we are a big resort,” Simonin said of Val d’Isère. “We have a greater economic challenge in order to maintain our current levels of profit.” For a few moments Simonin held his head in his hands. “It will require solidarity between the villagers, the resorts, the hotels,” he said, finally. “But people who live in the mountains are hardy. We are used to having to adapt.” Perhaps, he wondered, with a note of surprise at what appeared to be a fresh afterthought, whether in 50 years, people might come to Val d’Isère, not to ski but simply to see snow – human-made or otherwise – precisely because of its scarcity. With a dry laugh, he added, “Maybe the mere sight of snow will become a privilege.” • This article was amended on 20 December 2019. Owing to a unit conversion error, an earlier version stated that property prices in Val d’Isère were 20 times higher than in Kensington in London. It has been corrected to five times. A reference to an early snow-making programme in Scotland has also been added. • Follow the Long Read on Twitter at @gdnlongread, or sign up to the long read weekly email here."
"
Share this...FacebookTwitterAre Modern Rates Of Sea Level Rise 
Too Slow For Optimal Coral Growth?

Since the 20th century began, global sea levels have been rising at rates of about 1.7 – 1.8 mm/year, or about 0.17 to 0.18 of a meter (~7  inches) per century.

NOAA 


Zerbini et al., 2017
“Our estimated rates for the northern Mediterranean, a relatively small regional sea, are slightly lower than the global mean rate, + 1.7 ± 0.2 mm/year, recently published in the IPCC AR5 (Intergovernmental Panel on Climate Change 5th Assessment Report) … Our regional results, however, are in close agreement with the global mean rate, + 1.2 mm/year, published by Hay et al. (2015) which is currently being discussed by the oceanographic community.”

Svendsen et al., 2016
“From our reconstruction, we found that the Arctic mean sea level trend is around 1.5 mm +/- 0.3 mm/y for the period 1950 to 2010, between 68ºN and 82ºN. This value is in good agreement with the global mean trend of 1.8 +/- 0.3 mm/y over the same period as found by Church and White (2004).”

Parekh et al., 2017
“Sea level change in the Indian Ocean is about 1.5 mm/year in the past sixty years or so, whereas the global sea level trends are a bit higher [1.7 mm/year].”

McAneney et al., 2017
“Global averaged sea-level rise is estimated at about 1.7 ± 0.2 mm year−1 (Rhein et al. 2013), however, this global average rise ignores any local land movements. Church et al. (2006) and J. A. Church (2016; personal communication) suggest a long-term average rate of relative (ocean relative to land) sea-level rise of ∼1.3 mm year.”

Wenzel and Schröter, 2014
“Global mean sea level change since 1900 is found to be 1.77 ± 0.38 mm year on average. …   [T]he acceleration found for the global mean, +0.0042  ±  0.0092 mm year, is not significant“

In contrast, during the middle Holocene, sea levels rose at rates of 9.6 mm/yr (0.96 of a meter per century) during the 350 years between 6,850 to 6,500 years ago (Meltzner et al., 2017), and relative sea levels (RSL) were about 1 to 2 meters higher than present during that time.  During the Early Holocene (~12,000 to 8,000 years ago), sea levels rose at rates of about 0.74 of a meter to to almost 1.1 meter per century (7.4 mm/yr to 10.9 mm/yr), which is about 5 to 6 times the modern rate (Khan et al., 2017).
Corals, thought to be biologically fragile and highly susceptible to abrupt sea level changes and high sea temperatures…survived these much higher rates of sea level rise from the geological past.
Scientists have apparently found that coral communities do not grow as well, but instead they “shut down” — even reaching very high mortality rates (85%) — when sea levels fall rapidly.  Falling sea levels (and cooling) are suggested to be more lethal to corals than high-temperature bleaching events during El Niño years or rising sea levels (Eghbert et al., 2017).
These findings would not appear to support the current perspective that modern coral communities are threatened by “global” warming and rapidly rising sea levels.

Recent Rapid Sea Level Fall Induced Higher Coral Mortality Than Bleaching

Eghbert et al., 2017
“In September 2015, altimetry data show that sea level was at its lowest in the past 12 years [Indonesia], affecting corals living in the bathymetric range exposed to unusual emersion. In March 2016, Bunaken Island (North Sulawesi) displayed up to 85% mortality on reef flats dominated by Porites, Heliopora and Goniastrea corals with differential mortality rates by coral genus.”
“[R]apid sea level fall could be more important in the dynamics and resilience of Indonesian reef flat communities than previously thought. This study reports coral mortality in Indonesia after an El Niño-induced sea level fall. The fact that sea level fall, or extremely low tides, induces coral mortality is not new, but this study demonstrates that through rapid sea level fall, the 2015–2016 El Niño has impacted Indonesian shallow coral reefs well before high sea surface temperature could trigger any coral bleaching. Sea level fall appears as a major mortality factor for Bunaken Island in North Sulawesi, and altimetry suggests similar impact throughout Indonesia.”

Reefs ‘Turn Off’ (Stop Growing) When Sea Levels Fall And Seas Cool

Dechnik et al., 2017
“[I]t is generally accepted that relative sea level reached a maximum of 1–1.5 m above present mean sea level (pmsl) by ~7 ka [7,000 years ago] (Lewis et al., 2013).”
“Over the last few decades, the global decline of modern reefs has been linked to environmental and climatic changes in response to anthropogenic activities.  However, recent geological and ecological research on fossil reefs in the Great Barrier Reef (GBR) and wider Indo-Pacific identified intervals of significant reef ‘turn-off’ in response to natural environmental forces earlier in their development during the mid- to late Holocene.”
“Increased upwelling, turbidity and cyclone activity in response to increased sea-surface temperature (SST’s), precipitation and El-Nino Southern Oscillation variability have been ruled out as possible mechanisms of reef turn-off for the mid-outer platform reefs. Rather, a fall (~0.5 m) in relative sea level at 4–3.5 ka is the most likely explanation for why reefs in the northern and southern regions turned off during this time.”
“Similar hiatuses in Holocene reef growth were identified in Japan from about 5.9 to 5.8 ka, 4.4 to 4.0 ka and from 3.3 to 3.2 ka. They were attributed to oscillating sea level and relatively cold sea-surface temperatures.”
 


Corals Survived Sea Level Rise Of 6 – 13 mm/yr During Middle Holocene – But ‘Killed’ When Sea Levels Fell Rapidly

Meltzner et al., 2017
“Half-metre sea-level fluctuations on centennial timescales from mid-Holocene corals of Southeast Asia … RSL [relative sea level]  history between 6850 and 6500 cal years BP that includes two 0.6 m fluctuations, with rates of RSL change reaching 13±4 mm per year.”
“Here RSL rose to an initial peak of +1.9 m [above present] at 6,720 cal years BP, then fell rapidly to a lowstand of +1.3 m, remaining at about that level for ∼100 years, before rising to a second peak at +1.7 m shortly after 6,550 cal years BP.  Around 6,480 cal years BP, RSL appears to have fallen again to +1.3 m before rising to a third peak at +1.6 m or higher. … The peak rate of RSL rise, averaged over a 20-year running time window over the period of study (∼6,850–6,500 cal years BP), is +9.6±4.2 mm per year (2σ); the peak rate of RSL fall is −12.6±4.2 mm per year.”
“The central dome of each microatoll grew during a period when RSL was high; RSL then fell rapidly, killing the upper portions of the corals; RSL then stabilized at a lower elevation, forming a series of low concentric annuli ∼0.6 m higher than present-day analogues; RSL [relative sea level] then rose ∼0.6 m in less than a century, allowing the coral to grow upward to 1.2 m higher than modern living corals.”

During The Early Holocene, Sea Levels Rose At Rates 5 – 6 Times Higher Than Today

Khan et al., 2017
“Only Suriname and Guyana [Caribbean] exhibited higher RSL [relative sea level] than present (82% probability), reaching a maximum height of ∼1 m [above present] at 5.2 ka [5,200 years ago].”
“Because of meltwater input, the rates of RSL change were highest during the early Holocene, with a maximum of 10.9 ± 0.6 m/ka [1.09 meters per century] in Suriname and Guyana and minimum of 7.4 ± 0.7 m/ka [0.74 meters per century] in south Florida from 12 to 8 ka [12,000 to 8,000 years ago].”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe online Berliner Morgenpost here reports that electric cars in Germany are going to lead to even higher electricity prices for the country’s already massively burdened consumers. Hat-tip Gerti B.

NAEB power price projections for 2020. Note that the horizontal scale changes at the year 2010 in order to condense the chart. The upper curve shows German electricity prices in euro-cents per kilowatt-hour, the middle curve shows the price for France and the lower curve for the USA. Source: NAEB.
The original plan was to put one million electric cars on the streets by 2020, but so far the country is nowhere near being on that trajectory, and very likely will fall very far short of the target. So far only 34,000 of Germany’s 45 million vehicles are electric. The plan for 2030 calls for 5 million vehicles!
What would cause electricity rates to climb if more electric cars come on the market? Citing the Bundesnetzagentur, the Morgenpost writes:
The power grid needs to be expanded for a million electric cars. Consumers will feel it through surcharges imposed on the price of electricity.”
Germany’s infrastructure for electric cars continues to be extremely limited and patchy, thus making electric cars impractical in most situations and areas.
A massive investment is necessary just to expand the charging station network in order to overcome the huge charging infrastructure obstacle — never mind the limited range of electric cars, long charging times, high life-cycle costs and environmental impact.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Morgenpost also cites Germany’s National Platform for Electro-Mobility in stating: “for 1 million e-cars by 2020, about 70,000 charging locations and 7100 rapid charging stations are needed” and that currently “only about one tenth of that exists“.
According to experts, writes the Morgenpost, just the grid expansion (without charging stations) is estimated to cost 30 billion euros over the coming years. That figure may be enormously conservative, as recent German infrastructure projects have shown.
Another problem is that despite hundreds of billions in investment, Germany’s power grid is still nowhere near being green, and is still heavily reliant of coal and fossil fuels. Charging cars with electricity that is produced mostly by fossil fuel does nothing for reaching the greenhouse gas reduction targets. It could in fact be counter-productive.
Germany’s Energiewende (transition to renewable energies) is a classic case of a mad, activistic rush into something without first thinking it through.
They can’t even build an airport
Transitioning an entire economy to renewable energies is a worthy target, of course, if allowed the appropriate amount of time (some generations) to do so. But it is absolutely insane for a country to believe it can accomplish this in a decade or two, especially in light of the fact that it cannot even handle the construction of an airport in the same timeframe. Yes, these are the very same people who claim Trump is unfit to be president.
In a nutshell: These bozos can’t even build a simple airport, and so how can they be trusted to rebuild the nation’s entire energy supply system?
So far they are proving that they can’t, and that the Energiewende may very well turn out to be the Berlin Airport times 1000, or worse!
 
Share this...FacebookTwitter "
"The Intergovernmental Panel on Climate Change (the IPCC) published its first major report 28 years ago. This watershed document described the ominous implications of escalating emissions and the scale of the challenge in reversing this seemingly inexorable trend.  Today, despite four further IPCC reports, 23 rounds of international negotiations, and thousands of climate change papers and conferences, annual emissions are more than 60% higher than in 1990, and are still rising. Put simply, the international community has presided over a quarter of a century of abject failure to deliver any meaningful reduction in absolute global emissions. Certainly the rhetoric of action is ramping up. Yet those who talk confidently about renewables, nuclear and “carbon capture and storage” (CCS) eventually driving down emissions in decades to come are guilty of misunderstanding the fundamental science of climate change.  We face a “cumulative problem”, with rising temperatures relating to the build up of carbon dioxide in the atmosphere. Based on this, the Paris 1.5°C and 2°C commitments demand total emissions remain within a small and rapidly dwindling “carbon budget”. Time is truly of the essence. Less than 12 years of current emissions will see our 1.5°C aspiration go the way of the dodo, with the 2°C carbon budget exceeded by the mid 2030s.  Paris defines a timeframe and scale of mobilisation reminiscent of major wars, yet our collective response remains much more akin to the apocryphal tale of a gently warming frog. Continuing with today’s ineffective “mitigation”, delusion and fear will bequeath many humans and other species decades and even centuries of climatic instability. This preference for short-term hedonism (for the few) over longer-term planetary stewardship is essentially an active choice for politically expedient incrementalism over revolutionary change. The latter is a prerequisite of meeting our Paris commitments – but can such rapid change ever be more than a “romantic illusion”? The first two decades of this millennium have been marked by a series of deep upheavals, illustrating opportunities for rapid change, though not necessarily in a favourable direction. The banking crises exposed the internal failure of our precious free market model to both self-regulate and deliver on its central tenet: the “efficient allocation of scarce resources”. It also revealed how, with sufficient political will, unprecedented finances could be mobilised at the stroke of a pen. And as the bankers and economists regrouped to thwart progressive regulation, much of the power of unaccountable media barons was being seized by the amorphous twists and turns of social media. At the same time, political institutions in many parts of the world have faced serious challenges from the left, the right and “unforeseen” circumstances. Set against this, and despite an orchestrated campaign of denial, there is now common acceptance that responding to climate change requires significant government intervention. Rounding off this assemblage of upheaval, the plummeting cost of renewable energy has coincided with widespread recognition that relying on fossil fuels also has serious consequences for health and security. In themselves, each of the above disruptions has important implications for the evolution of contemporary society. But broadly aligned they could be guided towards something much more revolutionary – perhaps even a progressive and epoch-changing confluence of circumstances? Imagine a space where climate academics could be truly honest with policy makers about their analysis and conclusions, and where disagreements were discussed openly and constructively. Add to this, vociferous engagement by younger generations, listened to by a new breed of policy makers playing a straighter bat.  Imagine then an enlightened “quantitative easing” transferring resources not to banks, but to mobilise a rapid transformation in energy infrastructure, retrofitting existing buildings, decarbonising transport and constructing zero-carbon power stations. A reformist political agenda could begin to emerge, facilitating secure, local and high-quality employment, eradicating fuel poverty, improving urban air quality, driving innovation and eliminating carbon emissions. Stretch the imagination a little further to embed a democratic media reporting on this transformation to an increasingly savvy and responsive audience. Under such conditions, an alternative progressive paradigm could be ushered in – and soon. Certainly, none of this looks likely, but who predicted the near-collapse of the Western banking system, the emergence of Bernie Sanders, Donald Trump and Jeremy Corbyn, the rise and early demise of the Arab Spring, or even the plummeting price of renewables? Most political and economic pontificators, buttressed by naysayers and established elites, remain incapable of seeing beyond their familiar 20th-century horizon. But the 21st century is already proving how the future is a different country – one that could yet be shaped by alternative interpretations of prosperity, sustainability and equity."
"At least 7.3m tons of fish (usually dead or dying) are thought to be discarded each year from marine fisheries around the world. But these estimates come mostly from observations of large-scale industrial fisheries. Limited attention has been paid to small-scale fisheries, which are assumed to have low discard rates – some estimate as little as 3.7% total catch, compared to more than 60% for some large-scale shrimp trawlers.  Small-scale or artisanal fisheries – for which there is no universal definition – are generally considered more sustainable than their large-scale industrial counterparts, but there is increasing evidence that shows this is not always the case. They employ more than 99% of the world’s 51m fishers and likely account for more than half of the total global fisheries catches.  One of the biggest problems for both large and small-scale fisheries around the globe is bycatch – fish and other marine organisms caught when the fishers are targeting something else. Powerful images of turtles and dolphins caught in fishing gear have caught the sympathy of the general public, but unintentional landings of fish aren’t as evocative. The truth is, however, that fish bycatch is a big issue.  Progress is being made in Europe within large-scale fisheries thanks to campaigns such as the Fish Fight. But small-scale fisheries – though there is increasing recognition outside that they are “too big to ignore” – are only just beginning to recognise the fish bycatch and discard problem. Our newly published research has found that artisanal fisheries in Sri Lanka are throwing away more marine species than they keep. For every fishing trip in one of Sri Lanka’s largest lagoons, Puttalam Lagoon, fishermen could be throwing away more than 50 fish. What’s more, of the 62 species recorded in the survey, more than 80% were routinely discarded. The reasons for this practice are unclear but sometimes it is because the individual fish are too small – or they are species without a high market value. We found that fishers targeting shrimp in particular caught more non-target species and had higher discards than those targeting fish. This is particularly worrying at a time when Sri Lankan shrimp exports are increasing, after the EU granted the country improved access to its market. Potentially 90% of the world’s fish stocks are threatened by over-fishing – when more fish are caught than the population can replace. And the “tell-tale” signs of over-fishing are now being observed in Sri Lanka and across other research sites in the Indo-Pacific region. Fishers in these locations have told us and other researchers that they are catching much less fish than they were five years ago. But this is not just an ecological issue, it is a social one too. In this era of increasing food insecurity, our findings highlight a serious concern for Sri Lanka. This unwanted seafood could be used to provide protein for the poorest in society. Instead, we found that fish with high nutritional value is being eaten by feral dogs and birds.  Billions of people worldwide rely daily on fish for protein, while 50m people also rely on catching fish for work. But, if the levels of bycatch and discard continue, the livelihoods and food security of the people that depend on these fisheries will be under threat. If the problem is not managed, there won’t be any fish left in the waters. There is one ray of hope for Sri Lanka, however. There are some small-scale fishery cooperatives which maximise long-term community benefits by dealing with the threats of fisheries mismanagement, livelihood insecurity and poverty. Communities with successful and inclusive cooperatives are better off than those without. Cooperatives have the potential to empower small-scale fishers against environmental and socioeconomic shocks, but the problem in Puttalam Lagoon is that these cooperatives are not operating across all levels of society. If the bycatch and discards issue is going to be solved over the long-term, we need to look at combining sustainable management practices with community schemes to reduce unnecessary seafood waste all over the world. Together the millions of small-scale fishers all over the world have an immense amount of power, they just need to realise it."
"
Share this...FacebookTwitterWe have all heard about the record-breaking ice mass balance and cold temperature reading of -33°C recently set in Greenland — the Arctic island that is supposedly the canary in the climate coal mine.
It turns out that things up there are colder than we may be led to believe and that the alleged warming there is fiction.
Hat-tip: Gerti
Struggling to explain
The Swiss online Baseler Zeitung (BAZ) here reports: “In Greenland July this year has been the coldest ever. That has left climate catastrophists struggling to explain it.”
Citing the Danish Meteorological Institute, the BAZ comments that the -33°C reading earlier this month was “the coldest July temperature ever recorded in the northern hemisphere“, smashing the previous record of 30.7°C.
Expanding ice mass, media ignore
The BAZ adds that also the “ice cover has grown strongly over almost all of Greenland“.
But this has been ignored, as the Switzerland-based daily also bravely writes that “most journalists and media leaders are active or passive members of the green-socialist Climate Church and the new religion of the post-Christian western world” and acknowledge only things that fit their world narrative. This likely explains why there’s been no word about the record cold in Greenland. Why? The BAZ comments:
It casts the central prophesy of a continuous and ultimately lethal global warming, for which we are ourselves to blame, into question.”
Greenland has been cooling


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Recently NTZ reported here that Greenland in fact has been cooling over the past decade, as three recent studies alarmingly show us. According to one published in May of this year by a team of researchers led by Takuro Kobashi of the University of Bern, mean annual temperatures at the summit of Greenland have been showing “a slightly decreasing trend in accordance with northern North Atlantic-wide cooling“. See chart below.

Greenland’s temperatures headed in the wrong direction, defying climate model projections. Underlying chart source: Kobashi et al., 2017.
Warm optimum near an end?
The team by Kobashi also show that the Greenland Summit temperature have not risen in 90 years, and that Greenland was far warmer earlier in the Holocene:

Greenland temperatures were much warmer over past 10,000 years than they are today.
One has to wonder if the current optimum may be nearing an end. History shows that the earth’s surface temperature is in fact highly unstable and that most optimums don’t last much beyond 10,000 years. We need to ask ourselves what could be done to avert the catastrophe that a new ice age would bring with it. The overall trend does not bode well.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterExposing ‘Staggering’ Ice Sheet Melt Deceptions

In recent months, two new papers published in The Cryosphere have provided a condensed summary of the ice-melt and sea-level-rise consequences of global warming for the Arctic region.
1.  Between 1900 and 2010, the Greenland Ice Sheet (GIS) has melted so extensively and so rapidly that the GIS ice-melt contribution to global sea level rise has amounted to 1.5 centimeters for the entire 110-year period.   One-and-a-half centimeters.  That’s 0.59 of an inch!
2. It gets worse.  Between 1993 and 2010, the contribution to global sea level rise has been a disturbing 0.39 of a centimeter.  Almost 4/10ths of a centimeter.  That’s 0.15 of an inch!

Leeson et al, 2017
“Melt water from the Greenland ice sheet contributed 1.7–6.12 mm [median 3.9 mm, or 0.39 of a centimeter] to global sea level between 1993 and 2010“

Fettweis et al ., 2017
“SMB [surface mass balance, Greenland Ice Sheet] during the 1920–1930 warm period over Greenland was comparable to the SMB of the 2000s, due to both higher melt and lower precipitation than normal.”
“Finally, with respect to the 1961–1990 period, the integrated contribution of the GrIS SMB [Greenland Ice Sheet Surface Mass Balance] anomalies over 1900–2010 is a sea level rise of about 15 ± 5 mm [1.5 centimeters], with a null contribution from the 1940s to the 2000s“

Breakdown: 1900-2010 GIS Sea Level Rise Contribution
1920s-1930s: GIS contribution to sea level rise: 1.1 cm
1993-2010: GIS contribution to sea level rise: 0.39 cm
1940s-2000s: “a null contribution” [to sea level rise]

Washington Post Peddles Alarmism With Deceptive ‘Trillion Tons’ Of Lost Ice Pronouncements

It’s scary to learn that the Greenland Ice Sheet has lost a “staggering” 9 trillion tons of ice since 1900.
It’s not scary to learn that 9 trillion tons of ice losses actually amounts to less than 1 inch (0.6 of an inch, or 1.5 centimeters) of sea level rise contribution from Greenland meltwater since 1900.
So what does a world-renown news organization like the Washington Post do with this contextually-weighted scientific information?   Of course, like most other media organizations in the modern era,  the Post attempts to frighten the public with disturbing trillions of tons of lost ice exclamations without emphasizing the modest and nearly imperceptible sea level impact such “staggering” ice losses produce.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In December, 2015, the Post‘s Chris Mooney summarized “Greenland’s massive, centennial contribution to sea level rise”.

Washington Post  (December, 2015)



It is apparent from reading the article that Mooney is either (a) unaware that less than 1 inch of long-term sea level impact is not “massive”, and therefore using that descriptor in conjunction with  trillions-of-tons of ice loss can be misleading, or (b) he is aware that less than 1 inch of sea level impact in 110 years is not especially alarming, so he buries this inconvenient detail in the body of the article and instead he focuses on employing terms like “staggering” and “massive” and “trillions” and “disturbing” and “alarming” in an effort to conceal.
It would appear that (b) is more likely.
Notice above how Mooney cursorily acknowledges that 1 inch of global-scale sea level rise from 9 trillion tons of melted GIS ice “may not sound like much”.  But then, to recover, he misleadingly pivots to hypothetical scenarios, equating what one inch of sea level rise would do if this water equivalent from across the world ocean was only dumped on the United States’ interstate highway system.  (How does fantasy writing like this make it into a serious science article?)
And then, to pile on another thought experiment, Mooney adds the obligatory “if the entire ice sheet were to melt” conjuring so he can mention that “20 feet of sea level rise” is what’s at stake here.
One inch in 110 years isn’t enough to garner attention, but 98 feet (times 63) of submerged U.S. roads and global coastal areas is quite the scary scenario.
The Washington Post employed this same misleading and diversionary strategy about 8 months later, again relying on the “9 trillion tons of ice” lost study to scare readers.

Washington Post (July, 2016)


If Misleading Readers Wasn’t Allowed, What Would The ‘Honest’ Headlines Look Like?

If news organizations weren’t allowed to mislead readers about climate science, what would the headlines say?
With regard to the long-term (and recent) ice melt records for the Greenland Ice Sheet, a non-deceptive, non-misleading headline might look something like this.

Share this...FacebookTwitter "
"A geriatric semi-captive rhino died in Kenya recently. “Sudan”, a 45-year-old northern white rhino was put to sleep as vets decided, after months of ill health, that his condition had deteriorated to the point where the levels of pain and quality of life were unacceptable. From a conservation perspective, this does not sound like a big deal. Sudan was one old rhino. He was well past breeding age. So why did his death make headlines? Sudan was the last surviving male northern white rhinoceros, a subspecies known to scientists as Ceratotherium simum cottoni that went extinct in the wild about 20 years ago thanks to poaching. He was captured and removed from the wild in 1975, the last wild-caught northern white rhino. Sudan’s daughter Najin, and granddaughter Fatu, are now the only two left, and they are both old and incapable of reproduction even if they had a mate. It is a strange situation. On the one hand, it matters a lot. The northern white rhino is extinct, it just doesn’t know it yet. Conservationists refer to such populations as “the living dead”.  On the other hand, does it really matter? Despite persistent misreporting in the media (and some debate among scientists) the northern white is generally recognised as “only” a subspecies of the white rhinoceros. It is survived by its relative the southern white rhino, Ceratotherium simum simum, around 20,000 of which remain. The species as a whole is not currently endangered. The importance of Sudan’s actual death remains unclear, partly because it seems increasingly possible to bring his subspecies back to life. The northern white rhino may be resurrected by Jurassic Park-style technology. That would require conservationists to collect eggs from the remaining females and develop IVF techniques that are as yet unproven on rhino. DNA has been stored from 13 northern white rhino that died in recent years, including Sudan, and it would be combined with similarly-frozen eggs and sperm. The embryos produced would then be implanted within surrogate female southern white rhino. I recently spoke to Professor Thomas Hildebrandt, a global leader in conservation reproduction and pioneer of this technique, and he was confident it would work. If these optimistic plans play out, the first northern white rhino calf born since the year 2000 could be produced before the death of the two remaining females. An alternative would be to produce a genetically-engineered baby rhino that is a hybrid of both northern and southern species. If plans to resurrect the extinct woolly mammoth via hybridisation with Indian elephants are possible, then a white rhino hybrid is not unachievable. Nevertheless, we are talking not about saving a subspecies from extinction, but resurrecting an extinct subspecies – a much more challenging proposition. The second issue, that clouds the importance of the almost certain extinction of the northern white rhino, is that the white rhino survives through its southern subspecies which may (with help) be able to replace the northern white rhino in its historical range across central Africa. In doing so, it could fill the vacant ecological niche. We, as a society, have to be pragmatic and economic with the resources available to protect wild animals. Can we justify spending an estimated £7.1m (US$10m) to try to bring back to life a subspecies from stored DNA with limited genetic diversity? Even if the animals were all alive and breeding, there would still be fears of the “founder effect” that can occur when a population is started from just a few individuals, with some traits lost and others dominant within the resulting population. As a near-extinct subspecies, the conservation argument for continued investment to save the population is based upon whatever adaptive genetic diversity it holds that differentiates it from the other subspecies. But it is not clear exactly what genetically-useful traits are found in the sample of 13 northern white rhinos that are not also present in the southern white. To be direct, if millions of pounds can be raised to try and resurrect the northern white rhino, should it not instead be invested in protecting the southern white rhino (still at risk from poaching)? Or alternatively, direct the money towards even more vulnerable Asian rhinos. It is easy to see why cutting edge reproductive technology is so appealing now that the planet’s sixth mass extinction crisis is well under way. But the only economic and practical long-term solution to biodiversity loss is to conserve wildlife in the wild and to prevent it from reaching the sorry state of the northern white rhino. After all, if humans cannot save a species in nature while it is alive, what future for animals that we manufacture? My worry is that they would simply be living museum exhibits, destined to live out their lives in zoos, with habitat loss or poaching preventing life in the wild. Where would this end? Do we want to repopulate the world with lab-produced engineered organisms?  It is difficult to be positive about our ability to manage these incredible animals to survival. We have already failed the northern white rhino, let us ensure that we do not let down the remaining rhinoceros species and all the other endangered animals out there that need our help."
nan
nan
"
Share this...FacebookTwitterIn a referendum slated for this coming Sunday, Swiss citizens are being called to vote on a national energy strategy, dubbed Energiestrategie 2050.

Germany Green Party co-founder and former federal Homeland Minister Otto Georg Schily warns Swiss citizens voting on energy referendum that the Energiewende is “an economic, social and ecological disaster”. Photo by Olaf Kosinsky (2015), CC BY-SA 3.0 de.
Now it is reported that just days ago German Green Party co-founder (later turned socialist) and former German Homeland Minister Otto Schily has come out to warn Swiss citizens against voting yes on the project, reminding them that Germany’s Energiewende (transition to green energies) is not the success it is often claimed to be, and that it has in fact turned into a 25 billion euro a year disaster.
This is reported the online Swiss daily, Basler Zeitung here.
Schily held the top position in Germany’s Homeland Ministry in the country’s Socialist/Green coalition government led by Gerhard Schröder from 1998 to 2005. He is regarded as one of the country’s most respected elderly politicians and statesmen.
According to the Basler Zeitung, Schily wrote a letter to Christoph Blocher, where he judged the Energiewende to be an “economic, ecological and social disaster” and so urged Swiss citizens to vote no.
The rightwing Swiss SVP party, led by Blocher, is leading the campaign against the green energy transformation project put forth by Swiss President Doris Leuthard of the centrist Christian CVP party. Both Schily and Blocher were Homeland ministers at the same time in their respective countries in the 2000s and are reported to maintain light contact.
The online Swiss site BLICK characterized Schily’s letter as “explosive”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Basler Zeitung reports: “The costs of the Energiewende have grown to over 25 billion euros annually. As a result consumer electricity bills have risen year after year.”
Socially unjust
Schily wrote that Germany’s green energies are also “extremely socially unjust” because they force low income consumers to pay more money into the pockets of wealthy wind and solar park operators – in a classic redistribution from the bottom up.
Jobs-killer, done nothing for the climate
Moreover, the Basler Zeitung writes that the Energiewende has scarred Germany’s natural landscape, has probably cost more jobs than it created, and has “contributed nothing to climate policy as it hoped to do“. Schily advised Swiss citizens “not to repeat the far reaching energy policy of the German Energiewende“.
German CO2 emissions rising instead of falling
The Basler Zeitung also cites an “expert team” by McKinsey consulting group, which not long ago found that the German energy policy has fallen far short of its aims: “Emissions of climate-harmful carbon dioxide are not going down, but rather are increasing, as is power consumption even though it was supposed to go down because of efficiency measures.”
The Basler Zeitung adds: “a collapse of the power supply threatens when the remaining German nuclear power plants are taken offline over the coming years“.
 
Share this...FacebookTwitter "
"The UN’s ambitious new Sustainable Development Goals include a target to halt biodiversity loss by 2030. The SDGs have generated a great deal of comment, with questions raised as to whether the lofty aspirations can be turned into realistic policies. An article in The Lancet even dismissed the SDGs as nothing more than “fairy tales”. So is halting biodiversity loss a fairy tale? “Biodiversity” refers to the diversity of life on Earth. It includes diversity within species, between species, and of ecosystems. There are any number of statistics that confirm its decline across the globe. For instance, the Red List of threatened species, developed by the International Union for the Conservation of Nature (IUCN), identifies 22,784 that are at risk of extinction – almost 30% of the species that have been assessed. By other measures, habitats continue to be destroyed and degraded, and population sizes of most wild species are in decline. This is bad news not only for nature lovers but for all of us since we rely on biodiversity to deliver many crucial services such as pollinating crops and providing medicines. By projecting current trends forward in time, a study published in Science last year concluded we are already on course to miss most of the international community’s other main targets for biodiversity – the “Aichi Targets” – which were adopted in 2010 under the Convention on Biological Diversity (CBD) and aspire to improve things by 2020. So why might the new SDG biodiversity target be any more achievable than those that have gone before? The inclination is to be extremely pessimistic, but there are some reasons to be hopeful. The same Science paper also looked at indicators of societal responses to the biodiversity crisis. Here the trends are much more in the right direction. Coverage of protected areas is increasing across the planet, sustainable management practices in industries such as fishing and forestry are taking root, and public awareness of biodiversity issues is rising. There has been real progress in the policy arena. To date 184 of 196 parties to the CBD have developed National Biodiversity Strategies and Action Plans, which set out actions such as promoting laws and providing funds to help achieve the convention’s goals. The establishment in 2012 of the Intergovernmental science-policy Platform on Biodiversity and Ecosystem Services (IPBES) also provides an important new mechanism to inject sound scientific advice into policy making. In business as well, biodiversity conservation and the related concept of “natural capital” are becoming mainstream. For instance, the Natural Capital Coalition is developing the economic case for valuing natural ecosystems and includes buy-in from some of the biggest players in business, accountancy and consulting. And the financial industry is moving toward more responsible investing. The UN Principles for Responsible Investment, which commit investors to act in accordance with conventions such as the CBD, now has almost 1,400 signatories who manage assets with a combined total of US$59 trillion. These are major positive changes that have come to the fore in the past decade or so. And there are conservation success stories that illustrate how such changes can turn things around for biodiversity. For example, the latest update to the IUCN Red List reports that conservation action has bolstered populations of the Iberian lynx, which had only 52 mature individuals in 2002. And the Guadalupe fur seal, which had twice in the past been thought to have gone extinct due to hunting, is also making a comeback. More generally, there is an overall positive trend among populations of almost 1,000 bird and mammal species across much of the northern hemisphere.  These instances of good news still leave us a long way from halting global biodiversity loss. I don’t mean for a moment to underestimate the magnitude of the problem. Habitat loss, climate change, pollution, overexploitation and the spread of invasive species all remain huge threats that will require extraordinary efforts to tackle. But time has not yet run out. Although many plants and animals are threatened with extinction, we have in fact lost only a few percent of known species over recent centuries. It is heartening that there is still an astonishing amount left to save. It will take time to slow and turn around the juggernaut that is biodiversity loss, and everyone must pull in the same direction in order to shift course. The period over which the new SDGs will run, from now until 2030, will be absolutely crucial for making this happen. There are indications that things are beginning to turn around. Hints that we can do this. It would be a big mistake to dismiss the biodiversity target as a fairy tale. And anyway, fairy tales usually have happy endings, don’t they?"
"Governments both in Australia and internationally are not moving fast enough to avoid 2C warming, according to the former head of Scott Morrison’s department, and Australia is also creating a significant problem for itself down the track by deploying carryover credits from Kyoto to meet the Paris target. In a frank and wide-ranging interview on Guardian Australia’s politics podcast, Martin Parkinson – the former secretary of the prime minister’s department and the bureaucrat at the centre of policymaking at the federal level on climate change during the Howard, Rudd and Gillard governments – reflected on the experience he describes as the worst of his professional life. Parkinson said John Howard pursued constructive climate action towards the end of his prime ministership, pursuing an emissions trading scheme, but progress was halted because of a “civil war” inside the Coalition and because of “truly appalling” behaviour by the Greens in sinking Kevin Rudd’s Carbon Pollution Reduction Scheme. The former top bureaucrat excoriated the Greens, declaring that from his vantage point, they “never wanted to see anything succeed. If you are the party of protest, you don’t want to take away your protest platform. Maybe I’m being a cynic, but I think that’s what happened.” Parkinson said the Greens didn’t accept that you could put a mechanism in place and then dial targets up and down depending on where the community was at and the demands on Australia, courtesy of being signatories to international agreements. “I can’t see inside their minds but I’ve never heard anyone from the Greens apologise for what they have done. “And let’s be blunt about it, 12 years on the [emissions reduction] targets are no more ambitious – if anything, they are watered down from where we should be, and that’s not the current government’s fault, that was Tony Abbott. “We have missed a decade of mitigation action and adaptation action.” Parkinson said the decade of inaction had prompted business to try and seek its own solutions to lowering emissions, rather than wait for the government to end the hyperpartisan war. He said business in 2019 was acutely conscious that climate change meant the risk of stranded assets, more natural disasters and a potential “tsunami” of liability when superannuation funds and pensions funds turn on companies for failing to manage carbon risk. He said the outlook was really challenging. “I cannot see governments here or overseas moving fast enough to avoid 2C, let alone 1.5C, just to be really blunt about it. “The International Energy Agency, which is hardly a bunch of crazy climate [change] believing leftists, says we are on track for 2.7C to 3.5C even if countries do what they are committed to do for Paris – and they are not doing what they have committed to do.” Parkinson said the Morrison government’s decision to use carryover credits from the Kyoto period to account for about half the abatement required under Australia’s 2030 target was going to create significant problems down the track. Using the Kyoto-era accounting means Australia can meet the Paris target nominally while delaying a significant amount of practical emissions reduction. “If you use the carryovers, then at the end of 2030 the gap you’ve got to close, as you go into whatever comes next, is that much bigger,” he said. Parkinson retired from his position in August. Before heading the prime minister’s department, Parkinson was the secretary of the Treasury department and the climate change department. Under John Howard, he ran the Shergold review, which cleared the path for the Liberals to adopt the policy of emissions trading, and he remained at the centre of policymaking in the Rudd and Gillard eras, before being sacked from Treasury by Tony Abbott. He was brought back to run the prime minister’s department when Malcolm Turnbull took the Liberal leadership. Asked whether the climate policy failure was the worst experience of his professional life, Parkinson said: “Yes, it was. It was awful on a number of fronts. We were so close [with the CPRS].” Coupled with all this, Parkinson said he inherited responsibility for managing the fallout from the home insulation scheme. “We’d had four young Australians tragically die, and it was awful”. He said he and his colleagues had “many, many sleepless nights”. “That whole period was absolutely terrible,” he said. Parkinson said the broader cause of reform in Australia had faltered because there was no longer a consensus, either in the political class or the economic profession, about what needed to be done. He said some participants in public life wanted to “pretend that really complex problems are really simple” when the reality was there were a number of problems that government couldn’t fix. While he maintained a positive view of ministers and their advisers, including the current prime minister, Parkinson said ministers often came to their posts significantly unprepared. Ministers were asked to assume awesome responsibilities without proper training. Sign up to receive the top stories from Guardian Australia every morning He expressed disappointment that the Morrison government has rejected some of the central recommendations of the recently released Thodey review, such as adopting a code of conduct for ministerial advisers. “I think the vast majority of people who go into parliament or ministerial offices are trying to do the right thing, so I don’t see training or a code of conduct for them as any way a negative – it would be about helping them do their jobs better and positioning them much better,” Parkinson said. He says there was some antipathy in the government about the Thodey review process. “I think there’s a reasonable number of people in the government who took the attitude that this was a Malcolm Turnbull/Martin Parkinson frolic, and were never really committed to it, and definitely didn’t want to do anything that would have impacted on their freedom to operate.”"
"The city of Chennai – a coastal metropolis of 8.7m people and capital of India’s Tamil Nadu region – has been flooded by an extreme weather event. The city experienced incessant rain, in what has been its wettest November for over a century: December 1 broke local records, with 490mm of rainfall.  The results have been catastrophic: the Adyar and Cooum rivers overflowed, 35 major lakes breached their banks and large parts of the city – including the international airport – were submerged. Schools and hospitals were shut down, electricity and electronic networks were unavailable for days, and life was turned upside down not just for residents, but also for flagship IT and automobile companies such as Tata Consultancy Services, Infosys, Cognizant, Yamaha, Renault Nissan and BMW India.  The confirmed death toll from the flooding is 270 and rising, and a trade body has estimated that monetary losses will be in the region of Indian Rupees 15,000 crores (£1.5 billion). While the flood waters have now receded, health epidemics ranging from malaria to cholera and typhoid may well be imminent. It is widely believed that Chennai’s misery was brought on by climate change, and that such extreme weather events are going to increase in frequency and impact. World leaders have blamed the event on global warming, even as the COP21 climate change conference plays out as expected in Paris. As the climate battles rage in the natural and political worlds, Chennai represents the human dimensions of disaster. Climate change is not the only guilty party: the scale of the disaster at Chennai was magnified by a rampant disregard for town planning, and the basic principles of ecology and hydrology. To name just a few of the violations: the international airport is built on the floodplain of the Adyar river; the Mass Rapid Transit System sits atop the Buckingham Canal; the government allowed buildings to be erected over more than 273 hectares of the Pallikarni marshland to the south of the city; and the city’s famed Information Technology and Knowledge Corridors encompass wetlands and marshlands that would normally act as a sink for flood water.  Modern states have always used urban and infrastructure planning as a way to control and exploit nature’s more unruly tendencies: whether it’s water flowing down a river, waves battering the coast or food sources growing on the land or in the sea. There have been countless examples: from the colossal web of transport lines and ports built throughout colonial East Africa and South Asia, to the extensive damming of the Tennessee River System, which inspired similarly ambitious projects in the Mekong River Basin and the Narmada Valley.  But the planning distortions of contemporary Chennai show that the state can take it too far, especially when it is attempting to meet the demands of a growing population and a competitive economic climate. Since economic liberalisation in 1991, Tamil Nadu has competed with other sub-national units in India – as well as productive regions in neighbouring countries such as China – to attract private investment. In the words of a retired Tamil Nadu bureaucrat, whom I interviewed for my research in 2012: Companies are like bridegrooms. If they are bringing an iconic brand into the [sub-national] state, they come with a huge list of demands, the primary one being land. In the case of [an automobile manufacturing company], we had large, vacant … plots, which we could transfer to them in a short period. In addition, they wanted road, rail and port access. They wanted to be near a metropolis. They wanted all sorts of social infrastructure, like land for an international school and sporting facilities for families of executives… Overall, there were 80-90 parameters related to land, tax concessions and clearances for water, electricity, etc. With increasing competitive pressures on states, land and natural resources become pliable reserves for meeting the exacting demands of national and international capital. But recent events in Chennai are a reminder that nature is flexible only to a point. It does strike back. While governments work formally with private entities to change the face of our cities, there is also a great deal of informal development going on behind the scenes. Private firms, India’s booming real estate industry, and middle class consumers work with unregulated brokers, middlemen, government touts, moonlighting officials, political strongmen, and various other intermediaries to acquire and build on land. The government acknowledges that there are 150,000 illegal structures in the city, and that 300 tanks and lakes have simply been built over. The actual number of breaches is probably much higher. Chennai is by no means the only city where space is more often allocated informally than through the “logic” of planning. Privatisation of the commons, filling of water bodies, encroachment on ecologically sensitive wetlands and the illegal alteration of maps to reflect these changes is evident in my field sites in east, west and south India. This is a translation of a quote from a Kolkata land broker, interviewed in 2014: Changing a pond record is backdoor work, and this is totally illegal. Every time it is changed, it happens under the table. The government office will have to be managed. All buyers (e.g. real estate developers) have a setting arrangement in the government office, and they all have a civil lawyer…. Politics also plays a role in our work … if there is a pond to be filled politicians will not leave us. They will demand Indian Rupees 10 lakhs to 20 lakhs (£10,000 to £20,000)… Besides, how will you fill the pond? You need mud, sand, and ash. Organisations affiliated to the locally powerful political party will supply this. As Chennai emerges from the water and takes a fresh look at itself, poorer residents and slum settlers will probably be the first to be evicted, in order to free up illegally acquired space for development. But if the city teaches us one lesson, it is that we are in this together. We are reaping what we have sowed as consumers, voters, home owners – not to mention the role of politicians, government officials and private companies. To pass the blame would be as shortsighted as world leaders blaming each other for climate change."
"Next year’s United Nations Climate Change conference (COP26) will be held in Glasgow, with Boris Johnson in the chair. It will be the largest gathering of world leaders in Britain since the opening ceremony for the 2012 Olympics in London, in which Mr Johnson also played a leading role. Unlike the Olympics, conditions are hardly propitious for a successful UN conference in 2020. The COP25 conference in Madrid at the weekend ended with despair about the lack of progress in reducing greenhouse gas emissions. To avoid repeating what was widely criticised as one of the worst outcomes in 25 years of climate negotiations, Mr Johnson will have to display hitherto unknown diplomatic depths. The irony is that he needs a global green deal while pursuing a post-Brexit British trade policy to outcompete the European Union by undercutting green standards.  Madrid was a depressing example of how not to do international diplomacy. This is not the fault of Spain, which took over the running of the conference at short notice after Chile, which had been due to host, pulled out following bloody unrest at home. Understandably distracted, Chile’s lack of leadership saw a coalition of states with strong links to fossil fuel industry – the United States, Brazil, Australia and Saudi Arabia – seize the opportunity to undermine the talks. Their success was to render meaningless the summit’s final declaration. This is a snub to science and strikers in a year of unprecedented climate activism. If this climate denialism persists we will pay a heavy price. Under the Paris agreement 190-odd countries have plans which, if implemented, would still see Earth’s temperature rise by 3.2 degrees. Scientists have warn that beyond 1.5 degrees of warming there’s a real risk of extreme heat, drought and floods becoming the norm. Next year countries will have to bridge the gap between the policies now in place and what is required to stop global heating with a round of new, bolder climate pledges. As the impact of the emergency becomes more evident, so does the scale of the challenge ahead. The UN now says that countries must increase their ambitions fivefold. Mr Johnson does not want a rerun of the UN summit in Copenhagen in 2009, which ended in failure amid clashes between 100,000 environmental protesters and Danish police. To ensure that the Glasgow conference passes off smoothly, he will first have to show that he is cleaning up his act at home. At present the government won’t hit carbon reduction targets after 2028, hardly inspiring confidence that the UK will reach net-zero by 2050. This needs more than just a new government department. Mr Johnson’s newfound green zeal can be politically useful: his manifesto promised to spend £6bn on improving the energy efficiency of 2.2m social homes, which may be allocated – brazenly – to the constituencies of new northern Tory MPs. But whatever his own approach, Mr Johnson’s fate is in the hands of others. Most important are US voters who might deliver a Democratic president just days before the Glasgow summit takes place. This would halt the Trump White House’s attempt to withdraw from the Paris agreement. EU leaders hope to strike a bargain with Beijing next September, so efforts to cut emissions remain meaningful even without the US. The Paris agreement has Mr Johnson facing one way on climate, but Brexit has him facing the other way. He will have to choose, perhaps symbolically by cracking down on City financing for dirty coal abroad. The world is not short of ideas to realise climate goals. We urge and encourage the prime minister to secure a global response that matches the scale of the crisis. "
"Douglas Tompkins, the pioneering entrepreneur who created the outdoor company The North Face and fashion chain Esprit, and who spent his riches creating the world’s largest network of privately owned nature reserves, died at the age of 72 following a kayaking accident.  His conservation philanthropy made him a polarising figure in Chile and Argentina, where he spent the last three decades purchasing more than a million hectares to create a series of privately-owned parks and reserves. Lauded by some as a conservation hero, criticised by others as an abrasive imperialist, it became clear during my two years studying private reserves in Chile and speaking to the key actors, that his remarkable story shows both the potential and limitations of wealthy philanthropists in saving nature. Tompkins’ youth was spent skiing, mountaineering, surfing and climbing, including a six-month expedition in 1968 to Chilean Patagonia with his friend Yvon Choinard, founder of outdoor brand Patagonia Inc. Kris McDivitt, CEO of Patagonia Inc for several decades, would become Topmkins’ second wife.  Early business success came when he established The North Face, which he sold after a few years, and much greater success came when he created Esprit with his first wife and saw the company become a massive global brand. Tensions within the company, and within his marriage, saw him retire from business in 1990 and move to southern Chile.  Inspired by the long US tradition of wildland philanthropy, he began purchasing parcels of land for conservation in Chaiten province, Patagonia, using intermediaries to evade attention and avoid price inflation. In 1994, he publicly announced the creation of Parque Pumalín (Puma Park), covering 275,000 hectares. By comparison, Lake District National Park, England’s largest, covers 220,000 hectares.  The announcement was immediately controversial. Parliament debated whether Tompkins was undermining national sovereignty. Chile had just emerged from a long military dictatorship, during which it nearly went to war with Argentina over the location of the frontier in Patagonia. A “gringo” buying land on this scale was not well received.  Crucially, Pumalín stretched from the Pacific Ocean to the Argentine border, effectively cutting the country in two. The military and Patagonian senators raised objections over whether this challenged national territorial integrity and whether it would prevent the construction of crucial infrastructure, such as roads and powerlines, that would link Patagonia with the rest of Chile.  Tompkins was accused of ignoring the rights of smallholder farmers who had lived on his newly purchased properties for generations, but who lacked proper land titles. His aim of conserving forests was seen as undermining Chilean economic development, which was (and remains) heavily dependent on natural resource extraction.  Wildland philanthropy was unknown in Chile, and some suspected ulterior motives. Conspiracy theories circulated that Pumalín was a front for CIA operations or Zionist plots, or an attempt to seize control of the region’s water supplies – this is reminiscent of the 2008 James Bond film, Quantum of Solace, in which the villain uses private reserves as a front for seizing control of Bolivia’s water supply. The “Bolivian” scenes were filmed in Chile.  The resulting political tensions led to Tompkins signing an agreement in 1996 with president Frei promising to desist from purchasing further properties and agreeing to infrastructure crossing his land. Foreign forestry and utilities companies have similar properties bisecting Chile, but have not attracted similar criticism, and no infrastructure has been built because of the challenges of the vertiginous and landslide-prone terrain.  This agreement was later mutually annulled, and Tompkins subsequently more than doubled his Chilean land holdings, and purchased even more in Argentina. Although he promised to later donate all his land to the state, lingering mutual distrust limited donations greatly. Tompkins became less politically toxic with time, although he remained uncompromisingly and vocally critical of what he saw as the environmental damage of salmon farming, forestry and hydroelectricity. While Tompkins remains Chile’s best-known owner of private reserves, hundreds of others have been established since 1994. They now cover over 2% of Chile, ranging in size from a dozen to 300,000 hectares. Owners include middle-class families, luxury eco-resorts companies, forestry companies, and national and international NGOs.  The best vindication of Tompkins’ approach came in 2005, when Chilean airline and credit card billionaire Sebastián Piñera, who served as Chile’s president from 2010-14, established the 112,000 hectare Tantauco private reserve. Yet the wider private reserve movement in Chile hesitated from close engagement with Tompkins, wary of his political toxicity. It was Tompkins’ wife, not him, attended Tantauco’s opening. Tompkins’ activities raise bigger questions about conservation philanthropy. First, Tompkins’ purchases have been seen as eco-colonialist land grabs, and there are legitimate concerns over powerful foreigners controlling large swathes of land.  Others within the Chilean conservation movement feel that the controversy over sovereignty has hampered their own efforts to get legal recognition for private reserves, and there are similar controversies in other countries. One international organisation specialising in private reserves always works through local partner NGOs and never owns land itself, to avoid accusations of colonialism and to ensure local support for its work.  Second, are private actors better than the state at conservation? Proponents argue that they are more motivated, flexible and innovative than governments, although there are few studies that explore this in detail. We do know that private reserves in Chile are more likely to be located in places with high levels of endangered species than government reserves, although Tompkins’ properties are not in this category. His purchases were largely driven by landscape aesthetics, not the density of biodiversity within them.  Tompkins purchased large wild areas which could be easily conserved through benign neglect, rather than the arguably more important challenge of conserving species in landscapes shared with humans. If private reserves are to be most effective, then they need to be planned carefully using assessments of what places are the greatest priority, rather than on the whims of wealthy philanthropists. Can private reserves create a vibrant green economy in places such as Patagonia? Several companies have tried to make money from conservation, through tourism, carbon sequestration and other initiatives, but successes are rare. Tompkins never bothered making money from his reserves – entrance fees were minimal – but was more interested in exporting US conservation philanthropy to Patagonia. It has proven difficult to make money from saving nature, so it is perhaps best to view it as a public good, worth doing even if it costs money. Either way, we are in a time where private actors, be it corporations, NGOs or philanthropists, are increasingly replacing governments’ role in saving nature. The successes and failures of Doug Tompkins contain lessons on how to do this fairly and effectively."
"
Share this...FacebookTwitterYesterday at Twitter here meteorologist Joe Bastardi, a well-known climate science antagonist, directed our attention to the NCEP temperature situation for South America. Yikes!

The massive scale of the cold is of Amazonian proportions, with temperatures well below normal across the entire continent. Bastardi even called the cold “spectacular”.
Recently snow was reported to have fallen in Santiago, Chile. According to the Washington Post here, “heavy, wet snow weighed down tree branches, which snapped power lines. Up to 350,000 homes lost power“. In some places 40 cm of snow blanketed the ground. The AP also reported
Chile’s Meteorological Office said it was the biggest snowfall in the capital in 46 years.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




For Santiago, it was the first snowfall the city had seen since 2011. What follows is the 7-day forecast anomaly for the Latin American continent. Cold is forecast to remain:

Chart cropped here.
Things in the Arctic, at the opposite hemisphere, are not improving. Paul Homewood here writes DMI June sea ice data shows “a steady recovery in extent since the low in 2010” and that sea ice extent is where it was 11 years ago.
Climate alarmism’s “canary in the coal mine” Greenland also is behaving opposite of what global warming scientists predicted. It’s surface ice mass budget has been hovering at near record high levels.

Source: www.dmi.dk/surface-mass-budget/
Share this...FacebookTwitter "
"The Scottish government has been warned it will miss its next climate target after failing to take sufficiently radical and urgent action. The Committee on Climate Change, which advises the UK and devolved governments on their targets and policies, said Scotland’s credibility would be damaged unless it took action before Glasgow hosts next year’s global climate talks.  The COP26 negotiations have been billed as the most important since the Paris talks in 2015. Nicola Sturgeon, Scotland’s first minister, has invested her personal and party’s reputation in taking action on the climate. Lord Deben, the CCC’s chair, said Scotland’s rapid progress on cutting emissions was in danger of stalling because its policies on transport, farming and home heating were insufficiently far-reaching. It risked missing its target of cutting overall emissions by 56% compared with 1990 levels by 2020, he said, and it needed to take urgent and significant action to enable it to hit its target of net zero by 2045. “Scotland has set an ambitious world-leading net zero target of 2045. Now Scotland needs to walk the talk,” Deben said. “The new legally binding target for 2030 – a 75% reduction in emissions compared to 1990 – is extremely stretching and demands new policies that begin to work immediately. “The spotlight is now on Scotland’s plan to deliver meaningful reductions across all sectors of the economy, including buildings, road transport, agriculture and land use. Scotland has outperformed the rest of the UK in cleaning up its economy, resting on the rapid closure of coal. As this chapter closes, the Scottish story must change. But so far we haven’t seen the same progress in other sectors.” He said both the Scottish and UK governments – the latter has a net zero target of 2050 for the UK as a whole – needed to collaborate closely to help each other hit their goals, particularly over heavy industries, green energy generation and carbon capture and storage. Green campaigners welcomed the CCC’s warnings but the Scottish government insisted it was committed to taking the necessary action. “We strongly agree [we] must walk the talk and adopt policies over the coming year that make those targets a reality,” a spokesman said. “The global climate emergency and a green new deal for Scotland are at the centre of our programme for government. However, we recognise that even more will need to be done for Scotland to reach net zero emissions by 2045.”"
"
Share this...FacebookTwitter“Do we have the next Solyndra at hand?”
I had to shake my head when reading the recently published Fox News report: Another taxpayer-funded energy company files for bankruptcy.

Image cropped from Aquion Energy.
Hat-tip: Indomitable Snowman
According to Fox News, Pennsylvania-based Aquion Energy had received “a $5.2 million stimulus-tied grant” (not a loan) from the U.S. federal government and that the company had once been “touted as a rising star in the energy storage business”. It even attracted “an investment from Microsoft founder Bill Gates“.
On Wednesday Aquion Energy filed for Chapter 11 bankruptcy.
“North American Company of the Year”
Fox News adds:
In January, the company was named ‘the North American Company of the Year Award’ at the annual Cleantech Forum in San Francisco…”
This is a classic example of how a house of cards gets built and begins to collapse. It should remind us of what can happen whenever bureaucrats and politicians get so caught up in a pie-in-the-sky idea that they literally become deaf to technical, scientific and economic reason.
Multi-tiered subsidy debacle


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




There was certainly no lack of warnings from skeptics that renewable energies (mainly sun and wind) were fraught with daunting technical and economic obstacles, and that the technology for overcoming these obstacles still remained decades out into the future.
But green energy proponents wanted to hear none of it, and so embarked on a blind and reckless money give-away of the sort never seen before. Already trillions have been earmarked worldwide — one trillion in Germany alone.
Today the green energy subsidy folly has since made its way down through multiple supply tiers as the government funds tens of billions of dollars to prop up the junk science that tells us us we need the green energies, which in turn also receive hundreds of billions in subsidies. This in turn has led to billions in subsidies made to companies claiming to have the technologies for overcoming the technical hurdles that the rest of us had long warned about.
What’s next? As expected these companies are now folding. It was a scam all along, as they were never as close to solutions as they led many of us to believe. Now the government will have to subsidize the many workers who are losing their jobs, at least for awhile, as scheme implodes on itself. What a folly.
Driven by rampant cronyism
Naturally almost everyone supports funding for the development of new energy technologies, but there is a huge difference between pitch-forking tax dollars, by the billions, into a huge crony feeding trough, and wisely and strategically allocating precious funds to the right places.
Unfortunately the green industry has been one driven by cronyism, and not technical or scientific merit — and certainly not economics. It has been a huge bonanza for very few at the great expense of the common good. The hundreds and hundreds of billions wasted would have been far better invested elsewhere.
The storage solutions come from the past, not the future
When it comes to efficient energy storage, putting a man on the moon is in fact easy compared to finding a new way that stores energy even a fraction as well as a chunk of coal, a bottle of gas, or can of petroleum does. In fact we find the storage solution millions of years in the past in the form of fossil fuels, and not the shady, over-hyped half-baked technologies of today.
There are all kinds of future energy storage solutions out there. But so far most of them hold little or no promise of even coming close to being economical. It’s going to take years or decades to develop them, and we have to be smart about how we do this. We cannot continue pouring money on something that will never work.
Yet, until bureaucrats wake up to this truth, expect many more Solyndras and Acquion Energy debacles in the years ahead.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter Temperatures, Sea Levels ‘Naturally’ Rise
 30 – 40 Times Faster Than Today’s Rates

Modern Temperatures Only Rising 0.05°C/Decade

Since 1850, CO2 concentrations have risen from 285 ppm to 400 ppm.  During these ~165 years, the IPCC has concluded that surface temperatures have warmed by 0.78°C.  This is a warming rate of only 0.05°C per decade for 1850-2012 — which happens to be the same rate of warming over the 1998-2012 period.

IPCC AR5 (2013):     “The globally averaged combined land and ocean surface temperature data as calculated by a linear trend, show a warming of 0.85°C over the period 1880 to 2012, when multiple independently produced datasets exist. The total increase between the average of the 1850–1900 period and the 2003–2012 period is 0.78 °C, based on the single longest dataset available 4 (see Figure SPM.1). … [T]he rate of warming over the past 15 years (1998–2012; 0.05 °C per decade), which begins with a strong El Niño, is smaller than the rate calculated since 1951 (1951–2012; 0.12 °C per decade).”

Modern Sea Levels Only Rising 0.17 Of A Meter/Century

IPCC AR5 (2013):     “[T]he rate of global averaged sea level rise was 1.7 mm yr between 1901 and 2010“

Historical Hemispheric Temperatures Rose 2.0°C/Decade

According to a new paper, the Bølling Warming event 14,700 years ago raised the surface temperature for the entire Northern Hemisphere by 4 to 5°C within a few decades.  This is a hemispheric warming rate of approximately 2.0°C per decade, which is 40 times faster than the 0.05 °C per decade global warming rate since 1850 (and 1998).

Historical Sea Levels Rose 5.3 Meters/Century

Central Greenland’s surface temperatures rose by as much as 12°C during this time frame (14,700 years ago to 14,500 years ago).  Consequently, glaciers and ice sheets disintegrated rapidly and sea levels rose by about 18 meters (“12-22 m”) in 340 years.  An 18 m rise in 340 years is the equivalent of 5.3 meters per century, which is more than 30 times faster than the rate of sea level change (0.17 m per century) between 1901 and 2010.

Ivanovic et al., 2017     “During the Last Glacial Maximum 26–19 thousand years ago (ka), a vast ice sheet stretched over North America [Clark et al., 2009]. In subsequent millennia, as climate warmed and this ice sheet decayed, large volumes of meltwater flooded to the oceans [Tarasov and Peltier, 2006; Wickert, 2016]. This period, known as the “last deglaciation,” included episodes of abrupt climate change, such as the Bølling warming [~14.7–14.5 ka], when Northern Hemisphere temperatures increased by 4–5°C in just a few decades [Lea et al., 2003; Buizert et al., 2014], coinciding with a 12–22 m sea level rise in less than 340 years [5.3 meters per century] (Meltwater Pulse 1a (MWP1a)) [Deschamps et al., 2012].”


Bølling Warming/Sea Level Rise Occurred With Stable CO2


CO2 record for 25 kya-present courtesy of Kawamura et al., 2003

Greenland Warmed By 10°C Within 3 Years 14,700 Years Ago


Steffensen et al., 2008     High-Resolution Greenland Ice Core Data Show Abrupt Climate Change Happens in Few Years 
“A northern shift of the Intertropical Convergence Zone could be the trigger of these abrupt shifts of Northern Hemisphere atmospheric circulation, resulting in changes of 2 to 4 kelvin in Greenland moisture source temperature from one year to the next.”
“The d18O warming transition at 14.7 ka [14,700 years ago] was the most rapid and occurred within a remarkable 3 years, whereas the warming transition at 11.7 ka [11,700 years ago] lasted 60 years; both correspond to a warming of more than 10 K.”


Greenland Warmed By 8-15°C Within Decades During Last Glacial

CO2 concentrations remained essentially stable  and dangerously low (~180 parts per million) throughout the last glacial (roughly 80,000 to 15,000 years ago).  And yet despite the lack of CO2 flux, Greenland’s surface temperatures often warmed by about 10.0°C within a matter of decades during this period.  This indicates that CO2 variability is not a detectable factor in abrupt climate changes.

Sánchez et al., 2017


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Schmidt and Hertzberg, 2011     “There are twenty-five of these distinct warming-cooling oscillations (Dansgaard 1984) which are now commonly referred to as Dansgaard-Oeschger cycles, or D-O cycles. One of the most surprising findings was that the shifts from cold stadials to the warm interstadial intervals occurred in a matter of decades, with air temperatures over Greenland rapidly warming 8 to 15°C (Huber et al. 2006).”

In Contrast, There Has Been No Net Warming In Greenland For 80 Years

Zhao et al., 2016


Hasholt et al., 2016      “We determined that temperatures for the ablation measurement periods in late July to early September were similar in both 1933 and the recent period [1990s – present], indicating that the temperature forcing of ablation within the early warm period and the present are similar.”


van As et al., 2016     “JJA [summer] temperatures were higher in 1928 and 1929 than in any other year of the Qaqortoq record, both attaining values of 9.2°C. This suggests that ablation in those years may have exceeded the largest net ablation measured on the Greenland ice sheet (2010).”


Box et al., 2009     “The annual whole [Greenland] ice sheet 1919–32 warming trend is 33% greater in magnitude than the 1994–2007 warming.”


Conclusion

Modern rates of temperature change and sea level rise are quite modest and unremarkable relative to the magnitude of the changes in the geological past (that are 30 to 40 times larger or faster).  The abrupt and pronounced historical temperature and sea level rise events occurred without any significant changes in atmospheric CO2 levels.
In contrast, during the last 100 to 150 years there has been a dramatic rise in anthropogenic CO2 emissions and atmospheric CO2 concentrations…but no accompanying dramatic rise in temperatures or sea level.
Thus, the conceptualization that human activity or CO2 concentration changes are the primary drivers of temperature changes and sea level rise does not  seem to be supported by the geological evidence.
Share this...FacebookTwitter "
"The US has banned mention of the climate crisis in trade talks with the UK, an analysis of leaked documents has revealed. In negotiating a trade deal, the UK acknowledges that there will be pressure to ensure that any agreement meets its climate commitments. But to the anger of environment groups, analysis of a 451-page dossier leaked last month confirms that the Trump administration has told the UK that the climate crisis cannot be mentioned.  “The fact that the US has banned even the mention of climate change says it all,” said Nick Dearden, director of Global Justice Now, which first drew attention to the dossier’s existence. “Trump is a climate [change] denier, and any US deal is going to make it much harder for Britain to meet its already tepid commitments.” The dossier made explosive reading when it was highlighted by Labour during the election campaign. Britain’s security agencies are now investigating whether hackers targeted a personal Gmail account to obtain it. Jeremy Corbyn said it proved the NHS was “on the table” in future talks. But environmental groups now point out that the dossier also sheds light on how far the UK will have to bend to the White House on the environment. One memo reads: “UK inquired about the possibility of including reference to climate change in a future UK-US trade agreement given that the UK has a strong historical stance on climate change and pushed strongly for the Paris agreement. UK also highlighted the pressure for this that would come from civil society and NGOs. US responded emphatically that climate change is the most political [sensitive] question for the US, stating it is a ‘lightning rod issue’, mentioning that as of 2015, USTR [US trade representatives] are bound by Congress not to include mention of greenhouse gas emission reductions in trade agreements. US stated this ban would not be lifted anytime soon.” The Greenpeace policy director, Dr Doug Parr, said: “If ‘climate change’ are taboo words for Trump’s negotiators, that’s just a hint of the crushing pressure our environmental standards will come under in any trade deal with the US. For US industrial lobbies, this deal is the long-awaited chance to get rid of the rules banning things like chlorinated chicken and hormone-grown beef from our shelves, while leaving our climate and energy policies at the mercy of trade disputes.” Dearden added that trade deals today tend to be bad for the environment: He said that the abandoned EU-US deal had a clause that would have made it much harder for the government to discriminate between fossil fuels and renewables. “Recent trade deals with North America have increased climate-destructive industrial agriculture and the flow of tar-sands oil into Europe. But in a US-UK deal, US negotiators have been clear that they’re not remotely interested in even listening to discussion of climate change. Either we allow policies which will further devastate the environment, or the deal is dead.” The dossier also shows that the US wants the UK to agree to an investor-state dispute settlement (ISDS) system, which allows foreign corporations to sue governments outside of the national legal system. “There is value in including ISDS in an investment chapter,” one memo records. “Even if disputes do not proceed to claims, the presence of a backstop is invaluable in resolving things.” Dearden said: “The icing on the cake is the awful ‘corporate court’ system, which allows big business to sue governments in secret tribunals, without the right of appeal. “Only this year, an energy corporation has sued the Netherlands in one such court because the Dutch government proposed to phase out coal production and use. US negotiators have been clear that they would want the most red-blooded corporate court system available in a US-UK trade deal, allowing the massive US fossil fuel industry to bully and threaten the British government over its climate policy. This will lock in climate devastation and undermine any promises Johnson makes on environmental protection.” A spokesman for the Department for International Trade said it did not comment on leaks: “We will publish our own negotiating objectives for a future trade agreement with the US in due course. The UK leads the world in tackling climate change, as the first major economy to pass new laws for net-zero emissions by 2050. The prime minister has set out his vision to ensure Britain has the most ambitious environmental programme of any country on earth.” But Parr was sceptical. “So far, all we have to set against these powerful industries backed by the White House is Boris Johnson’s promise that standards will be maintained – that’s nowhere near enough. The UK government should set in law a guarantee that environmental and food standards will never be weakened in future trade deals, and that policies to tackle the climate emergency will never be subjected to secretive corporate courts.”"
"“The Big House”, home to the University of Michigan’s American football team, is one of the world’s largest stadiums. Here’s what it looks like when packed to the brim with more than 100,000 rowdy spectators: Now, imagine replacing those people with Bornean orangutans. It’s a funny sight, isn’t it? Thousands of red-haired apes jostling in the stands. Well, scientists just learned that at least 100,000 of these orangutans have disappeared over the past 16 years. And the worst part of this story is that all the remaining orangutans on the vast island of Borneo would only just about fill The Big House again one more time. This finding is the result of our new study, published in the journal Current Biology, in which we investigated what has happened to orangutans in Borneo, the Southeast Asian island where most of them live.  We first gathered 16 years of survey data, collected both from researchers on the ground and from “aerial surveys” which used helicopters to identify orangutan nests high in the canopy. We then combined this with satellite images which indicated how the landscape has changed.  Our results show that the declines were steepest in areas that were deforested or transformed for industrial agriculture (often oil palm or paper pulp plantations), as orangutans struggle to live outside the forest.  Worryingly, however, the largest number of orangutans were lost from areas where the forest remained intact or where only the tallest trees had been selectively logged. Here the species is in decline because it is hunted, just like any other edible animal on Borneo.  One analysis, based on interviews with 5,000 local people, found that few hunters would go out specifically to target an orangutan, and locals generally prefer deer and pigs. However, when an orangutan is encountered at the end of a long hunting day, a big orange primate sitting in a tree is a sitting duck or, more accurately, a sitting ape.  Orangutans are also increasingly killed when their forest habitat is cut down and they are pushed into people’s gardens and into plantations. People who encounter them there are scared or angry and resort to killing them. Orangutans are very slow breeders. Previous research has indicated that a population will probably go extinct even if only one reproductive female per 100 adults is removed per year. But killing rates have been identified as being as much as three to four times higher than this, which would explain the immense losses seen within Borneo’s forests.  There is a positive twist to the story: there are actually more orangutans than we had previously thought. Some populations, in parts of Malaysian Borneo and larger national parks in Indonesian Borneo, even appear to be relatively stable and make it seem unlikely that the species will go extinct just yet.  And the more we learn about orangutans, the more we find that they are a resilient species that can adapt to new challenges. For example, our colleague Marc Ancrenaz has discovered that orangutans can cover large distances by walking on the ground, and that they adapt their diet to new resources such as acacia or oil palm. If they are not hunted, these abilities may allow them to survive in the fragmented landscapes that now make up most of Borneo. People working on the ground know that the orangutan can be saved. It requires persistence, good collaboration with governments, strong support from local people, and help from companies that manage the land. Once forests are maintained and protected, and killing is stopped, orangutan populations can be stabilised. It might even allow them to slowly bounce back and recolonise forest areas where orangutans have disappeared in the past. We need to think outside of the box. For instance, a lot of effort and funding goes towards rescuing individual orangutans, who are then moved to a safer place where they can be rehabilitated. But while this may help individuals in desperate situations, it is a very expensive and ineffective way to deal with the overall conservation problem. To put things into perspective, we lost more than 100,000 orangutans in the past 16 years and saved perhaps 1,000 through rescues, translocations and rehabilitation in the same period.  If we really want to stop the decline, we must both protect forests and stop the killing within them. As most orangutans live outside protected areas, we need to get the communities and companies who manage their habitats on board. Here, there are many possibilities. For example, one oil palm plantation is now protecting 150 orangutans within its concession, showing that oil palm is not inevitably linked to the complete destruction of primate habitat.  On a larger scale, the Malaysian state of Sabah and the Indonesian province of Central Kalimantan, both in Borneo, intend to certify their entire production of palm oil as sustainable by the year 2025, which includes a zero-killing policy. At the same time, both countries are developing new long-term action plans for orangutan conservation.  We urge the governments of Indonesia and Malaysia to include firm strategies to stop the killing of orangutans. Because if we do not learn from past failures that stadium will eventually be empty, forever."
"A number of ancient settlement sites were recently discovered in the Amazon’s Upper Tapajós Basin. This is no El Dorado – although you’d be forgiven for thinking so. The press coverage demonstrates a fixation on the idea that the tropical New World may once have been the site of monumental societies, such as those in Egypt or Mesopotamia. The recent discoveries were heralded by Newsweek as “rewriting” the history of the Americas before Columbus: not a modest claim. The Guardian proclaimed: “Lost Amazon villages uncovered by archaeologists.” Meanwhile, the National Geographic (partly responsible for the funding of the project) announced that the “Amazon jungle was once home to millions more than previously thought”. This is far from the idea of a pristine landscape that conservationists have been alluding to for years. As one of the Exeter researchers noted to the Washington Post: “It seems that it was a mosaic of cultures.” News from the Amazon has long been concerned with “lost tribes” or “uncontacted peoples”. One 1970 documentary portrays the key element of the genre: native peoples resisting assimilation. In this century, the emphasis has shifted somewhat. Increasingly, native Amazonian peoples are portrayed not only as “lost”, but also occupying a natural realm that is in danger of being lost itself to oil exploration, mining and timber extraction. This was strikingly illustrated in 2008, when José Carlos dos Reis Meirelles Junior, a FUNAI official (Brazil’s national Indian agency) published dramatic and still widely reproduced images of exotically-dyed Indians trying to bring down aircraft with bows and arrows. Meirelles described the threats to such tribes and their land as “a monumental crime against the natural world”.   Meirelles acknowledged that efforts to forestall destructive timber exploitation were more effective if borne on the shoulders of “uncontacted” Indians, in part because the “exotic Indian” is a potent symbol to a metropolitan public.  Yet as noted in a review of a 2016 documentary that chronicled some of Meirelles’ efforts to draw attention to the Indians’ plight, there is a useful ambiguity in the term “uncontacted”. To the naïve observer, the term implies autonomy and isolation. But, in fact, it is a term used by FUNAI officials to identify groups that simply have no official relationship with those agents of the state empowered to act on their behalf. As Meirelles himself said when queried by The Guardian about the term:  All the peoples described as ‘isolated’ have had some kind of contact with us. Usually violent. What they don’t have is regular contact. But they’ve been using axes, machetes and iron pots for at least 100 years. The “lost” Indian of the present depicted as a living version of the Indian of the past (as opposed to what many regard as the composite, ersatz, mestiço derivative – that is, most Amazonians) continues to be a formidable icon of Amazonia, and is bolstered now by the notion of the discovery of a historical tropical civilisation. Journalistic accounts, after all, are still driven by a fascination with lost cities, lost tribes and the exotica of neo-tropicalism. And so these findings may seem to revolutionise our understanding of the Amazon. But beyond the numbers in this particular region (the authors of the recent study estimate that between 500,000 and a million people lived in the Upper Tapajós Basin), there is really very little new here. A very substantial literature has challenged the prevailing views about the pristine character of pre-Conquest Amazonia for decades (or longer). Ironically, in the same month that these discoveries were announced, two major contributors to the revised view of Amazonian history, Alfred Crosby and Denise Schann, died.  They are among a very large set of scholars whose work has challenged orthodox views centred around the claim that Amazonia is a “counterfeit paradise” intrinsically unsuited to any but the most marginal social existence. Evidence of social complexity in chiefdoms and proto-states, such as is further evidenced by the recent discovery, counters these claims. But the challenge to the image of Amazonian “green hell” has considerable historical depth. Indeed, the chronicler of the first European descent of the Amazon river, Gaspar de Carvajal, reported a density of riverbank populations in 1542 that stands in striking contrast to subsequent characterisations of Amazonia as a land of isolated, small-scale, forest-dwelling hunter-gatherers. Since then, many others have, in various ways, contributed to a reconfiguration of pre-modern Amazonia that refuses to succumb to the prevailing stereotypes. In fact, few historical Indian groups maintained lives anywhere near as isolated or pacific as prevailing picture postcard representations suggest. The same is true today. Indians are beleaguered by the state and resource hungry interlopers. They therefore generally maintain an existence characterised by high levels of social conflict (as they seek to defend territorial boundaries, for example), despair (notoriously high levels of suicide) and cultural disintegration. The repeated invocation of the Amazonia of myth – of lost tribes or lost cities – is easy to challenge on a factual basis, though such objections appear rather feeble in the face of the power of cliché. The clichés are far more comestible than the banality of profitable exploitation of Amazonian “cheap nature”, minerals, hydroelectric power, timber, and agricultural land available at minimal cost to enterprises able to extract at scale. But the typical portrayal of “lost peoples” beleaguered by capitalist industry hardly captures the long-term, implanted, and globalist character of resource exploitation in the region.  That the clichés prevail is not surprising. But it is disheartening that the relationship between the past and the present has been so regularly rendered opaque. We speak repeatedly of lost worlds, lost peoples, lost civilisations, as if this has occurred through some kind of natural process, rather than as a result of the persistent and systematic destruction of those societies (as well as their natural environments).  Being “lost”, misplaced or requiring “re-discovery” is not an intrinsic condition. Realistic assessment of what is happening in the course of Amazonian development is hardly encapsulated in postcard images and El Dorado fantasies."
"Writing in these pages last month, Robert Del Naja of Massive Attack articulated many of the concerns that the music industry is grappling with over its effect on the environment. The survival of the classical music industry relies very heavily on international touring. My colleagues and I at talent agency HarrisonParrott are this year celebrating our 50th anniversary; over the past five decades we have booked tens of thousands of concerts and performances around the world, for musicians from sopranos to saxophonists, conductors to cornet players.  In recent decades globalisation has opened markets and created audiences for western classical music far from its original roots in Europe. In the last 12 months alone HarrisonParrott has organised 38 international tours to more than 200 countries, many involving American and European orchestras travelling to Asia, which usually entails well over 100 people flying to different cities. Our roster is around 190 musicians, and many of them perform upwards of 100 concerts a year around the world. But now, faced with undeniable scientific evidence of manmade climate change, music and arts professionals must take a stand rather than blindly continuing with business as usual. We have a responsibility to galvanise our industry and question the established way of working in order to mitigate its ecological impact. Welcome work by the Tyndall Centre for Climate Research examines all the areas of impact touring has on the environment and recognises that the issue is complex: it cannot be solved by planting a set number of trees per tour. From audiences travelling to concerts to the power required by the halls, this crisis is the responsibility of all of us. Everyone must be conscious of their behaviour and acknowledge the active part they have to play. Planning permission for all new concert halls, for example, should only be given if the buildings will be carbon neutral. Existing concert halls must make radical changes to ensure they are as close to carbon neutral as possible. I’m proud of our musicians who are leading by example. Violinist Patricia Kopatchinskaja last season partnered with the musicians from the Orchester des Wandels (the Orchestra of Change) and performed works written as a reaction to the climate crisis, with all proceeds donated to environmental projects. Kopatchinskaja now organises her schedule so as to travel by train as much as possible, and our touring department plan tours that allow orchestras to avoid taking flights. As so often in debates about climate change, the Scandinavians are leading the way. The Norwegian conductor Tabita Berglund recently wrote: “Travelling back and forth, visiting a new orchestra every week, is not ultimately sustainable. There are more clever ways of organising ourselves, and these might bring new perspectives and values to our musical life. They might even create possibilities that we haven’t even thought about.” Her mix of urgency and optimism strikes exactly the right chord. So much of this debate takes place within a frame of comfort, with most of us kidding ourselves that we can keep on as we always have, and that by being a bit smarter – no single-use plastic bottles! – we can fix this. In truth, that time has long gone. Musicians and artists need to be disruptive in challenging assumptions about how our industry operates – and we all need to make real changes. Jasper Parrott is co-founder and executive chairman of HarrisonParrott Ltd"
nan
"Barnaby Joyce says he is “sick of the government being in my life” as he urged Australians to respect God, otherwise “we’re going to get nailed”. In a short video posted on social media late on Christmas Eve, the former National party leader is seen feeding cattle and reflecting on climate change, declaring that “new taxes” are not the way to address it.  “You’ve got to wonder what politicians do on Christmas Eve, well, when it’s drought, feed cattle,” Joyce says. Merry Christmas pic.twitter.com/QGYPv51pTN “Now you don’t have to convince me the climate is not changing, it is changing,” he says. “My problem has always been whether you believe new taxes are going to change it back. “I just don’t want the government any more in my life, I am sick of the government being in my life.” With the camera pointing to the sky, the former deputy prime minister urges Australians to respect God. “There’s a higher authority that’s beyond our comprehension – right up there in the sky. And unless we understand that that’s got to be respected, then we’re just fools. We’re going to get nailed.” Social media users commenting on the post were quick to point out that Joyce was a member of the government and that he was free to resign if he wanted it out of his life. Had to check I didn’t make this video. https://t.co/7gIjT0qb8C"
"Bullfighting appears to be facing tough times once more. As many as 76% of the Spanish public may oppose it receiving public funding. What’s more, the conservative Partido Popular has just lost its absolute majority in the Spanish parliament, which it had been using to support bullfighting. This follows the loss of key city councils to allies of Podemos, which recently resulted in Madrid scrapping its longstanding subsidy to the oldest of the country’s 52 bullfighting academies.  The European parliament also recently voted to prevent Common Agricultural Policy (CAP) subsidies going to breeders of fighting bulls – potentially affecting bull-breeding estates in France and Spain, where bulls die in the arena.  Opponents see bullfighting as a barbarous and medieval relic which has no place in modern Europe. But who are these 21st-century “barbarians” who breed fighting bulls? And what do we know about the lives of the animals themselves, beyond their deaths on the torero’s sword? Probably not very much, in most cases. But as an anthropologist who worked for 15 months on a bull-breeding estate in Andalusia, I can offer some insight into the people who care for and know these animals.  “Care” and “know” are the right words here, incidentally. The job of the foreman on bull-breeding estates is to care for (“cuidar”) the herd. To care for fighting bulls means to know (“conocer”) them, so the foreman is often referred to as the “conocedor”: the one who knows. The conocedor is in charge of the everyday well-being of the bulls, with a particular focus on feeding up and exercising animals which will bear the colours of the estate at bullfights.  I worked closely with Joaquín, the conocedor of the Partido de Resina bull-breeding estate. He was an animal lover. His little dogs, Mona and Mono, were sleek working animals. They got more cuts of cured ham than I did. And while Joaquín was aware that raising bulls was a commercial endeavour, caring and good animal husbandry were central aspects of his job.    The bulls’ psychological and physical well-being is part of what determines whether they perform to their potential. This encourages breeders to raise them as “naturally” as possible: in herds, with varied grazing, space, shade, dust baths, water and hidden spots to which they can retreat. These formidable creatures are incredibly sensitive to change. To ensure proper care and minimise disruptions, the foreman works with a team of cowhands, working horses, the estate owner/manager, secretaries, grounds staff, vets, ethologists and even nutritionists. As with any industry, standards can vary. I cannot speak for all bull breeders, but I certainly saw how seriously people took correct care and a modern approach in Andalusia. The world of the bulls is often labelled “traditional”, but breeders don’t oppose modernity. These “barbarians” have their own vision of the future, which actually complements the CAP in some respects. Aside from food production – and let’s not forget fighting bulls are high-quality beef animals – CAP subsidies are intended to support the sustainable management of natural resources and rural economies. Partido de Resina is an island of biodiversity: around 500 hectares of open woods and marshland surrounded by a sea of monotonous orange, olive and peach plantations.   You could of course argue that commercial horticulture employs more locals, or that there are other ways of protecting biodiversity which do not involve bullfighting. You might be right. Right now though, outside Seville – and across Spain, France, Portugal and Latin America – there are vast stretches of bull breeding land that are already spaces of biodiversity. The Common Agricultural Policy is modern: progressive, science-based, future-oriented and bureaucratic. So are many estates in the world of breeding fighting bulls. Whatever your view, the European parliament’s decision to ban subsidies for bull breeders will be diffiult to enact. It would require legistlative change to the CAP, which is a sticky area of EU politics. After the vote, the European Commission informed the parliament that there was no legal basis upon which to enact the amendment. Every such challenge pushes the scattered bullfighting lobby to unite and strengthen its legal position. That could be important in future battles, but for now the victory for the European Greens who tabled the budget amendment is purely symbolic.  As for the the state of bullfighting more generally, things are more complicated than they might appear. Recent attendance figures from the Spanish ministry of culture don’t support a simple narrative of decline. Though there was a clear dip during Spain’s economic crisis, attendance in the year 2014/2015 overtook pre-crisis figures. The industry was also placed under government protection in Spain after the government voted in 2013 to give bullfighting intangible cultural heritage status. We are certainly not talking about a one-way losing battle.  So we should take care when it comes to derogative rhetoric, particularly about poorly understood traditions. It’s worth noting that attacks on bullfighting, while often out of genuine concern for the suffering of animals, also come from a tradition of northern moral supremacy. Not surprisingly, the European parliament vote on the anti-bullfighting amendment largely divided along a north-south axis, with 57% of Spanish MEPs voting against.  There is still a large public out there who appreciate bulls and bullfighting: 9.5% of Spaniards attended events involving fighting bulls in 2014-15. These people live in the same modern Europe as the rest of us. Anyone who condemns bullfighting as barbaric should not judge until they have looked beyond the arena to the wider world of the bulls."
"
Share this...FacebookTwitterClimate models in distress: Problems with forecast performance give cause to worry
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
The 2015/16 El Nino 2015/16 is over, and so are the celebrations by the climate alarmists. It’s becoming increasingly clear that the projections made by the climate models were wildly exaggerated. Already in April 2015 a Duke University press release stated that the worst IPCC temperature prognoses need to be discarded immediately:
Global Warming More Moderate Than Worst-Case Models
A new study based on 1,000 years of temperature records suggests global warming is not progressing as fast as it would under the most severe emissions scenarios outlined by the Intergovernmental Panel on Climate Change (IPCC).  
“Based on our analysis, a middle-of-the-road warming scenario is more likely, at least for now,” said Patrick T. Brown, a doctoral student in climatology at Duke University’s Nicholas School of the Environment. “But this could change.” The Duke-led study shows that natural variability in surface temperatures — caused by interactions between the ocean and atmosphere, and other natural factors — can account for observed changes in the recent rates of warming from decade to decade. The researchers say these “climate wiggles” can slow or speed the rate of warming from decade to decade, and accentuate or offset the effects of increases in greenhouse gas concentrations. If not properly explained and accounted for, they may skew the reliability of climate models and lead to over-interpretation of short-term temperature trends.
The research, published today in the peer-reviewed journal Scientific Reports, uses empirical data, rather than the more commonly used climate models, to estimate  decade-to-decade variability. “At any given time, we could start warming at a faster rate if greenhouse gas concentrations in the atmosphere increase without any offsetting changes in aerosol concentrations or natural variability,” said Wenhong Li, assistant professor of climate at Duke, who conducted the study with Brown. The team examined whether climate models, such as those used by the IPCC, accurately account for natural chaotic variability that can occur in the rate of global warming as a result of interactions between the ocean and atmosphere, and other natural factors.
To test how accurate climate models are at accounting for variations in the rate of warming, Brown and Li, along with colleagues from San Jose State University and the USDA, created a new statistical model based on reconstructed empirical records of surface temperatures over the last 1,000 years. “By comparing our model against theirs, we found that climate models largely get the ‘big picture’ right but seem to underestimate the magnitude of natural decade-to-decade climate wiggles,” Brown said. “Our model shows these wiggles can be big enough that they could have accounted for a reasonable portion of the accelerated warming we experienced from 1975 to 2000, as well as the reduced rate in warming that occurred from 2002 to 2013.”
Further comparative analysis of the models revealed another intriguing insight. “Statistically, it’s pretty unlikely that an 11-year hiatus in warming, like the one we saw at the start of this century, would occur if the underlying human-caused warming was progressing at a rate as fast as the most severe IPCC projections,” Brown said. “Hiatus periods of 11 years or longer are more likely to occur under a middle-of-the-road scenario.” Under the IPCC’s middle-of-the-road scenario, there was a 70 percent likelihood that at least one hiatus lasting 11 years or longer would occur between 1993 and 2050, Brown said.  “That matches up well with what we’re seeing.” There’s no guarantee, however, that this rate of warming will remain steady in coming years, Li stressed. “Our analysis clearly shows that we shouldn’t expect the observed rates of warming to be constant. They can and do change.”
Paper: Patrick T. Brown, Wenhong Li, Eugene C. Cordero and Steven A. Mauget. Comparing the Model-Simulated Global Warming Signal to Observations Using Empirical Estimates of Unforced Noise. Scientific Reports, April 21, 2015 DOI: 10.1038/srep09957“
Modelers like to pat each other on the back. Well modelled, dear colleague! Calibration tests using the past of course are all part of checking models. This in many cases starts with the Little Ice Age, which was the coldest phase of the past 10,000 years. When the models appear to reconstruct the warming since then, the joy runs quite high: Look here, everything is super.
The main driver of warming, however, remains unclear. Isn’t it logical that a re-warming follows a natural cooling? Is it a coincidence that CO2 rose during this phase?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




More honest would be using calibration tests going back to the Medieval Warm Period  Only when the preindustrial warm phases are successfully reproduced can we say that the models are confirmed.
In 2015 Gómez-Navarro et al used the Little Ice Age trick. They began their test at 1500 AD. i.e. during the mentioned cold phase. The result is no surprise: The general trend is “confirmed”, but in detail it doesn’t work. Here’s the abstract from Climate of the Past:
A regional climate palaeosimulation for Europe in the period 1500–1990 – Part 2: Shortcomings and strengths of models and reconstructions
This study compares gridded European seasonal series of surface air temperature (SAT) and precipitation (PRE) reconstructions with a regional climate simulation over the period 1500–1990. The area is analysed separately for nine subareas that represent the majority of the climate diversity in the European sector. In their spatial structure, an overall good agreement is found between the reconstructed and simulated climate features across Europe, supporting consistency in both products. Systematic biases between both data sets can be explained by a priori known deficiencies in the simulation. Simulations and reconstructions, however, largely differ in the temporal evolution of past climate for European subregions. In particular, the simulated anomalies during the Maunder and Dalton minima show stronger response to changes in the external forcings than recorded in the reconstructions. Although this disagreement is to some extent expected given the prominent role of internal variability in the evolution of regional temperature and precipitation, a certain degree of agreement is a priori expected in variables directly affected by external forcings. In this sense, the inability of the model to reproduce a warm period similar to that recorded for the winters during the first decades of the 18th century in the reconstructions is indicative of fundamental limitations in the simulation that preclude reproducing exceptionally anomalous conditions. Despite these limitations, the simulated climate is a physically consistent data set, which can be used as a benchmark to analyse the consistency and limitations of gridded reconstructions of different variables. A comparison of the leading modes of SAT and PRE variability indicates that reconstructions are too simplistic, especially for precipitation, which is associated with the linear statistical techniques used to generate the reconstructions. The analysis of the co-variability between sea level pressure (SLP) and SAT and PRE in the simulation yields a result which resembles the canonical co-variability recorded in the observations for the 20th century. However, the same analysis for reconstructions exhibits anomalously low correlations, which points towards a lack of dynamical consistency between independent reconstructions.”
In January 2017 Benjamin Santer et al attempted to justify the validity of models. In the Journal of Climate they compared satellite data with the simulations of temperature over the last 18 years. The result: The models calculated a warming that was one and a half times more than what was measured in reality. Abstract:
Comparing Tropospheric Warming in Climate Models and Satellite Data
Updated and improved satellite retrievals of the temperature of the mid-to-upper troposphere (TMT) are used to address key questions about the size and significance of TMT trends, agreement with model-derived TMT values, and whether models and satellite data show similar vertical profiles of warming. A recent study claimed that TMT trends over 1979 and 2015 are 3 times larger in climate models than in satellite data but did not correct for the contribution TMT trends receive from stratospheric cooling. Here, it is shown that the average ratio of modeled and observed TMT trends is sensitive to both satellite data uncertainties and model–data differences in stratospheric cooling. When the impact of lower-stratospheric cooling on TMT is accounted for, and when the most recent versions of satellite datasets are used, the previously claimed ratio of three between simulated and observed near-global TMT trends is reduced to approximately 1.7. Next, the validity of the statement that satellite data show no significant tropospheric warming over the last 18 years is assessed. This claim is not supported by the current analysis: in five out of six corrected satellite TMT records, significant global-scale tropospheric warming has occurred within the last 18 years. Finally, long-standing concerns are examined regarding discrepancies in modeled and observed vertical profiles of warming in the tropical atmosphere. It is shown that amplification of tropical warming between the lower and mid-to-upper troposphere is now in close agreement in the average of 37 climate models and in one updated satellite record.”
See comments on this at WUWT.
Judith Curry reported on a PhD thesis in the Netherlands, where the author was involved with model results on a daily basis, which fired harsh criticism. An excerpt of the paper by Alexander Bakker:
In 2006, I joined KNMI to work on a project “Tailoring climate information for impact assessments”. I was involved in many projects often in close cooperation with professional users. In most of my projects, I explicitly or implicitly relied on General Circulation Models (GCM) as the most credible tool to assess climate change for impact assessments. Yet, in the course of time, I became concerned about the dominant role of GCMs. During my almost eight year employment, I have been regularly confronted with large model biases. Virtually in all cases, the model bias appeared larger than the projected climate change, even for mean daily temperature. It was my job to make something ’useful’ and ’usable’ from those biased data. More and more, I started to doubt that the ’climate modelling paradigm’ can provide ’useful’ and ’usable’ quantitative estimates of climate change.
After finishing four peer-reviewed articles, I concluded that I could not defend one of the major principles underlying the work anymore. Therefore, my supervisors, Bart van den Hurk and Janette Bessembinder, and I agreed to start again on a thesis that intends to explain the caveats of the ’climate modelling paradigm’ that I have been working in for the last eight years and to give direction to alternative strategies to cope with climate related risks. This was quite a challenge. After one year hard work a manuscript had formed that I was proud of and that I could defend and that had my supervisors’ approval. Yet, the reading committee thought differently.
According to Bart, he has never supervised a thesis that received so many critical comments. Many of my propositions appeared too bold and needed some nuance and better embedding within the existing literature. On the other hand, working exactly on the data-related intersection between the climate and impact community may have provided me a unique position where contradictions and nontrivialities of working in the ’climate modelling paradigm’ typically come to light. Also, not being familiar with the complete relevant literature may have been an advantage. In this way, I could authentically focus on the ’scientific adequacy’ of climate assessments and on the ’non- trivialities’ of translating the scientific information to user applications, solely biased by my daily practice.”
Read more at Judith Curry.
Share this...FacebookTwitter "
"If the prophets of technology are to be believed, the best hope for solving the climate crisis is ever more efficient batteries. But the race to produce enough materials for this energy-storage revolution is creating a host of other environmental problems, as cobalt-producing nations like the Democratic Republic of the Congo, Zambia and Cuba are discovering.Lung disease and heart failure have been linked to high levels of this element, while the mines that produce it are blamed for devastated landscapes, water pollution, contaminated crops and a loss of soil fertility. Scientists are also investigating a possible link to cancer.As with any chemical, the risks depend on the amount and duration of exposure. Cobalt is a metal that occurs naturally in rocks, water, plants, and animals. It is less toxic than many other metals. At low levels, it is beneficial to human health and is a component of vitamin B12.  But the dangers of high doses are increasingly apparent. They were first discovered in the 1960s, when a Canadian brewer started adding cobalt to beer to ensure a consistently foamy head. A surge of fatal heart attacks among heavy drinkers, who also had poor diets, was linked to the cobalt additive. More recently, German doctors have questioned whether surgical implants containing cobalt might also be causing hypersensitivity reactions.Cobalt is used in alloys, semiconductors, fertiliser, as a drying agent for varnish and enamel coating for steel. In the form of cobalt sulphate, it is particularly important in lithium batteries, where it acts as a cathode stabiliser.These lithium-ion batteries are increasingly in demand for electric cars, laptops and mobile phones, which means cobalt – once deemed a worthless chemical – is now the object of a geo-strategic rivalry between the world’s biggest economies. It is also potentially exposing humans and other species to greater doses.A study this year noted that global production had increased more than sevenfold between 2008 and 2015 with an increasingly evident impact. “The appearance of cobalt levels exceeding the environmental threshold levels has led, however, to disturbances in the proper functioning of living organisms,” the paper concluded. Another paper said extended blood concentrations of more than 700 µg led to heart problems and impaired eyesight and hearing. It considered pregnant women who ingest food or drinks containing high levels of the chemical at greatest risk. Earlier research has detected side-effects including diarrhoea, headaches, blood pressure changes and damage to the immunological system. High concentrations of cobalt have been linked to the death of crops and worms  vital for soil fertility. The Centers for Disease Control and Prevention in the US warns that chronic exposure can cause “hard metal disease” and even skin contact with cobalt salts or hard metals can result in rashes. They say the safe workweek limit is 0.1 milligrams per cubic metres.The environmental impact extends through the life-cycle of the product from refineries, battery plants, consumers goods manufacturers, electronic recycling facilities and waste dumps. Among the most affected are workers at poorly-regulated mines. This has allegedly reached alarming levels in the Congo, which produces more than 60% of the world’s cobalt. Concerns have also been reported in many other countries, where the mineral is often mined in tandem with nickel, copper or silver. In Australia, which is the world’s second biggest producer, authorities issued the Whim Creek mine in Pilbara with an environmental protection notice after floods led to levels of cobalt, copper and other metals significantly above water quality guidelines. In Cuba – which has the world’s third biggest cobalt reserves – satellite analysis of the huge open-cast nickel and cobalt mine at Moa in Holguín Province appears to show what researchers have described as a “lunar-like landscape” devoid of life over 570 hectares (1,408 acres), while they say their research shows pollution plumes have contaminated 8km of coastline and 10km of the Cabañas River. Despite these environmental problems, cobalt production is seen as the key to rapprochement with the US, which needs the mineral for its electric car industry and wants to ease Chinese domination of the global supply chain.In Zambia, studies of soil and mango fruit grown near copper and cobalt mines have revealed metals above the safety limit. NGOs say miners in the country are also prone to silicosis and tuberculosis. It is a similar story at Madagascar’s biggest foreign investment project – the $8bn (£5.9bn) Ambatovy nickel and cobalt mining complex near Toamasina, which has been blamed for air and water pollution, as well as health problems among the local population. Official data, independent reports and scientific studies are scarcer in other producing countries, though the authorities appear to be concerned. In China inspections by the Ministry of Ecology and Environment in June 2018 temporarily halted production in Jiangxi province, which is the global centre of cobalt refining. Two years ago, the Philippines closed or suspended 17 nickel mines – several of which also produce cobalt – because of environmental concerns.The concerns are likely to grow along with production. It is an exaggeration to say lithium-ion batteries will become the new oil, but a low-carbon future will almost certainly mean high-cobalt energy storage. In 2017, the world’s battery makers used 41,000 tonnes of cobalt (a third of total production). By 2025, this is expected to increase to 117,000 tonnes. The surge in production will increase the dangers of exposure to high doses. To prevent this, more studies and better safeguards are needed now – particularly in DRC and other countries where people and habitats are most at risk. Failure to do this will mean batteries wreck lives rather than saving the climate. "
"
Share this...FacebookTwitterThe ‘Energiewende’ (transition to green energies) risks leading to a complete meltdown of Germany’s power generation sector.
The latest news is that German electricity giant Eon expects to post a massive 12.4 billion euro loss for the year 2016, NTV news site writes here. Careful not to link the loss to Germany’s failing renewable energy bid, NTV blames it on Eon subsidiary Uniper and its write-downs for “spun-off nuclear power plant business” and the “strongly fallen wholesale power prices“.

Photo: Eon
Eon share prices plummeted from €7.57 a share earlier this weak to €6.98 by early Thursday morning, before clawing back up to €7.15 in Friday trading.
The figure is only a preliminary estimate, and the final figure will be released on March 15. But the Handelsblatt writes that the loss could even be higher: “It’s going to be even higher,” say those within the company.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Handelsblatt reports that “at least 1000 jobs” are planned to be slashed by Eon in an effort to get the cost situation under control.
Massive financial trauma
Just days ago NTZ wrote here that another of Germany’s major power producers, RWE, also posted staggering losses of 5.7 billion euros.
Eon’s latest loss comes in the wake of a 7-billion euro loss the German power giant posted a year earlier, in 2015.
Once steady makers of profits and providers of solid, high-paying technical and engineering jobs, Germany’s traditional power industry has been bleeding profusely since the Energiewende (transition to renewable energies) has really took hold. Jobs have been lost by the thousands.
The German power grid used to be considered as one of the most stable worldwide, providing low-cost and reliable electricity to consumers, but has since deteriorated due to distorted market conditions and the wildly fluctuating wind and solar power that is required to be fed in.
 
Share this...FacebookTwitter "
"The 2019 Guardian and Observer climate emergency charity appeal, aimed at planting trees and protecting forests and woodlands, has raised more than £250,000 in less than a fortnight. The appeal is supporting four charities which promote environmental and social justice through natural climate solutions, ranging from safeguarding the Amazon rainforest to rewilding parts of the Scottish Highlands, to planting trees in Britain’s towns, cities and countryside  The four charities are: Woodland Trust, Trees for Life, Trees for Cities and Global Greengrants Fund UK. Responding to the news, Steve Micklewright, the chief executive of Trees for Life, said he was overwhelmed by the generosity of Guardian and Observer readers. “Through their support, Trees for Life will be able to do more in the fight against climate chaos through natural solutions and enable wildlife to flourish and communities to thrive.” The chief executive of Trees for Cities, David Elliott, said: “The amazing support for this appeal will not only result in thousands of trees being planted across the UK and internationally, but also demonstrates that the climate and our natural environment are loud and clear priorities in the public’s mindset.” Guardian and Observer journalists will be taking phone donations in person at the annual charity telethon between 10am and 6pm this Saturday. Those taking readers’ calls include: Katharine Viner, Polly Toynbee, Owen Jones, Gary Younge, Marina Hyde, George Monbiot, John Crace, Anushka Asthana, Jonathan Freedland and Sali Hughes. Introducing the appeal earlier this month, the Guardian editor-in-chief, Viner, said that while it was crucial to remain focused on the giant steps that governments and corporations must take to combat the climate crisis, our partner charities highlighted practical actions that citizens could take to renew nature and the planet. She wrote: “Planting and protecting trees is a positive way that we can help. Trees are vital in producing oxygen and absorbing carbon dioxide from the atmosphere. They provide a natural habitat for animals, birds and insects and stem the decline of biodiversity. “They can prevent flooding and soil erosion. They provide shelter and shade, and reduce air and noise pollution. Forests and woodlands are natural sources of beauty, wellbeing and peace.” "
"Biological evolution, the changes in living organisms over time, is often considered an elusive and long process that cannot be observed during a human lifespan. But is that really the case? And is there evidence that we can see it happening right before our eyes? Evolution is a process that occurs at a different pace in different organisms. For instance, paleontologists have shown, thanks to the fossil record, that it took a million years for whales to evolve from their land-dwelling mammalian ancestors.  But evolution can also be observed and monitored in living organisms within a human lifetime. This is true for infectious agents, such as bacteria and parasites, that can evolve extremely quickly to resist the drugs we use to fight them. But it is also the case for larger organisms, such as vertebrates – the back-boned animals. One of the most famous examples was documented in a population of finches living on Daphne Major island in the Galapagos archipelago. In this case, ground finches Geospiza fortis evolved larger beaks after a major drought in 1977. During this harsh period, the small seeds on which the ground finches were feeding on became scarcer, and most of the birds died.  However, scientists noticed that the mortality rate was lower among larger birds, with a larger beak. They were able to crush bigger and harder seeds to feed on while the small seeds were depleted. Large-beaked finches had a great advantage over their small-beaked relatives to survive these tough conditions. They reproduced more and transmitted this trait to their offspring. Following the drought, scientists observed a shift towards larger beaks and body size among subsequent generations.  Strikingly, researchers reported a reversal towards small body and beak size after large rain falls and abundant small seed supply in 1983. Monitoring the finch population over the years has thus allowed scientists to observe their rapid evolution and to link it to different environmental changes.  The fact that evolution can be rapid not only allows scientists to observe it in action, it also means that they can perform real-time experiments in the field to test their hypotheses by changing specific environmental parameters.  Recently, a team of scientists in Florida demonstrated that rapid evolution of a species can be triggered by a negative interaction with a competitor. To do so, the scientists introduced an invasive species of anole lizard to a group of small islands that shared the same lifestyle and diet as the native one, Anolis carolinensis.  The invader anoles forced the native ones to move from their original habitat on the forest floor and into the trees. Scientists were not only able to follow the rapid shift in the lifestyle of the native anole species (they perch higher and higher in the trees over time), but also observed that it involved rapid changes to their body shape. Within only 15 years (20 generations), the native anole species evolved larger toe pads with stickier scales, enabling them to climb more efficiently in their new, higher habitat. Closer to home, many invertebrates change quickly, too. Bed bugs, for example, have rapidly evolved in the last few decades, developing tougher exoskeletons to protect them from the insecticides and other poisons in their increasingly urban environment. In his On the Origin of Species, Darwin considered evolution as a very slow process, the outcome of which would have taken much more time than an human lifespan. Of course, Darwin’s assumption was making sense of things in the scientific context of his epoch, but the field observations and experiments conducted over the past 40 years have shown that animals often evolve very rapidly indeed. Life, it seems, never stays still."
"It is painful to watch political denial in action. Believe me, I’ve been down this road before. I lived through Aids denialism in South Africa and I’m witnessing denial again in Australia. In the last few weeks, as fires have raged across New South Wales, and as the nation has grown increasingly furious about Scott Morrison’s lack of leadership, I have felt like I am in a time warp.  In the late 1990s and early 2000s, South Africa’s President Thabo Mbeki inexplicably decided to gaslight the nation by denying the existence of human immune deficiency virus – HIV. He had just taken the reins from Nelson Mandela and the country was shocked. We quickly mobilised to counter the denial. There was no time to dither. For my generation, the fight against Aids denialism was existential – we were literally fighting for our lives. The parallels to the current fight for climate justice are stark. The same obfuscation is on display, the same arrogance. Journalists in South Africa had to plead with politicians to answer their questions. The same desperation is apparent in the Australian media today. In South Africa the media and civil society refused to stop asking questions. They hounded the government and embarrassed the president in international forums. The sustained efforts paid off. Today the South African government runs the largest antiretroviral program in the world and has won global accolades for its rollout. Despite the positive outcome, the entire debacle was an epic waste of time and cost many lives – a Harvard study found that 300,000 people lost their lives during the period when South Africa’s president was debating the merits of virology and science. Australia cannot afford a distraction of this scale. And, while there are many parallels between South Africa and Australia, there are also some important differences. While Mbeki’s form of denial was crude and fairly straightforward, Scott Morrison’s is far more slippery and clearly buttressed by political expediency. In fact, it is not clear what the prime minister himself believes in respect to global warming. Last week he affirmed that it is a real phenomenon affecting the bushfires, but only did so after mounting pressure from media outlets and angry, fire-hit communities. In addition, over the last few months, Morrison has been deeply disdainful of climate activists. He has indulged in climate sadism – the phenomenon of mocking those who are outspoken about the climate crisis in order to paint them as hysterical. Using language and tactics straight out of the Trump playbook, Morrison accused Greta Thunberg of causing young people “needless anxiety,” and has threatened to crack down on climate justice protesters. By minimising the concerns of activists, Morrison has proven himself adept at deploying one of the most powerful rightwing tactics of the moment – trolling. Unfortunately for Morrison, playing people of different political affiliations against one another isn’t a smart long-term strategy in the face of an existential threat. The quiet Australians whose virtues he has extolled don’t necessarily have different views about climate change from the noisy ones who seem to bother him so much. Morrison can be forgiven for thinking this is a wining formula. After all, divisive rhetoric that pits one kind of person against another has been useful in the culture wars. But, on matters of the environment, the strategy of polarisation is almost sure to backfire in the long term. This is because despite what the Liberal party’s lunatic backbenchers say, 61% of Australians think “global warming is a serious and pressing problem and are prepared to take measures to address it even if it involves significant costs”. In other words, climate change is a bipartisan issue. If this is the case – and events seem to prove it as everyone from schoolchildren to firefighters have come out supporting basic science and challenging the government to do more – Morrison will need to change course quickly. A year ago embracing the facts of climate change cost Malcolm Turnbull his position as party leader. The bluster and scare tactics secured a victory for Morrison and his team but they cannot take that victory for granted. If the PM does not read the public sentiment properly he could lose his footing by being out of touch with people’s genuine anxieties about the fate of the planet. Ultimately, South Africa’s president was turfed out by the party faithful. The activists played their part but it was the so-called “silent majority” who destroyed his political career. I learned a lot during that era. I have no doubt that when the “quiet” Australians join the “noisy” ones to protect our future, Morrison’s petty climate denial will come to an abrupt end. Sisonke Msimang writes about democracy and politics, and is the author of Always Another Country: A memoir of Exile and Home"
"
Share this...FacebookTwitterIt’s good to see that I am not the only person looking critically at Germany’s rather inept attempt to switch over to green energy sources in order to reduce CO2 emissions.
The environmentalprogress.org site here presents a good overview of Germany’s recent performance when it comes to reducing so-called “greenhouse gases”. Unfortunately German citizens have not seen any success recently for the tens of billions of euros they are paying extra for the “Energiewende” (transition to renewable energy).
A new Environmental Progress analysis finds that “German emissions increased in 2016 for a second year in a row“, blaming the result on “the country closing one of its nuclear plants and replacing it with coal and natural gas“. Obviously wind and sun failed to step in and do the job.
Environmental Progress reports the shocking result:
Not only did new solar and wind not make up for the lost nuclear, the percentage of time during 2016 that solar and wind produced electricity declined dramatically.
Germany added a whopping 10 percent more wind turbine capacity and 2.5 percent more solar panel capacity between 2015 and 2016, but generated less than one percent more electricity from wind and generated one percent less electricity from solar.”
The site describes Germany’s wild variability that the country has to deal with producing power from sun and wind.
2016’s rise to 916 gigatonnes of CO2 extends Germany’s streak of failing to lower its CO2 emissions to 8 years. The following chart goes to 2014. The year 2015 saw 908 gigatonnes CO2 emissions compared to 902 in 2014.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Chart source: UBA Umweltbundesamt (Federal Office of the Environment). 
This means Germany literally has made virtually no progress at all over the past decade. The latest jump in CO2 emissions make the chances of Germany reaching its 2020 CO2 reductions target even far more remote. Add to this that subsidies for wind and solar power recently have been watered down and the surge of up to 2 million refugees will boost demand for energy. Germany’s commitment to fulfilling the Paris Agreement is looking like a real farce.
Another fact that shows that solar and wind will never work: Environmental Progress points out that even if Germany adds 50% more solar panel capacity by 2030, it will boost solar’s share of power from 6% to 9 percent.
Germany’s Energiewende has only succeeded in massively elevating Germany’s consumer power prices, making its power almost twice as expensive as power in neighboring France, which relies heavily on nuclear. While France’s power is half the cost, the country also emits far less CO2 from electricity production:
 Chart source: http://www.environmentalprogress.org.
That’s what one would call success. Why some countries are still racing into the renewable energy foray despite the German debacle, remains a mystery.
Read all of the Environmental Progress report here.
 
Share this...FacebookTwitter "
"Like grave-robbers, they come at the dead of night, wearing camouflage and dark clothes to avoid detection. Armed with increasingly powerful metal detectors, they work their way across the fields, digging holes wherever they find a target. Landowners wake to find their crops trashed and dotted with holes. Nobody can ever know what they found, as any artefacts are rapidly sold through online auctions or smuggled out of the country. They are called nighthawks – and they are the bane of archaeologists across the country. The English landscape is filled with ancient sites – from prehistoric forts and barrows, to Roman towns and villas, medieval villages and industrial remains. Each archaeological site has a unique story to tell and will often contain buried artefacts that help us to understand our history. Around 37,000 of these sites have been identified as ancient monuments: protected from development and treasure hunters.  For many years, archaeologists have been deeply divided on the subject of metal detecting. Some see detectorists as an army of keen amateurs, who go brave all weathers in the hope that one day, they will strike lucky. Provided that they work within the law and with the permission of landowners, they are generally seen as harmless, even beneficial.  Detectorists are encouraged to report their finds to the Portable Antiquities Scheme – a massive recording operation run through the British Museum – which maintains a database of every item that has been reported. The website contains pictures of more than 1m objects, based on more than 700,000 records. This huge amount of data has helped archaeologists to find new sites and to better understand little-known periods of our history as represented by artefacts, rather than buildings and physical remains. Some suspect that this is just the tip of the iceberg of the many important finds that have been made – possibly as many as 4m – in recent years. But there is a dark side to this seemingly harmless hobby. A small minority of treasure hunters try to evade permissions and go onto well-known, protected sites, wielding powerful metal detectors with the intention of stealing valuable artefacts.  England and Wales are unusual in that metal detecting is legal, provided that detectorists avoid ancient monuments and declare any treasure (defined as gold and silver or prehistoric metalwork) to the Coroner. In Scotland and Northern Ireland, detectorists must obtain a licence to search anywhere, while in most of continental Europe, metal detecting is a crime.  The rather more liberal approach taken in this country means that we now know about many more sites than archaeologists alone could have discovered. But it also means we have a serious problem with looting which, until now, authorities have largely failed to face up to: police often neglected to prosecute and magistrates were reluctant to convict. In the past, the ambiguous legal position on heritage crime has often allowed those arrested to plead ignorance, by claiming they didn’t realise that the site was protected, or that they even needed permission. In a joint investigation between the University of Bristol and the BBC, we set out to discover just how prevalent night-hawking is. Fortunately, we now have new motion sensing, infrared camera traps, which can film at night time without artificial lighting – a technology largely developed for wildlife photography.  We set up six of these cameras around a well-known Roman settlement and protected ancient monument in the Cotswolds, and retired for a week to see what we might capture. There were, of course, several deer and foxes, but to our amazement our cameras also caught the full details of a night-hawking operation.  The group arrived at 10.30pm, wearing full camouflage and beanie hats, and armed with powerful metal detectors. They stayed for around four hours, and we filmed them scanning the fields and digging holes across the site. A getaway car finally picked them up at 2am. We have no idea if they found anything significant or not but they were clearly equipped with the intention of looting, just as a burglar with a crowbar is equipped to steal. The investigation aired on Inside Out West, and you can view the whole episode on BBC iPlayer. Coincidentally, around the time of our investigation, the Sentencing Council – which produces independent guidelines on sentencing for the judiciary – revised its recommendations on heritage crime. Now, night-hawking is classed as an aggravated harm, along with stealing from war memorials and stripping church roofs.  We hope that stiffer sentences will deter the nighthawks, and that new technologies will make it much easier to collect evidence of wrongdoing. Now, for the first time, it looks like we might just have the tools we need to defeat the nighthawks, and save our heritage for future generations."
nan
"
Share this...FacebookTwitterIt’s time for wind energy proponents to admit that their well-intended idea of wind energy has in fact had disastrous ecological consequences.
No technological development has ever so negatively impacted the environment and landscape like wind turbines have. Not only do they blight the scenic landscape and make people living near them ill, they are a serious killer of avian wildlife, as made evident by a recent German ZDF Terra X documentary shows (starts at 34:15 min). Hat-tip: Alessandra E.

Wind turbines in fact do pose serious threat to endangered birds. Image cropped from ZDF Terra X.
One of Germany’s most protected bird species is the endangered red kite hawk. Today it faces a threat that is unprecedented: towering wind turbines strewn across the German landscape. The ZDF public television documentary reveals that the measures enacted by government wind park approval authorities have done nothing to protect this predatory bird.
The segment focusses on the southwest German state of Baden Württemberg, where its Green state minister is attempting to force through the construction of thousands of turbines on the regions idyllic landscape in a bid to go green.
To survive, the red kite finds its meals on the ground, and so it’s only natural that its sharp eyes remain focussed downward, and not ahead. That habit spells huge trouble for the bird in wind turbine regions. According to environmental journalist Andreas Kieling: “Ornithologists and experts have called wind turbines bird shredders.”
Worldwide, the ZDF reports, only about 25,000 pairs of the red kite remain — 60% of them are in wind-turbine country Germany.
Ignorance, corruption and criminal sabotage
Using a fake owl (owls are the enemies of red kites) as bait (37:20), researchers caught a red kite and tagged it with transmitter, thus allowing them to later track the bird’s flight patterns and the actual living space the bird really requires. As the results will show, the living space required by red kites is far greater than what is claimed by the wind industry and the officials who approve the parks.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Wind turbine approval boards have the responsibility of keeping wind turbines at a safe distance away. Unfortunately, likely due to a mixture of ignorance and outright corruption, the wind turbine rules in many cases call for a setback distance of a mere 1000 meters from a nest. We reported here last year of how stork nests were likely criminally sabotaged in order to clear the way for wind park construction approval!
Need 12 sq. km of space, and not 3 sq km.
Just how far the birds fly from their depends strongly on how far they have to go to find their prey. In the ZDF Terra X documentary, days later the researchers provided a graphical image of the flight activity of the tagged bird.

Flight area and plot of red kite activity after 30 days. Image cropped from ZDF Terra X.
The result is that the endangered red kite needs far more than a single measly 1 kilometer setback distance and 3 sq km of safe activity area as often claimed, but rather it needs some 12 sq km of space. In fact the examined bird located near Lake Constance flew as far as 19 km away from her nest (41:05). Other bird species showed similar patterns and space needs, yet turbine approval boards insist the current requirements are enough.
The experts disagree and summarize that the now specified setback distances offer “certainly no effective protection” for the birds.
Sooner or later every red kite ends up in the area of a turbine. The risk of a collision is hugely large.”
The expert then adds that in the areas where there is a large population, as is the case near Lake Constance, there should be “absolutely no wind turbines“, or to shut them down when the birds are hunting.
The ZDF Terra X report says that no one knows just how many red kites fall victim to turbines each year. Counting is difficult because a struck bird is often quickly taken away by foxes or other scavengers. One thing is sure: turbines are killing the endangered birds, and likely in numbers that wind lobby hopes will never be known.
 
Share this...FacebookTwitter "
"Australian businesses are calling for a more ambitious national climate policy, backing a target of net zero emissions by 2050 and raising concerns about the lack of a coordinated energy policy and the government’s proposed use of carryover credits. The findings are contained in a Carbon Market Institute survey of more than 200 businesses, to be released on Thursday, which reveals 96% of those surveyed believe Australia should not delay the transition to a decarbonised economy.  About a third of businesses surveyed are emissions intensive companies that have obligations under the National Greenhouse and Energy Reporting Act, and include the mining, oil and gas and manufacturing industries. Others surveyed include investors, carbon project developers, carbon market experts and professional service providers. The survey finds widespread concern among business and industry groups about the government’s current policy settings, with 94% saying the approach is insufficient to meet Australia’s 2030 Paris commitment to cut emissions to 26%-28% of 2005 levels. This was an increase from the 92% who expressed the same view in 2018 when the survey was last undertaken. A similar number of respondents were concerned that current policies were also inadequate to help business manage the risks and capitalise on the opportunities in the transition to a net-zero emission economy. In October, the Reserve Bank of Australia used its financial stability review to warn that it was becoming increasingly important for investors and institutions to actively manage their carbon risk. Corporate regulators, the Australian Securities and Investments Commission (Asic) and the Australian Prudential Regulation Authority (Apra) have also warned that climate change is a foreseeable risk for corporate Australia. The findings come as Australian officials return from the UN climate change conference in Madrid after defending the country’s plan to use 411 million tonnes of emissions credits from the Kyoto protocol to meet its Paris targets. On Wednesday, the energy minister, Angus Taylor, told the Australian Financial Review that Australia could possibly meet its abatement targets without the use of carryover credits, claiming the government was already “over delivering”. But a government report released last month showed the Coalition was relying on the accounting loophole negotiated, with Australia expected to achieve just a 16% cut below 2005 levels by 2030 if they did not use the credit. The carryover credit comes from Australia achieving a better result than it agreed to under the first Kyoto target, which allowed for an 8% increase in emissions between 1990 and 2010. The CMI survey finds that about three-quarters of business respondents (76%) do not believe that Australia should be able to use the carryover units to achieve its 2030 emission reduction target, joining critics and other countries who want the practice banned. Also heaping pressure on the government to set more ambitious mid-century targets, which the Coalition has indicated will be outlined next year, the vast majority of businesses (83%) support a national target of net-zero emissions by 2050. Almost all of those surveyed (96%) agreed that the longer Australia delays decarbonisation, the more “abrupt, forceful and disruptive” the policy response will need to be, especially for carbon-intensive industries. When asked what Australia’s long-term policy should look like, the business leaders surveyed nominated a legislated net-zero 2050 target, coupled with a coordinated national climate policy suite to meet the target with a clear trajectory that was regularly reviewed. They also called for “sectoral decarbonisation strategies” that identified abatement potential, structural barriers and economic opportunities, a price on carbon, and a plan to ensure orderly closure of old coal plants and their replacement with clean energy. The survey shows support for changes to the safeguard mechanism, which sets emissions caps for high emitting facilities, with 83% of businesses wanting the baselines set under this scheme to be reduced. About three-quarters (74%) want lower-emitting facilities also to be captured under the mechanism. Australia has been left without a cohesive national energy policy after Scott Morrison dumped the national energy guarantee that helped terminate Malcolm Turnbull’s leadership. In a sign that the issue of climate change and carbon emission reduction is becoming more pressing, 84% of survey respondents reported that their organisation recognises the financial and strategic risks of climate change at a board and executive level. Just under half (42%) reported increased shareholder engagement regarding climate change for their organisation in the past 12 months. The chief executive of CMI, John Connor, said there was a gap between business expectations and government policy that was concerning business. “This survey tells us that many in Australian business – including Australia’s highest-emitting companies – are already planning to transition to a net-zero emissions world,” Connor said. “Business is looking for more ambitious climate policies to set a defined pathway and assist them in managing this.” Connor said Australian businesses were grappling with the knowledge that science required net-zero emissions by 2050, while also dealing with “policy volatility, evolving global carbon markets, investor calls for action and reporting requirements”."
"Pollinating insects like bees, butterflies and flies have had a rough time of late. A broad library of evidence suggests there has been a widespread decline in their abundance and diversity since the 1950s. This matters because such insects are critical both for the reproduction of wild plants and for agricultural food production. The decline of these pollinators is linked with destruction of natural habitats like forests and meadows, the spread of pests such as Varroa mite and diseases like foulbrood, and the increasing use of agrochemicals by farmers. Although there have been well documented declines in managed honeybees, non-Apis (non-honeybee) pollinators such as bumblebees and solitary bees have also become endangered.  There are more than 800 wild (non-honey) bee species in Europe alone. Seven are classified by the IUCN Redlist as critically endangered, 46 are endangered, 24 are vulnerable and 101 are near threatened. Collectively, losing such species would have a significant impact on global pollination. Though much of the media focus is on honeybees, they are responsible for only a third of the crop pollination in Britain and a very small proportion of wild plant pollination. A range of other insects including butterflies, bumblebees and small flies make up for this pollination deficit. Pollinators also vary in their effectiveness due to their behaviour around flowers and their capacity to hold pollen. Bigger and hairier insects can carry more pollen, while those that groom themselves less tend to be able to transfer pollen more effectively. Bumblebees, for example, make excellent pollinators (far superior to honeybees) as they are big, hairy and do not groom themselves as often. Where they are in decline, honeybees suffer primarily from pests and diseases, a consequence of poor nutrition and artificially high population density. This differs from other pollinators, where the decline is mainly down to habitat destruction. It seems pesticides affect all pollinators. Curiously, the issues facing non-Apis pollinators may be exacerbated by commercial beekeeping, and attempts to help honeybees may even harm efforts to conserve wild pollinators.  The problem is that there are only so many flowers and places to nest. And once the numbers of honeybees have been artificially inflated (commercial-scale beekeeping wouldn’t exist without humans) the increased competition for these resources can push native non-Apis pollinators out of their natural habitats. Honeybees also spread exotic plants and transmit pathogens, both of which have been shown to harm other pollinators. Over the coming decades, farmers and those who regulate them are faced with a tough challenge. Agricultural output must be increased to feed a growing human population, but simultaneously the environmental impact must be reduced.  The agriculture sector has tried to address the need to feed a growing population through conventional farming practices such as mechanisation, larger fields or the use of pesticides and fertiliser. Yet these have contributed to widespread destruction of natural landscapes and loss of natural capital.  Limited resources and land use pressure require conservation strategies to become more efficient, producing greater outcomes from increasingly limited input. So-called agri-environment schemes represent the best way to help insect pollinators. That means diversifying crops, avoiding an ecologically-fragile monoculture and ensuring that the insects can jump between different food sources. It also means protecting natural habitats and establishing ecological focus areas such as wildflower strips, while limiting the use of pesticides and fertilisers. As pollinating insects need a surprisingly large area of land to forage, linking up restored habitats on a larger scale provides far more evident and immediate benefits. However, so far, connections between protected areas have not been a priority, leading to inefficient conservation. We need a substantial shift in how we think about pollinators. Encouraging land managers to work cooperatively will help create bigger, more impactful areas to support pollinators. In future, conservation efforts will need to address declines in all pollinators by developing landscapes to support pollinator communities and not just honeybees."
"Volkswagen has accelerated its push into electric cars, as company forecasts suggest the world’s largest carmaker will produce its millionth battery electric vehicle two years earlier than previously planned. The core Volkswagen brand will have turned out 1m battery-only cars by the end of 2023 and will reach 1.5m by the end of 2025, the Wolfsburg-based manufacturer said on Friday.  This year it produced more than 70,000 electric cars, and last year 50,000. Volkswagen, which produced 10.8m cars in 2018, said it had produced 250,000 electrified vehicles (including fossil fuel-driven hybrids) since 2013. Volkswagen and other carmakers are scrambling to increase the number of electric cars they make and sell in the EU. Limits coming into force from 1 January will heavily penalise carmakers with fines for excessive greenhouse gas output. The regulations aim to reduce average carbon dioxide tailpipe emissions from new cars sold in the EU to below 95g per km. The fallout from the Dieselgate scandal, in which VW engineers cheated emissions tests, has prompted the company to increase its focus on electric cars. The Volkswagen group will release eight electric or hybrid models in the next year across its brands, which include Audi, Seat and Skoda. It is pinning its hopes of mass-market sales on the Volkswagen ID.3, with its plant in Zwickau, east Germany, aiming to produce 330,000 vehicles a year by 2021. The ID.3 base model will cost less than €30,000 (£26,000) and be capable of travelling for between 205 and 340 miles on a single charge, depending on the model. Thomas Ulbrich, the Volkswagen brand board member responsible for electric cars, said: “2020 will be a key year for the transformation of Volkswagen. With the market launch of the ID.3 and other attractive models in the ID family, our electric offensive will also become visible on the roads.” While Volkswagen’s main market is the EU, it is also expected to face growing pressure in other markets as emissions standards gradually catch up. The mayor of Los Angeles, Eric Garcetti, told the Financial Times on Friday that the city was considering forcing ride-hailing companies such as Uber and Lyft to use electric vehicles, in an effort to meet a target of zero net carbon emissions by 2050."
"Climate change has reduced Australian farms’ average annual profitability by 22%, or around $18,600 per farm, in the past two decades, according to the agriculture department. In a report released on Wednesday, the Australian Bureau of Agricultural and Resource Economics and Sciences has found that since 2000 changes in climate have reduced the revenue of Australian cropping farms by a total of $1.1bn a year. The report notes that average temperatures increased by about 1C since 1950 and compares Australia’s climate over the period 2000 to 2019 with the period from 1950 to 1999 by holding other variables, including farm output and commodity prices, constant. Abares, the Department of Agriculture’s science and economics research division, has developed a statistical model called Farmpredict using data from 40,000 farm observations to simulate differences in more than 50 physical and financial farm variables. Since 2000, climate change has had a negative effect on the profitability of broadacre farms in Australia. Only Northern Territory farms improved profitability, up 8.7%, with massive cuts to profit in Victoria (–37.1%), Western Australia (-25.8%) and New South Wales (-25.5%) attributed to climate change. Cropping farms were the worst hit, with revenue down 8% or around $82,000 a farm, and a 35% reduction in profits, or $70,900 for a typical cropping farm. Report co-author David Galeano said adaptation to climate variability “is certainly helping” – and without it farms would have experienced a 26% reduction in profit, and cropping farms’ profits would be down 49%. Sheep farms experienced an 18.2% reduction in average annual profit, or $6,100 per farm. Beef farms were “less affected overall” with a reduction in average profits of 5%, although some areas – including south-western Queensland – were more affected than others. Climate conditions have “also contributed to increased risk in terms of more variable cash income and profitability, particularly for cropping farms”, the report says. Climate change increased downside risk, with the chance of “very low” profits – below 2% – more than doubling since 2000. The Abares report says that the current drought across much of eastern Australia “has demonstrated the dramatic effects that climate variability can have on farm businesses and households”. It says that drought-affected NSW recorded “large falls in profit in 2018–19” but less drought-affected regions, including Western Australia, increased profits due to high commodity prices for grain and livestock. Abares warns that drought policy faces “an almost unavoidable dilemma: that providing relief to farm businesses and households in times of drought risks slowing industry structural adjustment and innovation”. “In some cases, well-intentioned policies can also disadvantage farmers who have been better prepared – or luckier – than farmers who are provided assistance and relief, diluting management incentives and raising difficult equity issues.” Sign up to receive the top stories from Guardian Australia every morning It recommends that in addition to supporting farm households experiencing hardship, drought policy should “promote resilience and improved productivity”. Climate change is making drought worse in Australia, although senior government figures including the Nationals leader, Michael McCormack, tend to emphasise that Australia’s climate has always been characterised by intermittent drought and flood. The centrepiece of the Coalition’s drought policy is a $5bn drought future fund that will make annual payments of $100m to improve resilience. In November the government announced an extra $1.5bn for drought relief, consisting of a $1bn concessional loan package for farmers and small businesses affected by the drought and $500m for “direct investment into communities”. Modelling the effect of drought, the Abares report says a cropping farm will see profit decrease from around $230,000 in a typical year to a loss of $125,000 in a dry year. For an Australian beef farm, profit falls from $60,000 in a typical year to a loss of $5,000 in a dry year."
"Last week, a whistle rang out in a buzzing conference fairground on the edge of Madrid. Instantly, a swell of protesters rose up, determined to “bring in the streets and tear down the walls”, enraged that the annual UN climate talks had wound to a grinding deadlock. Two days from a close, the talks had not yet produced a single line of text. Instead, while Sydney burned, Australia used an “accounting loophole” to cover for its poor climate record. Do politicians even live on the same planet?  The conference of the parties (COP) brings thousands of states, NGOs and observers together for two weeks each year to decide what is to be done about the climate crisis. In 2015, most countries signed the Paris accord that aims to keep global warming “well under” 2C – and to do all they can to limit this temperature increase to 1.5C. It’s 2019. We’re already at 1.1C. The world of COP is divided on economic and geographic faultlines. On one side is the global south, which lacks the resources to pick itself up after every new disaster brought on by the climate crisis; at the same time, dissent there is violently quelled. On the other lie northern countries such as the UK, which announced “net-zero by 2050” plans, by which time many current politicians will not be alive and mega-cities such as Mumbai will be under water. On both sides of the divide, pro-fossil fuel leaders on the right have come to power. This COP pointed to deepening fissures in old blocs, as real-time climate risks widened the rift. Small island nations with the most to lose voiced opposition to countries such as India, Brazil and China being in favour of carbon trading to offset the emissions of the global north and to count towards their own. Tuvalu, with two of its nine islands at risk of going under, called out the US for blocking loss and damage finance, saying it could amount to “crimes against humanity”. To achieve the 1.5C limit, countries have to increase their commitments five-fold, starting in 2020, said a new UNEP Emissions Gap report released for Madrid. At COP25, this year’s gathering, rich countries said they wanted more ambition, but also a clean slate. “This throws all history in the garbage, it’s acting as if emissions started today,” said Palestinian ambassador Ammar Hijazi, who chairs the G77 and China group. “When some countries emit without accountability at any level, it undermines the world order at every level.” I sat and fiddled with my earpiece, listening in horror as rainforest-clearing Brazil tried (and failed) to delete references to science around the relationship between climate change, land use and oceans. Through the night of last-ditch negotiations, I wandered the halls of this after-dark world, surveying the snacks that non-profits had stockpiled to see them through. Broken activists and diplomats curled up on recycled-wood armchairs and fuzzy rugs at the Ikea-sponsored UN pavilion for the night. I took pictures with the neon Gandhi in India’s massive greenwashing pavilion to send to environmentalists back home. Does the world still need COPs or could they be replaced by an intergovernmental Slack chat? COP25 should have been about welcoming new science, clearing unfinished business on climate finance, and raising trust and ambition. While there were wins on gender, agriculture and capacity building, this became a carryover COP, with decisions around carbon markets unclear, leaving old hostilities and glaring loopholes to sort through next year, an outcome even Patricia Espinosa, executive secretary of UN Climate Change, expressed disappointment with. We’re now just days away from 2020, when all countries must sit together to communicate and review all that they’ve done so far and all they can do under their commitments to the Paris agreement. This offers countries a last chance to “update” their national climate pledges to “reflect [each country’s] highest possible ambition” before 2025, a time by which we would have blown through more of our carbon budget. What happens at COP26 in Glasgow next year will determine if nations have a reason to stay in the Paris deal at all. But dysfunctional as they are, COPs are perhaps the only international legal forum that are partly open to observers to witness geopolitics and global call-out culture first-hand. And it’s those witnesses – all of us – who must apply the pressure. The youth climate strikes have managed to rattle the UN – they even ended up finding their way into the clunky text produced at this COP. Nearly 500,000 people had joined the climate strikes in Madrid, evidence that people are not their governments. For all that it’s worth, we must continue to blow the whistle everywhere, as loudly as we can, and make sure they can hear us outside their closed doors. • Aruna Chandrasekhar is a journalist from India. She is currently based at the University of Oxford’s Environmental Change Institute"
nan
"Scott Morrison’s response to questions about the link between catastrophic fires and climate change is right. Right in a narrow, technical sense which only serves to emphasise how wrong he is.  The prime minister is right that Australia only contributes a small proportion of global carbon emissions, though an honest figure is closer to 3.6 % rather than the 1.3 % he is so fond of quoting. He is right that if Australia stopped burning coal tomorrow and transitioned to a zero-emission economy next week, the forests would still burn, the pastures and crops would still wither, the stock would still starve, the corals would still bleach and the coasts would still be battered by storms and surges. We know this. We know that Morrison can’t grab his hose and put out the fires. But we also know that a plumber who skips a Friday afternoon job to pick up the kids is not the same as a prime minister who skips the country for a holiday during an escalating disaster. To make this comparison is to insult all those paid and volunteer emergency workers who sacrifice their family life to protect the communities they serve. We know that the climate crisis is a global problem. We know that the gigatonnes of greenhouse gases already emitted have locked the world into terrifying future, and that, as a country of “drought and flooding rains” Australia is particularly at risk. We know all these things. And we know that Morrison’s patronising response to this catastrophe only confirms that he doesn’t understand the question Australia is asking. Australians aren’t asking for miracles – we’re begging for leadership. We are begging for leadership on the national stage. This must start with an honest acknowledgement of the problem. An unqualified admission that we are facing a climate crisis and that we must act. We are begging for leadership stripped of hubris. Leadership that is willing to seek and acknowledge the expertise of scientists, engineers, land managers, economists, emergency services chiefs and health professionals. Leadership that is willing to use that expertise to develop strategies to mitigate the crisis. We are begging for leadership stripped of political partisanship that will reach across the aisle and seek common ground and national unity. We are begging for leadership that is courageous enough to tell us the truth. We know that taking effective action will involve costs. But it could also bring opportunities. Australia is fortunate to be well-endowed with renewable resources and technological expertise. With government leadership and support, the transition to a zero-carbon economy could benefit our economy in the medium term and generate much-needed regional jobs. We are begging for leadership on the international stage. The crisis facing Australia’s farms, forests, coasts and vulnerable ecosystems can only be addressed in the long term if there is meaningful global action. A government that truly wants to help our firefighters and farmers must lead the fight for a global response. But a government which pleads for special treatment and resorts to dodgy accounting to meet woefully inadequate commitments has no international credibility. A government whose policies are ranked among the world’s worst carries no moral authority. And without that moral authority the government has no clout to advance the only long-term solution to this crisis – an international framework for the rapid decarbonisation of the global economy. Instead of leading, Morrison hides behind the marketing strategy of a boldfaced lie which he hopes will be miraculously self-fulfilling if it is repeated often enough. The lie that Australia is leading the world in mitigation and will meet its international obligations at a canter. Let’s be brutally honest. A specious argument about Australia’s past emissions completely misses the point. Right now, at the advent of 2020, despite our natural and technological advantages, Australia is one of the world’s highest per-capita emitters of greenhouse gases. Regardless of the past, this single, verifiable fact places a moral obligation on Australia to be a world leader when it comes to emissions reduction. Instead Australia wilfully obstructs effective international action and provides cover for other countries to do likewise. The great tragedy of this lack of leadership is the opportunity squandered. Australia has squandered the international authority it gained as a progressive force in the postwar years. Australia has squandered the opportunity to be a global leader in the industries of the future. Australia has squandered the opportunity to protect its people from an increasingly hostile future. All of this to protect the interests of fossil industries who have known for decades that their accumulating wealth is literally costing the Earth. Australia is facing a crisis. This scorching summer has given us a glimpse of a frightening future. It has also exposed the failings of the hyperpartisan politics that increasingly mocks our system of representative democracy. The question Australia is asking Scott Morrison is not whether an effective climate policy will extinguish the fires. The question is whether he can show the leadership necessary to unite us and take the difficult decisions required to avoid the greater catastrophe that these horrific fires portend. Dr Geoff Goldrick is a scientist, educator and volunteer firefighter "
"
Share this...FacebookTwitterTextbook Details Robust Planetary Theory
Explaining Climate Change Without CO2

Wiley Textbook Image Source
The increasingly corroborated atmospheric mass pressure (gravity) explanation for variances in planetary temperatures – which precludes a significant role for CO2 concentration changes – has now advanced from peer-reviewed scientific journals to university-level textbooks.
The “adiabatic theory” of the greenhouse effect (adiabatic: “the constant decline in temperature of an air parcel as it rises in the atmosphere due to pressure drop and gas expansion”) is capable of explaining the variances in temperatures on planets like Earth, Mars, and Venus using each planet’s atmospheric pressure gradient – and without reliance on the traditional greenhouse effect theory that assigns a governing role to CO2.
As a simplified example, Mars has an atmosphere made up of about 950,000 ppm (95%) CO2 compared to the Earth’s 400 ppm (0.04%), and yet Mars’ average surface temperature is about -75°C colder than Earth’s.  Venus also has an atmosphere with about 950,000 ppm (95%) CO2, but its surface is +447°C warmer than Earth’s.   In addition to each planet’s variable distance from the Sun, the difference in temperature for Mars, Venus, and Earth can be calculated by considering its atmospheric mass (pressure) gradient.  Mars’ atmosphere is 100 times thinner than Earth’s.  Venus’ atmosphere is 92 times heavier (pressurized) than Earth’s.  The CO2 concentration of each planet may therefore be insignificant in determining surface temperature relative to factors (a) distance from the Sun and (b) atmospheric density.
Sciencing.com
“In general, the weaker the gravitational pull of a planet, the thinner the atmosphere will be. A planet with weak gravity will tend to have less mass and allow more atmosphere to escape into space. Thus the thickness or thinness of the atmosphere depends upon the strength or weakness of gravity. For example, the gravity on Jupiter is 318 times greater than Earth, and thus Jupiter’s atmosphere is much thicker than Earth’s. Gravity gets weaker the further away it is from a planet, so the atmosphere will be thicker near the surface.”

The determinative role of atmospheric pressure in planetary temperatures has previously been asserted by Dr. Oleg Sorokhtin (Russian Academy of Sciences) and other scientists introducing the “adiabatic theory of greenhouse effect”.
Sorokhtin et al., 2007
“According to the adiabatic theory of greenhouse effect (see below), besides the Sun’s radiation, the main determining factors of the Earth’s climate are the Earth’s atmosphere pressure and its composition. The denser the atmosphere (i.e., the higher the atmospheric pressure), the warmer the climate. Thus, the high surface temperature at the ocean level during the Archaean time, at a low Sun’s luminosity, may only be a result of higher atmospheric pressure. The gradual decrease in the oceanic water temperature with a smooth increase of Sun’s luminosity may only be a result of a gradual decrease in the atmospheric pressure.”
Florides and Christodoulides (2009) followed up with a peer-reviewed scientific paper of their own that also affirmed the “adiabatic theory of the greenhouse effect” and its cogency in explaining planetary temperatures, as well as the “negligible” effect of CO2 concentration changes.
“The analysis indicates that the average surface temperature of the Earth is determined by the solar constant, the precession angle of the planet, the mass (pressure) of the atmosphere, and the specific heat of the atmospheric mixture of gases.”
“A very recent development on the greenhouse phenomenon is a validated adiabatic model, based on laws of physics, forecasting a maximum temperature-increase of 0.01–0.03 °C for a value doubling the present concentration of atmospheric CO2. … If the CO2 concentration in the atmosphere increases from 0.035% [350 ppm] to its double value of 0.070% [700 ppm], the atmospheric pressure will increase slightly (by 0.00015 atm). Consequently the temperature at sea level will increase by about 0.01 °C and the increase in temperature at an altitude of 10 km will be less than 0.03 °C. These amounts are negligible compared to the natural temporal fluctuations of the global temperature.”
Adiabatic Theory: Textbook Science
Drs. John Robertson and George Chilingar, professors of geology and environmental (petroleum) engineering, have authored 12 textbooks, 70 books, and 575 scientific papers between them.  Both are verifiable experts in heat transfer physics.
Their latest joint effort, a 416-page university-level textbook published in June (2017), includes a section on the adiabatic theory that precludes a significant role for CO2 in determining planetary temperatures.  In fact, after explaining the details of the theory and its validation with respect to the atmospheric temperatures of Venus, Robertson and Chilingar conclude:
“The anthropogenic impact on global atmospheric temperatures is negligible, i.e., 5%.”
“From the above estimates, one can conclude that even significant releases of anthropogenic carbon dioxide into the Earth’s atmosphere practically do not change average parameters of the Earth’s heat regime.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






In the textbook, the authors explain the theory in meticulous detail (pgs. 197-204).  Below is a summary of their conclusions from page 204.


Image cropped from: Environmental Aspects of Oil and Gas Production, John O. Robertson, George V. Chilingar, ISBN: 978-1-119-11737-7, July 2017. Book source here.

Scientific Papers Supporting Adiabatic Theory
Nikolov and Zeller, 2017
“Our analysis revealed that GMATs [global mean annual temperatures] of rocky planets with tangible atmospheres and a negligible geothermal surface heating can accurately be predicted over a broad range of conditions using only two forcing variables: top-of-the-atmosphere solar irradiance and total surface atmospheric pressure. The hereto discovered interplanetary pressure-temperature relationship is shown to be statistically robust while describing a smooth physical continuum without climatic tipping points. This continuum fully explains the recently discovered 90 K thermal effect of Earth’s atmosphere. The new model displays characteristics of an emergent macro-level thermodynamic relationship heretofore unbeknown to science that has important theoretical implications. A key entailment from the model is that the atmospheric ‘greenhouse effect’ currently viewed as a radiative phenomenon is in fact an adiabatic (pressure-induced) thermal enhancement analogous to compression heating and independent of atmospheric composition. Consequently, the global down-welling long-wave flux presently assumed to drive Earth’s surface warming appears to be a product of the air temperature set by solar heating and atmospheric pressure. In other words, the so-called ‘greenhouse back radiation’ is globally a result of the atmospheric thermal effect rather than a cause for it. … The down-welling LW radiation is not a global driver of surface warming as hypothesized for over 100 years but a product of the near-surface air temperature controlled by solar heating and atmospheric pressure … The hypothesis that a freely convective atmosphere could retain (trap) radiant heat due its opacity has remained undisputed since its introduction in the early 1800s even though it was based on a theoretical conjecture that has never been proven experimentally.”
Chemke et al., 2016
“Observations suggest that Earth’s early atmospheric mass differed from the present day. The effects of a different atmospheric mass on radiative forcing have been investigated in climate models of variable sophistication, but a mechanistic understanding of the thermodynamic component of the effect of atmospheric mass on early climate is missing. Using a 3D idealized global circulation model (GCM), we systematically examine the thermodynamic effect of atmospheric mass on near-surface temperature. We find that higher atmospheric mass tends to increase the near-surface temperature mostly due an increase in the heat capacity of the atmosphere, which decreases the net radiative cooling effect in the lower layers of the atmosphere. Additionally, the vertical advection of heat by eddies decreases with increasing atmospheric mass, resulting in further near-surface warming. As both net radiative cooling and vertical eddy heat fluxes are extratropical phenomena, higher atmospheric mass tends to flatten the meridional temperature gradient.”
“An increase in atmospheric mass causes an increase in near-surface temperatures and a decrease of the equator-pole near-surface temperature gradient. Warming is caused mostly by the increase in atmospheric heat capacity, which decrease the net radiative cooling of the atmosphere.”
Chilingar et al., 2014
“The quoted comparisons indicate that average temperature distribution in the planet’s troposphere is completely defined by the solar constant, atmospheric pressure (mass), heat capacity of its gas composition and the precession angle. The theoretical temperature on Venus surface turned out to be Ts = 735 K, and on Earth’s surface, 288 K. The empiric values are 735.3 and 288.2 K, respectively. This close fit cannot be accidental and presents the convincing evidence in favor of the adiabatic theory of heat transfer in a dense atmosphere.”
Jelbring, 2003
THE “GREENHOUSE EFFECT” AS A FUNCTION OF ATMOSPHERIC MASS
“Here, using a different approach, it is shown that GE [the greenhouse effect] can be explained as mainly being a consequence of known physical laws describing the behaviour of ideal gases in a gravity field. A simplified model of Earth, along with a formal proof concerning the model atmosphere and evidence from real planetary atmospheres will help in reaching conclusions. The distinguishing premise is that the bulk part of a planetary GE [greenhouse effect] depends on its atmospheric surface mass density. Thus the GE can be exactly calculated for an ideal planetary model atmosphere.”
Miatello, 2012
“In an isolated global atmospheric system as that of Earth, in hydrostatic equilibrium in the cosmic vacuum, heat is transmitted only in accordance with the laws of thermodynamics, the thermal and conductive properties of different components, such as ocean waters, soils, and atmospheric gases, and the atmospheric adiabatic gradient. The same conditions apply to planets having huge atmospheric masses, such as Venus, Jupiter, and Saturn, whose surfaces and/or cores are heated only by a Kelvin-Helmholtz mechanism, gravitational compression of gases, according to their mass/density, as well as the impedance of their opaque atmospheres to solar radiation. In the case of Earth’s atmosphere with relatively high rarefaction and transparency and an active water cycle, which does not exist on Venus, Saturn, or Jupiter, the main factors influencing heat transfer are irradiance related to solar cycles and the water cycle, including evaporation, rain, snow, and ice, that regulates alteration of the atmospheric gradient from dry to humid. Therefore, the so-called “greenhouse effect” and pseudo-mechanisms, such as “backradiation,” have no scientific basis and are contradicted by all laws of physics and thermodynamics, including calorimetry, yields of atmospheric gases’ thermodynamic cycles, entropy, heat flows to the Earth’s surface, wave mechanics, and the 1st and 2nd laws of thermodynamics.”
Florides and Christodoulides, 2009
“As Sorokhtin et al. (2007) mention, until recently a sound theory using laws of physics for the greenhouse effect was lacking and all numerical calculations and predictions were based on intuitive models using numerous poorly defined parameters. In order to investigate the phenomenon they devised a model based on wellestablished relationships among physical fields describing the mass and heat transfer in the atmosphere. This model uses a general approach for obtaining analytical solutions for global problems and can be further refined to incorporate additional parameters and variables for examining local problems.”
“Their model was based on the observation that in the troposphere (the lower and denser layer of the atmosphere, with pressures greater than 0.2 atm) the heat transfer is mostly by convection and the temperature distribution is close to adiabatic. The reasoning for this is that the air masses expand and cool while rising and compress and heat while descending.”
“Basic formulae describe among others, the heat transfer in the atmosphere by radiation, the atmospheric pressure and air density change with elevation, the effect of the angle of the Earth’s precession and the adiabatic process. For the adiabatic process the formula considers the partial pressures and specific heats of the gases forming the atmosphere, an adiabatic constant and corrective coefficients for the heating caused by water condensation in the wet atmosphere and for the absorption of infrared radiation by the atmosphere.”
“The adiabatic constant and the heat coefficients are estimated using actual experimental data. This adiabatic model was verified, with a precision of 0.1%, by comparing the results obtained for the temperature distribution in the troposphere of the Earth with the standard model used worldwide for the calibration of the aircraft gauges and which is based on experimental data. The model was additionally verified with a precision of 0.5%–1.0% for elevations up to 40 km, by comparing the results with the measured temperature distribution in the dense troposphere of Venus consisting mainly of CO2.”
Gerlich and Tscheuschner, 2010
“In our falsification paper we have shown that the atmospheric CO2 greenhouse effects as taken-for-granted concepts in global climatology do not fit into the scientific framework of theoretical and applied physics. By showing that (a) there are no common physical laws between the warming phenomenon in glass houses and the fictitious atmospheric greenhouse effects (b) there are no calculations to determine an average surface temperature of a planet (c) the frequently mentioned difference of 33 degrees Celsius is a meaningless number calculated wrongly (d) the formulas of cavity radiation are used inappropriately (f) the assumption of a radiative balance is unphysical (e) thermal conductivity and friction must not be set to zero the atmospheric CO2 greenhouse effects have been refuted within the frame of physics.   In other words, the greenhouse models are all based on simplistic pictures of radiative transfer and their obscure relation to thermodynamics, disregarding the other forms of heat transfer such as thermal conductivity, convection, latent heat exchange et cetera.”
“In the speculative discussion around the existence of an atmospheric natural greenhouse effect or the existence of an atmospheric CO2 greenhouse effect it is sometimes stated that the greenhouse effect could modify the temperature profile of the Earth’s atmosphere. This conjecture is related to another popular but incorrect idea communicated by some proponents of the global warming hypothesis, namely the hypothesis that the temperatures of the Venus are due to a greenhouse effect.”
Share this...FacebookTwitter "
"In the arid lands that have seen one of the most brutal wars of the 21st century so far, green shoots of peace may finally be appearing. In the hot Darfur fields farmed by Adam Ali Mohammed, these green shoots are alternating rows of lentils and melons. “We tried lentils before, but there was not enough water,” the farmer says. Here in the Sahel, water is the key to life, but there is precious little of it – just 20cm of rain a year – and it is the source of much of the conflict. The climate crisis is making marginal existences even more fragile. It is no future threat here, with the Sahara marching southwards, temperatures rising and precious annual rains becoming ever more erratic. But a new approach is bearing fruit. The seasonal river that runs by El Fasher, the capital of Sudan’s North Darfur state, has been transformed by community-built weirs. These slow the flow of the rainy season downpours, spreading water and allowing it to seep into the land. Before, just 150 farmers could make a living here: now, 4,000 work the land by the Sail Gedaim weir. Crucially, the weirs are not just promising a more bountiful future, but a more peaceful one. Communities of farmers and nomadic camel herders, deadly enemies during the war, are coming together to plan and build them. This has often meant meeting face to face for the first time since the conflict began in 2003, but recrimination has turned into cooperation over shared water, and even resulted in wedding invitations. “There was a lot of killing here – there isn’t enough time to tell you about it all,” says Sheik Abdoelhman Saeed, part of the Sail Gedaim weir committee. “But now we are planning among ourselves to reach new areas with weirs.” Millet and sorghum were the staples, but Ali Mohammed has been able to expand into cucumbers and okra, lemons and grapefruit, and is trying sunflowers for the first time, all of which are valuable cash crops. “You give me the seed, and I will test it,” he says. Millions were forced to flee the violence in Darfur that killed as many as 400,000 people during a decade of conflict from 2003. Many people remain in huge camps today. “But if the fields are green like now, nothing could force me to go anywhere else,” says Ali Mohammed. The weir project on the Wadi El Ku river has also brought women, who do much of the farming work, to the fore. “Before, I was not able to sit with these men, and to speak like this,” says Azaz Mohammed, as the dam committee from 22 villages meets, sitting on carpets in the shade of a tree and sharing a meal harvested from the surrounding fields. The weirs are a “pioneer project”, says Enaam Ismail Abdalla, director general at the ministry of production in North Darfur, adding that the timing of the rains has completely changed due to climate change. The weirs are enabling people to return to their villages and adapt to the changing climate, which would otherwise drive them away once again, she says. She hopes they will be replicated in other parts of Darfur, Sudan and beyond. The collaborative climate-proofing provided by the Wadi El Ku project shows a way to tackle the complex mix of climate impacts, conflict and migration that are thought to be rising around the world. Ever wondered why you feel so gloomy about the world - even at a time when humanity has never been this healthy and prosperous? Could it be because news is almost always grim, focusing on confrontation, disaster, antagonism and blame? This series is an antidote, an attempt to show that there is plenty of hope, as our journalists scour the planet looking for pioneers, trailblazers, best practice, unsung heroes, ideas that work, ideas that might and innovations whose time might have come. Readers can recommend other projects, people and progress that we should report on by contacting us at theupside@theguardian.com The Darfur conflict was labelled “the first climate change war” by some observers, with the then-UN secretary general Ban Ki-Moon saying in 2007: “Amid the diverse social and political causes, it began as an ecological crisis, arising at least in part from climate change.” Research has shown that climate impacts such as drought and increasing temperatures increase the risk of armed struggles, particularly in regions where populations are already divided. Bitter divisions are starting to dissolve 50 miles (80km) north of El Fasher along the Wadi El Ku, where the next phase of the project is taking place. Until very recently, project staff needed a convoy of dozens of heavily armed soldiers to visit. “Now we can go on our own: that is a real sign of improvement,” says Atila Uras, head of the United Nations Environment Programme (UNEP) in Sudan, which oversees the €16m EU-funded project, which is aiming to help 180,000 people. In the semi-desert encampment of Mamora, the pastoralists are reluctant to talk about the war. But after a traditional greeting meal of camel milk and goat meat inside an ornately decorated tent, Omer Ali Mohammed says: “For sure, during the conflict there was a breakdown of relations between the different communities.” He is a former member of the Rapid Support Forces, a government paramilitary group that grew out of the Janjaweed militias used by the former Sudanese regime to fight rebels in Darfur. In April, a revolution deposed President Omar al-Bashir after a 30-year rule. He is now in jail in Khartoum and faces genocide charges at the international criminal court in the Hague. “The government fuelled us to fight against each other, but we have realised we were being misused,” says another Mamora nomad, Mohammed Ahmed. “We got sick of the conflict. Now we want to live in peace. Our fathers and grandfathers used to live in peace.” The Wadi El Ku project began work in this area in September with a six-day peace conference of seven pastoralist groups and 44 farming villages. “At first, they were all very angry and shouted a lot. The farmers said these [pastoralists] have killed our people,” says Awadalla Hamid Mohamed, of NGO Practical Action, which is implementing the UNEP project. “But we gave them time and the tensions slowly reduced. It took two months,” says Hamid Mohamed, who managed to escape from Janjaweed kidnappers nearby in 2015, when working on the early part of the project. “They realised coexisting was good for them,” he says. The nomads need clear routes for their 600-mile (1,000km) migrations, which were getting blocked by farms, while the farmers need milk, meat and safety for themselves and their crops. The nomads also say that they feel marginalised, with little access to medical care and deaths during childbirth common. The key was enabling the communities to come to an agreement on how to share the water and land. “There are layers and layers of conflict, so we started with what they could agree on, and everyone agrees there is a problem with the environment, with water by far the biggest priority,” says Uras. “But if you look like you are dictating things, that is a killer.” The peace meeting led to a breakthrough: for the first time in years, the nomads invited farmers to a wedding in September. More than 800 people attended, including many young people who had never met, with some guests travelling from 25 miles (40km) away. “It was an opportunity to rebuild the old relations,” says Ibrahim Abdalla, the nasir (leader) of the pastoralists. In nearby Kafod, the hundreds of donkeys gathered on the edge of the town show it is market day. Farmer Abdelrahman Hamad grows potatoes, radishes and onions on the Wadi El Ku, which runs nearby, and says he lost people to the conflict: “But the project has brought us together. Now I can go to the pastoralists’ area no problem. There were a lot of problems to overcome, of course, but everybody needs peace.” Downstream, at the village of Shagra, a colourful crowd of women and children have gathered to see the star entertainer Sasa. As the crowd processes around her, clicking their fingers above their heads, she sings a favourite tune: “Look at the widows and the little children / They have drained our tears / Forwards, oh Darfur.” The gathering is celebrating 9,000 new trees being planted by a local women’s community association, replacing the many destroyed for firewood during the war. The shady spot is a now a meeting place, and the gum arabic trees a future source of income. “The men tried to plant trees – they failed,” says Fathia Hamed Xagod, chair of the women’s association. They lacked the patience, she says. In El Fasher, Fuzia Abass, chair of the Women’s Development Association Network, says the Wadi El Ku project is having a big impact on women’s lives. More widespread access to water means much less time carrying it to their homes, while the greater incomes from the farms means more girls are going to school. “But while women are doing most of the work, the men are dominant in the decisions,” she says. The Wadi El Ku project has not been trouble-free. In 2018, the long Korga weir, built five miles from El Fasher, was sabotaged. “All the communities upstream and downstream had agreed to the weir, whether they benefited or not,” said Adam Mali, a member of this weir’s committee. “It worked really well in the first year and everyone was very happy. But then a few people [downstream] became jealous.” A night-time raid with a mechanical digger fatally weakened the weir. Despite repairs, when the unusually intense rains came this year, the resulting torrent ripped a 50-metre hole in the structure. This ruined its impact and forced farmers to abandon the unwatered fields. The prime suspects were linked to the deposed regime, but with no witnesses, they were released from police custody. But the revolution has brought new people to power. The new deputy wali (governor) of North Darfur, Mohammed Ibrahim Abdelkareem, says: “This sabotage was a crime. We have issued a decree to protect all the projects – the current ones and all the future ones.” His office will also fund the restoration of the Korga weir. “These projects contribute to the repair of Darfur society. Water projects are usually in the areas where the war happened.” This represents a significant change in tone, says Uras: “I have met a few walis, but this is the first time I have heard one talk about peace.” Omer Abdelrahman, at the groundwater and wadi directorate in North Darfur, is clear about the critical importance of such water projects: “Water is the key to our life – if we are breathing, we need water. If it is not equally shared, then again we will have more war and more killing.” But Hamid Mohamed, from Practical Action, is cautious about the future. “Security is 99% better now. But the situation is still fragile – the tension is still there – and nobody really knows what is going to happen tomorrow.” • The UN Environment Programme assisted with travel for the Guardian This article is part of a series on possible solutions to some of the world’s most stubborn problems. What else should we cover? Email us at theupside@theguardian.com "
"It is midnight at an almost deserted bus station and one of the Amazon’s most courageous warriors is sitting on a plastic chair and breastfeeding her child, apparently indifferent to the hefty price on her head. Illegal miners have offered 100g of gold to anyone who kills Maria Leusa Munduruku, a forest defender, indigenous leader and women’s rights activist who has spearheaded campaigns to halt invasions of the Tapajós river basin by polluters, loggers and dam builders.  After some of the men of her tribe – the Munduruku – were co-opted by gold prospectors, she formed a women’s association that now takes an increasingly prominent role in dangerous missions to demarcate territory and evict illegal occupants. “We need to be brave,” she says, adjusting a heavy nylon bag that serves as a suitcase while another child pulls at her painted arm. “Our women’s group is very strong. We are now in the front because the men put too much trust in the authorities. We think differently. We think it is up to us to protect ourselves. We don’t expect the government and police to do that.” About 300 women attended the inaugural meeting in Boca do Rio das Tropas Nova Trairão last year of the Wakoborun Women’s Association, one of the recipients of donations to the 2019 Guardian and Observer charity appeal, which focuses on solutions to the climate change crisis. Some of the meeting’s participants had to travel more than two days by boat from distant villages in the vast Munduruku territory, which is home to many of the best maintained forests in the Brazilian Amazon. This reflects a trend that is of global importance in sequestering carbon dioxide, maintaining natural diversity and ensuring fresh water supplies. Numerous studies have shown the most effective way to protect forests worldwide is to support indigenous land rights. In the Amazon, deforestation rates inside indigenous territory are two to three times lower than outside of them. For hundreds of years, Munduruku lands were largely inaccessible to outsiders due to dense vegetation, waterfalls that made river navigation difficult, and the tribe’s reputation for cutting off the heads of their enemies. Threats have grown in recent decades, particularly with proposals by the previous Workers Party government for a cascade of dams on the Tapajós, which prompted the Munduruku to self-demarcate territory and form alliances with other tribes – even former enemies in the riverine communities of Montanha e Mangabal. This was partially successful in shelving plans for a hydroelectric project at São Luís. Pressure has reached a new pitch in the past year since the ultra-rightwing militarist Jair Bolsonaro took power. The president – who has admitted that he, like his father, tried illegal mining – has weakened environmental protections, halted demarcation of indigenous lands, condemned Indians as lazy, and promised to open up more of the Amazon to extractive industries. “Where there is indigenous land, there is wealth underground,” he said before taking office. He has also revived hydroelectric plans across the Amazon. Leusa – who won the 2015 United Nations Ecuator prize on behalf of the Munduruku Ipereg Ayu movement (which she coordinated at the time) – says invasions on Munduruku territory have surged in the past 12 months because illegal miners believe the government is now on their side. She says some Munduruku men feel they have no choice but to accept a cut of the profits, which they squander on alcohol, drugs and prostitutes. She fears they are losing their culture and their language. The Guardian and Observer appeal donations are channelled by Global Greengrants Fund UK, which has previously paid for the women’s group to have multimedia training (including the use of drones for monitoring territory), craft workshops and beekeeping lessons so that locals can sell art and forest produce as an alternative income. “We are trying to show the men there is another way to make a living,” she says. “It’s true that mining makes more money, but we argue it destroys the future for our children. It is true that mining brings death, not a future, to our children. Some of our people can be persuaded, but others won’t listen. Some want to kill me. Even my own uncle has relatives that have threatened me.” She is undaunted. The damage to the river and the forest is too great for her to ignore. The situation is different at each of the 130 or so Munduruku communities, which sit along the Tapajós and its tributaries. Worst affected is the Tropas river – where local leaders made a deal with miners who brought in bulldozers, dredges and chemicals. Leusa says the once-clear water is now murky, the fish are dying and children are suffering diarrhoea. But where the women’s association is strong – on the Cururu and Anipiri rivers – the water is still clean. But threats continue to grow from numerous directions. Leusa has joined the men in fighting against government plans for a cascade of dams that would deluge swathes of their territory. She has also taken the fight – along with her baby – to the capital, Brasília, where she compared the forest to a mother: “Because of the government, our forest is shedding tears. Tears that fall like milk from our breast.”"
"
Share this...FacebookTwitterOver the past few years Germans have been increasing their protests against the construction of wind trubines in the countryside and the idustrial littering of the landscape.
Hundreds of citizens’ protest groups have since formed with the aim of fiercely opposing the construction of wind parks in forests, open landscapes and near residential areas.

The level of resistance has reached the point where politicians are taking real notice, and now view it as a political issue worth adopting.
Photo right: René Rock, credit: FDP
The latest sign of this happening comes from the FDP Free Democrats, who have been resurging in Germany as of late. Last Sunday the party saw a record number of voters turn out in the state elections of North Rhine Westphalia. The Greens, on the other hand, saw almost half of their voters disappear.
Further south in the German state of Hesse, home of Frankfurt, parliamentarian René Rock, FDP fraction energy policy spokesman, has called for the return of “an energy policy of reason” and come out “with great passion against a purely ideologically motivated building of further wind parks in the Hesse“.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Rock’s website here states:
Wind energy is neither economically nor climate-politically sensible, it endangers the health of people and wildlife, and it destroys the beautiful and valuable natural and cultural heritage.”
Over the past years many Germans have been horrified seeing protected forests getting chopped down and cleared to make way for 200-meter tall turbines. Not only is it an eyesore, a danger to wildlife and uneconomical, Rock also adds that Germany’s EEG feed-in act is “the most unsocial law that Germany has ever had and that it must be stopped immediately. It is nothing more than pure redistribution from the bottom up and has put the market economy out of order.”
Rock also calls for a new energy policy that “really protects people, wildlife and the environment, that is the best market solution and one that foremost researches nuclear fusion.”
He also calls for the 10H setback rule, which requires wind turbines to be placed no closer to any resident than 10 times its height and that people’s concerns need to be taken more seriously.
Bad Nauheim mayor candidate Britta Weber, also of the Free Democrats, came out against the construction of a wind park nearby, stating that the “FDP here won’t go along with it. Every wind turbine is one too many. We need new technologies, other research areas, a return back to supply and demand, protection of our homeland, without ideology and state nannyism.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGreenland Cooling Since 2005
Arctic Region Cooler Now Than Most Of The Last 10,000 Years

It’s official.  According to a new paper published in the journal Scientific Reports, Greenland has been cooling slightly since 2005.
This trend development may be a harbinger of what may be in store for the coming years.  Shifts in North Atlantic temperatures typically lead changes in the Arctic  by a few years.  And throughout the North Atlantic, rapid cooling has been underway since 2005, plunging below the levels reached in the 1950s.

Kobashi et al., 2017
“For the most recent 10 years (2005 to 2015), apart from the anomalously warm year of 2010, mean annual temperatures at the Summit exhibit a slightly decreasing trend in accordance with northern North Atlantic-wide cooling.  The Summit temperatures are well correlated with southwest coastal records (Ilulissat, Kangerlussuaq, Nuuk, and Qaqortoq).”


A Few Thousand Years Ago, The Greenland/Arctic Region Was 3-5°C Warmer Than Now

Between 10,000 and 4,000 years ago, atmospheric CO2 concentrations were almost 150 ppm lower than they are now (~260 ppm).  Despite such low CO2 levels, the Arctic region was several degrees Celsius warmer than it has been in recent decades.   Arctic summers were likely sea ice-free during these much warmer years.

Mangerud and Svendsen, 2017
“Shallow marine molluscs that are today extinct close to Svalbard, because of the cold climate, are found in deposits there dating to the early Holocene. The most warmth-demanding species found, Zirfaea crispata, currently has a northern limit 1000 km farther south, indicating that August temperatures on Svalbard were 6°C warmer at around 10.2–9.2 cal. ka BP [10,200 to 9,200 years ago], when this species lived there. … After 8.2 cal. ka, the climate around Svalbard warmed again, and although it did not reach the same peak in temperatures as prior to 9 ka, it was nevertheless some 4°C warmer than present between 8.2 and 6 cal. ka BP. Thereafter, a gradual cooling brought temperatures to the present level at about 4.5 cal. ka BP. The warm early-Holocene climate around Svalbard was driven primarily by higher insolation and greater influx of warm Atlantic Water, but feedback processes further influenced the regional climate.”



Lasher et al., 2017
“This paper presents a multi proxy lake record of NW Greenland Holocene climate. … Summer temperatures (2.5–4 °C warmer than present) persisted until ∼4 ka [4,000 years ago] … Continual cooling after 4 ka led to coldest temperatures after 1.2 ka, with temperature anomalies 2-3°C below present.  Approximately 1000 km to the south, a 2-3°C July temperature anomaly (relative to [warmer than] present) between 6 and 5 ka [thousand years ago] was reported based upon chironomid assemblages near Illulisat and Jakobshavn (Axford et al., 2013). Across Baffin Bay on northeastern Baffin Island, HTM [Holocene Thermal Maximum] summer temperatures were an estimated ~5°C warmer than the pre-industrial late Holocene and 3.5°C warmer than present, based upon chironomid assemblages (Axford et al., 2009; Thomas et al., 2007).”


Kobashi et al., 2017
“After the 8.2 ka event, Greenland temperature reached the Holocene thermal maximum with the warmest decades occurring during the Holocene (2.9 ± 1.4 °C warmer than the recent decades [1988-2015]) at 7960 ± 30 years B.P.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Lusas et al., 2017 (East Greenland)
“The lack of glacio-lacustrine sediments throughout most of the record suggests that the ice cap was similar to or smaller than present throughout most of the Holocene. This restricted ice extent suggests that climate was similar to or warmer than present, in keeping with other records from Greenland that indicate a warm early and middle Holocene. Middle Holocene magnetic susceptibility oscillations, with a ~200-year frequency in one of the lakes, may relate to solar influence on local catchment processes. … Air temperatures in Milne Land, west of our study area, based on preliminary estimates from chironomids, may have been 3–6°C warmer than at present (Axford et al. 2013), and in Scoresby Sund itself, warm ocean fauna, including Mytilus edulis and Chlamys islandica, both of which live far to the south today, occupied the fjords (Sugden and John 1965; Hjort and Funder 1974; Street 1977; Funder 1978; Bennike and Wagner 2013; Fig. 13).  … Recession of Istorvet ice cap in the last decade has revealed plant remains that show that the glacier was smaller than at present during the early stages of the Medieval Warm Period, but expanded during the late Holocene ca. AD 1150 (Lowell et al. 2013).”

No Net Warming For The Greenland Ice Sheet In 90 Years

Kobashi et al., 2017


Zhao et al., 2016


Hanna et al., 2011


Greenland Ice Sheet Had Retreated 20-60 Kilometers Behind Present Margins ~8,000 Years Ago

Lasher et al., 2017
“Following deglaciation, the GrIS [Greenland Ice Sheet] retreated behind its present margins (by as much as 20-60 km in some parts of Greenland) during the HTM [Holocene Thermal Maximum] (Larsen et al., 2015; Young and Briner, 2015).”

Briner et al., 2016 
“The Greenland Ice Sheet retracted to its minimum extent between 5 and 3 ka [5,000 and 3,000 years ago], consistent with many sites from around Greenland depicting a switch from warm to cool conditions around that time.”

 


A Long-Term Context

Greenland has warmed 20-24 times the magnitude reached during the last century multiple times.  During these abrupt warming events (10°C to 15°C temperature rise within decades), CO2 concentrations were stable and hovered below 200 parts per million.  This indicates that the Arctic climate is not significantly influenced by CO2 variations nor human activity in general, as the past 100 years are well within the range of natural variability.

Easterbrook, 2016
“In the past 500 years, Greenland temperatures have fluctuated back and forth between warming and cooling about 40 times, with changes every 25–30 years. … Comparisons of the intensity and magnitude of past warming and cooling climate changes show that the global warming experienced during the past century pales into insignificance when compared to the magnitude of profound climate reversals over the past 25,000 years. At least three warming events were 20–24 times the magnitude of warming over the past century, and four were 6–9 times the magnitude of warming over the past century.”
Share this...FacebookTwitter "
nan
"Noise pollution, generally an unintended byproduct of urbanisation, transport and industry, is a key characteristic of human development and population growth. In some cases, it is produced intentionally, for example when seismic surveys are being carried out using powerful airgun arrays to explore and map the seafloor, or active sonar, which uses sound waves to detect objects in the ocean.  All of this noise – whether intentional or not – has the ability to alter the acoustic environment of aquatic and terrestrial habitats. This can have a dramatic effect on the animals that live in them, perhaps even driving evolutionary change as species adapt to or avoid noisy environments. The dramatic and comparatively recent rise in noise levels is marked in both magnitude and extent, with an estimated 30% of the European population exposed to road traffic noise levels greater than 55dB (decibels) at night, well above the 40dB target recommended by the World Health Organisation. Even remote natural areas do not escape the reach of anthropogenic, or manmade, noise. One study across 22 US national parks demonstrated that this kind of noise was, on average, audible more than 28% of the time. Noise is not just irritating; we have known for some time that it can have direct human health impacts. Indeed, chronic exposure to noise levels above 55dB dramatically increases the risks of heart disease and stroke, while aircraft noise has been shown to impact the development of reading skills in children attending schools close to busy airports. The WHO estimates that in Europe at least a million healthy life years are lost every year due to traffic noise. But what are the implications for wildlife, particularly given how important sound production and hearing are for a range of behaviours, such as locating food, avoiding predators and finding a mate? For example, bats and dolphins rely on high frequency sonar to detect highly mobile prey, while great tits, red deer and grasshoppers are among the many species that advertise their dominance and desirability using vocalisations. Elephants can even use sound to determine the threat presented by different human groups.  Scientific interest in the effects of noise pollution on wildlife has intensified over the past decade and we are now developing a better understanding of how noise can impact behaviour, population and community level processes across a range of animal species. Using experimental and observational approaches to characterise and explore the specific effects of different noise sources, the evidence generated from these studies is considerable, particularly among songbirds and marine mammals, which rely heavily on sound and vocal communication.  We now know, for example, that the foraging, vocal behaviour and physiological stress of cetaceans – whales, dolphins and porpoises – can be impacted by ship noise. This is of particular concern for species such as the endangered North Atlantic right whale that inhabits coastal US waters that experience very high levels of shipping traffic. Furthermore, in addition to shifts in distribution and vocal behaviour, military sonar has also been linked to the stranding of cetaceans.  The impacts are not just limited to marine mammals, considerable negative effects of noise are also documented in marine and freshwater fish and invertebrates. These include recent studies that have demonstrated compromised anti-predator behaviour in crabs and eels exposed to ship noise. In terrestrial habitats, bird diversity and abundance has been shown to decline as a result of chronic noise levels around cities and along roadways. A number of species have demonstrated adjustments to their vocal behaviour in an attempt to adapt to the cacophony of human noise. Urban great tits for example, are able to raise the frequency of their calls to reduce acoustical masking by predominantly low-frequency urban noise, while European robins adjust the timing of their singing to coincide with quieter periods in the city. Meanwhile, black-chinned hummingbirds and house finches appear to actively select noisy areas near active gas wells to avoid nest predation by more disturbance sensitive species. Roads are a major source of terrestrial noise due to their spatial extent and the volume of traffic. A 2003 study calculated that 83% of the lower 48 states of the US was within about 1km of a road. I have been working with colleagues at Colorado State University and the National Park Service to explore the effects of road noise on the prairie dog, a social mammal.   Our research demonstrated that prairie dogs, which commonly live in habitats near roads and urban areas, significantly reduced their foraging and increased their vigilance behaviour when exposed to road noise. Such shifts in behaviour could have impacts on their long-term population health particularly in combination with other stressors such as disease and habitat loss.  Road noise has also been shown to impair the foraging efficiency of bats and alter vocal communication in frogs and invertebrates. Studying noise isn’t an easy thing to do. First of all, sound levels cannot accurately be measured and defined using a single absolute scale, such as those used for temperature, rainfall and wind speed. For simplicity we often just refer to a decibel level, but this does not take into account the duration and frequency of the acoustical signal. The specific effects of noise also need to be disentangled from the sources of disturbance that often accompany it, including human presence, habitat fragmentation and chemical pollution.  The need to further understand the complex biological effects of noise and establish scientifically relevant thresholds of noise exposure is a priority for human health and wildlife conservation. Rapid development, urbanisation and population growth are set to continue into the future. As a result we need to ensure a collaborative effort between scientists, industry and government to protect natural soundscapes where possible, while also promoting new technology and approaches that mitigate the effects of noise. Man made noise is a relatively recent phenomenon, particularly in evolutionary terms, but scientific studies have demonstrated that it has the potential to adjust behaviour, alter physiology and even restructure animal communities. Ultimately, such a strong selection pressure could drive evolutionary change. These are complex questions that are now being explored by experts across a range of disciplines from animal behaviour to bioacoustics."
"
Share this...FacebookTwitterModern ‘Warmth’ A Brief Excursion From
8,000-Year (Continuing) Cooling Trend

The scientific literature is replete with evidence that the geological record for the Holocene (the last 10,000 years) fails to support the concept that rising atmospheric CO2 concentrations cause ocean and land temperatures to rise.
Actually, the scientific literature strongly suggests that the correlation between rising CO2 and temperature would appear to veer off in the opposite direction: as CO2 rises, temperatures decline.
So if there is a correlation for the Holocene, it may be the inverse of climate model expectations.

Modern ‘Warmth’ Excursion Has Had Little Or No Effect On The Overall Long-Term Cooling Trend 

According to an estimate of global sea surface temperature (SST) changes during the last 2,000 years (“Robust global ocean cooling trend for the pre-industrial Common Era“), the addition of the last 2 centuries (1800 to 2000 C.E.) of relatively modest SST warming only changes the overall per-millennium global cooling trend (~0.4°C) by one tenth of one degree.  In other words, using a long-term perspective, the Holocene cooling trend has continued largely uninterrupted during the last two centuries.

McGregor et al., 2015
“Our best estimate of the SST cooling trend, scaled to temperature units using the average anomaly method (method 1), for the periods 1–2000 CE is –0.3°C/kyr to –0.4°C/kyr, and for 801–1800 CE is –0.4°C/kyr to –0.5°C/kyr“


Overall cooling has been ongoing for most of the last ~8,000 years, mixed in with temporary warming “spikes” that last for a century or two.  The modern warming that emerged in the early 20th century will, if history is a guide, eventually revert back to the cooling trajectory of the last several thousand years.  Gerhard (2004) facilely illustrates this overall global cooling trajectory — with swerves and spikes along the way.

Gerhard, 2004



CO2 Concentrations Rose Steadily Throughout The Last 8,000 Years…While Earth Cooled

While the planet has been steadily cooling (with brief warming excursions) for the last 8,000 years, atmospheric CO2 concentrations have tilted in the opposite direction, rising from about 260 parts per million (ppm) ~8,000 years ago to about 280 ppm in ~1800 C.E.
So if CO2 rises as temperature drops, the correlation suggested by climate models (temperature should rise as CO2 rises) is not supported by by a large portion of the available scientific evidence.
Listed below are 50 inverse “hockey stick” graphs featuring a long-term global cooling trend that is largely uninterrupted by modern era temperatures.  These reconstructions illustrate the unheralded disconnect between CO2-driven climate models and the geological record.




Jiang et al., 2015


Lecavalier et al., 2013


Luoto et al., 2014


Abrantes et al., 2017



Esper et al., 2014


Jalali et al., 2016
 


Renssen et al., 2009


Rosenberg et al., 2004


Rosenthal et al., 2013


Khiyuk and Chilingar, 2006


Rinne et al., 2014


Gennaretti et al., 2014


Fudge et al., 2016


Harning et al., 2016


Munz et al., 2015


Tyson et al., 2000


Mark, 2016


Steinman et al., 2016


Bertrand et al., 2014


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






 



Yamamot et al., 2016


Shevenell et al., 2011


Bostock et al., 2013


Kim et al., 2007


Viau and Gajewski, 2009


Thienemann et al., 2017
“[P]roxy-inferred annual MATs [annual mean air temperatures] show the lowest value at 11,510 yr BP (7.6°C). Subsequently, temperatures rise to 10.7°C at 9540 yr BP followed by an overall decline of about 2.5°C until present (8.3°C).”


Schneider et al. 2014


Sepúlveda et al., 2009


Böll et al., 2014


Brocas et al., 2016


 
Shevenell et al., 2011


Mulvaney et al., 2012
“A marine sediment record from off the shore of the western Antarctic Peninsula also shows an early Holocene optimum during which surface ocean temperatures were determined to be 3.5°C higher than present. Other evidence suggests that the George VI ice shelf on the southwestern Antarctic Peninsula was absent during this early-Holocene warm interval but reformed in the mid Holocene.”


Krawczyk et al., 2017



Foster et al., 2016


Andersen et al., 2004
 



Fortin and Gajewski, 2016


Caniupán et al., 2014


Birks and Seppä, 2004


Rella and Uchida, 2014


Kawahata et al., 2017


Levy et al., 2013


Weldeab et al, 2005


Dupont et al., 2004

Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitterOzone Measurement Error  
‘Shatters’ Established Theory

It was 10 years ago this month that scientists revealed an order-of-magnitude-sized error in molecular chemistry measurement that threatened to severely undermine the commonly accepted explanation for  how ozone depletion occurs.
The iconoclastic discovery fomented “much debate and uncertainty in the ozone research community.”    The mechanism that causes polar ozone destruction had, with one measurement, become more “unknown” than known.
With the stunning new evidence, a leading ozone researcher proclaimed that, “Our understanding of chloride chemistry has really been blown apart.”
But then, in the ensuing months and years after the measurement error had been exposed, there was . . . silence.
Rarely, if ever, was this discovery of a molecular rate change “substantially [ten times] lower than previously thought” brought to the public’s attention again.  Ostensibly because of a lack of appetite for admitting they may be wrong, scientists just seemed to . . . move on.
The 1980s zeitgeist that insisted we humans are the predominant cause of ozone depletion due to our ozone depleting substances emissions has been maintained for more than 3 decades now despite a growing body of contrary evidence that says variations in ozone density are predominantly determined by natural phenomena (meteorology, volcanic eruptions), not human emissions.
The ozone “hole” narrative and the widely-held perception that governmental policies determine how small or large the “hole” gets would appear to be analogous to the current climate debate and its connection to the governmental push to dramatically limit CO2 emissions.

Schiermeier, 2007
As the world marks 20 years since the introduction of the Montreal Protocol to protect the ozone layer, Nature has learned of experimental data that threaten to shatter established theories of ozone chemistry. If the data are right, scientists will have to rethink their understanding of how ozone holes are formed and how that relates to climate change.
Markus Rex, an atmosphere scientist at the Alfred Wegener Institute of Polar and Marine Research in Potsdam, Germany, did a double-take when he saw new data for the break-down rate of a crucial molecule, dichlorine peroxide (Cl2O2). The rate of photolysis (light-activated splitting) of this molecule reported by chemists at NASA’s Jet Propulsion Laboratory in Pasadena, California, was extremely low in the wavelengths available in the stratosphere — almost an order of magnitude lower than the currently accepted rate. “This must have far-reaching consequences,” Rex says. “If the measurements are correct we can basically no longer say we understand how ozone holes come into being.”  What effect the results have on projections of the speed or extent of ozone depletion remains unclear.
The rapid photolysis of Cl2O2 is a key reaction in the chemical model of ozone destruction developed 20 years ago (see graphic). If the rate is substantially [10 times] lower than previously thought, then it would not be possible to create enough aggressive chlorine radicals to explain the observed ozone losses at high latitudes, says Rex. The extent of the discrepancy became apparent only when he incorporated the new photolysis rate into a chemical model of ozone depletion. The result was a shock: at least 60% of ozone destruction at the poles seems to be due to an unknown mechanism, Rex told a meeting of stratosphere researchers in Bremen, Germany, last week.
Other groups have yet to confirm the new photolysis rate, but the conundrum is already causing much debate and uncertainty in the ozone research community. “Our understanding of chloride chemistry has really been blown apart,” says John Crowley, an ozone researcher at the Max Planck Institute of Chemistry in Mainz, Germany.
 “Until recently everything looked like it fitted nicely,” agrees Neil Harris, an atmosphere scientist who heads the European Ozone Research Coordinating Unit at the University of Cambridge, UK. “Now suddenly it’s like a plank has been pulled out of a bridge.”

Ozone ‘Hole’ Size Naturally Determined  


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




CFCs Ban Effects Not Detectable In Trends
NASA, 2013
NASA scientists have revealed the inner workings of the ozone hole that forms annually over Antarctica and found that declining chlorine in the stratosphere has not yet caused a recovery of the ozone hole. …. [T]wo new studies show that signs of recovery are not yet present, and that temperature and winds are still driving any annual changes in ozone hole size.
The classic metrics create the impression that the ozone hole has improved as a result of the Montreal protocol. In reality, meteorology was responsible for the increased ozone and resulting smaller hole, as ozone-depleting substances that year were still elevated. The study has been submitted to the journal of Atmospheric Chemistry and Physics.
“Ozone holes with smaller areas and a larger total amount of ozone are not necessarily evidence of recovery attributable to the expected chlorine decline,” said Susan Strahan of NASA’s Goddard Space Flight Center in Greenbelt, Md.
“We are still in the period where small changes in chlorine do not affect the area of the ozone hole, which is why it’s too soon to say the ozone hole is recovering,” Strahan said. “We’re going into a period of large variability and there will be bumps in the road before we can identify a clear recovery.”
Barnes et al., 2016
Trends in trace atmospheric constituents can be driven by trends in their (precursor) emissions but also by trends in meteorology. Here, we use ground-level ozone as an example to highlight the extent to which unforced, low-frequency climate variability can drive multi-decadal trends. … Ozone trends are found to respond mostly to changes in emissions of ozone precursors and unforced climate variability, with a comparatively small impact from anthropogenic climate change. Thus, attempts to attribute observed trends to regional emissions changes require consideration of internal climate variability, particularly for short record lengths and small forced trends.
Pozzoli et al., 2012
The changes in meteorology (not including stratospheric variations) and natural emissions account for 75 % of the total variability of global average surface O3 concentrations.
Regionally, annual mean surface O3 concentrations increased by 1.3 and 1.6 ppbv over Europe and North America, respectively, despite the large anthropogenic emission reductions between 1980 and 2005.
Hossaini et al., 2015
Scientists report that chemicals that are not controlled by a United Nations treaty designed to protect the Ozone Layer are contributing to ozone depletion.

In the new study, published today in Nature Geoscience, the scientists also report the atmospheric abundance of one of these ‘very short-lived substances’ (VSLS) is growing rapidly.


The Ozone ‘Hole’ Reached Record Levels In Oct., 2015
     Ivy et al., 2017
Recent research has demonstrated that the concentrations of anthropogenic halocarbons have decreased in response to the worldwide phaseout of ozone depleting substances. Yet, in 2015 the Antarctic ozone hole reached a historical record daily average size in October.
Model simulations with specified dynamics and temperatures based on a reanalysis suggested that the record size was likely due to the eruption of Calbuco, but did not allow for fully-coupled dynamical or thermal feedbacks. We present simulations of the impact of the 2015 Calbuco eruption on the stratosphere using the Whole Atmosphere Community Climate Model with interactive dynamics and temperatures. Comparisons of the interactive and specified dynamics simulations indicate that chemical ozone depletion due to volcanic aerosols played a key role in establishing the record-sized ozone hole of October 2015. The analysis of an ensemble of interactive simulations with and without volcanic aerosols suggests that the forced response to the eruption of Calbuco was an increase in the size of the ozone hole by 4.5 million km2.

Today: The Assumption That Humans Determine Ozone
Destruction Persists Despite Growing Contrary Evidence
National Geographic
Chlorofluorocarbons (CFCs), chemicals found mainly in spray aerosols heavily used by industrialized nations for much of the past 50 years, are the primary culprits in ozone layer breakdown.
Science News
In a rare bright spot for global environmental news, atmospheric scientists reported in 2016 that the ozone hole that forms annually over Antarctica is beginning to heal. Their data nail the case that the Montreal Protocol, the international treaty drawn up in 1987 to limit the use of ozone-destroying chemicals, is working.
[P]ublic engagement was key to solving the ozone problem, with people coming together to identify an issue that threatened society and develop new technologies to fix it. In that respect, the most successful environmental treaty in history holds lessons for dealing with a much bigger threat, she says — climate change.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSchneefan at wobleibtdieerderwaermung.de here does a good job summarizing weather and climate trends. His latest focuses on the ENSO, which is a powerful Pacific driver of global weather.
Earlier this year a number of experts projected that another El Niño would appear later this year, and thus keep global temperatures elevated and thus end the pause in global warming we’ve seen since the century began.
For example the May ECMWF ENSO projection saw powerful El Niño conditions brewing for this coming fall, with an anomaly of up to +3.0° K!

Source: ECMWF ENSO FORECAST.
But already in April other forecasters started revising their projections downwards as nature started to show she had other plans in mind. Today it strongly appears La Niña conditions are going to emerge after all.
The result? The “Al Gore effect”.
Expect the cooling we’ve seen over the past one and half years to continue even through 2018.

Figure 1: Global lower troposphere temperature (1500 m) anomalies have been cooling since the El Niño peaked in early 2016. Source: www.woodfortrees.org/graph/trend.
The mid August 2017 CFSv2 prognoses for the equatorial Pacific 3.4 zone surface temperature projections now indicate La Niña conditions by October:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Click to enlarge. Source: www.cpc.ncep.noaa.html. 
To know what’s behind the latest development, we look at the ocean heat content anomalies of the upper 300 m of the ocean in the equatorial Pacific. The following chart shows a return to the negative range at the end of July 2017.

Source: www.cpc.ncep.noaa.gov/MJO/enso.shtml
The following chart shows what’s going on just below the ocean surface:
Source: 4-month sequence of Pacific Ocean Equatorial temperature anomaly cross sections
Clear to see is the cold emerging La Niña mass under ocean surface in August 2017. That spells generally cooler global conditions for the months ahead.
Global warming “reality check” of 2017
With Arctic ice mass growing and the Antarctic showing cold surface anomalies, Schneefan calls the recent development: “The Global Warming“ Reality Check”!
Once again we see that experts are a long way from understanding what the system is doing, and thus make forecasts dealing with the climate totally fraught with uncertainty. We can only look forward to late fall.
 
Share this...FacebookTwitter "
"If you’re one of the millions of people concerned about the growing pressures that our food habits are placing on the environment, then you’ve probably felt confused, conflicted or downright overwhelmed by your own food choices on more than a few occasions. Is quinoa good, evil, or somewhere in between? Were the coconuts in my coconut milk picked by a monkey? Am I a bad person if I eat an avocado? In the drive for change, it’s vital for consumers to use their purchasing power as discerningly as they can. But with profit-making still at the top of the food industry agenda – and the environmental costs of many food products hidden by complex supply chains – we need more than consumer power alone to achieve a truly sustainable food system. The global population continues to grow in a world with limited resources, increasing the pressure on producers to maximise the amount of food that can be grown on existing land. As the long tentacles of transnational corporations seek the most cost-effective and efficient supply chains to feed these extra mouths, the environment has often had to take the strain.  A billion tonnes of top soil vital to crop quality are lost every year through erosion in the 28 EU states alone, while land use change has driven a 58% decline in vertebrate abundance since 1970. Food supply chains are now often so complicated and opaque that consumers are rarely — if ever – presented with a comprehensive picture of the journey their food has been on. Instead, we have to rely on businesses and individuals at each stage to act ethically – and on supermarkets to provide the information necessary for us to make sustainable choices.   But our trust is tempered by the opposing pulls of supermarkets’ interests. To satisfy customers, they need to make sure that their food is safe to eat and has been produced in a sustainable way – but their first responsibility is to turn a profit for shareholders. The pitfalls of this conflict are clear. Rarely a day seems to go by without a story pointing out the flaws in certification schemes, or the concealed social and environmental costs of seemingly harmless supermarket food. Often, the food labels and ingredients lists that consumers rely on to make purchasing decisions are wholly inadequate. Take meat production, where many of the true costs of production are hidden. We’ve been conditioned by the industry to look out for the “Red Tractor” or “organically certified” symbols as a sign of quality. But where, for example, is the label indicating what the animal was fed on? The chances are that soybeans were a large part of your former cow, pig, or chicken’s diet. Often, this soy will be linked to deforestation of ecologically important landscapes. In some cases, the soybeans might have been sourced ethically, but a lack of information means that as consumers we simply don’t know. In the fresh fruit and vegetable aisles, consumers have become used to being able to purchase any food item that they desire throughout the year. Consumers are not provided with the information, though, to decide whether the benefits to overseas farmers who produce this food outweigh the environmental costs of eating foods out of season. Collectively, this fosters food habits that are fundamentally incompatible with sustainability. In many cases, retailers have little power to provide the information consumers deserve. Half of the food consumed in the UK today is classified as “ultra-processed”, passing through multiple factories and using industrial ingredients a far cry from the fresh produce associated with home cooking. These complex supply chains are often impenetrable from the outside, meaning that often even retailers don’t know the source or even contents of their products – as was the case when UK supermarkets unknowingly stocked “beef” lasagne products containing 60-100% horse meat. Because of this, we cannot depend on food retailers alone to promote genuinely sustainable consumption. They are, after all, just the visible endpoint of a food system with problems at every stage of the chain. It’s time to bring more voices to the table and take a system-wide approach. The Modern Slavery Act, Sustainable Development Goals, Paris Climate Agreement, and New York Declaration on Forests have all enshrined grand shared ambitions for society and development. New policy initiatives such as FOOD 2030 are now drawing from these frameworks in an attempt to define the collective roles and responsibilities of producers, manufacturers, retailers and consumers in delivering sustainable food. Food “pacts” are already helping to align international, national and local policy. For example, more than 100 cities have signed up to the Milan Urban Food Policy Pact, while New York has adopted regulations to benefit local producers, and Paris has developed plans to develop 33 acres of urban farmland by 2020. Inter-disciplinary research activities are also bringing producers, suppliers and consumers together to work out practical solutions to key problems such as maintaining soil health. In the past few years, social and environmental issues have even become among the biggest concerns of shareholders. This new-found conscience in investors could play a big role in bringing about meaningful change across the food supply chain – although we must remain vigilant to greenwashing, a marketing strategy aimed at portraying a company as environmentally friendly when they are not. Of course, consumers and retailers still have a role in driving change towards a more sustainable food system. Supply does follow demand – and we mustn’t shirk our own responsibilities. But we must also band together to ensure that there are structures in place that stop food choices from being such a minefield. Only then will consumers be given the choice that they – and the planet – deserve: one that is ethical and sustainable."
"I am no supporter of peerages, but unlike Iain Ferris (Letters, 21 December), I think I can discern how the “elevation” of Oona King, a black Labour MP and woman, to the House of Lords might, in fact, have helped alleviate the democratic deficit in a way that Zac Goldsmith’s self-evidently doesn’t.Jem WhiteleyOxford • In this time of climate emergency, it seems odd that both the first and second heir to the throne feature motor vehicles on their Christmas cards (Politicians and princes say happy Christmas, 21 December).Mary HamiltonNorthleach, Gloucestershire  • For Christmas I would like an entire edition of the Guardian without a picture of Boris Johnson. I have been good in 2019 and have not voted Conservative.Judith FrenchLichfield, Staffordshire • Valerie Crews (Letters, 21 December) said: “Come back, Blair. All is forgiven.” Oh no it isn’t!Val KermodeSheffield • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
nan
nan
"Like many political neologisms, “Green New Deal” became de rigueur so fast that it had multiple variations, passionate disciples, critics (some measured, others fierce) and endless namechecks before anyone had said definitively what it meant. The “why” was clear: after decades of the business-as-usual answer to the climate crisis, the environmental movement was more or less united in its conviction that more profound change was needed than awareness-raising and intergovernmental target setting. The precedent was Franklin D Roosevelt’s New Deal of the 1930s, with which he successfully combatted the Great Depression. But does this green version essentially correspond to the bid Jeremy Corbyn made for the Labour leadership in 2015: a national investment bank and 1m jobs in green energy, to simultaneously upskill the population and reach towards a zero-carbon economy? Or is it Alexandria Ocasio-Cortez’s vision of environmental justice wrapped into social justice, the private sector swept up in the enthusiasm of a radical state? Is it Keynesianism – except instead of digging the hole and filling it up, you put a tree in it? Or is it a plan so root-and-branch post-capitalist that none of the old words will do? These books by Ann Pettifor and Naomi Klein have similar titles and are similar, too, in respect of their urgency. Pettifor delivers a sober, technical but readable account of the framework, as she – among a handful of economists and/or environmentalists, including Richard Murphy (the main architect of Corbyn’s 2015 programme), Larry Elliott (the Guardian’s economics editor) and Jeremy Leggett (solar entrepreneur) laid it out more than a decade ago. It was devised in the wake of the global financial crash, which had two obvious effects: to give it an internationalist perspective, since never more than in 2008 were economists aware of the irrelevance of borders; and to put the focus squarely on systems, rather than individual actors.  Pettifor’s case is pretty straightforward: there is a climate crisis, and it may be too late to avert it, yet to surrender means nihilism. While she directs the occasional weary sideswipe at the climate-change denier, her true enemy is defeatism, and she is very convincing on this: whether or not the planet can be saved, there is no alternative but to try. In such a context money is no object, but it’s not so much “you can’t put a price on our habitat”, rather it is the rallying cry of the heterodox economist, echoing Keynes, Roosevelt, through to US policy wonk Demond Drummer: “we can afford what we can do.” Money is not a finite natural resource, handed us by the mountains or the seas: it is a social construct based on trust and cooperation, created through credit, which is itself backed by the toil of today’s citizens, and the citizens of the future (an idea explored in her last, very readable book, The Production of Money) Deploying examples of the sheer limitlessness of money, when a government really puts its mind to it, Pettifor points to Roosevelt (a fascinating experiment in social ambition, with its own environmental element: over the nine years of the New Deal, 5% of the total male population was engaged in the Civilian Conservation Corps, planting among other things, 2bn trees). She also points to the Marshall plan, to the moon landings – all the classic examples of the hope genre, though given a different spin by climate catastrophe. If we can, as a species, muster all that effort, iconoclasm and single-mindedness just to get to the moon and have a poke about, imagine what we’re capable of when our children’s lives are at stake. Nothing will be realised, however, without systems change: the problem is not simply that “private financial firms have for decades now displaced governments in the financing of … water, transport, education, housing, environmental services and health”, leaving elected politicians without leverage or agency, and an electorate crying out for strength (hence the inexorable rise of the strongman). It is not just that governments are increasingly impotent in the face of “dollarised financial capitalism shifted off-shore”, powerless before speculative finance which demands high returns on low effort, and therefore is by definition extractive The block on progress is all those things, underpinned by something more fundamental: you cannot, as George Lakoff once spelt out, put profit in a cost benefit analysis against nature. Pettifor has a rare approach, both radical and intricate., and is never more enthusiastic than when she is spelling out the potentially transformative effects of a global transaction tax, or capital controls, or the management of interest rates by public authority, or an alternative to the dollar standard. She can persuade the reader to abandon growth as a goal in the blink of a page, and adopt instead the idea of an economic “Plimsoll line” (what’s the most a vessel can carry before compromising its seaworthiness?). The book’s purpose, though, is more than a manifesto for the climate, while stopping short of fully costed fixes it sets out to show which elements of the world as it is are incompatible with meaningful change, and how manageably (if not necessarily easily) they could be overturned. Quoting the American abolitionist Frederick Douglass, Pettifor notes: “Power concedes nothing without a demand.” Naomi Klein’s On Fire, a collection of her environmental essays over the past decade, follows the same principles. There are differences in emphasis between the UK’s Green New Deal and the US’s – Britain’s is oriented more internationally, the American version more focused on Roosevelt’s template of transformation through social justice and democratic agency, which by definition is bordered. Fundamentally, though, their prescriptions are the same, and the depth and uniqueness of Klein’s work is in the human beings she brings to the party. Philosophers, flood victims, students, conservationists – she has a reporting style that is rooted in her decades of activism; everybody’s voice is given the same dignity, the same weight. This pluralism alone presents a vast horizon of possibility, a sense of limitless creative energy, all engaged on the same question. None of us is alone, and nor do we have to leave it all to Greta Thunberg. This sweetens what is otherwise quite a bitter pill, a globe that knows its peril but can’t respond. From the floods of Hebden Bridge to the fires of British Columbia, from the oil spill in the Gulf of Mexico to cobalt mines in the Democratic Republic of Congo, the harder you look, the more cause there is to despair. Klein finds hope not in large motivational assertions, but in the detail: so she quotes the geophysicist Brad Werner, talking an audience through his computer modelled conclusion that “global capitalism had made the depletion of resources so rapid, convenient and barrier-free that ‘earth-human systems’ were becoming dangerously unstable in response”. When pressed by a journalist for a clear answer on the “are we fucked” question, Werner set the jargon aside and replied: “More or less.” Wait, though: there is one source of friction that could slow down and even derail the machine – mass resistance movements. Direct action by environmentalists, say; or hundreds of thousands of school children striking; resistance is not only germane to the dynamic, it is a powerful countervailing force. This isn’t a book about heroes: Klein has an equally keen ear and roving eye for the deniers, the obstructionists, the defeatists, the status quo-ists. She creates vivid and terrifying portraits of the fossil fuel industry in full sail, of the Republican party completely subservient to it (this feels new and Trumpian, but isn’t: Newt Gingrich unveiled the slogan “Drill Here, Drill Now, Pay Less,” in 2008), of the victims of corporate carelessness and catastrophic climate events. Klein can sink your spirits with an analogy: she draws a parallel between the extinction peril of “mismatching”– the process whereby “warming causes animals to fall out of step with a critical food source” – and our own cultural mismatch, where the greatest collective action is required of us just as we are at our most socially atomised. Yet she can lift them again with a metaphor, a parable, the sight of a whale, the feeling of the wind. Pettifor works extremely hard to describe the mechanisms by which capitalism and corporatism created the climate crisis and, more recently, the degradation of democratic politics. Klein is bolder, tearing through these ideas – the connection between “climate crisis, wealth concentration and racialised violence”, the “violence of othering in a warming world” – on her way to somewhere both more urgent and more nourishing: the sites of resistance, and how each grain might turn into enough sand to stop the machine. These Green New Deals dovetail so well as companion works that they seem designed to be read together. Or is it simply that this is an idea whose time has come – not a moment too soon, and quite possibly too late? • The Case for the Green New Deal is published by Verso (RRP £12.99); On Fire: The Burning Case for a Green New Deal is published by Allen Lane (RRP £20). To buy copies go to guardianbookshop.com. Free UK p&p call 020-3176 3837."
nan
"In the last month alone, major players within the fossil fuel industry – “big oil” – have made some big announcements regarding climate change. BP revealed plans to reduce its greenhouse gas emissions by acquiring additional renewable energy companies. Royal Dutch Shell defended its US$1-US$2 billion green energy annual budget. Even ExxonMobil, until recently relatively dismissive of the basic science behind climate change, included a section dedicated to reducing emissions in its yearly outlook for energy report. But this idea of a “green” oil company producing “clean” fossil fuels is one that I would call a dangerous myth. Such myths obscure the irreconcilability between burning fossil fuels and environmental protection – yet they continue to be perpetuated to the detriment of our planet. Myth 1: Climate change can be solved with the same thinking that created it Measures put in place now to address climate change must be sustainable in the long run. A hasty, sticking plaster approach based on quick fixes and repurposed ideas will not suffice. Yet this is precisely what some fossil fuel companies intend to do. To address climate change, major oil and gas companies are mostly doing what they have historically excelled at – more technology, more efficiency, and producing more fossil fuels. But like the irresponsible gambler that cannot stop doubling down during a losing streak, the industry’s bet on more, more, more only means more ecological destruction. Irrespective of how efficient fossil fuel production becomes, that the industry’s core product can be 100% environmentally sustainable is an illusion.  A potential glimmer of hope is carbon capture and storage (CCS), a process that sucks carbon out of the air and sends it back underground. But despite being praised by big oil as a silver bullet solution for climate change, CCS is yet another sticking plaster approach. Even CCS advocates suggest that it cannot currently be employed on a global, mass scale. Myth 2: Climate change won’t spell the end of the fossil fuel industry According to a recent report, climate change is one factor among several that has resulted in the end of big oil’s golden years – a time when oil was plenty, money quick, and the men at the top celebrated as cowboy capitalists.  Now, to ensure we do not surpass the dangerous 2°C threshold, we must realise that there is simply no place for “producers” of fossil fuels. After all, as scientists, financial experts, and activists have warned, if we want to avoid dangerous climate change, the proven reserves of the world’s biggest fossil fuel companies cannot be consumed. Myth 3: Renewables investment means oil companies are seriously tackling climate change Compared to overall capital expenditures, oil companies renewables’ investment is a miniscule drop in the barrel. Even then, as companies such as BP have demonstrated before, they will divest from renewables as soon as market conditions change. Big oil companies’ green investments only produce tiny reductions in their overall greenhouse gas emissions. BP calls these effects “real sustainable reductions” – but they accounted for only 0.3% of their total emissions reductions in 2016, 0.1% in 2015, 0.1% in 2014, and so on. Myth 4: Hard climate regulation is not an option One of the oil industry’s biggest fears regarding climate change is regulation. It is of such importance that BP recently hinted at big oil’s exodus from the EU if climate regulation took effect. Let’s be clear, we are talking about “command-and-control” regulation here, such as pollution limits, and not business-friendly tools such as carbon pricing or market-based quota systems. There are many commercial reasons why the fossil fuel industry would prefer the latter over the former. Notably, regulation may result in a direct impact on the bottom line of fossil fuel companies given incurred costs. But climate regulation is – in combination with market-based mechanisms – required to address climate change. This is a widely accepted proposition advocated by mainstream economists, NGOs and most governments. Myth 5: Without cheap fossil fuels, the developing world will stop Total’s ex-CEO, the late Christoph de Margerie, once remarked: “Without access to energy, there is no development.” Although this is probably true, that this energy must come from fossil fuels is not. Consider, for example, how for 300 days last year Costa Rica relied entirely on renewable energy for its electricity needs. Even China, the world’s biggest polluter, is simultaneously the biggest investor in domestic renewables projects. As the World Bank has highlighted, in contrast to big oil’s claims about producing more fossil fuels to end poverty, the sad truth is that by burning even the current fossil fuel stockpile, climate change will place millions of people back into poverty. The UN concurs, signalling that climate change will result in reduced crop yields, more waterborne diseases, higher food prices and greater civil unrest in developing parts of the world. Myth 6: Big oil must be involved in climate policy-making Fossil fuel companies insist that their involvement in climate policy-making is necessary, so much so that they have become part of the wallpaper at international environmental conferences. This neglects that fossil fuels are, in fact, a pretty large part of the problem. Big oil attends international environmental conferences for two reasons: lobbying and self-promotion.  Some UN organisations already recognise the risk of corporations hijacking the policy-making process. The World Health Organisation, for instance, forbids the tobacco industry from attending its conferences. The UN’s climate change arm, the UNFCCC, should take note. Myth 7: Nature can and must be “tamed” to address climate change If you mess with mother nature, she bites back. As scientists reiterate, natural systems are complex, unpredictable, and even hostile when disrupted. Climate change is a prime example. Small changes in the chemical makeup of the atmosphere may have drastic implications for Earth’s inhabitants. Fossil fuel companies reject that natural systems are fragile – as evidenced by their expansive operations in ecologically vulnerable areas such as the Arctic. The “wild” aspect of nature is considered something to be controlled and dominated. This myth merely serves as a way to boost egos. As independent scientist James Lovelock wrote, “The idea that humans are yet intelligent enough to serve as stewards of the Earth is among the most hubristic ever.”"
"
Share this...FacebookTwitterNote: Kenneth’s usual Thursday post will appear tomorrow
========================================
U.S. House Majority Whip Steve Scalise was seriously wounded by a loony leftist gunman, who obviously had been driven over the edge by all the recent hate signals coming from a violence-inciting media.
However, all the left-wing environmental violence just didn’t start yesterday, or since Trump started his campaign. It has in fact been energetically brewing for years. We’ve been warning about it for a long time. Especially skeptics of alarmist climate science bear witness to this. For example an Austrian professor not long ago called for the execution of climate deniers.
Before that, in 2010, a video of pornographic violence produced by the 10 10 climate activism campaign and Richard Curtis fantasized of blowing up climate skeptics:

The message: people who refuse to accept global warming dogma need to be dehumanized, blown up and discarded with the trash. Today these disturbing fantasies of violence are becoming the new reality.
In 2007 Greenpeace featured an angry kid, who used highly threatening language aimed at adults who declined to agree to all radical carbon emissions reductions. Give in to our demands, or we’ll throw a tantrum like you’ve never seen.

That kid has since grown up, and we’ll note that none of his scripted “by the time I grow up” catastrophe scenarios have come to pass. Ironically the one prediction that has come true is that they “won’t be cute“. Today’s youth are resorting to a level of political violence and destruction not seen in generations.
Recently, Australian climate skeptic journalist Andrew Bolt was attacked as well. The list of attacks on skeptics is endless.
Severed heads, “blood in the streets”
On the political front, things have caught up and surpassed the viciousness we’ve seen in climate science. Far more disturbing was Grammy award-winning comedian Kathy Griffin holding up a model severed head looking like Donald Trump.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Yesterday Breitbart provided a list of 15 examples of celebrities envisioning violence against the GOP or President Trump.
Even former Department of Justice head Loretta Lynch hinted at “blood in the streets“.
Germany’s AfD party under constant violent attack
Leftist violence is not exclusive to the USA, but is worrisomely real in Germany. The right wing AfD party – a completely legal and totally legitimate party – has been physically attacked numerous times by leftist thugs. The media mostly ignores it all, and thus give the green light for the violence to continue.
Justice by thugs
In April one AfD politician was beaten with a board by a lunatically radicalized 18 year-old. Such attacks are often viewed with glee and snickers of delight in Germany. Alternative views and opinions are no longer tolerated in the land of “poets and thinkers”, where one can be in favor of intergenerational relationships, communism, Sharia law, etc. but must avoid expressing support for strong borders, Brexit or the US President.
Even hotels and establishments providing hosting services for AfD events are singled out and violently attacked. Die Welt here writes how one establishment owner had to shut down:
Doors were vandalized, tires punctured, horse manure sprayed: After massive threats an innkeeper in Schleswig Holstein closed his business. He had rented rooms to the AfD for an election campaign party.”
The list of attacks on the right wing party is long as well, and all carried out by radical leftists with the full blessing or tolerance of “mainstream” parties and media.
It’s time to call for a march of tolerance in Washington, and an end to the political posse that’s been unleashed by the left.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAGW ‘Disaster’ Predictions Recycled
1978: 5 Meter Sea Level Rise By 2028
 2015: 10 Feet Sea Level Rise By 2065 


Forecasting human-caused climate disaster is anything but new.
Nearly 40 years ago, a landmark paper was published in the prestigious scientific journal Nature providing a dapper rubric for the modern human-caused climate disaster papers to follow.
The Mercer (1978) “…a threat of disaster” paper introduced above was fraught with presumptions, guesswork, and spectacularly wrong predictions about the connections between fossil fuel consumption by humans and future carbon dioxide (CO2) parts per million (ppm) concentrations, the melting of polar ice sheets, and an impeding sea level rise disaster.
Specifically, Mercer claimed that atmospheric CO2 concentrations would double from ~330 parts per million (late 1970s) to ~660 ppm within 50 years, or by 2028 — due to a continuance of the rapid growth in fossil fuel consumption.  Indeed, global-scale fossil fuel or CO2 emissions rates have increased by approximately 100% since the late 1970s, or from about 5 gigatons of carbon (GtC) per year (late 1970s) to about 10 GtC/year by 2014.  And yet, despite the explosive increase in CO2 emissions, the atmospheric CO2 concentration is nowhere close to reaching 660 ppm.  Instead, it currently hovers around 400 to 405 ppm.  It would appear highly implausible to claim that CO2 concentrations will rise by more than 250 ppm in the next 11 years.
The Mercer paper also states that the expected temperature increase due to the doubling of CO2 concentrations would, according to climate models, yield a temperature change of +10°C for the region.  This sweltering warmth could, according to advocates of human-caused climate alarm, cause a “rapid deglaciation” of the West Antarctica ice sheet that would, in turn, lead to sea level rise by about 5 meters within 50 years (2028).
As will be illustrated below, the temperatures for Antarctica as a whole have not risen since 1979.  Instead, they have been flat to slightly cooling.  And, of course, without the “rapid deglaciation” of the West Antarctic ice sheet, sea levels would need to rise by about 4.95 meters in the next 11 years to satisfy the “disaster” forecasts outlined by Mercer in 1978.



Today, Scientists Predict 1400 ppm CO2, 16- 30°C Warming By 2130

Dr. James Hansen, the leading  climate scientist at NASA for decades and often characterized as the father of climate change awareness, has long been alarming the public with forecasts of climate doom.
Like Mercer (1978), Hansen has written that CO2 concentrations will quintuple to reach 1400 ppm just 118 years from now (2013), or by the year 2130.  Humans, he writes, will burn through 10,000 GtC of fossil fuels by then. This atmospheric CO2 concentration (1400 ppm) is said to yield a warming of 16°C globally, 20°C over land, and 30°C at the poles by 2130.  It is also claimed that this human-caused climate disaster will eliminate agricultural production for most of the world and otherwise  make “most of the planet uninhabitable by humans”.

Hansen et al., 2013
“If we assume that fossil fuel emissions increase by 3% per year, typical of the past decade and of the entire period since 1950, cumulative fossil fuel emissions will reach 10 000 Gt C in 118 years [~2130].  Are there sufficient fossil fuel reserves to yield 5000–10 000 Gt C? Recent updates of potential reserves, including unconventional fossil fuels (such as tar sands, tar shale and hydrofracking-derived shale gas) in addition to conventional oil, gas and coal, suggest that 5×CO2 (1400 ppm) is indeed feasible.”
“Our calculated global warming in this case [1400 ppm] is 16°C, with warming at the poles approximately 30°C. Calculated warming over land areas averages approximately 20°C. Such temperatures would eliminate grain production in almost all agricultural regions in the world. Increased stratospheric water vapour would diminish the stratospheric ozone layer. More ominously, global warming of that magnitude would make most of the planet uninhabitable by humans.”

Modern Alarmist Forecast: Now 10 Feet Of Sea Level Rise By 2065

It is obvious the 660 ppm CO2 concentration, wholesale melting of West Antarctica, and 5 meters of sea level rise forecast by Mercer in 1978 has not materialized.  No matter.  When observations contradict projections found in climate models, modern climate scientists don’t question or modify their CO2-caused-climate-disaster assumptions.  They just change the dates.
The current forecast from climate scientists is that both the Greenland and Antarctica ice sheets will melt 10 times faster than what they have been in recent decades, and this will lead to 10 feet (~3 meters) of sea level rise by about 2065.


Observations Of Negligible Mass Losses For Antarctica In Recent Decades

According to the most highly-cited analyses of polar ice sheet melt and contribution to sea level rise, the Antarctic ice sheet as a whole changed in mass by -71 gigatonnes (GT) per year between 1992 and 2011.  This modest mass loss contributed just 0.2 mm/year to sea level rise over that 20 year period.

Shepherd et al., 2012
“Between 1992 and 2011, the ice sheets of Greenland, East Antarctica, West Antarctica, and the Antarctic Peninsula changed in mass by –142 ± 49, +14 ± 43, –65 ± 26, and –20 ± 14 gigatonnes year−1, respectively. Since 1992, the polar ice sheets have contributed, on average, 0.59 ± 0.20 millimeter year−1 to the rate of global sea-level rise.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




To put that 0.2 mm/year sea level rise contribution from Antarctica (1992-2011) into perspective, at that pace it would take 100 years for the Antarctic ice sheet as a whole contribute 2 centimeters to sea level rise.
And more recent estimates of the Antarctic mass balance contribution to sea level rise has the East Antarctica ice sheet gaining mass at a more accelerated pace for 2003-2013 than the mere +14 Gt per year identified by Shepherd et al. (2012) for 1992-2011.  For example, Martín-Español et al. (2017) find that the total mass trend for the East Antarctic Ice Sheet was a gain of +57 Gt per year during 2003-2013, which is 4 times the rate of gain assessed for 1992-2011.  Effectively, this would reduce the Antarctic contribution to sea level rise to close to zero for recent decades.

Martín-Español et al., 2017
“We investigate the mass balance of East Antarctica for 2003–2013 using a Bayesian statistical framework. … We apportion mass trends to SMB and ice dynamics for the EAIS, based on two different assumptions, different remote sensing data and two RCMs. In the first experiment, the model apportions about a third of the mass trend to ice dynamics, +17 Gt/yr, and two thirds, +40 Gt yr−1 to SMB, resulting in a total mass trend for the EAIS [East Antarctic Ice Sheet] of +57 ± 20 Gt yr−1.”

Observations Reveal No Recent Warming In Antarctica

Antarctica has not been cooperating with the forecasts of human-caused climate disaster narrative.  Within the last year, scientists have been reporting that essentially the only place on the Antarctic ice sheet where there was pronounced warming in recent decades — the West Antarctic Peninsula — has reversed course since the 21st century began.  It is now cooling…rapidly.  There has even been “a shift to surface mass gains” for glaciers in that region.

Turner et al., 2016
“Here we use a stacked temperature record to show an absence of regional warming since the late 1990s. The annual mean temperature has decreased at a statistically significant rate, with the most rapid cooling during the Austral summer.”


Oliva et al., 2017
“However, a recent analysis (Turner et al., 2016) has shown that the regionally stacked temperature record for the last three decades has shifted from a warming trend of 0.32 °C/decade during 1979–1997 to a cooling trend of − 0.47 °C/decade during 1999–2014. … This recent cooling has already impacted the cryosphere in the northern AP [Antarctic Peninsula], including slow-down of glacier recession, a shift to surface mass gains of the peripheral glacier and a thinning of the active layer of permafrost in northern AP islands.”

Another recent analysis reveals that West Antarctica — the region that Mercer maintained would rapidly melt and contribute 5 meters to sea level rise — has undergone the “strongest” long-term cooling trend of any region in the Antarctic.  Furthermore, Stenni et al. (2017) conclude there has been “no continental-scale warming of Antarctic temperature” evident in the last century.

Stenni et al., 2017
“A recent effort to characterize Antarctic and sub-Antarctic climate variability during the last 200 years also concluded that most of the trends observed since satellite climate monitoring began in 1979 CE cannot yet be distinguished from natural (unforced) climate variability (Jones et al., 2016), and are of the opposite sign [cooling, not warming] to those produced by most forced climate model simulations over the same post-1979 CE interval.
(1) Temperatures over the Antarctic continent show an overall cooling trend during the period from 0 to 1900 CE, which appears strongest in West Antarctica, and (2) no continent-scale warming of Antarctic temperature is evident in the last century.”


Extending the temperature record back even further, modern temperatures in West Antarctica are still some of the coldest of the last 8,000 years.

Fudge et al., 2016


Forecasts Of Human-Caused Climate Disaster Are Non-Scientific

In science, when a hypothesis is advanced and tested using empirical evidence, and the results of the testing do not support the hypothesis, the hypothesis is then discarded.
In climate science, a hypothesis has been advanced that says a rise in human CO2 emissions will cause polar ice sheets to dramatically recede and contribute meters to sea level rise within a span of decades.  This hypothesis is not supported by the observational evidence.
But instead of discarding this hypothesis and conceding that our knowledge of the factors contributing to polar ice sheet melt and sea level rise are still not fully developed, climate scientists continue to embrace their favored hypotheses anyway.
So instead of human-caused climate disaster occurring in 2028, it will now occur in 2065.  Or perhaps 2100.  Or 2130.  Or…someday.

Image Source: State of the Climate, 2016
 
Share this...FacebookTwitter "
"There’s much more to snow crab than their tasty legs and claws. Especially so in the last few years as these large, cold water Arctic crabs have started showing up in the Barents Sea, where they’ve never been before. The snow crab’s story is a harbinger of climate change complexities on the horizon, and much more. Until recently, they could only be found in Alaskan, Pacific Russian and Atlantic Canadian waters. But globalisation and growing human access to Arctic waters due to climate change have expanded the crab’s reach: increased marine traffic has seen the species successfully hitch a ride to the Barents from elsewhere in the Arctic. The new territory has proved quite amenable, and they are thriving. Crabs still at home in their native habitats, however, have been weathering climate change less successfully due to climate changes and warming waters.  Climate change is also making it easier to fish the crabs, with more of the Barents ice-free for longer. And that means humans are benefiting too, because humans adore eating this particular variety of crab. Alaskan crab fishing is so dangerous, risky, but potentially profitable that it has had its own TV series since 2005: The Deadliest Catch.  Given humanity’s voracious appetite for this particular variety of crab, when they started appearing in Russian waters in the Barents Sea in the late 1990s, the Russians and Norwegians agreed to study them to see whether they could make money for them too. They also wanted to know what effects they were having as newcomers to the area’s seabed. The countries now do joint ecosystem surveys each autumn, and have a pretty good idea now that populations are growing very fast – fast enough that some predict that their value in the fishing industry in Norway could overtake cod in terms of value within a decade or two. The crabs eat pretty much everything, but the net effect on the marine ecosystem’s productivity is still unclear. This is for two reasons. First, baseline science on Arctic seabed conditions still has a lot of unknowns. We can’t be sure what the changes are, because we don’t really know what has always been there. Second, the way the crabs dig into the seabed can release food for other species.  The ecosystem is definitely changing, but we don’t really know if that’s going to be good or bad for the planet. It’s at times like these that we like to invoke the precautionary principle, which suggests that we should avoid taking risks when consequences are highly uncertain but may include permanent losses or other unacceptable damages to present or future generations. In this case, that means stopping the spread of the crab until we know more. That way we can avoid making irreversible choices.  But humans also like to make money, and the global price of snow crab keeps rising. As the crab has expanded west, it has crawled out of Russian waters and into international waters – more than 200 nautical miles from any shore – meaning any nation’s vessels could fish for them. Some EU and Norwegian vessels started doing that around 2012.  This fishing has an added bonus: it has reduced the population of crabs that remain on the seabed that could continue moving west and changing the existing ecosystems. And so market forces are currently helping implement the precautionary principle, which is unusual to say the least. The crab’s advance into international waters meant anyone might fish crab and make money. But in 2015, Norway and Russia found common ground and changed the rules in their favour.  They used a loophole in international law to categorise the crab as seabed resource, basically equivalent to a mineral or oil, instead of a fishing resource. Reclassifying the crab means that the Russians and Norwegians can kick out vessels from other countries and keep the profits from the crab. This is because continental shelves define mineral resource boundaries, while distances to shore define fisheries boundaries. The Barents’ continental shelves extend beyond the 200 nautical mile fishing boundaries, and so this identity change benefits the Norwegians and the Russians. The arrest of a foreign crab fishing vessel in these Barents international waters spawned a lawsuit in Norway that has made it to the highest state court, which recently held up Norway’s actions. The case has potential to proceed to European courts.  But that’s not even the biggest controversy. The Norwegian continental shelf also extends to Svalbard. Due to an international treaty from 1920, anyone who wants to engage in commercial or scientific opportunities on Svalbard may do so.  This has led to a complementary set of international treaties which help govern fishing in the area around the archipelago. When international vessels were kicked out of the international waters, some moved to the Svalbard zone, gaining international permits to fish snow crab there. But Norway arrested one of these boats, too. EU states continue to issue licenses, against Norway’s insistence that they cease. The question at the bottom line is – do the continental shelf rules trump the 1920 Svalbard rules, or vice-versa?  This time, it is not just about profit from crabs. The stakes are high. The dispute is set to resolve broader questions about the seabed under the Svalbard zone. As valuable as the crabs may be, oil, gas and other seabed resources may be many times more valuable. Norway and the EU are at an impasse: legal arguments will have to decide whether Norway has the right to other seabed mineral and oil resources in the zone, or whether the resources fall under the open commercial access rules for Svalbard.  The consequences should also be expected to extend far beyond the Barents. Because climate change is making it more and more common for species to move in and out of legal jurisdictions. This will require new ways of negotiating shared resources amongst interested local and global parties. And these decisions will then impact the ecological changes brought by the species, as well as who profits."
"
Share this...FacebookTwitterProfessor Friedrich Indra has been retired since 2005 and is considered to be one of the world’s leading engine developers. The 76-year old used to work for Audi and General Motors.

Electric mobility is an environmental fraud, says world leading expert in engine technology. Image: Tesla
“Doesn’t solve single environmental problem”
In a recent interview with the online FOCUS news magazine he raised a lot of eyebrows by stating that he thinks electric mobility is a “dangerous false path”, claiming that the electric car “does not solve a single environmental problem” and that it “contributes nothing to climate protection”.
Indra calls the claims that electric cars are CO2-free “absurd”.
Fake efficiency
Citing an earlier stiudy by a Professor Spicha, Indra says that the well-to-wheel-CO2 of an electric car in Germany is in fact 1.6 times worse than the conventional internal combustion engine. The CO2 perforamnce of an electric car in China is even four to five times worse when it comes to consumption, and that does not mention the huge energy quantities needed for manufacturing the batteries that electric cars need, which would be enough to power a conventional automobile 30,000 kilometers, he told FOCUS.
Electric cars also have the problems of recycling the batteries, as they are a long way from being fully recyclable.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to Indra, internal combustion engines have made “very impressive progress“, saying: “The motors are continuously getting more powerful and more fuel efficient.” The engine expert believes that the final solution is “CO2-neutral synthetic fuels. They need as much CO2 for for their manufacture as emitted when in operation.”
The “second greatest environmental fraud”
When it comes to hybrid automobiles, Indra opinion is harsh, calling the plug-in-hybrids “the second greatest environmental fraud because the determination of the fuel consumption does not even include the power that was previously needed to charge up the car.” This is how “sportscars using the technology come up with perverse values like 3.1 liters consumption per 100 km [80 mpg]”.
In the interview Indra rails against what he calls “widespread hatred against internal combustion engines” among the media and policymakers, who he says exploited the VW emissions test cheating affair to spread more hate against the internal combustion engines. He thinks the scandal was played up by the media and is “completely disassociated from fact“. Never has “industry and policymaking acted so irrationally“. He believes politicians are in for a rude awakening once the true costs start coming in.
Toy for the rich
On the current a future trend of electric cars, Indra tells FOCUS:
In the meantime in some countries the market share by pure electric cars is already retreating. That’s also going to happen with the plug-in-hybrids after all the ‘rich people’ are supplied with these cars.”
Massive government subsidies
He says the claimed “success” of electric cars in China and Norway is due to massive government subsidies: “No country in the world can afford that over the long-term. That will level off once again, as is already the case in Norway.”
 
Share this...FacebookTwitter "
"For too long “building your own home” in the UK has been a privilege reserved for those who already own property. Expensive land, tough planning rules and the time and expertise required have meant that most people self-build homes were more architectural vanity projects – like you might see in Grand Designs and less a practical housing solution. While design-led homes might be the dream for architects, TV producers and the restless urban middle classes, they tend to be an unaffordable luxury for almost everyone else. Yet it doesn’t have to be that way. Why shouldn’t those who most need housing also get to build it themselves? The huge demand for new homes in the UK has lead to a resurgence in collectively owned self-built developments, featuring many first time owners. This opens the property market up to a new demographic and may even help overcome the housing crisis. You don’t have to go far back to find the more egalitarian roots of self-built housing. Until the end of World War II, self build offered a way for working class people to become home owners. However, over time building your own home became increasingly more restricted to the middle-class who already owned property.   Yet even within this landscape a small number of schemes aimed specifically at those in housing need have succeeded. My own research has focused on understanding how self build fits into the wider housing economy. I’ve worked closely with self builders to understand their motivations and experiences, and have documented several group projects.  Two particularly stand out: one, a group of nine families in north-east London who helped build their own secure social housing; the other, a scheme in Liverpool that combines self build with shared ownership.  The London project was started by a local council tenant, John Struthers, whose only motivation was to provide housing stability for his children. Faced with overcrowded homes and a ten-year wait for larger properties, Struthers and other families instead formed the Headway Selfbuild Group and worked together to fit out the inside of ten new houses in exchange for tenancy. Struthers pushed the council and the housing association Circle Housing Circle 33 to provide support (the council still owns the new homes). He identified available land and demonstrated the scheme was viable. He approached the Community Self Build Agency, all the while encouraging other council tenants to join the group.  They worked evenings and weekends for 18 months fitting out the insides of the houses, attending evening college classes to learn more about construction and carpentry. No one could move in until all the homes were completed and they had successfully worked on each others’ houses – a truly collective endeavour. After they completed the kitchen fitting and carpentry training in March 2015 the group moved on site.  The award-winning project in Toxteth, Liverpool, focused on giving people in housing need access to shared ownership, while also building up relationships between future residents and the wider community.  Future residents had to already live or work in the city, or otherwise have strong links. These “home partners” worked with volunteers to construct 32 houses. In exchange for 500 hours of work on site, future residents received “sweat equity”: a £10,000 reduction on the cost of their home. A model of shared ownership, potential residents also had to have an income that would permit them to take out a mortgage to cover at least 50% of the value of the property.  This scheme was managed and organised by the charity Housing People, Building Communities (formerly Liverpool Habitat for Humanity), in association with Sanctuary Group.  These examples demonstrate that, even in the current housing climate, self build can offer alternatives to the mainstream.  The schemes that have succeeded are to be commended and celebrated. Often championed by one or two individuals determined to see the projects through against the odds, these schemes are hard work, requiring specialist training in construction, group processes and conflict resolution. They have to be carefully managed. Finding land and investment partners, bringing on board housing associations and councils, and maintaining peace between the various groups, all require significant time and energy. At the same time, this is set within a housing economy that favours large house builders and profit-driven developments. The significant barriers to self build in the UK that have resulted in a sector dominated by middle-class homeowners reflect the state of the wider housing economy. Widespread adoption of group self build schemes faces serious challenges from rising land and property values and profit-driven housing developments. Nonetheless, with some hard work and organisation, they can offer alternatives to mainstream housing both for those people who can’t afford to buy a property and those who need a decent roof over their head full stop."
" The government was warned by the Department of Home Affairs after the May election that Australia faced more frequent and severe heatwaves and bushfires, and that livelihoods would be affected without effective action on climate change. The department’s incoming government brief to the home affairs minister, Peter Dutton, warned of “disasters” exacerbated by climate change. “The physical effects of climate change, population growth, and urbanisation mean that without effective action more Australians’ livelihoods will be impacted by disasters into the future and the cost of those disasters will continue to grow,” the brief stated. “Coordinated national action to drive efforts to reduce these risks and improve national resilience is required.” The brief, obtained under freedom of information, said disasters were only going to get worse. “Life in Australia is increasingly disrupted by disasters. Australians will experience – as we did this summer – more frequent and severe heatwaves, bushfires, floods, and cyclones. These will increasingly occur concurrently.” Sign up to receive the top stories from Guardian Australia every morning The brief quoted Deloitte Access Economics figures putting the cost of disasters to the Australian economy at $18.2bn a year, rising to $39bn by 2050. Scott Morrison has ruled out a change in climate policy in response to the bushfire crisis. Since returning to Australia from a holiday in Hawaii on Saturday night, Morrison has been touring fire-affected regions of New South Wales. While those defending the prime minister’s decision to take leave have frequently referred to the bushfire and disaster response as primarily a state issue, a chart put together by the department in the brief puts the prime minister on equal footing with state premiers and chief ministers when it comes to crisis coordination arrangements. The brief noted that while state and territory governments are considered the first responders, the federal government’s role is to support the governments through national coordination of efforts in the event crises cross state borders, as well as developing and implementing national mitigation policies. “The Australian government provides support to the states and territories when coordinated assistance is requested [or] jointly manages a crisis with state and territories if the crisis has the potential to affect, or has affected multiple jurisdictions.” The document said the federal government had responsibility for a national crisis coordination centre for hazard monitoring across the country, as well as responsibility for the national aerial firefighting centre. In April the government set up the national disaster risk reduction framework with $130.6m set out over five years to help state and territory governments implement the strategies in the framework. The framework identifies climate risk as part of the overall national disaster risk, but strategies are focused on identifying potential disaster risks and collecting data on disasters, rather than specific action on climate change."
"The bangs and fizzes of fireworks are rapidly replacing the chimes of Big Ben as the defining sound of New Year’s Eve celebrations in London, while around the world, city landmarks are becoming stages for increasingly spectacular pyrotechnic displays. Since the millennium, the popularity of fireworks has even extended into back gardens, where smaller fireworks or sparklers are lit up at the stroke of midnight. Fireworks are great fun. We all enjoy guessing the colours of the rockets before they ignite in the sky, hearing the explosions echo off nearby buildings, or writing our names in light with hand sparklers.  But there is an environmental price to pay. Firework smoke is rich in tiny metal particles. These metals make firework colours, in much the same way as Victorian scientists identified chemicals by burning them in a Bunsen flame; blue from copper, red from strontium or lithium, and bright green or white from barium compounds.  There is more smoke from potassium and aluminium compounds, which are used to propel fireworks into the air. Perchlorates are also used as firework propellants; these are a family of very reactive chlorine and oxygen compounds, which were also used by NASA to boost space shuttles off the launch pad. Fireworks can lead to substantial air pollution problems. There are well documented examples from cites around the world. In Spain, metal particle pollution from Girona’s Sant Joan fireworks fiesta can linger in the city for days. Across India’s cities, the annual Diwali fireworks cause pollution that is far worse than Beijing on a bad day.  Guy Fawkes is regularly the most polluted day of the year in the UK, although scientists from King’s College London have found that pollution from bonfires – the traditional way of marking Guy Fawkes – is also a part of this mixture. Fireworks can have significant effects on air pollution in enclosed spaces, too. In Germany, tests have shown how goal and match celebrations with flares, smoke bombs and other pyrotechnics can fill football stadiums with high concentrations of airborne particles.    And of course, what goes up has to come down. Fireworks that fall to the ground contain residues of unburnt propellants and colourants, while particle pollution in the air eventually deposits on the ground or gets washed out by rain. Some of this finds its way into lakes and rivers , where percolate has been linked to thyroid problems, causing limits to be set for drinking water in some US states.  This is a major concern for lakeside resorts and attractions that have frequent firework displays. Researchers in London have collected airborne particles from Diwali and Guy Fawkes. These were found to deplete lung defences far more than pollution from traffic sources, suggesting a greater toxicity. Across India, Diwali fireworks have been linked to a 30% to 40% increase in recorded breathing problems. Like New Year’s Eve, fireworks are a relatively new phenomenon at Diwali.  Traditionally, Diwali was celebrated with the lighting of ghee burning lamps – but this changed with the opening of India’s first firework factory in 1940. An Indian court petition is demanding better public safety information and restrictions on the sale and use of fireworks – but this came too late to limit the smog caused by this year’s celebrations. Some simple steps can be taken to reduce our exposure to firework pollution. For one thing, setting them off in enclosed spaces is a very bad idea, as are hand-held sparklers. Positioning crowds upwind of fireworks displays is another obvious way of reducing their negative health impacts. Yet fireworks are already the largest manufactured source of some types of metal particles in the UK atmosphere. And the proportion of pollution from fireworks will only increase, as huge investments are made to reduce other sources of urban pollution. Particle filters are present on nearly all modern diesel vehicles and factory emissions across the developed world are continually being tightened  – but firework pollution remains unchecked.  Perhaps the best way to tackle the pollution caused by fireworks is not to have them at all. But this seems rather extreme (not to mention a lot less fun). The high-precision, controlled displays that we see at international landmarks on New Year’s Eve demonstrate the great innovation of the fireworks industry. It’s time for this innovative approach to be applied to reduce the environmental impact of fireworks, so that we can continue to enjoy the excitement of displays for years to come."
"Plastic pollution in the oceans is a major problem that is finally getting the attention it deserves, thanks to Blue Planet II. It makes headline news almost every week – and famous figures such as the Pope, Prince Charles, Dame Ellen MacArthur and Sir David Attenborough have all joined the debate.  Regular people without such platforms can at least urge governments across the globe to take action. And one idea would be to use the budget for foreign aid. While many countries still have a problem with litter, there are at least regular collections of waste and recyclable materials. The point is not that richer nations don’t need to address their use of plastic – they do – but that the benefits “per dollar” are much greater in poorer countries where even minimal interventions would make a huge difference. Therefore there is now a moral and environmental case for using aid money to support better waste management in poorer countries. A recent report by the Chartered Institute of Waste Managers and the UK-based NGO WasteAid claims that mismanaged waste from developing countries accounts for up to 70% of ocean plastic by weight. Just five countries in East Asia are responsible for most of this. Meanwhile 38 out of 50 of the world’s largest uncontrolled dump sites are in coastal areas and many of them spill waste directly into the sea. So to clear up marine plastics, we firstly have to address waste management in poorer countries. Doing so could halve the quantity of plastics entering the oceans worldwide. But plastic doesn’t just affect the oceans, it also pollutes the air and water on land – and it directly harms humans too. Poor waste management is linked to diseases or conditions such as diarrhoea, cholera, respiratory illness, and eye and skin infections. The same WasteAid report shows that 2 billion people live without waste collection and 3 billion without controlled waste disposal – so the numbers affected can be huge: roughly 9m people die each year of diseases linked to either mismanagement of waste or pollutants. There’s even a climate change aspect to this, as waste that isn’t recycled or properly managed tends to be burnt off, releasing soot and other greenhouse gases into the atmosphere. If the growing volume of waste in emerging economies is not properly controlled, dumpsites could account for 8-10% of global greenhouse gas emissions by 2025 at a time when international agreements are already attempting to control emissions. Helping poorer countries deal with ever-increasing amounts of plastic and other waste is ultimately a core development issue – and one squarely within the remit of government ministries such as the UK’s Department for International Development (DFID) or international organisations such as the World Bank. It is much better to deal with plastic at the point it becomes waste, rather than attempt to salvage it later from the ocean. Treatment of waste is specifically mentioned in three of the UN’s 17 Sustainable Development Goals , after all. And waste also has an impact on many other UN goals, such as reducing poverty, improving health and equality, providing clean energy, cleaner cities and healthier populations and – last but not least – the protection of air, land and water from pollution damage. As a member of the United Nations, the UK has committed to spending 0.7% of gross national income on foreign aid, amounting to around £14 billion each year. Just 0.3% of this of this is currently spent on waste management. Diverting additional money would help out some of the world’s poorest communities – and help the people there to live healthier and happier lives. And it could also take a major step towards cleaning up the environment and tackling the ocean plastics crisis."
"It’s hot as I write this final column for 2019, the day is creeping towards 40C. It’s dry. The ground is like concrete, and dust is obscuring yellowed grass on my parched suburban block. Bushfire smoke has rolled in and out of Canberra. Smoke is the last thing I smell before going to sleep and the first thing I smell as I wake up. With the summer stretching out in front of us and no significant rain forecast before April, according to the Bureau of Meteorology, December and January promises extreme weather, burning bushland, eerie blood-red sunsets. Towns are on the brink of running out of water. Instead of resting and recharging with their loved ones, emergency services workers are spending their days toiling in a hellscape. Long dries are dangerous times for Coalition governments, politically. The public furore over Scott Morrison’s ill judged mini-break in Hawaii while parts of the country were battling a national disaster – and Morrison’s attempt on Friday to clean up the damage – points to the political difficulties the government faces. Long dries create negative feedback loops for centre-right parties in Australia. The Nationals find themselves besieged by furious constituents. Rural independents position themselves to challenge major party incumbents. Far-right populists preen and circle – Pauline Hanson, the Shooters party. As a consequence of the unwelcome competition, Nationals want to flex their muscle within the government and be seen to be delivering, which can create difficulties for the Liberals in urban areas. Water politics (as my wise colleague Gabrielle Chan put this, predictively, in August) is in hyperdrive in regional Australia. The irrigators engaged in an existential fight to preserve their livelihoods (like the group that came to Canberra during the final sitting weeks of the parliament and camped outside the main entrance and outside the National Farmers Federation HQ, a protest convoy demanding an audience) – want more of the scarce water. They feel wedged between the ecology, the speculators and a basin plan they evidently associate with misery. But in cities, progressive Liberal voters fret about persistent government inaction on climate change. Restiveness about a lack of climate action puts pressure on the other arm of the government, the arm inclined to worry the Coalition has lost control of the climate change narrative. A prelude to this summer nocturne played out during the last federal election, when Nationals found themselves under significant challenge in seats with direct exposure to the Murray-Darling. It gets forgotten, because the government has been entirely successful in projecting the sweetest victory of all post-election narrative, but Sussan Ley, the Liberal member for Farrer, suffered a negative swing on primaries of 7%. A high profile independent contesting the seat got almost 20,000 votes in the seat. National Mark Coultan had a similar experience in Parkes – a negative swing on primaries, and a bump for an independent. In the cities, climate-related anxiety swung votes too. Tony Abbott lost his seat, Josh Frydenberg suffered a negative swing of over 8% and Tim Wilson a negative swing of 3.66%. In Trent Zimmerman’s seat of North Sydney, the Labor candidate got a positive swing of over 8%, while in Brisbane, Trevor Evans had a negative swing of 2% and the Greens a positive swing of nearly 3%. While the May election was fought on a range of issues, certainly not climate and environment alone, the election result tells us the Coalition did a better job than Labor of straddling its split constituency, neutralising and weaponising where required; and was more effective in channeling the inevitable protest votes back to the Coalition. So it is possible – Christmas holiday SNAFU and abject prime ministerial apologies notwithstanding – that Team Morrison will end the year resolved to maintaining the status quo with its actions and messaging. It’s possible the Coalition will try and wait out the backlash. After all, what problem needs to be fixed here? The negative swings in May happened in seats the government holds by a large margin, so what’s the case for a course correction? On this benign view Morrison can go on managing the different aspirations among the Coalition’s supporters by walking every side of every street. To recap quickly, the Coalition’s formula for neutralising the climate backlash in May was campaign calm down in the cities. Morrison told voters he was not Abbott, and the Coalition would meet its international commitments with sensible practical policies that wouldn’t crash the economy. In the regions, Morrison was also for the coal industry, for the farmers, for everyone immediately in front of him. The government lost bark, but speaking out all sides of its mouth worked earlier this year. Everyone apart from the unmourned apex wrecker Abbott hung on, and while Labor and the Greens picked up votes on climate change in some parts of the country, a majority of voters either rejected Bill Shorten’s plans to take corrective action, or didn’t particularly but prioritised another set of issues when casting their votes. So the Morrison et al political strategy prevailed. It absolutely did. But will it work forever? And by work, I mean continue to command a national majority of 50% plus one. Will Australians continue to either vote against climate action, or prioritise other things, when they are experiencing the practical consequences of policy failure in their daily lives? To frame this thought another way, if sanguine, or she’ll be right mate (our natural default in Australia), is a piece of string, just how long is that piece of string? I’m not asking this question rhetorically. I’m asking it because I don’t know the answer. I do know this. Australia’s climate is changing, there are practical consequences associated with warming and these consequences are now too present to be ignored. Sign up to receive the top stories from Guardian Australia every morning A new authoritative study published this week found that climate change has reduced the average annual profitability of farms by 22% over the past two decades (and yes, I know effective climate action is a global imperative, not just a local one). Cropping farms have been the worst hit, with revenue down 8% or around $82,000 a farm, and profits down 35%, or $70,900 for a typical cropping farm. Regional Australia is well aware it is now engaged in an adaptation exercise, because agribusinesses deal with that reality every day. One of the small fascinations of the year, certainly for me, and I suspect for a number of us that live outside Sydney, has been watching the perils of climate inaction becoming a major national story largely because Australia’s largest city was inconvenienced by noxious bushfire smoke. All of a sudden, the issue gained traction and surround-sound coverage – television, radio, digital, print – at least in outlets that still perform journalism. I know the government has just endured a pretty spiky and uncomfortable month. You can only imagine how ropable Morrison would have been when it became obvious he would have to eat humble pie on Friday. You can actually picture that scene, or at least I can, quite vividly. What I don’t know is whether the current community concern about the lack of leadership will be transient, vanishing once glorious Sydney harbour reverts to sparkling, and people resume bushwalking in the Blue Mountains without masks and asthma inhalers, or whether the summer of 2019 and 2020 will be remembered in the future as an awakening of sorts. Obviously, I hope it’s the latter. In the spirit of good cheer, generosity and hope, I also hope that Morrison and the government he leads will take the opportunity of shifting on climate policy in 2020, and by shifting I mean actually doing something rather than pretending to be doing something. The government has an entirely viable opportunity to pivot in 2020, to end the domestic war of political convenience in the new year, because the world will be contemplating what fresh emissions reduction commitments to offer between now and 2050. Opportunity beckons. I am often tough on this prime minister, because he furnishes plenty of reasons to be. But I’ve said before, and will now say again, I think Morrison is capable of finding a 50% plus one on climate change that is about more than winning a single election at a particular point in time, but about actually trying to fix a problem that requires fixing. But first he has to make some decisions. Morrison has got to decide whether he covets power for its own sake or whether he wants to use the power Australian voters have given him to do good. He’s got to decide whether he’s a chess grand master or a prime minister. These are two different callings. Morrison can be feckless and shallow, possibly without serious negative consequences. It is the political age for feckless and shallow. Populists and charlatans litter the landscape. So he can do that, and he won’t lack company when he struts and frets on the world stage. Or he can find the courage and the moral purpose to do some good in the world, and leave a legacy that benefits future generations. Katharine Murphy is Guardian Australia’s political editor"
"
Share this...FacebookTwitter
“It is generally accepted that the climate warms during periods of strong solar activity (e.g., the Medieval Warm Period) and cools during periods of low solar activity (e.g., the Little Ice Age).” — Lyu et al., 2016

Graph Source: WoodForTrees.org
Scientists are increasingly tuning out the claims that the Earth’s temperatures are predominantly shaped by anthropogenic CO2 emissions, or that future climate is destined to be alarmingly warm primarily due to the rise in trace atmospheric gases.  Instead, solar scientists are continuing to advance our understanding of solar activity and its effect on the Earth system, and their results are progressively suggestive of robust correlations between solar variability and climate changes.
For example, in 2016 alone, there were at least 132 peer-reviewed scientific papers documenting a significant solar influence on climate.  Among them there were 18 papers that directly connected centennial-scale periods of low solar activity (the Little Ice Age) with cooler climates, and periods of high solar activity (the Medieval Warm Period and the Modern Warm Period [20th Century]) with high solar activity levels.  Another 10 papers warned of an impending solar minimum and concomitant cooling period in the coming decades.
And this trend of scientists linking climate changes to solar forcing mechanisms — and bypassing an anthropogenic explanation — continues to rage on in 2017.
A Seminal New Paper Unveils The ‘Cause Of Causes’ Of Climate Change
In their groundbreaking New Astronomy paper, Norwegian professors Harald Yndestad and Jan-Erik Solheim indicate that the modern (1940-2015) Grand Maximum of very high solar activity — the highest solar activity levels in 4,000 years — has just ended.   Within 10 years, or by 2025, these scientists project the next solar minimum period (which will be similar in character to the late 18th Century’s Dalton Minimum) will exert its cooling effect on the Earth’s climate.
Yndestad and Solheim have been working together on this project for more than 2 years.  Although Dr. Yndestad was “skeptical about the idea of ​​sunspots as climate indicators” initially, the two discovered “for the first time” a strong long-term correlation between Total Solar Irradiance (TSI) and sunspots for periods of 84 and 210 years, confirming the “Cause of causes” of climate change.  Details can be found in their illuminating new paper.

Yndestad and Solheim, 2017
Summary
“Deterministic models based on the stationary periods confirm the results through a close relation to known long solar minima since 1000 A.D. and suggest a modern maximum period from 1940 to 2015. The model computes a new Dalton-type sunspot minimum from approximately 2025 to 2050 and a new Dalton-type period TSI minimum from approximately 2040 to 2065. … Periods with few sunspots are associated with low solar activity and cold climate periods. Periods with many sunspots are associated with high solar activity and warm climate periods.”
1940-2015 Grand Maximum Of Solar Activity, Highest In 4,000 Years, Just Ended
“Studies that employ cosmogenic isotope data and sunspot data indicate that we are currently leaving a grand activity maximum, which began in approximately 1940 and is now declining (Usoskin et al., 2003; Solanki et al., 2004; Abreu et al., 2008). Because grand maxima  and minima occur on centennial or millennial timescales, they can only be investigated using proxy data, i.e., solar activity reconstructed from 10Be and 14C time-calibrated data. The conclusion is that the activity level of the Modern Maximum (1940–2000) is a relatively rare event, with the previous similarly high levels of solar activity observed 4 and 8 millennia ago (Usoskin et al., 2003). Nineteen grand maxima have been identified by Usoskin et al. (2007) in an 11,000-yr series.”
Solar Activity Minimum/Maximum Periods Linked To Colder/Warmer Climates
“Twenty-seven grand minima are identified with a total duration of 1900 years, or approximately 17% of the time during the past 11,500 years (Usoskin et al., 2007). An adjustment-free reconstruction of the solar activity over the last three millennia confirms four grand minima since the year 1000: Maunder (1640–1720), Spörer (1390–1550), Wolf (1270–1340) and Oort (1010–1070) (Usoskin et al., 2007). The Dalton minimum (1790–1820) does not fit the definition of a grand minimum; it is more likely a regular deep minimum that is observed once per century or an immediate state between the grand minimum and normal activity (Usoskin, 2013).  Temperature reconstructions for the last millennium for the Northern Hemisphere (Ljungquist, 2010) show a medieval maximum temperature at approximately the year 1000 [Medieval Warm Period] and a cooling period starting at approximately 1350 [Little Ice Age], immediately after the Wolf minimum and lasting nearly 500 years, with the coldest period in what is referred to as the Little Ice Age (LIA) at the time of the Maunder minimum. A cold period was also observed during the time of the Dalton minimum. The Maunder and the Dalton minima are associated with less solar activity and colder climate periods. In this investigation, minimum solar activity periods may serve as a reference for the identified minimum irradiations in the TSI oscillations.”

Other scientists have just published papers in peer-reviewed journals documenting a robust correlation between solar activity and surface temperatures in the paleoclimate record.  Zawiska et al. (2017) have found that the amplitudes of the warming and cooling periods — modulated by changes in solar activity and the North Atlantic Oscillation (NAO) — during the last 1,000 years far exceeded the temperature changes that have occurred since about 1950, or since anthropogenic CO2 emissions began rising at an accelerating pace.  For example, these scientists point out that within a matter of 100 years (1050-1150 to 1150-1250), summer temperatures rose from 9.2°C during a low solar activity period (Oort Minimum) to 12.0°C in concert with the subsequent rise in solar activity.
Zawiska and colleagues also point out that the rise in modern era temperatures began around 1800, not the 20th century.  In fact, they find that temperatures rose by 4.3°C (from 8.5°C to 12.8°C) within 75 years starting at the beginning of the 19th century (+0.57°C per decade), and this warming “correlates with the positive NAO index and increased solar activity.”   The authors further indicate that the warming in the 20th/21st centuries has been “less pronounced” by comparison.
During the 19th century, of course, anthropogenic CO2 emissions rates were but a tiny fraction of what has been observed since the mid-20th century, strongly suggesting that temperature changes associated with natural variations in atmospheric/oceanic cycles (NAO) and solar activity far exceed the forcing strength of anthropogenic CO2 emissions.

Zawiska et al., 2017
Summary
“The chironomid-based temperature reconstruction from Lake Atnsjøen in Eastern Norway with mean resolution of 30 years provided evidence that large-scale processes, such as the NAO fluctuations and solar activity modified local climate, and subsequently affected lakes functioning. The three minor cooling periods were reconstructed in the first half of the Millennium: 1050–1150, 1270–1370, 1440–1470 CE, that coincide with solar activity minima: Oort, Wulf, and Spörer respectively. Furthermore, a two peaked cooling period in the second half of the Millennium was identified that coincided with the LIA. These changes co-occurred with the prevailing negative NAO index.”
Cold Periods (Temp. Average 9.2 °C) Correlate With Low Solar Activity, NAO
“At 1050–1150 CE the first of the short-term cooling periods of the last Millennium began and the mean July temperature in the Lake Atnsjøen region dropped to 9.2 °C. The beginning of this cooling coincided with the Oort solar activity minimum. The reconstructed climate deterioration agrees very well with temperatures revealed for Europe (PAGES 2k Consortium, 2013) and Finland (Luoto and Helama, 2010), and partly with tree-ring based temperature trends from Northern Sweden (Osborn and Briffa, 2006). … The climate cooling around 1100 CE has been observed also in Northern America, Russia and Central Asia (Osborn and Briffa, 2006; Wanner et al., 2008), but intrestingly not in Greenland (Osborn and Briffa, 2006). … The beginning of the 1270–1370 CE cooling coincide with Wulf solar activity minimum suggesting that the climate was responding to Sun activity. The climate cooling synchronous to this solar minimum had almost global range and it has been recorded from Europe, Arctic, North America and Antarctica (Osborn and Briffa, 2006; PAGES 2k Consortium, 2013) but again not in Greenland (Osborn and Briffa, 2006). … The beginning of the 1440–1470 CE cold period is synchronous to the pronounce negative NAO phase (Trouet et al., 2009). … Maunder solar minimum caused a very deep negative NAO index phase (Shindell et al., 2001), which consecutively lead to significant drop in the reconstructed temperature.”
Warm Periods (Temp. Average 12°C) Correlate With High Solar Activity, NAO 
“According to presented reconstruction, climate shifted towards warmer conditions during 1150–1250 CE, as mean July temperature raised to 12 °C. Studies from Finland and Sweden also indicate short climate warming around 1200 CE (Luoto and Helama, 2010; Osborn and Briffa, 2006)  … The above described time interval 1000–1250 CE coincides with the MCA [Medieval Climate Anomaly] that occurred around 950–1250 CE and was regarded as a generally warmer and drier period (Mann et al., 2009).
The temperature reconstruction from Lake Atnsjøen indicates that recent and ongoing climate warming began already in 1800 CE following the LIA. Temperatures increased very fast, from 8.5 to 12.8 °C during the first 75 years, but in the 20th century the increase became less pronounced.
The warming at the beginning of 19th century in the region of Lake Atnsjøen coincides with a reconstruction from Southern Finland (Luoto, 2013), and a record from Northern Sweden (Osborn and Briffa, 2006).  Its onset correlates with the positive NAO index and increased solar activity.”


Another scientist just published a paper in the journal Palaeogeography, Palaeoclimatology, Palaeoecology that also concludes solar activity drove variations in the East Asian Monsoon (EAM), El Niño Southern Oscillation (ENSO), and the centennial-scale cooling periods corresponding to the Oort, Wolf, Spörer, and Maunder sunspot minimums.
In his graph of Western Tropical Pacific sea surface temperatures (SSTs), notice how Park (2017) also documents a dramatic warming event occurred beginning about 1800, with the SST warming rate and amplitude far exceeding that which has occurred in recent decades, once again demonstrating the lack of correlation between anthropogenic CO2 emissions and surface temperatures relative to natural variation.

Park, 2017
“Late Holocene climate change in coastal East Asia was likely driven by ENSO variation.   Our tree pollen index of warmness (TPIW) shows important late Holocene cold events associated with low sunspot periods such as Oort, Wolf, Spörer, and Maunder Minimum. Comparisons among standard Z-scores of filtered TPIW, ΔTSI, and other paleoclimate records from central and northeastern China, off the coast of northern Japan, southern Philippines, and Peru all demonstrate significant relationships [between solar activity and climate]. This suggests that solar activity drove Holocene variations in both East Asian Monsoon (EAM) and El Niño Southern Oscillation (ENSO). In particular, the latter seems to have predominantly controlled the coastal climate of East Asia to the extent that the influence of precession was nearly muted during the late Holocene.”


The year has just begun, and, in addition to the 3 papers introduced above, there have already been several other 2017 scientific papers published in scientific journals documenting a robust correlation between solar activity and climate changes.  With the rapidly growing body of evidence that has been accumulating within the last few years, it can no longer be said that it is “settled” science that the Sun and its modulation of natural atmospheric/oceanic oscillations (NAO, ENSO, PDO, AMO) has only a negligible influence on climate.  The claim that we human beings predominantly drive climate changes with our CO2 emissions is increasingly being challenged, if not categorically undermined, in the peer-reviewed scientific literature.

Sun et al., 2017
“[A]t least six centennial droughts occurred at about 7300, 6300, 5500, 3400, 2500 and 500 cal yr BP. Our findings are generally consistent with other records from the ISM [Indian Summer Monsoon]  region, and suggest that the monsoon intensity is primarily controlled by solar irradiance on a centennial time scale. This external forcing may have been amplified by cooling events in the North Atlantic and by ENSO activity in the eastern tropical Pacific, which shifted the ITCZ further southwards. The inconsistency between local rainfall amount in the southeastern margin of the QTP and ISM intensity may also have been the result of the effect of solar activity on the local hydrological cycle on the periphery of the plateau.”

Deng et al., 2017
“The results indicate that the climate of the Medieval Climate Anomaly (MCA, AD 900–1300) was similar to that of the Current Warm Period (CWP, AD 1850–present), which contradicts previous studies. … As for the Little Ice Age (LIA, AD 1550–1850), the results from this study, together with previous data from the Makassar Strait, indicate a cold and wet period compared with the CWP and the MCA in the western Pacific. The cold LIA period agrees with the timing of the Maunder sunspot minimum and is therefore associated with low solar activity.”
Zielhofer et al., 2017
“Western Mediterranean Holocene record of abrupt hydro-climatic changes … Imprints of North Atlantic meltwater discharges, NAO and solar forcing …Early Holocene winter rain minima are in phase with cooling events and millennial-scale meltwater discharges in the sub-polar North Atlantic. … [A] significant hydro-climatic shift at the end of the African Humid Period (∼5 ka) indicates a change in climate forcing mechanisms. The Late Holocene climate variability in the Middle Atlas features a multi-centennial-scale NAO-type pattern, with Atlantic cooling and Western Mediterranean winter rain maxima generally associated with solar minima.”
Matveev et al., 2017
“An increase in atmospheric moisture for the warm period of the year (May–September) since 1890s, and mean annual temperatures since the 1950s was identified. During the same time period, there was a marked increase in amplitude of the annual variations for temperature and precipitation. … These fluctuations are consistent with 10–12-years Schwabe–Wolf, 22-years Hale, and the 32–36-years Bruckner Solar Cycles. There was an additional relationship found between high-frequency (short-period) climate fluctuations, lasting for about three years, and 70–90-years fluctuations of the moisture regime in the study region corresponding to longer cycles.”
Share this...FacebookTwitter "
"On Campbell Island in the Southern Ocean, some 400 miles south of New Zealand, is a single Sitka spruce. More than 170 miles from any other tree, it is often credited as the “world’s loneliest tree”. Planted in the early 20th century by Lord Ranfurly, governor of New Zealand, the tree’s wood has recorded the radiocarbon produced by above ground atomic bomb tests – and its annual layers show a peak in 1965, just after the tests were banned. The tree therefore gives us a potential marker for the start of the Anthropocene. But why 1965? The 1960s is a decade forever associated with the hippie movement and the birth of the modern environmentalism, a sun-blushed age in which the Apollo moon landings gave us the iconic image of a fragile planet framed against a desolate lunar surface. It was also a time when the world was fast globalising, with rapid industrialisation and economic growth driving population expansion and a massive increase in our impact on the environment.  This postwar period has been called the “Great Acceleration”. So the question we’re interested in is whether this step change in human activity left an indelible mark on our planet, one which, if we disappeared today, would still leave a permanent signature in the geological record. The concept of a human-dominated geological epoch has been around since the 19th century, but the idea that we have created an Anthropocene has recently become more popular in the face of long-term global changes in the environment far beyond what may be considered “natural”. While humans have long had an impact on the planet at the local and even continental level, the scale of modern change is sufficiently large that geologists are considering the evidence to recognise the Anthropocene officially in the geological timescale. They have set the scientific community a major challenge to find a global-wide environmental marker or “golden spike” that represents this crucial change. A major contender for defining the start of the Anthropocene Epoch is the peak in radioactive elements produced from above ground thermonuclear bomb tests, the majority of which occurred at the height of the Cold War in the early-1960s. The problem from a geologist’s point of view is most of the records of this spike in radioactivity (for example preserved in lake sediments and the annual growth of tree-rings) have been reported from the Northern Hemisphere where the majority of the tests took place. To demonstrate a truly global human impact requires a signal from a remote, pristine location in the Southern Hemisphere that occurs at the same time as the north. This is where our new study comes in. In the journal Scientific Reports we publish a new record that identifies a radioactive signal preserved from exactly this sort of place: Campbell Island, a rare piece of real estate in the depths of the Southern Ocean.  During the Australasian Antarctic Expedition 2013-2014 we undertook scientific sampling across the island to get a better handle on the scale of environmental change in this most remote of locations. The solitary Sitka spruce is in the southern part of the island. The species is found naturally along the west coast of North America from Alaska to California – it is only in the Southern Hemisphere because humans transplanted it there.  Nonetheless, the Campbell Island tree is growing exceptionally well – at a rate five to ten times faster than surrounding native shrubs – which gave us plenty of data to work with. Detailed analysis of the tree’s year-by-year growth shows the peak in radioactive elements took place sometime between October and December 1965, which coincides with the same signal in the Northern Hemisphere. This spruce has demonstrated unequivocally that humans have left an impact on the planet, even in the most pristine of environments, that will be preserved in the geological record for tens of millennia and beyond. Our research promises to reignite the debate around when humans really became a geological superpower. Should we define the Anthropocene by when humanity invented the technology to make themselves extinct? If so, then the nuclear bomb spike recorded in the loneliest tree on the planet suggests it began in 1965."
"The climate crisis is hurting communities across the United States. Hurricanes, heatwaves and torrential downpours are on the rise, and have already exacerbated devastating floods, droughts and wildfires in communities from South Dakota to California, Florida and North Carolina in recent years. The threat of environmental hazards is also increasing as the Environmental Protection Agency (EPA) rolls back regulations on clean water, toxic coal ash, fossil fuels, air pollutants, pesticides, smog and vehicle emissions. Such deregulation may benefit big business polluters, including some of Donald Trump’s biggest donors, but the public health threat disproportionately affects millions of black, poor and Native Americans and Alaskans. But amid mounting frustration with political leaders, a growing number of community activists are running for office on climate and environmental justice platforms in local and state elections – and winning. This was about about my kid’s health, and my health, and I didn’t have the luxury of someone else taking care of that “This was about about my kid’s health, and my health, and I didn’t have the luxury of someone else taking care of that,” said Eric LaBrant, who was elected in 2015 as a commissioner of his local port authority in the Pacific north-west. Such candidates “are deeply engaged because they have firsthand experience of climate and environmental issues in their communities”, said Alex Cornell du Houx, co-founder of Elected Officials to Protect America, a group working with local and state representatives on these issues He added: “They learn quickly once elected and have the capacity to make a big difference.”  Extreme weather events and environmental injustice also exacerbate food and water insecurity, housing shortages, economic hardship and other inequalities. We profile four first-term officials who used their experience as community organizers and alarm over inaction in combating the climate crisis to win public office. Veronica Carter, 59, a retired military officer, was elected to Leland town council in North Carolina in November 2019. Carter moved to Leland, a coastal town of 24,000, in 2003, where she joined a fledgling grassroots group to oppose a huge toxic landfill planned for neighbouring Navassa. This economically deprived, predominantly African American community already had a superfund site and six of the seven brownfields in the county. “This was my introduction to environmental justice violators and it was a textbook case,” said Carter. And when Hurricane Florence churned over the Carolinas for 72 hours in 2018, causing widespread damage that left poor people stranded, Carter was on the frontline. She organised a distribution centre, and organized volunteer teams to deal with fallen trees, flood damage and urgent repairs. “Florence was the tipping point for me to move from activism to politics,” she told the Guardian. “I realized that we needed to build for the next storm, and incorporate resilient methods and technology to improve our infrastructure and build affordable workforce housing … all this was swirling in my head when an opening came up on town council.” Carter ran her campaign on safe air and water, infrastructure, climate resilience and workforce housing. She beat the incumbent by two points. “I want to us see us build smartly, be more inclusive, and help our neighbours in Navassa get more attention in the state capital. I’m only one voice, but I will use my experience and ability to make sure every permit and ordinance the council considers is looked at through an environmental justice lens,” she said. Eric LaBrant, 39, lives in Fruit Valley in Vancouver, Washington, a blue-collar neighbourhood with 1,200 residents and the Port of Vancouver located on the Columbia River. He was elected to the port authority and helped stop what would have been North America’s largest oil terminal. Plans to construct the oil-by-rail terminal emerged in 2013 but the community couldn’t get straight answers from Texas oil giant Tesoro, or officials. “I had specific questions about the scope, scale, emissions and safety, but was ignored or got meaningless answers from the company and the port,” said LaBrant, who spent several years in his twenties working on offshore oil fields in Texas. LaBrant, a member of the Fruit Valley neighbourhood association, trawled company documents and become increasingly alarmed at the risks posed by the exposure to carcinogenic contaminants, and the company’s environmental and safety track record. The project aimed to transport 360,000 barrels of crude oil by train to the port daily, ready for shipping to Asia. But despite growing public concerns and numerous fatal derailments and accidents involving oil trains, the port signed a lease with the company. “It was discouraging to see how much money influences the political process, especially petroleum money, but this was about about my kid’s health, and my health, and I didn’t have the luxury of someone else taking care of that,” LaBrant said. LaBrant was elected as a port authority commissioner in November 2015 after campaigning against the fossil fuel terminal, and for a sustainable green economy. Two years later, Don Orange, another anti-oil community activist turned candidate, was elected, too, giving those opposing the oil terminal the majority on the port authority. Soon after, the state recommended against the oil terminal on safety grounds, and the governor denied the necessary permits. The port lease was cancelled, Fruit Valley had defeated big oil. Since then, the port has enacted a policy to not pursue fossil fuel terminals, and last June, set a record for the biggest shipment of wind turbine blades. “We’ve shown that ports don’t have to be polluters, they can be good neighbours, do business responsibly, and make money on green energy transition,” he said. In Pennsylvania, Danielle Friel Otten, 42, was elected to represent the 155th district in the state house of representatives in 2018 after a race against the incumbent Republican who was largely defined by opposition to the Mariner East 2 pipeline project – a multibillion-dollar pipeline project to carry highly volatile natural gas liquids across Pennsylvania. The project is now subject to multiple criminal investigations and civil lawsuits. “The gases are odourless, colourless and five times more combustible than traditional natural gas products, so there’s huge potential for mass casualties in undetected leaks. My property is within 50ft of the easement [pipeline] … I genuinely thought that people elected to represent us would protect our families, and not approve the project. When that didn’t happen, it blew my mind,” said Otten. In 2017, Otten met with state representative Becky Corbin after drilling contaminated a water aquifer. “I was worried that the contamination could affect my son’s kidney condition … her reaction was cold. I started investigating publicly declared financial contributions and found companies directly involved in the project were donors to her campaign. That was my moment,” she said. I started investigating publicly declared financial contributions and found companies directly involved in the project were regular donors to her campaign Otten helped two neighbours get elected as township supervisors before beating Corbin by 10 points. But the Republicans still control both houses, and the state governor is a “pro-fracking Democrat”. “We’ve not made much headway getting good environmental policies through the legislature this session. But for the first time in the history of the Democratic caucus, we’ve adopted the environment as a key pillar for our plan for Pennsylvania. It’s on the agenda,” he said. “I do get down in the dumps sometimes because we are not making the big impact we so desperately need. No one person is going to be our saviour in this situation, but I bring up the pipeline and environmental justice at every opportunity, and offer tangible alternatives and solutions.” Regina Romero, 45, was elected mayor of Tucson, Arizona, in November 2019 after campaigning on a climate crisis platform. She was elected alongside three council members who also ran on environmental and sustainability issues. In her first council meeting as mayor, the city signed up as an amicus brief in a lawsuit against Donald Trump’s promised border wall. “We took a position against militarizing our borderlands, separating our communities and environmental destruction by a border wall that will not make us more secure,” she said. Romero is not new to local politics: she served three terms on the city council when she spearheaded an initiative by Pima county and Tucson officials to buy the 286-acre Painted Hills property on the foothills of the desert in order to curtail the urban sprawl and preserve it as green open space for the community and wildlife habitat. “We love the desert, so taking care of our land and environment is essential for the survival of our community. I’ve seen with my own eyes the climate changing. Tucson is the third fastest warming city in the country, we have to do something,” she said. Romero’s mayoral campaign was centred around a pledge to create a comprehensive climate action plan for the densely populated city, which is suffering its 21st year of drought.  Several decades of water conservation policies has meant the city has so far avoided rationing, but there’s more to be done amid dwindling water reserves and record high temperatures, including planting a million drought-tolerant native trees by 2030 and setting emissions reduction targets. “The first step is to create a climate action task force by January 2020 and start planting those trees,” she said."
"The seas will continue to rise for 300 years. That’s the conclusion of a new study, published in Nature Communications, which projects how much the sea level will rise under varying degrees of success in tackling climate change right up to the year 2300.  But 2300 is almost three centuries from now. Three centuries ago the industrial revolution hadn’t even started. This raises the question of whether, when considering present-day climate policy, there is any value at all in considering such distant futures. After all, the Paris Agreement on climate change hasn’t set its global temperature rise targets beyond the end of the current century. And even this appears too remote a horizon to motivate emissions cuts in the near future. Therefore, Paris focuses on five-year climate policy cycles starting in 2018, which are more in line with typical political and business cycles, and in tune with our everyday concerns. Nonetheless, multiple climate studies do consider projections of the far future. For instance, one paper estimated that, if we fail to tackle climate change, the Arctic Ocean could be ice-free all year round somewhere between 2150 and 2250. Another study looked at carbon emissions from thawing permafrost as far out as the year 2500. The obvious criticism is that such work is mere fiction, driven by the intellectual curiosity of a small group of highly specialised scientists, rather than anything relevant to daily life. And in any case, critics might argue, won’t we figure something out in the next century or two that could tackle climate change and prove all the predictions of doom and gloom unfounded?  As is often the case, the truth is a little bit more complex. The first thing to note is that a certain amount of climate change is already “locked in”. Our use of energy and other resources is not going to slow down any time soon, as poorer countries race to industrialise and catch up with the global leaders, while more affluent nations aim to maintain and further improve their living standards. Most people can relate to these aspirations, even if the upshot is they ensure that global emissions stay at their current high levels. Solar and wind power will of course help, but the reality is that such technologies are still nowhere near enough to radically alter the link between emissions and economic expansion. Despite the renewables boom, 2017 saw a 2% rise in global emissions following a three-year plateau. Experts argue that making serious emissions cuts will require much more ambitious efforts across nearly all economic activities, including energy, urbanisation, infrastructure, transport, heavy industries and land use. This brings us back to the very long-term scenarios used by climate scientists. These scenarios are actually based on credible assumptions about a large set of long-term socio-economic and technological drivers that define contrasting futures for the world as a whole. And it turns out that things which will affect future emissions and climate, like the rates of technological progress, or population and wealth growth, are likely going to be constrained within a reasonably predictable range. Even if one includes the possibility of “game-changing technologies”, for example a hypothetical new generation of much cheaper and more effective batteries for electric cars, the world is almost certainly going to stay within this range of scenarios.  This is where climate science comes into play. As certain physical processes triggered by global warming are relatively slow, their full impact won’t be apparent for hundreds of years. Consider the ice sheets found in Greenland and Antarctica, for instance, both so big that they respond to climate change only slowly. However, once triggered, and the ice starts sliding towards the oceans, causing the sea level to rise, the melting process takes centuries to reverse. Something similar is happening with thawing permafrost, which releases additional greenhouse gases into the atmosphere. Both rising sea levels and thawing permafrost could impact hundreds of millions of people, particularly those living in coastal areas or hotter climates. But if we want to know how much we should be worried, then climate predictions up until 2050 won’t cut it – the world may still be warming at that point, even if we stopped emitting carbon overnight. Given the future of the world is bound within a reasonably predictable range of scenarios, it therefore makes sense to estimate the risks posed by these slow physical processes, by extending the analysis as far out as 2300.  Back to the original study. Its main result was that the sea level could still rise by up to 1.2 metres (4ft) by 2300 even under a very optimistic climate scenario where the global temperature never rises more than 2℃ above pre-industrial levels. That is, even if manmade emissions peak within the next two decades, then drop down to zero no later than by 2070 and remain at zero from then onwards – sea levels would still rise by more than a metre. Achieving zero net emissions within the next 30 to 50 years will be hard enough. But the study shows that even if this ambitious target is achieved, sea levels will continue to rise for the following two centuries. This is a climate time bomb for coastal areas. Though it may not seem like a lot, a 1.2-metre sea level rise will still force megacities such as London and New York to spend billions to maintain flood defences in the face of stronger storm surges. Achieving zero emissions is therefore not enough to prevent the long-term effects of sea level rise from kicking in. To bring temperatures back to at least the current levels – that is around 1℃ above pre-industrial – we’ll need negative emissions technologies that draw carbon directly out of the atmosphere. This is an important long-term policy result that was made possible by considering extended time horizons. By reaching as far out as 2300, we have reaffirmed the need to take ambitious climate action in the more immediate future."
"You benefit from plastic from the moment you get up and use your toothbrush or kettle. Plastic is embedded in agriculture – and it keeps you alive if you end up in hospital. Even some of our money is made from it. Yet I can’t watch the news without being bombarded by the evils of plastic. As a polymer scientist, it feels like my life’s work is dismissed as immoral by even my hero Sir David Attenborough, simply because I deal with plastics.  But plastic itself is inanimate and cannot be evil – what’s morally wrong is what humans do with it. But some plastic packaging does have benefits – even for the environment. Some packaging, for instance, prevents enough food waste (and therefore deforestation, fertiliser use or vehicle emissions) to balance out the inevitable litter. So how can you tell what is and isn’t worth it? One reason this is so hard to figure out is down to the nature of the material itself. Different kinds of plastic have to be separated for recycling because they contain tiny building blocks that don’t mix at the molecular level. For instance, even many chemists don’t realise that polyethylene (PE) and polypropylene (PP) don’t mix, though they are the two of the most common forms of plastic and both have the same empirical formula of n(CH2). That’s why separating plastics at the recycling centre is so important. A sports drink, for instance, can have three different and incompatible types of plastic in the bottle, the shrink-wrapped film, and the lid. All three components can be individually recycled but they are rarely separated other than by shredding.  Or look at black plastic trays. Their only function is to amplify the colour of a product, yet they also prevent recycling as sorting machines cannot detect black pigment.  In many cases, the packaging does have a genuine function and prevents waste by, for example, sealing in moisture or gas. But this can also mean certain thin films of plastic become impossible or prohibitively expensive to separate. Packaged fruit and vegetables are egregious examples of excess plastic because they already come in a protective skin. Bananas already come in a perfectly designed wrapper – individuals can be snapped off a from a bigger pack, the skin splits length ways to expose the product, and it is truly biodegradable. Prepacked orange segments, meanwhile, last about four days whereas a whole orange can last months. Compare the environmental lifetime of orange peel (months) and polyethylene (effectively eternity) – all for the convenience of not peeling an orange. Such packaging serves little practical purpose, yet only a minority of supermarket fresh fruit and veg is offered “loose”. Consumers are waking up to some of the worst excesses – see the recent furore over an M&S cauliflower steak that was pulled after complaints. But none of this is simple. Given that prepacked fruit and vegatables enable some disabled people to access fresh food, one person’s lazy and profligate is another’s lifesaver. So what can be done to reduce single-use plastic? A society that valued the environment over marketing could make evidence-based choices. On a larger scale, this involves policies such as the UK’s 5p carrier bag charge, which has driven an 80% reduction in single-use bags. But personal actions matter, too. Take the choices involved in a simple packed lunch of a falafel wrap, prepared at home. For the wrap, many advocate reusing aluminium foil rather than clingfilm. But foil has to be reused nearly 200 times to release less greeenhouse gases than clingfilm – 5g of aluminium versus 0.2g of film at six times more embedded energy and nine times more GHG per gram.  Compare this to a reusable plastic sealed bag made from 14g of the same material as the clingfilm. This only needs to be used 70 times to get ahead (on GHG emmisions) of using new clingfilm every time, while there is no daily clingfilm or weekly foil going to landfill. Or consider bottled water. The logical approach here is to reuse thicker bottles 100 times or more, but this may require a deposit scheme, collection and return, wash and refill – all of which costs. Thin single-use bottles are the lowest price, whereas refilling and reusing has the lowest environmental burden. Companies’ balance sheets and our pockets lead us to single-use plastics in the sea. Single-use plastic is a complex issue – in some cases it is very useful, in others just the opposite. But consumers can make conscious choices, businesses can act responsibly and governments can enforce good policy to rid ourselves of pollution for profit."
"As heavy rain continues to contribute to the devastating flooding in Cumbria, there have once again been calls – notably from the environmentalist George Monbiot – for the reforestation of our uplands, to help tackle rural flooding. The government has stated that it is funding the planting of 11m trees over the next five years to this end. It has also been suggested that trees could help reduce the number and severity of flash floods in cities, such as those that devastated Hull in June 2007.  To determine whether the humble tree really can provide such robust defences, we first need to understand the role they play in soaking up excess rain water. All floods, whether fluvial (when rivers burst their banks) or pluvial (when rainfall overwhelms drainage systems before it reaches rivers), are caused because the rain cannot soak into the soil fast enough. Instead, it runs rapidly over the surface of the land.  And while climate change is causing bigger and bigger storms, our alterations to the environment – especially to the ground surface – have been one of the major causes of the increased frequency of flooding events in modern times.  Cities offer the most obvious example of how human development is making flooding worse. In urban areas, the ground surface is covered by impermeable buildings and roads, which rapidly divert rainfall into gutters and drains. When these reach capacity, flooding occurs.  Computer modelling of water flows in cities suggests that for every extra 1% of impermeable land that is converted to woodland, runoff would be reduced by less than 0.5%. So even large-scale urban tree planting would only reduce runoff by a small amount – far lower than the 80% increase in storm size that climate change models predict for the UK. But these estimates assume that trees don’t affect how much water runs into drains from buildings and roads. Recent research we carried out in Manchester has suggested that trees planted on the streets can have a much greater effect than predicted, largely because rainfall can run from pavements into their planting holes.  Trees which are planted as a part of Sustainable Urban Drainage Systems (SUDS) schemes – in which rainfall is deliberately diverted into swales, hollows and soakaways – could be even more effective. Unfortunately, though SUDS schemes are increasingly popular, little research has been carried out to monitor their effectiveness at reducing runoff. Rural areas of the UK have also undergone a massive transformation at the hands of humans. Forests, which would have provided natural vegetation cover, have been removed and replaced with arable crops (in the lowlands) or grass pasture (in upland areas such as the Lake District). Both of these types of agricultural land shed much more runoff than forests. Their thin soils are compacted by heavy farm machinery and the hooves of cattle and sheep. This reduces their permeability, making it more difficult for rain to penetrate the soil, while short-cropped grasses and flat fields offer little resistance to the overland flow of the runoff.  Reforesting such areas can have several benefits. For one thing, the tree canopy can intercept some rain, which can then evaporate before it even reaches the ground.  But this only reduces the effective rainfall by a few millimetres, and the effect would be negligible in winter, when low temperatures reduce evaporation and deciduous trees have shed their leaves.  The effects of trees on the soil are much more significant. Fallen tree leaves build up a deeper, humus-rich soil, which is criss-crossed by thick surface roots that intercept the overland flow of rain water. Meanwhile, sub-surface roots penetrate deep into the soil, drying it out and increasing its permeability. These mechanisms are well-established, and seem to point to trees as a possible solution to flooding.  Yet in rural areas, the effectiveness of reforestation in preventing flooding is still uncertain. A recent study at Pontbren, in Wales, showed that planting trees on former pasture can increase the rate at which water infiltrates the soil by a factor of around 70 in just seven years, thereby reducing overland flow. Unfortunately, the planting was done on a relatively small scale, and there was no way of comparing catchments with and without trees, so it was impossible to tell whether these changes had significantly reduced the speed at which water drained into the local streams, the water which would cause fluvial flooding downstream.  Ultimately, we lack the strong research base necessary to accurately quantify the anti-flooding benefits of planting trees: large scale studies cost money, and scientists have difficulty repeating experiments to confirm their findings, because no two catchments are the same. Most studies therefore depend on modelling, but even this is unreliable, because the models cannot be validated by experiment. There are also a range of other factors, which might be affecting our results, such as soil type, slope, and whether the trees are positioned next to streams and rivers. But based on what we know, it seems unlikely that reforestation would be a total panacea; after all, forested areas still flood.  And so it seems unlikely that reforestation alone would have been able to prevent the current floods in Cumbria. But by finding ways to measure the benefits of trees, we will be able to use them to their full potential, as a part of our engineered flood prevention schemes. By incorporating trees as part of the solution, we could add some green to the concrete jungles in which so many of us live, and transform our countryside into a lush and varied environment."
"
Share this...FacebookTwitterScientists Ascribe Climate Changes
To Solar Forcing – No CO2 Attribution



In recent months, there have been dozens of papers published in the scientific literature ascribing variations in temperature and precipitation (climate) to corresponding variations in solar forcing.
Another new paper, Zhang et al., 2017, has just been published online.  The nine scientists contributing to the research place special emphasis on the relationship between solar activity and climate for the Qinghai-Tibetan Plateau region of Central Asia for the last 10,000-12,000 years.
The authors link high and low solar activity to correspondingly high and low temperatures and precipitation.  Undulating millennial- and centennial-scale temperatures are found to vary by about 2.5°C throughout the Holocene.   No mention is made of carbon dioxide as an influential factor affecting climate change.
Although the instrumental record for the region documents an abrupt warming in recent decades (which aligns with the Modern Grand Maximum), the proxy evidence from subfossil chironomids used to reconstruct temperature does not show a significant or unusual regional warming trend during the last century.

Holocene high-res. quantitative summer temp. reconstruction …
southeast margin of the Qinghai-Tibetan Plateau [Central Asia]
Zhang et al., 2017
1.    The record suggests the summer temperature varies by ~2.5 °C across the entire period. A generally warmer period occurred between c.8500 and c.6000 cal yr BP and a cooling trend was initiated from c.5500 cal yr BP. The overall pattern broadly matches the summer insolation at 30N and the Asian Summer Monsoon records from the surrounding regions suggesting that summer temperatures from the southeast margin of the QTP [Qinghai-Tibetan Plateau] respond to insolation forcing and monsoon driven variability on a multi-millennial time scale. Modifications of this overall trend are observed on the finer temporal resolution and we suggest that solar activity could be an important mechanism driving the centennial-scale variability. It may have a strengthened effect in the late Holocene when the monsoon influence weakened.
2.    We highlight that solar activity likely plays an enhanced role in changes of summer temperatures because of the high elevation of the QTP when the monsoon is weaker. The results also indicate that summer temperature variability at the QTP responds rapidly to solar irradiance changes in the late Holocene.
3.  The temperature drop may be also due to a decline in the solar activity related to the Hallstatt cycle, with solar minima centered at approximately 8200, 5500, 2500 and 500 cal yr BP (Steinhilber et al., 2012).


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




4.   All three records broadly follow the decreasing trend of summer insolation at 30 N (Berger and Loutre, 1991) and this pattern is widely recorded across southern and eastern Asia including from Dongge and Qunf Caves (Dykoski et al., 2005; Fleitmann et al., 2007). The trend is marked by a broad shift to lower average summer temperature values from ~5500 cal yr BP in the lake records, suggesting that long-term summer temperature and precipitation changes in southwestern China respond to changes in insolation forcing (Gray et al., 2010).

5.   The delayed response of regional climate to orbital forcing in the early Holocene may be linked to the temperature variability predominantly being driven by centennial scale solar irradiance fluctuations during this period (Fleitmann et al., 2003; Wang et al., 2005). In addition, the existence of remnant ice sheets in the Northern Hemisphere high latitudes in the early Holocene could have also caused the delay of the attainment of a temperature optimum in southwestern China in response to the solar insolation maximum (Xiao et al., 2009; Wen et al., 2010).
6.   The chironomid record from Tiancai Lake shows a 2.2° C summer warming just after ~2500 cal yr BP and the alkenone-based record from Qinghai Lake also shows a warming at this time interval. The warm period persisted for nearly 1000 years until ~1600 cal yr BP. This temporal coherence suggests a regional climate response and indicates that secondary forcing mechanisms can modify the insolation driven system. This warm period is possibly related to the rapid and overall rise of solar activity (Steinhilber et al., 2012).
7.   [T]hese observations may reflect the variability of the Indian Summer Monsoon as a result of the enhanced solar activity influence. It is in line with evidence suggested in a few studies (Lihua et al., 2007; Thamban et al., 2007; Hiremath et al., 2015) from the Indian Summer Monsoon (e.g. Bay of Bengal) influenced area. In summary, the solar irradiance fluctuation is inferred to affect the summer air temperatures at the QTP either by directly raising lake water temperatures at the high altitude under a weakened summer monsoon condition or alternatively, it could also result in variations of the Indian Summer Monsoon activity at decadal to centennial scale in the late Holocene.
8.   In general, the pattern of millennial summer temperature changes is driven by the summer insolation-forced intensity of Asian summer monsoons during the Holocene. Variations from this general pattern were evident during the late Holocene and may be related to a shift in solar activity (e.g. from ~2500 to 1600 cal yr BP).



Share this...FacebookTwitter "
nan
"In cities around the world, trees are often planted to help control temperatures and mitigate the effects of the “urban heat island”. But while trees have been called “nature’s air conditioners”, in practice, scientists often have difficulty demonstrating their cooling properties.  The most obvious way to measure the cooling effect of trees would be to compare the air temperature in parks with that in nearby streets. But this method often comes up with disappointing results: even in large, leafy parks, the daytime air temperature is usually less than 1°C cooler than in the stuffy streets, and at night the temperature in parks can actually be higher. To explain this contradiction, we need to think more clearly about the physics of heat flows in our cities, and the scale of the measurements we are taking.  Theoretically, trees can help provide cooling in two ways: by providing shade, and through a process known as evapotranspiration. Locally, trees provide most of their cooling effect by shading. How warm we feel actually depends less on local air temperature, and more on how much electromagnetic radiation we emit to, and absorb from, our surroundings. A tree’s canopy acts like a parasol, blocking out up to 90% of the sun’s radiation, and increasing the amount of heat that we lose to our surroundings by cooling the ground beneath us.  All up, the shade provided by trees can reduce our physiologically equivalent temperature (that is, how warm we feel our surroundings to be) by between seven and 15°C, depending on our latitude. So it’s no surprise that, in the height of summer, people throng to the delicious coolness of the shade provided by London parks, Parisian boulevards, and Mediterranean plazas. Trees can also cool down buildings – especially when planted to the east or west – as their shade prevents solar radiation from penetrating windows, or heating up external walls. Experimental investigations and modelling studies in the USA have shown that shade from trees can reduce the air conditioning costs of detached houses by 20% to 30%.  But air conditioning is more common in some places than in others: for example, while three out of four Australian households have an air conditioner, they’re much less common in Northern Europe, leaving the population there more vulnerable to the harms of urban heat. During the 2003 European heatwave, there were 70,000 more deaths recorded, compared with equivalent cool periods. We urgently need more research to find out how much shade from trees could cool down the terraced houses and apartment blocks, where so many less well-off people live. Trees can also be used to tackle a bigger problem: the urban heat island. During periods of calm, sunny weather, the air temperature of cities can be raised above that of the surrounding countryside by up to 7°C, especially at night. In cities, the hard, dark asphalt and brick surfaces absorb almost all the incoming short-wave radiation from the sun, heating up to between 40°C and 60°C, and storing energy which is then released into the air during the still of night, when it can be trapped in the narrow street canyons.  Urban trees can counter this process by intercepting the radiation before it reaches the ground, and using the energy for evapotranspiration. Evapotranspiration occurs when the sun’s rays hit the trees’ canopy, causing water to evaporate from the leaves. This cools them down – just as sweating cools our skin – thereby reducing the amount of energy left to warm the air.  The effects of evapotranspiration can be quantified in two ways. First, you can measure the temperature of the tree canopy, which is typically much cooler than built surfaces – only 2°C to 3°C above air temperature. Unfortunately, we can’t really claim that this temperature difference is evidence of cooling capacity; leaves would be cooler than built surfaces even if they weren’t losing water, because they are cooled more effectively by convection. A better method is to calculate the cooling effect of a tree directly, by measuring how much water it is losing. You can do this by measuring the sap flow up its trunk, or the water loss from single leaves. These methods show that tree canopies can divert over 60% of the incoming radiation to evapotranspiration. Even a small (4m high) Callery pear tree – a commonly planted species in Northern Europe – can provide around 6kW of cooling: the equivalent of two small air-conditioning units.  But there’s a catch: trees only provide this cooling effect when they are growing well. By measuring water loss from individual leaves, we showed that sparser, slower-growing plum and crab apple trees provided only a quarter of the cooling effect of the Callery pears. What’s more, the effectiveness of trees can be greatly reduced if the growing conditions are poor. We found that the transpiration of Callery pears could be reduced by a factor of five, if the roots were growing through compacted or poorly aerated soil. Much more research is needed on the relative performance of large and small trees, whether they’re planted on streets or in parks. One final difficulty in working out the cooling power of trees is to determine how much a given tree’s evapotranspiration will actually reduce the air temperature. As so often in science, a modelling approach is needed, with physicists, engineers and biologists working together. We need to put realistic trees into detailed regional climate models, which can mimic the complex daily movements of air and energy through the city. Only then can we determine the regional benefits of the urban forest, and work out how to use trees to make our cities cooler and more pleasant places to live in."
"
Share this...FacebookTwitterHundreds Of Scientific Papers 
Challenge ‘Global’ Warming

Recently, an article citing over 80 graphs from scientific papers published in 2017 — and another 55 graphs from 2016  — established that modern “global” warming is not actually global in scale, and that today’s warmth is neither unprecedented or remarkable when considering the larger context of natural variability.
Here, an additional 140 non-hockey stick graphs taken from papers published in 2015 and earlier have now been made available.  With this latest installment, graphical temperature reconstructions challenging the conceptualization of global-scale or unprecedented modern warming are rapidly approaching 300.
For those interested in perusing this growing body of scientific evidence all at once, a new page has been added to the NoTricksZone website.
Global Warming Disputed: 300 Graphs

The list is categorized by the year (or decade) of publication.  It will be updated as new temperature reconstructions are published or located in the peer-reviewed scientific literature.  Perhaps these pages can be used as a resource when challenging those who claim that modern temperatures are unusual, dangerous, or outside the range of natural variability.




Schneider et al., 2015


Stoffel et al., 2015


Soon et al., 2015
“[M]ost of the temperature trends since at least 1881 can be explained in terms of solar variability, with atmospheric greenhouse gas concentrations providing at most a minor contribution.”



Thapa et al., 2015
“[T]emperature in Central Asia and northern Hemisphere revert back towards cooling trends in the late twentieth century.”


Yan et al., 2015


Boldt et al., 2015


Matskovsky and Helama, 2015
“The DIRECT reconstruction reveals long-term cooling during the LIA [Little Ice Age, 1300-1900 AD]  and considerable warming during the MCA [Medieval Climate Anomaly/Medieval Warm Period, 800-1200 AD]. The 20th century marks a period of generally warm temperatures; however, the temperatures of the MCA were reconstructed to be warmer and the long duration of the former makes the MCA incomparable to the 20th-century warmth (Matskovsky and Helama, 2014).”



Munz et al., 2015


Wei et al., 2015


Sánchez-Sesma, 2015


Krusic et al., 2015



Jiang et al., 2015


de Frietas et al., 2015


Larsen et al., 2015
“Southern Greenland proxy-inferred atmospheric temperatures also peaked between ca. 7 and 4 cal. kyr B.P. at 2–4 °C higher than present, followed by a Neoglacial cooling reaching a minimum during the LIA [Little Ice Age] (Fréchette and de Vernal, 2009; D’Andrea et al., 2011; Axford et al., 2013). The second phase of ice retreat behind the present-day extent in southwest and south Greenland was from ca. 1.5 to 1 cal. kyr B.P.”


Naulier et al., 2015




Gajewski, 2015




Hou et al., 2015
“Lake Qinghai also displays significant temperature oscillations in the past 3000 years, which may reflect an amplified response to volcanic and/or solar forcings [Stuiver et al., 1995]. The warm period peaking around 2 ka coincides with the Roman warm period, which is followed by cooling into the little ice age, peaking at about 500 years ago (Figure 2). The most distinct and unusual feature of Lake Qinghai summer temperature record is a temperature decrease of more than 4°C between 5 and 3.5 ka. Such temperature changes have not been observed in ice core records in Greenland and speleothem records in China and East Asia. Here we show, however, that this “unusual” feature is in fact prevalent in regional records.”


Loomis et al., 2015




Rebolledo et al., 2015


Kolansky et al., 2015






Esper et al., 2014


Rinne et al., 2014


Luoto et al., 2014


Yan et al., 2014
“The results suggested that the mean SSTs around AD 990 (±40) and AD 50 (±40) were 28.1 °C and 28.7 °C, 0.8 °C and 1.4 °C higher than that during AD 1994–2005, respectively. These records, together with the tree ring, lake sediment and literature records from the eastern China and northwest China, imply that the temperatures in recent decades do not seem to exceed the natural changes in MCA [Medieval Climate Anomaly], at least in eastern Asia from northwest China to northern SCS.”


Gennaretti et al., 2014


Zinke et al., 2014


Bertrand et al., 2014


Silveira and Pezzi, 2014


Wunsch and Heimbach, 2014
“A very weak long-term [1993-2011] cooling is seen over the bulk of the rest of the ocean below that depth [2000 m], including the entirety of the Pacific and Indian Oceans, along with the eastern Atlantic basin.”




Schneider et al. 2014


Böll et al., 2014


Caniupán et al., 2014


Rella and Uchida, 2014


Meyer et al., 2014


Eldevik et al., 2014
“Through the LH [Late Holocene], ocean temperatures [North Atlantic, Nordic Seas] are comparable to the present, but up to 1°C warmer“





Elbert et al., 2013



Miles et al., 2013


Lecavalier et al., 2013


Saunders et al., 2013


Ault et al., 2013


de Jong et al., 2013


Rosenthal et al., 2013
“We show that water masses linked to North Pacific and Antarctic intermediate waters were warmer by 2.1°C and 1.5°C, respectively, during the middle Holocene Thermal Maximum than over the past century. Both water masses were ~0.9°C warmer during the Medieval Warm period than during the Little Ice Age and ~0.65° warmer than in recent decades.”




Hanhijärvi et al., 2013
“According to Chylek et al. (2009), the Arctic warming from 1900 to 1940 proceeded at a significantly faster rate than the warming during the more recent decades and was highly correlated with the Atlantic Multi-decadal Oscillation (AMO) suggesting that the Arctic temperature variability is highly linked to the Atlantic Ocean thermohaline circulation at various temporal scales.”


Butler et al., 2013




Massaferro and Larocque-Tobler, 2013


Bostock et al., 2013


Levy et al., 2013

 

Kylander et a., 2013


Antinao and McDonald, 2013





Esper et al., 2012


Delong et al., 2012


Pitman and Smith, 2012


 Cronin, 2012




Mulvaney et al., 2012
“A marine sediment record from off the shore of the western Antarctic Peninsula also shows an early Holocene optimum during which surface ocean temperatures were determined to be 3.5°C higher than present. Other evidence suggests that the George VI ice shelf on the southwestern Antarctic Peninsula was absent during this early-Holocene warm interval but reformed in the mid Holocene.”


Durantou et al., 2012
“Sea surface temperature [Arctic Ocean] between ∼ AD 1885–1935 are warmer by up to 3°C with respect to the average modern temperature at the coring site.  For the period ∼ AD 1887–1945, reconstructed sea ice cover values are on average 8.3 months per year which is 1.1 months per year lower than the modern values.”


Kilian and Lamy, 2012



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->









Li et al., 2011


Yamanouchi, 2011


Neukom et al., 2011
“The reconstructed SSA [Southernmost South America] mean summer temperatures between 900 and 1350 are mostly above the 1901–1995 climatology. After 1350, we reconstruct a sharp transition to colder conditions, which last until approximately 1700. The summers in the eighteenth century are relatively warm with a subsequent cold relapse peaking around 1850. In the twentieth century, summer temperatures reach conditions similar to earlier warm periods.”



Divine et al, 2011


Liu et al., 2011
“Climate events worldwide, such as the MWP and LIA, were seen in a 2485-year temperature series. The largest amplitude and rate of temperature both occurred during the EJE [Eastern Jin Event (343–425 AD)], but not in the late 20th century. The millennium-scale cycle of solar activity determined the long-term temperature variation trends, while century-scale cycles controlled the amplitudes of temperature. Sunspot minimum events were associated with cold periods. The prediction results obtained using caterpillar-SSA showed that the temperature would increase until 2006 AD on the central-eastern Plateau, and then decrease until 2068 AD, and then increase again.”


Bird et al., 2011


Hanna et al., 2011




Shevenell et al., 2011


Govil et al., 2011


Ilyashuk et al. 2011


Shevenell et al., 2011


Godad et al., 2011


Saenger et al., 2011
“A prominent feature of this record is the ∼1°C warm anomaly that occurred between 1930 and 1950. … Carolina Slope SST does not exhibit the warming trend seen in the AMO since the 1970s suggesting that other factors also impact SST variability at our site.”





Ran et al., 2010


Yang et al., 2010




Bonnet et al., 2010
“Sea-surface temperature (SST) estimates suggest warmer conditions than present (anomaly∼+2 °C) averaging at 7 °C in summer until 300 cal. years BP, although cooling pulses are recorded around 1700, 1500, 1200 and 800 cal. years BP. The last 300 years were marked by a cooling from 7.6 to 3.5 °C and sea-ice cover increasing up to 7 months/yr. … From 2500 to 300 cal. years BP, SSTs were relatively high with mean values of about 2 °C and 7 °C in winter and summer, respectively. Warm phases are recorded around 1900, 1600, 1320, 1120 and 325 cal. years BP, with an optimum centered at 1320 cal. years BP. After 300 cal. years BP, SSTs were significantly lower with mean values of about 0 °C and 3.5–4 °C in winter and summer, respectively. … The record of sea-surface conditions from core JM04 indicates warmer winter SSTs during the last 2500 years than the modern average. The only exception is the interval spanning from 250 to 50 years BP, which is characterized by particularly low temperatures both in winter and summer.”


Ran et al., 2010





Gerhard, 2004



Box et al., 2009

“Meteorological station records and regional climate model output are combined to develop a continuous 168-yr (1840–2007) spatial reconstruction of monthly, seasonal, and annual mean Greenland ice sheet near-surface air temperatures. The annual whole ice sheet 1919–32 warming trend is 33% greater in magnitude than the 1994–2007 warming.”



Saenger et al, 2009


Cook et al., 2009


Yadav and Singh, 2002
“The 1945–1974 period was the warmest 30-yr mean period of the 20th century. However, this warming, in the context of the past four centuries, appears well within the range of normal limits. The 30-yr mean temperature anomaly for 1662–1691 (0.19°C) exceeds in magnitude (although not significantly, p = 0.23) the 1945–1974 mean (0.05°C).”



Renssen et al., 2009




Yadav, 2009
“The decreasing temperature trend in late 20th century is consistent with trends noted in Nepal (Cook et al. 2003), Tibet (Briffa et al. 2001) and Central Asia (Briffa et al. 2001).”


Rosenberg et al., 2004


Grudd et al., 2002


Schneider et al., 2006


Cook et al., 2006


von Gunten et al., 2009


Fan et al., 2009


Tyson et al., 2000
“The climate of the interior of South Africa was around 1°C cooler in Little Ice Age [AD 1300 to 1800] and may have been over 3°C higher than at present during the extremes of the medieval warm period [AD 1000 to 1300]. … It was variable throughout the millennium, but considerably more so during the warming of the eleventh to thirteenth centuries.  The lowest temperature events recorded during the Little Ice Age in South Africa are coeval with the Maunder and Sporer Minima in solar irradiance.  The medieval warming is shown to have coincided with … the Medieval Maximum in solar radiation.”




Doran et al., 2002
“[O]ur spatial analysis of Antarctic meteorological data demonstrates a net cooling on the Antarctic continent between 1966 and 2000, particularly during summer and autumn.”


Cook et al., 2002
“This record is the longest yet produced for New Zealand and shows clear evidence for persistent above-average temperatures within the interval commonly assigned to the MWP [Medieval Warm Period]. Comparisons with selected temperature proxies from the Northern and Southern Hemispheres confirm that the MWP was highly variable in time and space. Regardless, the New Zealand temperature reconstruction supports the global occurrence of the MWP.”


Hanna and Cappelen, 2003
“Analysis of new data for eight stations in coastal southern Greenland, 1958–2001, shows a significant cooling (trend-line change −1.29°C for the 44 years), as do sea-surface temperatures in the adjacent part of the Labrador Sea”


Chuine et al., 2004
“Figure 1 [below] shows two early warm decadal fluctuations: one in the 1380s (0.72 °C) and one in the 1420s (0.57 °C), both above the 95th percentile. The warm period of the 1420s was followed by a cold period that lasted from the mid-1430s to the end of the 1450s (0.45 °C, under the 10th percentile). Our series also reveals particularly warm events, above the 90th percentile, in the 1520s and between the 1630s and the 1680s. These decades were as warm as the end of the twentieth century. The high-temperature event of 1680 was followed by a cooling, which culminated in the 1750s (under the 5th percentile) — the start of a long cool period that lasted until the 1970s.”


Menzel, 2005


Khiyuk and Chilingar, 2006


Hantemirov and Shiyatov, 2002


Drinkwater, 2006


Sano et al., 2005
“March–September temperature was reconstructed for the past 249 years, which shows a warming trend from 1750s until approximately 1790, followed by cooling until 1810, then by a gradual warming trend extending to 1950, and a notable cold period continuing up to the present. No evidence of a consistent warming trend over the last century or two commonly appearing in higher latitudes was found in the present reconstruction”


Etien et al., 2008


Box, 2002
“Temporal and spatial variability are analysed in Greenland instrumental temperature records from 24 coastal and three ice sheet locations. … The standard period 1961–90 was marked by 1–2°C statistically significant cooling.”


Bhattacharyya and Chaudhary, 2003


Moore et al., 2001
“Summer temperatures at Donard Lake [Canadian Arctic] over the past 1250 yrs averaged 2.9 °C.  At the beginning of the 13th century, Donard Lake experienced one of the largest climatic transitions in over a millennium. Average summer temperatures rose rapidly by nearly 2 °C from 1195–1220 AD [+0.80 C per decade], ending in the warmest decade in the record (~4.3 °C).”


Fettweis et al., 2008
“The rate of warming in 1920– 1930 is the most spectacular as pointed out by Chylek et al. (2006). Finally, Greenland climate was colder around 1920 and, in the 1970s and 1980s. The temperature minimum (resp. maximum) seems to have occurred in 1992 after the Mont Pinatubo eruption (resp. in 1931). The warm summers of recent years (1998, 2003, 2005), associated with large melt extent areas (Fettweis et al., 2007), seem to be less warm than these of the 1930s, as also pointed out by Hanna et al. (2007). … The absolute minimum [surface mass balance] occurred around 1930 with a SMB anomaly near −300 km3 yr−1 . Secondary (minor) SMB minima appear to have occurred in 1950 and 1960, equalling the surface mass loss rates of the last few years (1998, 2003, 2006). … After the 1990s, the GrIS SMB decreases slowly to reach the negative anomalies of the last few years, although the summers of the 2000s were not exceptional compared to 70 yr ago“


Goodkin et al., 2008




Huguet et al., 2006


Andersen et al., 2004




Richey et al, 2007


Jiang et al., 2005


Sepúlveda et al., 2009


Kim et al., 2007


Viau and Gajewski, 2009


Dupont et al., 2004


Masson-Delmotte et al., 2004


Weldeab et al, 2005


Birks and Seppä, 2004


Heiri and Lotter, 2005


Richter et al., 2009



Li et al., 2009
“The highest temperature was 22.7°C which was recorded at 1.01 cal ka BP. … Cooling period from 0.85 cal. ka BP to present. SST declined obviously in this period, with the maximum decrease amplitude of 2℃. … No global climate warming due to the greenhouse effect since the Industrial Revolution occurs in the study area.”


Tarasov et al., 2009





Yadav et al., 1997
“The most striking feature of the present reconstruction is the absence of any warming trend in the 20th century”


Dahl-Jensen et al., 1998

Share this...FacebookTwitter "
"
Share this...FacebookTwitterInconvenient historical natural sea ice fluctuations
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(Translated/edited by P Gosselin)
On April 29 German ARD public television presented a report on a Canadian sea ice reconstruction using coral algae growth. The report (in German) can be seen at the ARD-Mediathek in the Internet (begins at the 16:38 mark).
German researcher Jochen Halfar of the University of Toronto found a coral algae type in Canada’s Arctic Ocean that forms annual rings. During the polar nights of winter, photosynthesis stops. In the spring it reactivates again and the algae starts to grow, and does so much better when there is less ice to block out the sunlight. This allows the sea ice cover to be reconstructed over the past several centuries.
It is truly a documentary worth seeing.
But it does has one point that deserves to be criticized. Beginning at the the 27:10 mark, Halfar shows a reconstruction for northern Canada with a strongly receding ice cover since 1850 (Figure 1). Thus the algae growth has increased greatly since 1850 because the shrinking ice cover allowed more light to find its way to the algae.


Fig. 1: Curve for sea ice cover over the past 200 years in North America was reconstructed from coral algae growth, which is shown in the above chart. The strong upward trend means reduced sea ice cover. Screenshot from ARD documentary at 27:20 mark.

The problem is that Halfar blames the effect solely on the industrialization that started in 1850 and the rise of atmospheric CO2 concentration. Here it would have been more real if he had brought up the Little Ice Age – the coldest phase of the last 10,000 years – a natural climate variation. He must have forgotten about it. But things got interesting shortly thereafter when Halfar claimed that such a reduction in sea ice had never occurred during the examined pre-industrial time. But then the camera moved in on the curve for the past 600 years (Fig. 2):


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Fig. 2: Coral algae curve for northern Canada over the past 600 years, which allows sea ice cover to be reconstructed. The upward trend line on the right side supposedly corresponds to what Halfar said was an unprecedented sea ice reduction. Screenshot from ARD documentary at the 27:37 mark.
Lo and behold, the data immediately refuted Halfar’s claim. Between 1430 and 1470 there were multiple algae growth spurts which would mean a sea ice reduction.
So what could have caused these earlier warm phases? Here the solar active phase between the Wolf and Spörer Minima may have played a role. But maybe it was due to the AMO or PDO.
In any case Halfar succeeded in documenting significant pre-industrial fluctuations which were flat out ignored on Germany’s flagship ARD public television.
The elephant in the room is plain to see: If one goes back some hundreds of years into the Medieval Warm Period (MWP) when Arctic sea ice also melted, we find that sea ice cover was about what it is today.
We have documented the Medieval ice melt very well within the scope of our ongoing MWP Mapping Project  We have to assume that Halfar is very familiar with this literature. It remains a mystery as to why he left out this important climate-historical context in the documentary.
 
Share this...FacebookTwitter "
"Britain’s seagrass is a refuge for numerous species of fish, stabilises sandy beaches, and helps to lock away the carbon which humans produce. The meadows that surround the country’s coast have been called the “canaries of the sea”, due to their sensitivity to a changing environment. And like a canary in a coal mine, their health can be used as an indicator of the condition of coastal areas. We know that the seagrass meadows surrounding the UK are in a perilous state of decline, and our recently published research has now uncovered one of the biggest causes. Our study suggests that a major driver of seagrass decline is nutrient pollution from sewage and livestock waste.  Though a new finding, it sadly comes as no surprise, given that about 40% of rivers in England and Wales are polluted with sewage. This nutrient pollution puts the long term viability of seagrass meadows in doubt. Over-enrichment results in the suffocation of seagrass. The nutrients cause microscopic algae – called epiphytes – to smother the seagrass leaves, decreasing their ability to capture light, ultimately killing them, and destroying the habitat for fish and other marine animals. In addition to this environmental impact, we found that several areas, including the Thames waterway seagrass, and a meadow in Studland Bay, Dorset – which are popular with swimmers and boaters – were considerably enriched in nutrients from sewage, livestock effluent and/or human waste. Despite this, neither location, nor any other we identified with the same problem, were classed as unsuitable for swimmers. Clearly, we have a massive problem at hand – but water companies, farmers and the government have not done and are still not doing enough to prevent it. Though efforts have been made to develop a British marine protected area network, and EU legislation has improved water quality in the last few decades, we have found these initiatives to be insufficient. Ten of the 11 sites we studied were in areas with designated EU protection, but most of these seagrass meadows were still polluted with nutrients derived from urban sewage and livestock waste. So how has this happened? Analysis of the seagrass tissues points to constant sewage exposure. Old and outdated water treatment facilities are one of the likely culprits, resulting in discharges of untreated sewage during times of heavy rainfall. These are legal, but evidently the capacity of these facilities is insufficient to handle the country’s needs, and waterways are suffering because of it. There is also the problem of livestock waste. Farming is now one of the UK’s leading causes of water pollution, and inefficiencies in storage and disposal of slurry mean that it ends up in rivers and coastal waters.  Evidently, in addition to national and international initiatives, we need to start quickly identifying and understanding all local threats to seagrass. Especially if we are going to harmonise conservation goals with sustainable economic development. Only by finding out specifically where the nutrients affecting seagrass areas have come from can we really start to think about a targeted solution for each meadow. Unfortunately, to date, the conservation of specific seagrass meadows is rarely based on the explicit consideration of local threats and drivers. Instead, projects focus on conserving seagrass as part of a broader plan, incorporating other specific habitats or species. While this may be effective at dealing with problems such as fisheries impacts, and is certainly a step forward for the marine environment, it doesn’t deal with the persistent and chronic problem of pollution – which can go largely unnoticed.  Poor water quality isn’t just a problem for seagrass in the British Isles, it’s a global concern. But if we want to solve it, we must look beyond “protecting” seagrasses with legislation, and challenge the way we think about marine protection overall. Serious infrastructure changes and better management of river catchments – for example, restoration of riverbanks – are vital if we are going to develop long term waste water management plans that span both land and sea."
"When Michael Gove first called for responses from the public to his plan to ban ivory sales back in October 2017, the environment secretary said a ban would “put the UK front and centre of global efforts to end the insidious trade in ivory”. Four months and 127,607 consultation responses later, Defra (the UK’s Department for Environment, Food and Rural Affairs) has published its own response, confirming a ban will come into effect once legislation can be passed. The law will close the “antiques exemption” in the current legislation, which allows for the sale of ivory that was carved pre-1947. The problem was that same exemption also enabled unscrupulous or unknowledgeable sellers to pass off illegal post-1947 ivory items as if they were older.  The ivory trade won’t be entirely banned under the new regulations, however, and some exemptions will remain: Pianos fall under the first exemption, which relates to musical instruments made before 1975 where ivory makes up less than 20% of the volume. This covers most familiar instruments such as pianos with ivory keys and violin bows.  The musicians unions lobbied hard for the exemption to be included, and this will come as a great relief for them. Most respondents to the consultation opposed such an exemption, but Defra believes that the continuing use and trade in pre-1975 instruments would not contribute to further poaching. The second exemption category is perhaps the most controversial. It allows for trade in objects where ivory makes up less than 10% of the volume, and as long as it was carved pre-1947. Representatives of the arts and antiques sector naturally wanted much more lenient rules – up to 50% ivory – but Defra took a tougher line. Most furniture with decorative ivory will remain exempt from the ban but commonly traded artefacts such as netsuke will not.  Another exemption considers portrait miniatures at least 100-years-old from the start of the new rules. These small portraits were often painted on whisper thin slivers of ivory and encased in glass fronted lockets. The ivory used is so thin that it cannot be re-curved. Defra has also introduced an exemption for museums, which will keep their right to sell to, or buy from, accredited museums in the UK or elsewhere. Many of those in favour said it was important to protect cultural heritage and to conserve pieces for educational and research purposes. This 17th-century ivory carving was sold by Christies auctioneers in 2016 for £965,000. It is mentioned here as an example of one of the relatively small number of items that would fall under the final exemption, for items of “artistic, historic or cultural value”. Such items must be an example of the rarest of their type. Defra will seek out specialist knowledge from advisory institutions such as museums before granting an exemption under this category. As one of the largest and most remarkable statues of its kind in the world, and one of just a handful of confirmed works by its sculptor, “The Flagellation of Christ” would warrant an exemption. But that nice carving you picked up on holiday? Probably not. To enforce the ban, the government wants to introduce new compliance rules which will be administered by the Animal and Plant Health Agency. Owners of ivory items who wish to sell them will have to consider which exemption they come under and then register the items on an online database which will be accessible by the government, the regulatory body and the police. The database generates a unique number. As time goes on, the database will get bigger and unregistered items will become impossible to sell.  Putting the onus on the seller should make the policing of the new rules much easier. Breaches of the new rules will involve both civil punishments such as stop notices or fines, and criminal charges with the offender sentenced to up to five years in jail. Yes, this represents more “red tape” if you are thinking of selling your old piano or antique furniture. But the elephants will thank us."
"We should thank Volkswagen for the wake-up call. The scandal that has engulfed the company has highlighted how an overwhelming focus on carbon dioxide emissions has oversimplified the debate about the negative impacts of all our combustion engines.  Yes, looking at CO2 works well to quantify effects on global climate and fossil resource depletion, but health impacts are a more complex story. “Dieselgate” is forcing people to realise that most vehicles also produce harmful chemically reactive substances such as nitrogen oxides or tiny particulate matter.  This insight has reached the highest ranks of UK government, where diesel subsidies may soon become re-examined. In fact particulate matter may be responsible for as many as 3m prenatal deaths globally every year, according to a recent study in Nature. No one can tell at this point if this is the end of the diesel engine but surely now is the right moment to look towards cleaner and more sustainable ways to power a car. Two key technologies are on the rise: electric vehicles, including hybrids, and fuel cell vehicles which run off hydrogen. The problem for electric vehicles is most people like to stay in their comfort zone and are worried about charging stations and mileage. The industry recently passed the threshold of 1m global sales in total, half of these sold since July 2014, but it is still behind targets set by the US and other governments.  Fuel cell vehicles are a better match with existing habits. Their energy comes from hydrogen stored in a high-pressure tank which then reacts with water to produce electricity that powers the drive train. This allows for mileages similar to those of conventional cars while being refuelled within a few minutes. Hyundai and Toyota already have small numbers of these vehicles on the market, and some other brands are not far behind.  Hydrogen suffers from a long-standing damaged reputation since the Hindenburg disaster in the 1930s. But lots has changed in the past eight decades. These days, the hydrogen isn’t stored in a flimsy airship but in a tank made of a highly stable carbon composite so the risk of it catching fire is minimal. Hydrogen cars can now be considered as safe as petrol or diesel cars, even in crashes. The more recent fuelling stations extract hydrogen from water by running a current through it, effectively converting electrical energy into hydrogen fuel (you may remember doing this exact water electrolysis experiment in school). This all takes place on site, next to where the hydrogen is then stored ready for drivers to use. Doing everything in the one place – essentially all you need to bring is electricity and water – helps avoid transporting hydrogen fuel around in trucks.  A point commonly raised in this context is the fact that electricity production still largely relies on fossil fuels and that hydrogen production through electrolysis is not the most efficient way of using that primary energy. And, if one really wished to have hydrogen, the “cheaper” way was large-scale production out of natural gas. But this leads back to the important differentiation between localised emissions that harm your health and global emissions that damage the atmosphere: even if the hydrogen production involves fossil fuels, fuel cell cars are still considerably better for your lungs. Even the global emissions will benefit from a hydrogen economy in the long run: hydrogen can be stored in tanks, thus allowing for the production of more hydrogen at times of electricity oversupply. Hence, hydrogen fuels will become an essential buffer to help smooth out increasing gaps between supply and demand in the electric grid of the future. That grid will be increasingly dominated by solar and wind power – which follow weather and daylight patterns – and nuclear power, which provides a solid base supply but cannot dynamically react to demand fluctuations either. Economically, all three technologies are dominated by capital expenditure rather than fuel costs, so producing hydrogen at times when no one else needs the electricity may become even cheaper than today.  Hydrogen refuelling stations are stuck in the same chicken-egg problem that battery-charged vehicles had to overcome. This calls for large strategic investments to ensure that a critical mass of cars powered by fuel cells can be reached and operated, which will then drive down the costs of refuelling stations.  Given such stations can be developed and produced in the UK, rolling out hydrogen refuelling infrastructure will serve a double purpose: it paves the way for cleaner air along our roads and it gives the country an opportunity to lead rather than to react in a rising technology. We should be more than a market for the hydrogen technology that is already embraced and pushed forward by the big technology nations: Japan, Korea, China, and the US. The recent discussion around the proposed nuclear power plant at Hinkley, French-owned and Chinese-funded, had a similar ring to it. Why is the country that once built the first civil nuclear power plant in the position of a technology-importing customer? On hydrogen, it’s time to take the lead."
"We are standing at a pivotal moment in the UK’s relationship with the rest of the world. As parliament reassembles post-election, nations around the world, both within the EU and beyond, are waiting to see what direction the UK will take.  The past three years have been dominated by Brexit. By deals forged and then lost. By a string of votes in parliament. By demonstrations and debates and disunity. Whatever side of the fence you fall on, it’s hard to disagree that our country has lost its united national purpose. Looking from the outside, many nations – even while accepting the referendum result – have been truly puzzled and dismayed by our handling of it. We cannot afford another three years of navel-gazing. While digesting the impact of the election on pressing national issues, it’s time that Britain confounded that puzzlement abroad and reaffirmed its place as an outward-facing, global leader. And there’s no better place to do that than within international development. The UK has a long and proud legacy of supporting and investing in the world’s most vulnerable communities. From Bolivia to Bangladesh, our investment has saved the lives of millions, and is helping them reshape and rebuild shattered communities. But while we’ve made huge progress in reducing extreme poverty worldwide, there is still a long way to go. Climate change is taking hold, natural disasters are becoming more deadly and frequent than ever before, new wars are erupting and mass displacement is growing. The world is becoming a more dangerous place, especially for children. They can’t wait for Britain to get its act together. I served as minister of state for the Department for International Development (DfID) until earlier this year; I’ve seen first-hand what a difference aid makes. With the full backing of a parliament that is often bitterly divided on other matters, we helped deliver £30 million to rebuild hospitals, schools and other vital buildings destroyed by Islamic State in Iraq. As a result, families torn apart by the terror group’s brutality have been able to start moving back home. Aid is more than just platitudes by governments. It transforms lives. It’s because of this proven success that we can’t back away from our international commitments. In southern Africa, the worst drought in more than three decades has put a record 45 million people across 16 countries at risk of food shortages. Aid agency World Vision has estimated that put together, this is enough people to stretch around the world one and a half times. Across the globe, the impact of quakes, tsunamis, typhoons, floods and droughts is slowing economic growth, undermining development and trapping millions of people in poverty. Just this year, Mozambique suffered its two most severe cyclones on record within weeks, while devastating floods tore through Asia. These crises need urgent intervention if we are to avoid thousands of needless deaths. I hope the government will not make a hasty decision on merging DfID and the Foreign Office. A standalone DfID has been excellent for the UK’s reputation abroad, and those who work for it truly represent global Britain. As we enter this new season, my message to our new political leaders is this: use that unity between parliament and people as an anchor for rebuilding our national purpose, and demonstrate that we will not forget the world’s poor. They’re counting on us. Alistair Burt is a former minister of state for international development and former Conservative MP. "
"
Share this...FacebookTwitter
Click image to watch.

It is the duty of every Catholic to persecute heretics.”

– Pope Gregory IX, 1170-1241, organizer of the Inquisition

They that approve a private opinion, call it opinion; but they that mislike it, heresy: and yet heresy signifies no more than private opinion.“

– Thomas Hobbes (1588-1679), Leviathan
Now fast forward almost 800 years since Pope Gregory IX’s proclamation on heretics. Guided by global warming dogmatists such as Hans Joachim Schellnhuber of the ultra-alarmist Potsdam Institute for Climate Impact Research, Pope Francis went on to issue a Papal encyclical on the environment and human ecology: Laudato Si, thus making environmentalism a part of Catholic dogma – one that makes challenging climate science heresy.
Now in the wake of Hurricane Irma, Pope Francis has sharply criticized man-made climate change skeptics, implying they are “stupid”. He said on Monday during an in-flight press conference:
Those who deny it [climate change] should go to the scientists and ask them. They speak very clearly. I am reminded of a phrase from the Old Testament, I think from the Psalm: ‘Man is stupid, he is stubborn and he does not see.'”
So says His Holiness, whose Church obstinately took 390 years to apologize for the persecution of heretic Galileo. The bad weather was in fact brewed by skeptics and bad people, the pope insists.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Today a number of (Democrat) politicians and overzealous alarmists in USA are hysterically calling for the criminalization of climate science skepticism and skeptic opinion. For those having read some religious history, this may sound very familiar and remind them of the ugly Inquisition days of the Catholic Church – time when “heretics” were rounded up, brutally tortured and murdered by Church higher-ups — all over Europe, 600 years long.
Papal pact with population control advocate Paul Ehrlich
For many of the faithful, something is terribly amiss with this Pope. Recently he even suggested that Donald Trump was not really a pro-lifer, thus seemingly turns a blind eye to the US Democratic Party’s staunch support for Planned Parenthood abortion factories and a US health care law that forces faithful Catholics to fund abortions against their will.
Earlier this year “population control activist Paul Ehrlich spoke at a Vatican conference on how to save the natural world” today despite an outcry by members of the Catholic faithful“, writes LifeSiteNews.com here. Pope Francis appears to be opening the door to population control.
This is all getting monstrous, hysterical and irrational, and so it’s time for global warming skeptics and the faithful to take a firm and resolved stand against this rogue Pope.
We must never cave in to the Pope’s destructive Inquisition-like dogma and demonization of free thought. We have to remain steadfast, and possibly so for decades or even centuries. Those who want us to forget the past, are those who long for its repeat. Inline with his “stupid and stubborn” statement, Pope Francis seems to harbor a detestation for the human race.
I’m done listening to this Pope.
 
Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitter2nd Highest Subantarctic Glacier Advance 
Of Last 1,000 Years Occurred 50 Years Ago
Yesterday we learned that a giant iceberg just split off from the Antarctic Peninsula.
Most media outlets were uncharacteristically mild with their declarations of concern.  Even The Guardian pointed out that the breakup of the ice is naturally occurring, glaciologists are “not unduly concerned about it“, and while the event “might look dramatic, experts say it will not itself result in sea level rises.”
Rolling Stone‘s Jeff Goodell, on the other hand, was not quite so apt to dismiss the importance of the Antarctic ice “crack-up“.  He insisted that there is a certain big-deal connection between the calving of the Larsen C ice shelf and both catastrophic sea level rise…
“Given that Antarctica contains enough ice to raise sea levels about 220 feet … the break-up for Larsen C is certainly a big deal.”
…and human-caused “cooking the planet”.
“It is also well-timed politically. Larsen C has broken off just a month or so after President Trump withdrew the U.S. from the Paris climate agreement, when people around the world are wondering just how much time we have left before the climate spins out of control – and what to do about it. A story in New York magazine about how climate change is cooking the planet kicked up a lot of debate about the usefulness of fear in inspiring political change. Meanwhile, the responsibility for the Larsen C crack-up is already being doled out: Climate activists have launched a campaign to rename the now-liberated Larsen C ice shelf as the Exxon Knew 1 iceberg.”

Scientists: The Antarctic Peninsula Has Been Rapidly Cooling Since 1999

Apparently Jeff Goodell hasn’t been keeping up with the latest cryosphere science.
It is now well established in the scientific literature that the Antarctic Peninsula  – the location of the Larsen C ice break-up – has been cooling since the 21st century began.  In fact, the Antarctic Peninsula as a whole is cooler now than it was in 1979 (+0.32 °C per decade for 1979-1997, but -0.47 °C per decade during 1999-2014).
Glacier retreat in the region has begun to slow down or shift to surface mass gains.
And the ocean surrounding Antarctica as a whole (the Southern Ocean) has also been cooling since 1979, consistent with the overall trend of sea ice growth during this time period.

Turner et al., 2016
“Here we use a stacked temperature record to show an absence of regional [Antarctic Peninsula] warming since the late 1990s. The annual mean temperature has decreased at a statistically significant rate, with the most rapid cooling during the Austral summer.”


Oliva et al., 2017
“However, a recent analysis (Turner et al., 2016) has shown that the regionally stacked temperature record for the last three decades has shifted from a warming trend of 0.32 °C/decade during 1979–1997 to a cooling trend of −0.47 °C/decade during 1999–2014. … This recent cooling has already impacted the cryosphere in the northern AP [Antarctic Peninsula], including slow-down of glacier recession, a shift to surface mass gains of the peripheral glacier and a thinning of the active layer of permafrost in northern AP islands.”

Fan et al., 2014


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Cooling is evident over most of the Southern Ocean in all seasons and the annual mean, with magnitudes approximately 0.2–0.4°C per decade or 0.7–1.3°C over the 33 year period [1979-2011].”

Comiso et al., 2017     
“The Antarctic sea ice extent has been slowly increasing contrary to expected trends due to global warming and results from coupled climate models. After a record high extent in 2012 the extent was even higher in 2014 when the magnitude exceeded 20 × 106 km2 for the first time during the satellite era. … [T]he trend in sea ice cover is strongly influenced by the trend in surface temperature [cooling].”


New Paper Indicates Subantarctic Glacier Retreat Higher In Late 1700s, 1100-1550 AD

A new scientific paper reveals that modern rates of glacier recession – including the recent fate of the Larsen C ice shelf – are well within the range of natural variability.
Van der Bilt et al. (2017) have produced a glacier reconstruction for Southern Ocean islands near Antarctica (South Georgia) indicating glacier recession was more pronounced than today during the late 18th century, and that the second highest glacier advance of the last 1,000 years occurred in the 1960s and 1970s.  Only the peak glacier advances of the late 1600s were more extensive than the advances of ~50 years ago.
Similar to the recent Antarctic Peninsula and Southern Ocean cooling and nearly 4 decades of sea ice growth described above, this millennial-scale record of glacier retreat and advance supports the position that humans and variations in carbon dioxide concentrations do not play an influential role in determining the fate of polar ice.

Van der Bilt et al., 2017
Late Holocene glacier reconstruction reveals retreat behind present limits…
“Regional palaeoclimate evidence from the adjoining Southern Ocean region also reveal contemporaneous shifts. For example, reconstructed sea surface temperatures (SSTs) west of the Antarctic Peninsular rose 3 °C in less than a century (Shevenell et al., 2011). … Following the termination of a Late Holocene glacier maximum around 1250 cal a BP, warming created conditions unfavourable for glacier growth during the regional expression of an MCA [Medieval Climate Anomaly] between 950 and 700 cal a BP (Villalba, 1994). From 500 cal a BP [years before present], the Hamberg overspill glacier rapidly retreated behind its present-day position, possibly driven by local warming and/or major shifts in regional atmospheric and oceanic circulation patterns (Moy et al., 2008; Shevenell et al., 2011; Abram et al., 2014; Foster et al., 2016).”


To further put yesterday’s ice “crack-up” news into a long-term context, scientists have found there was a widespread (∼280,000 km2 ) collapse of the “world’s largest” ice shelf that occurred between 4,000 and 1,500 years ago.   Retreat rates averaged about 10 kilometers per century during this period.
Of course, this ice sheet collapse occurred while CO2 concentrations hovered near a stable 275 parts per million (ppm), which is about 130 ppm lower than today’s CO2 levels.
Succinctly, the Larsen C ice shelf calving event is not unusual, unprecedented, or even remarkable in the context of Antarctica’s long-term natural variability.

Yokoyama et al., 2016
Widespread collapse of the Ross Ice Shelf during the late Holocene
“The Ross Sea is a major drainage basin for the Antarctic Ice Sheet and contains the world’s largest ice shelf. Newly acquired swath bathymetry data and sediment cores provide evidence for two episodes of ice-shelf collapse. Two novel geochemical proxies, compound specific radiocarbon dating and radiogenic beryllium (10Be), constrain the timing of the most recent and widespread (∼280,000 km2) breakup as having occurred in the late Holocene. … Breakup initiated around 5 ka, with the ice shelf reaching its current configuration ∼1.5 ka. In the eastern Ross Sea, the ice shelf retreated up to 100 km in about a thousand years. Three-dimensional thermodynamic ice-shelf/ocean modeling results and comparison with ice-core records indicate that ice-shelf breakup resulted from combined atmospheric warming and warm ocean currents impinging onto the continental shelf.”
Share this...FacebookTwitter "
"Jaguar Land Rover has become the latest car manufacturer to announce its entry into the world’s first fully electric racing series – the FIA Formula E World Championship. It is reported that the racing series will serve as a platform for the development of an electric-powered road car – perhaps an SUV to rival Tesla’s Model X.  As the nations of the world pledge action on climate change, the automotive industry will face renewed pressure to come up with alternative energy solutions. Consumer demand for passenger cars which reduce harmful emissions without sacrificing performance will be on the rise – more so in the wake of the VW scandal,   Against this backdrop, the potential of both hybrid electric vehicles (HEVs) and battery electric vehicles (BEVs) certainly needs to be considered. But they are not our only clean energy alternative.  The internal combustion engines of both petrol and diesel-fuelled cars can be hybridised by adding electric components – such as motor-generators – together with a small amount of energy storage. Hybridisation offers an excellent opportunity to optimise the way we use the internal combustion engine. It enables the engine to operate at a higher average level of efficiency, and gives cars a way to recover the kinetic energy produced by braking, which is otherwise wasted.  It’s reasonable to expect that a majority of vehicles will be hybridised to some extent in the not-so-distant future, since these small modifications can yield big returns in terms of energy use.  The BEV is a much more challenging proposition as it requires large, expensive, resource-intensive batteries to deliver the kind of power that drivers expect. By contrast, combustion-powered cars are affordable because they are built from cheap materials using cost-effective processes and have a very inexpensive energy storage system – a liquid fuel tank. As a result, the extra costs associated with BEVs will be a major turn off for manufacturers.  What’s more, BEVs only offer a marginal reduction with regard to in-use and life-cycle CO₂ emissions, compared with their combustion-powered competitors. This is because – in Europe at least – almost half of our electricity is generated by burning fossil fuels. Of course, we’ll need to re-evaluate this assessment as our electrical grids become less carbon intensive. And one of the best arguments for EVs is that they help us to develop our infrastructure and technology, in anticipation of a time when renewable electricity becomes commonplace.  Even so, there are a number of competing technologies in the passenger car space – and it’s critical that we research all possible routes to clean, sustainable transport.  Electrofuels – which are fuels manufactured using renewable electricity – offer one plausible alternative to BEVs and HEVs. The idea of using hydrogen gas (H₂) made with renewable electricity to power cars has been around for a long time. The attraction is that releasing energy from H₂ produces only water as a by-product, making it a very clean fuel. But unfortunately, it presents some serious challenges around distribution and storage.  It’s currently thought that H₂ will have to be stored at a very high pressure to get a reasonable amount of energy on board a vehicle – and even then, its density is only comparable to styrofoam. To be sure that H₂ storage tanks are crash- and fire-proof, they have to be extremely thick, carefully-made composite structures. For comparison: to contain the same amount of energy as a 10 US gallon liquid fuel tank, a hydrogen storage tank would have to weigh about 170kg to 180kg. This inevitably drives up costs, and that’s not even considering the problem that H₂ – being the smallest molecule – has a tendency to leak out of tanks and storage systems, and can cause steels to become brittle.  Arguably, a more exciting and practical alternative is to use this technique in power plants. The H₂ generated using renewable energy can then be combined with waste CO₂, in order to synthesise methane. The methane is then injected into the national gas grid, to be used by compressed natural gas (CNG) powered cars. The ultimate goal for this approach is to use CO₂ extracted from the atmosphere. If this can be done, the approach would yield a truly renewable fuel which takes out as much carbon from the atmosphere as it puts in. This process points the way to a sustainable future which retains the low-cost, high-utility internal combustion engine.  It is also possible to produce liquid fuels in a similar way, by using H₂ and CO₂ to synthesise methanol – an alcohol related to methane, which is the simplest liquid energy carrier. While liquid fuels take more energy to produce, they also tend to have a higher energy density than most gas fuels.  Importantly, methanol can also be blended with gasoline and ethanol, and synthesised into pure hydrocarbon fuels, which can act as substitutes for gasoline, diesel and kerosene. Creating these types of high energy density fuels will be the only practical way to decarbonise aviation, for instance. What’s more, methanol can also be made into plastics and other petrochemicals, allowing many different industries to harness excess CO₂.  There’s one sticking point, though: currently, the extraction of CO₂ from the atmosphere on an industrial scale remains a futuristic goal. Still, it is a known, practical process which would enable the mass use of renewable energy in some of the poorest nations on earth, while providing a supply of liquid energy to meet the world’s transportation requirements. It also permits mass uptake of wind and solar power within existing economies, since fuel production provides a means of converting and storing renewable energy, which the electricity grid currently lacks.  At the present time, it makes more sense to use renewable electricity in fixed applications which do not need storage batteries and to reserve fossil fuels for mobile applications, where their energy density is of most use. Because electrofuels can be blended with the fossil fuels we already use, they don’t require us to radically change our energy infrastructure and they don’t decrease utility for drivers.  Both approaches need funding, but electrofuels represent the minimum change to the status quo. They will also require no investment in infrastructure from governments, while yielding the same amount of tax revenue. For all these reasons, electrofuels seem a much more probable route to cleaner driving than BEVs."
"Imagine a country that met the basic needs of its citizens – one where everyone could expect to live a long, healthy, happy and prosperous life. Now imagine that same country was able to do this while using natural resources at a level that would be sustainable even if every other country in the world did the same.  Such a country does not exist. Nowhere in the world even comes close. In fact, if everyone on Earth were to lead a good life within our planet’s sustainability limits, the level of resources used to meet basic needs would have to be reduced by a factor of two to six times. These are the sobering findings of research that my colleagues and I have carried out, recently published in the journal Nature Sustainability. In our work, we quantified the national resource use associated with meeting basic needs for a large number of countries, and compared this to what is globally sustainable. We analysed the relationships between seven indicators of national environmental pressure (relative to environmental limits) and 11 indicators of social performance (relative to the requirements for a good life) for over 150 countries.   The thresholds we chose to represent a “good life” are far from extravagant – a life satisfaction rating of 6.5 out of 10, living 65 years in good health, the elimination of poverty below the US$1.90 a day line, and so on. Nevertheless, we found that the universal achievement of these goals could push humanity past multiple environmental limits. CO₂ emissions are the toughest limit to stay within, while fresh water use is the easiest (ignoring issues of local water scarcity). Physical needs such as nutrition and sanitation could likely be met for seven billion people, but more aspirational goals, including secondary education and high life satisfaction, could require a level of resource use that is two to six times the sustainable level. Although wealthy nations like the US and UK satisfy the basic needs of their citizens, they do so at a level of resource use that is far beyond what is globally sustainable. In contrast, countries that are using resources at a sustainable level, such as Sri Lanka, fail to meet the basic needs of their people. Worryingly, the more social thresholds that a country achieves, the more biophysical boundaries it tends to transgress.  No country currently achieves all 11 social thresholds without also exceeding multiple biophysical boundaries. The closest thing we found to an exception was Vietnam, which achieves six of the 11 social thresholds, while only transgressing one of the seven biophysical boundaries (CO₂ emissions).   To help communicate the scale of the challenge, we have created an interactive website, which shows the environmental and social performance of all countries. It also allows you to change the values that we chose for a “good life”, and see how these values would affect global sustainability. Our work builds on previous research led by the Stockholm Resilience Centre, which identified nine “planetary boundaries” that – if persistently exceeded – could lead to catastrophic change. The social indicators are closely linked to the high-level objectives from the UN’s Sustainable Development Goals. A framework combining both planetary boundaries and social thresholds was proposed by economist Kate Raworth, and is described in her recent book Doughnut Economics (where the “doughnut” refers to the shape of the country plots, such as the one above for Vietnam).   Our findings, which show how countries are doing in comparison to Raworth’s framework, present a serious challenge to the “business-as-usual” approach to sustainable development. They suggest that some of the Sustainable Development Goals, such as combating climate change, could be undermined by the pursuit of others, particularly those focused on growth or high levels of human well-being. Interestingly, the relationship between resource use and social performance is almost always a curve with diminishing returns. This curve has a “turning point”, after which using even more resources adds almost nothing to human well-being. Wealthy nations, including the US and UK, are well past the turning point, which means they could substantially reduce the amount of carbon emitted or materials consumed with no loss of well-being. This would in turn free up ecological space for many poorer countries, where an increase in resource use would contribute much more to a good life. If all seven billion or more people are to live well within the limits of our planet, then radical changes are required. At the very least, these include dramatically reducing income inequality and switching from fossil fuels to renewable energy as quickly as possible. But, most importantly, wealthy nations such as the US and UK must move beyond the pursuit of economic growth, which is no longer improving people’s lives in these countries, but is pushing humanity ever closer towards environmental disaster."
nan
"
Share this...FacebookTwitter
Global Temperature Data Manipulation
 Thousands Of Non-Urban Thermometers Removed 
0.3°C Of Pause-Busting Warmth Added Since 1998 
0.5°C Of Warming Removed From 1880-1950 Trend

Over the course of the last few decades, overseers of the 3 main 19th century-to-present global temperature data sets — NOAA, NASA, and HadCRUT — have been successfully transforming the temperature record to the shape dictated by climate models.  Namely, there has been a concerted effort to cool down the past — especially the 1920s to 1940s warm period — and to warm up the more recent decades, especially after about 1950.  In this way, a trend of steep linear warming emerges that looks similar to the linear shape of anthropogenic CO2 emissions for the 20th and 21st centuries.  A better fit between anthropogenic CO2 emissions and surface temperature helps to imply causation, and this ostensible correlation-turned-causation can then be used to justify policy decisions aimed at eliminating fossil fuel energies.

75% Of GHCN Temperature Stations Removed Since 1970s

One of the most unheralded means by which this temperature “shaping” occurs has been the tendentious and wholesale removal of thousands of weather station land thermometers from remote, high altitude, and/or non-urban locations since the 1970s.  These are stations which do not show the warming trends predicted by models, as they are not affected by proximity to artificial or non-climatic heat sources (pavements, buildings, machinery, industry, etc.) like urban weather stations are.  (As detailed below, locating thermometers near urban heat sources can cause warming biases of between 0.1 and 0.4°C per decade.)
If a highly disproportionate number of non-urban weather stations are removed from the global temperature archive, the urban-based thermometers will be weighted much more heavily than they were before the non-urban stations were removed.  And therefore, the temperature record will show (much) more warming — even though the additional warmth is not climatic, but artificial.
And this is exactly what has happened.  The Global Historical Climatology Network, or GHCN, is the primary source for temperature data records from all over the world.  NOAA, NASA, and HadCRUT heavily rely on GHCN for temperature histories in constructing their global data sets dating back to the 1800s.  According to McKitrick (2010), there were still between 5,000 and 6,000 weather stations across the globe contributing to the GHCN temperature archive as recently as the 1970s.  Today (or as of 2009), there are only a little over 1,000 left — 75% of the thermometers used in the 1970s have disappeared.  There are now fewer weather stations contributing to the GHCN than there were in 1919.
Astonishingly, as many as half (49% as of 2009) of the weather stations across the globe used by the GHCN are now located on the grounds of airports.

McKitrick, 2010
“There are three main global temperature histories: the combined CRU-Hadley record (HADCRU), the NASA-GISS (GISTEMP) record, and the NOAA record. All three global averages depend on the same underlying land data archive, the Global Historical Climatology Network (GHCN). Because of this reliance on GHCN, its quality deficiencies will constrain the quality of all derived products.”
“The number of weather stations providing data to GHCN plunged in 1990 and again in 2005. The sample size has fallen by over 75% from its peak in the early 1970s, and is now smaller than at any time since 1919.”




Growing bias toward airport sources
“The collapse in sample size has increased the relative fraction of data coming from airports to about 50 percent (up from about 30 percent in the 1970s). … The change in the sample was not uniform with respect to source type. For instance it has biased the sample towards airport locations. GHCN had already been heavily-weighted towards airports, which, for many reasons, are not suitable for climatic monitoring. A problem with airports is that they are often in urban or suburban locations that have been built up in the past few decades, and the increase in global air travel has led to increased traffic, pavement, buildings and waste heat, all of which are difficult to remove from the temperature record. … [A]t the global level, as of 2009 49% of all GHCN data came from airports (46% NH, 59% SH), up from just over 20 percent in the late 1920s.”   —  McKitrick, 2010


NOAA’s Tom Karl Was Once Concerned About Urban/Airport Warm Bias

During the late 1980s, the warm bias of 0.1°C to 0.4°C per decade attributed to the urban (or airport) siting of temperature stations was thought to severely compromise the global temperature data sets, with “a substantial portion of the overall trend of global and regional temperatures” directly reflecting this warm bias.   The “artificial warming in the primary station network” never went away.  But it is now just ignored.

Karl and Quayle, 1988
“Karl et al., 1988) has shown that at some ‘sun belt’ cities in the West, the rise of temperature that can be attributed to the urban heat island is as much as 0.3 to 0.4°C per decade. In the East, the rise is over 0.1°C per decade. … The artificial warming in the primary station network, relative to the climate division data, is nearly 0.17°C over the past 34 years [since ~1950]. Such trends are at least as large as any of the observed trends over the United States (Karl, 1988) or the globe (Jones and Wigley, 1987).”
Karl and Jones, 1989
“Results indicate that in the United States the two global land-based temperature data sets have an urban bias between +0.1°C and +0.4°C over the twentieth century (1901-84). … At present, only rough estimates of the potential impacts of urbanization can be given.  This includes an urban bias in the Hansen and Lebedeff (1987) [NASA] data over the United States between 0.3°C and 0.4°C over the 20th century, which is larger than the overall trend in the United States over this period. … To our knowledge, the United States is the only large area of the globe where the magnitude of this bias has been thoroughly studied.”
“The magnitude of this urban bias in two global, land-based data sets was found to be a substantial portion of the overall trend of global and regional temperatures.”
Kukla, Gavin, and Karl, 1986
“Meteorological stations located in an urban environment in North America warmed between 1941 and 1980, compared to the countryside [cooling], at an average rate of about 0.12°C per decade.  Secular trends of surface air temperature computed predominantly from [urban] station data are likely to have a serious warm bias. … [W]e compared trends of the 34 urban/rural station pairs…urban stations show a warming with respect to the countryside throughout most of the year.  
The average annual difference of the trends is about +0.11°C per decade [of non-climatic warming due to urban location]. … The average difference between trends [urban siting vs. rural] amounts to an annual warming rate of 0.34°C/decade.  … The reason why the warming rate in subset D is considerably higher [may be] that the rate may have increased after the 1950s, commensurate with the large recent growth in and around airports. … Our results and those of others show that the urban growth inhomogeneity is serious and must be taken into account when assessing the reliability of temperature records.”

Growing bias toward lowland sites
“The steady increase [in the mean altitude of temperature stations above sea level until the 1980s] is consistent with a move inland of the network coverage, and also increased sampling in mountainous locations. The sample collapse in 1990 is clearly visible as a drop not only in numbers but also in altitude, implying the remote high-altitude sites tended to be lost in favour of sites in valley and coastal [urban] locations. This happened a second time in 2005. Since low-altitude sites tend to be more influenced by agriculture, urbanization and other land surface modification, the failure to maintain consistent altitude of the sample detracts from its statistical continuity.  … GHCN has progressively lost more and more high latitude sites (e.g. towards the poles) in favour of lower-latitude sites. Other things being equal, this implies less and less data are drawn from remote, cold regions and more from inhabited, warmer regions.” —  McKitrick, 2010



The Results: Artificial Land Warming Since 1980


NOAA Global Land vs. Sea 


HadCRUT Land vs. Ocean Temperature Anomalies

NOAA Adds +0.3°C Of Warming (Relative To Satellites) Since 1998

Earlier this month, the Karl et al. (2015) “pause-buster” paper was once again subjected to significant criticism by another former NOAA scientist (Tom Karl was NOAA’s Director during 2015) due to allegations there were political motivations to rush the paper to press before the (December) 2015 Paris Climate Change Conference without requisite quality checks.  The motivation was obvious: If the inconvenient pause in global warming reported by the IPCC in 2013 could be eliminated, it would be a significant development that might encourage government leaders to pledge to reduce CO2 emissions.   Unfortunately, the original temperature data used to compute the new trend (“For 1998–2014, our new global trend is 0.106± 0.058°C dec−1“) in the NOAA publication has been “lost” on a faulty computer that had undergone a “complete failure,” leaving little chance for independent replication or verification.
Since then, the New York Times has issued a defense of the NOAA controversy by claiming that the 1998-2014 trend used in the Karl et al. (2015) paper has been independently verified by other scientists, as well as by satellite data, to show that the +0.11°C per decade trend (+0.2°C overall) between 1998-2014 was consistent across all data sets.
This claim is false, of course.   Using the raw data available and the WoodForTrees interactive tool, we see that the trend discrepancy for the period under consideration (1998-2014) in the Karl paper is nearly 0.3°C when comparing the recently created NOAA trend to satellites (RSS).  There is as much as a 0.5°C difference between the NOAA/NASA GIS and RSS trend line end points (December, 2014).  The -0.1°C cooling that emerges in the satellite data has been transformed into a +0.2°C warming by Karl et al. (2015).  Almost immediately after its publication, the new warming trend for 1998-2014 was accepted by NASA and HadCRUT as well, allowing all three long-term data sets to now show significant warming when there had previously been a pause, even cooling.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Source: WoodForTrees

HadCRUT Erases 1998-2012 Slight Cooling Trend By Changing Versions

Changing unpalatable temperature trends in time for an event of intergovernmental and public policy significance has happened before.
The combined Hadley Centre and Climatic Research Unit (HadCRUT) data set — which is featured in the Intergovernmental Panel on Climate Change (IPCC) reports — underwent a revision from version 3 to version 4 in March of 2012.  This was about a year before the latest IPCC report was to be released (2013).  At the time (early 2012), it was quite inconvenient to the paradigm that HadCRUT3 was highlighting a slight global cooling trend between 1998 and 2012, as shown in the graph below (using HadCRUT3 and HadCRUT4 raw data from WoodForTrees).
Graphs used by the IPCC depicting a slight cooling trend since 1998 would not be acceptable to policymakers wishing to emphasize the urgency of addressing dangerous global warming.  So, just in time for the 2013 edition of the IPCC report, about 0.1°C was added to the 1998-2012 HadCRUT trend.  The effect was to transform the slight cooling into what the IPCC called a “hiatus” from warming.  To achieve the removal of the slight cooling trend found in HadCRUT3, the more recent anomalies in HadCRUT4 were warmed up (by 0.1 to 0.2°C), whereas the past warmth (especially around 1998) was left intact.  The effect was to warm the present and cool the past.


Source: WoodForTrees

IPCC (2013) analysis of the 1998-2012 “hiatus” from warming:
“For the period 1998–2012, 111 of the 114 climate-model simulations show a surface-warming trend larger than the observations.”
“During the 15-year period beginning in 1998, the ensemble of HadCRUT4 GMST trends lies below almost all model-simulated trends.”
“Almost all CMIP5 historical simulations do not reproduce the observed recent warming hiatus.”

NASA Has Removed Almost 0.5°C From 1880-1950 Warming Since The 1990s

As recently as 1990, it was widely accepted that the global temperature trend, as reported by NASA (Hansen and Lebedeff, 1987), showed a “0.5°C rise between 1880 and 1950.”

Pirazzoli, 1990


This 0.5°C rise in global temperatures between 1880-1950 (and 0.6°C between 1880 and 1940) can clearly be seen in the NASA GISS graph from 1987:


Schneider, S. H. 1989. The greenhouse effect: Science and policy. Science 243: 771-81.

Today, it is no longer acceptable for the HadCRUT, NASA, and NOAA global temperature data sets to graphically depict a strong warming trend during the first half of the 20th century.  This is because anthropogenic CO2 emissions were flat and negligible relative to today during this abrupt warming period, as shown here:



So as to eliminate the inconvenience of a non-anthropogenic warming trend in modern times, NASA and NOAA have removed all or nearly all the 0.5°C of warming between 1880 and 1950.  If past raw temperature data do not fit the narrative that human CO2 emissions drive climate change, the raw data must be changed.  In this way, the paradigm is kept alive.


NASA GISS graph


 
Share this...FacebookTwitter "
"A shipping industry summit is looking into how it can reduce its share of global greenhouse gas emissions in line with the Paris Agreement. But a lack of low carbon technologies is not the problem. The International Maritime Organization’s (IMO) 72nd Marine Environment Protection Committee meeting (MEPC) in London started off by being a promising, yet contentious gathering, as the industry desperately tried to agree a strategy for reducing emissions. The sector has responded to this challenge with differing levels of enthusiasm. The Marshall Islands called for a 100% cut in emissions by 2035, a group of countries (including India and Saudi Arabia) pushed for no outright cap on emissions, while the European Union wanted a cut of between 70% and 100% by 2050. It is looking likely that a strategy to deliver a 50% reduction from 2008 levels by 2050 is going to be the agreed outcome. Many fear this demonstrates insufficient progress. Previous analysis indicates that significant cuts in emissions within the sector will be extremely challenging to achieve unless fundamental changes are realised in the short term.  So what can the sector do to rapidly reduce its emissions in the near term? There are many technical measures and operational improvements already being investigated in industry and academia. Here are five viable options, which are not necessarily mutually exclusive, that could help the industry cut emissions. Operational measures including slow steaming (ships operate at slow speeds, reducing their fuel consumption considerably) and route optimisation. Incremental measures (mostly short term) which would cause the sector limited disruption, but are able to reduce emissions per vessel by as much as 5%. These include improving hull design, propeller optimisation and waste heat recovery. Renewable energy – in particular the use of wind-assist, or wind power, for propulsion. Examples include the work that Cargill and Wessels have done trialling kite systems, and the experience of Enercon and Norsepower who both installed different rotor designs on ships. Energy storage through the use of batteries and cold ironing (the process of providing shoreside electrical power to a ship at berth while its main and auxiliary engines are turned off). This would enable the sector to decarbonise by allowing it to run off electricity produced via a low carbon grid. Fuel switch to lower carbon fuels for propulsion.  The most hotly debated of these measures is undoubtedly the choice of fuel burned on the ships themselves. With climate change firmly on the agenda and the historic legacy associated with the use of high sulphur content heavy fuel oil, the sector is at a pivotal point with regards to future fuel choices. Regulation surrounding local pollutants means that the future use of heavy fuel oil is unsustainable. This topic is also being discussed separately at MEPC in association with sulphur limits in shipping fuels. Furthermore, ongoing efforts at MEPC to introduce more stringent measures on climate change mean that heavy fuel oil, diesel and liquefied natural gas (LNG) are not viable. This is despite LNG being seen by many in the sector as the most viable fuel to deliver on both these aspirations. To understand the full extent of the environmental implications, it is important to consider the emissions released over the full life cycle and not just during fuel combustion. These “upstream” emissions include those associated with growing and/or manufacturing, distribution, use and disposal of a shipping alternative fuel. In failing to consider these wider emissions, there is a risk of misleading the industry and policy on the true emission penalties of any alternative fuels.  Research conducted by Tyndall Manchester has evaluated the upstream and operational local pollutant and greenhouse gas emissions associated with conventional fuels alongside a wider range of alternative fuels up to 2050. The fuels assessed are heavy fuel oil, diesel, LNG, hydrogen (with and without carbon capture and storage), renewable hydrogen, methanol, straight vegetable oil, biodiesel and bio-LNG. Despite the likelihood of a weaker than hoped agreement on greenhouse gas emissions at MEPC, the analysis here still demonstrates that no widely available fuel exists to deliver on both the motivation of low carbon and low local pollutants. The conclusions for the industry are therefore contrary to its current direction of travel towards investments in LNG. If the sector were to adopt hydrogen or other synthetic fuels, it would need to rely heavily on the decarbonisation of the energy input required for fuel production to ensure it can deliver absolute reductions in greenhouse gas emissions. It would also need widespread uptake of carbon capture and storage, which is far from a commercial reality. Similarly, bio-derived fuels could be an abatement option, but only if it can be ensured that upstream emissions – in particular, land use change while growing biomass – does not impact wider potential savings. So looking ahead, if the sector wishes to deliver on the aspirations of MEPC, crucial barriers will be the respective fuel life cycles. The way to overcome these barriers may reside beyond the scope of the shipping sector alone.  As the urgent need to curtail greenhouse gas emissions is the more severe challenge, it is important to ensure that any short term measure does not diminish the potential roll-out of low carbon fuels, in particular when taking into account the long life times of ships and fuel supply infrastructure. To meet the objective of reducing greenhouse gas emissions, whole life cycle emissions need to be accounted for."
"
Share this...FacebookTwitterIt was just reported that Greenland set a new all-time July cold record, where the mercury plummeted to -33°C. Read details here.
What follows are excerpts from the most recent analysis of global temperature at wobleibtdieglobaleerwaermung.wordpress.com.
A Greenland record low shouldn’t come as a surprise since in the wake of the recent El Nino global temperatures measured by satellite now continue their freefall. UAH saw it’s lowest measurement in two years, with June coming in with an anomaly of 0.21°K, which was considerably lower than the 0.45°C anomaly recorded in May.

 Source: UAH Global Temperature Update for June, 2017: +0.21 deg. C
Especially the southern hemisphere, which comprises 81% of the globe’s water surface, has been cold recently. The surface temperature plummeted by 0.4°K over the course of June, coming in at an anomaly of just +0.09°C. Antarctica, according to NCEP, was especially cold in June 2017:

A reanalysis of the WMO 1981-2010 2mtemperature  anomaly for June, 2017, shows widespread Antarctic cooling. Source: www.karstenhaustein.com/climate.php.
Also RSS satellite data is showing a clear downward trend since early 2016:

Global temperature anomaly of the lower troposphere at 1500 meters since early 2016, measured by RSS. Source: www.woodfortrees.org/2016/to:2017.5/trend.
Warming hiatus to reach 20 years
As does UAH, RSS shows little or no warming occurring over the past 20 years:

As RSS temperature continues its retreat from the natural ENSO-caused spike, the warming hiatus will resume and extend. By the end of this year, the hiatus will reach 20 years. Source: www.woodfortrees.org/from:1997.7/to:2016.08/trend.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Another interesting pint is that mid troposphere temperatures also fell sharply over June and are at the lower range of the spectrum seen over the past 16 years.

Plot of the UAH-AMSU temperatures at the middle troposphere, 400 hPA (approx. 7.5  km altitude), from January 2002 to July 2017. Source: https://ghrc.nsstc.nasa.gov/amsutemps/.
Greenland surface ice mass balance has also reached a record high, defying the often heard claims that it’s melting. Greenland’s ice mass so far is showing a surplus of some 700 billion tonnes – a record!

Source: www.dmi.dk/en/groenland/maalinger/greenland-ice-sheet-surface-mass-budget/.
Arctic surprises the experts
Arctic sea ice has also surprised many experts, who previously had been predicting record lows, or even its outright disappearance.
Ironically Arctic sea ice has shown a record May-to-May growth from 2016 to 2017. It was the strongest growth for that period since measurements began in 1979.

Source: http://nsidc.org/data/seaice_index/
There has also been a sharp drop in troposphere temperatures above the oceans, which explain the global temperatures. Ocean cycles in large part drive the global temperature over year and decadal scales. Last month they fell to just 0.09°K above the WMO 1981-2010 mean, falling from 0.29°C a month earlier.

Ocean cycles driving global temperature, not trace gas CO2. Source: www.climate4you.com/ here: Sea surface temperature estimates: UAH.
RSS also shows a similar drop in temperature above the world’s oceans, with the anomaly falling from 0.38°K to 0.18°K.
Share this...FacebookTwitter "
nan
"When I was growing up in the 1960s, December marked the onset of winter with regular falls of snow, even in the London suburbs. But recent Decembers have bucked the historical trend, being mild and wet, and none more so than December 2015. Indeed, this was not just the wettest December, but the wettest month ever recorded across the UK, with close to twice as much rain as the long-term average. This was largely due to the arrival of three Atlantic storms from the west: Desmond, Eva and Frank. These contributed to an average rainfall across the UK of 230mm (a shade over 9in), beating the previous monthly high set in November 2009.  The prevailing south-westerly airstream also made December 2015 the warmest December on record, with highs of over 17C (63F) in Gravesend, Kent, warmer than Athens and Lisbon. In Dorset, holidaymakers took advantage of the unusually warm weather to bathe in the sea. More ominously, a record night-time temperature of 14.2C (58F) was logged in Devon. The record highs were the result of a warm airstream reaching the UK from the Azores; with an unusually powerful El Niño leading to warmer sea temperatures, which had a knock-on effect on air temperature readings in the south-west."
"Lewis Hamilton’s recent declaration of support for climate action attracted derision as well as plaudits. “I like fuel. Can I say that? I don’t like electric stuff,” was the deliberately provocative response from a fellow Formula One driver, Max Verstappen. But the sport is officially on Mr Hamilton’s side. In November it announced a net-zero carbon target of 2030. In planning to eliminate most of the carbon emissions for which it is responsible, and offset the rest, F1 is part of a growing movement. The most recent round of United Nations climate negotiations may have ended in disappointment. But the past 12 months have undeniably seen a global surge in public awareness and activism on climate issues. Even Jeremy Clarkson, the television presenter and anti-environmental journalist, admitted the danger of global heating in a public statement last month. While filming a journey from Cambodia to Vietnam for his TV show, The Grand Tour, he saw for himself the impact of water shortages on a dried-up riverbed and admitted to being alarmed.  Since the automobile industry’s earliest days, motor sports have served both as a laboratory and a showcase. While advances were once focused on speed, design and safety, energy could be viewed as just another challenge. But should we embrace “electric stuff”, or other alternatives to petrol, as the automotive future? Of the estimated 1bn cars in the world currently, 5m (0.5%) are electric. Sales in the US, China, Japan and Europe are rising fast, and secondhand markets starting to take shape as batteries perform better than expected. Last month Volkswagen embarked on the most ambitious scheme of any carmaker to date, with the opening of a new assembly line in eastern Germany to build its first mass-market battery-powered car. Tesla’s Model 3 is among the UK’s most popular new vehicles. An electric future?Driving enthusiasts and industry champions, including governments, naturally welcome these developments. For authorities struggling with high levels of air pollution as well as emissions targets, there is no doubt that electric vehicles represent an improvement, especially when they replace older vehicles and SUVs. For decades, petrol pumps have been the most direct point of contact between people and the oil industry. To anyone who seeks to weaken the hold of these powerful businesses, breaking these bonds feels like progress. But is it enough to wean drivers off petrol and diesel? Or could 21st-century transport be more radically reconfigured in such a way as to reduce our dependence on private cars? Automobiles were the creation of the age of oil, as a timely new exhibition about their history at London’s Victoria and Albert Museum makes clear. As nations across the globe get set for the decade of emissions cuts that is mandatory if we are to avoid the catastrophe of global heating of 2C or more, what should be our attitude to driving? Transport is the fastest-growing contributor to global emissions, accounting for around a third of the total in Europe and the US. One recent study found that between 2010 and 2018, SUVs were the second-largest contributor to rises. In the UK, the government is considering a proposal by its climate advisers to bring forward to 2035 a ban on the sale of new petrol and diesel cars. But if the environmental case against the combustion engine is clearcut, arguments about electric vehicles are more complicated. While environmentalists argue for a fundamental shift away from private cars, other sceptics borrow their arguments about the damaging impact of electric vehicle manufacturing and batteries to defend the status quo. These are partly technical questions about the way that emissions are calculated, and how other harms – such as that caused by the mining and disposal of cobalt and lithium used in batteries – are balanced against the danger of continued global heating. But their political importance can hardly be overstated. That is because what is at stake, when we talk about the future of the car, is not only a crucially important industrial sector, particularly in Germany, the US and Japan, but also the way that societies are organised. In the 20th century, the car became part of who we are. While this is perhaps truer in the US than anywhere else, car culture as well as technology has made deep inroads in almost every corner of the world. The economic and social aspects of our relationship with motor transport are so bound up together that they are difficult to unwind. But the V&A exhibition, drawing on work by cultural historians, illustrates the extent to which cars have shaped the world we know. Exhibits include a useful introduction to the mode of industrial production known as Fordism (after Henry Ford), a depiction of the role of motorways in 20th-century nation-building, and sections on safety, gender, and the future – as well as a vast screen showing video of an oilfield. The alternativesThere is no getting away from the politics of transport. Arguments over the division of space and resources between roads and public transportation, and between drivers and other travellers – walkers, cyclists, bus passengers – are generally played out as culture wars between rival tribes. Different political philosophies, as well as lifestyles and needs, push people in opposite directions. Broadly speaking, cars appeal most strongly to people (and political parties) who are more invested in private ownership and individual freedom, while public and low-carbon transport are championed by those who value public space and collective modes of living. All of these issues are even more fraught in the developing world, where investment in public transport is urgently needed if there are to be viable alternatives to further increases in car ownership rates. At a time of dangerous political polarisation, it is important to recognise that beliefs about cars, as about most things, are contingent on experience. Bear in mind the faultlines between cities and towns that have recently attracted notice in countries including France, the US and UK. Attitudes to transport, as to much else, will vary according to geography. A rise in fuel duty was the initial grievance of the gilets jaunes. Climate science dictates that the use of petrol and diesel cars and trucks must be drastically reduced. Electric vehicles are part of the solution, but car culture as a whole also needs an overhaul. This will not be easy. As well as their utility, motor vehicles have come to symbolise powerful human longings for privacy, autonomy, speed, mobility and freedom. Lewis Hamilton is not alone. The rest of us need to do some thinking too."
"Goldman Sachs has ruled out future financing of oil drilling or exploration in the Arctic and said it would not invest in new thermal coal mines anywhere in the world. The new environmental policy, which was released by the US bank on Sunday, was praised by environmentalists, though many warned that it was only a first step.  In its statement, Goldman Sachs also “acknowledged” the scientific consensus on the climate crisis, which it said was one of the “most significant environmental challenges of the 21st century” and said it planned to more effectively help its client manage climate impacts, including through the sale of weather-related catastrophe bonds. Jason Opeña Disterhoft, a climate and energy campaigner at Rainforest Action Network (RAN), which helped to lobby for the change, said the decision to rule out direct financing for Arctic exploration made Goldman the first US bank to establish a “no-go” zone in the oil and gas sector. “Goldman Sachs’s updated policy shows that US banks can draw red lines on oil and gas, and now other major US banks, especially JPMorgan Chase – the world’s worst banker of fossil fuels by a wide margin – must improve on what Goldman has done,” he said. If other banks followed suit, he added, coal financing would become “unbankable”. An investigation by the Guardian earlier this year found that the world’s largest investment banks had provided about $700bn in financing for the most aggressive fossil fuel companies since the signing of the Paris climate agreement. That financing was led by JP Morgan Chase, which has provided $75bn to companies expanding fracking operations and Arctic oil and gas exploration since 2016. RAN and other activists, including veteran Bill McKibben, singled out the “tireless Indigenous-led resistance for pressing Goldman Sachs to make the change, including the Gwich’in Steering Committee, which represents more than a dozen indigenous Gwich’in communities in Alaska and Canada. The new policy was seen as an important development in part because, environmentalists said, the US had been lagging behind European peers and Asian banks that have been making the most rapid progress in addressing the climate crisis. Even as Goldman Sachs won some praise, however, it is clear that the company was not fully committed to backing away from its involvement in the oil and gas sector. The bank reportedly lobbied aggressively last summer to win a seat at the table ahead of the initial public offering of Saudi Aramco, the world’s worst state-owned polluter. Recent reporting on the IPO indicated that Goldman Sachs, among other banks, was likely to miss out on an anticipated fee “bonanza” after the size of the offering was scaled back. Citing people with knowledge of the matter, Bloomberg News recently reported that Goldman Sachs was among the banks that were expected to make less than it had anticipated after foreign investors opted not to participate in the share sale. While Goldman Sachs suggested that its motive in refraining from Arctic drilling was an environmental one, it was not the first time the bank has suggested it was opposed to the idea. In 2017, one of the bank’s natural resource experts said that the allure of tapping the Arctic for new resources had been “dispelled” by the other “enormous cheap, easier to produce and quicker time-to-market resources in the Permian onshore US” resources, referring to western Texas and southeastern New Mexico. Michele Della Vigna, head of energy industry research at Goldman Sachs, said in 2017: “We think there is almost no rationale for Arctic exploration … Immensely complex, expensive projects like the Arctic we think can move too high on the cost curve to be economically doable.” The move on Sunday nevertheless won plaudits from the Sierra Club, among others, which said it had met with Goldman Sachs representatives and other major banks in recent months, along with the Gwich’in Steering Committee, to discuss the dangers of Arctic drilling. “The Trump administration may not care about ignoring the will of the American people or trampling Indigenous rights, but a growing number of major financial institutions are making it clear that they do,” said Ben Cushing, a Sierra Club campaign representative. “We hope other American banks will follow their lead.”"
"As recently as 6,000 years ago the Sahara was green and fertile. We’ve found evidence of large rivers crossing the region, lined by flourishing settlements. Then suddenly things changed. Trees died and the land dried up. Soil blew away or turned into sand and those rivers were no more. In just a few centuries, the Sahara was transformed from a region similar to modern South Africa into the desert we know today. This is an example of a “tipping point”. Just think of the climate like a chair. It takes a strong push to tip over a chair stood on four legs, but when it’s leaning on only two legs the required push becomes smaller. Indeed, if the inclination becomes large enough, it will tip over by itself.  Today, climate change inclination is increasing – and we know it could suddenly tip over, as our planet has previously witnessed several abrupt switches between different states. Along with what happened to the Sahara, there are also the flip-flops between ice ages and moderate conditions which happened every 1,000 years, before things settled down 10,000 years ago.  The idea that global warming might destabilise many climate systems and give rise to abrupt transitions was explored in the movie The Day After Tomorrow, in which melting ice shelves caused a sudden reversal in Atlantic currents – and a worldwide catastrophe. The idea of climate tipping points was explored more rigorously by a team of scientists led by myself for a study recently published in the journal PNAS. We looked at all the simulations performed by 37 climate models that had been used to inform the Intergovernmental Panel of Climate Change (IPCC) – together with their historical and pre-industrial simulations. That gave us a gigantic amount of data: around 1015 bytes divided over several computer servers around the world.  We detected 37 cases of abrupt change, distributed over three different climate change scenarios. These include the Arctic becoming ice-free even in winter, the Amazon rainforest dying off and the total disappearance of snow and ice cover on the Tibetan Plateau. There’s a 30% chance that at least one of these tipping points will be crossed over the next 200 years. This increases to 50% in the most aggressive warming scenario. However, the likelihood of crossing any individual tipping point is much lower, only a few percentage points. So the Himalayas will probably still retain at least some of their glaciers. You should still be able to stand on the North Pole in January. But, taken together, there’s a decent chance that something major will happen. One of the most important findings is that 18 out of 37 abrupt changes are likely to occur when global temperature rises are 2℃ or less, often presented as an upper level of “safe” global warming. Our results imply that there is no window of “safe” global warming and no threshold separating safe and dangerous climate change. Every 0.5℃ temperature increase is similarly dangerous. Many of the tipping points we found apply to sea ice and ocean circulation. Because seawater reflects less sunlight than ice – and absorbs more heat – disappearing sea ice means further local warming, which in turn means more melting sea ice. This process may quickly amplify the effect of global warming. Most climate models simulate an abrupt disappearance of all summer sea-ice in the Arctic at some point this century. Sometimes models predict the reverse process will occur, with sea-ice forming in regions that were previously open water. For instance, water draining from the Greenland and Antarctic ice sheets, combined with increased precipitation and melting sea ice may lead to ocean surface waters becoming fresher and lighter than usual. In the far north Atlantic, this would prevent the mixing between colder surface water and heat from the deep ocean that usually takes place in the region. With heat remaining deep in the ocean, the resulting cooling would be more widespread – one model predicted that by 2060 the Baltic Sea could almost entirely freeze over every winter. In two scenarios this process is associated with a collapse of the Atlantic circulation that brings warm water from the Southern Hemisphere to cold seas around Greenland where it sinks. A collapse of all sinking shuts this circulation down.  This is The Day After Tomorrow scenario. I recently wrote a separate paper analysing the possible effects of such a collapse in oceanic currents – it’s more plausible than you might think and it really would lead to global cooling. In fact, depending on continued emissions levels, the effects could even outweigh global warming for decades to a century, especially in the Northern Hemisphere. Such sudden transitions are more rare on land, but some models predict that a 2.5℃ warming could cause the Amazon rainforest to disappear within 200 years. Forests contain a lot of moisture, and evaporation keeps the local climate cool. If trees start dying the region will grow warmer and drier, which will kill more trees.  Most climate models still don’t even factor in how vegetation will respond to changes in climate – and improvements in this respect would probably lead to more predictions of land-based “tipping points”. Likewise, ice sheet collapses and carbon and methane release from thawing permafrost could also lead to abrupt transitions but aren’t yet included in climate models. For these reasons my colleagues and I believe that the catalogue of abrupt shifts we found is actually at the lower end of what might occur in reality. Dangerous climate change isn’t restricted to 2℃ global warming or more – to avoid unpleasant surprises we should limit it as much as possible."
"
Share this...FacebookTwitterThe German online Nordwest Zeitung (NWZ) reports here how mainly German Socialists and Greens (of all people) are moving to relax strict laws designed to protect nature and endangered species.
The aim is to clear the way for the industrialization of the North German rural countryside and natural areas with wind turbines.

Pushed by Germany’s Greens and Socialists, the country’s nature protection act to be watered down to make the industrialization of natural areas far easier. Image cropped from here.
Journalist Marco Seng reports that under the existing law a planned wind park near the town of Zetel, for example, will have to remain shut down for 6 months every year in order to protect the area birdlife. However, denying wind park construction and operation in order to protect nature and wildlife has become just too much to ask of Germany’s socialists and environmentalist greens.
They are now pushing through a watered-down law.
Each year in early spring a number of bird species transit through or nest in north German regions, which wind park developers and operators happen to find ideal wor wind energy generation. That’s a big problem. Under the current federal law wind turbines located in sensitive areas are required to shut down from March 1 to August 30 in order to comply with § 44 of the German Nature Protection Act.
Seng reports how a number of turbines are planned to be erected in different areas this year. For example the county of Friesland gave its approval in early January to rezone the areas by the end of March and allow the construction of turbines. Citizens groups however have protested, claiming that the turbines will not be profitable due to the summer shutdown period. Yet the mayors insist they will still make a profit and the projects will go ahead.
All this is highly controversial as the NWZ writes that recent studies and expert assessments have concluded that “many bird species are threatened, foremost predatory birds because they do not avoid turbines“.
Also the Deutsche Wildtier Stiftung (German Wildlife Foundation) estimated that approximately 250,000 bats and over 12,000 predatory birds fall victim to wind turbines annually, with a high number being killed over northern Germany. Recently some courts found in favor of the red kite hawk, and thus some planned wind parks were denied approvals to be constructed. The reason, NWZ reports, “a high risk of death to birds and adverse feeding conditions for predatory birds.”
So it’s little wonder that wind energy proponents are adamantly pushing for relaxing Germany’s nature protection laws.
At other locations, wind park projects are being given the green light anyway, angering nature-protection activists. The NWZ quotes Monika Oetje-Weber of the Kammersand citizens’ action group:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




If all the information and documentation on the presence of important bird species had been taken seriously, then the approvals would have never been issued.”
The municipalities and project proponents, however, insist that the the turbines that are to be erected will pose no threat to bird life.
Watering down the nature protection laws to allow the turbines to run all year.
Because of the intensifying collision course between wind projects and birdlife and nature, and the increasing protests against wind parks in rural areas, the German government is now moving to alter Germany Federal Nature Protection Act to make it easier to build and operate wind parks and highways. The NWZ writes:
You read that correctly. In the future the Federal Nature Protection Act’s § 44 Section 1 No.1 ban against killing will be valid for interventions and projects if the risk of death for especially protected species in unavoidably signficantly high.”
This means the bar will be significantly lowered for wind projects. The reaction from nature activists came swiftly and harshly. The NWZ:
‘The amendment leads to a dramatic threat increase to birdlife and bats by wind turbines, and that is unacceptable,’ says Fritz Vahrenholt, Chairman of the German Wildlife Foundation. The killing of birds is thus no longer a principle reason for obstructing wind turbine parks.”
Other leading traditional environmental protection groups such as NABU are outraged, writes the NWZ:
We see absolutely no necessity for the planned amendment. We demand that lawmakers do not pass the amendment as it currently stands,’ says NABU President Olaf Tschimpke.”
Others accuse the government of having hollowed out the country’s nature protection laws and caving in to industry lobbyists. Others say that approval committees have not been strict enough when it comes to species protection assessments, claiming that the planning of the projects violates the law.
The NWZ concludes that a major collision between nature protection and the wind industry is now more unavoidable than ever. But the trend is clear: in Germany nature and birdlife are losing the battle against the powerful industrial wind lobby and climate protection activists.
Germany risks seeing the worst government-steered environmental disaster since the collapse of Communism late last century.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhat follows is a wrap up of an article written by skeptic climate and weather site wobleibtdieerderwaermung.de here.
It writes that for thousands of years it has been the solar and ocean cycles that have been influencing the weather worldwide and in Germany.
And looking at data objectively, it is pretty clear that there is little relationship between weather/climate and the rising CO2 concentrations in the atmosphere, as the global warming pause between 1997-2016 shows:

Linear trend of RSS temperatures. No warming in 224 months despite the current powerful El Niño-event. “The least-squares linear-regression trend on the RSS satellite monthly global mean surface temperature anomaly dataset shows no global warming for 18 years 8 months since May 1997, though one-third of all anthropogenic forcings have occurred during the period of the Pause.“ Source: The Pause hangs on by its fingernails.
Naturally climate models continue to grossly overstate the trend for global temperature:

IPCC climate models obviously have assumed an excessively high value for CO2 climate sensitivity. Source: On Natural Climate Variability and Climate Models.
The IPCC climate model projections diverge increasingly from the measured reality, year after year. 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In fact new studies have clearly exposed three decisive errors in the programming of climate models:
1. The cooling effect of aerosols has been over-estimated by a factor of 2: Hamburg Max Planck Institute for Meteorology: Aerosols cool less than originally thought.
2. The warming effect of CO2 in in the atmosphere is as a result overestimated by a factor of 2 or three. See: Die kalte Sonne site here (German).
3. The complex effect of fluctuations in solar activity are poorly accounted for in climate models. Solar Forcing of Climate – NIPCC
The consequences: All parameters when used realistically lead to a considerably lower global and regional warming — especially in the future, see following chart:

Source: Peer-reviewed pocket-calculator climate model 
It’s time to end the hysteria surrounding CO2 and its grossly exaggerated effects on climate and the ridiculous efforts of protecting the climate on every point on the planet every day for 30 years (whose statistical average is the World Meteorological Organization’s definition of climate). Very little can be accomplished trying, and the price would be enormous and ruinous.
We can argue over whether the pause has ended or not, but one thing is clear: the observations are all well below the model projections.
 
Share this...FacebookTwitter "
"Early to bed and early to rise makes a man healthy, wealthy and … also energy efficient, as it turns out. After 1am on Sunday night here in Oxford the time suddenly jumped forward to 2am – the UK is now officially on “British Summer Time”, where it will remain for the next seven months. The rest of Europe also put its clocks forward at the same moment, while the US and Canada moved to summer time earlier in March. Collectively, this is known as daylight saving time.  But what if all these countries kept to summer time throughout the winter? About a decade ago researchers at the University of Cambridge made a strong case that, in the UK at least, it would have a range of positive effects. Twelve months of summer time could reduce road deaths and crime, boost business and trade and also reduce energy consumption at peak times by up to 8%. All of this is possible because our most active periods would be better aligned with daylight hours. Shifting the timing of electricity use has gone up the academic agenda for another reason. Flexible demand has the potential to save billions in the integration of renewables, such as wind and solar. The logic is simple: the highest energy demand occurs in winter around 5.30pm. This is when people come home and many businesses are still open. It’s also when it is cold and dark and we need extra energy for heat and light. Yet, output from low-carbon solar power is pretty much guaranteed to be zero. If British Summer Time was continued through the winter, the peak-demand problem would be reduced. Everyone would get up an hour earlier, work earlier and come home earlier, often when it is still light. Activity would still peak at around 5.30pm human time, but that same time would be earlier relative to sunset.  Given that lighting alone may be responsible for 20% of peak demand in the UK, there is lots of scope for saving energy. One review found that using energy at different times could lead to peak reductions of up to 8%. In lighter evenings there might even still be some solar power available to further reduce the net demand for fossil fuels. The savings in the evening would exceed any potential increase in the mornings.  So why don’t we talk more about how daylight saving hours could help the effort to decarbonise? One reason is political economy – while getting up an hour earlier makes sense to an expert in energy policy or road safety, it won’t necessarily be popular with the public (not to mention Scottish farmers or teenage children). This is the same problem that affects many other potentially very sensible energy saving measures: as soon as there is even a remote chance of inconveniencing people, it is likely not to see the light of day. This is part of the reason why energy policy making is dominated by measures to boost supply such as new nuclear plants, fracking, or support for renewables. Tampering with the demand side requires a lot of political courage. However, we may be able to put a more positive spin on it. Why should changing what we call “7am” to “8am” make such a difference anyway? After all, it is just a relabelling exercise. It is fascinating how an entire society re-synchronises its activities based on a change of the clock hands. Yet if people stuck to their own rhythm they could avoid the worst rush hours and even get home in daylight during the winter. Of course it is not that simple. Our daily rhythms are strongly reinforced by traditional conventions, such as working hours, schooling hours and shop opening hours. It began in the 19th century with factories using time to synchronise their workforce into shifts. With the arrival of the railways, clocks across the country were synchronised and millions of people began to operate to the same rhythm – not their natural rhythm, but the clock rhythm. There are some obvious benefits to having a workforce in the same place at the same time. However, when looking at the system as a whole, synchronisation brings with it some serious challenges, most notably peak demand constraints. It may therefore not be all that helpful to shift everyone’s day by one hour with a nationally synchronised clock change. Allowing for some more diversity to develop instead could be advantageous. More flexible working hours could reduce and spread peaks. This could even be encouraged regionally, given that Cornwall, on England’s south coast, faces very different daylight conditions than, say, north Scotland. You don’t need to wait for the government either. Next autumn, when the clocks go back, be a rebel and just go to bed one hour earlier – that is, don’t change anything. You’ll not only reduce energy demand, but also help to diversify it."
"
Share this...FacebookTwitterIf Florida’s transportation were based mostly on electric vehicles, as activists demand, it would quickly come to a standstill in times of hurricanes and mass evacuations. Charging stations would be overwhelmed and millions of lives put at risk. 

Good thing we have fossil fuel powered vehicles, which can run and be refueled whenever the power is out. Army National Guard load trucks as they prepare to hand out supplies to people in need. E-vehicles would sit idle and leave millions abandoned and at risk. (U.S. Navy photo from FEMA site, by Chief Mass Communication Specialist Ryan J. Courtade/Released)
E-mobility in times of hurricane would be “a nightmare”
Yesterday Michael Limburg of the Germany-based European Institute for Climate and Energy (EIKE) here posted a brainstorming thought exercise, posing the question of what would the evacuation of Florida look like if most of the cars were electric?
And to take it a step further, what would rescue services today be like if they depended on electric vehicles?
EIKE concludes that it would be “a nightmare!”
“Mass death”
EIKE cites a post by IT expert Hadmut Danisch here, who drove the point home, saying the outcome would be “mass death on the highways“. Though the discussion rages over the degree to which man may be at fault for hurricanes like Irma, one thing is sure: as long as it’s September, the Atlantic and the Gulf of Mexico will always be in peak hurricane season with or without man. Powerful hurricanes have always been the case, and always will be.
What has emerged, Limburg writes, is: the better the early warning system is, and the more mobile people are, the less victims you are going to see.
Cars would lose their charge, millions stranded on highway


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Imagine if the environmentalists had had their way and had managed to force the US into electric cars…something that is underway now in some countries like Norway, the UK and soon France. Germany recently has been discussing in earnest banning by 2030 the internal combustion engine.
And now imagine with Irma approaching if the millions of citizens evacuating populated south Florida had had electric cars instead to make the 400-mile journey to get out of harm’s way. After 100 miles or so these cars would have lost their power, and charging stations quickly would have become overrun with cars waiting to make the one-hour charge-up.
Traffic would have rapidly come to a halt.
These millions of stranded people then would have been sitting ducks waiting to be blown away by nature’s fury.
Fossil fuel vehicles never need a rest
With fossil fuels, the car’s range is far greater, fueling time is just minutes and extra canisters of fuel also can be easily brought along. Power outages would not interrupt petrol stations because the gas pumps can be easily powered by portable fossil fuel-powered generators.
But with electric cars it would be a totally different story. If a hurricane hit, power lines would go down, knock out the power grid and thus would make the charging of electric vehicles impossible. Solar panels would fly off buildings as roofs are torn off. Wind parks would automatically turn off because they are not designed to operate in hurricane force winds. Many wind towers would simply buckle in the 250 km/hr wind gusts, meaning the green power supply infrastructure would of course get destroyed. In summary, solar panels and offshore wind parks in the Caribbean and Gulf of Mexico make about as much sense as raising sheep on a wolf-farm.
And after the hurricane passes, electric cars would remain immobile because the power grid would be knocked out. Recharging vehicles would be impossible. Emergency vehicles also would quickly lose their power charge and sit idle. Recovery and clean up efforts would take months, if not years. The toll on human life would be unimaginable.
This is the future of electric mobility.
Today, thanks to fossil fuels, energy is always portable, available and reliable. Fossil fueled vehicles are able to travel great distances, be onsite within a minutes notice, and be refueled quickly. Nuclear and coal power plants stand their ground, and so restoring power is easy.
Floridians have shown that even in the aftermath of the most destructive storms, recovery and a speedy return to business is a matter of days or a few weeks, all thanks to the always dependable and available fossil fuels.
 
Share this...FacebookTwitter "
"Two weeks ago, as I was walking west through my neighbourhood in the early morning, I was struck by the eerie copper tone in the atmosphere. I turned and looked to the sky and was stunned by the glowing red sunrise. It was utterly disorienting – I stared, took photos, checked the sky in all directions, confused about what I was seeing. I knew from its position that it had to be the sun but it looked nothing like it. To the west of the city, and north along the coast, bushfires raged out of control. The intense red light bounced off concrete and shined off street poles. There were a few other early risers on the street, all of us stopped in our tracks, faces turned to the sky. Many raised their phones and snapped. And then we went on with our day. Unsettled, disoriented and looking over our shoulder every few steps, but for the most part operating as we usually would. It is a bizarre position in the landscape to hold, living at the edge of calamity. Paying closer and more considered attention to the natural world has been a personal project of mine over the last 18 months, which I have chronicled at times in journal entries. It began as a somewhat inward-looking exercise to help myself feel more grounded in times of stress. For the most part, those journal entries unfurled like plants themselves, forming at the root with whichever plant or flower I identified with at the time of writing, and reaching out towards the underlying feeling as if towards the sun. It has, at times, caused me significant emotional distress. When I noticed certain plants blooming months after they usually do, when I noticed the persistent greens right through the winter months, when I noticed cold-weather blooms coming out later because of the steadfast heat – these things prompt awareness of the future of the planet and I have given in many times to despair. I discovered the true potential of this project recently in reading Jenny Odell’s How to Do Nothing, a meticulous and wide-ranging treatise on rejecting modern capitalism’s notions of productivity and optimisation. In the book, Odell describes discovering, among many other things, that embracing bioregionalism can be a way of returning to community, which in turn ensures more effective activism. Odell writes: “Observation and simple conviviality should be recognised not only as ends in and of themselves, but as inalienable rights belonging to anyone lucky enough to be alive.” The summer I experienced when I first moved to Sydney three years ago was full of days spent in a near-sensual anticipation of heading outdoors. I fell in love with the air in all its sickly sweet promise, thick and nourishing with humidity. Before this year, the idea of being outdoors represented a promise of bright expanse, the sky felt wide and infinite. By December, hedges of unruly jasmine start curling and browning in the heat, wilting and heavy after their springtime explosion. The fragrance of frangipani emerges and mingles with that of hot, wet concrete. The jacarandas turn and the bright purple blooms start dropping to the streets. What I love most about the jacarandas is their capacity to surprise you, particularly in built-up urban environments, dotted as they are throughout the city, in pockets between apartment buildings, warehouses and garages. This year, that anticipation of moving outdoors at the end of the day has transmuted to dread. I heed health advisory warnings that instruct us to stay indoors. I cancel classes and appointments. I notice the subtle tightening in my chest. Looking to the jacarandas outside my office, I am startled by the colour contrast – the bright purple against a shock of orange sky. When afternoon comes, the light turns and an ominous red light starts stretching across the floors, through windows that are dusted with a thin film of ash. A week ago – before the day the thickest smoke choked Sydney and thousands of protesters took to the streets in particle respirator masks – I walked through my neighbourhood on my way to meet a friend. The sky was a deep tangerine and I watched as crowds of office and retail workers on their way to Christmas parties rushed through the street in groups, wearing felt reindeer ears and Santa hats, clutching at each other in what I intimated was a perverse, confused joy. I walked past outdoor dining tables, people eating with their pollution masks suspended from their chins. I overheard one man talking to his friends as they waited at a pedestrian light, “I can’t stop thinking about the dinosaurs.” I looked up at the glowing sky as he crowed, “This is it!” We in the cities are experiencing now what those in areas afflicted by drought, floods and fire have felt for some time: solastalgia. Solastalgia is a term coined by the philosopher Glenn Albrecht while researching the impact of open-cut coalmining in New South Wales’ upper Hunter region. It describes a sense of grief, of existential dread and distress, caused by significant environmental change. I find myself refusing to accept that this is the new normal by insisting on another normality Alexis Wright has written of the new language of climate catastrophe and the powerful nature of this country. Indigenous people have long argued of the responsibility we humans have to the land. The sense of connection we feel to the natural world is vital, and it is no less so for those of us living in cities and built-up environments. In recent weeks I catch myself making matter-of-fact asides about the end of days, and I’m working to pull myself up, because I worry what it does to any sense of purpose or resilience I might need. It has become clear to me that going forward, nothing will be more important than sensitivity and hope – and nothing will be more dangerous than resignation. A phrase I’ve heard often over the past fortnight is, “the new normal”. Most of us are questioning, but I worry that some of us are, already, accepting. I’m guilty of this tendency, too. I share photos of the impossibly red sun on my Instagram stories and I caption them “normal”. “Normal sun, normal planet.” I text my houseshare group chat pictures of the P2 masks I bought for us and caption it “just Anthropocene things”. A year or so ago I started joking that my gym membership was less about managing my mental health (it was) and more about preparing for the end of days (it started to feel possible). Of course, part of this is a natural inclination to revert to humour, when to submit to the overwhelming sense of catastrophe would be too much to bear. But beneath the jokes is a very real fear. My hope is that I have a few ways of pushing against this sense of resignation within myself, the first of which is to remain aware of the ways in which politicians and mining corporations benefit from these exact feelings of hopelessness. The second way feels open to dismissal as frivolous but it’s for that very reason I want to hold on to it – it is a refusal to be denied the pleasure of nature. It’s not a solution on its own and it must necessarily take place in context of sustained protests and strikes. But part of what has made these strange orange days so distressing is the fact that life does go on. It feels absurd that life should be so normal. I find myself refusing to accept that this is the new normal by insisting on another normality. Insisting on the right to an unencumbered existence outdoors means insisting on a planet that is not merely habitable, but one that is joyful, nourishing and sustaining. I don’t want for my friends to adjust their toddlers’ playtime routines to navigate playgrounds covered in ash, to seek out respirator masks that will fit their small and ever-changing faces. I want the prospect of going outside at the end of a work day to feel thrilling and rejuvenating. This is not denial – I know that if I have a child, their summer will be markedly different from any that I knew. But I hope for all of us to know the pleasure of slow, early mornings, to walk through urbanised spaces and still be reinvigorated by jacarandas lining the streets. To know unfettered access to green, public spaces, and to be able to breathe, freely and deeply. Léa Antigny is a Sydney-based writer and publishing professional"
"“There is neither Jew nor Greek, there is neither slave nor free, there is no male and female, for you are all one in Christ Jesus.” These words, written by Saint Paul 2,000 years ago, are central to the Christian faith. They speak of a vocation for the universal and point to an ethic of social justice and solidarity. The Christian tradition’s account of the humble circumstances of the birth of Jesus, represented in the nativity scene, is in the same spirit, identifying Christ with the marginal, the maligned and the poor. It has therefore, for many Christians, been depressing to witness the faith of their churches being used to justify the abandonment of such principles in Europe, Donald Trump’s America and beyond. For liberally minded Christians, 2019 was the latest in a succession of anni horribiles, during which a cultural appropriation of their religion did service for aggressive nationalism, xenophobia, homophobia and anti-environmentalism.  In Poland, the Law and Justice party was re-elected, with the enthusiastic backing of the country’s Catholic establishment. It made the demonisation of LGBT people a key part of the autumn election campaign. In doing so it received the active assistance of the archbishop of Kraków, Marek Jędraszewski, who warned voters that a “rainbow plague” had replaced the “red plague” which blighted the country in the communist era. The country also stands accused of breaking European Union law by refusing to comply with a refugee quota programme, instituted in 2015. A question of faithHungary’s prime minister, Viktor Orbán, has forsaken talk of illiberal democracy and now speaks of “Christian liberty”. Mr Orbán’s ambition appears to be to turn Budapest into the capital of rightwing Christian thought, an arch-conservative counterpoint to Pope Francis’s Vatican. Last month, at a conference convened in the Hungarian capital to highlight the persecution of Christians in places such as Iraq, Syria and Nigeria, Mr Orbán repeated his argument that Christian culture was under threat from Muslim migration, and warned that the persecution of Christians in Europe was “much closer” than generally understood. The Hungarian Helsinki Committee, a human rights organisation, has accused Mr Orbán of systematically denying food to failed asylum seekers held in detention camps on Hungary’s border – an action it described as “an unprecedented human rights violation in 21st-century Europe.” He has also made homelessness a criminal offence. Mr Orbán discovered a religious side in his 30s, as the political party he led, Fidesz, moved to the right. In Italy, the leader of the League party, Matteo Salvini, uses Christianity to pursue culture wars relating to migration and national identity. When Mr Salvini, as minister of the interior in Italy’s previous government, proposed in 2018 that crucifixes should be displayed in all Italian public spaces, including ports he had closed to vessels carrying rescued migrants, he was reprimanded by a close adviser of Pope Francis. The Rev Antonio Spadaro tweeted: “The cross is a sign of protest against sin, violence, injustice and death. It is NEVER a sign of identity. It screams of love to the enemy and unconditional welcome.” But Mr Salvini has since doubled down on his politicisation of Catholic symbols, claiming he is “the last of the good Christians”. Support for him among practising Catholics is high. The battle to defend the rights and human dignity of all, irrespective of gender, race or sexuality, is having to be fought all over again. But the theological roots of that liberal vision in a Pauline notion of universality – “all are one in Christ” – is rarely examined by progressives. In an era when Christian ethics are being so brazenly twisted to serve nativism and attacks on minorities, that could be a mistake. Happily, there are signs that this may change in 2020. Some of the Democrat candidates in next year’s US presidential race are wearing their faith on their sleeve to an unusual extent. The popularity of Donald Trump among American evangelical Christians is well known. In 2016, 81% of evangelicals and a large majority of US Catholics put Mr Trump’s flawed personal morals to one side, voting for a candidate who would fight their corner in culture wars over same-sex marriage and abortion, as well as on migration. The Pew Research Centre survey this year found that only 25% of evangelicals believe that the US has a responsibility to accept refugees. President Trump’s Catholic former adviser, Steve Bannon, has been a prominent promoter of the supposedly “Judaeo-Christian” values that inform Trumpian nationalism. Straws in the windHowever, Democrat candidates have begun to play this game on their own terms. Elizabeth Warren, the senator for Massachusetts, has frequently referenced the gospel of Matthew, in which Jesus talks of feeding the hungry, clothing the naked and caring for the sick. Pete Buttigieg, the gay Christian mayor of South Bend, Indiana, has explicitly attacked the Republican party’s taste for “cloaking itself in the language of religion”. Mr Buttigieg told an American magazine: “For a party that associates itself with Christianity to say that it is OK to suggest that God would smile on the division of families at the hands of federal agents, [that party] has lost all claim to ever use religious language again.” Last week the influential US evangelical publication Christianity Today called for Mr Trump to “be removed from office”. Straws in the wind? For both secular liberals and Christians, there are lessons to be drawn from what might be seen as a prophetic alliance between Pope Francis and Greta Thunberg on the most urgent issue facing the world: the climate emergency. When Time magazine made Ms Thunberg its person of the year, the Vatican was quick to celebrate her as “a witness to what the church teaches on the care of the environment and the care of the person”. The pope has identified the protection of the Amazon rainforest, where this year the greatest levels of deforestation for a decade were recorded, as an environmental priority. But the culture wars being fought in the public square – which have seen Ms Thunberg become a target – are also being played out within the Christian churches. A three-week Rome synod on the Amazon in October was overshadowed by conservative criticism of the Pope’s decision to invite native peoples and welcome their religious symbols. Liberal democracies rightly prize the separation of church and state which emerged following the Enlightenment. But as the reactionary right denigrates ideas of human dignity and equality that can be traced back to the first formulations of early Christianity, liberals of goodwill need to unite across the religious/secular divide in 2020. • This article was amended on 26 December 2019 because an earlier version gave the plural of annus horribilis as anni horribili. This has been corrected to anni horribiles."
"The energy regulator has warned the operators of the UK’s electricity networks that it will cut investor returns in a push to keep a cap on household electricity bills. Ofgem says the networks will provide lower company returns in the next price control period, from 2023, and it will push them to invest more in building a carbon neutral energy system. The regulator’s drive to force networks to deliver more while making less comes after it admitted companies had been allowed to make “unjustified” returns for their owners to the detriment of household bills. Cathryn Scott, the acting head of networks at Ofgem, said the regulator’s “stable and predictable regulatory regime” would allow companies to attract the investment they needed to “go further in decarbonising the system whilst saving consumers money by keeping returns as low as possible”. Scott is filling the position on an interim basis after the previous head of networks, Jonathan Brearley, was promoted to become Ofgem’s chief executive from February next year. The regulator is under pressure to prove that it can fully support the UK’s 2050 climate targets after Britain’s biggest business group, the CBI, said the regulator was failing to prioritise the climate emergency and should be given new statutory duties by the government. The CBI said Ofgem must place the climate crisis at its core to ensure that it did not unintentionally undermine the UK’s green agenda. The calls have been echoed by major energy companies, green groups and the Committee on Climate Change. Ofgem says it will overhaul its regulatory approach to enable companies to meet new sources of demand on local grids, such as electric vehicles, and help energy users to manage their demand. It will also help companies to invest in anticipation of rising demand on the grid for car charging, even while this demand is uncertain. Earlier this year Keith Anderson, the chief executive of Scottish Power, accused Ofgem of hindering the rollout of electric vehicles by refusing to allow the company to invest an extra £42m in upgrading its networks in anticipation of an electric boom. He told the Guardian there was a “colossal disconnect” between the government’s policy of accelerating the uptake of electric vehicles and the regulator’s policy on supporting investment in charging. Ofgem said electricity networks would be “crucial” to help the UK to meet its climate targets as the energy system increasingly relies on renewables “to generate the electricity to power the country, our vehicles and potentially heat our homes too”. The regulator said it planned to impose “tough scrutiny” of energy firms’ plans. Ofgem made the warning just days after Labour’s plans to take energy networks back into public control were dashed by the Conservatives’ election victory. Earlier this week the regulator of the water industry – which was also included in Labour’s wide-ranging nationalisation agenda – handed water companies the toughest price controls since privatisation. • This article was amended on 18 December 2019. Due to an editing error, an earlier version referred to “energy suppliers” in the headline and text when “energy networks” was meant. This has been corrected."
nan
"Two volunteer firefighters have been killed and three have been taken to hospital with severe burns as the bushfire emergency raging across the east coast of Australia reached a new crisis point on Thursday. The two NSW Rural Fire Service volunteers were killed when a truck believed to have been travelling in convoy near the town of Buxton late on Thursday hit a tree and rolled off the road. The driver and front passenger died at the scene, police said, while three other firefighters were injured. The fatal accident occurred at the end of an exhausting day for firefighters in which it’s feared some 40 homes could have been lost in Buxton, Balmoral, Bargo and surrounds, as the Green Wattle Creek blaze tore through the Wollondilly Shire on Thursday. The NSW RFS officially says 20 homes may have been lost but there are reports 40 buildings were destroyed. “The Service’s thoughts are with all the firefighters’ family, friends and fellow brigade members,” the RFS said in a statement early on Friday. “This is an absolutely devastating event in what has already been an incredibly difficult day and fire season.” The premier, Gladys Berejiklian, said on Twitter the news was “devastating”, and NSW had “tragically lost two heroes”. Earlier on Thursday, three firefighters were treated for burns after their truck was enveloped by the bushfire. Two members of the crew, a 36-year-old man and a 56-year-old man, needed to be intubated to protect their breathing as they were airlifted from the scene with serious facial and airway burns. Fitzsimmons said the two men also suffered burns to their arms, elbow, upper chest and leg. A 28-year-old woman was also treated for smoke inhalation and superficial burns and was taken to hospital by road ambulance. Record temperatures and gusty, damaging winds combined with the prolonged drought crippling this part of the world to create what the commissioner of the Rural Fire Service, Shane Fitzsimmons, described as “volatile and erratic” conditions as more than 100 fires continued to burn across New South Wales. A day that began with Berejiklian declaring a second week-long state of emergency in a little over a month ended with Fitzsimmons telling media that three firefighters had been hospitalised after a crew of volunteers was “overrun” and “enveloped” by fire while trying to protect homes. Fitzsimmons, whose press conferences have become an increasingly common sight, appeared shaken as he described how the five-person crew had been overwhelmed as a fire burning to Sydney’s south-west changed from metre-high flames to a towering inferno in a matter of minutes. “I have had field reports from out there that very quickly they saw lots of fire activity, from metre-high flame heights to flames burning through the tops of trees [and] crowning fires, under very strong winds,” Fitzsimmons said. “It was very volatile, very dynamic and, unfortunately, emblematic of much of the fire behaviour we’ve seen, under the hot, dry, windy conditions.” It came amid a backdrop of growing anger at prime minister Scott Morrison’s handling of the bushfire emergency. Morrison has been criticised for his initial reluctance to link the worsening bushfire conditions with climate change, and more recently for his decision to take an overseas holiday in the midst of the crisis. In the tiny village of Itchenstoke in the state’s Blue Mountains the defence force was mobilised to rescue residents who became isolated when fire cut off the only road in and out of the town. Aerial footage from Bargo to the south-west of Sydney, where the three firefighters were overwhelmed, showed dozens of burning buildings and Fitzsimmons told reporters he feared dozens of properties had been lost to a separate fire burning to Sydney’s south-west. “We’ve got indications of quite a considerable amount of property being impacted,” he said. Fitzsimmons said he believed some of the homes lost belonged to firefighting volunteers. “They’re devastated by loss no matter what, but it just goes that little further when it’s your own home, or the colleague you’ve got sitting on the fire truck next to you, having lost their home, while they’re out saving others,” he said. “So it’s a tough afternoon. It will be another very emotional, very draining day for our firefighters.” As Sydney again woke to a now-familiar blanket of thick smoke on Thursday, hundreds of protesters gathered at the prime minister’s official residence, Kirribilli House, angry at his perceived lack of leadership. A NSW Greens MP, David Shoebridge, was arrested at the protest for refusing to obey a move on direction by police. But speaking after the protest the deputy prime minister, Michael McCormack, dismissed their concerns, telling protesters they were “wasting your time” and that the prime minister was “entitled to a holiday”. “Go and do something productive,” McCormack said to protesters. “Those people who are shouting and screaming … go and help someone out in need. Do a good turn rather than shouting and screaming and holding up placards that not always the words are spelt correctly on.” Before Thursday both Berejiklian and Fitzsimmons had warned that fire crews across the scorched state would again face an “enormous challenge” in the coming days during a fire season in which six people have already died and more than 750 properties have been destroyed. Australia’s all-time record average temperature has been broken twice already this week, with the more than 50 fires continuing to burn out of control across the state quickly fanned by temperatures exceeding 40C coupled with strong, gusting winds. Throughout Thursday four major fires stretching from the state’s south coast to the south-west of Sydney and the central coast reached “emergency” levels. One of those blazes, at Gospers Mountain on the state’s central coast, north of Sydney, has burned through more than 400,000 hectares already. And after a brief reprieve on Friday, conditions are expected to deteriorate further on Saturday. “The temperatures will be higher, and the wind turbulence more severe,” Berejiklian said. Fitzsimmons echoed that concern, saying strong winds from the west were expected for “10 to 15 hours”. “Saturday will be a very, very difficult day,” he said."
"If recent trends continue for another two years, the global share of electricity from renewables excluding hydropower will overtake nuclear for the first time. Even 20 years ago, this nuclear decline would have greatly surprised many people – particularly now that reducing carbon emissions is at the top of the political agenda.  On one level this is a story about changes in relative costs. The costs of solar and wind have plunged while nuclear has become almost astoundingly expensive. But this raises the question of why this came about. As I argue in my new book, Low Carbon Politics, it helps to dip into cultural theory.  The seminal text in this field, Risk and Culture (1982), by the British anthropologist Mary Douglas and American political scientist Aaron Wildavsky, argues the behaviour of individuals and institutions can be explained by four different biases:
  The first three categories help explain different actors in the electricity industry. For governments and centralised monopolies often owned by the state, read hierarchists. For green campaigning organisations, read egalitarians, while free-market-minded private companies fit the individualist bias.  The priorities of these groups have not greatly changed in recent years. Hierarchists tend to favour nuclear power, since big power stations make for more straightforward grid planning, and nuclear power complements nuclear weapons capabilities considered important for national security.  Egalitarians like Greenpeace and Friends of the Earth usually oppose new nuclear power plant and favour renewables. Traditionally they have worried about radioactive environmental damage and nuclear proliferation. Individualists, meanwhile, favour whichever technologies reduce costs.   These cultural realities lie behind the problems experienced by nuclear power. To compound green opposition, many of nuclear power’s strongest supporters are conservative hierarchists who are either sceptical about the need to reduce carbon emissions or treat it as a low priority. Hence they are often unable or unwilling to mobilise climate change arguments to support nuclear, which has made it harder to persuade egalitarians to get on board.  This has had several consequences. Green groups won subsidies for renewable technologies by persuading more liberal hierarchists that they had to address climate change – witness the big push by Greenpeace and Friends of the Earth for the feed-in tariffs that drove solar uptake in the late 2000s, for example. In turn, both wind and solar have been optimised and their costs have come down.  Nuclear largely missed out on these carbon-reducing subsidies. Worse, greens groups persuaded governments as far back as the 1970s that safety standards around nuclear power stations needed to improve. This more than anything drove up costs. As for the individualists, they used to be generally unconvinced by renewable energy and sceptical of environmental opposition to nuclear. But as relative costs have changed, they have increasingly switched positions.  The hierarchists are still able to use monopoly electricity organisations to support nuclear power, but individualists are increasingly pressuring them to make these markets more competitive so that they can invest in renewables more easily. In effect, we are now seeing an egalitarian-individualist alliance against the conservative hierarchists. Donald Trump’s administration in the US, for example, has sought subsidies to keep existing coal and nuclear power stations running. This is both out of concern for national security and to support traditional centralised industrial corporations – classic hierarchist thinking.  Yet this has played out badly with individualist corporations pushing renewables. Trump’s plans have even been rejected by some of his own appointments on the Federal Energy Regulatory Commission.  In similarly hierarchist fashion, electricity supply monopolies in Georgia and South Carolina started building new nuclear power stations after regulatory agencies allowed them to collect mandatory payments from electricity consumers to cover costs at the same time.  Yet even hierarchists cannot ignore economic reality entirely. The South Carolina project has been abandoned and the Georgia project only survives through a very large federal loan bailout.  Contrast this with casino complexes in Nevada like MGM Resorts not only installing their own solar photovoltaic arrays but paying many millions of dollars to opt out from the local monopoly electricity supplier. They have campaigned successfully to win a state referendum supporting electricity liberalisation.  The UK, meanwhile, is an example of how different biases can compete. Policy has traditionally been formed in hierarchical style, with big companies producing policy proposals which go out to wider consultation. It’s a cultural bias that favours nuclear power, but this conflicts with a key priority dating back to Thatcher that technological winners are chosen by the market.  This has led policymakers in Whitehall to favour both renewables and nuclear, but the private electricity companies have mostly refused to invest in nuclear, seeing it as too risky and expensive. The only companies prepared to plug the gap have been more hierarchists – EDF, which is majority-owned by France, and Chinese state nuclear corporations.  Even then, getting Hinkley C in south-west England underway – the first new nuclear plant since the 1990s – required an extensive commitment by the UK treasury to underwrite bank loans. There is also an embarrassingly high price to be paid for the electricity over a very long 35-year period. Such has been the bad publicity that it’s hard to imagine a politician agreeing to more plant on such terms.  Where does this reality leave hierarchists? Increasingly having to explain prohibitive nuclear costs to their electorates – at least in democracies. The alternative, as renewable energy becomes the new orthodoxy, is to embrace it.  In Australia, for example, a big utility company called AGL is trying to seduce homeowners to agree to link their solar panels to the company’s systems to centralise power dispatch in a so-called a “virtual power plant”.  When the facts change, to misquote John Maynard Keynes, you can always change your mind."
"Want to talk about the climate crisis with George Monbiot or discuss tumultuous recent political events with Polly Toynbee, Owen Jones or Marina Hyde? Or talk food and drink with Felicity Cloake, beauty with Sali Hughes, or movies with Peter Bradshaw? A team of Guardian and Observer journalists will be taking calls and donations at our annual charity telethon this Saturday. The cause is the climate emergency and we’re raising money for four charities that plant and protect trees, forests and woodlands.  The charities – Woodland Trust, Trees for Life, Trees for Cities and Global Greengrants Fund UK – promote environmental and social justice through natural climate solutions, from safeguarding the Amazon rainforest to rewilding parts of the Scottish Highlands to planting trees in Britain’s towns, cities and countryside. Readers have told us why they felt compelled to give this year: because the climate crisis is the most important issue affecting the planet, governments are failing to act and future generations must be safeguarded – and because they love trees. As one reader put it: “No trees. No future. No-brainer.” We’ve already raised more than £300,000, but we want to raise a lot more, and with your help, we can. You can call (+44) 0203-353 4368 between 10am and 6pm (GMT) on Saturday 21 December to make a donation by credit or debit card, and have a chat with our journalists. Others on hand to take calls include the Guardian’s editor-in-chief, Katharine Viner, political sketch writer John Crace, the columnists Gary Younge, Zoe Williams, Jonathan Freedland and Tim Dowling, and the daily podcast presenter, Anushka Asthana. If you don’t have time to call on Saturday, you can donate online here or send a cheque (payable to the Guardian and Observer charity appeal 2019) to: The Guardian and Observer charity appeal 2019, Charities Trust, Suite 20-22, Century Building, Tower Street, Liverpool, L3 4BJ."
"With reference to your report on the COP25 climate talks in Madrid (13 December), we have just returned from Madrid, where we displayed a large banner saying “War causes climate change and climate change causes war”. Thousands of passing delegates expressed a great interest in, and approval of, the message. Scientists for Global Responsibility estimates that 6% of global greenhouse gas emissions result from military-related activity – apart from the unfathomable human devastation – so at first sight it appears astonishing that the subject of war does not feature in the COP negotiations; nor are its emissions taken into account when reduction targets are set.  Perhaps this absence can be explained by the fact that military-related emissions have been excluded by some of the largest polluters from the global north whose delegates, as government officials, will naturally avoid jeopardising lucrative arms and military aid contracts, and whose people do not suffer the catastrophic wars and climatic devastation that directly affect the global south. Evidently we cannot rely on government negotiators to address the subject of war and militarism. We have to stop believing that war is inevitable and accept that international climate finance offers better value in both resolving conflict and sustaining the environment than the equivalent spent on military operations.Hilary Evans Movement for the Abolition of WarDavid Collins Veterans for Peace UK • I was delighted to see Greta Thunberg announced as Time magazine’s person of the year (Report, 12 December). For me, after so many years of campaigning on environmental issues, it has been a huge relief that now, in 2019, the future of the planet has finally entered the political mainstream – and not a moment too soon. This is thanks, in no small part, to the vision and actions of Greta herself, but also to those many others whom she has inspired to take up the fight. The world is realising the scale of the threat posed by every aspect of our destructive exploitation of our lovely planet. Now we need to see some real political leadership so that the leading nations of the world, our own included, can ensure a real revolution in practice, to match the fiery ambitions that have been lit up in our hearts by this inspirational Swedish teenager.Catherine RowettGreen party MEP, East of England • I’m writing in reference to your use of the term “global heating”. I understand the motivation is probably to draw attention to the fact that we are actively changing the climate, a laudable goal. However, the term should be used correctly. In an article about the disappointing results of the COP25 climate negotiations (Discord at climate talks branded a betrayal, 16 December) it was noted that: “Experts say more ambitious emissions cuts are needed globally if the Paris pledge to hold global heating to no more than 2C is to be met.” However, heating involves a change in energy and is measured in joules. Warming, on the other hand, is a change in temperature and is measured in degrees celsius. So “global warming” would have been more apt here. I know that climate change deniers, some of whom have some knowledge of physics, keep a lookout for inconsistencies like this. Better not to give them any extra ammunition. Keep up the good environmental reporting – I’m a fan.Prof Joe LaCasceUniversity of Oslo • This article was amended on 17 December 2019 to add David Collins as a co-signatory to Hilary Evans’ letter. His name had been omitted due to an editing error. • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"Cryptocurrencies like Bitcoin may fill news headlines, but attention has been shifting to the technology that underpins them: blockchains. Blockchains are virtual ledgers on which data can be permanently stored. They are a public record, so they are very transparent and accountable.  The Big Four accounting firms, IBM and JP Morgan have been driving uptake by investigating applications. Blockchains could transform everything from national government systems to payment apps for coffee chains to the fight against climate change.  They are also starting to make a difference to the world’s waste problem. As we shall see, this has exciting possibilities.  Despite significant progress, the weight equivalent of one SUV is still going to landfill every year for each of the circa 500m people in the EU. Waste litters our oceans, beaches and wider environment, making it one of the  pressing issues of our times – not least thanks to David Attenborough’s popular Blue Planet series for the BBC, whose last episode addressed waste directly.  It is becoming harder to just shift it elsewhere – witness China’s recent ban on importing plastic waste, for example. Most countries are far behind Sweden, which has such a well developed network of waste-to-energy plants that it imports waste to feed them.  So where do blockchains fit in? They are a sophisticated way of recording transactions without having one central institution like a bank controlling them. They comprise a series of blocks, each containing a set of transactions such as sales of assets or other transfers of value.  It’s almost impossible to tamper with the information these blocks contain, since each has a unique tag of numbers and letters known as a cryptographic hash, overlaid with other complicated security mechanisms. Blockchains are so reliable that the ability of governments and central banks to control currency in future is very much in question.  Various waste initiatives have seen potential to incorporate this technology. One is the Plastic Bank, a global recycling venture founded in Canada to reduce plastic waste in developing countries – so far Haiti, Peru, Colombia and the Philippines, with plans to extend this year.  The initiative rewards people who bring plastic rubbish to bank recycling centres, and one option is blockchain-secured digital tokens. These can purchase things like food or phone-charging units in any store using the Plastic Bank app.  The plastic is meanwhile bought by companies and recycled into new consumer products. The system attracts them because blockchain’s transparency means they can see where their investment goes.  A more novel use of blockchains is meanwhile emerging in French rail. Waste management in stations has traditionally been chaotic, with up to six providers sorting endless rubbish. The central station in Lyon, for example, produces 360 tonnes of waste each year.   A new system developed by SNCF subsidiary Arep uses blockchain to allow detailed information to be collected. There is a block for each station bin, which uses Bluetooth to continually update on quantities of each type of waste, which waste managers collected it and how it is being moved around.  Station managers can use this data to see what providers have done and when. This enables them to improve waste management and optimise sorting. In a pilot, this saved almost €2,000 (£1,746) in one month in one station by facilitating a new system for collecting five different streams of waste separately.  Blockchains are also being mooted to underpin a system for trading waste quotas similarly to how carbon quotas are traded under the EU Emissions Trading System. Using blockchains could help keep track of how much waste companies are producing, and could also help facilitate trading.  These are various ways in which this technology can help address our waste problem, but they all focus on existing waste. They don’t look at the full life cycle of products from when they are created to when they are thrown away.  For a proper life cycle approach to waste, we need to think about holding the companies responsible who made the products in the first place – as well as other companies in the supply chain, since they will potentially put pressure on the producers.  We need to introduce standards to underpin this shift in responsibility, along with costly penalties for those who infringe them. Some incentives exist already – the EU’s extended producer responsibility, for example – but countries don’t tend to implement them because of issues around tracking the waste and enforcing the rules. Again, blockchain technologies could have a role here. When goods are produced, responsibility for them could be assigned. This would be recorded as a transaction to be stored in a block on the blockchain, identifying the product and the responsible party. Every time the product was transferred – when it was sold, say, or when it was disposed of in landfill – this would be recorded in a new transaction. This could all be accessible via a QR code stamped on each product.  If the product then ended up as litter on a beach somewhere, the blockchain would provide a digital trail to identify who was responsible. It would be up to the government in question to determine where responsibility lay at any given time.  Setting up this kind of system raises many practical considerations, of course: set-up costs, running costs, how to monitor and enforce it. But none are necessarily insurmountable. There are parallels, for example, with the EU’s system of requiring energy labels for household appliances to help consumers choose energy efficient products.  When it comes to our worldwide problem with waste, it is time to think outside the box. Blockchains are already beginning to provide benefits in this area and they have much greater potential yet. If we can use them to build decentralised reliable networks for where rubbish has come from and where it ends up, it could lead to the breakthrough that has been eluding us for decades."
"Many of us depend on coffee to fuel our early morning meetings, mid-afternoon slumps or all-night study sessions. These days, the words “coffee” and “fuel” are half-jokingly synonymous. More than 9m tonnes of the bean are produced annually around the world and, once we brew it, an awful lot of waste is created. The vast majority ends up in landfill. Researchers in South Korea, however, have discovered a way of using waste coffee grounds as a fuel in a far more literal sense. In a study in Nanotechnology, they report using coffee waste to produce a carbon material full of small pores which increase the surface area, known as “activated” carbon. This new material is capable of absorbing and storing methane and hydrogen, both of which can be used as fuels.  While the ability to store these fuels from such a cheap material is a great step towards making this technology more viable, it also provides an environmental advantage: methane is a harmful greenhouse gas. This is by no means the only use for waste coffee grounds. As a relatively pure and essentially free waste stream, scientists, engineers and entrepreneurs have looked into various ways of putting it to use. For a few years now, Nestlé has been using waste coffee grounds from its instant soluble coffee production as thermal fuel. It currently uses coffee to cook the food it produces in more than 20 factories globally, displacing more than 800,000 tons of coffee grounds each year that would otherwise go to landfill. In a more specific enterprise, the London-based company Bio-bean is trying to turn waste from local instant coffee producers (nearly 200,000 tonnes in London and south-east England alone) into biomass pellets for power generation, as well as residential heating using trendy biomass burners. These beans burn more cleanly and contain 50% more energy than traditional wood pellets. However unlike Nestlé, Bio-bean first removes oil from the coffee, which brings us to our second point. Like most plant seeds, the coffee bean contains a significant amount of oil which can either be squeezed out or chemically extracted. It can then be converted into biodiesel, a liquid with similar properties to that of regular diesel.  My own research found coffee-derived biodiesel wasn’t affected by where the coffee was grown, the type of bean or how it was brewed. This is a great plus as it means the coffee-derived fuel will give off a predictable and consistent amount of energy when burnt. Coffee grounds can also be fermented to produce ethanol or subject to extreme heat and pressure in order to create bio-oil, a material similar to crude oil. Both processes, however, are expensive. Biodiesel is the only fuel that seems to be viable on a larger scale, hence Bio-beans’s endeavours to commercialise it. Coffee contains a number of chemicals that, when isolated and purified, can serve very specific uses. Examples include chlorogenic acid, a food additive that slightly lowers blood pressure; trigonelline, which helps prevent and treat diabetes and central nervous system diseases; polyhydroxyalkanoates, which are used to make bioplastics; and a wide range of antioxidants which can be used in healthcare or added to fuel and lubricants to lengthen their lifetimes. Coffee grounds are rich in nitrogen, a vital nutrient for plant growth. This is known by a number of coffee shops which will provide their used coffee to customers who request it. It reduces their waste, and might be tipped into organic, caffeine-infused fruit and veg. What barista could say no to that? Waste coffee is even effective at soaking up harmful “heavy metals” such as chromium, copper, nickel or lead which often leak out of chemical plants, farms or factories and cause significant damage. In specific lab conditions waste coffee has been reported to remove up to 91% of heavy metal ions from solution – a good example of potential environmental benefits.  Most complex of all, researchers have investigated using coffee to make supercapacitors – electrical stores capable of holding more power and more charge cycles than traditional batteries. Ultra-thin porous carbon nanosheets have been produced with good electrical properties.  Whether it’s used at home as garden compost, in lab for research or even in industrial fuel production, there are clearly lots of uses for waste coffee. This huge variety could potentially be a negative thing. After all, how do you decide what to do with something so versatile?  One thing is for sure, however. We certainly shouldn’t be throwing it away."
"
Share this...FacebookTwitterIt amazes me how activists and even highly educated scientists are clinging to the hope that global society is somehow still able to meet the junk-theoretical 2°C greenhouse gas emissions target.
And so I had to laugh when Zeke Hausfather at Twitter brought down two Potsdam, Germany, activist scientists from their fantasy world of radical CO2 reductions and back to brutal reality. Hausfather is right, we have to start getting real about things and how the world really works.
Time to wake up
Hausfather was reacting to a recent post by Stefan Rahmstorf and Anders Levermann over at Real Climate, where they seem to desperately hold on to the hope that the 2°C target can be reached – if we all sacrifice mightily. Unfortunately the only way that could happen is if governments declared a global state of emergency, called out the army and ordered everyone at gunpoint to cut massively CO2 emissions – to the absurd extent that would allow the theoretical 2°C target to be met. It almost feels like the two scientists would even accept that.
Yes, they say there’s a chance – if we reach peak emissions by 2020, and then if we all happily hop on our bicycles and eat a vegan diets thereafter.
Rahmstorf and Levermann write:
We will need an enormous amount of action and scaled up ambition to harness the current momentum in order to travel down the decarbonisation curve at the necessary pace; the window to do that is still open[x].”
Hasn’t anyone told Rahmstorf and Levermann that China and India aren’t going to change anything until 2030, at the absolute earliest (and that’s a big if)? Haven’t the two Potsdam scientists read the lax conditions in the Paris Accord?
Someone needs to sit the two scientists down and break the bad news to them: It’s already too late. The theoretical 2°C target is now pure fantasy. That point is long gone…assuming the CO2 theory is right to begin with.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Strongly doubt any of the scenarios are remotely feasible”
I’m not the only one who is sure that the alarmists made the tactical mistake of placing the 2°C target goal posts way too close, but so is warmist Zeke Hausfather.
Here’s his reaction to the two German alarmist authors over at Twitter:

I hate to be the bearer of bad news, but I strongly doubt that any of these scenarios are remotely feasible. https://t.co/PwXPWo2sNU 1/2 pic.twitter.com/YcQ8OmoSvi
— Zeke Hausfather (@hausfath) June 6, 2017

Looking at the chart above, if humanity had started cutting back say 25 years ago, it might have had a chance to reach that target. But as the chart shows, today it is only possible with ultra-drastic, state-of-emergency emissions cuts. Forget it – it’s not gonna ever happen.
I couldn’t resist, and so I left my comment (before it was taken down) in response to Zeke:

 
Share this...FacebookTwitter "
"The Melbourne Boxing Day Test may have to be played at night or moved away from Christmas to November or March as the number of extreme heat days rises over coming decades, a new report says. The analysis by the Monash Climate Change Communication Research Hub says the climate crisis is already disrupting Australian cricket, citing the cancellation of club matches on hot days and the abandonment of a Big Bash game in Canberra after bushfire smoke reduced air quality and visibility.  The report, commissioned by the Australian Conservation Foundation, says the impact is expected to grow along with the number of days of extreme heat in Melbourne through the 2020s and beyond. Paul Sinclair, the ACF’s campaigns director, said climate change loomed over this cricket season. There were calls for the starting time of the Perth Test match between Australia and New Zealand to be delayed due to a run of 40C-plus days and New South Wales and Queensland players were blanketed in smoke in a Sheffield Shield match at the Sydney Cricket Ground that prompted former Test player Steve O’Keefe to say Cricket Australia should intervene in future. New Zealand’s preparation for the second Test starting in Melbourne on Boxing Day was curtailed when the first day of a scratch match against a Victorian XI was cancelled last Friday as the temperature reached 43.5C. The report says continuing to play the Boxing Day Test in its current format will expose players and fans to unprecedented levels of extreme heat and, if effective action to limit climate change is not taken, consideration should be given to moving the Test to the shoulder season. “Moving the event isn’t the only option, but alternatives come with their own risks,” the report says. “Because radiant heat is a significant factor in heat stress, night Tests could lower the heat stress risk to players and others, but there may be logistical, cultural or safety challenges involved in this.” Asked for its response to the suggestion the Boxing Day Test might be rescheduled, Cricket Australia said cricket was played in different climates and countries around the world and it was committed to both addressing the impact of climate change and ensuring cricket continued to be played in Australia on December 26 for many years to come. Sinclair said cricket depended on the weather in a way few other sports did as changes in temperature and rainfall affect pitch condition and ball movement. He called on cricket authorities to “champion the national and international action needed to combat the root causes of climate change”. “Cricketers from grassroots clubs across the country to those in the national squad need Cricket Australia to speak up for climate solutions that match the scale of the problem facing the game we love,” Sinclair said. The report suggests the conversation about cricket and heat is starting to change, giving the example of the hospitalisation of England captain Joe Root with dehydration and viral gastroenteritis in January 2018 as temperatures hit 42C. It prompted former Australian cricketer Dean Jones to say extreme heat was a workplace issue, and games should be called off on days that reached 41C. After speaking to a couple of doctors this morning.. in my opinion cricket should be called off after 41C.. it’s a workplace issue now.. just my opinion .. It says extreme heat is a major health hazard for cricketers as it disrupts the body’s thermoregulation. Heat stress can initially cause muscle cramps, profuse sweat, thirst and fatigue. As players move towards heat stroke, people could feel chills and have nervous system problems that impair coordination and decision making. The report applauds Cricket Australia for last year publishing the cricket world’s first heat stress management policy, but says the organisation declined to say how often it had been used or whether it supported Australia moving to net zero greenhouse gas emissions or 100% renewable energy. A Cricket Australia spokesman said it had been closely monitoring temperatures, air quality and visibility this summer and found it had “certainly brought about new challenges”. It said the executive team was in the early stages of developing a “strategy for sustainability”, and the organisation was conducting and had published research into best practice in dealing with a changing climate. “Armed with this evidence, CA will continue to lobby the International Cricket Council to adopt these approaches for international tournaments,” it said. “Players’ and officials’ health at all levels of cricket is the absolute priority of Cricket Australia.” At a community level, it said it had recommended matches be postponed or cancelled if temperatures reached a maximum designated by local authorities. The report mentions in passing the bushfires that have recently smothered Sydney and other centres in smoke up to 11 times the hazardous level. Men’s and women’s Sydney grade matches have been called off in recent weeks, with paramedics called to at least one game. Cricket Australia has said it is preparing for smoke to affect play during the Test match starting at the SCG on 3 January. Its head of operations, Peter Roach, said International Cricket Council regulations allowed officials to stop play due to smoke as they would due to rain. Scientists say the scale and impact of the fires is unprecedented, and that the climate crisis is exacerbating the risk and lengthening the bushfire season. More than 5m hectares has burned across the country. At a grassroots level, the report gives the example of Red Cliffs Cricket Association in Mildura, north-west Victoria, where the average daytime January temperature has increased 2.7C over the past 40 years. On average, 5.5 more January days are hotter than 38C than in 1980. Peter Kelly, the Red Cliffs Association secretary, said over the past four years there have been about four days when cricket has been called off due to heat. “We now play shorter games in January and have taken one of the Saturdays out because of the hot temperatures we’ve had for the past few years. It’s getting that consistent,” he said. Australia last week recorded its three hottest days, averaged across the continent, on record. Scientists said the strongest Indian Ocean dipole event on record, atmospheric warming above Antarctica and average global heating of more than 1C due to increased atmospheric greenhouse gas all contributed. Temperatures in Melbourne this Boxing Day Test are forecast to range from 20.5C recorded on the first day to 41C on Monday, should it last that long."
"A Russian climate youth activist has been sentenced to six days in prison for taking part in a demonstration in Moscow. Supporters said the punishment of Arshak Makichyan was disproportionately severe, and was one of the harshest crackdowns on student campaigners anywhere in the world.  Makichyan, a 25-year-old violinist, was inspired by Greta Thunberg to join the Fridays for Future movement, which urges governments to listen to scientists and meet the commitments they made in the Paris agreement. He had recently returned from international climate talks in Madrid but was summoned by the Russian authorities on Friday to face charges that he participated in a protest without permission. Earlier, he tweeted thanks to his lawyer and supporters. “We are waiting for the judge’s decision,” he wrote, then later updated with the verdict: “Six days of arrest.” Climate activists from dozens of other countries expressed solidarity on social networks. “Hang in there. You are doing the right thing,” said the Fridays4Future Twitter account, which described the activist as an inspiration. You are an inspiration to many activists out there Arshak. Hang in there. You are doing the right thing ✊🏽💚/FFF Twitter team Makichyan had been staging a solo school strike in Pushkin Square, Moscow, for more than 40 weeks. Under Russia’s tight restrictions on gatherings, individual protests are lawful but anything bigger requires police permission. Shortly before September’s global strike, Makichyan told the Guardian the lengths he and fellow Russian campaigners went to try to avoid problems with the authorities. “In Moscow it is almost impossible to get permission for a mass demonstration so we protest in a queue. One person holds a poster for five minutes, then hands over to the next person who is waiting nearby. That way, we don’t have any problems because it is a series of solo strikes rather than a group gathering,” said the graduate of the Moscow Conservatory. He had applied unsuccessfully more than 10 times for approval for a bigger protest in the hope of building momentum for the climate movement in Russia, a major gas-producing nation that has one of the world’s worst records in tackling emissions."
"In 2018, about 1,400 hectares of trees were planted in England, against a government target of 5,000 hectares. Less than £1 per person per year is spent on planting English trees, and less than £2 across the UK, according to estimates by Friends of the Earth, compared with £90 per person per year on roads and £150 on fossil fuel subsidies. Scotland has succeeded in planting more trees, but the UK is still one of the least wooded countries in Europe, with only 13% tree cover, compared with about 32% in Germany and 31% of France. Those trees are also unevenly distributed: tree cover is about 10% in England, 15% in Wales, 19% in Scotland, and only 8% in Northern Ireland. The reasons for the lack of woodland across the UK stretch back centuries, from the timber needed for ships to bolster the empire’s navy and the industrial revolution, to the first world war, when the countryside was so denuded that the government set up the Forestry Commission in 1919 to reforest emptied land and provide a national resource to meet future needs.  More recent impediments to forest-growing have included the complicated nature of agri-environment subsidies and for decades a farming policy focused on intensifying food production over environmental gains. Farmers and landowners have had little incentive to take a punt on slow-growing forests, which carry substantial upfront costs but no financial return for decades, while cash-strapped local authorities have had other spending priorities. The Committee on Climate Change, the government’s statutory adviser, has suggested that to meet the target of net zero carbon by 2050, we need to plant at least 30,000 hectares of new trees every year. The Woodland Trust sees new woodland planting as one of the three main aims for forestry in the UK: protection of existing sites; restoration of degraded woodland; and creation of new forests. The trust is one of four charities supported by the 2019 Guardian and Observer climate emergency appeal. Just growing more trees is not that simple, however. The UK’s recent history holds many examples of hapless forestry schemes gone awry. The Forestry Commission was responsible for some of them, with plantations in its early years that failed to provide a strategic reserve of the sort of timber needed. More recently, in the 1980s, peatlands, bogs and moorlands were planted with conifer, with environmentally damaging results, because planting trees on peatland dries out the soil, whereas peat in its natural state can act as a powerful carbon sink. The regimented monocultural conifer plantations can still be seen in Scotland, Wales and Northern Ireland. If the UK is to meet its targets without further collateral damage to native peatlands, wildlife and scenery, past mistakes must be avoided. “It’s about the right tree in the right place,” says Darren Moorcroft, chief executive of the Woodland Trust. “Trees can provide carbon capture, but also clean water, fresher air and flood alleviation, if they are planted with care.” Native broadleaf woodlands are often more suitable than the timber-producing conifer forests, and varying the species planted means they are less vulnerable to disease than monocultures. Planting a new woodland from scratch costs roughly £6,000 a hectare, or £3.80 per tree, according to the Woodland Trust, but there are many variables. The land that is planted may have previously been farmland, or other land up for sale from private hands, or in public ownership. The Queen Elizabeth Diamond Jubilee Wood, for instance, was formerly a UK Coal site bought by the charity. Heartwood Forest in Hertfordshire, with 600,000 trees that were all planted by volunteers, was formerly farmland that was up for sale. According to the Woodland Trust, “local people were worried it was going to be houses, so were delighted when we consulted on our plans”. The wood is now well used as a local amenity. The Woodland Trust, which has planted more than 43m trees since 1972 with more than 15 million people involved, works closely with local communities, consulting on large-scale projects to convert land to woods, and sometimes through community groups that have contacted the charity. “It’s rare that people aren’t happy to see a woodland being created for them,” says a spokesman. The charity decides what sort of woodland and its design through working with local people.  “We find that by engaging with local communities to create and plant the site, there is much more buy-in and support for the new woods, as they feel like it’s theirs.” Rob Draper, manager of the Grange Farm Centre, a 90-acre community facility in Chigwell, Essex, has applied successfully for free community tree packs from the Woodland Trust for more than a decade, and has built up a woodland next to a local housing estate that now plays home to barn owls, great crested newts, beehives and a wide variety of small mammals and birds. Blackthorn, elder, rowan and hazel have all begun to bear fruit, and hornbeam, hawthorn, crab apple and dogwood have been planted as hedging. “People probably don’t realise that they can get free trees from the Woodland Trust, but we would encourage people to apply. At first we were nervous about completing the forms, as we weren’t sure we would be successful, but since then we’ve applied most seasons successfully,” says Draper. “[Local people volunteering gained] a sense of purpose and structure in terms of seeing how project develops. And they had the opportunity to learn about the benefits of spending time outdoors, in a green space, and the improved health and wellbeing that results.”"
"
Share this...FacebookTwitterThere’s no doubt about it, most people today are highly confused and misinformed when it comes to proper nutrition. And when you look at the vast array of kooky food and diet fads out there, it’s clear very few people in fact understand what is really healthy. The obesity rates and chronic disease statistics tell the sad story.
Planet saving vegan diet
One of the main factors motivating some people to switch to a leafy-greenie vegan diet is to reduce the impact on a planet that is supposedly totally stressed out in part by meat-producing agriculture. That kind of environmental and food zealotry embodied by the vegan movement poses a considerable health risk to the vegans who do not practice it correctly — especially children and pregnant women. The risk of nutrient deficiency is way too high and so it’s little wonder that most doctors recommend avoiding the vegan diet altogether.
Vertical planet-saving farming indoors
The latest planet-saving trend that’s been taking off is urban, vertical farming using so-called hydroponic methods where soil and real sunlight are not even used. It’s done indoors, often in large, shut-down industrial buildings.
In the following video, Aerofarms claims (as do most vertical farms) a great number of advantages with its technology, such as the non-use of pesticides and herbicides, a highly monitored and controlled round-the-clock growing process, 95% water-use reduction, clean produce, and short farm-to-dinner table times.
More importantly, it boasts having a much smaller impact on the planet and climate, and many vertical farms are even backed by big investors, like Goldman Sachs.

Naturally, all these wonderful selling points will likely send planet-protection-obsessed vegans flocking in droves to this new source of leafy greens and produce.
But stepping back for a moment and taking a closer look, we see that these vertical farms are in fact far from being natural. They are industrial, technical mass food production that have very little to do with nature. They do not use soil, are automated, use artificial light, and there’s no exposure to weather elements. The real target is to produce as much plant mass as possible, and as quickly as possible. Nutrient density is a side issue.
Recycled plastic cloth instead of natural soil
At Aerofarms, located in an industrial area of Newark, New Jersey, the crop roots are put in “a reusable cloth made of recycled plastic”. Under the microfleece membrane, the bare roots are enveloped by “nutrient-rich mist”, another promotion video explains. In hydroponic farming, crop roots supposedly get constantly exposed to a “nutrient-rich” solution instead of regular fertile, worm-filled black earth that we typically associate with healthy crops.
Low nutrient density
Although these vertical farms are highly productive in terms of plant mass (which happens to be how food is sold, and not according to nutrient content), the question is just how nutrient-dense are these planet-saving industrially grown crops? Buying mass at a market is one thing, buying nutrients is quite another. After all, what good is a pound of kale if it was produced by doping the plant so that it makes lots of empty cellulose?
The human body needs in total dozens of essential minerals, trace elements, vitamins, fatty acids and amino acids to remain in good health. The source of many of these nutrients is fertile soil from Mother Nature. The question is: Can vertical, soil-less farms grow crops that are just as good as those grown outdoors with their roots in real earth in a real garden? Can a laboratory produce a hydroponic solution replace real soil?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Vegans may be putting themselves at higher risk
A number of experts are high skeptical, and warn that these artificially grown crops may be highly deficient in a vast number of essential nutrients.
For vegans, who are already practicing a diet that borders on malnutrition, opting for the vertically-farmed crop variety could pose serious and real health risks.
Criticism of vertical farms is not new. For example the healthy home economist here thinks hydroponically grown foods are in fact low-nutrient foods and should not be relied on.
Environmental awareness site treehugger here thinks “it’s wrong on so many levels”.
Even the greenie Guardian here wonders if it really makes any sense at all.
So what risks happening to the already half-starved, climate-panicked vegans who may be rushing to this new utopian source of leafy greens? There’s a high risk that they will only end up exacerbating their already nutrient-deficient situation and wind up making themselves ill quickly. Another case of good intentions possibly leading to a disaster.
No comment from vertical grower
I sent an e-mail (twice!) asking Bowery if they had their produce analyzed for nutrient content, and if so, if it would be possible to get the results so that a comparison to the regular stuff could be made. Up to now I have not gotten a reply of any type. I’m also skeptical.
Vegans would be well-advised to find out what nutrients are really in the produce that comes from vertical farms.
Clean obsessions
There’s another risk possibly associated with what also appears to be a growing obsession with food cleanliness and purity. We may indeed be doing the human species more harm than good over the long run, as the human immune system and our natural detoxification and cleansing systems may wind up getting lazy and slow over the long term. Our bodies are equipped to handle impurities. There’s a reason we have kidneys, a liver, etc. The risk is: If you don’t use it, you’ll lose it.
===============================
UPDATE:
Bowery just responded by email:
At Bowery, our nutrients are water soluble versions of the same ones you would find naturally occurring in the most fertile of soil environments, and this nutrient-rich water is taken up directly by the roots of our plants. By monitoring the growing process 24/7 and capturing data at each step, we give our crops exactly what they need and nothing more to grow the purest produce imaginable, while using absolutely zero pesticides, herbicides, or fungicides. We do also regularly test for nutrient composition to ensure plant health and quality, though we don’t publicly release this data.”
Share this...FacebookTwitter "
"The UK’s Climate Change Act is a pioneering and far-sighted piece of legislation, ushered in ten years ago by a remarkable cross-party consensus in parliament and clear support across the nation. As we celebrate its tenth anniversary, it is time to ask, though, whether the central ambition of the Act – reducing carbon emissions by at least 80% from 1990 levels by 2050 – is still adequate in light of changing circumstances, or whether it needs strengthening. Climate scientists are clear that global carbon emissions will have to fall to net zero at some point if the rise in average temperature is to be halted. This is because as long as the concentration of carbon dioxide in the atmosphere continues to increase, the temperature is likely to keep on rising. (“Net zero” means that although there may be a small amount of carbon dioxide being emitted each year to the atmosphere, an equivalent amount will be absorbed and stored.) The UK government, along with all others, acknowledged this reality by signing up first to the Intergovernmental Panel on Climate Change (IPCC) report in 2014, and then the Paris Agreement in December 2015. The IPCC said that meeting the 2℃ target then in place “…would require that global net emissions of CO₂ eventually decrease to zero”. In the Paris Agreement governments committed “…to achieve a balance between anthropogenic emissions by sources and removals by sinks of greenhouse gases in the second half of this century”. In 2016, the UK’s then energy minister, Andrea Leadsom, told parliament: “The government believes that we will need to take the step of enshrining the Paris goal for net zero emissions in UK law.” Having agreed that a net zero target is necessary, the next question is “when?” In the Paris Agreement, governments pledged not only to hold global warming to “well below 2°C above pre-industrial levels”, but also to attempt to “limit the temperature increase to 1.5°C … recognising that this would significantly reduce the risks and impacts of climate change.” The government’s statutory advisor, the Committee on Climate Change (the CCC, on which one of us used to sit), advises that in order to stand an evens chance of meeting the 1.5°C aspiration, global emissions of CO₂ need to fall to net zero by the 2040s. The IPCC is producing a special report this year on the case for limiting warming to 1.5°C and pathways for doing so, and is likely to say the same thing. One of the principles of the UN climate convention is that prosperous nations lead the way. Britain agreed to this back in 1992 and has reaffirmed it many times since. If the science is clear that the global target should be “net zero by 2050”, there is no case for the UK setting a later date – and there is a case for making it earlier. Nevertheless, adopting a national net zero target is not a trivial matter. Carbon emissions in most sectors of the economy would have to fall to zero. This is largely achievable with current technology, but in sectors such as agriculture and aviation it will be challenging. It will also be necessary to put in place mechanisms to take carbon dioxide from the atmosphere, to make up for the small amount of emissions that will inevitably remain. There are opportunities as well as challenges. For example, many measures that store carbon in nature, such as restoring peat bogs or planting forests, bring other benefits in terms of landscape, recreation and wildlife. Sweden, Norway, Iceland, and France have either adopted a net zero target or are considering doing so. The longer the UK delays, the more its claim to be a global leader on climate change is compromised. British leadership has led other countries to introduce legislation modelled on its Climate Change Act, and a decision to set a net-zero target is also likely to stimulate others to do the same. The UK can justifiably be proud of the Climate Change Act. But it’s time to be more ambitious."
"There’s a buzz in the air at the moment, and it’s all about “entomophagy”. If you’ve not heard this word before, it simply means the human practice of eating insects. Western governments are keen as it has huge potential for feeding growing numbers of people (and the livestock they eat) sustainably, while on the street people are daring to try novel and exotic foods. Despite the exotic label, entomophagy is nothing new. Two billion people eat insects every day, just not in the West. In fact, insects are extremely good for you and eating them is good for the planet too. That’s why Andy Holcroft and I are starting up Grub Kitchen, the UK’s first restaurant with insects on the menu full-time.  We want to champion insects as a sustainable source of protein in modern diets and have been planning the collaboration for some years. I’m a scientist and farmer, researching sustainable food production and the importance of insects in agriculture. In 2013, I set up Dr Beynon’s Bug Farm, a research and education centre and 100-acre working farm, combined with a visitor attraction all about insects and sustainable agriculture. Andy is an award-winning chef, who has become more and more disillusioned with the unsustainability of conventional restaurants. Working together gives us the opportunity to explore the food chain from field to fork. But why try changing people’s eating habits? By 2050 humans will require 70% more food, 120% more water and 42% more crop land. Meat production is predicted to double and, to meet current environmental targets, impacts of livestock on the environment will need to halve. Conventional livestock production is land and water thirsty: farmed animals graze 30% of the earth’s land and consume 8% of all water usage mediated by humans. This comes at a drastic cost to our environment and is why we need additional, or alternative, protein sources with lower environmental costs. Bring on the insects. A recent Food and Agriculture Organisation report suggested that there are more than 1,000 known species of edible insect, offering an Aladdin’s Cave of flavours and textures. Insects breed quickly and require very little space, or water. This makes farming them extremely efficient. For example, it takes about 3,290 litres of water to produce a 150g beef burger: the equivalent insect burger requires less than a pint. Insects are also extremely nutritious. They contain lots of calcium, zinc, and omega-3 fatty acids and are low in cholesterol. They’re also packed full of protein. Weight for weight, crickets can contain more protein than beef and are 12 to 25 times more efficient in converting their feed into food for us. Some insects such as black flies can even convert our own waste into food, or at least into feed for farmed animals. Indeed, feeding insects to livestock may be a first step to incorporating them into the UK food chain. Using insects to feed chickens, pigs and fish is one thing, but convincing the British public to try them will be more challenging. At Grub Kitchen, we want to move away from the idea of eating insects as novelty items, or as a dare, as popularised by certain television programmes. Diners will be able to eat insects in all forms, from an insect taster plate to our signature bug burgers or cricket cookies. There will be whole insects on the menu, but many people will be put off by the various legs, antennae and eyes so we will offer options where insects are incorporated into dishes: ground up and used as flour or burger mince.  Though the industry is growing there are still several barriers to mass production. Currently the UK allows you to farm insects for human consumption. However, insects are categorised as “farmed animals”, which means we can’t slaughter them where they are reared. Parts of insects, such as legs or wings, are considered novel foods and so undergo stringent safety testing but we can use whole insects in food so long as we carry out “due diligence”. We’re also banned from feeding insects to livestock entering the human food chain.  It’s clear we still have a lot to learn. We’re still not sure whether humans have the correct gut microflora to make the most of insect protein, for instance, and we need to find out more about potential allergies. For now, if you’re allergic to house dust mites or shellfish then it’s best to avoid eating insects – but this isn’t yet based on much research. In the UK, we’re awaiting a decision as to whether the Food Standards Agency counts insects as “novel food”; a decision which will impact the entire industry. If the agency agrees that there is enough evidence that insects were eaten before 1997 then the food will be subject to fewer regulations. So, brace yourselves, you may be seeing insects on the supermarket shelves before long and you’re welcome to come and dine at Grub Kitchen later in the year. However, even if you don’t think that you want to veer into the world of entomophagy, I’m afraid I’ve got news for you: you already are. You may be eating up to 60 fragments of insects in every 100g of chocolate and whenever you eat a fig, you are eating remnants of a fig wasp."
"
Share this...FacebookTwitterVery sad news. One of Europe’s most vocal critics of the climate alarmism movement, lecturer and chemist Prof. Istvan Marko, recently passed away on July 31, 2017.
Not only was Prof. Markó a distinguished scientist and researcher, but also a noted critic of authoritarian governments, climate alarmism and a fighter for human liberty.
Born in Hungary in 1956, his parents fled communist oppression soon after his birth.

Prof. Istvan Markó , Professor of Organic Chemistry, Université Catholique de Louvain; 1956 – 2017. Photo: Facebook.
Markó was often a frequent guest on French-language television and radio on topics concerning climate policy and was featured at NoTricksZone.com on several occasions, for example here, here and here. His death was unexpected, a shock, and deeply saddening. He was also featured at Climate Depot.
The Université Catholique de Louvain professor and researcher died prematurely of complications from surgery on July 31. He was only 61 years old.
Last year he was among the signatories to an open letter disputing alarmist claims publicly made by 377 members of the National Academy of Sciences to draw attention to the “serious risks of climate change”. More here.
IPCC theories “sordid”, “failed”
Prof. Markó was an especially outspoken and harsh critic of alarmist climate science and the IPCC. In March 2016 he responded to an article posted by NTZ guest author and weekly contributor Kenneth Richard, writing that observations made by many scientists once again “contradict the sordid theories of the IPCC” and that atmospheric CO2 concentrations “absolutely do not correlate with the fluctuations of the levels of the oceans and the movements of advances and withdrawals of glaciers“.
He wrote that the IPCC science had “failed again”.
He also blasted the COP21 Paris Climate Accord (which President Donald Trump has since thankfully rejected). Markó called the COP21 agreement “a resounding failure” and “grand illusions” based on “delirium“.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“Wishful thinking” by rich countries
In an English-language interview he blasted COP 21, claiming that it essentially resulted in nothing. He commented:
The result of COP 21 is no result …because there is nothing binding in this particular treaty.”
Markó added the only thing that motivates CO2 reductions is the lack of shame by officials:
To my knowledge no politician knows what shame is at all. They are totally not subject to shame.”
In an interview with the Belgian online Le Peuple here in December, 2015, Markó called the COP21 agreement an “obvious failure” because nothing was binding and that it was merely rich countries engaging in “wishful thinking“.
On the 2°C target, Markó said it had “strictly no physical or scientific basis”, was “nothing serious“ and was a randomly picked number by Hans-Joachim Schellnhuber, Director of the Potsdam Institute for Climate Impact Research, which Markó called “the green lobby in Germany” and “a voice of the Church of climate alarmism”.
“A prince among men”
Fellow Belgian skeptics wrote in an e-mail to NTZ that Prof. Markó was “a great man” and one of the “leading spirits” among the skeptic side of the debate. “István was a prince among man, a true scientist.”
A true inspiration
Europe and the world has lost an important foot soldier in the fight for scientific integrity and human freedom, and he will continue to inspire us to never relent. According to sources, Istvan Markó’s body will be cremated today.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe sun in March 2017
By Frank Bosse and Prof. Fritz Vahrenholt
(Translated/edited by P. Gosselin)
Our source of energy continued to be especially quiet last month. The mean sunspot number (SSN) was 17.7 and the sun was completely blank for 16 days.
It is important to recall once again that the SSN is not simply the sum of the observed sunspots, rather it is generated by the number of spots multiplied by the 10-fold of the observed sunspot regions. When one single spot is observed in an active region, this yields an SSN of 11.
The mean SSN for all cycles recorded so far, up to month 100 into the cycle, is 48.6, which means that the current cycle has seen a solar activity that is only 36% of the mean. It’s a weak cycle.

Fig. 1: The current solar cycle (SC) 24 is shown in red and is compared to the mean of the previous 23 cycles (blue) and the similar SC 5 (black).
What follows is a comparison of all cycles observed thus far:

Fig. 2: The accumulated sunspot anomaly between each cycle and the mean (depicted in blue in Figure 1). 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




As the chart above shows, the current cycle is the 3rd quietest overall since observations began in the 17th century. Overall only SC 5 and 6 (Dalton-Minimum) were quieter (so far). What is especially remarkable is that the 75 – 100 month period of the current cycle is the quietest of the such ever.
A real drop off in activity
Compared to the 1930 – 2000 period, the current cycle in fact represents a real drop off in activity. If we smooth the curve over 4 cycles, this is what activity looks like since systematic sunspot observations began:

Fig. 3: 44-year smoothed sunspot curve using Loess filter 44 SIDC (orange) and the mean value since 1700 (brown). In amplitude and time period, the 1930-2000 years were the most active of the past 300 years. The current drop-off has a strong similarity to that seen during the Dalton period. 
We are of course keeping an eye on the solar polar fields. At this point into the cycle, its strength is an indicator of the activity may be in the upcoming SC 25. Since December not much has changed, and so we will continue to stick to our prognoses from last month: The coming cycle will be approximately 1/3 weaker than the current SC 24.
The next few billion years
Over large timescales, the sun’s thermonuclear furnace strengthens at its core as the sun ages. The “solar constant” is currently ca. 1362 W/m², but is in fact not constant because it is increasing. There are a number of publications about this, and one recent study has come to the following result: Over the next 1.3 billion or so years, it is gradually going to get warmer as the sun will gain about 12% more strength compared to today. For the climate system that will result in about 41 W/m² in effective greater forcing (compared that to about 3.8 W/m² for a doubling of CO2, according to scientific literature). This will lead to a new modus for the earth’s climate, as temperatures will rise about 20°C. Naturally this is nothing to worry about, as by then we’ll be long gone.
That of course will not mean the end of life on earth as water will continue to exist and the earth will stabilize at its new plateau. And as the sun gains another 10% in strength, water will rapidly be lost into space. That will be the case in about 2.1 billion years. Later after that life as we know it will cease to exist on earth. And another 4 billion years later the sun will engulf the parched earth as it expands into a red giant.
But as far as we are concerned today, there is no need for pessimism! And don’t forget: there will continue to be an ice age every 100,000 or so years – just as this has been the case over the recent geological past (2 million years). And even if man should succeed in doubling the atmospheric CO2 concentration, the earth will not turn into Venus. For that an additional forcing of 72W/m² would be necessary.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
Climate Model Errors = 20 W m-2
CO2 Climate Forcing = 0.2 W m-2



Scott Pruitt, the new head of the U.S. Environmental Protection Agency, has recently been characterized as a climate science “denialist” by world news organizations.   A UK Guardian headline, for example, has claimed that “EPA head Scott Pruitt denies that carbon dioxide causes global warming“.  
The “denialist” characterization stems from an interview with CNBC’s Joe Kernen in which Pruitt was asked whether he believes that CO2 has been proven to be the climate’s “control knob”.  Pruitt replied that “we don’t know that yet” and that “there’s tremendous disagreement about the degree of impact.”  But he also said, no, he doesn’t think CO2 is a primary contributor to climate change.  Apparently that is all it takes to unleash the climate “denialist” name-calling.
Scott Pruit:   “No. I think that measuring with precision human activity on the climate is something very challenging to do, and there’s tremendous disagreement about the degree of impact.  So no, I would not agree that it’s a primary contributor to the global warming that we see. But we don’t know that yet. … We need to continue the debate and continue the review and the analysis.”
In a Washington Post analysis of Pruitt’s comments entitled “EPA Chief’s Climate Change Denial Easily Refuted…”, the host’s reply to Pruitt’s last statement about the need to continue debating the degree of human impact was included:
“That’s the whole point of science. You keep asking questions.”
Responding to this rather fundamental point, Washington Post political journalist Philip Bump seemingly agreed with the need to keep questioning and debating the science (since that is indeed the “whole point of science”).  But then he immediately contradicted himself.
“Well, sure. But the point of science is also to accept the answers to those questions once determined. And in the scientific community, the answer to the question of the link between greenhouse gases and warming has been determined.”
So apparently because it “has been determined” that CO2 causes warming or cooling when increased or decreased, therefore we should not question the degree to which the climate models accurately record the effect of increasing or decreasing CO2, or how much warming or cooling is caused by CO2 fluctuations relative to other climate-forcing factors.
And why should we refrain from asking questions about the relative influence of CO2 forcing on the climate?  Because those questions have not been determined…or answered.  Not even close.  After all, the uncertainty and error margins associated with modeling the radiative energy changes in the Earth system are 10 to 100 times  greater than the entirety of the forcing attributed to CO2 changes.

1. CO2 Radiative Forcing Effect Just 0.2 W m-2 For 2000-2010

As the Intergovernmental Panel on Climate Change (IPCC) has indicated, “global climate is determined by the radiation balance of the planet.”  If the balance in the radiative energy budget (incoming vs. outgoing energy) tips positive (as expressed in Watts per square meter, or W m-2), warming occurs.  If it dips negative, cooling occurs.  The IPCC presumes that positive energy balances have been ongoing for decades, driven almost exclusively by the increase in anthropogenic CO2 emissions.
According to climate models, the total climate forcing effect of the roughly 120 parts per million (ppm) increase in atmospheric CO2 during the ~165 years since 1750 is 1.8 W m-2.
As assessed in a 2015 paper published in the journal Nature, the CO2 concentration increased by 22 ppm during the first 10 years of the 21st century.  The radiative forcing (warming) effect of this 22 ppm CO2 increase was modeled to be 0.2 W m-2.  So of the 1.8 W m-2 of total radiative forcing since 1750, 0.2 W m-2 was added during the first decade of this century.

Feldman et al., 2015 

2. The Radiative Energy Imbalance For 2000-’10 Was 0.6 W m-2

In a 2012 Nature Geoscience paper entitled “An update on Earth’s energy balance in light of the latest global observations” by Stephens et al. (2012), the radiative energy imbalance for the 2000-2010 decade was determined to be positive, as expected.  Interestingly, though, the positive energy balance of 0.6 W m-2 was 3 times larger than the forcing value (0.2 W m-2) attributed to the CO2 increase during the same period.

Stephens et al., 2012
“The current revised depiction of the global annual mean energy balance for the decade 2000–2010 is provided … For the decade considered [2000-2010], the average imbalance is 0.6 Wm–2 when these TOA fluxes are constrained to the best estimate ocean heat content (OHC) observations since 2005.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






3. 67% (0.4 W m-2) Of The 2000-’10 Energy Increase Not From CO2

If the imbalance in the energy budget was 0.6 W m-2 during 2000-2010, and the modeled CO2 radiative forcing estimate was 0.2 W m-2 during the same period, that means that there was a positive forcing of 0.4 W m-2 that was not due to the increase in CO2 concentration.  What this indicates is that the IPCC’s conclusion that all or nearly all of recent global warming is due to the increase in anthropogenic CO2 emissions is not supported by the surface energy imbalance estimates.  Two-thirds of climate forcing must be due to some unknown mechanism or mechanisms that the IPCC has somehow failed to identify in etiological analyses.  And if only 33% of recent climate forcing is anthropogenic, and 67% cannot be accounted for, where does the certainty that humans are driving climate change come from?

4. Energy Change Uncertainty 10-100 Times Larger Than CO2 Forcing

Speaking of certainty — or, more appropriately, uncertainty — in climate forcing or energy imbalance values, Stephens and colleagues emphasize the requisite uncertainty in the estimates of the energy imbalance for 2000-2010: an enormous ±17 W m-2.
A 17 W m-2 uncertainty range in the energy balance estimate (0.6 W m-2) means that the actual energy balance could be anywhere from -16.4 W m-2 to +17.6 W m-2.   This range of uncertainty effectively renders the 0.2 W m-2 CO2 forcing estimate meaningless, as the uncertainty in the volume of energy change during 2000-2010 is 85 times greater than the forcing attributed to CO2 for the same period.

Stephens et al., 2012
“This small imbalance [0.6 W m-2] is over two orders of magnitude [100 times] smaller than the individual components that define it and smaller than the error of each individual flux.”
“The net energy balance is the sum of individual fluxes. The current uncertainty in this net surface energy balance is large, and amounts to approximately 17 Wm–2.  This uncertainty is an order of magnitude [10 times] larger than the changes to the net surface fluxes associated with increasing greenhouse gases in the atmosphere.”
“The quoted value of the sensible heat flux is a combination of the land and ocean sensible heat fluxes  with a simple weighting based on land/ocean surface area. The flux value of 24 Wm–2 is also larger than previously assumed and remains highly uncertain, as exemplified by the range of 14–34 Wm–2 that results from different land flux estimates. No definitive measure of the uncertainty of this flux exists and the uncertainty range given merely reflects a judgement on where the value most likely lies.”

Even the IPCC acknowledges that the uncertainty in heat flux estimates reaches up to 20 W m-2, and that this uncertainty dwarfs the less than 2 W m-2 of total radiative forcing attributed to anthropogenic CO2 emissions during the last few centuries.

IPCC AR4 (2007)
“Unfortunately, the total surface heat and water fluxes are not well observed. Normally, they are inferred from observations of other fields, such as surface temperature and winds. Consequently, the uncertainty in the observational estimate is large – of the order of tens of watts per square metre [20 W m-2] for the heat flux, even in the zonal mean.”

IPCC AR5 (2013)
“The overall uncertainty of the annually averaged global ocean mean for each term is expected to be in the range 10 to 20%. In the case of the latent heat flux term, this corresponds to an uncertainty of up to 20 W m–2. In comparison, changes in global mean values of individual heat flux components expected as a result of anthropogenic climate change since 1900 are at the level of <2 W m–2  (Pierce et al., 2006).”

Frank, 2008
“It turns out that uncertainties in the energetic responses of Earth climate systems are more than 10 times larger than the entire energetic effect of increased CO2.”

5. IPCC Hides Uncertainty, Errors In Radiative Energy Change

Advocates of the position that CO2 is the climate’s “control knob” would like to divert attention away from the uncertainties and errors in climate modeling, of course.  Likewise, the IPCC has notoriously buried data that might cast doubt on the “consensus” position (which states that most climate changes have been driven by anthropogenic CO2 emissions since the mid-20th century).
To find the uncertainty and error ranges in the climate model estimates of radiative forcing, one must deliberately set out to locate the esoteric “Supplemental Material” documents from each report.  The IPCC would not dare publish estimates of massive climate modeling errors and uncertainty in locations where they are most likely to be viewed.

Frank, 2008
“One must go into Chapter 8 and especially Ch 8 Supplementary Material in the recently released IPCC AR4 to find GCM [General Circulation Model] errors graphically displayed in W m-2. Such forthright displays [of error/uncertainty, as shown in the graphs below] do not appear in the SPM [Summary for Policy Makers] or in the Technical Summary; i.e., where public bodies are more likely to see them.“
Supplementary Material from Chapter 8, IPCC AR4
“Figure S8.5 shows that GCM errors in ‘mean shortwave radiation reflected to space’ range across 25 W m-2.”


“The errors in outgoing longwave radiation, Figure S8.7, are similarly large [~20 W m-2]…”


6. ‘From Where Comes The Certainty Of A Large CO2 Impact On Climate?’

So if the models are so hopelessly riddled with errors and uncertainty that an anthropogenic radiative forcing signal cannot be distinguished from noise, or if the total magnitude of the warming attributed to humans is one-tenth to one-hundredth of the error or uncertainty ranges, why are those who dare question the degree to which humans affect the Earth’s climate branded as “deniers” of science?
Exactly what is the truth that climate “deniers” are actually denying?
“If the uncertainty is larger than the effect, the effect itself becomes moot. If the effect itself is debatable, then what is the IPCC talking about? And from where comes the certainty of a large CO2 impact on climate?“                                                   –Dr. Patrick Frank, “A Climate of Belief“
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMunich Re stumped: wonders why damages from natural catastrophes have fallen dramatically
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt)
(translated/edited by P Gosselin)
One of the most often named consequences of climate change is the prognosticated increase in extreme weather damage. At the forefront stood the insurance companies which loudly warned and thus stealthily laid out the groundwork for new customer acquisitions and higher premiums. But there’s one small problem: the climate refuses to play along with the climate establishment. The online Bayerische Staatszeitung (Bavarian State News) reported on July 18, 2017 on the latest development:
Less damage from natural catastrophes

In the first half of this year it was comparably quiet on the planet

In the first half of the year the planet suffered less from heavy natural catastrophes when compared to the long-term mean. According to figures from reinsurer Munich Re, damage worldwide due to natural catastrophes amounted to 41 billion dollars (approx. 35.7 billion euros) from the start of January to the end of June. That was less than half of the 111 billion dollars of damage due to natural catastrophes that had occurred in the first half of 2016.”
Read more at the Bayerischen Staatszeitung.
==================================================
Munich Re: Damage from “cold snap in late spring”
By P Gosselin
And according to the highly dramatized Munich Re press release here, the largest share of the damage, 18.1 billion dollars, came from “many thunderstorms and tornadoes in the USA”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Overall the 10-year average global natural catastrophe damage for the first half of the year is 102 billion dollars, Munich Re writes here. This makes the 2017 first half year dramatically mild.
Munich Re sales pitch: But do stay alarmed! 
Munich Re Board member Torsten Jeworrek: “The exceptional accumulation of severe thunderstorms in the USA highlights just how important it is for insurers to have in-depth knowledge of natural catastrophes and how these are affected by climatic changes. This is true of both natural climatic changes and those that are man-made. Insurers not only help to overcome losses, they also improve our understanding of what triggers them. This is a fundamental basis for preventing future losses.”
Peter Höppe, Head of Munich Re’s Geo Risks Research: “The unusual atmospheric conditions in the USA in the first half of 2017 provided the perfect conditions for powerful supercell thunderstorms, which frequently bring major hailstorms and tornadoes. The number of tornadoes observed in the first quarter of 2017 was twice as high as the average for the last ten years.”
The Munich Re did not report the number of tornadoes for the first half.
Damage from “cold snap in late spring”
Another contributor to the natural catastrophe damage was a “cold snap in late spring”, the Munich Re added.
Some unusual weather events in Europe made a substantial contribution to the overall losses of €4.4bn, of which €1.7bn was insured. One event with very high losses that will not be remembered by many as a real natural catastrophe was a cold snap in April that affected a number of European countries. Temperatures as low as minus 7 degrees and snowfall in many parts of Europe in the second half of April resulted in serious frost losses in the agricultural sector, mainly vineyards and orchards.”
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNote: Due to the very positive feedback of this post, I’ve decided to leave it up at the top spot for another day. -PG
==============================================

In 1981, James Hansen was the Director of the NASA Goddard Institute for Space Studies.  He was also the lead author of a seminal paper published in the prestigious journal Science entitled “Climate Impact of Increasing Atmospheric Carbon Dioxide“.  In the paper, Hansen and his colleagues reported (and illustrated with multiple graphs) the widely accepted 100-year (~1880-1980) record of hemispheric and global temperature changes.  At the time, most climate scientists were reporting that the Northern Hemisphere’s (NH) temperatures had undergone a rapid warming of between +0.8 and +1.0°C between the 1880s and 1940.  Then, after 1940 and through 1970, NH temperatures were reported to have dropped by about -0.5 to -0.6°C, a decades-long cooling trend which at the time had fomented widespread debate about global cooling in the scientific community.
Like their peers, NASA’s Hansen and his co-authors indicated that the Northern Hemisphere had warmed by ~0.8°C between the 1880s and 1940, and then cooled by ~0.5°C between 1940 and 1970.

A graph of “observed temperature” for the Northern Hemisphere was included in the paper to illustrate these climatic trends.

Today, NASA’s Goddard Institute for Space Studies is directed by Dr. Gavin Schmidt, a trained mathematician.  (James Hansen retired from the position in 2013.)   Schmidt’s version of the Northern Hemisphere’s temperature record for 1880-1980 looks vastly different than what his predecessor had illustrated in 1981.  Instead of leaving the historically observed temperatures alone, NASA has invented new ways to portray the pre-1981 temperature history of the Northern Hemisphere.
2017 NASA Hemispheric Graph

To subjectively summarize the wholesale adjustments to past temperature data, the +0.8°C warming between 1880 and 1940 has been reduced to +0.35°C.  The -0.5°C cooling between 1940 and 1970 has been reduced to -0.2°C.  And in NASA’s 2017 version of Northern Hemisphere temperatures, 1980 is now even with 1940.  Neither year was warmer than the other.  In the original 1981 NASA graph, however, 1980 was -0.3°C colder than 1940.

If the originally recorded observations for the Northern Hemisphere had not been erased from the temperature record, the pre-1981 trend would look like it does in the graph below (black trend line).  In other words, if the temperature observations as they appeared in 1981 had not been tampered with, it would be clear the Northern Hemisphere’s surface temperatures have undergone an oscillation, or warming-cooling-warming cycle, with no significant net change from the earlier warming amplitude or rate (1880-1940) to the more recent one (1980s-present).

Why Did NASA Eliminate The Early 20th Century Warming And Mid-20th Century Cooling?
The fundamental reason why NASA has manipulated past temperature data is so that the historical climate record may conform to the IPCC models that presume variations in surface temperatures are predominantly determined by anthropogenic CO2 emissions.  Fossil fuels consumption in particular and anthropogenic CO2 emissions in general plodded along steadily at about 1 GtC/year (gigatons of carbon per year) during the 1900 to 1945 period.  Then, after 1945, human emissions exploded.  They reached 4 GtC/year by the 1970s, 6 GtC/year by the 1990s, and 10 GtC/year by 2014.

NASA recognized that (a) anthropogenic CO2 emissions were not rising much at all while the surface temperatures were rising dramatically (1880s-1940s), and that (b) surface temperatures were cooling (1940s to 1970s) while anthropogenic CO2 emissions were surging upwards.  These observed trends did not support climate modeling; instead, they undermined the models.  So, to counteract this, NASA has undergone a decades-long effort to change past temperature data that do not adhere to modeled expectations.  In other words, NASA has sought to suppress the 1880s to 1940 warming amplitude and rate, and they have warmed up the 3 decades of NH cooling by about +0.3°C.  In this way, the overall 1880s-present trend will look linear rather than oscillatory, and it will also look more and more like the trends in anthropogenic CO2 emissions (above graph).   When the facts don’t fit the models, NASA apparently changes the facts.
Non-Adjusted Temperature Data Appear To Correlate With 20th Century Solar Forcing
In a paper just published in the journal New Astronomy, scientists Yndestad and Solheim (2017) have released a reconstruction of solar activity (Total Solar Irradiance, or TSI) for 1700-2013.  As explained here, the 20th Century contained the so-called Modern Grand Maximum of very high solar activity.

Taking a closer look at the 20th Century solar irradiance trend only, the (a) rapid rise in TSI for 1900-1950, the (b) dramatic drop in TSI during the 1950s to 1970s, and then the (c) abrupt 1980s to early 2000s increase in TSI all seem to correspond generally to the non-adjusted temperature trend for the Northern Hemisphere — prior to the NASA temperature data manipulation.


In fact, many other recently published surface temperature reconstructions indicate that the warming-cooling-warming oscillatory 20th Century trend may correlate with this solar forcing trajectory.
Rydval et al. (2017), for example, include several graphs of surface temperatures for Northern Hemisphere locations that show warming and cooling periods largely correspond to multi-decadal- and centennial-scale records of high (warming) and low (cooling) solar activity.  In the NH graphs below, for example, notice how the temperature records follow a similar track that correspond with the non-adjusted (pre-1981) NASA temperature record: (a) rapid warming from around 1900 to the mid-20th Century, (b) rapid cooling for a few decades, and then (c) another warming ascent from about the 1970s or 1980s onward.  Also notice that the mid-20th Century peak warmth is not significantly different than the warmth achieved in the last decade or two, again affirming an oscillatory pattern rather than a linear one.

Rydval et al., 2017
“[T]he recent summer-time warming in Scotland is likely not unique when compared to multi-decadal warm periods observed in the 1300s, 1500s, and 1730s … [E]xtreme cold (and warm) years observed in NCAIRN appear more related to internal forcing of the summer North Atlantic Oscillation. … There is reasonable agreement in general between the records regarding protracted cold periods which occur during the LIA and specifically around the Maunder solar minimum centred on the second half of the seventeenth century and to some extent also around the latter part of the fifteenth century coinciding with part of the Spörer minimum (Usoskin et al. 2007).”








<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Temperature records for many other regions within the Northern Hemisphere (as well as several from the Southern Hemisphere) may also align with the original (non-adjusted) NASA temperature observations and recent reconstructions of TSI.   So as not to cross the threshold of excessiveness, only a small portion of the many similarly correlative warming-cooling-warming temperature reconstructions available are included below.

Yamanouchi, 2011 (Arctic)

Box et al., 2009  (Greenland Ice Sheet)

Hasholt et al., 2016  (Southeast Greenland)
“We determined that temperatures for the ablation measurement periods in late July to early September were similar in both 1933 and the recent period [1990s – present], indicating that the temperature forcing of ablation within the early warm period and the present are similar.”

Kobashi et al., 2011  (Greenland Ice Sheet)

Chafik et al., 2016  (Atlantic, North)

de Jong and de Steur, 2016 (Irminger Sea, North Atlantic)

Reynolds et al., 2017 (Central England, North Atlantic)

Saenger et al, 2009 (Bahamas, Northern Hemisphere)
 

De Jong et al., 2016  (Andes, South America)
“[T]he reconstruction…shows that recent warming (until AD 2009) is not exceptional in the context of the past century. For example, the periods around AD 1940 and from AD 1950–1955 were warmer. This is also shown in the reanalysis data for this region and was also observed by Neukom et al. (2010b) and Neukom and Gergis (2011) for Patagonia and central Chile. Similarly, based on tree ring analyses from the upper tree limit in northern Patagonia, Villalba et al. (2003) found that the period just before AD 1950 was substantially warmer than more recent decades.”

O’Donnell et al., 2016 (Southeast Australia)

de Jong et al., 2013 (Chile)

Gouretski et al., 2012  (graph) (Global Ocean 0-20 m)


To summarize, then, there seems to be no scientific justification for NASA’s conspicuous temperature data tampering.  From all appearances, the removal and/or doctoring of observed temperature data from the pre-1981 period was a tendentious act designed to change the appearance of graphs to fit climate models that presuppose a deterministic anthropogenic influence.  NASA’s apparent manipulation of climate science endangers the reputation of scientists across all disciplines.  It should be stopped immediately before even more credibility is lost.
Share this...FacebookTwitter "
"Upon becoming Greater Manchester’s first elected mayor, Andy Burnham announced his ambition to make the city-region one of the greenest in Europe. In his Mayor’s manifesto, the former MP and Labour leadership candidate, committed to “a new, accelerated ambition for Greater Manchester on the green economy and carbon neutrality”. If achieved, Manchester would be transformed from one-time poster city for Britain’s dirty past to a decarbonised oasis in the post-industrial north-west of England. What it will take to realise this vision is the topic of a “Green Summit” to be held in Manchester on March 21. The Green Summit website claims the best minds from Greater Manchester’s universities and businesses, local activists and residents will be brought together to debate how to “achieve carbon neutrality as early as possible”, ideally by 2050. Leading up to the summit, expert workshops and “listening events” were held across the region, in order to inform a forthcoming Green Charter, the plan for how the city will become “carbon neutral”. We argue that the concept of “carbon neutrality” is a lofty ambition, but it needs unpacking before anyone gets too excited about its potential. The idea that a zero carbon target is the best driver for creating a city-region and planet that’s inclusive and liveable for all raises important questions. Carbon neutrality, or “zero-carbon”, is a curious term. NASA remarks that “carbon is the backbone of life on Earth. We are made of carbon, we eat carbon, and our civilisations – our homes, our means of transport – are built on carbon”. Even our bodies are 18.5% carbon. Ridding our cities of carbon suddenly seems absurd. Removing the “backbone of our life on Earth” is surely not on Burnham’s eco-agenda. So what does “carbon neutral by 2050” actually mean? Understanding a little about carbon footprinting helps to expose the nuances and silences behind the ambition. Carbon is emitted at various points within the production, transportation and consumption of goods and services, but establishing responsibility for these emissions depends on your standpoint. Is it the consumer, the manufacturer, the haulage firm, the investor, the source country or the destination country? Our actions and impacts do not respect political boundaries.  Governments typically count carbon emissions following guidelines from the Intergovernmental Panel on Climate Change (IPCC). Taking a “territorially-based” approach, only the direct carbon emissions (and removals) taking place within a certain city or a country are counted, along with those from the production of the energy consumed. “Carbon” stands for a whole raft of greenhouse gases, including CO₂. This approach underpins declarations of successes and failures worldwide, but it’s just one way to allocate carbon emission. And herein lies the issue. An alternative “consumption-based” accounting is more often used by environmental NGOs such as the WWF or some parts of the UK government. This approach counts the total emissions from goods and services (including travel) consumed by a person, city or country, regardless of where they occurred. Under consumption-based accounting, eating an imported steak means factoring in shipping emissions, the plastic used in packaging, and the emissions from the cow itself – all of which take place far outside of the typical “footprint”. One recent analysis found a group of large cities across the world emitted 60% more carbon when considered like this.  But will Greater Manchester, the aspiring “Northern Powerhouse”, really want to include emissions from such key drivers of economic growth? The city-region has a busy airport, for instance, that it might be convenient to exclude under “zero carbon”. Greater Manchester’s ambition may be laudable, but the zero-carbon definition risks side-lining much-needed action in other areas. There is some degree of hope. Greater Manchester is implementing a new standard which extends the IPCC’s approach, also considering emissions from residents’ travel beyond Greater Manchester and waste disposed of beyond the city-region. This is significantly more ambitious than a territorial-based approach. But, even if “zero-carbon” was defined under this approach, there would still be difficult questions as to what extent aviation emissions would be included – if at all – not to mention other consumption-based emissions, such as those from imported food. In any case, the city needs environmental policies beyond the focus on becoming “carbon neutral”. Litter is one of the top resident concerns about environmental quality, for instance, while a recent study by MMU’s Gina Cavan found many people in the city have limited access to green and blue spaces. Research by our colleagues found the greatest level of microplastics ever recorded anywhere on the planet in Manchester’s very own River Tame. No doubt the mayor and his team will be concerned about these other problems too. But the pollution crises and the lack of access to green spaces are questions of environmental injustice, and their root causes will not necessarily be addressed by carbon neutrality. To avoid obscuring other areas of action, it’s vital that claims about a “carbon neutral” future clearly state what they are referring to.  Carbon neutrality doesn’t cover everything – it might only be concerned with decarbonising energy and in-boundary emissions. If Greater Manchester is serious about becoming greener, cleaner and inclusive, then there needs to be accountability for other perspectives on emissions responsibility, including those associated with consumption and aviation."
"
Share this...FacebookTwitterSun rules sea level: Scientists discover unexpected relationship
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated by P Gosselin)
A group of researchers led by Adrian Martinez-Asensio have found an 11-year Schwabe solar cycle in the European sea level. The authors published their findings 19 November 2016 in the Geophysical Research Letters:
Decadal variability of European sea level extremes in relation to the solar activity
This study investigates the relationship between decadal changes in solar activity and sea level extremes along the European coasts and derived from tide gauge data. Autumn sea level extremes vary with the 11 year solar cycle at Venice as suggested by previous studies, but a similar link is also found at Trieste. In addition, a solar signal in winter sea level extremes is also found at Venice, Trieste, Marseille, Ceuta, Brest, and Newlyn. The influence of the solar cycle is also evident in the sea level extremes derived from a barotropic model with spatial patterns that are consistent with the correlations obtained at the tide gauges. This agreement indicates that the link to the solar cycle is through modulation of the atmospheric forcing. The only atmospheric regional pattern that showed variability at the 11 year period was the East Atlantic pattern.”
Already in May 2015 a group of researchers led by Daniel Howard found an influence by solar activity and ocean cycles on sea level trends in a paper  published in the Journal of Geophysical Research. The 2 factors  made up minimum 70% of the annual fluctuations. The paper’s abstract follows:
The solar and Southern Oscillation components in the satellite altimetry data
With satellite altimetry data accumulating over the past two decades, the mean sea level (MSL) can now be measured to unprecedented accuracy. We search for physical processes which can explain the sea level variations and find that at least 70% of the variance in the annually smoothed detrended altimetry data can be explained as the combined effect of both the solar forcing and the El Niño–Southern Oscillation (ENSO). The phase of the solar component can be used to derive the different steric and eustatic contributions. We find that the peak to peak radiative forcing associated with the solar cycle is 1.33 ± 0.34 W/m2, contributing a 4.4 ± 0.8 mm variation. The slow eustatic component (describing, for example, the cryosphere and large bodies of surface water) has a somewhat smaller peak to peak amplitude of 2.4 ± 0.6 mm. Its phase implies that warming the oceans increases the ocean water loss rate. Additional much smaller terms include a steric feedback term and a fast eustatic term. The ENSO contributes a peak to peak variation of 5.5 ± 0.8 mm, predominantly through a direct effect on the MSL and significantly less so indirectly through variations in the radiative forcing.”
 
Share this...FacebookTwitter "
nan
"Fracking looks set to arrive in Britain after all. US-Australian energy company Cuadrilla recently announced it may begin producing the UK’s first commercial shale gas sometime in 2019. The government says that shale plays an important role in the country’s energy strategy. As a domestic resource it can not only can make up for declining gas production from the North Sea, but also help ease concerns about the UK’s dependence on imports, notably against a backdrop of strained relations with Russia as well as recent supply shortages. Supporters of fracking also argue it could fill the gap left by the phase-out of coal power, helping decarbonise the energy system while bringing additional jobs.  Yet shale gas hasn’t done a great job of selling itself in the UK.
Fracking technology itself has come under fire – in order to obtain shale gas, underground rocks are fractured under high pressure and using chemicals. Many people are worried about groundwater safety, the environmental impact and public health, thus leading to protests. All this raises the question of how to reach an agreement. Is shale gas desirable or not? Is the extra energy worth the environmental damage? Do the jobs created outweigh local residents’ concerns? What’s needed is a shared understanding between the various social, economic and political stakeholders. In short, energy companies need what is known as a social license to frack. As my recent research on fracking in Eastern Europe suggests, such a social licence rests on a policy process that all stakeholders see as legitimate, along with public acceptance of a technology that doesn’t often go wrong but could be disastrous if it did.  Although shale gas had been hailed as a “game changer” for East Europeans, given their strong dependence on Russian gas supplies, Bulgaria ended up banning fracking, exploration plans were shelved in Romania, and quietly abandoned in the Baltics. Across the region, environmental activists were joined by ordinary citizens, the Orthodox Church and even a national grain producer association to protest against the alleged threat of shale gas to food security, the environment and the sell-off of “national treasure” to foreign companies such as Chevron. Only a few countries, notably Poland, remained legally open to shale gas extraction, and there fracking was granted a social licence by stakeholders.   Judged by the actual output, shale gas in Poland isn’t exactly a success story. As in Bulgaria, Romania or Lithuania, the country saw foreign majors abandoning domestic shale prospects. The economics simply didn’t add up, geology proved more difficult than expected and the regulatory environment was far from ideal. But public support for the Polish government’s shale gas policies stayed strong, protests remained limited, and people bought into the idea of unconventional energy being of overall net benefit. Why was that? Governments that pushed for shale in a top-down manner, cared little about public communication and only involved a few friendly faces from the corporate and NGO world faced public opposition – Bulgaria is a good example. By contrast, countries such as Poland that involved those energy corporations already in place, consulted local mayors and ensured some of the profits would remain in the area, saw their efforts pay off. The policy narrative is another important element. Research I carried out with my colleague Benjamin Sovacool found very different narratives across Eastern Europe. In Poland, shale gas emerged as a national project that could potentially bring economic prosperity and energy security – and this united various stakeholders behind government policy. In Bulgaria and Romania, the discussion of shale gas focused on authoritarian governments and environmental hazards. Poor public bureaucracy meant that people there had little trust in the policy process and began to question the governments’ motivations. The upshot is that even proving shale gas is economical to extract – in Lancashire or elsewhere in the country – will not be enough to make it happen. Extracting unconventional energy resources at an industrial scale will eventually require a social licence from society as a whole, not just the local communities that are most directly affected. This won’t be achieved simply through bureaucratic processes, such as production permits, or even through a mandate from an election – the social licence requires a much broader buy-in. Instead, the UK government would be well advised to think up ways to enhance institutional outreach and community empowerment as well as opportunities to facilitate the buy-in of important stakeholders on national and sub-national levels. This may be a cumbersome process, and the outcome may be hard to determine. But it is the only way to lend legitimacy to its policies and to possibly generate the necessary public acceptance for a highly contested technology. The broader takeaway, however, is that what holds true for fracking also applies to core aspects of the imminent transition towards low-carbon energy. Are people truly ready for massive numbers of new high-voltage electricity pylons? What about enormous new wind farms? Do they appreciate the technology it will take to eventually achieve negative emissions and meet the Paris climate targets? Society as a whole still doesn’t really anticipate anything of the required scale, and a serious jump into a low-carbon world may come as a shock to people used to the status quo. Changes of that scale should be broadly acceptable to the nation and would therefore warrant a social licence. Starting with appropriate frameworks for fracking may therefore not be a bad idea, and would pay off at larger scale in future."
"
Share this...FacebookTwitterLast Sunday voters in Germany’s most populous state, North Rhine Wesphalia (NRW), sent a loud message: voters are much more concerned about problems other than climate protection and green energies.
The state’s ruling SPD Socialists/Green Party coalition government led by Hannelore Kraft took an historic beating, getting tossed out as the state swung far – from the left to the right.
The online International Economic Forum for Renewable Energies here consequently wrote:
Energy policy in Germany’s most populated state could change profoundly.”
Rise of the right
The center-right CDU party led by Armin Laschet took the top spot as it pulled in 33% of the vote, some 6.7% more than they did in the 2012 election. Most observers believe the CDU will partner up with business-friendly FDP free democrats, who picked up an impressive 12.6% of the vote, 4% more than the previous election.
The newcomer hard-right AfD party pulled in 7.4% in their first election in NRW ever.
Demise of the left: In total the center/right-of-center parties gained a whopping 18%, marking a major political shift.
Meanwhile the once ruling SPD Socialists saw their result disintegrate, falling almost 8% lower than 5 years ago, going from 39.1% to just 31.2%. The SPD coalition partners, The Greens, collapsed from 11.3% to a mere 6.4%. Meanwhile the extreme leftists, Die Linke, fell below the 5% threshold, and thus were booted out of the state parliament.
If anything, the results of the election show foremost that NRW citizens are far more concerned about other issues, such as crime, deteriorating educational quality and uncontrolled immigration, than they are about green issues. In recent polls climate and environment scored at the bottom of concerns.
Shift back to fossil fuels?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The results also hint at a growing sentiment that may be taking hold across Germany: Germans are realizing that no matter how much pain they might endure in trying to rescue the climate, ultimately their contribution on a global scale really will have very little impact at all. Whatever reductions Germany may achieve over the next 10-20 years will be wiped out in just a matter of months by large developing countries elsewhere, like China, India, and the African continent. What’s the point of all the pain?
According to the online International Economic Forum for Renewable Energies here:
With the altered balance of power in the most populated federal state comes an end to the previous energy policy of the ousted Red-Green state government. Conventional power sources will now get more support.”
Working class anger
The hard right AfD in fact garnered a large share of its support from working class people, who traditionally voted for the SPD, but who had grown dischanted with the widespread crimes waves, and hostility aimed by Greens at traditional energy industries and jobs.
Greens and a number of Socialists have called for an accelerated shut down of German coal plants, many of which are located in NRW. German power companies, such RWE and EON, have seen billions in losses and tens of thousands of layoffs over the past years, a direct result of massive green energy subsidies and a run-away feed-in act.
The NRW election results bode especially ill for the German left nationally, as federal elections are slated for September. It had been speculated earlier that the SPD’s new leader Martin Schulz would have a chance at ousting Angela Merkel and lifting the leftists and greens back into power for the first time in over a decade. But already any added popularity Schulz may have brought to the party earlier appears to have fizzled. Moreover, The Greens, traditional coalition partners of the SPD, are near record lows in the opinion polls (near 6%).
There’s risk that September’s election will end in a rout for the DPD and Greens.
New potential NRW government no big fan of green energies
Although the CDU often pays lip service to green energies, they are in fact not so keen about pushing them through with vigor. The FDP has recently been becoming more vocal in opposing wind and solar energy outright in many locations, and rather favor limiting them to certain area located along motorways and offshore.
The winds of energy are truly shifting in Germany.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Frankfurter Allgemeine Zeitung (FAZ) — Germany’s version of the Washington Post — reports here that the country’s Energiewende (transition to green energy) has been fraught with “serious errors” and that the government has lost control of its energy policy.
The FAZ cites a report released by the Bundesrechnungshof (federal accounting office).
Out-of-control costs
The report unloads criticism on Economics Minister Sigmar Gabriel, who is also vice chancellor to Angela Merkel.
The federal accounting office report slams Gabriel’s Economics Ministry, concluding, that it “has no overview of the financial impacts of the Energiewende.” In short, the government has lost control over the project – similarly like it lost control of the construction of Hamburg’s Elbphilharmonie concert hall, which originally had been estimated to cost less than 80 million euros, but wound up costing a scandalous 789 million euros before finishing years behind schedule!
“Serious organizational deficiencies”
The accounting office report also accuses Germany’s energy policy of being fraught with “serious organizational deficiencies” that are “difficult to comprehend“.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In the earlier days of the Energiewende, proponents such as Green Party member Jürgen Trittin boasted that the green energy project would be affordable, costing the average German citizen about as much as the cost of “one scoop of ice cream each month“. Since then Germany’s electricity costs for consumers have exploded and are now among the highest in the world, averaging near 30 cents per kilowatt hour.
The stability of the supply has also taken a serious hit.
Price spiral continues
Even worse, the prices of German electricity bare projected to increase substantially over the coming years. The FAZ adds:
The federal accounting office sees a risk that it will get more expensive to advance the Energiewende.”
Germany’s shocking electricity price spiral shows no signs of slowing. A week ago the online Kieler Nachrichten here reported in a separate story that “electric bills for consumers will be significantly higher in 2017” and that if things do not change, prices will continue to rise until at least 2023.
 
Share this...FacebookTwitter "
"The image of 13-year-old Izzy crying as she was told she could be arrested outside Australian prime minister Scott Morrison’s Sydney residence has become one of the defining images of the country’s bushfire crisis. Guardian Australia asked her to write about why she was there and what she felt.  As Australia burned from tragic bushfires, on Thursday I joined hundreds of others to demand action from our prime minister outside his Kirribilli residence. It was a whirlwind of emotions and action. The drastic change from motivational speeches, to a peaceful sea of tents awaiting the PM’s climate action, to a squad of riot police moving through the crowd arresting people, was unsettling. Many people have asked me what motivated me to drag my dad on a one-hour bus trip to Kirribilli House on one of the hottest days of summer. My answer? Our politicians’ denial, and the inaction of our government and our prime minister. Their denial has gone on for far too long. I’m tired, tired of the lies and misdirection. I’m tired of watching my future, my friends’ and family’s futures, all of our futures, burn before our very eyes. How dare Scott Morrison race off to Hawaii during Australia’s time of crisis? What we need is a prime minister who acknowledges that this isn’t another normal fire season, that the cause of this is climate change! Lives and homes have been taken while Morrison lies on a tropical beach with his head in the sand. As police went about their move-on order at Kirribilly House, one girl was visibly frightened during police direction. She and her father complied with the move-on order.#ClimateProtest pic.twitter.com/PJHHAs1B8n When I first arrived at the protest it was a happy sight: young kids, families, students, adults young and old. Some were in costumes, some had painted faces, others had signs and banners. All gathered at the end of a small cul-de-sac, under a blazing sun. All there with a story, a purpose, a reason. The number of police didn’t worry me then, we were told they were there to protect us. After the rally wrapped up, a number of people announced that they had decided to camp out until Morrison returned from his holiday. The crowd had mixed emotions, some cheered while others looked on with surprise and apprehension. Tents were pitched, food and games were passed around. We settled in, made new friends, exchanged stories. Even a Christmas tree was put up. At this point, many more police vans had pulled up. Greens MP David Shoebridge arrived and complained to the police that it was unreasonable to move us as we weren’t hurting anybody or blocking anything. A “move on” order was issued. We chanted in response. We had a reason to be here – our prime minister is missing in action on the most important issue of our time. Right before the riot police came it was quiet; dense smoke swirled over the road. A sense of unease settled over me. A squad of about 25 fully suited and armed riot police came marching over the hill. It was like something out of a movie. The officers approached the wall of students and protesters with intense intimidation tactics. They went for the loudest and most motivating people first, the natural leaders, grabbing their arms and pulling them into the police van if they didn’t comply. I watched shocked and confused as my friends and fellow protesters were scattered, arrested and escorted off premises. It was chaotic, people were scrambling around filming on phones and photographers were buzzing around, capturing acts of bravery and courage in the face of injustice. My dad and I were told to move on, which we did, but as I moved on I held my sign high in the sky: Look at what you’ve left us Watch us fight it Watch us win. It’s a day I won’t forget in a hurry."
"Former emergency leaders who have been pushing the Morrison government to take action on the climate say they will “go it alone” and convene their own summit on the bushfire crisis. The Emergency Leaders for Climate Action say they will hold the summit after the current bushfire season because of their “huge disappointment in the lack of national leadership during a bushfire crisis”. It comes as fires raged across New South Wales and Western Australia on Monday and as Australia was named as one of a handful of countries responsible for thwarting a global deal on the rulebook of the Paris climate agreement. A week ago, former fire chiefs Greg Mullins, from NSW, and Lee Johnson, from Queensland, called for a national summit on how the country should prepare for and resource bushfire emergencies in a changed climate. Both men are part of Emergency Leaders for Climate Action, a group of former fire and emergency chiefs who had warned the government that Australia faced a disastrous fire season. The group’s ranks have expanded from 23 to 29 members since it first warned the government earlier this year that Australia was unprepared for the escalating climate threat. Sign up to receive the top stories from Guardian Australia every morning Late last week the prime minister, Scott Morrison, moved to reassure voters he understood the fires were a national emergency and said climate change was one of many contributing factors to the current fire season. But Mullins said those “many factors are all related to climate change”. “What we feel is that there’s just still this denial of the problem and where we have denial of the problem, there’s not going to be any action,” he said. “So we’ll go it alone. We’ll arrange a national summit that will look at building standards, fuel management practices, response capability and national coordination arrangements. “We’ll invite the prime minister and we hope that he comes too.” The Emergency Leaders for Climate Action said Australia had “embarrassed” itself through its performance at the United Nations climate conference in Madrid at a time when people around the world were watching reports about the country burning. Mike Brown, a former chief officer for the Tasmanian Fire Service, said the outlook for the next three months was for drier and hotter than average conditions for much of the country. “That doesn’t stand well for how things develop into the summer,” he said. Brown said the eastern half of Tasmania, including all of the east coast and the Derwent Valley, was particularly dry. It follows the summer of 2018-19, when huge fires hit world heritage forest. “I’m a big fan of fuel reduction but the weather window in which to do fuel reduction is becoming narrower due to hotter and windier weather due to climate change,” Brown said. “You also can’t do fuel reduction in wet forest types. We think that due to the changing climate there needs to be a fresh approach to manage fires and just how people in communities are going to be managed into the future when we’re facing increased fire weather.” The proposed summit would include fire service workers, Indigenous landowners, the military, the insurance industry and local governments. Mullins said it would occur in late March, but the timing was subject to change if the bushfire season ran for longer than usual.    "
"The Paris deal generally got a very good press. Most reporting in the immediate aftermath had a similar focus on a few key headline points: this was a “landmark victory”, albeit one with a few cautionary notes. Yet a closer look reveals some telling differences.  The left-leaning Guardian called it an “ambitious agreement” and “an end to the fossil fuel era”. While criticisms were recognised, the tone was generally positive, even euphoric, emphasising the historic nature of the achievement. There was mention that NGOs “could never have envisaged a deal that was so ambitious” and, although it was still not ambitious enough, “campaign groups were broadly positive about the outcome”. Yet, negative points were made about “the weakening of the agreement when it came to dealing with the irreparable damage of climate change”.  The more centrist Independent similarly emphasised the historical and revolutionary nature of the moment, offering stronger cautionary notes, such as that of UCL’s Chris Rapley who pointed out that only “time will reveal the true nature of the Paris agreement”. On the political right, the Telegraph was much more cautious. It referred to the success of the agreement, but chose to outline what had been agreed, rather than emphasise the historic significance of the moment. The paper was interested in what this will mean for UK policy and in what NGOs think of the agreement, balancing positive judgements from Christian Aid with negative evaluations from Friends of the Earth. The Times and the Sunday Times however, were less positive. Writing just before the announcement, the agreement was being presented in the Times as a success for small island states in holding the UK and the rest of the world to a tougher deal. The cost of technological solutions was of more interest than marking the seminal moment. The Sunday Times (Irish edition) the following day was more appreciative of the agreement, claiming it was “historic”, but not as significant as asserted elsewhere. The article views technology and self-interest as the forces that will beat global warming. Aside from the nuts and bolts of the agreement – the financial mechanisms, pledges made, and so on – one of the strong messages of the news coverage was that investors and governments could now make choices based on a collective commitment to emissions reduction; something regarded as a very positive step. Another emphasis was the role of the US in pushing for a deal and France in brokering it.  However over in the comment pages, strongly sceptical/negative voices were also included, particularly in the Guardian. George Monbiot, the paper’s high-profile environment columnist, claimed that: “By comparison to what it could have been, it’s a miracle. By comparison to what it should have been, it’s a disaster”. Similarly former NASA climate scientist James Hansen emphasised the failures: “It’s a fraud really, a fake. […] It’s just bullshit for them to say: We’ll have a 2℃ warming target and then try to do a little better every five years.” Then we have coverage that was hostile to the entire idea of a grand environmental summit. The Daily Mail, for example, investigated the environmental impact of the conference itself and concluded it was “a prime example of what wasteful lives the green lobby lead”. Meanwhile in the Telegraph veteran journalist Christopher Booker ridiculed COP21 as the moment “political panic” over climate change began to collide with the reality of a fossil fuel-based global civilisation. But this sort of climate denial – or policy “realism” – is increasingly rare in the mainstream media across the world. In our research we’ve looked at climate coverage in Russia, one of the world’s major carbon emitters and a country with every reason to avoid high-profile debate. Yet even there things are changing. The usually reluctant media joined the positive coverage of the Paris announcement, perhaps a logical outcome of the strong statement delivered by Russia’s president, Vladimir Putin, on the summit’s first day.  For example, the state-owned newspaper Rossiyskaya Gazeta discussed the successes of the Russian delegation, which managed to achieve all its aims. Russian reporters did criticise the legal aspects of the agreement, while activists and NGOs voiced some doubts over COP21’s achievement, pointing out, for instance, the increased likelihood of controversial low-carbon policies (such as China’s potential switch to nuclear) and Russia’s ambiguous position between the developed and developing camps. But these criticisms are a positive sign of engagement with the process, rather than simple denial or misinformation.  For climate change communication, 2015 has been crucial – the media played an instrumental role in translating environmental risks for a wider audience. The awards for specific climate communication heroes and villains haven’t yet been handed out, but the whole media deserves a pat on the back for at least giving the historic achievement in Paris the column inches it deserves. This article was co-authored by Teresa Ashe."
"French wine lovers have always taken their soil very seriously. But now the country’s government has introduced fresh reasons for the rest of the world to pay attention to their terroir. As industrial emissions of greenhouse gases continue to increase and concerns about climate change grow, scientists and policy wonks are searching for potential solutions. Could part of the answer lie in the soil beneath our feet? French agriculture minister Stéphane Le Foll thinks so. Soil stores vast amounts of carbon, far more than all the carbon in the world’s forests and atmosphere combined. Plants take carbon out of the atmosphere through photosynthesis and when they die the carbon they stored is returned to the soil.  This forms part of the soil’s organic matter: a mix of undecayed plant and animal tissues, transient organic molecules and more stable material often referred to as humus. It is food for organisms in the soil that play a vital role in cycling nutrients such as nitrogen and phosphorus. These organisms decompose the organic material and return much of the carbon to the atmosphere leaving only a small proportion in the soil. In the UK alone, soils store around 10 billion tonnes of carbon – that’s about 65 times the country’s annual carbon emissions. Increasing the amount of carbon in our soils has the potential to suck CO2 out of the atmosphere. At a March 2015 conference on Climate Smart Agriculture, Le Foll proposed the ambitious target of increasing French soil carbon contents by 0.4% year-on-year (“4 pour mille”). How France will meet the target is currently unclear but by throwing down the gauntlet Le Foll clearly wants to stimulate French farmers and researchers into action.  A 0.4% increase might not sound like a lot but, given the scale of carbon storage in soil and the fact that small increases add up over the years, meeting the target would have a significant impact on atmospheric CO2 concentrations.  Le Foll hopes that protecting carbon-rich soils (like those in natural bogs, permanent grassland or wetlands), better use of organic manures and farming that returns more plant biomass to the soil (such as by using cover crops and ploughing their residues into the earth) together with the use of bioenergy crops such as short rotation willow coppice, can contribute towards a 40% reduction in France’s CO2 emissions by 2030. He plans to bring forward an international programme to promote increases in soil carbon and to propose it to the UN climate talks in Paris. Such a programme would include research, innovation and engagement with farmers. There is no doubt this is a bold move. Research has shown raising soil carbon contents is not that easy due to much of the organic matter added to soils being lost to the atmosphere as it is decomposed by soil microbes. However, protecting the carbon we already have in our soils and just storing a little more could make a big difference.  In the UK most soil carbon (by far) is found in peaty soils under bogs, followed by soils under grass, woodland and arable agriculture. Protecting this carbon should be the first priority. That means maintaining and restoring bogs, avoiding conversion of grassland and forestry to arable land, or even reconverting arable land to grassland. These measures would all have a positive effect on soil carbon stocks.   Whether all this can deliver the 0.4% increase year-on-year that the French want is open to debate. What is clear though is that not only does soil offer a way to store carbon and help mitigate climate change, carbon-rich soil has numerous other benefits. It is more fertile and helps to promote food production, it improves soil’s physical properties – it protects against soil erosion and increases water-holding capacity – and it enhances biodiversity.  Promoting practices that increase soil carbon contents really is a win for both the soil and the climate."
"Next year is likely to be another of the hottest on record, with global temperatures forecast to be more than 1.1C above the pre-industrial average, according to estimates from the Met Office. The forecast for 2020 is based on observations of trends over recent years that have seen a series of years more than 1C above pre-industrial levels, and bearing what meteorologists said was the “clear fingerprint” of human-induced global heating.  That trend is likely to continue in 2020, the Met Office predicted on Thursday, barring unforeseeable events such as a major volcanic eruption, which would have a cooling effect from the dust thrown into the atmosphere. Next year is also unlikely to see a strong natural warming event, with no El Niño predicted. El Niño is the weather system in the Pacific that can result in unusually high temperatures, as it did in 1998, which until 2005 held the crown of the warmest year since records began in 1850. For years, that fuelled false claims from some quarters that climate science was wrong and global heating was not occurring. The hottest year on record currently is 2016, when there was an El Niño effect, and the years since have all been close to the record. “Natural events, such as El Niño-induced warming in the Pacific, influence the climate system,” said Prof Adam Scaife, head of long-range prediction at the Met Office. “In the absence of El Niño, this forecast gives a clear picture of the strongest factor causing temperatures to rise: greenhouse gas emissions.” If the forecast is correct, the world will come even closer to the brink of climate breakdown next year. Scientists have warned that warming of more than 1.5C above pre-industrial levels would have damaging effects on the world’s climate. The first year in which temperatures were certified to be more than 1C above the average from 1850 to 1900 was 2015, so the rate of change has been rapid. If current trends continue, we could breach the 1.5C threshold within two decades. Greenhouse gas emissions show little sign of abating, however: research published during the UN climate talks earlier this month showed that annual carbon emissions were now 4% higher than they were in 2015, when the historic Paris agreement on climate change was signed. The Met Office used the same methods last year to forecast 2019 temperatures, and observations this year show that temperatures tracked its central estimate closely. Its forecast for 2020 is for an increase in global average temperature of between 0.99C and 1.23C, with a central estimate of 1.11C. Temperature rises have been uneven across the globe, with the Arctic heating far faster than the average. Greenland ice is melting seven times faster than in the 1990s, according to research."
nan
"Imagine a world where every country has not only complied with the Paris climate agreement but has moved away from fossil fuels entirely. How would such a change affect global politics? The 20th century was dominated by coal, oil and natural gas, but a shift to zero-emission energy generation and transport means a new set of elements will become key. Solar energy, for instance, still primarily uses silicon technology, for which the major raw material is the rock quartzite. Lithium represents the key limiting resource for most batteries – while rare earth metals, in particular “lanthanides” such as neodymium, are required for the magnets in wind turbine generators. Copper is the conductor of choice for wind power, being used in the generator windings, power cables, transformers and inverters.  In considering this future it is necessary to understand who wins and loses by a switch from carbon to silicon, copper, lithium, and rare earth metals. The countries which dominate the production of fossil fuels will mostly be familiar: The list of countries that would become the new “renewables superpowers” contains some familiar names, but also a few wild cards. The largest reserves of quartzite (for silicon production) are found in China, the US, and Russia – but also Brazil and Norway. The US and China are also major sources of copper, although their reserves are decreasing, which has pushed Chile, Peru, Congo and Indonesia to the fore.  Chile also has, by far, the largest reserves of lithium, ahead of China, Argentina and Australia. Factoring in lower-grade “resources” – which can’t yet be extracted – bumps Bolivia and the US onto the list. Finally, rare earth resources are greatest in China, Russia, Brazil – and Vietnam.  Of all the fossil fuel producing countries, it is the US, China, Russia and Canada that could most easily transition to green energy resources. In fact it is ironic that the US, perhaps the country most politically resistant to change, might be the least affected as far as raw materials are concerned. But it is important to note that a completely new set of countries will also find their natural resources are in high demand. The Organization of the Petroleum Exporting Countries (OPEC) is a group of 14 nations that together contain almost half the world’s oil production and most of its reserves. It is possible that a related group could be created for the major producers of renewable energy raw materials, shifting power away from the Middle East and towards central Africa and, especially, South America.  This is unlikely to happen peacefully. Control of oilfields was a driver behind many 20th-century conflicts and, going back further, European colonisation was driven by a desire for new sources of food, raw materials, minerals and – later – oil. The switch to renewable energy may cause something similar. As a new group of elements become valuable for turbines, solar panels or batteries, rich countries may ensure they have secure supplies through a new era of colonisation.  China has already started what may be termed “economic colonisation”, setting up major trade agreements to ensure raw material supply. In the past decade it has made a massive investment in African mining, while more recent agreements with countries such as Peru and Chile have spread Beijing’s economic influence in South America. Given this background, two versions of the future can be envisaged. The first possibility is the evolution of a new OPEC-style organisation with the power to control vital resources including silicon, copper, lithium, and lanthanides. The second possibility involves 21st-century colonisation of developing countries, creating super-economies. In both futures there is the possibility that rival nations could cut off access to vital renewable energy resources, just as major oil and gas producers have done in the past. On the positive side there is a significant difference between fossil fuels and the chemical elements needed for green energy. Oil and gas are consumable commodities. Once a natural gas power station is built, it must have a continuous supply of gas or it stops generating. Similarly, petrol-powered cars require a continued supply of crude oil to keep running.  In contrast, once a wind farm is built, electricity generation is only dependent on the wind (which won’t stop blowing any time soon) and there is no continuous need for neodymium for the magnets or copper for the generator windings. In other words solar, wind, and wave power require a one-off purchase in order to ensure long-term secure energy generation.  The shorter lifetime of cars and electronic devices means that there is an ongoing demand for lithium. Improved recycling processes would potentially overcome this continued need. Thus, once the infrastructure is in place access to coal, oil or gas can be denied, but you can’t shut off the sun or wind. It is on this basis that the US Department of Defense sees green energy as key to national security. A country that creates green energy infrastructure, before political and economic control shifts to a new group of “world powers”, will ensure it is less susceptible to future influence or to being held hostage by a lithium or copper giant. But late adopters will find their strategy comes at a high price. Finally, it will be important for countries with resources not to sell themselves cheaply to the first bidder in the hope of making quick money – because, as the major oil producers will find out over the next decades, nothing lasts forever."
"The Paris climate deal shows that the international community finally gets the science. Our leaders have publicly committed to the idea that we need to decarbonise our energy supplies and undertake a radical transformation of the global economy. But the challenge that Paris has presented the world with is how to convert that rhetoric into the laws and regulations needed to make the goal of the agreement a reality. The final text provides little detail on implementation, just a complex web of pledges with no certainty of when or if they will be fulfilled. One of the biggest gaps between the reality of our climate situation and the text of the Paris Agreement is in the absence of two sectors that are major contributors to the world’s greenhouse gas emissions. Shipping and aviation were referred to in the world’s previous climate change deal, the Kyoto Protocol, and were still referred to in the draft of the Paris Agreement until just a few days before it was signed. But they disappeared from the final text, perhaps in an attempt to secure a stronger agreement. This is important, because in combination they are a large and growing share of total CO2 emissions. Under current policy and projections, assuming that the world’s total carbon emissions fall by enough to prevent more than 2℃ of warming, by 2050 shipping and aviation could contribute 40% of our CO2 output. Failure to control these sectors will jeopardise the fulfillment of the Paris “well below 2℃” ambition. Had shipping and aviation been included in the deal, it would most likely have obliged the international bodies responsible for the sectors – the International Maritime Organization (IMO) and the International Civil Aviation Organisation (ICAO) – to develop emissions policies to meet the Paris targets. It would have sent a clear signal about the importance of the sectors in the world’s efforts to combat climate change, to two organisations that have a poor track record of action on greenhouse gas emissions. Under current policy, shipping’s CO2 emissions are expected to rise by 50-250% by 2050. Paris gives us a target of reaching net-zero carbon emissions around that time, giving us little more than a ship’s economic working lifetime (typically around 30 years) to turn things around. Exactly what contribution shipping will make is unclear but there will certainly be no room for the sector’s currently expected 1.2-2.8 gigatonnes of carbon emissions in 2050. Fortunately for shipping, there are plenty of opportunities to address CO2 emissions. The efficiency of both the world’s trade system and the ships that power it can be substantially improved with better logistics and technologies such as friction-resistant coatings and lubrication, and even simply reducing ship speeds. There is a fantastic potential for wind andsolar-powered ships. And ships have the storage capacity for alternative fuels such as hydrogen and ammonia, which are typically less energy dense and so take up more space than fossil fuels. For aircraft, the timescale of the challenge is similar. Commercial aircraft have a lifespan of around 30 years and demand is growing. But the scale of the technological challenge is greater. There are some further energy efficiency opportunities such as making planes lighter using more composite materials, more aerodynamic designs to reduce the amount of fuel needed, and alternative propulsion systems such as high-bypass turbofans and open-rotor engines. But unlike with ships, we cannot substantially reduce a flight’s CO2 by reducing aircraft speed or using on-board renewable energy sources. And the weight and space limitations make anything but the most energy dense fuels extremely costly. As a result, biofuels are regularly suggested as a key way to decarbonise aviation. But these cannot solve the non-CO2 climate impacts of flying. For example, aircraft contrails can impact cloud formation and deposit aerosols into the atmosphere, a problem that as yet has no straightforward solution.  The other major challenge for the sectors is that none of these technological solutions will occur without further meaningful regulation. This will have to be led by specific targets and trajectories defined by the sectors’ governing bodies and could include objectives for vehicle CO2 emissions, or new market-based mechanisms to drive companies to change their new and existing craft. Oil remains a fantastically cheap and reliable source of energy, and fuel is a key component of a ship or plane’s operating costs. So without such regulatory changes, the industry is highly unlikely to simply accept more expensive fuel costs. Achieving that regulation in the shipping sector will be difficult for at least two reasons. By recognising a difference between rich and poor countries, the Paris Agreement contradicts the International Maritime Organisation’s non-discrimination principle, which treats all countries equally, creating a conflict that could hamper change. There are also fears that mitigating greenhouse gases from shipping could increase the costs of transport in a way that might damage world trade and economic growth. This is likely one of the reasons the sector was left out of the Paris text. These two regulatory hurdles must be overcome, and for the sake of the shipping industry – and the planet – they must be overcome fast. Any procrastination will only increase the rate of change required by the sector and so the turbulence it will experience. Fortunately, the IMO and ICAO are UN agencies driven by governments and so we could see the mood and rhetoric of the Paris summit percolate into these bodies. But that requires governments to be consistent, something they are not historically good at in these sectors. The world needs to watch and hold its politicians and businesses to account more than ever. And these two sectors need to prepare for some fascinating and rather dramatic changes."
"
Share this...FacebookTwitterCritical German climate site wobleibtdieererwaermung.de (WBDE) reports that the earth’s surface is cooling, and presents the latest chart from NCEP:

 
As of April 11, the measured global values continue to decline (black curve) as do the computed values for April 18. Source: www.karstenhaustein.com/climate.php.
The time-delayed post El Niño cooling is now showing up in the UAH and RSS satellite data.

 Source: UAH Global Temperature Update for March, 2017: +0.19 deg. C
Foremost the atmosphere over the ocean – the largest storage of energy on the planet – cooled significantly over the month of March.
Especially remarkable is the 0.29°K drop in temperature above the global oceans measured by the UAH, and is now only 0.09°K above the WMO 1981-2010 climate mean.




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The plot shows the anomaly from the 1981- 2010 mean, UAH satellite temperature in the atmosphere 1500 meters over the sea surface. (TLT). The rose colored curve shows the 37-month running mean of the ARGO buoys which measure the water temperature 2.5 meters below the sea surface. Source: www.climate4you.com/
The RSS satellite data also showed a significant drop in global surface temperature above the seas falling from +0.38°K above the mean to 0.18°K above the mean — a drop of 0.20°K.

Chart: Woodfortrees.org
Although there have been some ups and downs over the past months, the overall global surface temperature trend remains steeply downward, dropping more than 0.6°K since early 2016.
Moreover, the surface temperature above the oceans is significant as the oceans cover more than 70 percent of the earth’s surface.
The overall negative linear trend will likely continue over much of 2017 as the delayed effects of the disappeared El Niño work their way into the satellite data.
So is the pause over? WBDE writes:

Despite the warming effect of the powerful 2015/16 El Niño, the unfalsified satellite date show that the year 2016 did not produce any new significant global heat record compared to the 1998 El Niño year. […]
The claimed global warming by the IPCC climate models has been missing for almost 20 years! And that with continuously rising atmospheric CO2 concentrations!”


The question remains: what happens in the years and decade that follow? A new slightly higher plateau, or stuck at the current old plateau?
Share this...FacebookTwitter "
"The Amazon rainforest is described as the planet’s lungs for good reason. So much carbon is locked up in its trees that protecting the forest is a must if we want to do something about global warming. However, reducing the CO₂ that is emitted when a tropical forest is destroyed depends not only on stopping the actual deforestation, but also on fighting wildfires within the forest.  In a new study published in Nature Communications we show that forest fires are responsible for a huge portion of the carbon emitted from the Brazilian Amazon. During drought years, these fires can emit around a billion tonnes of CO₂. That alone is double the amount of carbon effectively emitted through deforestation in the Amazon. Humans are throwing vast amounts of CO₂ into the planet’s atmosphere. While in developed countries such as the US and UK most of the emissions come from industrial activities, in developing tropical countries such as Brazil, most come from forests being chopped down and burnt.  Yet while deforestation is already recognised as an important driver of carbon emissions, wildfires under the forest canopy present a less visible but still pernicious threat. To figure out just how bad the problem is, we combined satellite data on the current climate, atmospheric carbon content and the health of forest ecosystems. Our work revealed that emissions from tropical forest fires are growing, even though they are still not normally accounted for in estimates of national emissions. Wildfires in the Amazon are not natural events, but are instead caused by a combination of droughts and human activities. Both anthropogenic climate change and regional deforestation are linked to increases in the intensity and frequency of droughts over Amazonia.  This kicks off a nasty cycle: as trees have less water during such droughts, their growth slows and they’re less able to remove CO₂ from the atmosphere through photosynthesis. Trees then shed extra leaves or even die, which means more wood and leaves are ready to burn on the forest floor and, without a dense canopy to retain moisture, the forest loses some of the humidity which acted as natural fire prevention.  These changes are exacerbated by “selective logging” of specific tree species, which opens up the canopy and further dries out the understory and forest edges, which are drier than the interiors. The result: normally fire-proof rainforests become flammable. The resulting wildfires have reached a worrying level, burning millions of hectares during the recent El Niño. But the worst could still be to come, as the unusually warm conditions in the Atlantic or Pacific oceans that have caused previous droughts are expected to intensify. So far this century the Amazon has already experienced three “droughts of the century”, in 2005, 2010, 2015-2016. If the climate science is accurate, and if no action is taken to efficiently predict and avoid fires occurring, we expect that carbon emissions from forest fires would be sustained even if deforestation ended overnight. As one of the signatories to the Paris agreement on climate change, Brazil is committed to reducing its emissions to 37% below 2005 levels by 2025. A major reduction in deforestation rates over the past decade is a great start. However, deforestation policy doesn’t help reduce forest fires and consequently isn’t fully efficient in mitigating carbon emissions from the Amazon.  Brazil has made substantive advances in reporting emissions from deforestation. It now needs urgently to focus on incorporating CO₂ losses from wildfires into its estimates. After all, those fire emissions are expected to increase in future, thanks to more extreme droughts, an expansion of selective logging, and the ongoing use of fire to manage pasture or to remove regrowing vegetation on farmlands.  Given that fire is an essential part of many smallholders’ livelihoods, it is critically important to implement sustainable and socially-just policy responses. Brazil should start by reversing the budget cut to the organisation that overseas its only existing fire-prevention programme. It should also avoid selective logging in regions that are prone to fires, and ensure forest management always factors in long-term fire-prevention. In summary, these findings are not only critical for policymakers in Brazil to strengthen the efforts of effectively quantifying and limiting carbon emissions from forest fires in the years ahead, but also to other tropical nations to tackle the potential impacts of drought-induced fires on their carbon budget. These new findings bring critical information for nations to prepare for urgent actions aiming to mitigate the potential increase of fire emissions in response to the intensification of droughts in tropical ecosystems."
"
Share this...FacebookTwitterThe earth is greening and 16 other comments on climate hysteria
By Simon Rozendaal
(Translation from his article in Netherlands Elsevier’s weekly Magazine, January 21st, 2017, with author’s permission)
In fact vegetation is thriving, figures for wind power are misleading, “sinking” islands are not sinking, safer nuclear energy is in the offing, and more that can be said loudly now that there is a real climate skeptic in the White House.
When Donald Trump was elected as president of the United States of America, the first thing that the Dutch media reported with unconcealed revulsion was that he was a ‘climate skeptic’.
The exact nature of this exotic species may not have been immediately clear to the reader or viewer of the Dutch media, because climate skeptics are consistently being ignored by them. But everyone should understand that it is something awful – even worse than a populist.
In Europe, and certainly in the Netherlands, global warming is seen as a threat, outclassing all other threats, viewed as being even much more dangerous than the rise of Islamic terrorism. One doesn’t need to be a fan of Donald Trump to frown upon this presumption.
Skeptics have been mislabeled
Much of what people daily hear about climate and climate skeptics is demonstrably wrong. The climate adviser to former President Barack Obama, Steven Koonin, tried in 2014 to infuse some nuance into the debate by arguing in The Wall Street Journal that the science is not unambiguous: not all experts believe global warming is caused entirely by man.
Nor is it certain that the current, fairly mild warming will continue unconstrained in the coming decades. What is certain is that the earth is rapidly greening, courtesy of the infamous carbon dioxide (CO2). And that’s just one of the many comments one could make on climate hysteria.
Ice melting everywhere, but not around Antarctica
Sea ice around Antarctica is growing by about 1.5 percent per decade. Even the IPCC (Intergovernmental Panel on Climate Change – the climate panel of the United Nations), which hardly ever shies away from a little exaggeration – confirms this in its reports.
The most likely explanation – presented by Richard Bintanja of the Netherlands Royal Met Office (KNMI) – is that the melting of the ice caps on the main land of Antarctica produces a layer of fresh water on the surrounding seawater. According to the laws of physics fresh water freezes more quickly than seawater. Therefore, we sprinkle salt on our roads in winter. Thus, warming may lead to more ice. If this theory is correct, this phenomenon should disappear over thirty years, so that the sea ice would melt at the Antarctic as well.
The Earth isn’t out of whack
> The land area of the Marshall Islands – a chain of volcanic atolls in the Pacific Ocean – is not sinking, but rising. The sea level rise is offset by the washing ashore of sand.
> The rate at which the concentration of CO2 increases in the atmosphere, has slowed down since 2000. Presumably, as has been published in Nature Communications a few months ago, because plants absorb more carbon dioxide from the air.
> The same magazine also recently stated that the carbon stored in peat and bogs, is contained more firmly than previously thought. The probability that global warming will reach a tipping point because this carbon is released from the peat and swamp methane (which causes a 28 times stronger greenhouse effect than CO2) is small.
10 the cost to put man on the moon for 0.17 Celsius
Critics claim that the Netherlands Energy Agreement [comparable with the Energiewende in Germany], which aims at a share of 16 percent renewable energy by 2023, will cost 100 billion euros — more than a couple of major projects together, such as the Delta Works, the Betuwe railway, the tunnel under the Green Heartland and the acquisition of JSF fighter plane.
The annual costs of the international climate agreement, concluded in Paris last year, is estimated to be between $ 1,000 and $ 2,000 billion. In comparison: the man-on-the-moon-program cost in today’s value approximately $100 billion. On the Manhattan Project, which produced the American atomic bomb, 24 billion was spent (adjusted for inflation).
That means that international climate policy costs each year ten times more than the man-on-the-moon-program and the development of the atomic bomb together. If climate policy intentions come true, the result will be only a net 0.17 degrees less warming by 2050, as has been calculated by the Danish (skeptical) environmentalist Bjørn Lomborg, founder of the think tank ‘Copenhagen Consensus Center’.
This enormous expenditure will not only affect the wallets of citizens, but also the environment. After all, economic growth in the second half of the twentieth century, did not only produce more disposable income for many, but also generated the money to tackle the pollution of forty years ago.
Geed news: the earth 14% greener than 1980
The concentration of carbon dioxide (CO2) in the atmosphere has increased from 280 ppm (parts per million) in 1800 to over 400 now. In percentage terms this rise looks less scary: from 0.028 to 0.04 percent of the total atmosphere.
This increase does not only have negative consequences. To the contrary, plants convert sunlight using CO2 into carbohydrates which become part of their mass. For them, carbon dioxide is a yearned-for fertilizer. The increase in carbon dioxide has greened the earth, said Ranga Myneni of Boston University in a lecture in 2011. On the basis of satellite images he concluded that the earth had become 14 percent greener over the past thirty years. The increase manifests itself everywhere, even in arid regions such as the Sahel.
Myneni’s paper appeared in April last year in Nature Climate Change. 32 researchers from 24 international institutions had participated in the exercise. In 2011 Myneni still believed that the half of the increase in plant growth could be attributed to CO2.
Currently, he estimates that this figure should be 70 percent. One of his co-authors, Zaichun Zhu from Beijing University, points out that a green continent of the size of two times the U.S. has been added to the earth because of CO2 fertilization.
Bonus of warming outweighs the negative factors
The Dutch should know better than anybody else that plants love CO2. Since 2005 the Shell refinery in Pernis (near Rotterdam) supplies carbon dioxide to greenhouses in South Holland through pipelines. Thus, hundreds of Dutch growers can achieve higher yields.
The Swedish Nobel Prize winner for chemistry, Svante Arrhenius, who more than a century ago was the first in the world who presented the theory of global warming, was also aware that an increase in CO2 would have beneficial effects.
In his book ‘Worlds in the Making’ (1908) he predicted that the earth would warm up and that agricultural yields would rise. As the discoverer of the greenhouse effect, this global greening was more important to him than global warming. He might haven been surprised to learn that today the reverse is the case. In fact, the positive effects haven been skillfully swept under the carpet.
Climate skeptics are being ignored, vilified and badgered by their universities
William Happer (77) is emeritus professor of physics at Princeton University (USA). He was dismissed in 1993 from the US Energy Department as Vice President Al Gore did not like his critical views. Greenpeace is conducting an ongoing slander campaign against Happer on the Internet.
Judith Curry (63), former professor at the Georgia Institute of Technology (USA), believes that there is some man-made global warming, but in her view the role of nature is dominant. A few weeks ago she resigned, partly because there is too much ‘insanity’ and ‘alarmism’ in climate science.
The Swedish Professor Lennart Bengtsson (81) was director of the European ECMWF weather bureau and the Max Planck Institute for Meteorology. In 2014 he joined the advisory council of skeptical Global Warming Policy Foundation (GWPF). He became the target of an fierce orchestrated campaign of mud-slinging, and so he felt forced to withdraw from the council within two weeks.
A study by Roger Pielke Jr. (48), professor at the University of Colorado (USA), showed that the number of storms and hurricanes has not increased. Subsequently, Pielke – who believes that humans contribute to global warming – was so vilified that he has chosen a different field of research.
Trump: ‘Sometimes it gets warmer, sometimes cooler.’
The president of the United States, Donald Trump, is called a climate skeptic (in The New York Times even a ‘climate denier’). He has appointed several people in his cabinet, who are known to be climate skeptics.
He wants step out of the Paris’ climate agreement as soon as possible and said: ‘Sometimes it gets a little warmer, sometimes cooler.’ That is called weather. It has often been alleged that Trump said that man-made global warming was a Chinese fabrication. But it is ignored that he emphatically said that this was meant as a joke.
However, he did say: ‘I think climate change is just an expensive, very expensive way to raise more taxes.’
Many journalists are not objective about climate
Alan Rusbridger, former editor of the British newspaper The Guardian, said recently in an interview with NRC Handelsblad [a Dutch daily] that his newspaper had decided in 2014 to take action against climate change. The newspaper was campaigning against oil companies under the motto: ‘Keep it in the ground.’
Rusbridger, who is now at the University of Oxford, admits that his newspaper thereby clearly exceeded all boundaries of objectivity and independence, but in this case the goal justifies the means.
Jelmer Mommers, reporter on climate and energy for the internet newspaper ‘Correspondent’, says and writes repeatedly that objective reporting like the ‘old media’ is not a priority for him. With his articles he wants to contribute to the fight against global warming.
Henk Hagoort, until recently head of the Dutch Public Broadcasting Corporation, has admitted several times that he does not want objective reporting on climate. He thinks that the television network should encourage Dutch politicians to take urgent action against climate change. During a radio discussion Hagoort stated he refused to make programs that questioned the existence of a climate problem.
The many hidden costs of offshore wind
Offshore wind technology is progressing rapidly. For instance, Shell believes it can build wind farms that are profitable at 5.45 cents per kilowatt hour. Four years ago that figure was still 17 cents. Good news, partly because offshore wind blows twice as often and twice as hard. And partly because the learning curve leads to more efficient production.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




And thus ‘only’ 300 million subsidy has to be spent on wind farms, cheers Minister Henk Kamp (minister of economic affairs, Classical Liberals, VVD). But it should be noted that, ultimately, the real price of major projects is often twice as high than the budgeted one. Also, the low price of offshore wind power is still well above the market price, which is now just over 3 cents, and will fall further below 2 cents according to experts.
The integration of wind power also requires additional investment. For example, the high-voltage network has to be improved and strengthened earlier than planned. Backup must be secured by gas plants that can quickly respond to rising demand when the wind is not blowing. Storage is required in case the wind blows, but there is no demand. The cost of all this is not attributed to wind, but ‘socialized’, i.e. passed on to the consumer.
Producers and government hold out false hopes of low electricity prices of wind power. But the reality in Denmark and Germany proves to be different, since electricity prices in these countries are among the highest in the world. It is nice that prices for wind power have fallen so rapidly, but in the mean time citizens will be facing rising energy bills by up to thousands of euros per year.
It’s like a salesman who tries to palm off a cooking-plate on you, a little bit more expensive, but very fashionable. Just before you leave the store, the friendly smiling man tells you: ‘You do realize, however, that you need to purchase a new set of cookware for this wonderful cooker?’ Oops! And just when you are about to leave the shop, he adds: ‘It is also advisable to buy a new extractor … indeed even a new kitchen.”
Fossil fuels are more subsidized than wind power
Mark Rutte (Netherlands Prime Minister, Classical Liberals, VVD) said in 2010 during the election campaign: ‘Wind turbines are not running on wind, but on subsidies.’ Proponents of wind are embarrassed by these comments. And so they reciprocate with the statement that fossil fuels are even more heavily subsidized.
In a sense this is true. But it is like comparing apples with oranges. In countries such as Venezuela, Indonesia and Mexico, poor people are being subsidized so that they can buy petrol.
In Western countries, the generation cost of electricity amounts to a few cents per kilowatt hour. However, in addition to all kinds of taxes and surcharges, the citizen has to pay 20 cents. These surcharges are partly explainable (transmission and distribution), but they also are in reality simple taxation. To promote the interests of national industry in international competition, these are excluded from these disguised taxes. Companies pay half the price for power than consumers.
It’s sloppy reasoning to compare these two forms of ‘subsidy’ with the subsidies to wind turbines, solar cells and electric cars, which are currently not (and maybe never) competitive without subsidies.
Back to prehistory: chop down trees. Green!
Most of the ‘green’ electricity generated in the Netherlands, does not come from wind turbines or solar cells, but from coal plants. In these plants so-called ‘biomass’ is mixed with coal. Wood pellets, the size of a suppository, constitute the major form of biomass.
Take the Amer-9-coal power plant in Geertruidenberg. It is even considering burning more wood pellets than coal. To that end, trees are being chopped and turned into wood pellets in the southern United States. Subsequently they are being transported in containers by ocean liners to Rotterdam and then by barges to Geertruidenberg via the Bergsche Maas.
The owner of the coal power plant, the German energy company RWE, will receive an estimated yearly subsidy of 1 billion euros. All this to achieve the renewable energy objectives of the Netherlands Energy Agreement.
This illustrates just how misguided energy policy has become under the influence of climate hysteria. Thus, the export of timber from the United States to the European Union has quadrupled in recent years. Wood – traditionally fuel of primitive societies – is back in Europe.
Today there are more polar bears than ever before
The polar bear is the favorite poster child of the melting of Arctic ice, as predicted by climate activist and former vice president Al Gore. He stated in 2009 that the Arctic would be ice-free in the summer of 2013. This would imply that the polar bear – which lives around the North Pole – would gradually become extinct.
The truth is that polar bears are doing fine. Of course, the bears suffer from melting sea ice and they have partly moved to more populated areas in Alaska and Canada to find food. But there are more polar bears than before. In 1966 there were only 10,000, now more than 25,000. According to the Canadian zoologist Susan Crockford, it is because the hunting of polar bears is better restricted than before. So hunting was a bigger problem than global warming.
Better nuclear energy is in the offing
Nuclear power is already safe and clean. Of all energy the atom is also the most energy intensive: a wheelbarrow uranium can generate as much electricity as an entire battery of wind farms in the North Sea. The problem is that so much misinformation has been disseminated that many people do not realize that although the nuclear energy does represent certain risks, it still has a very good safety record, despite Harrisburg, Chernobyl and Fukushima.
The good news is that there are new types in the offing (the thorium and the molten salt reactor) that are even safer. Even the environmental movement, traditionally a fierce opponent of nuclear energy, has to admit that it is not easy to come up with objections to the new nuclear power. The problem is that it will take another twenty years before various options become available.
Ideal transition fuel
Natural gas (and shale gas because that is the same substance: methane) produces 50% less CO2-emission than coal. So replacing oil and coal with natural gas is a good option to achieve reduction of CO2-emissions. Yet, in his recent Energy Agenda minister Henk Kamp (VVD) announces that new homes will not be connected to the gas grid and that existing homes will become gas free. All homes must be gas-free in 2050.
This is a bizarre decision. Because of its low CO2 emissions, easy and wide availability and relatively low price, natural gas is the ideal transition fuel to bridge the period until 2050 and even 2100, when alternative energy options (socially acceptable nuclear power, more efficient solar cells) will probably be competing without subsidy with cheap coal power.
How shale gas was thwarted 
Shale gas has boosted the U.S. economy and made a major contribution to the decline of American CO2 emissions since 2007. In ‘Between pride and hysteria’ (2015), energy journalist Remco de Boer explained why shale gas did not succeed in the Netherlands. Some environmental activists were looking for a new issue, people living near drilling sites feared value losses of their homes, politicians and administrators had weak knees. De Boer on the ability of citizens to influence policy: ‘Three people with a banner and an alarming message in front of the town hall, attended by the local newspaper, and you have already made a lot of progress.’
Pinstripe activism versus multinationals
Climate activism is no longer confined to public demonstrations. They go to court (as the Dutch action group Urgenda did in 2015) or the stock market, such as the Dutch ‘Follow This’ (with 1,800 members and 6 million shares) and the British ‘Share Action’-groups. They are particularly targeting Shell.
The emergence of pinstripe activists as Mark van Baal (founder of ‘Follow This’) seems to have success. Shell, Unilever and pension fund ABP, are increasingly posing as green and sustainable businesses.
By some this is seen as an argument that wind and solar energy represent the future. But that’s nonsense. Earlier Shell has invested in nuclear energy, but stepped out of it again. Ditto for solar cells. Shell has invested in windmills and bio alcohol. It is putting bets on several horses and watching how the markets (read: subsidies) will develop.
It is above all green window-dressing with which multinationals adorn themselves. At a climate conference it was suggested that CEO Paul Polman of Unilever should have a chat with president Trump about sustainability. Yet, Unilever manufactured margarine with trans-fatty acids, which has caused many people to die prematurely. With its production of palm oil in Southeast Asia, Unilever has since contributed to the extinction of the orangutan. In an interview Polman advised people not to shower for too long, and in having done so, his company is now suddenly on record as being sustainable.
Relationship between CO2 and climate is not one-to-one
Even when our ancestors had no cars, there was climate change. CO2 is only one of many factors that drive the climate. This is evident from the graph that shows the relationship between CO2 and temperature since 1900.
The rise of CO2 concentration in the atmosphere shows a relatively straight line, but the temperature varies. From 1900 to 1940 it increased, between 1940 and 1970 it slightly declined, between 1970 and 1998 the temperature rose again, but since 1998 it seems to have stabilized, although alarmists try to ignore, deny or qualify this (‘at sea, the warming continues’, so they say).
When the temperature in 2015 and 2016 reached new highs – partly due to a strong El Niño, and a spike in periodically oscillating ocean currents – it was said that the warming was back again.
Now that El Niño is over (late 2016), the global temperature has dropped again and it is generally expected that 2017 will not break any records. All in all, it seems that global warming pause or hiatus has lasted now almost twenty years.
Conclusion
Keep a cool head – there is time to think.
The earth has indisputably warmed up. With the caveat that this process has been going on for nearly 20,000 years, since the last ice age. It accelerated since the Little Ice Age – the period from 1500 to 1800 – when Hendrick Avercamp and other masters of the Low Lands painted their famous winter scenes.
The human race had no impact on the alternation of ice ages and warm periods in the geological past. These processes were the result of the position of the Earth’s axis and oscillations in the orbit in which the Earth moves around the sun. Nor had our ancestors anything to do with the warming over the last few thousand years.
The period starting with 1900 is a different story. Then the warming was undoubtedly reinforced by the burning of fossil fuels. Almost everyone agrees on that. — even climate skeptics. It is not true that they deny the existence of global warming and the fact that man contributes to it.
The debate is about the share of man in global warming. The IPCC, the alarmist prone climate panel of the United Nations, concluded in a recent report: ‘It is extremely likely that more than half of the observed increase in the surface temperature between 1951 and 2010 has been caused by man’. In other words, maybe almost half of the current warming was not caused by us.
The IPCC itself indicates that the science is not yet settled. Climate change is not black and white. Between ‘climate change is a fairytale disseminated by the Chinese’ and ‘the science is settled, leave those fossil fuels in the ground’, there are fifty shades of gray. Consequently, there is no justification for the current hysteria, whereby any kind of weather phenomenon is framed as evidence that the climate is upset and politicians of left and right, activists groups, multinationals and even generals, pretend that climate is world problem number 1, and so suggest that we could control weather with higher taxes.
Of course, ultimately we need to switch to non-fossil fuels. Yet we still have a lot of time to do so. For the moment it seems that the earth is more robust than the alarmists believe. For almost twenty years we are experiencing mild warming and CO2 appears to have a beneficial, greening effect.
There are plenty of reasons telling us that keeping a cool head is the reasonable thing to do.
=============================================
Simon Rozendaal is a chemist (honorary member of the Royal Dutch Society of Chemists, KNCV), and has been writing on science for over forty years, first for NRC Handelsblad and for Elsevier, the leading Dutch weekly news magazine, for thirty years now.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s Deutsche Welle (DW) here presents a commentary by Hans Joachim Schellnhuber, the director of German ultra-alarmist Potsdam Institute for Climate Impact Research.
Professor Schellnhuber fears that the planet could warm even as much as 12°C if man does not act quickly to totally eliminate greenhouse gases. He adds that he “has all the evidence” and that climate scientists “are only trying to do a job” for us.
Hat-tip: Reader Dennis A.
With the US Administration pledging to back out of the Paris climate treaty, Schellnhuber is now calling on scientists “to take to the streets to counter climate denial“.
If we want to hold the 1.5 degrees [Celsius; 3.6 degrees Fahrenheit] line, which is the ambitious goal of the Paris agreement, we have maybe 300 billion tons left – more or less the budget of 10 years – if we do business as usual. If we want to hold the 2 degrees line, which is more realistic, we have another 20 to 30 years to go, but no more actually. So it’s a very tight budget.
It’s quite mind-boggling – for example, by 2030, we have to phase out the combustion engine. And we have to completely phase out the use of coal for producing power. By 2040 we will probably have to replace concrete and steel for construction by wood, clay and stone.
We are at the crossroads now: We either say: this thing is too big for us, this task cannot be done. [Then] we will be transformed by nature, because we will end up with a planet warming by 4, 5, 6 or even 12 degrees. It would be the end of the world as we know it, and I have all the evidence.”
In short, the eccentric professor from Potsdam is essentially claiming that unless we return to living in mud huts with thatched roofs and forego the fundamental amenities of modern life, our great grandchildren will end up living in super tropical hot-house conditions.
Fortunately Schellnhuber’s view is a rare one that is out on the remote fringe. Other climate scientists hold a far more sober view, like Prof Judith Curry. Interestingly, climate hardly seems to be a concern for Schellnhuber’s boss, Angela Merkel, who yesterday did not mention climate change once during her press conference with President Trump. In fact much of the discussion was about trade, economy …along with a little fake news and wire-tapping.
 
Share this...FacebookTwitter "
"It has become a mantra here that Paris 2015 is not Copenhagen 2009. This time, the US and China are on board; the price of renewables has dropped by more than half; the vast majority of countries here have already pledged emission cuts and Paris is seen as a “staging post” not a final destination. But how different is Paris 2015 for the 3,700 media representatives accredited here? Like Copenhagen, where there were 4,000 from nearly 120 countries, the sheer volume of journalists makes the summits two of the most media-covered political events ever. So it’s a daunting task for anyone analysing the bewildering array of content the journalists are producing.  A preliminary look at some of the hundreds of articles already published by the mainstream media suggests that, as in Copenhagen, the main angles are the process of the negotiations, and the political wrangling behind the sticking points. So in Paris, much has already been published about the position of India, whereas in Copenhagen there was more about China. More interesting are the other aspects of the climate change “mega-story” that journalists choose to cover beyond the negotiations. One strong impression is that since Copenhagen, as one veteran agency reporter put it to me recently, “climate change has moved from being just an environment story to a business and energy story”.  The Financial Times, for instance, has long been interested in climate change for its business readers (often presenting it a risk issue). It covered the Copenhagen summit extensively. But this time round, like many legacy media organisations, the FT has added a live blog, videos, a beginners’ guide, and a special index on the Paris talks. Another difference is that journalists here receive an endless stream of announcements of new initiatives on renewables, technology and business risk. And many of them have received extensive coverage – the new initiative by Bill Gates and Mark Zuckerberg to boost clean energy research in the new “Breakthrough Energy Coalition” predictably hit the headlines beyond the business press. But so did the pledge by the US and 18 other countries to double funding for similar research, India’s International Solar Alliance aiming to boost the use of solar power, and the announcement of an international Financial Stability Board, chaired by Michael Bloomberg, to manage threats from climate risks. In the same vein, the Washington Post headlined a recent piece as possibly “the biggest news yet to come out of the Paris climate meeting”.  It was not about some breakthrough in the negotiations, but about a new initiative to deliver at least 300 gigawatts of electricity-generating capacity to Africa by 2030, all from clean or renewable energy. Such stories are one indication of how media narratives about climate change are becoming more about hope and opportunity and less about the more traditional doom and gloom. In part, this may be due to a realisation that the transition to a low-carbon economy is inevitable, even though the pace of it is uncertain. But for some media organisations, such as the Guardian, more messages of hope form part of a deliberate editorial policy driven in part by readers’ wishes. Another major change since Copenhagen is the boom in niche sites about climate change and the rise of successful “digital natives” such as Huffington Post, Vice and BuzzFeed giving priority to environment coverage. At first sight, BuzzFeed is offering its traditional diet of listicles, photo galleries, quizzes and humorous content. But a closer look shows that much of its coverage is positive and hopeful. They and other new players seem to offer no space to sceptical voices. The “Climategate affair” received considerable coverage at the time of the Copenhagen summit, offering plenty of traction to deniers particularly in the UK and US. But this time round there seems to be a consensus that deniers have become much more marginal. Unilever boss Paul Polman recently described them as “the only endangered species”. Matt Ridley, the Conservative hereditary peer who describes himself as a “lukewarm” sceptic, is an exception. He has appeared in several right-leaning newspapers in the US, UK and Australia. But several climate scientists have come out fighting, laboriously picking holes in a recent interview he gave to the BBC. A crucial test remains for the media at the end of the summit. The wise money is on some sort of deal being signed here. The outcome is likely not to be enough to keep warming below 2℃, but nevertheless an important step on the path. It is a truism that journalists like binary stories with winners and losers, and success or failure – nuance will be more of a challenge."
"Gill Andersen is, as far as she knows, the only British woman farming the lowlands of central Jutland. And after 32 years, she doesn’t think much of Denmark’s plans to meet new emissions targets by returning much of her land to peat bog. “I don’t think there are any farmers who want to ruin the climate,” she says. “But the answer is not to flood our land and kill all the trees.” Peat may seem like a fringe issue in the battle against climate change, but according to a recent study by Aarhus University, flooding cultivated former peatlands could cut Denmark’s emissions by 1.4m tonnes of carbon dioxide a year – about the same amount produced by the capital city of Copenhagen. With Denmark now committed to the world’s most ambitious climate goals, these savings are in the spotlight. The ruling Social Democrats struck a deal this month with supporting and opposition parties to enshrine these climate goals in law. “It’s the most ambitious climate law in place at the moment,” says professor Katherine Richardson at Copenhagen University. “This has been a social tipping point. Nobody in Denmark a year ago dreamed we could be in a situation like this now.” Denmark, currently on track to reduce emissions by 48% by 2030, has now committed to reduce them by 70%, and to go carbon neutral by 2050. When the climate emergency and the environment unexpectedly became the main issue in the run-up to Denmark’s June election, the now prime minister, Mette Frederiksen, hurried to Jutland, to the Vejen Mose peat bog on the edges of Andersen’s land, to underline her green credentials. Frederiksen came to see Andersen’s neighbour, farmer Henrik Bertelsen, who had already planned to flood 90 hectares, close to three quarters of his land. When former peat bogs are drained, organic matter trapped for thousands of years breaks down and releases carbon dioxide. Living peat bogs, on the other hand, absorb and trap carbon as they grow. Bertelsen’s scheme aims to reduce emissions by an estimated 2,000 tonnes of carbon equivalent a year, enough to offset the total climate impact of 350 Danes. “When people say that cultivating land like mine is one of the big problems and flooding land is key to reducing climate change, I think, ‘OK, I want to do that,’” he explains as we trudge through the sodden ground, cranes squawking all around us. Denmark’s political parties agreed at the beginning of this month to spend over the next decade 200m Danish kroner (£23m) a year on buying up land for reflooding, and work is likely to begin in 2020. In Denmark, opponents of climate action are in retreat. Even the far-right, anti-immigration Danish People’s party backed the law – quite something for a political party whose leader warned of “climate hysteria” in the election campaign and whose former chief talked of “climate morons”. Two small parties which represent just a dozen seats opposed the action, making its passing in February a formality. All future governments will have to abide by the climate goals. Denmark’s main business lobby, the Confederation of Danish Industry, is backing the 70% target and the Danish Agriculture and Food Council, the main agricultural trade body, aims to make the entire Danish food industry climate neutral by 2050. Jørgen Olesen, the Aarhus professor behind last year’s study on cutting agricultural emissions, is concerned that Denmark’s goals are so demanding that meeting them will mean farmers will have to cut food production as well as flood land. Denmark can only reduce emissions from agriculture by about 20% without reductions in food production, he estimates. “Given they have set themselves such a large emissions target, they might end up doing it, which in my view would be stupid,” says Olesen. Maria Reumert Gjerding, president of the Danish Society for Nature Conservation, believes Denmark will have to sacrifice the bacon industry. “We cannot be the pork factory of the world when we are on the brink of a collapse of world climate systems,” she says. “We import a lot of soy to feed to our pigs to export to China. That’s just not sustainable.” Such talk is too much, even for the pioneering Bertelsen, who plans to graze his beef steers on the flooded peat. He says, like it or not, global meat consumption is forecast to continue to grow for at least the next 30 years. “If we want to stop climate change, we have to produce meat where it is cultivated with the least climate impact,” he says. “So maybe it’s not such a good idea to stop producing it in Denmark and doing it somewhere else.” Back at Andersen’s farm, the two farmers look over Vejen Mose towards Bertelsen’s land on the other side of the bog. Andersen is worried that pulling up the draining pipes and flooding the land will kill trees. “Without the trees in front of the nearby motorway,” she says in her light Cheshire accent, “the noise from the traffic will come directly up the hills to us.” Andersen and her husband were instrumental in blocking one of Bertelsen’s earlier flooding schemes. Despite their disagreements, however, the two appear to be on good terms and Bertelsen is convinced that Andersen, and farmers like her, can be brought around. “Five to seven years ago there was more opposition to a project like this – mostly from old farmers,” he explains. “They would say: ‘I remember when we made this land, when we dug the ditches and put in the pipelines and it was fantastic.’ They can’t understand why we are turning it back. But they are getting older, and some of them are dying, and the younger farmers are different.” Andersen does appear to be wavering. Her Herefords might not tolerate wet, boggy soil, she says. “You could change them into water buffalo,” jokes Bertelsen. “But they’ve got horns,” she groans."
"As New Zealanders count down to the end of tumultuous year and look ahead to the election in 2020, the Guardian asked readers which questions they would like to pose to Jacinda Ardern. We will publish the prime minister’s answers on Monday, but here we lay out the topics that people in New Zealand felt were the most pressing.  Among the more than 700 questions sent in, many focused on the consequences of the Christchurch attacks. Some asked what was being done to plug intelligence holes, while others were concerned the March attack had divided the country in a “culture war” that had the potential to split communities in a way that Brexit has in the UK. A large number of readers also asked questions about the housing crisis, growing inequality and child poverty in New Zealand – in particular, the crisis in social housing. The standout theme was that housing was becoming unaffordable and many wanted answers to how the government was planning to address it. As the country approaches a population of 5 million in 2020 – a milestone that many New Zealanders who responded to our callout had thought would take longer – there were a significant number of questions about what was being done to manage the growing numbers of citizens and residents. Would New Zealand change its immigration policy? Would there be any changes for international students? The environment was another major theme. Many readers asked how the prime minister intended to reduce New Zealand’s carbon emissions. Others asked if Ardern thought the climate crisis had become too affiliated with left/right politics. The fractious Pacific Islands Forum in Tuvalu in August highlighted the emergency in the region, with small countries pleading with bigger nations such as Australia to act more aggressively on emissions. Ardern told the forum “Australia has to answer to the Pacific” on climate change, saying that New Zealand was doing what it could to limit global emissions to 1.5C and expected others to do the same. Readers wanted to know how much difference New Zealand’s efforts could make and how could Ardern influence other nations to follow her country’s lead. Could the prime minister form/influence an alliance of smaller countries to band together to help reduce emissions? Some of the questions posed to Ardern focused on foreign influence in New Zealand. In June, Canterbury University China academic Prof Anne-Marie Brady said she was “being watched” and living in fear of Beijing. One reader asked what was being done to counter Chinese influence and should Ardern take a more principled stance towards Beijing, given the detention of 1m Uighurs and other minorities in camps in Xinjiang province? Readers also wanted to know what the government would do if re-elected to ensure a free and independent media in New Zealand and how the government intended to combat sexism in schools. But it wasn’t all macro issues. One reader wanted to know something slightly more quotidian: what is the best away to cook snapper? The Guardian asked Simon Bridges to respond to readers’ questions, but he declined."
"
Share this...FacebookTwitterAturan Permainan DominoQQ utk Pemula! Domino QQ, pula dikenal sbg Qiu Qiu atau Domino Indo ialah wujud poker yg teramat ternama di Indonesia. Ini terkait dgn pai gow, yg yakni permainan judi domino Asia.
Kadang-kadang, ini mampu sedikit membingungkan buat mendalami permainan dominoqq ini tapi demikian kamu melakukannya, itu menyenangkan & menciptakan ketagihan! Aturan utk game ini tercantum di bawah ini maka kamu mampu membacanya & mendapati pemahaman yg lebih baik mengenai bagaimanakah gameplay terjadi & bagaimanakah total game bekerja.
wujud perjudian ini berikan kamu peluang buat menempatkan duit kamu terhadap hasil permainan dominoQQ yg dapat datang. Taruhan cuma bisa ditempatkan kepada hasil total dari kontes, atau terhadap beraneka situasi yg berlangsung sewaktu kejuaraan. Biasakan beraneka kategori taruhan sebelum kamu menyimpan duit kamu di telepon.
Aturan DominoQQ
yang merupakan permulaan, game ini dimainkan dgn 28 domino double-enam. tak seperti AS, domino di Indonesia kebanyakan card mungil yg dibuang sesudah sekian banyak dikala sebab menunjukkan tanda-tanda aus & bermain.
kepada kebanyakan, seluruh pemain mesti memasukkan taruhan dgn jumlah tertentu ke dalam pot yg disediakan. Jumlah ini dapat bervariasi tergantung di mana kamu main & itu sanggup jadi taruhan rendah atau tinggi. sesudah seluruh orang memasang taruhan mereka, tiap-tiap pemain diberikan 3 card domino. 
sesudah seluruhnya pemain telah menyaksikan domino mereka sendiri, mereka bisa jalankan 1 faktor dari 4 pilihan. jikalau tak ada yg lebih baik diawal mulanya mereka mampu bertaruh namun kalau ada yg diawal mulanya lebih baik sehingga mereka sanggup menelepon, menaikkan, atau melipat.
tatkala putaran perdana, seandainya cuma satu orang bertaruh sehingga mereka membawa pot kemenangan tidak dengan mesti menunjukkan tangan mereka. jikalau ada lebih dari satu orang, sehingga tiap-tiap orang yg tak melipat bakal dikasih card ke-4.
sesudah card dibagikan, babak final taruhan berlangsung. sebahagian akbar diwaktu, ke-2 putaran mempunyai batas taruhan & babak ke-2 rata rata mempunyai batas yg lebih tinggi. Di akhir babak final ini, seluruhnya pemain yg tak mundur mesti menunjukkan tangan mereka. Orang dgn tangan paling atas atau paling baik membawa pot kemenangan.
gimana Aturan basic dalam Permainan DominoQQ?
card dimasukkan berpasangan & pips ditambahkan bersamaan & cuma digit ke-2 yg diambil. sbg sampel, keseluruhan pip 23 jadi 3 & keseluruhan pip 17 jadi 7. bersama begitu, pasangan paling atas yakni 9, yg memberikan nama Qiu Qiu. Ada 3 tangan yg dapat berikan kamu score lebih tinggi dari sepasang angka 9. Yaitu:
• Tinggi – keseluruhan pip kepada 4 card domino sama dgn 38 atau lebih tinggi
• Rendah – keseluruhan pip terhadap 4 domino sama dgn 9 atau di bawah
• Double-4 domino bersama ganda
Satu tangan lain yg di atas tangan non-khusus tapi di bawah ganda 9 yaitu lurus. Di sinilah seluruh 4 domino mempunyai pips berturut-turut. Kita contohnya seperti ini, jikalau pips sama dgn 4, 5, 6, 7. Tangan special yang lain merupakan waktu kamu mempunyai 3 ganda & itu dinamakan juga sebagai anak-anak & ke-4 sendirian.
bila 2 pemain hasilnya mempunyai straight atau double, sehingga orang bersama double doubl menang. seandainya keduanya mempunyai straight namun tak double, sehingga orang bersama straight straight bakal menang.
waktu ini sesudah kamu tahu aturannya, kamu bakal sanggup memainkan game ini dalam disaat singkat! Seperti halnya permainan apa serta, bisa saja butuh sedikit latihan namun enteng buat menguasai & enteng utk dimainkan. kamu mampu menunjukkan pada kawan kamu version dominoQQ baru & menunjukkan terhadap mereka trick bermain!
Share this...FacebookTwitter "
"It is an awe-inspiring and terrifying sight, a volcano spewing lava and millions of tons of ash and rock into a blackened sky. Mexico’s “fire volcano”, Mount Colima, recently began erupting … again, a reminder of the spectacularly destructive forces that can be unleashed by nature.  But dramatic as online footage of this Mexican volcano is, the eruption is a mere trifle compared to some of the little-known natural disasters that have been predicted. From supervolcanoes to towering megatsunamis, these catastrophic events could affect millions – and occur sooner than you think. The threat posed to the world by the Yellowstone supervolcano in the United States is well documented. Less well-known (or acknowledged), however, is that it is just one of many posing a catastrophic threat to the planet.  The Lake Toba supervolcano, on the Indonesian island of Sumatra, is currently home to the largest volcanic lake on Earth, formed 74,000 years ago when it last blew in the biggest eruption for 25m years. It is estimated that around 2,800 cubic kilometres of volcanic ash and lava were thrown into the atmosphere, 12% more than was ejected by the last Yellowstone eruption of 2.2m years ago.  And it may be about to erupt again. As with any super-eruption, the vast quantities of ash and sulphur dioxide produced can have a devastating effect on the global climate. But a number of factors make the prospect of a Toba super-eruption much more intimidating than one at Yellowstone. Toba is located on the densely populated island of Sumatra, home to over 50m vulnerable people, and is only 40km from the Indian Ocean in which catastrophic tsunamis (of which we have recent experience) would certainly be generated. Additionally, in recent months, reports of volcanic gases and heating of the ground surface have led to suggestions that the sleeping giant may again be waking up. Forget the widely-publicised megatsunami threat that has been attributed to the potential collapse of the Cumbre Vieja volcano on La Palma in the Canary Islands. A far greater danger is posed by the possible collapse of the southern portion of Kilauea Volcano on the Big Island of Hawaii. Termed the Hilina Slump, this could drop 12,000 cubic kilometres of rock into the Pacific Ocean, generating a megatsunami that would propagate around the Pacific Ocean and reach the western seaboard of North America in a matter of hours, inundating coastal communities. There is evidence that a similar collapse at nearby Mauna Loa around 120,000 years ago generated a tsunami with a run-up height of over 400m. Even as recently as 1975, movement of the Hilina Slump generated a smaller, yet destructive tsunami that reached California. Given that the slump is continually active and moving, it might only take a jolt from an earthquake in the tectonically active state to set in motion this catastrophic chain of events. The North Sea may seem an unlikely place for a devastating tsunami but climate change has led to concern that a submarine landslide in the region might lead to just this.  There is a precedent. Scientists have suggested that over 6,000 years ago, a sharp sea-level rise, attributed to a changing climate and a rapid melting of ice, added weight to the submarine glacial deposits at the edge of the Norwegian continental shelf, destabilising them and causing a 300km long landslide. This generated a tsunami that reached heights of up to 20 metres in the Shetland Islands, ten on the Norwegian coast and six metres off the northern and western coast of Scotland.  Should Earth experience such a rapidly warming climate again, and experience the associated melting of the Greenland and/or West Antarctic ice sheets, a similar event might well be possible which, today, would affect the coastal populations of Scotland and Norway (around 3m) – and perhaps even London. At the bottom of the Pacific Ocean, just off the west coast of North America and running from northern California to Vancouver Island, is a subduction zone – a place where the Pacific Ocean floor is being forced beneath the North American landmass.  The rate of movement of the ocean floor here is currently just 40mm a year but the upper part of the system is currently stuck, meaning that the North American plate is being compressed. At some point, the pressure being built up has to be released and this will be in the form of a massive earthquake, perhaps up to a magnitude 9. This could cause subsidence of the coastal region of up to 2m and a possible horizontal displacement of 30m.  Shortly after the intense shaking subsides, the riling coastal community will be struck by a tsunami that could dwarf that of the 2011 Japanese wave. Around 7m people live in this region, from Vancouver, though Seattle, to Tacoma and Portland.  How feasible is it? Well scientists have calculated that in the last 10,000 years, the region has suffered 41 large earthquakes, occurring with an average interval of 244 years – the last was a magnitude 9 and that was 315 years ago.  Perhaps the biggest threat to the modern world is posed by our own star. Periodically, the sun emits a solar flare, an intense cloud of energetic photons and particles with the energy of millions of hydrogen bombs exploding at once. Once released, these clouds arrive at Earth’s upper atmosphere within a day or two and, in many cases, most ordinary people on Earth would be none the wiser.  If intense enough, however, a solar storm could devastate electrical systems both in orbit, for example, satellites, and on the ground, as the energetic electrons cause a charge build-up.  One of the largest known events was in 1921, which knocked out the US telegraph service; but scientists have calculated that should a similar event happen in today’s technology-reliant society, it could knock out many satellite systems, disabling global communications, the internet and the global positioning system. Chaos could ensue. The intensity of solar flares varies on a roughly 11-year cycle and fortunately, 2014 saw the most recent peak come and go without significant impact. We can only hope that the same can be said for the future."
"
Share this...FacebookTwitterMojib Latif: Climate models fail to simulate tropical Pacific. No detectable anthropogenic signal
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
Prof. Mojib Latif is a widely sought out speaker for events and the German media, and he never passes up the opportunity to warn the public of the impending climate catastrophe. However at his his daytime job he is also a scientist, and there he publishes research results on a regular basis. On many occasions we have noticed that in his scientific papers he appears to be far less dramatic and more balanced than he is in the media. Some examples follow:

Mojib Latif in a presentation in USA: CO2 climate sensitivity is set to high by the IPCC
Late realization: Mojib Latif abandons CO2-fingerprint in the stratosphere and finally focusses on ocean cycles
Mojib Latif: Models must account much more for natural variability

On April 5, 2017, in the Geophysical Research Letters there’s yet another example to behold. With his colleagues Latif examined the tropical Pacific. In the eastern and central parts temperatures have cooled over the past two decades. Climate models are having a hard time recreating this development. Latif and his group looked at this case and assumed that natural climate variability is behind it. They have not been able to find an anthropogenic impact on the temperature development in this region.
They conclude that the climate models would be too uncertain to make forecasts concerning the acting circulation in the region.
With that in mind, wouldn’t it be nice if Latif mentioned this the next time he appears on a talk show? But don’t hold your breath thinking this will happen anytime soon.
It’s the two faces of Mojib Latif. It’s unclear how her goes about justifying this scientifically and ethically. What follows is the abstract with the highlighted main points:
Role of Internal Variability in Recent Decadal to Multidecadal Tropical Pacific Climate Changes
Mohammad Hadi Bordbar, Thomas Martin, Mojib Latif and Wonsun Park
While the Earth’s surface has considerably warmed over the past two decades, the tropical Pacific has featured a cooling of sea surface temperatures (SSTs) in its eastern and central part, which went along with an unprecedented strengthening of the equatorial Trade Winds, the surface component of the Pacific Walker Circulation (PWC). Previous studies show that this decadal trend in the Trade Winds is generally beyond the range of decadal trends simulated by climate models when forced by historical radiative forcing. There is still a debate on the origin of and the potential role that internal variability may have played in the recent decadal surface wind trend. Using a number of long control (unforced) integrations of global climate models and several observational datasets, we address the question as to whether the recent decadal to multidecadal trends are robustly classified as an unusual event or the persistent response to external forcing. The observed trends in the tropical Pacific surface climate are still within the range of the long-term internal variability spanned by the models but represent an extreme realization of this variability. Thus, the recent observed decadal trends in the tropical Pacific, though highly unusual, could be of natural origin. We note that the long-term trends in the selected PWC indices exhibit a large observational uncertainty, even hindering definitive statements about the sign of the trends.
Highlights:

Pacific Walker Circulation strongly varies internally
Anthropogenic signals in the tropical Pacific sector are hard to detect
There is large model uncertainty about the future of the Pacific Walker Circulation”


Share this...FacebookTwitter "
"It’s about time people began to call out carbon offsetting for what it is (“If only saving the planet were as easy as planting a tree before speeding off in our SUVs”, Comment). But if we’re going to take issue with flight redemption initiatives, then we need to also call out the carbon offsetting delusion that is recycling, which promotes the notion that simply by putting mountains of packaging in the recycling bin and then paying someone else to deal with it, the slop of our profligate lifestyle is somehow neutralised. Our recourse to the bottomless pit that is the recycling bin has encouraged us to be less responsible shoppers and disposers of waste than ever, and facilitated the unchecked explosion of the use of plastic packaging. It would be bad news even if the waste were actually being recycled, but we now know that much of it isn’t; it is simply being transported to lands far, far away or ending up in our oceans.  The time has come to rethink our approach to recycling: it has to be a last-ditch option, not a get-out card. There is only one way out of the climate crisis and that’s for us all to try to use less carbon in the first place, and to put pressure on companies to do the same.Jane TidburyBrittany, France Your article on the killing of a young boy notes that “illegal drugs markets are... a ‘golden thread’ running through many accounts of violence in London and elsewhere” (“The long path to Jaden Moodie’s murder”, Viewpoint). Correct. You fail to add that the reason for this immense violence is prohibition. Prohibition gives criminal gangs control of the estimated $425bn that the drugs trade generates worldwide every year. Drug money, not drugs per se, is the issue. No one, from the cartels in Mexico to county lines gangs in Britain, is involved in violent crime over drugs, but over the vast money to be made through the trade. The only way to control the money is through legalisation. Until drugs are legalised and regulated, with strict quality and sales controls, similar to those applied for alcohol, such criminality will continue.Tony JacksonCamusterrach, Applecross Scottish Highlands Those interviewed in the article about women reading more fiction than men (“Why women love literature”, The New Review, 8 December) claimed that women are more empathetic, more social, more curious and that they have a bit more imagination than men. It seems that reading fiction has not prevented these women, in particular, from making such sweeping statements.Craig HuttonSmethwick, West Midlands Air pollution kills more people in the UK than prostate and breast cancers combined, and, as you point out, it harms children’s cognitive development (“Experts raise new fears over UK’s killer air pollution”, News). We need urgent action. Long commutes to work are a major cause of air pollution, as well as global warming, and expensive and miserable for most people involved. Instead of building new, faster roads (which encourages people to apply for jobs even further from where they live), the government needs to ensure jobs are near to homes. New housing estates need to provide commercial buildings, too. Public sector recruitment must prioritise local candidates. And empty shops in town centres must be turned into homes.Richard MountfordTonbridge, Kent Emma Graham-Harrison’s article gives the impression that Finns and/or the Finnish government deliberately created the pronoun “hän” as part of a “quirky international campaign” to promote gender equality (“Feminism comes of age in Finland as female coalition takes the reins”, Dispatch). In fact, the absence of grammatical gender is a feature of all Finno-Ugric languages and has been for thousands of years. Finns use the pronoun “hän” not to further a socio-political agenda but simply because that is how their language operates.David Hackston, translatorHelsinki, Finland How can Fiona Maddocks promote such a mealy-mouthed and fanciful explanation for why Violetta, the heroine of La traviata, is known as “the lady of the camellias” (“It’s got everything’: why we’re still in love with this Traviata after 25 years”, Focus). The true explanation, as provided in the Alexandre Dumas fils novel on which the opera is based, is that, as a woman who earns her living by having sex with relative strangers, she wears a white camellia when she is available, and a red one when menstruating and not available.Philippa PigacheCross in Hand, Heathfield East Sussex On 16 November, the Observer published an article by Peter Kellner citing data gathered by Deltapoll in the Kensington constituency (“London polls show surge to the Lib Dems”, News).  The data was seized upon by the Liberal Democrats. Countless fliers dropped though people’s letterboxes and it circulated on social media. The communications were being used specifically to target Labour Remain voters, and they cited the Observer as having commissioned the poll. Here are the results from the 12 December election, with the Deltapoll survey results and the percentage point difference in brackets: Conservative 38.3% (36%, +2.3); Labour 38% (27%, +11); Liberal Democrat 21.3 (33%, -11.7). Deltapoll conducted another telephone survey of 502 residents between 4 and 8 December. Here is the data that I found on their website – again the election result is listed first, with the poll result in brackets: Conservative 38.3% (39, -0.7); Labour 38% (29, +9); Liberal Democrat 21.3% (27, -5.7). These results were obliquely referenced in last week’s Observer, in another article by Mr Kellner (“Tactical voting was set to be Remainers’ saviour. So what went wrong?”, News). You can see that, with regard to Labour and the Liberal Democrats, Deltapoll got the results incorrect in both surveys. Indeed, I have shared the polling data and election result with a statistician and his conclusion was that something must have been wrong. The chance of arriving at a forecast for the Lib Dems of 33% when the actual result was 21.3% is less than one in a thousand. When I saw the results from the first survey, I dismissed them as rogue and ended up having arguments with Labour voters who were leaning towards the Lib Dems. I assured them that polling at a local level is notoriously unreliable; I pointed to the results from 2017 and explained that a swing of the scale forecast would have been close to unprecedented; I urged them to stick to Labour. My argument convinced some; I know that others went on to vote Lib Dem. Emma Dent Coad was a respected and loved Labour MP for Kensington. She has lost her job. And the people who depended on her to stand up for them in this constituency, those suffering hardship, those still traumatised by Grenfell, those who simply believe in a just society – they have lost her. Instead, we have a Conservative MP, Felicity Buchan, who has admitted to never having been on the Grenfell Silent walk.John LoweryLondon W11 It is not just the national parks that need to block the spread of electrical light, but the countryside as a whole – and much of the cities (“The battle to save our sky from light pollution”, Focus). Why are motorway lights not fitted with broad “hats” as they are in France, rather than throwing it up into the sky? Why do shops and offices still “need” to leave their lights on? Why, in an age of motion sensors, do street lights need to burn at full capacity when nobody is there?Amanda CraigLondon NW1"
"
Share this...FacebookTwitterSpiegel here calls it “the end of an era”.
Once ballyhooed as the technology of the future bearing the promise of economic revival in Germany, solar equipment manufacturing has crumbled and gone the way of dinosaurs, all in a matter of a decade. So rapidly can economic evolution send subsidized industries into extinction.
Germany’s last remaining major solar manufacturer, Bonn-based Solarworld, led by a flamboyant Frank Asbeck, has officially declared it will file for insolvency after 6 years of red ink (operating results). The announcement was made Wednesday.
Shattered dreams
Thousands of workers who banked their futures on solar jobs now face uncertain futures. Solarworld’s demise is the last in a spectacular series of solar manufacturer bankruptcies that swept across Germany over the past years, with names like Solon, Solar Millenium and Q-Cells going under.
According to Finanzen.net here, Solarworld had over 3000 employees on the payroll at the end of 2016.
In the early 2000s leaders and green energy proponents promised to turn parts of former communist East Germany into a “Solar Valley” that would boast secure, high paying hightech jobs. Today it’s a solar rustbelt with a ruined landscape of shattered visions and dreams. Spiegel calls it a “valley of tears”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Maserati-driving Green Party co-founder
Solarworld was viewed as the German solar industry’s leader, and its director Asbeck was called the “sun king” and even had solar panels installed on the Vatican and met Pope Benedict XVI personally.

Asbeck, one of the co-founders of the German Green Party and an avid owner of a 300 hp Maserati, blames the company’s woes mainly on cheap imports from China and legal battles in the USA, reports WirtschaftsWoche. Asbeck is reported by Wikipedia to also own expensive properties, such as Schloss Calmuth, Villa Cahn and Schloss Marienfels, Remagen (below):


One of Frank Asbeck’s houses, Schloss Marienfels. Image by Wolkenkratzer –  CC BY-SA 3.0
In 2016 Solarworld posted a 92 million euro loss. Solarworld’s subsidiary companies are also expected to declare insolvency. The insolvency signifies the end of the manufacture of solar components and technology in the country.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSea Levels Meters Higher While
CO2 Levels Were Below 300 ppm
 
Image Yoon et al., 2017

Before the advent of the industrial revolution in the late 18th to early 19th centuries, carbon dioxide (CO2) concentrations hovered around 280 parts per million (ppm).
Within the last century, atmospheric CO2 concentrations have risen dramatically.  Just recently they eclipsed 400 ppm.
Scientists like Dr. James Hansen have concluded that pre-industrial CO2 levels were climatically ideal.  Though less optimal, atmospheric CO2 concentrations up to 350 ppm have been characterized as climatically “safe”.  However, CO2 concentrations above 350 ppm are thought to be dangerous to the Earth system.  It is believed that such “high” concentrations could lead to rapid warming, glacier and ice sheet melt, and especially catastrophic sea level rise of 10 feet within 50 years.
It is interesting to note these prognostications of impending deluge are predicated on the assumption that CO2 concentrations are a driver of sea level fluctuations.
Scientists have determined that during the interglacial 400,000 years ago (MIS 11), CO2 peaked at a very safe 280 parts per million (ppm).  Despite such a low and “ideal” CO2 concentration, scientists have determined that sea levels during that interglacial were 20 meters higher than than they are now.

Guo et al., 2017
“The upper 250 meter-long sediment core of Site U1391 (1085 m water depth) retrieved from the Portuguese margin in the Northeast Atlantic Ocean was adopted for the benthic foraminiferal analyses to disclose the variations in Mediterranean Outflow Water (MOW) intensity over the last ~ 0.9 Ma [900,000 years]. The strongest MOW [Mediterranean Outflow Water]  intensity during MIS 11 [400,000 years ago] confirms the climatic influence of waving sea level on the MOW current by its +20 m high-stand above the present sea level.”

CO2 graph courtesy of NASA.gov

Sea Levels 6-8 Meters Higher 6-9 Thousand Years Ago (~260 ppm CO2)

Although most scientists have found that the Holocene’s (~11,700 years ago to present) sea level peaks (highstands) were between 1 and 4 meters higher than present, there are some who have found that Early Holocene sea levels reached as high as 6 to 8 meters above mean sea level today.

Prieto et al., 2016
“Analysis of the RSL [relative sea level] database revealed that the RSL [relative sea level] rose to reach the present level at or before c. 7000 cal yr BP, with the peak of the sea-level highstand c. +4 m [above present] between c. 6000 and 5500 cal yr BP [calendar years before present] … This RSL [relative sea level] curve was re-plotted by Gyllencreutz et al. (2010) using the same index points and qualitative approach but using the calibrated ages. It shows rising sea-levels following the Last Glacial Termination (LGT), reaching a RSL [relative sea level] maximum of +6.5 m above present at c. 6500 cal yr BP [calendar years before present], followed by a stepped regressive trend towards the present.”


Hodgson et al., 2016
“Rapid early Holocene sea-level rise in Prydz Bay, East Antarctica … The field data show rapid increases in rates of relative sea level rise of 12–48 mm/yr [+1.2 to 4.8 meters per century] between 10,473 (or 9678) and 9411 cal yr BP in the Vestfold Hills and of 8.8 mm/yr between 8882 and 8563 cal yr BP in the Larsemann Hills. … The geological data imply a regional RSL [relative sea level] high stand of c. 8 m [above present levels], which persisted between 9411 cal yr BP and 7564 cal yr BP [calendar years before present], and was followed by a period when deglacial sea-level rise was almost exactly cancelled out by local rebound.”


Recent Sea Level Rise Undetectable When Viewed In Its Long-Term Context

Despite the surge in anthropogenic CO2 emissions and atmospheric CO2 since the 20th century began, the UN’s Intergovernmental Panel on Climate Change (IPCC) has concluded that global sea levels only rose by an average of 1.7 mm/yr during the entire 1901-2010 period, which is a rate of less than 7 inches (17 cm) per century and an overall rise of just 0.19 of a meter in 110 years.
According to Wenzel and Schröter (2014), the acceleration rate for the sea level rise trend since 1900 has been just +0.0042 mm/yr, which is acknowledged by the authors to be “not significant” and well within the larger range of uncertainty (+ or – 0.0092 mm/yr), effectively putting the overall 20th/21st century sea level rise acceleration rate at nearly zero.
As mentioned, most scientists have found that sea levels were about 1 – 4 meters higher than they are now between 4,000 and 6,000 years ago (when CO2 concentrations were about 260 to 265 ppm).  It may therefore be enlightening to visualize the overall nineteen hundredths of a meter (0.19) rise in sea levels since 1901 in its long-term (Holocene) context.  Assuming a sea level highstand of about 2.5 meters above present during the Mid-Holocene, notice how modest the recent rise appears.




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




10 More New Papers Affirm Sea Levels Were Much Higher 4-6 Thousand Years Ago

In the last few years alone (2014 to 2016), there were at least 35 papers published in the peer-reviewed scientific literature indicating that sea levels were substantially higher than they are now just a few thousand years ago…when CO2 concentrations are thought to have been “safe”.
In 2017, there have already been another 10 scientific papers published that can be added to this growing list.
It is becoming more and more apparent that sea levels rise and fall without any obvious connection to CO2 concentrations.  And if an anthropogenic signal cannot be conspicuously connected to sea level rise (as scientists have increasingly noted), then the greatest perceived threat (rising sea levels) promulgated by advocates of dangerous anthropogenic global warming will have lost its impact.

1.  Das et al., 2017  (India)
“In the absence of any evidence of land-level changes, the study suggests that at around 6 ka to 3 ka [6,000 to 3,000 years ago], the sea was approximately 2 m higher than present.”

2.  Fontes et al., 2017   (Brazil)
“During the early-middle Holocene there was a rise in RSL [relative sea level] with a highstand at about 5350 cal yr BP [calendar years before present]  of 2.7 ± 1.35 m [higher than present], which caused a marine incursion along the fluvial valley.”


3.  Yoon et al., 2017  (Korea)
“Songaksan is the youngest eruptive centre on Jeju Island, Korea, and was produced by a phreatomagmatic eruption in a coastal setting c. 3.7 ka BP [3,700 years before present]. The 1 m thick basal portion of the tuff ring shows an unusually well-preserved transition of facies from intertidal to supratidal, from which palaeo-high-tide level and a total of 13 high-tide events were inferred. Another set of erosion surfaces and reworked deposits in the middle of the tuff ring, as high as 6 m above present mean sea level, is interpreted to be the product of wave reworking during a storm-surge event that lasted approximately three tidal cycles. … The reworked deposits alternate three or four times with the primary tuff beds of Units B and C and occur as high as 6 m above present mean sea level or 4 m above high-tide level (based on land-based Lidar terrain mapping of the outcrop surface).”

 

4.  Marwick et al., 2017  (full pdf)  (Thailand)
“Sinsakul (1992) has summarised 56 radiocarbon dates of shell and peat from beach and tidal locations to estimate a Holocene sea level curve for peninsula Thailand that starts with a steady rise in sea level until about 6 k BP, reaching a height of +4 m amsl (above [present] mean sea level). Sea levels then regressed until 4.7 k BP, then rising again to 2.5 m amsl at about 4 k BP. From 3.7 k to 2.7 k BP there was a regressive phase, with transgression starting again at 2.7 k BP to a maximum of 2 m amsl at 2.5 k BP. Regression continued from that time until the present sea levels were reached at 1.5 k BP. … Tjia (1996) collected over 130 radiocarbon ages from geological deposits of shell in abrasion platforms, sea-level notches and oyster beds and identified a +5 m [above present] highstand at ca. 5 k BP in the Thai-Malay Peninsula. …  Sathiamurthy and Voris (2006) summarise the evidence described above as indicating that between 6 and 4.2 k BP, the sea level rose from 0 m to +5 m [above present] along the Sunda Shelf [+2.8 mm/yr], marking the regional mid-Holocene highstand. Following this highstand, the sea level fell gradually and reached the modern level at about 1 k BP [1,000 years ago].”

5.  May et al., 2017 (W. Australia)
“[T]he mid-Holocene sea-level highstand of Western Australia [was] at least 1–2 m above present mean sea level. … Between approximately 7000 and 6000 years BP, post-glacial RSL [relative sea level] reached a highstand of 1-2 m above the present one, followed by a phase of marine regression (Lambeck and Nakada, 1990; Lewis et al., 2013).”

6.  Kane et al., 2017 (Equatorial Pacific)
“The high stand is documented across the equatorial Pacific with peak sea-level values ranging from 0.25 to 3.00 m above present mean sea level (MSL) between 1000 and 5000 yr BP (Fletcher and Jones, 1996; Grossman et al., 1998; Dickinson, 2003; Woodroffe et al., 2012). Woodroffe et al. (2012) argues that Holocene sea-level oscillations of a meter or greater are likely to have been produced by local rather than global processes.”


7.  Khan et al., 2017 (Caribbean)
“Only Suriname and Guyana [Caribbean] exhibited higher RSL [relative sea level] than present (82% probability), reaching a maximum height of ∼1 m [above present] at 5.2 ka [5,200 years ago]. … Because of meltwater input, the rates of RSL change were highest during the early Holocene, with a maximum of 10.9 ± 0.6 m/ka [1.9 meters per century] in Suriname and Guyana and minimum of 7.4 ± 0.7 m/ka [0.74 meters per century] in south Florida from 12 to 8 ka [12,000 to 8,000 years ago].”

8.  Meltzner et al., 2017  (Southeast Asia)
“Half-metre sea-level fluctuations on centennial timescales from mid-Holocene corals of Southeast Asia … RSL [relative sea level]  history between 6850 and 6500 cal years BP that includes two 0.6 m fluctuations, with rates of RSL [relative sea level] change reaching 13±4 mm per year. … Here RSL [relative sea level] rose to an initial peak of +1.9 m [above present] at 6,720 cal years BP, then fell rapidly to a lowstand of +1.3 m, remaining at about that level for ∼100 years, before rising to a second peak at +1.7 m shortly after 6,550 cal years BP. Around 6,480 cal years BP, RSL appears to have fallen again to +1.3 m before rising to a third peak at +1.6 m or higher. … The peak rate of RSL rise, averaged over a 20-year running time window over the period of study (∼6,850–6,500 cal years BP), is +9.6±4.2 mm per year (2σ); the peak rate of RSL fall is −12.6±4.2 mm per year. … To put the ∼0.6 m mid-Holocene fluctuations in context, annual mean sea level in some modern tide-gauge records is seen to change by as much as 0.2–0.3 m on interannual timescales, and the interannual s.d. of sea surface height between 1979 and 2013 approached 0.1 m in some portions of the western Pacific.  The central dome of each microatoll grew during a period when RSL was high; RSL then fell rapidly, killing the upper portions of the corals; RSL then stabilized at a lower elevation, forming a series of low concentric annuli ∼0.6 m higher than present-day analogues; RSL [relative sea level] then rose ∼0.6 m in less than a century, allowing the coral to grow upward to 1.2 m higher than modern living corals.”

9.  Leonard, 2017 (Great Barrier Reef)
“The resultant palaeo-sea-level reconstruction revealed a rapid lowering of RSL of at least 0.4 m from 5500 to 5300 yBP following a RSL [relative sea level] highstand of ~0.75 m above present from ~6500 to 5500 yBP. RSL then returned to higher levels before a 2000-yr hiatus in reef flat corals after 4600 yBP. The RSL oscillations at 5500 yBP and 4600 yBP coincide with both substantial reduction in reef accretion and wide spread reef “turn-off”, respectively, thereby suggesting that oscillating sea level was the primary driver of reef shut down on the GBR.”

10.  Dechnik et al., 2017 (Tropical Western Pacific)
“[I]t is generally accepted that relative sea level reached a maximum of 1–1.5 m above present mean sea level (pmsl) by ~7 ka [7,000 years ago] (Lewis et al., 2013).”
Share this...FacebookTwitter "
"Europe’s fish populations will continue to be over-exploited despite a longstanding 2020 deadline for setting fishing quotas at sustainable levels, after ministers from across the EU forced through higher limits than scientists advised. Key species such as cod in the west of Scotland and Irish Sea, some herring stocks, sole and plaice in the Celtic Sea, pollock in western waters, and ling and tusk in the north-east Atlantic, will all be under renewed and unsustainable pressure, according to campaigners. Quotas for some species were increased from last year, despite advice that they should be brought down.  “The limits agreed by ministers suggest that progress to end overfishing has stalled or even reversed,” said Andrew Clayton of the Pew Charitable Trusts. “This is especially disappointing for 2020, the legal deadline in the common fisheries policy to end overfishing. Missing the deadline means putting stocks such as cod under heavy pressure in 2020, even though their populations are at critical levels.” The quota for haddock in the North Sea for the UK was raised by 23% and UK catches of sole in the western Channel raised by 19%. George Eustice, the UK fisheries minister, defended the decisions made at a tense meeting that ended early on Wednesday morning: “This year there has been some very challenging science for cod stocks in many parts of the north-east Atlantic, and we have responded to conserve stocks. I know that some of the quota reductions will be very difficult for some sectors of the industry – however, we know that to protect the profitability of fisheries in the future, we must fish sustainably today.” He condemned the EU’s “outdated method for sharing quota” among member states, saying it meant the UK got a “very small share of the cod in our own waters”, but pledged that would be reconsidered after Brexit. The UK would also put in place its own policies to ensure fish catches were managed sustainably, he said. The UK will still have to negotiate with EU member states and non-EU nations such as Norway and Iceland over shared fishing grounds after Brexit. In an all-night meeting in Brussels, the ministers at the Agriculture and Fisheries Council failed to meet their own targets and deadlines on sustainable fishing, under pressure from their national fleets. Under reforms to the EU’s common fisheries policy, enacted in 2013 after two years of intense talks, fishing ministers were supposed to gradually phase out the too-high quotas that had been the norm for decades and contributed to steep declines in key fish populations. By 2020, all quotas were meant to be based on a maximum sustainable yield – the most fish that can be caught without damaging the ability of the species to recover itself – and there was to be an end to the wasteful practice of discarding dead fish at sea. But Tuesday night’s meeting, at which the quotas for 2020 were set, showed little departure from the pattern that has been set for years, in which ministers ignored science and fought bitterly for their own vested interests. “Everybody must comply with the law – and politicians are no exception,” said Andrea Ripol, fisheries policy officer at Seas At Risk. “Ministers decided today to breach the law, allowing overfishing even beyond 2020. This decision represents a betrayal of European citizens, and breaks their trust.” At the recent UN climate change talks, which ended amid discord and disappointment on Sunday, governments were told that ending overfishing could improve the prospects of dealing with the climate emergency. Protecting fish stocks restores a healthy balance to the seas that enables them to store more carbon and absorb heat, vital functions in the Earth’s natural processes. “They’re just not getting it,” said Rebecca Hubbard, programme director at Our Fish. “Demonstrating a shocking ignorance of the global biodiversity and climate crisis, the EU council of fisheries ministers refused to follow scientific advice. Ending overfishing would be a rapid, achievable act that would bolster the health of the ocean in the face of the climate crisis, securing futures for coastal communities, as well as being a firm response to calls from EU citizens for climate action.”"
"Yet again, distressing images of flood damage and destruction in northern England are prompting calls for further investment in UK flood defences and fearful talk of climate change.  There is a particularly worried tone to the commentary, because this flooding occurred after installation of new hard flood defences (completed in June 2010) that simply could not cope with the flow and – despite millions spent on glass flood walls and hydraulic modelling of the options – these defences failed. Or at least this is what we are hearing in the press. This verdict is too severe, flood defences have worked in places and have bought people – and the emergency services – more time and reduced flood risk.  But for those with homes covered in wet, polluted mud, these arguments sound hollow. The simple fact is that with record-breaking rainfall (341mm in 24 hours at Honister Pass) on a landscape which has been managed for centuries to be efficient at encouraging rainwater to flow into rivers, you would expect flooding – and the more extreme the rainfall, the more extreme the flooding. A key question being asked by all is: “What do we mean by extreme flooding?” Already we have heard repeatedly the common misconception “this is a flood that should only happen every 100 years”. This is incorrect. The science of flood extremes attempts to use the woefully short records of river flow (which has been around for about 30 years) and rainfall (which has been recorded for about 200 years) to estimate a probability: the chance of a flood of a given size happening.  A 100-year flood is actually better described as a flood that has a 1% chance of occurring within any given year. It does not mean that we expect one every 100 years – sadly as the people of Cumbria have found, a flood with a 1% chance of occurring can occur more than once in 100 years and quite possibly within the same year. In fact the chances of another 100-year event occurring in 2016 remains 1%. After the 2009 Cumbrian floods, the Natural Environment Research Council funded a study to look at using lake sediments to track any changes in flood frequency and magnitude. The lake sediment record from our lakes  can provide a long perspective on flood magnitude and frequency spanning thousands of years.  The mud covering the flooded homes and roads have been washed down rivers from the mountains – and in Cumbria they end up in the lakes. Each flood can leave a distinct sediment layer. Research by scientists from the universities of Southampton, Liverpool and Durham suggests that the floods of 2005 and 2009 in Cumbria were the largest for 600 years (the results of this analysis are yet to be published) and that these sorts of events had a probability of occurring 0.001% or one in every 1,000 years (substantially rarer than the one in 200-year value arrived at using the 30 years of measured river flows).  What is worrying is that the lake sediment flood record shows that two-thirds of the very largest floods experienced in Cumbria have happened in the past 15 years, a period characterised by warmer northern hemisphere temperatures (an index for moisture and energy in the atmosphere) and positive North Atlantic Oscillation Index – a measure of the direction of storm tracks over the UK (including Storm Desmond). Such conditions last occurred 800 years ago during the medieval climatic anomaly, a time when the Cumbria landscape was quite different from today with less intensive agriculture and more extensive woodlands. In the Howgill Fells a lack of trees and steep slopes have created conditions for landslides – sediment from which is then fed into the river channel creating changes in the river. A wooded valley would make the slopes less susceptible to landslides and would reduce the movement of sediments and water downstream. As it is, the huge rainfall that came with Storm Desmond has resulted in landslides around the valleys of Borrowdale, Thirlmere, Ullswater and the Howgill Fells."
"If you’re dreaming of a white Christmas you might look to the bookies to check the odds. Despite reports that this will be the coldest winter since 1963, with less than a week to go the odds of a flurry in London on the big day were hovering around 7/2, one of the lowest chances of snow for several years.  But perhaps mathematicians know better. When it comes to forecasting the likelihood of a snow blizzard, our weather presenters know what to say – predicting the odds of snow falling during the week ahead is relatively easy. However, predicting if there will be enough snow for festive frolicking with snowmen, sledging and snowball fights is much harder. We can tell if snow will fall, but not how much, which is arguably the most important Christmas weather question of all. Weather forecasting is based on computer modelling, but surprisingly these models do not actually predict snow. A single variable is used to predict whether water will visit as liquid, vapour or ice so other information, such as air temperature is needed to stack the odds of snow. Computer models are able to forecast the amount of water produced when air rises above the height at which water vapour begins to condense. Known as the Quantitative Precipitation Forecast (QPF), when it comes to snow prediction this is an important variable. But there are many sensitive factors that can affect the odds in favour of rain, or make it very difficult to distinguish between different types of snow, from a disappointing slush to our traditional fluffy festive flurry. If temperatures are low enough, rain will fall as snow. And then forecasters need a way to translate the QPF into an equivalent snowfall. We use a ratio of about 1 to 10 to calculate how much snow will be produced from an amount of rainwater. If the QPF predicts one inch of rain, we’d be admiring a pretty good ten-inch covering of snow! Sounds simple? Think again. As with so many things in life, it’s not all about quantity, but quality; the quality of the snow that is. This magic 1:10 rain to snow ratio can vary depending on whether the snow is “wet” or “dry.” Dry snow is composed of those small powdery flakes that make for great skiing; it is less dense and contains less water. It forms when there is very little moisture available. Under these circumstances, the rain to snow ratio can be considerably higher, quite often 1 to 20! Then there is “wet” snow. This is the heavier, moisture-packed variety that can quickly turn into ankle-twisting ice patches. Here, there is abundant moisture, and the snowflakes are bigger and wetter. The typical ratio becomes 1 to 5. To know if we’ll be getting the “right” kind of Christmas flurry, we therefore need to have very accurate forecasts of moisture levels in the atmosphere, plus an understanding of the variation of temperature with altitude. Our forecast models describe a snapshot of the weather at a given moment using vast arrays of numbers to describe the atmosphere. This array of numbers takes into account a host of basic variables such as moisture and temperature. Calculating how these many millions of “weather pixels” will interact and adapt requires superfast computation and large amounts of memory. This resource-heavy computational model leads to inevitable limitations when predicting snowfall. So there is a trade-off between the geographical coverage of the models and the detail that we can expect from them.  It simply requires too much computer power to accurately predict snow (and importantly, what kind of snow) across the country. This trade-off is critical when it comes to calculating reliable QPFs, and therefore working out the chances of a proper white Christmas. Forecasters often turn to the lessons learned at college – dew points, temperature soundings from meteorological balloon ascents and real-time reports from weather stations to assess the impact of a snow storm. So whether you turn to the bookies, TV weather presenters or even us mathematicians, getting an expert to predict snow – one of our most loved, and occasionally loathed, weather features – is a really tough call. But in any case it always depends on number crunching and the power of mathematics. We may be able to capture the beauty of a perfect snow-covered Christmas day with high-resolution digital cameras, but capturing the mystery behind snowfall in our sophisticated weather prediction models is much more challenging. Whether you should take a flutter on a flurry this year comes down to “seat of the pants” knowledge, a little hopeful wishing and, sometimes, a sprinkling of Christmas magic."
nan
"Climate breakdown played a key role in at least 15 events in 2019 that cost more than $1bn (£760m) in damage, with more than half of those costing more than $10bn each. Extreme weather including floods, storms, droughts and wildfires struck every inhabited continent in the past year, causing devastation and loss of life. Christian Aid, which tracked climate-related destruction in 2019, said the costs in human terms and insured losses were likely to have been underestimated. Floods in Argentina and Uruguay in January this year forced 11,000 people from their homes. Cyclone Idai killed 1,300 people in Zimbabwe, Mozambique and Malawi in March, and Cyclone Fani struck India and Bangladesh in May and June. A stronger than usual monsoon killed 1,900 people in India. Richer countries were also badly affected, with Storm Eberhard hitting Europe in March and the typhoons Faxai and Hagibis battering Japan in September and October, disrupting the Rugby World Cup. Wildfires laid waste to farming areas in California and caused more than $25bn in damage, and Hurricane Dorian swept along the US east coast, killing 673 people. The study published on Friday was compiled before the full effects of the Australian wildfires could be assessed. Kat Kramer, a co-author of the report and the global climate lead at Christian Aid, said time was running out to tackle the climate crisis. “Last year, [greenhouse gas] emissions continued to rise, so it’s essential that nations prepare new and enhanced pledges for action to [fulfil] the Paris agreement as soon as possible,” she said. “That will ensure the world responds urgently to the warnings of scientists, as well as the demands from schoolchildren around the globe who are horrified at the kind of world they are being forced to inherit.” Hurricane Dorian caused at least $11bn in losses, and floods in the midwest and south of the US from March to June cost about $12.5bn. India’s losses from floods and Cyclone Fani alone came to more than $18bn, and these estimates covered only insured losses. Typhoon Lekima in China was estimated to have cost at least $10bn, and floods in China from June to August cost a similar amount. Experts said the extreme weather and record-breaking temperatures were clearly linked to human actions. Michael Mann, the director of the Earth System Science Center at Pennsylvania State University, said: “If anything, 2019 saw even more profound extreme weather events around the world than last year, including wildfires from the Amazon to the Arctic, and devastating out-of-season simultaneous wildfires in California and Australia, winter heatwaves and devastating superstorms. “With each day now, we are seemingly reminded of the cost of climate inaction in the form of ever-threatening climate change-spiked weather extremes.” Governments failed to make much progress at the UN climate talks in Madrid earlier this month, but campaigners hope the public concern and activism around the world, as well as reminders of the vast and growing economic and social costs of inaction, will act as a spur. Nations will meet in Glasgow in early November to update their plans under the Paris accord, which binds them to take action to ensure global temperature rises do not exceed 2C above pre-industrial levels."
"
Share this...FacebookTwitterHere’s a good example of how climate alarmists and leftists in Germany react when confronted with different opinions or the truth. It just illustrates the brand of radicalism we’re up against.
Last week on August 8 Germany’s top climate alarmism propaganda site Klimaretter (Climate Rescuers) here reported on the “explosive” US government climate report that was “leaked” to the New York Times.
Supposedly the Trump Administration was suppressing the “leaked” report and fighting to keep it out of the public’s view. And now that it was out, the Trump government found itself “under pressure”.
Then a couple of days later, it emerged in the US media that the report had in truth not been kept away from public view after all, and that the New York Times really hadn’t broken any “explosive” story. The report had in fact long been available to anyone for months.
The New York Times even had to issue a humiliating correction and clarification for the “large screw-up“.
On  August 11, reader Reinhard Lange left a comment at Klimaretter pointing out that their story was faulty and needed to be urgently corrected. Lange provided a link to WUWT for Klimaretter, so that they could get the details.

The blunder of course was highly embarrassing for the extremely devout Klimaretter site, and one of their attack dogs, reader Martok, immediately responded (above):
Watts Up with That is one of the most radical climate-denier blogs that exists in the entire Internet. This site has only one purpose, namely to permanently produce fake news and to write exactly the opposite of what the latest research tells us. ‘Information’ from there has no value whatsoever because this site is a pure propaganda platform that only wishes to spread disinformation.”
This is a typical reaction one often gets from radical alarmists in Germany. Contrary information gets immediately regarded as blasphemy. Denial mode gets immediately activated.
Undeterred, Lange persisted, first wondering why such an aggressive attitude on the part of Martok, and then pointed out to Klimaretter that the report draft had long since been available, and that even the NYT itself issued a (half-hearted) correction.
Next Klimaretter lapdog Regim responded next, insisting that the US government never officially released the report, and then accused Lange of copying from the WUWT “climate denier blog”. She demanded of Lange:
Why wasn’t the report published on a government site and presented to the public? Why was only a draft published?
A disbelieving Lange in turn replied, “Are you really that clueless?“, and then explained where to find the report and that there was nothing unusual with anything.
Not good enough. Regim demanded an address to the government site containing the draft report.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




So Lange instructed her to try using a tool called “a search engine”. Again Regim demanded a direct address:

and warned (marked yellow) above:
If you again answer in this way for a third time, then I’m going to ask Moderation to ban you.”
Lange replied that they should feel free to ban him, and again told her where to get the information on the story, adding that details could be found among other places at an article by the Daily Caller before wishing her luck.
Still not good enough for Regim. The Daily Caller too is a “right-extremist” paper, she insisted.
By now Klimaretter’s embarrassment was becoming full-scale humiliation, as it was clear that the original NYT article was seriously flawed.
At this point a normal outlet would have long since issued a correction. But not Klimaretter. Rather than thanking Lange for pointing out the story’s major flaw, correcting it and apologizing, Klimaretter banned Lange:

In English:
User banned (multiple disparaging  comments, ‘trolling’)
That’s the reward one gets in Germany for bringing out the truth – you get banned because insisting on the truth that demolishes the narrative is “trolling”. As far as I know, Klimaretter continues to stand by its story, even though the NYT issued a correction.
Is it possible to engage in a discussion with the likes of Klimaretter? Obviously the answer is no. An open discussion is the last thing they seek. What they want is a discussion shut-down.
In case Klimaretter may still be interested, they can refer to the Washington Post here. Yes, the NYT piece was crap. Time to stop hiding.
Thanks, Reinhard Lange. You exposed how these people really work.
 
Share this...FacebookTwitter "
"A large crack, stretching several kilometres, made a sudden appearance recently in south-western Kenya. The tear, which continues to grow, caused part of the Nairobi-Narok highway to collapse. Initially, the appearance of the crack was linked to tectonic activity along the East African Rift. But although geologists now think that this feature is most likely an erosional gully, questions remain as to why it has formed in the location that it did and whether its appearance is at all connected to the ongoing East African Rift. For example, the crack could be the result of the erosion of soft soils infilling an old rift-related fault.  The Earth is an ever-changing planet, even though in some respects change might be almost unnoticeable to us. Plate tectonics is a good example of this. But every now and again something dramatic happens and leads to renewed questions about the African continent splitting in two. The Earth’s lithosphere (formed by the crust and the upper part of the mantle) is broken up into a number of tectonic plates. These plates are not static, but move relative to each other at varying speeds, “gliding” over a viscous asthenosphere. Exactly what mechanism or mechanisms are behind their movement is still debated, but are likely to include convection currents within the asthenosphere and the forces generated at the boundaries between plates. These forces do not simply move the plates around, they can also cause plates to rupture, forming a rift and potentially leading to the creation of new plate boundaries. The East African Rift system is an example of where this is currently happening.  The East African Rift Valley stretches over 3,000km from the Gulf of Aden in the north towards Zimbabwe in the south, splitting the African plate into two unequal parts: the Somali and Nubian plates. Activity along the eastern branch of the rift valley, running along Ethiopia, Kenya and Tanzania, became evident when the large crack suddenly appeared in south-western Kenya. When the lithosphere is subject to a horizontal extensional force it will stretch, becoming thinner. Eventually, it will rupture, leading to the formation of a rift valley. This process is accompanied by surface manifestations along the rift valley in the form of volcanism and seismic activity. Rifts are the initial stage of a continental break-up and, if successful, can lead to the formation of a new ocean basin. An example of a place on Earth where this has happened is the South Atlantic ocean, which resulted from the break up of South America and Africa around 138m years ago – ever noticed how their coastlines match like pieces of the same puzzle?. Continental rifting requires the existence of extensional forces great enough to break the lithosphere. The East African Rift is described as an active type of rift, in which the source of these stresses lies in the circulation of the underlying mantle. Beneath this rift, the rise of a large mantle plume is doming the lithosphere upwards, causing it to weaken as a result of the increase in temperature, undergo stretching and breaking by faulting. Evidence for the existence of this hotter-than-normal mantle plume has been found in geophysical data and is often referred to as the “African Superswell”. This superplume is not only a widely-accepted source of the pull-apart forces that are resulting in the formation of the rift valley but has also been used to explain the anomalously high topography of the Southern and Eastern African Plateaus. Rifts exhibit a very distinctive topography, characterised by a series of fault-bounded depressions surrounded by higher terrain. In the East African system, a series of aligned rift valleys separated from each other by large bounding faults can be clearly seen from space.  Not all of these fractures formed at the same time, but followed a sequence starting in the Afar region in northern Ethiopia at around 30m years ago and propagating southwards towards Zimbabwe at a mean rate of between 2.5-5cm a year. Although most of the time rifting is unnoticeable to us, the formation of new faults, fissures and cracks or renewed movement along old faults as the Nubian and Somali plates continue moving apart can result in earthquakes. However, in East Africa most of this seismicity is spread over a wide zone across the rift valley and is of relatively small magnitude. Volcanism running alongside is a further surface manifestation of the ongoing process of continental break up and the proximity of the hot molten asthenosphere to the surface. The East African Rift is unique in that it allows us to observe different stages of rifting along its length. To the south, where the rift is young, extension rates are low and faulting occurs over a wide area. Volcanism and seismicity are limited.  Towards the Afar region, however, the entire rift valley floor is covered with volcanic rocks. This suggests that, in this area, the lithosphere has thinned almost to the point of complete break up. When this happens, a new ocean will begin forming by the solidification of magma in the space created by the broken-up plates. Eventually, over a period of tens of millions of years, seafloor spreading will progress along the entire length of the rift. The ocean will flood in and, as a result, the African continent will become smaller and there will be a large island in the Indian Ocean composed of parts of Ethiopia and Somalia, including the Horn of Africa. Dramatic events, such as sudden motorway-splitting faults can give continental rifting a sense of urgency. However, rifting is a very slow process that, most of the time, goes about splitting Africa without anybody even noticing.  This article was updated and the headline changed on April 7 to reflect ongoing discussion by geologists about the cause of the large crack that appeared on the East Africa Rift and whether its location is related to the African continent split."
"
Share this...FacebookTwitterThe largest city of my home state of Vermont — Burlington — was buried by a record-shattering 30.4 inches (ca. 80 cm) of snow from recent storm Stella.

Burlington, Vermont area gets buried by record-smashing snow as bitter temperatures grip region. Image cropped from Westford Webcam.
Hat-tip: reader Indomitable Snowman
Amusingly the reader Snowman just informed me by e-mail that 10 years ago Former Vermont governor Peter Schumlin (then Senate President) warned the state would need to plaster its beautiful green mountains with 500-foot tall industrial wind turbines in order to prevent massive warming. He said:
Any reasonable scientist will tell you that we’re going to rise anywhere between another two and three degrees in the next 30 years. That means that New Jersey’s climate is moving to Vermont in the next decade. That has tremendous implications in our economy’s ski, maple-sugar making, leaf-peeping and the list goes on and on. So we are — I at least am — looking at this with a major sense of panic.”
Well, it looks like the maple sugaring and ski season will be extended well into April — at least for this year. Schumlin’s prediction is yet another that is exposed as just plain idiotic and silly.
The massive snowstorm dumped 30.4 inches at the Burlington airport, making it the greatest March snowstorm on record and the 2nd largest all-time (records date back to 1883) in terms of snowfall. The biggest snowfall was 33.1 inches in January 2010.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




A daily record snowfall of 17.8 inches was set at Burlington, VT on March 14. This smashes the old record of 10.0 inches set in 1980. Also with 12.6 inches on March 15 the snowfall record was shattered for the date — previous record was 4.1 inches set way back in 1940.
For those claiming that it just doesn’t snow like it used to in Vermont, the statistics show that 4 of the top 10 snowfalls in fact occurred over the past 10 years, with 7 of the top 10 in the past 31 years!
What follows are the statistics provided by Snowman.
Top 10 greatest snowstorms (inches of snow) at Burlington, Vermont:
(1) 33.1 Jan 2-3 2010
(2) 30.4 Mar 14-15 2017
(3) 29.8 Dec 25-28 1969
(4) 25.8 Mar 6-7 2011
(5) 25.7 Feb 14-15 2007
(6) 24.7 Jan 13-14 1934
(7) 22.9 Mar 5-6 2001
(8) 22.4 Mar 13-14 1993
(9) 20.0 Nov 25 1900
(10) 19.7 Jan 25-28 1986
Top 4 March snowstorms for Burlington:
(1) March 14-15, 2017…30.4″
(2) March 7-8, 2011…..25.8″
(3) March 5-6, 2001…..22.9″
(4) March 13-14, 1993…22.4″
Top 5 Snowiest March`s at Burlington:
(1) 47.6 2001
(2) 39.9 1993
(3) 37.0 1896
(4) 33.1 1971
(5) 31.8 2017 thru 3/15
Top 5 daily snowfalls at Burlington for March 14:
(1) 17.8 2017
(2) 10.0 1980
(3) 6.9 1993
(4) 4.1 1956
(5) 4.0 1897
Top 5 Daily snowfalls at Burlington for March 15
(1) 12.6 2017
(2) 4.1 1940
(3) 3.5 1998/1933
(4) 3.4 1958
(5) 3.0 1901
 
Share this...FacebookTwitter "
"Scott Morrison has signalled the Australian government will not increase its efforts to combat climate change despite an extended bushfire crisis and a record-breaking heatwave. Returning to work on Sunday after a controversial family holiday in Hawaii, the Australian prime minister apologised for his absence on top of the mea culpa he offered on Friday while still overseas.  At a press conference after a visit to the New South Wales Rural Fire Service headquarters in Sydney, Morrison called on Australians to “be kind to each other” and reject division – but then accused those who want more action against global heating of political point-scoring. Morrison acknowledged that his absence – leaving deputy prime minister Michael McCormack in charge since Monday – had caused “great anxiety” and said if he had his time over he “would make different decisions”. Morrison asked Australians to be “fair-minded”, arguing he went on holiday to keep a promise to his children, and put a positive spin on the widespread community backlash at his absence. “I am comforted by the fact that Australians would like me to be here simply so I can be here alongside them as they go through this terrible time,” he said. “And so to those Australians who ... I had caused upset to I apologise for that.” Morrison then sought to turn the page on the episode by unilaterally declaring “the time for that discussion is over”. Morrison said there was “no argument” about the links “between broader issues of global climate change and weather events around the world” but it was “not a credible suggestion” to make a direct connection to any single fire event. Global heating is leading to longer, hotter, drier summers which experts agree increases bushfires’ frequency and severity. But Morrison said it was “one of many factors”, listing others including backburning, vegetation management, building codes, carelessness, arson and lightning strikes. On Saturday, McCormack said he “absolutely” agreed that “further action” to combat climate change is needed. Morrison appeared to snuff out hope his government will improve its policies, which have caused Australia to be rated worst out of 57 countries for its handling of climate change by a group of thinktanks. “I do not accept the suggestion that Australia is not carrying its weight,” he said. Morrison claimed that McCormack was “making exactly the point I’m making” – citing existing commitments in the Paris agreement to decrease Australia’s emissions by 26% by 2030 – although he also suggested there may be room for “further refinement” before 2030. Australia needs to cut emissions by 695m tonnes cumulatively across the next decade to meet its 2030 target. The Morrison government has said more than half of that cut, 367m tonnes, will come from accounting – using carryover credits from meeting earlier Kyoto targets – and not from practical emissions reduction. The centrepiece of Australia’s policy is a $2.55bn fund to pay polluters to reduce emissions, after the Liberal-National government abolished Australia’s carbon price in 2014. Asked about the use of carryover credits, Morrison replied that “people can expect my government to do what it promised to do, what it took to the last election”. “I know there are some who tried to make political points and score points over these issues in the midst of these disasters and that is disappointing.” Morrison said the government would not act in a “knee-jerk, crisis or panicked mode” – likening his refusal to increase ambition on climate change with the steady professionalism of those managing the bushfire emergency. “A panic approach and response to anything does not help. It puts people at risk. “Not just their livelihoods but, I mean, if you walk out there into the control room you will not see people panicking, you will see people be very professional, very focused on the job they have, talking to each other in a very professional way and getting the job done. Government’s the same thing.” Minutes after calling for an end to division, arguing, partisanship and point scoring, Morrison said the Coalition is reducing emissions without the “reckless job-destroying and economy-crunching targets that others are seeking to force upon us”. The government’s own projections show Australia is on course for 50% renewables by 2030 – a target which Morrison labelled as reckless and economy-wrecking in the May election campaign. Morrison flagged that he will discuss resourcing for future emergency management with states and territories at a meeting in March. Morrison said the government is considering calls to pay volunteer firefighters, but noted that is “in the first instance” a matter for state governments. Morrison later visited the families of Geoff Keaton and Andrew O’Dwyer, two volunteer firefighters killed late on Thursday near the town of Buxton, and conveyed his sympathies. Labor leader Anthony Albanese told reporters in Sydney it was a “good thing” Morrison is back but there was “no change” in the prime minister’s approach to the bushfires or climate change. “The deputy prime minister yesterday said [that] new measures were needed … and today, going from the acting prime minister to the real prime minister, we have a dismissal of the need for any action on climate change,” he said. Albanese said Morrison’s holiday was “a matter for his judgement”. “He chose to leave. He chose also to do it in a way that I think created a major issue of secrecy.” Earlier, the NSW premier Gladys Berejiklian and federal emergency management minister David Littleproud announced an additional $3.5m of disaster recovery funding to the Wingecarribee and Wollondilly local government areas. The commitment brings the total federal-state recovery fund to more than $63m."
"
Share this...FacebookTwitterThe Globe Has Not Been Warming . . .
So Why Is It Called ‘Global’ Warming?

There were at least 60 peer-reviewed scientific papers published in 2016 demonstrating that  Today’s Warming Isn’t Global, Unprecedented, Or Remarkable.
As of the end of January, another 17 papers had already been published in 2017.  17 New (2017) Scientific Papers Affirm Today’s Warming Is Not Global, Unprecedented, Or Remarkable
Within the last month, another 14 papers have been published that continue to cast doubt on the popularized conception of an especially unusual global-scale warming during modern times.
Yes, some regions of the Earth have been warming in recent decades or at some point in the last 100 years.  Some regions have been cooling for decades at a time.  And many regions have shown no significant net changes or trends in either direction relative to the last few hundred to thousands of years.  In other words, there is nothing historically unprecedented or remarkable about today’s climate when viewed in the context of natural variability.


Goursaud et al., 2017


Wilson et al., 2017



Cai and Liu et al., 2017
“2003– 2009 was the warmest period in the reconstruction. 1970– 2000 was colder than the last stage of the Little Ice Age (LIA).”


Tegzes et al., 2017
“The objective of this study was to investigate northward oceanic heat transport in the NwASC [Norwegian Atlantic Slope Current] on longer, geologically meaningful time scales. To this end, we reconstructed variations in the strength of the NwASC over the late-Holocene using the sortable-silt method. We then analysed the statistical relationship between our palaeo-flow reconstructions and published upper-ocean hydrography proxy records from the same location on the mid-Norwegian Margin. Our sortable-silt time series show prominent multi-decadal to multi-centennial variability, but no clear long-term trend over the past 4200 years. … [O]ur findings indicate that variations in the strength of the main branch of the Atlantic Inflow may not necessarily translate into proportional changes in northward oceanic heat transport in the eastern Nordic Seas.”




Fernández-Fernández et al., 2017
“The abrupt climatic transition of the early 20th century and the 25-year warm period 1925–1950 triggered the main retreat and volume loss of these glaciers since the end of the ‘Little Ice Age’. Meanwhile, cooling during the 1960s, 1970s and 1980s altered the trend, with advances of the glacier snouts.”


Tejedor et al., 2017

 

Guillet et al., 2017


Köse et al., 2017
“The reconstruction is punctuated by a temperature increase during the 20th century; yet extreme cold and warm events during the 19th century seem to eclipse conditions during the 20th century. We found significant correlations between our March–April spring temperature reconstruction and existing gridded spring temperature reconstructions for Europe over Turkey and southeastern Europe. … During the last 200 years, our reconstruction suggests that the coldest year was 1898 and the warmest year was 1873. The reconstructed extreme events also coincided with accounts from historical records. …  Further, the warming trends seen in our record agrees with data presented by Turkes and Sumer (2004), of which they attributed [20th century warming] to increased urbanization in Turkey. Considering long-term changes in spring temperatures, the 19th century was characterized by more high-frequency fluctuations compared to the 20th century, which was defined by more gradual changes and includes the beginning of decreased DTRs [diurnal temperature ranges] in the region (Turkes and Sumer, 2004).”



Flannery et al., 2017
“The early part of the reconstruction (1733–1850) coincides with the end of the Little Ice Age, and exhibits 3 of the 4 coolest decadal excursions in the record. However, the mean SST estimate from that interval during the LIA is not significantly different from the late 20th Century SST mean. The most prominent cooling event in the 20th Century is a decade centered around 1965. This corresponds to a basin-wide cooling in the North Atlantic and cool phase of the AMO.”


Mayewski et al., 2017


Rydval et al., 2017
“[T]he recent summer-time warming in Scotland is likely not unique when compared to multi-decadal warm periods observed in the 1300s, 1500s, and 1730s“

Reynolds et al., 2017


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Rosenthal et al., 2017
“Here we review proxy records of intermediate water temperatures from sediment cores and corals in the equatorial Pacific and northeastern Atlantic Oceans, spanning 10,000 years beyond the instrumental record. These records suggests that intermediate waters [0-700 m] were 1.5-2°C warmer during the Holocene Thermal Maximum than in the last century. Intermediate water masses cooled by 0.9°C from the Medieval Climate Anomaly to the Little Ice Age. These changes are significantly larger than the temperature anomalies documented in the instrumental record. The implied large perturbations in OHC and Earth’s energy budget are at odds with very small radiative forcing anomalies throughout the Holocene and Common Era. … The records suggest that dynamic processes provide an efficient mechanism to amplify small changes in insolation [surface solar radiation] into relatively large changes in OHC.”




Li et al., 2017
“We suggest that solar activity may play a key role in driving the climatic fluctuations in NC [North China] during the last 22 centuries, with its quasi ∼100, 50, 23, or 22-year periodicity clearly identified in our climatic reconstructions. … It has been widely suggested from both climate modeling and observation data that solar activity plays a key role in driving late Holocene climatic fluctuations by triggering global temperature variability and atmospheric dynamical circulation“




Dong et al., 2017


Nazarova et al., 2017
“The application of transfer functions resulted in reconstructed T July fluctuations of approximately 3 °C over the last 2800 years. Low temperatures (11.0-12.0 °C) were reconstructed for the periods between ca 1700 and 1500 cal yr BP (corresponding to the Kofun cold stage) and between ca 1200 and 150 cal yr BP (partly corresponding to the Little Ice Age [LIA]). Warm periods (modern T[emperatures] July or higher) were reconstructed for the periods between ca 2700 and 1800 cal yr BP, 1500 and 1300 cal yr BP and after 150 cal yr BP.”


Samartin et al., 2017


Thienemann et al., 2017
“[P]roxy-inferred annual MATs[annual mean air temperatures] show the lowest value at 11,510 yr BP (7.6°C). Subsequently, temperatures rise to 10.7°C at 9540 yr BP followed by an overall decline of about 2.5°C until present (8.3°C).”


Li et al., 2017
“Contrary to the often-documented warming trend over the past few centuries, but consistent with temperature record from the northern Tibetan Plateau, our data show a gradual decreasing trend of 0.3 °C in mean annual air temperature from 1750 to 1970 CE. This result suggests a gradual cooling trend in some high altitude regions over this interval, which could provide a new explanation for the observed decreasing Asian summer monsoon. In addition, our data indicate an abruptly increased interannual-to decadal-scale temperature variations of 0.8 – 2.2 °C after 1970 CE, in terms of both magnitude and frequency, indicating that the climate system in high altitude regions would become more unstable under current global warming.”


Krawczyk et al., 2017



Kawahata et al., 2017
“The SST [sea surface temperature] shows a broad maximum (~17.3 °C) in the mid-Holocene (5-7 cal kyr BP), which corresponds to the Jomon transgression. … The SST maximum continued for only a century and then the SST [sea surface temperatures] dropped by 3.5 °C [15.1 to 11.6 °C] within two centuries. Several peaks fluctuate by 2°C over a few centuries.”


Saini et al., 2017


Dechnik et al., 2017
“[I]t is generally accepted that relative sea level reached a maximum of 1–1.5 m above present mean sea level (pmsl) by ~7 ka [7,000 years ago] (Lewis et al., 2013)”


Wu et al., 2017
“The alkenone-based SST reconstruction shows rapid warming in the first 1500 years of the Holocene … an increase of sea surface temperature from c. 23.0 °C to 27.0 °C, associated with a strengthened summer monsoon from c. 10,350 to 8900 cal. years BP. This was also a period of rapid sea-level rise and marine transgression, during which the sea inundated the palaeo-incised channel … In these 1500 years, fluvial discharge was strong and concentrated within the channel, and the high sedimentation rate (11.8 mm/yr [1.18 m per century]) was very close to the rate of sea-level rise.”


Sun et al., 2017
“[A]t least six centennial droughts occurred at about 7300, 6300, 5500, 3400, 2500 and 500 cal yr BP. Our findings are generally consistent with other records from the ISM [Indian Summer Monsoon]  region, and suggest that the monsoon intensity is primarily controlled by solar irradiance on a centennial time scale. This external forcing may have been amplified by cooling events in the North Atlantic and by ENSO activity in the eastern tropical Pacific, which shifted the ITCZ further southwards. The inconsistency between local rainfall amount in the southeastern margin of the QTP and ISM intensity may also have been the result of the effect of solar activity on the local hydrological cycle on the periphery of the plateau.”


Wu et al., 2017


Park, 2017
“Late Holocene climate change in coastal East Asia was likely driven by ENSO variation.   Our tree pollen index of warmness (TPIW) shows important late Holocene cold events associated with low sunspot periods such as Oort, Wolf, Spörer, and Maunder Minimum. Comparisons among standard Z-scores of filtered TPIW, ΔTSI, and other paleoclimate records from central and northeastern China, off the coast of northern Japan, southern Philippines, and Peru all demonstrate significant relationships [between solar activity and climate]. This suggests that solar activity drove Holocene variations in both East Asian Monsoon (EAM) and El Niño Southern Oscillation (ENSO). In particular, the latter seems to have predominantly controlled the coastal climate of East Asia to the extent that the influence of precession was nearly muted during the late Holocene.”
 
 


Pendea et al., 2017 (Russia)
“The Holocene Thermal Maximum (HTM) was a relatively warm period that is commonly associated with the orbitally forced Holocene maximum summer insolation (e.g., Berger, 1978; Bartlein et al., 2011). Its timing varies widely from region to region but is generally detected in paleorecords between 11 and 5 cal ka BP (e.g., Kaufman et al., 2004; Bartlein et al., 2011; Renssen et al., 2012).  … In Kamchatka, the timing of the HTM varies. Dirksen et al. (2013) find warmer-than-present conditions between 9000 and 5000 cal yr BP in central Kamchatka and between 7000 and 5800 cal yr BP at coastal sites.”

Stivrins et al., 2017  (Latvia)
“Conclusion: Using a multi-proxy approach, we studied the dynamics of thermokarst characteristics in western Latvia, where thermokarst occurred exceptionally late at the Holocene Thermal Maximum. …  [A] thermokarst active phase … began 8500 cal. yr BP and lasted at least until 7400 cal. yr BP. Given that thermokarst arise when the mean summer air temperature gradually increased ca. 2°C beyond the modern day temperature, we can argue that before that point, the local geomorphological conditions at the study site must have been exceptional to secure ice-block from the surficial landscape transformation and environmental processes.”

Bañuls-Cardona et al., 2017 (Spain)
“During the Middle Holocene we detect important climatic events. From 7000 to 6800 [years before present] (MIR 23 and MIR22), we register climatic characteristics that could be related to the end of the African Humid Period, namely an increase in temperatures and a progressive reduction in arboreal cover as a result of a decrease in precipitation. The temperatures exceeded current levels by 1°C, especially in MIR23, where the most highly represented taxon is a thermo-Mediterranean species, M. (T.) duodecimcostatus.”

Åkesson et al., 2017 (Norway)
“Reconstructions for southern Norway based on pollen and chironomids suggest that summer temperatures were up to 2 °C higher than present in the period between 8000 and 4000 BP, when solar insolation was higher (Nesje and Dahl, 1991; Bjune et al., 2005; Velle et al., 2005a).”
Share this...FacebookTwitter "
nan
"Almost all governments in the world joined the Paris agreement in 2015 in an effort to tackle climate change. In the same year, many of the same governments paid about US$400 billion in direct and indirect subsidies to help people buy fossil fuels.  Subsidies are government policies which make energy cheaper than under normal market conditions. They mostly go towards fossil fuels, since most of the energy we use comes from oil, gas or coal. As one of us noted in a review published in the journal Ecological Economics, fossil fuel subsidies are a popular and pervasive tool for helping people across the world have access to energy. But it isn’t clear whether both trends are possible. Isn’t there a contradiction between subsidising fossil fuels and meeting Paris climate targets? And, if the subsidies are removed, won’t many people suffer without cheap energy?  Though recent analysis shows that the worldwide removal would not magically solve climate change, there are many reasons for reform beyond reducing emissions. There is increasing disillusionment with subsidies. As one senior OECD official puts it: Subsidies often introduce economic, environmental, and social distortions with unintended consequences. They are expensive for governments and may not achieve their objectives while also inducing harmful environmental and social outcomes. Therefore, there is growing political momentum against fossil fuel subsidies. In 2016, the G20 leaders reaffirmed an earlier pledge to phase them out. In theory, reforming or even completely removing these subsidies should not be a particularly difficult task because there is increasing evidence that they are not especially effective at poverty alleviation: the very reason they were introduced in the first place.  For example, an IMF study documented that across 20 developing countries the poorest fifth of the population received on average just 7% of the overall subsidy benefit, whereas the richest fifth received almost 43%. Another study looked at India and found that, of the US$22.5 billion spent on fossil fuel subsidies in 2010, less than US$2 billion benefited the poorest 20%. This is essentially because poorer households in poor countries use less fuel than wealthier households, even when energy is subsidised.  Subsidies can also paradoxically lead to energy shortages. In Myanmar, fixed prices for electricity, diesel and petrol have resulted in shortages when those prices fall below international market levels. This has convinced suppliers to focus on exports to China and Thailand rather than domestic use, and has stripped them of the revenues needed for infrastructure. Why does such an obviously inefficient policy stay around? One easy explanation may be that the main obstacle to subsidy reform is the fossil fuel lobbies. But recent research shows that the situation is not so simple. Most subsidies were introduced to serve a social mission and some have done it really well. Examples include the US’s Low Income Home Energy Assistance Program or the UK’s Warm Front Program, which helped 2.3m “fuel poor” homes.  In developing countries, subsidies are also typically introduced as well-meaning policies to support lower income groups and thus gain support from large numbers of people. And, although they are an extremely inefficient policy to support development, subsidies are sometimes the best option when institutions are under-developed. Around the world, almost all subsidies are aimed at consumers rather than producers. It’s true that the bulk of this money goes to richer households, but since energy makes up a larger share of poorer household budgets, subsidies are relatively more important for people on low incomes. Many governments therefore fear that removing them risks political upheaval. Despite this difficulty, the tension between providing energy subsidies to the poor and protecting the climate is not as insurmountable as it may seem. A recent article in Nature led by one of us shows that, if fossil fuel subsidies were removed worldwide, the largest emissions reductions would occur in oil and gas exporting regions: Russia and some of its neighbours, the Middle East, North Africa and Latin America. Most subsidies originate in these regions, but they also benefit fewer people living below the poverty line than in lower income countries such as India. This presents a unique political opportunity, because it is these oil and gas exporting countries where subsidy cuts would be most welcomed, as government budgets are squeezed by low oil prices. The trick to making subsidy reforms stick, even in the face of an oil price rise, is to combine them with effective pro-poor policies. Examples include India paying for cooking gas for those households which fall below a certain income level, or the way Indonesia and Iran have reallocated energy subsidy money to help finance infrastructure development and universal health care respectively. Ultimately, subsidy reform is not impossible, but neither is it easy. To gain maximum benefits for the climate while doing the minimum harm to the poor, reforms must be carefully targeted at the regions and sectors where they will be most effective."
nan
"
Share this...FacebookTwitterCorrection: Reader Fred informs that the SRF is not a German radio station, but instead belongs to Switzerland: “And yes, all people living in Switzerland are forced to pay around 300 US dollars a year for that crap, even if you never watch or listen the SRF […] it is just another leftwing propaganda machine.”
==================================================
The German public radio and television network is funded by mandatory annual fees made by every German citizen. It is massive and it dominates the country’s media landscape. Unfortunately it is not at all objective and balanced, though it may be claimed to be so at Wikipedia and elsewhere.
German public television, for example, works closely with CNN. It is unabashed totally anti-Trump. On November 9 when it became clear that Trump would be the next president, total shock and meltdown spread across all of the German public media.
Like the BBC, German public media are also very much universally climate alarmist, insisting the science is settled (even though it is less so than ever today). Some have argued quite convincingly that Germany is now firmly under a media-political opinion dictatorship – but that’s a topic for another day.
The latest example of climate propaganda and fake science purveyed by the elitist German politico-media comes from SRF German public radio, so reports Africa-geology expert Dr. Sebastian Lüning at his Die kalte Sonne site.
===========================================
SRF Africa correspondent gets it all wrong in Ghana: Embarrassing mixing up of coastal processes and climate change
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
On December 7, 2016, Patrick Wülser at Radio SRF went off on weepy sea level climate alarmism:
Climate change in Ghana: The ocean is swallowing Totope piece by piece
What climate scientists are predicting is already happening in Ghana: The fishing village has already in part sunken into the sea.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Rising sea level and ever more powerful tidal waves are eating away at the coast of West Africa and threatening fishing villagers. The consequences of climate change and the construction of deep-sea harbors and dams have accelerated the erosion of the coastline over the past 20 years. The fishing village of Toto in Ghana has already in part sunken into the sea.”
A rather cheap piece of propaganda theater, as just a critical glance at the map will clearly shows that this village is located in the Volta Delta on a typical coastal sand dune island, which because of the sand dune shifting and sea erosion — also without sea level rise — is always undergoing change naturally. The sediment-transport processes in the region were already comprehensively described in detail back in 1998 by Nairn et al. (pdf here).
Back then coastal protection measures were proposed, but obviously were never implemented.
But there’s more to the story as the huge Volta-water reservoir is pressing down the entire area of the Volta-Delta and its Akosombo dam is preventing the Volta’s land mass from reaching its old Delta area. This means sea erosion can no longer be compensated. Therefore it is easy to demonstrate that the situation described in Totope/Ghana has very little to do with climate change and rising sea level rise, and in fact has much more to do with changed land-use and natural coastal erosion processes.


Moreover, this new SRF propaganda piece is only a rehash of an older Zeit article from 2012.
When one looks at the Wikipedia entry on Song(h)or-Lagune, one cannot find the claimed huge danger through climate change anywhere. Rather the concerned focus is much more on unsustainable use, e.g. through over-fishing, cutting down of the mangroves and drainage in order to create more farmland:
Threats and possible consequences
The main threats to the site exist as varied forms of excessive utilization. Some common cases are over-fishing, extreme harvesting of mangroves, extensive drainage and cultivation for farmland, heavy grazing by cattle and livestock, and an unsustainable level of salt winning. These threats are difficult to neutralize because the human communities surrounding the lagoon are largely poor and over-populated. In effect, the local people are dependent upon their harvesting of the lagoon for survival. Although ecotourism provides an ecologically friendly source of income, the practice is not extensive enough to sustain the local communities. Additional threats originate from the use of pesticides and herbicides, the damming of creeks and channels for the purpose of expanding infrastructure, and rubbish dumping.[16] These threats can and, in some instances, have had dire consequences. The breeding cycles of nesting species, like the several sea turtle species hosted by the lagoon, can be disturbed by exaggerated human activity. Furthermore, the eggs of such species are often trampled by grazing cattle and livestock. Another realized effect of human exploitation is the apparent shrinking of the lagoon, which can be easily observed in the satellite photo comparison shown at the opening of this article. Further disturbance of the lagoon could result in not only the loss of species that inhabit the site, but also the loss of nutritive and moderating benefits provided by the site. Aside from purifying ground water, acting as a reservoir for nutrients, and supporting the local food chain, the lagoon regulates water flow, staggers and lessens the effects of flooding, and disperses the extreme erosive forces exerted on the shore by the Atlantic Ocean.[17]
re

Share this...FacebookTwitter "
"
Share this...FacebookTwitterAt today’s Weatherbell Daily Update, meteorologist Joe Bastardi looks at the forecast over the next 15 days for Europe. The following chart depicts the forecast accumulated snowfall by January 27, 2017.

Image cropped from Weatherbell 11 January 20017 Daily Update.
As the chart makes clear, plenty of winter snow is in the pipeline. The cold that Europe experienced earlier this month was likely just a preview of remains ahead for the continent. The widespread snow cover threatens to send nighttime temperatures to harsh levels. Bastardi even goes on to say that the snowfall over Europe will be “a big headline maker”.
Bastardi, a veteran in the forecasting business, also shows the GFS temperature outlook for January 22-27, which will follow 10 days of below normal tempertaures:

Almost the entire European continent will gripped by cold during the period. Joe promises that we are going to be seeing weather headlines coming out of Europe, and may well be similar to what happened in 2013.
That likely means a very late spring. The gardening industry should take note.
 
Share this...FacebookTwitter "
"Australia recorded its hottest day on record on Wednesday, with an average maximum temperature of 41.9C (107.4F), beating the previous record by 1C that had been set only 24 hours earlier. Tuesday 16 December recorded an average of 40.9C across the continent, beating the previous record of 40.3C set on 7 January 2013. But it held the record for just 24 hours.  Wednesday was even hotter across the country, with the highest maximum temperature reached in Birdsville, Queensland, which hit 47.7C (117.8). On Wednesday the lowest maximum was 19C at Low Head, Tasmania. On Thursday, Nullarbor in South Australia set the record for the hottest December day on record, recording 49.9C (121.8). To calculate the average maximum, the Bureau of Meteorology takes the maximum temperatures recorded in about 700 locations, puts them into a grid, calculates an average, and then cross-checks this against its long-term quality controlled record, known as ACORN-SAT. So why is Australia so hot? Dr Karl Braganza, manager climate monitoring at the bureau, told Guardian Australia: “Natural variability and global warming are pushing in the same direction. That’s why we have broken records.” Dr Andrew Watkins, head of long-range forecasts at the bureau, identified three key factors that have pushed temperatures to record levels – two of them natural, and one of them not. Australia is currently feeling the impacts of one of the strongest Indian Ocean Dipole events on record. When the IOD is positive, the waters off Australia’s north-west are cooler, dragging moisture away from the continent and leaving very dry conditions. On the flipside, Watkins said parts of east Africa had seen devastating impacts from flooding rains, in particular in Somalia, Ethiopia and South Sudan. “That positive IOD has kept things very dry in winter and spring,” Watkins said. “That sets us up with an extremely dry environment. It has been the second driest year to date and the warmest year to date.” A second natural driver, Watkins said, was a negative phase of the Southern Annular Mode that was kicked off by warming of the atmosphere high above Antarctica. The SAM had helped drive the extreme heat in NSW and Queensland, Watkins said, adding to the extreme fire danger. This has also brought drier and warmer air across the continent on westerly winds. SAM events usually only last a few weeks, but Watkins said this event had been present since October. “All of this is leading to central Australia baking,” he said. “There’s nothing there to evaporatively cool the air.” He said an example of this heat was revealed in forecast temperatures in recent days of between 43C and 45C for Alice Springs. “When I see those forecasts I say, ‘wow.’ Because Alice Springs is 550m above sea level. 45C half a kilometre up is pretty insane. “Meteorologists will say that you get roughly 1C per 100m of elevation so we know that means the air at the surface would have been in the high 40s.” Underlying these two major drivers of the heat is climate change – the simple physics of loading the atmosphere with extra greenhouse gases, mainly by burning fossil fuels. Australia’s latest State of the Climate report shows the country has warmed by just over 1C since 1910, leading to more extreme events. Watkins said: “That long-term warming sees the bar lifted up so that it’s easier to get extreme conditions now than it was 50 or 100 years ago,” “One part of me says that this is amazing but then another says that we have seen this in other parts of the world so we’re not especially surprised.” He pointed to France’s heatwave of June 2019, when Montpellier hit 43.5C, breaking its previous all-time heat record set in August 2017 by a huge 5.8C. “I’m not sure we are shocked by much any more.” Dr Sarah Perkins-Kirkpatrick, a climate scientist at the University of New South Wales specialising in extreme events, said climate change had given the natural drivers of Australia’s record -breaking heat “extra sting.” She said without the extra CO2 in the atmosphere “it would still have been warm”, but, she added: “I doubt very much we would have seen a record on Tuesday and then another one on Wednesday. And we are still at the beginning of the summer with a long way to go.” On Thursday, she was driving through thick smoke haze in north-west Sydney with her family. She said: “It is frightening and a little frustrating, but this is what climate scientists have been saying for decades. “I’m bordering on saying ‘I told you so’ but I don’t think anyone really wants to hear that.”"
"
Share this...FacebookTwitterReader Indomitable Snowman sent a link to an AccuWeather report telling us of the intense winter weather gripping eastern Europe and how it has claimed close to 60 lives thus far. German weather site wetteronline.de also reports of close to 60 cold deaths so far from the current Eastern European cold blast.
Although we get scattered reports of cold deaths here in Europe, it’s been tough to find a total tally from the German global warming-devout mainstream media.
Accuweather writes:
Millions of people from Baltic states and Poland southward to the Mediterranean Sea have endured dangerous cold and bouts of snow. Thousands of refugees have also had to endure the bitter cold which is expected to last through at least Thursday. Temperatures plummeted to the lowest level in years in Warsaw, Minsk, Budapest and Moscow.”
Rescue from cold for the birds?
Entering the German term “Kältetote” (cold deaths) in Google, one gets few reports of the total deaths in Europe (at the time this post was written) from the German mainstream media. Online daily Bild did wrote here 2 days ago how the intensely cold conditions posed a dangerous threat to refugees in transit. Indeed this was true, and it still is.
Yet, another site here seem to think the real story of the day was how one man rescued a bird from freezing to death — as if poor citizens do not matter so much?
Die Welt reports 50 victims
To its credit, the online Die Welt here reported on the eastern European cold deaths earlier today:
Especially in the east and south of the continent several dozen people have frozen to death, in Belarus, Ukraine, in Hungary and Slovakia, in Bosnia, Austria, Belgium and Italy. Especially hard hit is Poland, where the mercury fell at times to -30°C. […] In total the cold wave in January has claimed so far about 50 victims, since November the number is close to 70 people.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The most vulnerable unable to afford heat
Moreover it appears that Europe’s socialist, compassionate systems aren’t really doing their job of helping society’s weakest. Die Welt comments that “pensioners, the unemployed and the homeless often cannot afford heating” and thus are the ones paying the price of a low-energy society with their lives.
Die Welt has been reporting regularly on the story, writing four days ago how the cold was claiming the lives of refugees and the homeless.
Cold wave forecast to spread, continue
Unfortunately there is going to be no let up in people freezing to death. The cold and wintry mix will spread across central Europe by the weekend, according to wetteronline.de.
 
Western Europeans need to brace themselves. Image: wetteronline.de
The German weather site writes:

A powerful high over the Baltic Sea and a strong Mediterranean low will flood the continent with Siberian cold air across all of Central Europe next week. Even highs of -10°C are within the range of possibility. […] Temperatures will fall into the cellar. With the exception of coastal areas and maybe northwest Germany, permanent frost conditions will persist for almost the entire week.. In the south high temperatures will range from -10 to -5°C.”

 
Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitterBefore getting to the yesterday’s Trump/Macron press conference, first I wish to bring up the nice reaction we got from Curtis Stone, the urban farmer I featured here a couple of days ago here in a less than flattering manner. (Now I wish I had not been so hard on him).
Here’s the comment he left:
Hey Pierre, a friend of mine forwarded this article you wrote about me. I want to thank you for it and let you know that I agree with most of what you said in the article. That video you found on me is pretty old. I have changed my views a lot in the last number of years. I am very pro free market and also think man made climate change is BS! Anyways, thanks for the article. I had a good laugh reading it. I can’t believe how much I’ve changed since then.
Best.
Curtis Stone”
You see, people do grow out of phases. The good news is that once someone figures out a complex issue like climate, they never go back and ‘unfigure’ it out. The alarmists have lost one.
================================================
Macron Budges On Climate

New signals coming from Paris? Public domain photo.
After Trump rejected the Paris Accord weeks earlier, Europeans huffed and vowed that the Paris Accord was not up for any negotiation. Signatories, led by Germany and France, them seemed to move to isolate the United States and President Donald Trump. But now it seems Macron his softened the line a bit.
Trump offering “commitments”, Macron open to talk


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




At mentioned “commitments” from Trump and that they were open to talk about the climate accord.

 
At the 16:20 mark of the video above when asked by a reporter about Trump possibly getting back onboard the Paris climate accord, Macron replied by confirming there were indeed “a number of disagreements” on the issue, but that the climate disagreement “should not have an impact on the other topics“.
The French President affirmed that they “share the same views some major common goals on many other topics, all other topics.” Macron the stated on climate:
Next, well of course President Trump…will tell you about it, but he’s made a number of commitments, that we are going to be working together and my willingness to continue to work with the United States and the President on this very major topic. I understand that it’s important to save jobs and that being said, we shall leave the United States of America work on what it’s roadmap and to continue to talk about it.”
Will “continue talking”
Before Macron emphasized his strong commitment to the Paris Accord, he added:
I believe there is a joint willingness to continue talking about this, and to try and find the best possible agreement.”
From the press conference we can gather that Trump “made some commitments, though no details on this were provided. Moreover it is made clear that they are going to keep discussing the issue, which means that the Accord may be not yet set in stone after all.
 
Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitterMost Of Warming Trend Since 1980s
Is Naturally Driven, Not CO2-Driven

According to a new statistical analysis of centennial-scale surface temperature changes, half (0.5 °C) of the warming trend over the last 135 years (0.95 °C) can be explained by both (a) the existence of commonly-occurring natural (non-anthropogenic) variations of temperature that can reach the same amplitudes of the modern trend (see above image), and (b) external factors such as solar activity and greenhouse gases, with the latter factor accounting for “less than is commonly believed”.
Scientist Dr. Maxim Ogurtsov and his colleagues cite extensive evidence that any external forcing of the modern trend that falls outside the range of natural variability can be appreciably attributed to non-greenhouse factors.

Ogurtsov et al., 2017
It is widely accepted also that this global warming is caused primarily by anthropogenic increase of greenhouse gases concentration . However debates on this question still continue.
Some experts maintain that current warming does not exceed the natural fluctuations of climate. Evidence of appreciable contribution to global warming of non-greenhouse factors has been obtained by many authors.
1.  Soon et al., 2015 noted that if the urbanization effect is properly taken into account, one can conclude that solar variability is the dominant factor of Northern Hemisphere long-term temperature changes since at least 1881.
2.  Zhao and Feng, 2014 reported that variations in solar activity play an important role in changes of climate over global scale during the last more than 100 years.
3.  According to Harde (2014), the Sun is the main contributor to global warming of the last century.
4.  Lüdeсke et al. (2014) showed that variations of Central European temperature after 1757 were likely governed by periodic oscillations resulted from intrinsic climatic dynamics.
5.  Scafetta (2010) and Scafetta (2012) claimed that the global climate oscillations from 1950 to 2011 were appreciably influenced by astronomic planetary cycles, particularly by motion of Jupiter and Saturn.
6.  Swanson and Tsonis, 2009 noted that in the period 1900-2000 Northern Hemisphere climate variability might be partly explained by chaotic dynamics.
7.  Privalsky and Fortus (2011) modeled variations of global temperature during 1850- 2009 as an autoregressive process of the fourth order. They arrived at a conclusion that global warming of the last 150 years could be fully explained by natural climatic variability without any external forcing.
Conclusion
[I]t is reasonable to regard the global warming as a phenomenon exceptional from the point of view of intrinsic climatic oscillations, which need an additional external forcing factor for explanation. On the other hand, the statistical experiments showed that an appreciable part of the global warming might be a result of natural fluctuations of climatic system. … [O]ur results show that the contribution of these external factors (including greenhouse effect) to the global warming could be less than is often believed.
Changes in the solar radiation at the Earth’s surface (global brightening) might be important source of the warming of the last decades (Ogurtsov et al., 2012).

Surface Incident Solar Radiation Trend Since The 1980s Can Explain All Recent Warming (And More)

As noted in their conclusion above, Ogurtsov and colleagues have previously published a paper that establishes surface incident solar radiation (SSR) – solar radiation absorbed (or not) by the Earth’s surface (oceans) via decadal-scale reductions (or increases) in cloud cover – can account for all of the radiative forcing of temperature changes during the 1983 to 2001 period, when surface temperatures increased by about 0.5 °C.   In fact, the intensity of the direct, shortwave forcing during that 18-year period – 3 W m–2 to 6-7 W m–2 – was larger than the resulting temperature change itself.

Ogurtsov et al., 2012
Changes in the climate of the Earth depend evidently on the background solar irradiance, i.e. on the amount of shortwave solar radiation incoming into the atmosphere and the fraction of this radiation, which is reflected back to the space. Recent evidence show that solar radiation incident at the Earth’s surface has increased appreciably in the end of 20th century (Pallé et al, 2006). The phenomenon is often called a global brightening.
Change in background solar radiation through 1983- 2001 causes a positive radiative forcing ranging from 3 W × m–2 to 6 – 7 W × m–2 . If we take a value of climatic sensitivity adopted by IPCC, we obtain that increase of the global temperature by 1.5˚C – 3.6°C is a result of the radiative forcing of 3 W × m–2.


In Contrast, CO2 Forcing Contributes Just 0.2 W m–2  Per Decade To Modern Warming

According to climate models, the total climate forcing effect of the roughly 120 parts per million (ppm) increase in atmospheric CO2 during the ~165 years since 1750 is 1.8 W m–2.
As assessed in a 2015 paper published in the journal Nature, the CO2 concentration increased by 22 ppm during the first 10 years of the 21st century.  The radiative forcing (warming) effect of this 22 ppm CO2 increase was modeled to be 0.2 W m–2.  So of the 1.8 W m–2 of total CO2 radiative forcing since 1750, 0.2 W m–2 was added during the first decade of this century.

So if CO2 forcing accounts for roughly 0.2 W m–2 per decade of the globe’s radiative forcing with an increase of 22 parts per million (ppm), and if surface incident solar radiation (SSR) accounts for 3 to 6-7 W m–2 for the 18-year period (~2.5 W m–2 per decade)between 1983 and 2001, it could be reasonably concluded that surface incident solar radiation could account for at least 10 times more of the modern climate forcing as CO2 increases have.  Graphed, the difference in trends may look like this:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





In sum, not only is the variation in temperature of the last 135 years not remarkable or outside the range of what can be achieved naturally or internally, but the magnitude of the external forcing from surface incident solar radiation for recent decades far exceeds the reputed attribution from CO2 concentration changes.   Therefore, it could reasonably be said that there is no clear anthropogenic signal detectable in the climate changes of the last 135 years when one considers the contexts of natural variation and natural climate forcing.

Supporting Scientific Papers

Goode and Palle, 2007
The decrease in the Earth’s reflectance from 1984 to 2000 […] translates into a Bond albedo decrease of 0.02 (out of the nominal value of about 0.30) or an additional global shortwave forcing of 6.8 Wm2. To put that in perspective, the latest IPCC report (IPCC, 2001) argues for a 2.4 Wm2 increase in CO2 longwave forcing since 1850. The temporal variations in the albedo are closely associated with changes in the cloud cover.
Conclusion: In this paper we have reviewed the physical mechanisms behind solar irradiance variation, and we have reviewed how on the timescale of solar evolution, the Sun cannot have been any dimmer than it is at the most recent activity minima. We have also shown how concurrent changes in the Earth’s reflectance can produce a much larger climate impact over relatively short time scales. Thus, a possible Sun–albedo link, would have the potential to produce large climate effects without the need for significant excursions in solar irradiance. These could provide an explanation for the apparently large climate response to apparently small solar changes, as well as how the 11/22 year solar cycle is imprinted on Earth. Regardless of its possible solar ties, we have seen how the Earth’s large scale reflectance—and the short wavelength part of the Earth’s radiation budget—is a much more variable climate parameter than previously thought and, thus, deserves to be studied in as much detail as changes in the Sun’s output or changes in the Earth’s atmospheric infrared emission produced by anthropogenic greenhouse gases.
Herman et al., 2013
[T]here has been a global net decrease [of 3.6%] in 340 nm cloud plus aerosol reflectivity [which has led to] an increase of 2.7 W m−2 of solar energy reaching the Earth’s surface and an increase of 1.4% or 2.3 W m−2 absorbed by the surface [between 1979 and 2011].
Sanchez-Lorenzo et al., 2017
Downward surface solar radiation (SSR) is a critical part of the Global Energy Balance and the climate system … Pinker et al. (2005) used a different product (2.5° resolution) and found that the derived global mean SSR series underwent a significant increase of 1.6 W m−2 per decade from 1983 to 2001. … On the other hand, Hatzianastassiou et al. (2005) derived a SSR product from 1984 to 2000 (2.5° resolution) and reported a significant increase of +2.4 W m−2 per decade in the global mean series, which is considerably higher than the results from Pinker et al. (2005) and Hinkelman et al. (2009).
Posselt et al., 2014
Global [surface solar] radiation has an overall positive, and significant, trend [1983-2010] over the Meteosat disk which is mainly due to a negative trend in the effective cloud albedo, i.e., a decrease in cloudiness. Trends due to changes in the clear sky radiation are small and only induced by trends in the water vapor fields. Trends caused by changes in the direct effects of atmospheric aerosol are not represented because an aerosol climatology is used.
All considered regions show positive trends for the extended CM SAF surface radiation dataset pointing to an increase in solar surface radiation and, thus, a brightening by either a decrease in cloudiness or a decreased atmospheric absorption of solar radiation. However, the extent and also the significance of the trends in the different regions vary substantially. The trend for Europe of 4.35 W m− 2 dec− 1 is in the order of trends derived from surface measurements by Wild (2012) of 2 W m− 2 / dec− 1 for the 1980s to 2000 and 3 W m− 2 / dec− 1 after 2000.
Wild et al., 2005
The changes in both satellite derived and measured surface insolation data are also in line with changes in global cloudiness provided by the International Satellite Cloud Climatology Project (ISCCP), which show an increase until the late 1980s and a decrease thereafter, on the order of 5% from the late 1980s to 2002. A recent reconstruction of planetary albedo based on the earthshine method, which also depends on ISCCP cloud data, reports a similar decrease during the 1990s. Over the period covered so far by BSRN (1992 to 2001), the decrease in earth reflectance corresponds to an increase of 6 W m-2 in absorbed solar radiation by the globe. The overall change observed at the BSRN sites, estimated as an average of the slopes at the sites in Fig. 2A, is 0.66 W m-2 per year (6.6 W m-2 over the entire BSRN period).
McLean, 2014
The reduction in total cloud cover of 6.8% [between 1984 – 2009] means that 5.4 Wm−2 (6.8% of 79) is no longer being reflected but acts instead as an extra forcing into the atmosphere… To put this [5.4 Wm-2 of solar radiative forcing via cloud cover reduction between 1984-2009] into context, the IPCC Fifth Assessment Report…states that the total anthropogenic radiative forcing for 2011 relative to 1750 is 2.29 Wm−2 for all greenhouse gases and for carbon dioxide alone is 1.68 Wm−2.  The increase in radiative forcing caused by the reduction in total cloud cover over 10 years is therefore more than double the IPCC’s estimated radiative forcing for all greenhouse gases and more than three times greater than the forcing by carbon dioxide alone [from 1750 to present].
Hukuba et al., 2017
At 36 locations worldwide, we estimate the cloud radiative effect (CREatm) on atmospheric solar absorption (ASRatm) by combining ground-based measurements of surface solar radiation (SSR) with collocated satellite-derived surface albedo and top-of-atmosphere net irradiance under both all-sky and clear-sky conditions. To derive continuous clear-sky SSR from Baseline Surface Radiation Network (BSRN) in-situ measurements of global and diffuse SSR, we make use of the Long and Ackerman (2000) algorithm that identifies clear-sky measurements and empirically fits diurnal clear-sky irradiance functions using the cosine of the solar zenith angle as the independent variable. The 11-year average (2000-2010) CREatm (all-sky minus clear-sky) is overall positive at around +11 Wm-2 using direct measurements form ground and space, and at 4 Wm−2 in the CERES EBAF dataset. This discrepancy arises from a potential overestimation in clear-sky absorption by the satellite product or underestimation by the combined BSRN/CERES dataset. The forcing ratio R shows that clouds enhance ASRatm most distinctly at desert-like locations that overall experience little occurrence of clouds. This relationship is captured by both the combined dataset and CERES EBAF.
Avakyan, 2013
The author associates the recently observed climate warming and carbon dioxide concentration growth in the lower atmospheric layers with variations of solar-geomagnetic activity in global cloud formation and the significant decrease in the role of forests in carbon dioxide accumulation in the process of photosynthesis. The contribution of the greenhouse effect of carbon-containing gases to global warming turns out to be insignificant.
Wielicki et al., 2002
It is widely assumed that variations in Earth’s radiative energy budget at large time and space scales are small. We present new evidence from a compilation of over two decades of accurate satellite data that the top-of-atmosphere (TOA) tropical radiative energy budget is much more dynamic and variable than previously thought. Results indicate that the radiation budget changes are caused by changes in tropical mean cloudiness. The results of several current climate model simulations fail to predict this large observed variation in tropical energy budget. The missing variability in the models highlights the critical need to improve cloud modeling in the tropics so that prediction of tropical climate on interannual and decadal time scales can be improved.
Stozhkov et al., 2017
The global millennial temperature rising trend seen in Figure 11 from 1984 to the peak and trend inversion point in the Hadcrut3 data at 2003/4 is the inverse correlative of the Tropical Cloud Cover fall from 1984 to the Millennial trend change at 2002. The lags in these trends from the solar activity peak at 1991 (Figure 10) are 12 and 11 years, respectively. These correlations suggest possible teleconnections between the GCR flux, clouds, and global temperatures.

Share this...FacebookTwitter "
"Earth’s crust is made up of fractured slabs of rock, like a broken shell on an egg. These plates move around at speeds of about 5cm per year – and eventually this movement brings all the continents together and form what is known as a supercontinent. The last supercontinent on Earth was Pangaea, which existed between 300-180m years ago. This collection and dispersion of the continents is known as a supercontinent cycle, and the world now is 180m years into the current cycle. It is predicted that the next supercontinent will form in about 250m years, when the Atlantic and Pacific oceans both close and a new ocean forms where the large Asian plate splits. Because the plates move around, ocean basins change their shape and size. For example, the Atlantic is currently expanding at about the rate your fingernails grow (a couple of centimetres per year), whereas the Pacific is slowly closing.  These changes in the ocean basins can have a very large impact on the tides over millions of years. This is because the tide moves around the oceans like a very long wave, with more than 1,000km between two peaks. The way this wave moves is largely controlled by the shape of the ocean basin and its depth, and if the ocean has the right size – if the length of a basin is half that of the wave, or “resonant” – the tides can become very large.  Resonance can happen in any system that swings or oscillates if you force it at its natural period. For example, if you give a child on a swing a small push at the right time, they will swing higher and higher, because you are forcing them at the natural period of the swing. The period of the tide is set by the motions of the Earth, moon and sun – and the natural period of an ocean basin is set by its geometry. For example, today, the north Atlantic is very near resonance because these two periods are almost the same. This is why the tides in the Atlantic are much larger than those in the Pacific or Indian Oceans.  But this has not always been the case. From experiments with computer models which can simulate the tides with great accuracy, we know that the tides were weak for long periods of the current supercontinent cycle, because the shape and size of the basins couldn’t support large tides. In fact, of the past 250m years, it is only the last 2m years or so that have seen large tides on Earth. Since we are approaching the halfway point of the supercontinent cycle, we asked ourselves a question: what will happen to the tides as the next supercontinent assembles in 250m years or so? Is it possible that there is a supertidal cycle linked to the supercontinent cycle? Using the computer model, we have now found that there is indeed a supertidal cycle linked to the supercontinent cycle. In fact, there are two: we are currently at the start of one “tidal maximum”, a period of time when the tides are very large. They will then weaken significantly, before briefly becoming large again in around 150m years from now. After that, the tides will again drop down to less than half of the energy levels they have at present as the next supercontinent forms. This will happen because the basins go in and out of resonance as their shape changes. The tidal maxima are brief in geological terms and only last 20m years or so. For most of the time, the tides are less energetic than they are today and, over the 400-600m years between the formations of the two supercontinents, the tides are only large for 50m years in total.  Tides are a major energy source for the ocean: the energy pumped into the tide by the sun and the moon is lost, or dissipates, within the ocean. This energy helps stir the ocean – much like a spoon stirs a cup of coffee. In the same way as the spoon moves sugar and milk around in the cup, the tide can drive movements of nutrients, heat and salt between the deep ocean and the surface. Fluxes of heat and salt are key to the large-scale climate controlling ocean circulation and fluxes of nutrients help sustain biological production, especially in shallow seas.  Changes in tides on any timescale can have large effects on the whole Earth system. While the changes described here may not have impact on us in the immediate future, it adds to our understanding of how the tides interact within various disciplines – including plate tectonics, the climate system, nutrient recycling and, eventually, the ocean’s ability to evolve and host life."
"While many prospective holidaymakers actively seek a change in cuisine or climate when choosing their destination, standardised sanitation usually remains a must. You might think that the preference for a porcelain pew is harmless, but in reality it can put a serious strain on both the local population and the environment. In fact, many of the most pervasive problems associated with tourism can be seen through the toilet bowl. Research suggests that in some locations up to 40% of water is consumed by tourists. Tourists tend to splash out far more per day on average than local residents, who are often outcompeted by industry for water access. Using limited freshwater supplies to flush tourists’ toilets means less for residents’ drinking, cleaning and cooking needs. Environmentally, the sheer volume of incoming tourists can come at a high price. Local sewage facilities often struggle to cope with the influx of human waste. Many small islands with limited infrastructure, such as Barbados, have no choice but to pump raw sewage straight into the sea, putting vast swathes of the Caribbean’s coral reefs at risk. This defecatory deluge also depletes limited water reserves. In Cape Town, hotels are having to abruptly limit guests’ water usage as the city suffers drought. In Bali, fast-growing tourism demand is linked to rapid depletion of the island’s water resources. These economic and environmental harms often stem from a misplaced sense of cultural superiority that accompanies us to the bathroom. The internet is awash with travellers’ toilet horror stories, written with apparently little social sensitivity or willingness to compromise. Those fortunate enough to be able to travel might want to remind themselves of UN estimates for 2017, which suggest that 61% of the global population – roughly 4.5 billion people – lack access to a toilet or latrine that disposes of waste safely. Westerners tend to judge other cultures harshly, when really they should be judging global inequality, poverty and politics. Perhaps some judgement should be reserved for people in rich countries themselves, where bathroom norms aren’t exactly perfect. For example, squatting rather than sitting is better for the colon. Rather than a sight to be avoided, a glance at one’s waste before flushing can in fact be a quick and easy health check. Embarrassment about bodily functions is inhibiting when holidays are meant to be liberating. Different sanitation solutions suit different situations. The World Bank and the WWF have both worked to celebrate toilet innovations across the world that challenge preconceptions and improve sustainability. For instance, urine-diverting privies in Bolivia are an integral link in a chain that converts waste into fertiliser for growing crops. Cranfield University is developing the Nano Membrane Toilet, which converts waste into clean water and energy, without the need for external power or water. Some Western tourist locations are already rethinking their taste in toilets. Composting toilets introduced in various Scottish nature reserves have proved highly popular with visitors. Melbourne Zoo and other attractions have implemented water conservation and recycling measures in restrooms, including waterless urinals. The increasing use of such practices by authorities and businesses will only help to challenge harmful expectations when people travel further afield. There are also simple changes that tourists can make when going to the bathroom that will have a positive impact on the environment and local communities, and possibly even lead to more interesting holiday experiences. Remember that different ecological settings require different bathroom styles. Always avoid flushing wipes and other non-biodegradables. In water stressed areas, be conscious of your water usage. Don’t demand what local people don’t have. The threat of extreme drought has forced Cape Town luxury hotels to ask guests to limit the length of showers, turn off the tap while brushing their teeth, and let it mellow if its yellow, but actions like these could benefit locals in tourist destinations across the developing world. Support small businesses. Their toilets may not always be gleaming, but the experience might be more memorable. While luxury tourism in developing countries rarely benefits those in need, going local is one way to contribute.  Lastly, nurture your sense of adventure. If you want to live like a local, you should defecate like one. Pack your hand sanitiser and spare toilet roll, and immerse yourself in local culture. Get ready to try out new facilities, not just whatever commode is à la mode. There are toilet attractions dotted all over the globe that are well worth a visit. For example, why not try the Haewoojae Museum in South Korea, solely dedicated to celebrating the lavatory. We shouldn’t expect all toilets to look the same. Tourism is about challenging expectations, exploring alternatives and expanding horizons. For the sake of the environment and the vulnerable, it is high time that we became more open-minded and adventurous with our toilette when travelling. After all, when in Rome, wipe as the Romans wiped (using a wet sponge on a stick, apparently)."
"Why would animal rights organisation PETA praise a film in which a group of apes are brutally attacked by humans? The answer is that War for the Planet of the Apes, the most recent movie in the franchise, used no real primates in its filming. Yet while computer generated imagery is now good enough to create realistic looking animals on screen, some movies still employ actual non-human primates. In the last few years, primate actors have been used in major Hollywood films such as The Hangover Part II (2011), The Wolf of Wall Street (2013) and Pirates of the Carribean: Dead Men Tell No Tales (2017). Regardless of how these animals are treated on set, the reality is that they’re being placed in unnatural environments and made to act for other people’s amusement against their will. What’s more, there’s evidence that using real primates on screen actually encourages the illegal pet trade. It’s estimated that more than 3,000 great apes and hundreds of thousands of other primates are traded as pets and bush meat each year.  A recent study of films released between 1990 and 2013 found 70 movies in which primate actors appeared. Chimpanzees, capuchins and old-world monkeys were the most commonly used animals. The study found that more than half the time they were shown among people, dressed up and performing human actions. It also found that primates on screen were “smiling” 19% of the time, something that primatologists widely recognise as an expression of fear or submission. Using primate actors was just as common at the end of the time period studied, even though much more had been learned about the complex welfare needs of these animals. The study concluded that using primates in film-making compromised their welfare by removing them from their social groups, training them to perform unnatural actions, and denying them the opportunity to behave naturally. All of these things have lasting negative psychological and physical effects on primates. The research also showed that using primates in films made people think the animals were less endangered than they really were, something backed up by a number of other studies. For example, one paper from 2008 surveyed members of the public and found 95% of respondents thought gorillas were endangered, 91% perceived orangutans to be endangered, but only 66% believed that chimpanzees were endangered. The specific survey responses suggested that this was because chimpanzees are often seen in films and TV programmes and their images often appear on comical greeting cards and in advertisements. The participants in that research were also shown videos of chimpanzees in their natural environment and in unnatural situations, such as dancing to music or working in an office. Those who watched the unnatural videos were more likely to think it was acceptable to own a pet chimp and less likely to think the animal was endangered. This was echoed by a 2011 study that just seeing a photo of a chimp and a human together, as opposed to a chimp on its own, increased the probability of participants wanting the animal as a pet. Further research from 2015 analysed comments from viewers after watching a YouTube video of a human tickling a slow loris. They found 25% of viewers wanted to keep a slow loris as a pet, but when information about their conservation crisis was added, this dropped to 10%. Although the human owner may have thought the slow loris enjoyed being tickled, the primate was raising their arms to activate their defence venom. From this evidence, we can see how portraying primates as human caricatures in the media fuels demand for them as pets. The illegal pet trade sees wild infant primates taken from their highly protective mothers soon after birth. Poachers will often kill the adults as they fight to protect the infant from being taken. The adults are sold as bush meat at local markets and the infants sold illegally as pets. These traumatised infants, who would normally spend up to five years with their mothers living in complex social groups, are deprived of normal development by their human carers. It’s increasingly common for primate owners to share videos of their “pets” on social media being clothed, bathed, fed inappropriate diets and forced to interact with domesticated animals such as dogs.  Pet primates are also often permanently harmed to make them “safer” for their human owners. For example, pygmy marmosets (also known as finger monkeys), the most trafficked primate species after squirrel monkeys, live in the Amazon rain forest and have sharp teeth to drain sap from trees. Pet traders will often remove the monkeys’ sharp teeth to prevent potential owners from getting bitten. Shockingly, it is not illegal to own one of these primates in the UK – and owners are often unaware of how and where their pets were obtained. Exploiting wild primates for entertainment must be stopped. The evidence suggests that using these animals in film-making, especially when they’re so often portrayed as human companions and caricatures, only adds to the demand for their part in the brutal illegal pet trade.  The Planet of the Apes series and other films have proven that animatronics and computer graphics offer a realistic substitute for the use of primate actors. But there is still concern that portraying primates, whether real or robotic, with humans and in unnatural situations gives the dangerous impression that they make suitable pets."
"Australia’s official greenhouse gas records have been adjusted such that emissions are now significantly higher than previously believed for the years when Labor was in power, and no longer rise each year since the Coalition repealed the carbon price. The revisions, made clear in data published during the recent UN climate conference in Madrid, have allowed Scott Morrison to start claiming that emissions are now lower than when the Coalition was elected in 2013 and in any year when Labor was last in government. That was not the case a year ago. As the graph below shows, changes to the data over the past year have increased emissions in the years of the Rudd and Gillard governments by between 3.5% and 6.7%. Emissions have been increased by smaller amounts or slightly reduced for the years since the Coalition regained power. Most of the large revisions are due to a change in how the amount of carbon dioxide released from or absorbed by soil in grazing land is estimated. Guardian Australia asked several experts in greenhouse accounting about the changes. Some said they were legitimate and an improvement, as they factored in the impact of the climate crisis on soil carbon levels. Others said the size of the changes, and the fact they significantly favoured the government’s narrative as it was facing rising criticism for not doing more to tackle emissions, warranted further explanation. The total revisions in emissions from the land and forests, including soil carbon, across the years in the graph up to 2018 was 382.6m tonnes of carbon dioxide. For emissions from fossil fuel and other industries, 41.2m tonnes worth of adjustments were made. Labor’s climate spokesman, Mark Butler, said he was concerned the government was using poorly explained revisions to emissions data to attack Labor and as an excuse not to act on climate change, singling out the emissions reduction minister, Angus Taylor. “This minister has form,” Butler said. “I hope he’s not continuing that form by politicising the reporting of emissions data.” A spokesman for Taylor said the emissions estimates by the Department of the Environment and Energy were made in accordance with international treaty requirements and subject to independent expert review each year. The department said the latest inventory of data had been reviewed by the UN climate secretariat and a report was likely to be published next year. Some experts told Guardian Australia the changes in soil carbon accounting made sense, but it was disingenuous for the government to take credit for it. The increase in emissions from grazing land soil carbon under Labor was most likely a result of the millennium drought, which broke in 2010 but took another couple of years for the effects to be felt. Analysts said if the government took credit for soil carbon it would also have to take responsibility for the future increases in emissions from the land due to the current drought and bushfires. Hugh Saddler, an energy consultant and ANU honorary associate professor at the Crawford School of Public Policy, said he respected the departmental officials who worked on greenhouse accounts and did not doubt the validity of their work. But he said calculating emissions from the land was a complex and arcane process, and that it would be better if national emissions accounts focused on areas over which people had greater control: electricity generation, transport, big industry, fugitive emissions from resource extraction, agriculture and the waste sector. If emissions from what are known as land use, land-use change and forestry (LuluCF) are removed, Australia’s emissions have risen about 30% since 1990 and are nearly 20% higher than in 2000, contrary to the impression given when the government claims it is meeting its targets under UN accounting rules. “These are the emissions we should be most focused on,” Saddler said. Ursula Fuentes, a senior policy advisor with Climate Analytics, said emissions in most parts of the economy continued to increase. Pollution was falling only in electricity – due to the rise of cheap clean energy and the now-filled renewable energy target, which the government has chosen not to replace – and floods and drought affecting agricultural output. “There is a lack of policy across all sectors,” Fuentes said. The significant changes that included the shift in how soil carbon emissions are modelled were first published in May. The large increase in the estimate of pollution for the years between 2008 and 2o13 smoothed what had previously been a noticeable rise in national emissions since the carbon price scheme was repealed in 2014. In the most recent data, for the June quarter this year, industrial emissions were adjusted for years over the past decade. The department said it reflected new information from companies and revised energy consumption estimates back to 2014. Following this change the data shows that, rather than rising annually under the Coalition, emissions have dropped slightly for the past two years. Combined, the two sets of changes have resulted in the emissions data now showing pollution was lower for each year under the Coalition than when Tony Abbott ousted Kevin Rudd in 2013. The latest data was released just before Taylor flew to Madrid for a UN climate conference where Australia faced criticism for its plan to use an accounting measure to meet its 2030 target under the Paris agreement, a 26-28% cut below 2005 levels. The report including the data suggested, for the first time, that the government was expected to meet that target, but only if it counted carryover credits for beating previous targets under the expiring Kyoto protocol. Dozens of countries at the meeting opposed the use of the carryover credits amid claims they had no legal basis and were at odds with the commitment made in Paris to increase climate action over time. Australia is the only country that has said it plans to use them. A decision on whether to ban them was pushed into next year. Matt Drum, from climate change advisory business Ndevr Environmental, said discussion of carryover credits often ignored they were just a short-term book-keeping measure that would make it harder to reach net zero emissions by 2050, the ultimate goal of the Paris agreement. “On the first of January 2030 our emissions will go straight back up because we have made no structural adjustment to our economy’s actual emissions,” he said."
"
Share this...FacebookTwitter CO2 Contributed Only 0.12°C 
 To Global Temps Since 1850


A Swiss scientist known to have published hundreds of scientific papers in physics journals has authored a new scholarly paper that casts serious doubts on the effectiveness of CO2 as a greenhouse gas influencing Earth’s temperatures.
This paper has been added to a growing volume of peer-reviewed scientific papers that seriously question estimates of a high climate sensitivity to significant increases in CO2 concentrations.
60 Low (<1°C) CO2 Climate Sensitivity Papers
The link above contains a compilation of over 60 scientific papers with “extremely low” (numerically ranging from 0.02°C to <1°C) estimates of the climate’s sensitivity to a 100% increase in CO2 concentrations (i.e., an increase from 285 ppm to 570 ppm).
Below are some of the key user-friendly (non-technical) points from Dr. Reinhart’s paper entitled Infrared absorption of atmospheric carbon dioxide.   
A summarizing conclusion from the calculations may be that if we doubled today’s concentration (400 ppm) to 800 ppm, the consequent temperature response would be less than 1/4th of a degree Celsius.  Even with a ten-fold increase in today’s CO2 concentration (400 ppm) to 4,000 ppm, the resulting temperature change would amount to just 0.8°C.

Reinhart, 2017
Abstract
Over 200,000 discrete absorption lines of CO2 are used for the numerical calculations. If the absorbed energy is converted entirely into heat, we deliberately overestimate the heat retention capability of CO2. The thermal occupation statistics of the CO2 energy states plays a key role in these calculations. The calculated heat retention is converted into a temperature increase, ∆T. Doubling the present CO2 concentration only results in ∆T [temperature increase of] < 0.24 K. At the present rate of CO2 concentration increase of 1.2% per year, it will take almost two hundred years to reach ten times the present concentration yielding ∆T < 0.80 K.
CO2 ‘Very Weak’, IPCC Assumptions ‘Violate Reality’
Based on all these facts, we conclude that CO2 is a very weak greenhouse gas. We emphasize that our simplifying assumptions are by no means trying to minimize the absorption potential of CO2. To the contrary, they lead to overestimating the limiting values. The assumption of a constant temperature and black body radiation definitely violates reality and even the principles of thermodynamics.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




[W]e conclude that the temperature increases predicted by the IPCC AR5 lack robust scientific justification. The main problem is probably caused by the lack of considering the occupation probabilities of the energy levels.
Temperature Changes In Response To Large CO2 Concentrations (800 ppm – 4,000 ppm)
We have calculated ∆Fmax and ∆Tmax for four concentrations namely 400 ppm, 800 ppm, 2000 ppm and 4000 ppm. The results are listed in Table I. They can be quite accurately fitted with logarithmic concentration dependence.
A doubling [to 800 ppm] of the present level of CO2 [400 ppm] results in ∆T [temperature change] < 0.24 K.
The tenfold value of [the present CO2 concentration, or 4,000 ppm] yields ∆T [temperature change] < 0.80 K.
At pre-industrial times, we had cco2 = 285 ppm. The resulting temperature increase [since pre-industrial] according to Eq. (11) only amounts to ∆T < 0.12 K.
Solar Activity Correlates With Temperature, Non-Positive Feedbacks
Lu [and co-authors, 2013] establishes a correlation of ∆T with solar activity, cosmic rays and ozone reactions with fluorocarbons in the stratosphere. According to his result, CO2 only plays a minor role in the temperature evolution since pre-industrial times. Our calculation is compatible with his finding.
There remains the question of the existence of feedback. This effect is thought to amplify or attenuate a small temperature change. Such mechanisms are easy to imagine, but they are extremely difficult to quantify and to observe. Lindzen has tried to observe feedback by complicated correlation studies. He found a tendency to negative feedback that attenuates induced temperature changes because, in this perspective, the weak CO2 concentration effect is not magnified.
Conclusion
Our results permit to conclude that CO2 is a very weak greenhouse gas and cannot be accepted as the main driver of climate change. The observed temperature increase since pre-industrial times is close to an order of magnitude higher than that attributable to CO2. We find that the increase of CO2 only might become dangerous, if the concentrations are considerably greater than 4000 ppm. At present rates of increase this would take more than 200 years. Therefore, demands for sequestering CO2 are unjustified and trading of CO2 certificates is an economic absurdity. The climate change must have a very different origin and the scientific community must look for causes of climate change that can be solidly based on physics and chemistry.
Share this...FacebookTwitter "
