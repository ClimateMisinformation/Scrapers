"
Share this...FacebookTwitterBy Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German excerpts translated/edited by P Gosselin)

On February 27, 2017, the DWD German National Weather Service concluded in its February report:


February 2017 was much too warm and with only average sunshine


Offenbach, 27 February 2017– At the beginning of February 2017, it was still cold in the north-east due to the influence of high pressure. However, low pressure troughs bringing milder air were already reaching into the south and west of the country. Then, from the middle of the month onwards, all parts of the country were exposed to a powerful westerly airflow that brought much precipitation. These conditions culminated on 23 February with storm gusts, particularly in the west, and spring-like temperatures in the south. Overall, February was much too warm and precipitation and sunshine were almost balanced. This is what the initial analysis by the Deutscher Wetterdienst (DWD) of data from its around 2,000 weather stations shows.”


Continue reading at DWD.
The recent February was much too warm! One can easily imagine as follows: A wild temperature peak standing out well above the otherwise usual temperatures. Once again more proof that for years things have been going in only one direction: only hotter and hotter and hotter.
However the DWD does not provide any chart along with its press release. Wouldn’t many people certainly like to see the February heat trend as a chart? It’s a pity that the DWD chooses not to show charts here.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Thankfully Josef Kowatsch stepped in for the DWD and produced a chart using the official DWD data to show the February mean temperature curve for the last 30 years:

Figure: Chart of the February mean temperature over the past 30 years in Germany, data from the DWD, chart: Josef Kowatsch.
The sense of wonder is large: What do they mean by “much too warm”? The climate trend over the past 30 years for February shows a clear downward movement. This year’s uptick is nothing unusual and has happened regularly over the past 3 decades. nach.
This is truly a poor showing by the DWD, which misled the citizens. There is absolutely no reference made to the last 30 years, no chart, no context. This is a most dubious politicization of the weather report…
Moreover what follows is the trend of the North Atlantic oceanic heat, which shows a very clear cooling trend has taken hold since 2007:

Figure: Trend of the North Atlantic heat down to a depth of 700 meters over the past 60 years. Chart: Climate4You

Share this...FacebookTwitter "
"Vultures are nature’s garbage disposers. They’re perfectly adapted to keep the environment clean and healthy by efficiently locating and consuming carcasses, recycling energy through the food web and preventing the spread of diseases. It’s an unpaid role. However it’s about time we did start repaying vultures for their services, by giving them the protection they deserve. A new study published in the journal Genome Biology illustrates just how finely-tuned these birds are. The researchers perform a whole genome analysis of the Eurasian cinereous vulture (Aegypius monachus) and reveal a unique genetic make-up that explains vultures’ strongly acidic digestive system and their ability to resist infection from pathogens present in the rotting carcasses on which they feed. It’s even possible vultures are able to exploit the flesh-eating properties of some bacteria to aid with the digestion of soft tissues and bones, while the secretion of corrosive gastric acids and specialised immune responses allow them to resist infection from, and potentially even destroy, highly infective pathogens such as anthrax and brucellosis. This unusual tolerance of natural toxins doesn’t protect vultures from man-made contaminants however, which explains why 69% of vulture and condor species are listed as threatened or near-threatened, most of which are classed as “endangered” or “critically endangered”. The California condor (Gymnogyps californianus), for instance, was declared extinct in the wild in 1987 when the last remaining individuals were removed and placed in captivity to protect them from lead poisoning from ingesting shot and bullet fragments from hunted carcasses. Although captive-breeding and release programs have allowed the wild population to increase to more than 200 individuals, lead poisoning continues to cause fatalities. Across Asia the big problem is accidental poisoning by diclofenac, an anti-inflammatory used to treat cattle. In vultures and some eagle species, tiny traces of the drug can lead to fatal kidney failure within 48 hours. In just 15 years, cow carcasses contaminated with diclofenac nearly wiped out three of Asia’s vulture species. This had a big knock-on effect. With less competition at carcass disposal dumps, where people once let vultures pick dead animals clean, India’s feral dog population exploded. This caused higher rates of rabies transmission at an estimated additional cost of US$34 billion to the country’s healthcare between 1993 and 2006. Although some populations have started to recover following the ban of diclofenac in India in 2006, a logic-defying 2013 approval to licence the drug for use in Europe now threatens vultures there too, particularly in Spain and Italy. In Spain, replacing the natural carcass disposal service provided by vultures with vehicle transport to processing plants would result in the equivalent of an additional 77,344 metric tons of CO2 being emitted to the atmosphere and US$50m of additional payments to insurance companies each year, according to a 2014 study in Nature. The situation in Africa is just as grim – “another continental vulture crisis”, as one group of researchers described it earlier this year. Populations of seven species have declined by more than 80% in three generations, giving rise to calls for six of those to be listed as “critically endangered”.  Once again man-made toxins and illegal activities are to blame. Poisoning accounts for 61% of vulture deaths, 29% are attributed to the trade in vulture heads and brains for local cultural beliefs# and 9% of fatalities are caused by electrocution or collision with power lines. Widespread poisoning is certainly the most immediate threat. Usually this happens after farmers target lions, leopards or hyenas that have been attacking their livestock. Vultures consume the poisoned predators or the baited carcass itself and subsequently become secondary, inadvertent victims. However the booming illegal trade in ivory and rhino horn is also bad news for them, as poachers don’t want hundreds of circling vultures pointing authorities towards recently-killed elephants or rhinos. Poachers are therefore deliberately targeting the birds by lacing carcasses with poisons – even after they’ve left with the tusks or horns. More than 500 vultures were poisoned at a single poached elephant carcass in Namibia in July 2013, and the recent discovery of at least 26 elephants poisoned at cyanide-laced water holes in Zimbabwe will also likely result in many vulture deaths. Why isn’t this a bigger scandal? After all, as many, if not more vultures are being killed in southern Africa each year as rhinos or elephants. Perhaps these big, bald, flesh-eating birds are perceived as sinister and lacking enough “cute factor”. But while vultures don’t share the good looks of penguins or puffins, the ecosystem services they provide are irreplaceable. They compete with – and control – populations of blowfly larvae, rats, feral dogs and other scavengers, many of which are disease vectors. They ultimately make the world cleaner and healthier. In fact, the ecological niche occupied by today’s vulture species is so specialised that two unrelated groups evolved on opposite sides of the world to become the primary scavengers in their ecosystems. “Old World” vultures from Eurasia and Africa and “New World” vultures and condors from the Americas might look and act the same but as the latest study highlights they don’t share a recent common ancestor, having diverged in evolutionary terms more than 60m years ago.  This is a classic example of “convergent evolution” – while Old World vultures share a common ancestry with eagles and New World species are more closely related to storks, they independently evolved similar specialisations to fulfil the important role of recycling carrion. It’s time for us to appreciate these unique and highly-specialised birds. We must restrict harmful veterinary drugs, control illegal poisoning, provide uncontaminated sources of food and reduce the impact of power lines and wind farms. This must happen immediately to avoid a worldwide vulture crisis – and all of the negative implications for our own health and well-being."
"The Paris agreement was a diplomatic triumph. The nations of the world spoke with one voice of their desire to limit the damage of climate change. But there is a distinct disconnect between the ambition and the action required to achieve that goal. Going into the talks, countries had indicated what they would do to contribute towards cutting back on greenhouse gas emissions. Totting up these promises would lead to a world warming by about 2.7°C – far more than the 2°C threshold of “dangerous” climate change. The fine words of Paris, reaffirming the commitment to avoid crossing 2°C – and indeed aiming towards a 1.5°C limit – are at odds with what has happened in the past, what is currently planned to happen and even what is achievable in the future. The simple truth is that stabilising the climate will require net emissions to fall to essentially zero, and we are nowhere near close to that. To have a good chance of avoiding the 2°C threshold we’d have to limit the total amount of carbon burnt (over all time) to less than a trillion tonnes. So far we have burnt about 600 billion tonnes and will use up the remainder before 2040. For a 1.5°C limit, we have only 100 billion tonnes of burnable carbon left, which will be used well within the next decade. Nations seem to be mouthing the “make me virtuous, but not just yet” prayer of Saint Augustine. Globally, emissions will accelerate at least up to 2030 when they need to begin heading rapidly in the other direction. Even with the most ambitious mitigation efforts it seems inevitable that we will overshoot the level of carbon dioxide in the atmosphere that is compatible with a stable climate.  To salvage the situation from such an overshoot would require that emissions go negative – that we remove more carbon dioxide from the atmosphere than we emit. There are certainly plenty of ideas. We could use biological methods like planting more trees or managing soils in such a way that they hold more carbon. Then there are the chemical methods. We could find a way to accelerate the rate at which minerals naturally weather and draw carbon out of air. Or we could set up “artificial trees” that suck carbon dioxide from the air.  Proponents have produced fancy artist’s impressions of what such artificial trees might look like. But the key point to note is that no such system has been built at anything like this scale. Getting the concept off the drawing board and into the real world is going to take a lot of time and money, and even then may turn out not to be feasible.  None of these is a get out of jail free card. They may be a get-out-of-jail-at-vast-expense card, but even that we cannot be certain of. All of the proposed methods have side-effects that may well balance out the good points. Planting trees sounds wonderful, but to make a material difference to the climate it would have to happen on such an enormous scale that it would severely restrict the ability for us to grow food and protect biodiversity.  And artificial trees would use vast amounts of energy and money – resources which humanity has alternative uses for.  We do not know which, if any, of the proposed techniques could be a deployed at a material scale. We need to understand whether these proposed techniques are technically possible, environmentally sound and socially acceptable. While the ambition to avoid dangerous climate change has been stated and the recognition that negative emissions will be required to achieve that objective is understood, there is a disconnect between what is being done and what is required. There is an implicit reliance on a suite of techniques that are essentially science fiction and a negligible evidence base with which to determine whether they could be transmuted into scalable fact. It’s as if a new disease was discovered and governments around the world committed to its eradication, but failed to provide any of their own resources, or provide incentives to anyone else to mobilise resources, to develop a cure. There’s a story about a man who has fallen on hard times. He prays to God: “Please, God, let me win the lottery”. Week after week he fails to win the lottery and his situation deteriorates. Eventually he climbs to the top of a cliff and cries out “God, if you don’t let me win the lottery, I’m going to kill myself”. A crash of thunder and a booming voice rings out “For goodness sake! Meet me halfway. Buy a ticket!”"
"
Share this...FacebookTwitterThe Sun In February and Arctic Sea Ice
Von Frank Bosse und Fritz Vahrenholt
(Translated and condensed [due to time constraints] by P. Gosselin)
The star at the center of our solar system was also very inactive last month. The determined sunspot number SSN of 26.1 was only 50% of what is normal.
Fig. 1: Mean solar activity (blue) compared to the activity of the current cycle (red) and the very similar solar cycle 5 (black).
A comparison of all the cycles:

Fig. 2: The activity of all cycles 1 to 24. Depicted is the deviation from the mean. The current cycle began in December 2008 and is the 3rd quietest since systematic observations began in 1755.
The behavior of the solar polar fields also indicate that the upcoming solar cycle 25 could be as weak as SC 6. According to the current conditions, we could experience a solar minimum that is similar to that experienced during the Dalton Minimum (SC 5, 6 and 7) of 1790 – 1830. The strongly decoupled polar fields is a phenomenon that has yet to be observed since systematic observations began in the 1970s – a time when the solar activity was stronger than at any time ever observed.
Antarctica: So little ice as never observed before! 
Last month we saw plenty of headlines about this. The German ARD remained rather factual, but others were dramatic and even employed photo-shopped images suggesting climate alarm. First the facts: This year’s ice extent is at a record low, as is referenced by the NSIDC in its report. Here’s the chart:


Fig. 3:  Sea ice extent around Antarctica in February compared to 1979 (in %). Source.
The dashed line depicts the overall trend, and it remains strongly upward. The long-term trend is what counts when it comes to climate. Yearly fluctuations are related to weather. A look at the GISS temperatures across Antarctica shows no relevant trend.

Fig. 4: Antarctic surface temperature as to GISS.
What follows are the sea surface temperatures (SST). Here we see where the sea ice loss is coming from:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Fig. 5: Temperature anomaly of the ocean surrounding Antarctica. 
Here we recognize the downward trend since the 1990s, followed by a sharp upward spike at the end. Certainly much of this has to do with the weather at the end of 2016, more precisely since September.  There is no real information on what is behind the spike.
One suspicion is the very powerful El Nino of 2015/16, but such a spike did not follow the El Nino 1997/98. It must be kept in mind that there were some real global differences between the last powerful El Nino and the one from the late 1990s, see study here. One suspects that a chain of events may have unfolded which led to a warming of the water around Antarctica. Next year will likely tell us if this is only a temporary powerful warming spike, or if it is the start of a trend reversal.
Media reports that global warming is now catastrophically reducing sea ice around Antarctica are however, wild speculation. In a recent study here on the AMOC, it is determined that a powerful heat transport towards the North causes a special pattern: The sea surface temperature (SST) cools and the depths get warmer. The deeper water at the edge of the continent down to 700 meters shows a warming trend. Here’s a look at the lower depths there:

Fig. 6: Ocean temperature anomalies down to 700 meters deep around Antarctica.
The divergence between the lower layers and its surface can be clearly seen. In Fig. 5 we see the sudden positive spike in SST, but the ocean down to 700 meters cannot of course follow along due to its high thermal inertia.
In the North Atlantic we do see, however, a retreat in heat transport since about 2012:

Figure. 7: The surface temperature anomalies in the sub-polar North Atlantic since 1980.
It may very well be that the El Nino is in part causing the “see-saw” effect: A stronger northward directed heat transport (strong AMOC) cools the water at the sea surface of the ocean (the sea ice grows) around Antarctica while it gets warmer in the water depths. A weaker AMOC (Fig. 7 favors a diminishment compared to the years after 1998) reverses the condition in the south: it gets warmer on the sea surface (sea ice melts) and the depths get colder.
We await with suspense the measurements around Antarctica to see whether this is the case. These are all natural processes, and whether man-made warming plays a role — if yes, how much of a factor it really plays — is completely unclear.
It is far too early to start blaring out that man is melting the Antarctic. Propaganda and science do not go well together. The internal variability of the currently cooling North Atlantic is simply “nature at work”.

Share this...FacebookTwitter "
"If we cannot figure out how to properly test car emissions, we might as well give up on regulating forests, factories or garbage dumps. After all, cars ought to be ideal targets for environmental regulators. They’re largely standardised – most look and act more or less the same – and they’re produced by the thousand or million. Test one Volkswagen Polo and you should have tested them all. In theory. Yet it hasn’t worked like that in practice. A month after the VW scandal broke most eyes are still on the German carmaker and its plunging shares, the desk clearing in management, and its hectic efforts at retrofitting. Fewer people are reflecting on what the scandal means for our system of environmental governance. This is missing the bigger story. In a way, the emissions scandal shows there is a difference between clever cheating and dumb cheating. By its own admission, Volkswagen tampered with the car’s software in order to get good emission figures in testing mode. This is dumb cheating, especially if you get caught: it’s clearly against the rules. But what if car manufacturers and regulators agree on a set of rules for testing that could deliver good figures for fuel efficiency? It is widely known that cars achieve notably better mileage per gallon on the test stand than in everyday practice. In fact, the difference has increased dramatically in recent years: according to the International Council on Clean Transportation, the NGO whose emission tests led to the fall of Volkswagen, the gap between official and actual carbon dioxide emissions in new European cars grew from 8% in 2001 to 40% in 2014. Such a divergence is clearly misleading customers and the general public, but it’s not illegal. That’s smart cheating. Standard setting on environmental matters is a murky area that few people bother to enter. Scientific results may provide some guidance, but there is always room for interpretation, and many rules and regulations are negotiated behind closed doors. The botched numbers for fuel efficiency are a good occasion to take a closer look. Is this the power of the automobile industry at work? Is this about lazy bureaucrats whose principal aim in life is to be out of the office at five? Or maybe it is about a third party such as the facilities that do the actual testing? Negotiations over test procedures are inherently boring, but they matter a lot. If the upcoming Paris climate summit finally seals a deal on global warming, it will all be about numbers, and there will be endless worries if we can no longer trust them. Thanks to standardised mass production, cars should be one relatively simple part of a global system of emissions regulations. If we cannot secure reliable numbers here, we are in trouble when it comes to forests, soils, and other parts of the biosphere. The trouble with test procedures is particularly disturbing since there really is not much room for debate. It is obvious that numbers should be accurate and that tests should reflect the real world. It’s also clear that an independent authority should certify the rules. The Volkswagen scandal indicates the industrial economies of the West cannot sustain that kind of independence anymore. When today’s framework of environmental governance evolved in the 1970s, the general idea was that environmental ministries and other government bodies would serve as a counterweight to the vested interest. Now it turns out that the presumed watchdog is curiously reluctant to bark. A lot has been written over the last month about the loss of trust, but it’s really a matter of institutions rather than morals. Maybe we need a watchdog for the watchdog? Volkswagen has shown the huge toll of dumb cheating, but the scandal also suggests the risk of getting caught was not significant. The story only broke because of a study that worked with a grand total of three cars, two of which happened to be Volkswagens. A cash-strapped NGO could not afford to cast a wider net, and it was a matter of luck that it made the right choices. No system of environmental governance can rely on these kinds of coincidences. Volkswagen’s managers are red-faced, but that will be a temporary thing. They will either change their corporate culture, or there will be no more Volkswagen managers. Whether regulators are red-faced is anyone’s guess, but they certainly should be embarrassed. The question is whether anyone bothers to look them in the face."
"There is nothing as awe-inspiring as watching the brutal power of a lion capturing its prey. At close range, their throaty roars thump through your body, raising a cold sweat triggered by the fear of what these animals are capable of doing now, and what they once did to our ancestors. They are the most majestic animals left on our planet, and yet we are currently faced with the very real possibility that they will be functionally extinct within our lifetime. In fact, lion populations throughout much of Africa are heading towards extinction more rapidly than previously thought, according to new research by Oxford biologist Hans Bauer and colleagues, published in PNAS. The team looked at 47 sites with credible and repeated lion surveys since 1990, and found they were declining everywhere in Africa aside from four countries: Botswana, Namibia, South Africa and Zimbabwe.  West and Central African lion populations have a 67% chance of halving in size in just two decades, and East African populations a 37% chance. Almost all large lion populations that once exceeded 500 individuals outside of southern Africa are declining. These declines in Africa’s apex predator occur at the same time that the continent’s mega-herbivores are also plummeting. Governance problems are less severe in the southern regions. These countries have also recognised the sad reality that large dangerous wildlife often come off second best when interacting with people. Consequently, these countries often fence their conservation areas. Where lions are free to wander in and out of East Africa’s flagship reserves like the Serengeti or the Masai Mara, their cousins in South Africa’s Kruger National Park are fenced in. This is a sad acknowledgement that our existing conservation actions aimed at living alongside wildlife are failing, but a robust analysis conducted recently points to the value of fences. Though they fragment habitats, potentially lead to genetic isolation and require costly upkeep (some say too costly) smaller, fenced reserves may be lions’ best hope. It takes a lot of hard work to maintain the fences and keep the animals in – and poachers out. Bauer and colleagues caution that lions “may no longer be a flagship species of the once vast natural ecosystems” across much of Africa. Research I’ve carried out with colleagues just published in the same journal reinforces the devastating implications this will have on their wider ecosystems.  We predicted what the mega-predators of the Pleistocene (2.5m to 11,700 years ago) would have killed. These predators, including sabre-toothed cats, cave lions, dire wolves and Homotherium (scimitar-toothed cats), were substantially larger than their modern day equivalents and were faced with a lot more competition from rival carnivores.  The largest of these would have regularly killed prey up to the size of juvenile mammoths and mastodons. This is likely to have meant some degree of top-down limitation on numbers of mammoths, giant sloths and other mega-herbivores, protecting the landscape and keeping ecosystems balanced. When the mega-predators died off – over the past 10,000-40,000 years or so – this control was lost. And this same lack of top-down limitation of herbivores by predators is likely to happen again as today’s lion populations are lost.  We can get a sense of these changes from the fact lion pride sizes are getting smaller. Lion pride sizes averaged about 24 between 1885 and 1950, and have declined dramatically to about nine since then. Human hunting seems likely to be the driver of this decline where larger prides were easier to detect and therefore hunt, which led to artificial selection against large prides.   Given cooperation between lots of lions is needed to successfully hunt an elephant, smaller prides mean smaller prey. These days only a few sites with unusually large prides have lions that actively hunt the biggest species, including elephants. Such a change in impacts of apex predators is likely to lead to fundamental changes in the ecosystems in which they live. There will be less control of herbivore numbers, so overpopulation may become an issue. Indeed controlling overabundant herbivores such as kudu antelopes has been the primary driver behind reintroducing large predators in Africa. With dense bushes near rivers and other obvious ambush spots no longer being so risky, vegetation will change. Those bushes will be eaten away. This may benefit some species at the expense of others and will have cascading effects throughout the ecosystem. As they sit at the top of Africa’s food chain, declining lion numbers highlight a wider conservation crisis. Learning more about lions and funding on-ground action to protect them, coupled with improved and open governance of states in which they live, could help to avert this crisis."
"Clothing brand Patagonia gives 1% of its sales “to support environmental organisations around the world”. Carpet-maker Interface takes an “aggressive approach” to reach its goal to source 100% of its “energy needs from renewable sources by 2020”. Nudie Jeans meanwhile, repairs, reuses and recycles its denim products, as well as using organic cotton to produce them in the first place. So, what’s going on? After decades of activists campaigning against companies’ poor environmental records, are companies suddenly becoming environmental activists themselves? Normally, companies are challenged by environmental activists from the outside. That is, NGOs, charities and community groups hold companies to account for their often negative impact on the environment. Think VW – it was an NGO that outed the car manufacturer for gaming the emissions testing system. Remember too last year’s Greenpeace campaign against the Lego-Shell partnership? It was a textbook example of environmental activists using clever social media and protest techniques to raise the public’s awareness about the environmental dangers involved in drilling for oil in the Arctic. And it worked. But increasingly companies have become environmental activists themselves. Take Ecotricity, for example, one of Britain’s biggest renewable energy companies, founded by the “travelling hippy” Dale Vince. The company takes an activist stance against fracking in the UK, producing campaign videos that don’t look too dissimilar from those produced by environmental activists. In fact, Ecotricity has teamed up with Friends of the Earth, one of the largest and most influential green NGOs, in its campaign to oppose fracking in the UK. Cosmetics brand Lush is another successful company that has been very vocal and explicit about opposing fracking in the UK. The company’s co-founder and managing director Mark Constantine (a major baker of Frack Off) is explicit about the fact that campaigning is part of the company’s core culture. Lush’s head of global campaigns, Tamsin Omond, coordinates Lush’s involvement and financing of a number of environmental groups, some of which use quite radical direct action tactics to make themselves heard. She herself is a well-known activist who was arrested in 2013 while protesting in West Sussex. The activist ethos of the company is underpinned by the fact that its own employees – “who are more likely to be drawn from the world of radical politics than business schools” – often play a central role in the environmental causes Lush supports. This is all a far cry from the questionable attempts by large corporations to green their image. Remember when, about a decade ago, BP tried to tell us that it is now “beyond petroleum”? Its global, multi-million pound marketing campaign spectacularly backfired when the company’s attempt to “think outside the barrel” was quickly named and shamed by Greenpeace and other environmental groups as a classic case of “greenwashing”. Why? Because it was mostly talk, and very little walk, which became all too real when BP became responsible for one of the biggest environmental disasters of modern times – the explosion of the Deep Horizon oil platform in the Gulf of Mexico in 2010. So, why do companies like Lush, Ecotricity and others take such an activist stance for environmental issues? Here are three main reasons: 1. Companies have always been activists  Business has always been about convincing customers, policymakers, employees and the like that companies can be trusted to provide goods and services that contribute to the wider good of society. Henry Ford could be seen as an activist; he wanted to bring automobility to the masses – and he even paid his employees a decent wage so that they could afford his Model T car. So, when Dale Vince founded Ecotricity in the mid-1990s to bring renewable energy to the people of Britain, he, in some ways, is today’s Henry Ford. 2. Capitalism is about competition  Activism is also implanted into the doctrine of capitalism because of competition in the market. Shareholder activism has been around for a long time; it’s a concept used to depict the attempts by some shareholders to get the most out of their investment, making companies more profitable and competitive.  What is new is that environmental issues are used to increase competitive advantage. So, when Ecotricity campaigns against fracking, then it also campaigns against its competitor, British Gas, which has invested significantly in fracking. It’s about engaging customers and making them choose one company and business model over another. 3. Motivating employees Environmental issues can also be a good motivating factor for employees. Human resource managers constantly think about new ways to keep employees engaged, motivated and loyal.  So when Lush encourages its employees to campaign against fracking, the managers will have at least one eye on the motivation, retention and performance of staff. Companies are becoming environmental activists because it makes good business sense. But we must scrutinise whether everything that corporate environmental activists tell us is green is indeed green. Employees can function as the litmus paper of corporate green activism. Once we have understood how green activism is reconfigured when it enters the corporate world, we can begin to scrutinise the environmental claims made."
"The Netherlands’ supreme court has upheld a ruling ordering the country’s government to do much more to cut carbon emissions, after a six-year fight for climate justice. The court ruled that the government had explicit duties to protect its citizens’ human rights in the face of climate change and must reduce emissions by at least 25% compared with 1990 levels by the end of 2020. The non-profit Urgenda Foundation, which brought the case, welcomed the “groundbreaking” judgment. The original judgment in 2015 was seen as a landmark in the then nascent field of climate litigation, and inspired similar cases across the world, from Pakistan to New Zealand. David Boyd, the UN special rapporteur on human rights and the environment, said it was “the most important climate change court decision in the world so far, confirming that human rights are jeopardised by the climate emergency and that wealthy nations are legally obligated to achieve rapid and substantial emission reductions.” The Dutch government had previously said it would comply with the substance of the ruling, but it repeatedly appealed over the legal basis for the decision. The latest national statistics show the Netherlands is very unlikely to meet the 2020 emissions target.  The Netherlands passed its first piece of national climate legislation in 2018, it has published a more ambitious carbon plan for 2030, and it is closing its first coal plant next year. According to the supreme court, individual nations have direct obligations under articles 2 and 8 of the European convention on human rights, covering the right to life and the right to private and family life. Dennis van Berkel, a member of the legal counsel for Urgenda, said: “The enormous importance of this case is not just that the Netherlands is obliged to act but that these principles are universal. No court outside the Netherlands is bound by this decision but the influence that this court has and the inspiration that it will give to others are really big.” Van Berkel said that if the government did not comply with the ruling, Urgenda could start separate legal proceedings against it. The Dutch climate minister, Eric Wiebes, said the government had “taken note” of decision and would issue a full response in January. He said the Netherlands had announced an “ambitious” set of measures this year to implement the judgment, although campaigners think it could go much further. As well as inspiring cases against other national governments, Urgenda’s success has encouraged campaigners to take up legal arms against corporations. In April a group of social and environmental justice groups led by Friends of the Earth Netherlands began the process of suing the oil firm Shell, arguing that its business model threatens international climate goals and endangers human rights. In a formal reply in November, Shell denied it was liable. A month earlier the company’s CEO said it had “no choice” but to invest in oil and claimed it was “entirely legitimate” to do so. Nine de Pater, a climate and energy campaigner at Friends of the Earth Netherlands, said the supreme court decision set an important precedent for the Shell case because they used similar legal arguments. “It is a huge decision for all current climate litigation cases,” she said."
"Scientists fear climate change will drive a surge in the number of supersized and dangerous bushfires that become coupled with the atmosphere and create their own violent thunderstorms. Guardian Australia can reveal 2019 is likely to be a “standout year” for the number of bushfires that generate giant thunderstorm clouds known as pyrocumulonimbus, or pyroCBs.  PyroCB storms are feared by firefighters for the violent and unpredictable conditions they create on the ground. PyroCBs are able to generate their own lightning strikes, mass downdrafts of air, gusty winds and even hail blackened with soot. The plumes generated from pyroCBs can influence the atmosphere at heights of up to 15km. Embers still hot enough to start new fires can be shot out of a pyroCB at distances of 30km from the main fire. The 411,000 hectare Gospers Mountain fire in the Blue Mountains, still burning out of control on Thursday, is likely the latest bushfire to have generated a pyroCB storm on 22 November. Nicholas McCarthy, who has just completed a Phd at the University of Queensland on why bushfire thunderstorms form, said watching one develop was a “grounding experience”. “Once you hear that first clap of thunder, you know there’s not a lot you can do,” he said. “There shouldn’t be anyone on the ground at that point. All of a sudden [the fire] loses a whole level of predictability.” PyroCB fires can have devastating and dramatic consequences. Victoria’s deadly Black Saturday conflagration in February 2009 created its own lightning that caused fires 100km ahead of the main fire front. Research scientist Rick McRae, who is the custodian of a register of Australian pyroCB events, said 2019 was a “standout year”. In March, there were 15 pyroCBs detected in the Victorian high country, including a cluster of 12 in just four days – an unprecedented grouping on McRae’s register. “This is the standout year but we are still analysing them,” he said. Dr Andrew Dowdy, a meteorologist at the Bureau of Meteorology, has published several studies on pyroCB fires and their underlying conditions. Research led by Dowdy and published in the journal Scientific Reports has found that adding more greenhouse gases to the atmosphere will make more dangerous conditions favourable to pyroCB events in the future, particularly for the southern parts of Australia. Dowdy said an examination of conditions in the atmosphere and on the ground between 1979 and 2016 that are conducive to pyroCBs had already found a “statistically significant” trend in southern Australia. He said: “We found that in summer in southern Australia and spring time, there have been large changes towards more dangerous conditions.” Dr Simon Heemstra, manager of planning and predictive services at the New South Wales Rural Fire Service, said: “What’s happening now is that we are noticing an increase in incidence of these sorts of events. With a changing and heating climate, you are going to expect these effects.” He said pyroCB fires were characterised by violent “mass flaming” that “puts lives at risk, whether those are firefighters or the community in the path of these events”. The advice given to firefighters in NSW before and during a pyroCB event is to “make sure they have a safe refuge”. He said: “It instills fear – the thought of a fire creating a thunderstorm that’s throwing embers and lightening in front of it. It creates a dangerous situation and we take them very seriously.” In response to a rising number of pyroCBs, he said the NSW Rural Fire Service was using weather balloons to take atmospheric measurements during times it is feared that pyroCBs could form. New communications material for firefighters has also been produced. Heemstra said one warning sign was a smoke column that rises to about 5km and forms a white top as moisture turns to ice. If the column continues to rise, a warning is sent to firefighters and communities on the ground. As well as creating dangerous weather conditions, Heemstra said pyroCBs prevent the fire service from using aircraft either to take measurements, or to drop water or fire retardant. Associate professor Jason Sharples, of the University of New South Wales, said pyroCBs needed two basic elements to form – an intense and expansive fire and an unstable atmosphere above it. He said: “Think of it like a really bad thunderstorm with all the winds and the rain but then take out the rain, and put in embers.” Dr Mike Fromm, of the US Naval Research Laboratory at the Department of Defence, told Guardian Australia that to identify pyroCB events scientists used satellites to examine images and also detect aerosol particles. “They generally will punch a hole through the boundary between the troposphere and stratosphere,” he said. “They create a huge blanket of cloud that turns day into night.” He said globally there was no evidence of a trend towards more pyroCBs but he also said the record was relatively short. PyroCB storms typically lasted between one and eight hours, Fromm said. There was evidence of embers being shot out from the fire at distances of up to 30km. “What we know about pyroCB conditions is summarised as ‘hot, dry, windy’,” he said. “If these factors intensify with climate change, it is reasonable to anticipate additional risk of such firestorms. “The pyroCB is the most dramatic manifestation of fire weather and behaviour from the standpoint of the views from space.” He said observations from the deadly Black Saturday fires of February 2009, where 173 people died, illustrated the dangers posed by pyroCBs. “Black Saturday’s Kilmore East fire didn’t even exist until late morning of that fateful day; by mid-afternoon it generated a full-fledged, devastating pyroCB.”"
"
Share this...FacebookTwitter
New papers show clear impact by solar activity on the earth’s climate. Images: NASA Earth Observatory.
Solar activity fluctuations control the climate: sea level in Venice, tropical storms in Australia, Amazon discharge rates
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated by P Gosselin)
It’s been claimed time and again that solar activity cycles for the most part can be neglected climatically. They hardly have any impact. Therefore it is all the more amazing when almost every month a new scientific study comes out that documents the exact opposite.
One example comes from November 2016 when the Geophysical Research Letters published a paper by Adrián Martínez-Asensio et al on the impact of solar activity on sea level. The scientists documented that the autumn sea level extreme in Venice and Triest are in fact controlled by the 11-year solar cycle.
In the wintertime the sun’s impact is seen at other coastal locations, namely Marseille, Ceuta, Brest and Newlyn. What follows is the paper’s fascinating abstract:
Decadal variability of European sea level extremes in relation to the solar activity
This study investigates the relationship between decadal changes in solar activity and sea level extremes along the European coasts and derived from tide gauge data. Autumn sea level extremes vary with the 11 year solar cycle at Venice as suggested by previous studies, but a similar link is also found at Trieste. In addition, a solar signal in winter sea level extremes is also found at Venice, Trieste, Marseille, Ceuta, Brest, and Newlyn. The influence of the solar cycle is also evident in the sea level extremes derived from a barotropic model with spatial patterns that are consistent with the correlations obtained at the tide gauges. This agreement indicates that the link to the solar cycle is through modulation of the atmospheric forcing. The only atmospheric regional pattern that showed variability at the 11 year period was the East Atlantic pattern.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Another example is found in March, 2016. Jordahna Ellan-Ann Haig and Jonathan Nott reconstructed the tropical cyclone history of Australia for the past 1500 years. Here they discovered that the observed variability was mostly controlled by solar activity over decades and centuries. Haig and Nott hope that future tropical storm forecasts can benefit from the important solar factor.
The paper’s abstract follows:
Solar forcing over the last 1500 years and Australian tropical cyclone activity
Accurate seasonal and decadal predictions of tropical cyclone activity are essential for the development of mitigation strategies for the 2.7 billion residents living within cyclone prone regions. The traditional indices (Southern Oscillation Index and various sea surface temperature indices) have fallen short in recent years as seasonal predictors within the Australian region. The short length of these records (i.e., <50 years) has meant that our current knowledge of larger-scale drivers at interdecadal, centennial, and millennial scales is limited. The development of a new tropical cyclone activity index spanning the last 1500 years has enabled the examination of tropical cyclone climatology at higher temporal resolution than was previously possible. Here we show that in addition to other well-known climate indices, solar forcing largely drives decadal, interdecadal, and centennial cycles within the tropical cyclone record.”
Lastly there’s a fairly recent example from South America. Andrés Antico and Maria Tores examined the discharge rate of the Amazon for the last 100 years in an article published in 2015. They discovered that the development is very closely coupled to solar fluctuations. The paper’s abstract follows:
Evidence of a decadal solar signal in the Amazon River: 1903 to 2013
It has been shown that tropical climates can be notably influenced by the decadal solar cycle; however, the relationship between this solar forcing and the tropical Amazon River has been overlooked in previous research. In this study, we reveal evidence of such a link by analyzing a 1903–2013 record of Amazon discharge. We identify a decadal flow cycle that is anticorrelated with the solar activity measured by the decadal sunspot cycle. This relationship persists through time and appears to result from a solar influence on the tropical Atlantic Ocean. The amplitude of the decadal solar signal in flow is apparently modulated by the interdecadal North Atlantic variability. Because Amazonia is an important element of the planetary water cycle, our findings have implications for studies on global change.”
 
Share this...FacebookTwitter "
"Australians are far less split on partisan lines than Americans on whether they accept the need to act on climate change, and are far more likely regardless of party allegiance to be willing to pay a carbon tax to cut fossil fuel use, a study has found. The research by the US Studies Centre at the University of Sydney found a majority of both Australians and Americans said climate change was happening at least in significant part due to human activity, and they would support a plan to cut fossil fuel use by raising taxes, including a carbon tax.  For all questions, support for acting on the climate crisis was greater in Australia. Researchers found 78% of Australians supported reducing fossil fuel use and 64% raising taxes to help do that. Among people who voted for the Morrison government at this year’s election, 62% said they backed cutting fossil fuel use and nearly half, 48%, supported higher taxes. There was overwhelming support to both questions from people who voted for Labor (88% and 79% respectively) or the Greens (96% and 88%). The divide in the US between people who voted for Donald Trump and those who backed Hillary Clinton at the 2016 presidential election was much greater. Across all voters in the US, support for reducing fossil fuel use was at 68%. That fell to 54% when people were asked if they would support a plan that required higher taxes. There was overwhelming support on both counts among those who backed Clinton, the failed 2016 Democrat candidate (95% and 82% respectively). But only 29% of people who voted for Trump supported reducing fossil fuel use. The proportion of Trump voters prepared to pay a carbon tax to address the issue was just 24%. Across all parties in both countries, including a category counting non-voters and other minor party voters, Trump supporters were the only group in which a majority did not think that climate change had been occurring either mostly due to human activity or equally due to human activity and natural causes. Just 30% of Trump supporters thought humans were significantly contributing to climate change. Among Coalition voters in Australia, it was 60%. A slim majority of Coalition voters (between 52% and 58%) said they believed climate change would cause more droughts and water shortages, increasingly severe storms and harm to wildlife. Trump voters (between 26% and 29%) disagreed. Shaun Ratcliff, a political science lecturer with the centre, said the survey results showed there was a significant difference between Australia and US politics on the right. While Clinton voters were similar to Australian Labor and Greens voters on climate change, Trump voters “looked nothing like” Coalition voters, he said. “Republican voters are much more ideological than Coalition voters are on this issue,” he said. Ratcliff said polarisation in the US was not a result of Trump but started decades ago. He may have exacerbated it but was not the cause. This was true on a range of issues, including climate change. He said it was evidence a Trumpian approach to politics was less likely to have sustained success in Australia. “The Liberal party is very different to the Republican party and there is a lot of concern in the Australian public about climate change,” Ratcliff said. “People say they want action.” He said Labor’s failure to win government with a more ambitious platform on climate change may have in part been due to how that was handled. “If you’re making major changes, voters have to have confidence you have the ability to do it well and won’t make things worse. If they fear that, you may not win their support.” The surveys were collected in both countries by YouGov, a global opinion and data company, over a week in late July, before Australia’s ongoing bushfire crisis. They are part of a broader study called Public Opinion in the Age of Trump. Different parts of the survey were released to different media outlets ahead of the report’s publication on Wednesday. Ratcliff said it was unclear whether concern about bushfires that have engulfed Sydney and other centres in smoke would change public opinion, and if it did whether that change would last. “If the public does come to see the fires and the smoke and the destruction we’re seeing along the east coast as being exacerbated by climate change and believe the Coalition is not doing enough that could have an impact,” he said. The sample size was 1,800 in the US and 1,820 in Australia; the margin of error 2.3% in Australia and 2.8% in the US."
"Fires are raging across the Amazon right now, while deforestation in the region is speeding up. As deforestation is the second-largest contributor to carbon emissions after fossil fuels, a forest deal will be crucial. What Brazil agrees to at the Paris climate talks – and what it does over coming decades – will affect us all. During the opening days of the Paris conference, virtual forests were projected onto the Eiffel Tower in recognition of their importance to the environment. Prince Charles joined in, warning that: “We must save our forests, for there is no Plan B”. And, on the first day,  Norway, Germany and the UK pledged US$5 billion to reduce deforestation in Brazil and other countries with large tropical forests.  If the world is to effectively combat climate change then it’s no surprise Brazil is considered a major player. The country has the third most trees in the world and – unlike Russia and Canada’s taiga – most Brazilian forests grow on fertile ground that could otherwise make good farmland. This means they’re disappearing – fast.  Only weeks before the climate talks began, embarrassing news emerged that deforestation in the Amazon had increased by 16% over the past year, suggesting that Brazil’s efforts to combat climate change in this area may already have peaked.  The country is aiming for zero net emissions from deforestation by 2030 yet this remains a huge challenge. A recent report by the Brazilian Institute of Space Research concluded that the government needs to make stronger efforts to enforce forest protection and to restore forests in areas that have already been cleared. With El Niño also leading to unusually intense forest fires in the Amazon rainforest, the government’s climate policy therefore seems less ambitious than it should be.  It will need to do this, as reducing deforestation remains a cornerstone of Brazil’s commitment to reduce carbon emissions from 2005 levels by 37% in 2025 and 43% by 2030. To be fair, the country does deserve some praise – since 2004 deforestation rates have been reduced by an impressive 70%. However forest clearances may need to end entirely for the country to meet its own targets. The Paris agreement is likely to tackle deforestation through REDD+, a form of “carbon offsetting” where rich countries pay poorer forested nations to keep their trees and effectively “offset” emissions made in the industrialised world. Critics have questioned whether this form of carbon market tackles the real causes of deforestation. They point out that offsetting simply allows developed countries to continue polluting rather than recognise their historical responsibilities. This is exactly why the Brazilian government decided to ban international trading of its REDD+ credits just ahead of COP21, while continuing to use bilateral funding against deforestation. While environmental movements welcomed this announcement, they also point out that the Brazilian government weakened forest protection legislation in 2012, threatening to undermine recent progress.  A more fundamental question is whether forests can be bought and sold without considering the communities who live there, as indigenous groups have had very little effective participation in the negotiations.  Even at COP21, the voices of people who actually experience the effects of deforestation first-hand only tend to be heard on the fringes. Latin American indigenous groups provided examples of effective forest management at side events but many of them could not get accreditationfor the official negotiations.  As one Guatemalan indigenous leader pointed out: “We are nations but we are not part of the negotiations.” Indigenous leaders claim that they are the guardians of the forest, able to offer alternative ways to protect the rainforest. Indeed, evidence from Brazil points to lower levels of deforestation in their territories – indigenous rights must be included in the Paris agreement. Despite the billions of dollars devoted to forests, there isn’t much evidence of this commitment within the conference buildings. Temporary structures housing the main negotiations and side events dominate the site, with two solitary “wind trees” generating renewable energy. Surrounded by colourful animal sculptures, visitors can also attach their messages about climate change to a lone wooden tree in the Climate Generations area. But while trees have made only a symbolic and virtual appearance in a battered Paris, they remain as important as ever – as does the vexed question of Brazil’s forest policy."
"
Share this...FacebookTwitterBy Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
On March 1st Arizona State University reported on Antarctica’s record high temperature. Surprisingly the record was set not this year, or even this decade, rather it was set in the year 1982:
World Meteorological Organization verifies highest temperatures for Antarctic region
ASU climate expert, WMO rapporteur talks about importance of such verification
The World Meteorological Organization announced Wednesday new verified, record high temperatures in Antarctica, an area once described as “the last place on Earth.” The temperatures range from the high 60s (in Fahrenheit) to the high teens, depending on the location they were recorded in Antarctica. Knowledge and verification of such extremes are important in the study of weather patterns, naturally occurring climate variability and human-induced change at global and regional scales, said Randy Cerveny, an Arizona State University professor of geographical science and urban planning and the Rapporteur of Climate and Weather Extremes for the WMO. “The temperatures we announced today are the absolute limit to what we have measured in Antarctica,” Cerveny said. “Comparing them to other places around the world and seeing how other places have changed in relation to Antarctica gives us a much better understanding of how climate interacts, and how changes in one part of the world can impact other places.”  Because Antarctica is so vast (it is roughly the size of the United States) and varied the WMO committee of experts, convened by Cerveny, provided three temperature measurements for the Antarctic.
The highest temperature for the “Antarctic region” (defined by the WMO and the United Nations as all land and ice south of 60-deg S) of 19.8 C (67.6 F), which was observed on Jan. 30, 1982, at Signy Research Station, Borge Bay on Signy Island. The highest temperature for the Antarctic Continent, defined as the main continental landmass and adjoining islands, is the temperature extreme of 17.5 C (63.5 F) recorded on Mar. 24, 2015 at the Argentine Research Base Esperanza located near the northern tip of the Antarctic Peninsula. The highest temperature for the Antarctic Plateau (at or above 2,500 meters, or 8,200 feet) was -7 C (19.4 F) made on Dec. 28, 1980, at an automatic weather station site D-80 located inland of the Adelie Coast.
The Antarctic is cold, windy and dry. The average annual temperature ranges from -10 C on its coasts to -60 C (14 F to -76 F) at the highest points in the interior. Its immense ice sheet is about 4.8 km (3 miles) thick and contains 90 percent of the world’s fresh water, enough to raise sea levels by around 60 meters (200 feet) if it were all to melt. Cerveny said that observing the extremes of what the Polar Regions are experiencing can provide a better picture of the planet’s interlinked weather system. “The polar regions of our planet have been termed the ‘canary’ in our global environment,” Cerveny said. “Because of their sensitivity to climate changes, sometimes the first influences of changes in our global environment can be seen in the north and south polar regions. Knowledge of the weather extremes in these locations therefore becomes particularly important to the entire world. The more we know of this critically important area to our environment, the more we can understand how all of our global environments are interlinked.”  Cerveny said an additional benefit is understanding how those extremes were achieved. “In the case of the Antarctic extremes, two of them were the result of what are called ‘foehn’ winds — what we call Chinook winds — very warm downslope winds that can very rapidly heat up a place. These winds are found even here in the United States, particularly along the front range of the Rockies. The more we learn about how they vary around the world, the better we can understand them even here in the United States. Full details of the Antarctic high temperatures and their assessment are given in the on-line issue of Eos Earth and Space Science News of the American Geophysical Union, published on March 1, 2017
==============================

PS: Happy Easter everybody! -PG
Share this...FacebookTwitter "
"Josie Douglas sits on a verandah overlooking a ridge of red rocks and earth, scrubby with saltbush and spinifex near the centre of Alice Springs. It’s late afternoon and only 31C – a reprieve from a run of days in the high 30s and 40s. But Douglas knows that from now on it will only get hotter. Last summer was the hottest on record, and the driest in 27 years in central Australia. Five per cent of the town’s street trees died. A heat monitoring study showed that on some unshaded streets the surface temperature was between 61C and 68C. “We can’t keep going on the way we’re going,” says Douglas, who is manager of policy and research at the Central Land Council. “Central Australian Aboriginal people are very resilient. They have evolved to cope with the harsh and variable desert climate, but there are limits. “Without action to stop climate change, people will be forced to leave their country and leave behind much of what makes them Aboriginal. Climate change is a clear and present threat to the survival of our people and their culture.” Across central Australia, people are bracing themselves for another scorching summer of drought. At least nine remote communities and outstations are running out of water. A further 12 have reported poor quality drinking water as aquifers run low and the remaining supply is saline.  Temperature records have already been broken. In the year to July 2019, Alice Springs had 129 days over 35C, and 55 days over 40C. It wasn’t meant to be like this – at least, not yet. The national science agency, the CSIRO, predictedthat these temperatures would not arrive until 2030. As the Northern Territory’s environment minister, Eva Lawler, said last September: “If we don’t do anything, the NT will become unliveable.” The problem is where to start. In Alice Springs opinion is divided among local politicians about the impact climate change is having on life in the desert. Sitting on the grassy lawn outside the council, Jimmy Cocking of the Arid Lands Environment Centre talks openly about climate refugees: those who have already come into town, and those who will have to come in the near future. “We’re going to end up with a whole bunch of internally displaced people within the Northern Territory in remote Australia, if we’re not planning for that,” he says. “If regional centres like Alice Springs and others aren’t planning to be able to deal with the influx of climate refugees internally within our region, we’re going to be left flatfooted and unable to deal with any of the challenges and social consequences that will come from that.” Cocking is on the town council and has sought to pass motions to declare a climate emergency. But the mayor, Damien Ryan, is reluctant to sound the climate alarm. “In local government speak, when you have an emergency, you close it down,” Ryan says. “I have not had any of the people who talk about an emergency say what is the next step. So you declare an emergency, what do you do then the next day? That’s never been made clear to me.” At its October meeting, the council did not agree on the word “emergency” but voted unanimously to say there was an “escalating urgency for climate action”. Douglas and the CLC say Aboriginal communities are doing what they can. “People are already mitigating climate change through traditional burning and they are investing their income from land use agreements to install solar power, plant bush tucker gardens in communities and operate swimming pools, but all that counts for little in the face of the lack of climate leadership from the government,” she says. The NT government says it has allocated $15m to “revitalising” the Alice Springs city centre. Some of those funds will go towards shade and landscaping to help cool the streets, and to public water stations. Ryan says the council is encouraging local schools to plant more trees. The Territory government says it has a climate change response strategy and is working with other governments and the Bureau of Meteorology to “develop national guidelines for the development of a warning system for extreme heat events”. In the meantime, Douglas says, people are living in houses that are “unbearable”. “During our summers you can sometimes see people in communities hosing the outside of their Besser brick walls with garden hoses to keep cool despite the water shortages – that’s how desperate they are.” About 3ookm north-west of Alice Springs is Yuendumu, the largest remote community in central Australia. Its 900 or so residents are facing summer without a reliable supply of adequate drinking water. The NT government has stopped building new housing because there isn’t enough water in the dwindling aquifer to accommodate more people. Yuendumu is not alone. The Central Land Council’s chief executive, Joe Martin-Jard, says that at every regional meeting, water security is top of the agenda. “Between Alice Springs and Mount Isa, there’s probably only one major community with a decent water supply,” Martin-Jard says. “We’re not getting the rain we used to, to recharge the aquifers. So as water is drawn out of the aquifers it becomes more saline and less potable [drinkable]. “It’s a really horrible dilemma.” The NT’s Power and Water Corporation, which is responsible for essential services in 72 remote communities and outstations, says most communities in the arid region are “faced with some level of water stress” and emergency planning is under way, but there are “rarely any simple solutions”. “The difficult reality is that many communities originally developed historically in locations where there was never any secure, reliable, high quality water resources in close proximity,” a spokesperson said. “As those communities have grown … and expectations of improved levels of service have appropriately increased, the challenges also continue to increase.” Power and Water says more drilling programs are planned but “finding new water sources is very challenging and often these drilling programs have moderate prospects for success”. “Without large or extended rainfall … the water security risks will progressively increase in some centres, with an increased likelihood that source supply capacity at some could fail.” At least 12 communities have reported poor quality drinking water. At Laramba, Willowra and Wilora, nitrates and uranium are at levels exceeding health guidelines. NT Power and Water says it is “investigating alternative technology options”. It has already installed treatment plants at Kintore, Ali Curung and Yuelamu to reduce high levels of nitrates, uranium and fluoride.  Sorry your browser does not support audio - but you can download here and listen https://audio.guim.co.uk/2019/12/17-41001-FS_HEATWAVE.mp3  In Alice Springs’ 18 town camps, where people from out bush often end up, houses are commonly built from Besser bricks – hollow concrete blocks which are cheap, but which trap the heat. There’s a lack of tree cover or other kinds of shade. Houses bake in the sun and, while the majority have solar panels, they often have only an evaporative air conditioning unit, known locally as a “swampy”, to cool the house. A “swampy” uses a lot of water and can struggle on hot days, especially when there are a lot of people sharing a house, which is common in town camps with big families and fluctuating populations. “Air conditioning is an essential item in the desert, not a luxury,” the CLC’s Josie Douglas says, “but it does not come standard.” When remote community and town camp tenants are offered housing, there is “a hole where the aircon unit should be and they are told to buy it themselves”. “Many can only afford to ‘close the gap’ with a piece of wood, or run expensive reverse-cycle aircon very sparingly,” she says. “Some places don’t have enough water to use a cheaper swampy.” Houses that don’t cool down overnight create big health and social problems. “People resort to sleeping outside, or cramming everybody into the coolest room of the house, with all the well-known consequences for the spread of diseases that whitefellas only know from medical textbooks. “It’s also common for people to sleep in shifts, with young people roaming the streets at night where they get into trouble, and sleeping during the day when they should be at school.” This is at odds with the NT government’s view of the quality of town camp and remote community housing. A government spokesperson tells Guardian Australia that homes are designed with weather conditions and regional climate in mind, and they include external shading, natural ventilation and insulation. “Investment into housing in town camps has included the installation of louvres, sunscreens, verandas and insulation,” the spokesperson said. “The Department of Housing and Community Development has also upgraded some key community infrastructure including improved shading and the installation of fans.” Douglas is calling on the government to “stop building concrete hotboxes”. “More than a decade ago, the government and the CLC were partners [in research] that came up with really solid recommendations about how to make desert houses more energy-efficient and communities more resilient. “Some measures, such as making sure houses are built with the right orientation … and have passive cooling and a white roof, cost almost nothing. We would like to know how many of these expensive research findings have been implemented in our region.” Shirleen Campbell is a Warlpiri and Arrernte woman who grew up at Hoppy’s Camp, or Lhenpe Artnwe. She told the Alice Springs climate rally in October that town campers were very worried about climate change. “This is our place,” she said. “If it gets too hot, if we suffer through endless droughts or we spoil our water, then we don’t have another place to go. “We want houses that are right for this place and right for our people. We want to invest in renewable energy, like solar.” Campbell is a co-coordinator of the women’s family safety group at Tangentyere council, which delivers services to and advocates on behalf of town camp residents. “Most of all we want people to treat this place as a legacy to be handed down to our children and grandchildren. It is not a speculative commodity and it is not something to be sold or exported. “We have been here for a long time and want to look after this place for those that come after.” There are few public places in Alice Springs to cool off. The Yeperenye shopping centre has security guards at the doors and, according to Douglas and Campbell, Aboriginal people are regularly moved on. The library is a popular, free cool space. There’s a widescreen TV rigged up with headphones, showing movies. Westerns are popular, as are replays of AFL grand finals. The Saltbush room down the hall is a haven for older folk, while little mobs of kids hang out among the young adult stacks or cluster around the phone-charging station. “We found there’s a gap in after-school care services from about 2.30 to 4.30, the hottest time of the day,” says the head librarian, Clare Fisher. “The kids can come to the library, cool off, have fruit and sandwiches.” “Libraries are for connection and relaxation as well as knowledge. We make everyone welcome – but we explain how to use the library and how to behave as well. We very much believe in come and be who you are.” In January footage of dead and dying horses in a dry creek bed at Ltyentye Apurte, 80km south-east of Alice Springs, flashed around the world. The Ltyentye Apurte rangers had the unenviable task of dragging more than 100 dead horses from the creek bed and disposing of their bodies. In June the CLC conducted an emergency cull of more than 1,400 feral horses, donkeys, camels and cattle from a waterhole near Lajamanu. The animals were thirsty and dying, congregating around the last remaining springs and water sites. The CLC has eradicated 6,279 feral animals in preparation for summer. Traditional owners don’t usually support animal culls, the CLC says, but there were no alternatives, with so many animals dying or in poor condition. Feral animals damage community infrastructure and housing. Thirsty camels, for example, will attack air conditioning units because they smell water, and lay waste to water tanks, bores, fences, pipes and taps. In town, Tangentyere council wants to measure exactly how well houses are functioning. Tangentyere’s social policy and research manager, Michael Klerk, is in discussions with the CSIRO to install temperature data loggers in people’s houses, to build a case for improvements that are taken for granted elsewhere: solar power, insulation, better air conditioning, wide awnings, more shade. “Last summer – which was a very hot summer, soon to be repeated – a lot of anecdotal feedback was that people’s evaporative air conditioners weren’t cooling the houses sufficiently,” Klerk says. “This probably reflects the reality that evaporative air conditioners are not good at cooling houses when the external temperatures are in the mid-40s. “You might drop the temperature of a house to mid-30s, but that’s not an optimal internal ambient temperature for comfort or for health.” Most people living in town camps and remote communities, and some in suburban public housing, have pre-paid electricity meters. Residents are issued a power card, which they top up with their welfare payments or income. Once the credit is spent, they have to top it up again, or go without electricity. Klerk says that happened a lot in the last quarter of 2018. In Alice Springs, 420 of 570 households with prepaid electricity meters had at least one self-disconnection, which lasted, on average, 7.5 hours. Of the 570 Alice Springs meters, 285 are in town camp dwellings. In effect, more than half the town campers ran out of money to pay for electricity. “When the power goes off, it is bad for our health, the food gets spoiled, we can’t wash our clothes and we can’t wash our kids,” Shirleen Campbell told the rally. “In summer, when our houses are hot or when we don’t have electricity, our people look for comfort in air-conditioned public places. We are not always welcome in these places and sometimes there are problems. We are thankful for places like the library and the pool.” Klerk says low-income residents shouldn’t have to go broke trying to keep their houses cool. “It’s not acceptable that people’s houses are making them sick, and something really needs to be done about it. It shouldn’t all be passed on to the consumer. “If it’s the case of people having to spend more money to keep the houses at a temperature that delivers health outcomes, then we have to rethink the levels of income support that are available to people, particularly in these regions where it’s so hot.” Predictions by the Central Australian Aboriginal Congress for the health impacts of heat are dire. In its submission to the NT government’s climate change policy discussion paper, it outlined some of them: “Increased sickness and mortality due to heat stress, increased food insecurity and malnutrition, increased risk from infectious disease, poorer mental health and an increased potential for social conflict.” The Pintupi-Luritja artist Irene Nangala was among the first to return to her home country at Kintore in the western desert, near the border with Western Australia, in the early 1980s. Until then, Pintupi people had been living a long way from home at the mission at Papunya, and they were homesick. Nangala helped set up the Kintore school. It was a “windbreak school” at first, she says: just a tarp to keep the sun and the rain water out. “Then we got a few teachers. It was hard work. We’ve got a proper good school now, proper shop. Nice clinic and aged care, child care.” Nangala says she doesn’t have an air-conditioner. On hot days the family puts blankets on the windows. Other elders whose aircon units break down have to wait for a repairer to come from Alice Springs, more than 10 hours’ drive away. “It’s really hot in Kintore. We can’t go and sit outside. We have to go at night to sit down with the families.” Nevertheless, Nangala says she does not want to leave. “We built up Kintore,’ she says. “People are really enjoying going back to their grandfather’s land. That’s the right thing to do. And it’s good for them to go back, the old people, good for the heart and the spirit. “When they went first, they cried, they missed that place for a long time.” Nangala says people don’t want to come into town, where life might be worse. “Climate change is true,” Nangala says. “They [politicians] got the map and weather things, they should see the temperature what is happening around Australia, it’s so hot.” Jimmy Cocking says: “We are walking blindly into the new climate reality. We’ve moved beyond hope, and we can’t be running on hope alone. “The only thing that is going to get us over the line is action. And the antidote to despair is action. “So there’s a lot of things that we need to be looking to change so that we aren’t going to be putting people’s lives at risk.”"
"Domestic dogs and cats might be a phenomenal evolutionary success story but we still know remarkably little about how, why and when these animals first became part of our human world. Archaeologists have been on the trail of these human-animal relationships for decades, searching for clues in the bones excavated from sites around the world.  Geneticists are now helping to address these questions, and adding to a picture that is both changing rapidly and becoming more confusing. The dog has a very special (and unique) history with humans. Remains from Israel, Germany and central Russia clearly document that they were already part of our lives as early as 15,000 years ago. This makes the dog the only domestic animal to have existed before the agricultural revolution – one of the most fundamental shifts in our own evolutionary history. We know the Eurasian grey wolf (Canis lupus) is the ancestor of all modern dogs. Early genetic studies (using “molecular clock” calculations now refuted) controversially pushed its domestication history back to more than 100,000 years ago, while more recent morphological studies have claimed that dog domestication began around 32,000 years ago – during the last Ice Age.  Where this first occurred remains equally problematic, with both the archaeological and genetic evidence indicating single or multiple places in Europe, the Near East,  Russia or China. The latest study, by researchers at Cornell, suggests the original dogs could be found in Central Asia. Zooarchaeologists and geneticists (including myself) from across the world are currently working together to test these many claims and counter-claims. We used to think that dogs were the result of direct human intervention, with wolf cubs being caught, tamed and eventually bred. However, the now generally accepted view is that wolves essentially “self-domesticated”. This involved a more long-term relationship, driven initially not by direct human intervention but by the local ecological conditions they created. In this scenario, human leftovers drew certain wolves closer to campsites and perhaps led some individuals or even small packs to follow human hunters in search of easy pickings. The presence of wolves so close to human settlements perhaps also had the effect of preventing other dangerous carnivores from straying too close – creating a loose but mutually-beneficial partnership. Over time, these wolves became more and more accustomed to humans until eventually new selection pressures changed them from wolves to dogs. Biologists would call such a relationship “commensal” – that is, where one organism benefits from another without causing any harmful side-effects. Archaeologists have since borrowed the term to describe the path to domestication in wolves, cats and even some other farmyard animals like the pig.  However, the reality of what some term “proto-domestication” is often more complex. The transition from wolf to dog, or boar to pig, involves the acquisition of a new and important capability to exploit or totally rely on the human environment.  Broad commensal relationships between humans and carnivores certainly do exist – some wolves enjoy scavenging rubbish, for instance. Likewise, carnivores such as cats may well have been highly dependent on predating other commensal (pest) species, such as mice and rats, which may have been infesting human grain stores. But commensal animals rarely have a neutral effect on humans, since they consume crops, steal food and provide a reservoir for disease. Because humans have such a big impact on local ecosystems, and there are so many different ways other organisms living in and exploiting new human-made environments can interact with us (and vice versa), perhaps we need to change how we think about this.  We need a way of talking about the early phases of animal domestication that fully integrates both the biological and cultural factors involved. You won’t find messy Palaeolithic eating habits listed as a textbook “evolutionary pressure”, but without them it’s possible we wouldn’t have dogs today. Assessing key human-animal relationships during the early phases of proto-domestication is an immense challenge, but one that will be important in establishing if those relationships were simply opportunistic, or involved a true commensal pathway whereby species became dependent on humans before being domesticated. Living as I do with my own dogs and cats, I know that I can at least be sure of two things: dogs are ecstatically happy that they managed to domesticate themselves, while cats are utterly indifferent about their remarkable skills at domesticating humans."
"
Share this...FacebookTwitterModern Polar Bear Habitat Among
Coldest  Of The Last 10,000 Years


Image Source: slideshare.net

The habitat range for polar bears extends across the circumpolar boundaries of the Arctic Ocean, primarily inclusive of North America (Canada), coastal Greenland, and northern Russia (Siberia, Northern Europe).  However, about 70 percent —  13 of 19 subpopulations — of the Earth’s polar bears reside in Canada.  And Canada not only has not been warming to any unusual degree in the last few centuries, modern temperatures are still colder now than they have been for most of the last 10,000 years.

A Benighted Short-Term Climate Perspective
The media-popularized viewpoint that insists polar bears are sweltering under an imminent threat of extinction due to global warming in general and Arctic warming in particular is benighted by a lack of appreciation or understanding of a long-term geological context.
For most advocates of the position that climate changes in the Arctic are predominantly caused by the explosive rise in anthropogenic carbon dioxide emissions since the mid-20th century, there is a conspicuous hyper-focus on the climate monitoring period beginning in the 1950s…or the late 1970s, when the satellite era began (and polar sea ice could be monitored).  The problem with this short-term perspective, of course, is that the 1950s to 1980s were a cold period in the Arctic, so any trend line beginning in those years will skew towards the point of view that more recent warming is unusual, if not unprecedented.  As the graphs below illustrate, the 1920s to 1940s were a relatively warm period in the Arctic — similarly as warm as the most recent decades.  The willful selection of the coldest decades of the last 100 years as the prerequisite starting point for examining modern climatic trends is reflective of the tendentious narrow-mindedness afflicting most advocates of the position that we humans pose a dangerous threat to the biosphere.  Expanding one’s perspective and focus beyond the last 60 or 70 years, or even a cursory look at the long-term climatic context as presented in the scientific literature, severely undercuts the perspective that recent climate changes in the Arctic are unusual, remarkable, or unprecedented.

Yamanouchi, 2011 (Arctic)



  Graph adapted from Climate4you, HadCRUT4 data

Using A Long-Term Context, Canada Has Not Been Warming

A few million years ago, the Canadian Arctic’s mean annual temperatures were about 18°C warmer than they are now.  During the summers many regions of the Arctic Ocean were sea-ice-free.  And yet polar bears survived these balmy, sea-ice-free climates anyway.

Cronin and Cronin, 2015
“Pliocene Arctic Ocean summer SSTs were appreciably warmer than modern and seasonally sea-ice free conditions existed in some regions. … At Lake El’gygytgyn (Lake ‘‘E’’) in Siberia summer temperatures were 8°C warmer than modern and at Ellesmere Island, Canada, summer and MAT [mean annual temperatures] were 11.8°C and 18.3°C higher than today.”
“[A] seasonally ice-free marginal and central Arctic Ocean was common … regionally during the early Holocene [6,000 to 10,000 years ago]. … Some species thought to be dependent on summer sea ice (e.g., polar bears) survived through these periods.” 

Although not as warm as a few million years ago, the polar bears’ Canadian habitat was nonetheless multiple degrees Celsius warmer than now as recently as a few thousand years ago.  Not only that, but the “reconstructed temperatures [for the Canadian Arctic] do not indicate a warming” during the last 150 years.  In other words, the (1) modern day Arctic temperature trends, the (2) sea ice loss trend observed via satellites since the late 1970s, and the (3) modern seal-hunting practices of the “endangered” 21st century polar bear…are all well within the range of what has occurred naturally, or without human interference, for the last several thousand years.  Polar bears have survived much warmer temperatures than this in the past, and the likelihood they will continue to survive in today’s relatively cold Arctic climate is high too.
Below are samples of available climate reconstructions for Canada and other locations (Siberia, Greenland, Northern Europe) where polar bears live.  Each demonstrate that there is nothing unusual about the modern day Arctic climate…other than it may be colder than most of the last 10,000 years.  And each demonstrate that the hand-wringing about polar bear species extinction potentialities due to today’s non-global warming is, to put it bluntly, much ado about nothing.

Fortin and Gajewski, 2016 (Canadian Arctic)
“Biological production decreased again at ~ 2 ka and the rate of cooling increased in the past 2 ka [2,000 years], with coolest temperatures occurring between 0.46 and 0.36 ka [460 and 360 years ago], coinciding with the Little Ice Age. Although biological production increased in the last 150 yr, the reconstructed temperatures do not indicate a warming during this time. … Modern inferred temperatures based on both pollen and chironomids are up to 3°C cooler than those inferred for the mid-Holocene.”


Moore et al., 2001 (Canadian Arctic)
“Summer temperatures at Donard Lake [Canadian Arctic] over the past 1250 yrs averaged 2.9 °C.  At the beginning of the 13th century, Donard Lake experienced one of the largest climatic transitions in over a millennium. Average summer temperatures rose rapidly by nearly 2 °C from 1195–1220 AD [+0.80 °C per decade], ending in the warmest decade in the record (~4.3 °C).“
[The 19th century average was higher than the 20th century average, and the 20th century average was lower than the average of the last 1,250 years.]


Cook et al., 2009  (Canadian Arctic)


Renssen et al., 2009 (Canada, Eastern)




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Viau and Gajewski, 2009 (Canada, Central)


Naulier et al., 2015  (Canada)

 

Polar Bears’ Siberian Habitat Is Colder Now Than Most Of The Last 10,000 Years

Hantemirov and Shiyatov, 2002 (Siberia, Northwestern)


Tarasov et al., 2009 (Siberia, Southern)


Polar Bears’ Greenland Habitat No Warmer Now Than In The 1920s, 1930s

Zhao et al., 2016   (Greenland Ice Sheet)


Hasholt et al., 2016 (Southeast Greenland)
“We determined that temperatures for the ablation measurement periods in late July to early September were similar in both 1933 and the recent period [1990s – present], indicating that the temperature forcing of ablation within the early warm period and the present are similar.”


Greenland Is Colder Now Than Most Of The Last 10,000 Years

Lecavalier et al., 2013 (North Greenland)


Thomas et al., 2016 (Greenland, West)
“Paired climate and ice sheet records from previous warm periods can elucidate the factors influencing GrIS mass balance on time scales longer than the observational record [Briner et al., 2016]. During the middle Holocene, temperature on Greenland was ~ 2°C higher than present [Cuffey and Clow, 1997; Axford et al., 2013].”


Aizen et al., 2016 (Asia, Greenland Ice Sheet)
“[P]eriods warmer than modern periods occurred for ∼6.5 ka [6,500 years] including during the HCO [Holocene Climate Optimum] and Medieval Warm Period.”


Northern Europe Is Colder Now Than Most Of The Last 10,000 Years

Esper et al., 2014 (Northern Europe)

Share this...FacebookTwitter "
"
Share this...FacebookTwitter
What follows is another example climate-scare prediction turned folly.
The NOAA’s and the University of Nebraska (Lincoln) National Drought Mitigation Center’s (NDMC) US drought monitor map that follows now shows extraordinarily little drought conditions across the USA, despite earlier predictions of permanent drought and misery over vast regions.


Meteorologist Paul Dorian of vencoreweather.com here in fact writes that moisture conditions across the US are now “about as good as it gets“.
He reports that “severe”, “extreme” or “exceptional” drought conditions are limited to a puny 1.6% of the continental US. Going back to the year 2000, only February and March of 2010 had similar limited drought conditions on a nationwide basis that we are enjoying today.
In fact the news may actually get better with the next drought monitor update as the numbers cited in today’s posting reflect only precipitation data registered through last Tuesday, April 4th and does not include the substantial rainfall that fell late last week in California and across the southern and eastern US.




&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img src=”https://static1.squarespace.com/static/56530521e4b0c307d59bbe97/t/58eb89ac29687f93406289b7/1491831225102/”  alt=”Western US drought conditions from one year ago (left) to current (right); courtesy NOAA/CPC”  /&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;


Western US drought conditions from one year ago (left) to current (right); courtesy NOAA/CPC








Discussion on current and recent conditions
In recent years, much of the western US was suffering through widespread and deep drought conditions, but that has changed dramatically in recent months; especially, in the state of California. One year ago, much of California was in the midst of an “exceptional” drought – the worst category of drought as classified by NOAA – but all of that has changed dramatically this winter season with a tremendous amount of rainfall throughout the state.
Today nowhere is California classified by NOAA/NDMC as experiencing “exceptional” (D4) or “extreme” (D3) drought conditions and less than one percent of California is currently experiencing “severe” (D2) drought.






&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img src=”https://static1.squarespace.com/static/56530521e4b0c307d59bbe97/t/58eb89e5197aea9c4041392a/1491831271942/”  alt=”Sierra Nevada Mountains provide more than 60% of California’s developed water supply”  /&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;


Massive Sierra Nevada snowpack
Figure right: Sierra Nevada Mountains provide more than 60% of California’s developed water supply








In addition to the recent rainfall in California, there has been an extreme amount of snow this winter season in the higher elevations of the Sierra Mountains across eastern California.  Snowpack in the Sierra Nevada region plays a critical role in California’s water supply as a natural form of water storage. More than 60% of California’s water originates in the Sierra Nevada region.
There has actually been so much snow this winter in some of the higher elevation locations that the National Guard has been called out to help with the removal of the snow. Another 3 or 4 feet of fresh snow piled up in the Sierra Nevada Mountains on Friday of last week in the latest major storm to affect California with significant rain and snow.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Now “as good as it gets.”
Also much of the south-central and eastern US experienced dry weather during the fall and winter seasons and this led to the declaration by NOAA/NDMC of “abnormally dry” (D0) or “moderate” (D1) drought conditions in many areas. But like California, recent significant rainfall events during a very active weather pattern have improved overall conditions in many regions across the south-central and eastern US.






&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img src=”https://static1.squarespace.com/static/56530521e4b0c307d59bbe97/t/58eb8a4e17bffc10a3b36417/1491831390837/”  alt=”The Palmer drought index, sometimes called the Palmer drought severity index and often abbreviated PDSI, is a measurement of dryness based on recent precipitation and temperature. The Palmer Drought Index is based on a supply-and-demand model of soil moisture. Drought conditions were extremely widespread and severe in July 1934 during the midst of the “Dust Bowl” era.&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;nbsp;”  /&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;


The Palmer drought index shows that drought conditions were extremely widespread and severe in July 1934 during the midst of the “Dust Bowl” era, far worse than what was experienced over the past years. Chart: NOAA








The worst heat and drought conditions by far occurred in 1930s
Meteorologist Dorian explains that any drought talk of recent years really pales in comparison to what happened in this country during the decade of the 1930’s. In the “The Grapes of Wrath”, John Steinbeck vividly captured the plight of millions of Americans whose lives had been crushed by what is referred to as the “Dust Bowl” era – a time when “climate gas” CO2 levels were far lower.
The 1930’s still ranks as the hottest and driest in US recorded history and the “Dust Bowl” was truly a significant event in our national history.






&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img src=”https://static1.squarespace.com/static/56530521e4b0c307d59bbe97/t/58eb8a8417bffc10a3b3765e/1491831938455/”  alt=”The figure on the left shows the annual values of the U.S. Heat Wave Index from 1895 to 2015 for the contiguous 48 states. An index value of 0.2, for example, could mean that 20 percent of the country experienced one heat wave, 10 percent of the country experienced two heat waves, or some other combination of frequency and area resulted in this value. &amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;nbsp;Data source: Kunkel, 2016 (EPA). &amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;nbsp;The figure on the right shows the number of all-time maximum temperature records at USHCN weather stations that reached extreme heights in 1936 – far and away above any other year.”  /&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;


The figure on the left shows the annual values of the U.S. Heat Wave Index from 1895 to 2015 for the contiguous 48 states. An index value of 0.2, for example, could mean that 20 percent of the country experienced one heat wave, 10 percent of the country experienced two heat waves, or some other combination of frequency and area resulted in this value. Data source: Kunkel, 2016 (EPA).
The above figure on the right shows the number of all-time maximum temperature records at USHCN weather stations that reached extreme heights in 1936 – far and away above any other year.
Tens of thousands of “climate refugees”








Conditions were so dry in such a widespread part of the country that dust storms formed numerous times in the Central Plains as loose soil turned to dust which the prevailing winds blew away in huge clouds that blackened the skies – even as far away as the east coast. The drought came in three waves during this decade, 1934, 1936 and 1939-1940, and tens of thousands of families had to abandon their farms.
Dorian summarizes today’s conditions:
Yes, these are pretty fortunate times we are currently living through across the US.”
See Vencore meteorologist Paul Dorian’s full report here.
 


Share this...FacebookTwitter "
"It is too simplistic to say that cutting livestock numbers everywhere is the most efficient way of reducing emissions, as your article suggests (Governments urged to set deadlines for cutting livestock production, 12 December). The world’s livestock systems differ too significantly for them to be generalised, and doing so hinders the countries that are practising sustainable farming methods and which have an ambition to do even more. Compared with the mass-scale intensive systems in the US or Brazil, our livestock systems are unrecognisable. British farmers do not clear rainforest to make way for beef production. Our meat does not come from the ashes of the Amazon. We value our carbon sinks.  Grazing cattle is the most sustainable way to use the 65% of UK farmland that is unsuitable for growing any other crop. It is hugely beneficial for the soil, helps lock up carbon, and is the best way to turn inedible grass into highly nutritious protein for a growing population to enjoy. What’s more, British farmers have an ambition to become net zero by 2040. We want to lead the way in climate-friendly meat and dairy and pave the way for others to follow. This needs to be recognised.Stuart RobertsVice-president, NFU  • Damian Carrington is correct that people in wealthy countries need to eat less meat. But to make targets for reductions in meat consumption is to put the cart before the horse. Excessive meat production is a symptom, not a cause, of the problem. Once we start to eliminate the use of fossil fuels, economic forces will reduce livestock numbers to sustainable levels because there will be increased demand for land for biomass, and because artificial fertilisers will almost certainly be in short supply. Until that happens there is a danger that focusing on meat and livestock will be a futile distraction from the task at hand which is to put an end to the use of fossil fuels. Simon FairlieThe Land magazine • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"Boris Johnson has been urged to follow in the footsteps of Margaret Thatcher by taking to the world stage to lead international action on the climate emergency – but to put the UK’s own emissions-cutting efforts back on track first. The prime minister was told on Wednesday that the UK had so far “fallen short” on its commitments to tackle greenhouse gases, in a letter from the committee on climate change (CCC).  To succeed, Johnson must bring forward new policies across the board as a matter of urgency, “demanding ambitious policy from all departments to ensure homes, businesses, industry, transport and land are helping to deliver net zero”, according to a letter to Downing Street from the government’s statutory advisers on how to achieve the UK’s long-term goal of reaching net-zero carbon by 2050. The UK is to host crunch UN talks on the climate emergency in Glasgow next November, at which nations will be asked to update their commitments on emissions under the Paris agreement. Lord Deben, the chair of the committee and a former Conservative environment minister under Thatcher, wrote: “We marked recently the 30th anniversary of Margaret Thatcher’s 1989 speech to the UN general assembly. That speech described accurately the science of human-induced climate change and the scale of its economic impact. The prime minister advocated a strong global response then; but what followed was too little. You have the opportunity to lead a better international effort. But first, we must get our own house in order.” Renewed economic policies and new regulations will both be vital, the committee said. There should also be more work on helping the UK adapt to the likely impacts of global heating, including more resources for flood prevention and planning for long droughts, such as the UK drought that caused widespread problems two years ago. Buildings, transport, electricity, industry and agriculture must be the five key areas of focus, the CCC said, and action on all fronts must begin urgently. “It has been nearly seven months since the net-zero target became law. Every day of inaction makes the challenge of cutting emissions harder and costlier. Technological innovation is only part of the answer. We must not wait for future technologies to solve the problems we can already tackle with known solutions,” the committee said. Campaigners urged Johnson to make following the committee’s advice a priority. “Aside from being crucial to life and wellbeing, action on climate change makes economic sense. It brings significant benefits for public health, UK jobs, and industries,” said Mike Childs, the head of science at Friends of the Earth. “The prime minister was alarmingly quiet on the climate crisis during his election campaign – failing to attend the televised debate on climate, and giving little attention to the issue in his party manifesto. “We can’t afford any more lost time where science is ignored and ministers dawdle over climate action. It’s time that the government listens to its own advisers and stops the climate crisis worsening.” A government spokesperson said: “In the manifesto, which delivered a majority for the prime minister, he clearly set out his vision to ensure Britain has the most ambitious environmental programme of any country on Earth. This government will deliver on our science-led target of net zero by 2050. “From increasing tree planting rates to bringing forward the phase out date for petrol and diesel cars, we will provide the policies needed to ensure we are on track to hit our world-leading climate targets and demonstrate our global leadership in advance of the crucial COP26 talks in Glasgow next year.”"
"Disagreement over Australia’s plan to use an accounting loophole to meet its climate target will spill into 2020 after a United Nations conference in Madrid failed to reach consensus on rules to implement the global deal. As talks dragged past the scheduled Friday close into Sunday afternoon, Australia was accused of “cheating” and named by other countries and conference observers as one of a handful of nations that thwarted a deal on the rulebook for the Paris climate agreement. The Morrison government drew criticism throughout the fortnight-long conference for planning to use carryover credits, an accounting measure linked to the expiring Kyoto protocol, to meet the 2030 emissions target it set at the Paris summit four years ago. Australia claims access to the carryover credits for beating its Kyoto targets. Opponents say those targets were unambitious and based on earlier favourable accounting rules won by the Howard government more than 20 years ago. Laurence Tubiana, a former French environment minister and architect of the Paris accord, told the Financial Times: “If you want this carryover it is just cheating. Australia was willing in a way to destroy the whole system, because that is the way to destroy the whole Paris agreement.” Using the credits would reduce what Australia needs to do to meet its 2030 target of a minimum 26% cut in emissions below 2005 levels by more than half. Analysts said there was no legal basis for Australia using the credits as the Kyoto and Paris agreements were separate treaties, and noted officials had acknowledged Australia was the only country planning to still count them. The conference fell victim to the base positions of a handful of major polluting countries, Australia included In a last-ditch bid to reach agreement on Saturday, a group of nations, led by Costa Rica and including Britain, Germany and New Zealand, released a set of minimum standards for a deal. Described as the “San Jose principles”, they included an explicit prohibition on the use of carryover credits and other Kyoto-era allowances sought by some major developing countries, particularly Brazil. Costa Rica’s environment and energy minister, Carlos Manuel Rodríguez, called out “Australia, Brazil and the US” for blocking progress. The group said the steps were necessary to keep open the possibility of limiting industrial global heating to as close to 1.5C as possible, a goal agreed in Paris four years ago. Japan, not a signatory to the principles, told the final plenary meeting that it also opposed the use of Kyoto-era credits. The proposed ban was opposed by Australia, Brazil and a small group of other countries. Australian negotiators at the talks argued carryover credits were beyond the scope of a debate over international carbon markets, a main focus of the Madrid talks, and should not be included in that rulebook. Observers at the talks said Australia’s team argued using carryover credits was a non-negotiable instruction from the prime minister, Scott Morrison, and they were not authorised to compromise. Richie Merzian, a former Australian climate diplomat, now with the Australia Institute, said Morrison was increasingly associated with Donald Trump and Brazil’s Jair Bolsonaro as leading culprits unmoved by fires raging in New South Wales, California and the Amazon. The US has formally signalled its intention to leave the Paris agreement next year. “The conference fell victim to the base positions of a handful of major polluting countries, Australia included,” Merzian said.  Dean Bialek, a former Australian diplomat at the UN, now principal adviser at Mission 2020, the group led by former UN climate chief Christiana Figueres, said Australia’s diplomatic contribution to the talks was “cynical, irresponsible and ultimately destructive”. He said that it went to the conference to reveal that 80% of its Paris target would be met through an accounting trick showed that Morrison’s claim Australia would meet its Paris target “in a canter” was legally baseless. “Along with the position of the US, it brought to the surface for developing countries that some developed countries were not serious about their commitments,” he said. “To do this at a time when large swathes of the country are ablaze is frankly unacceptable and would be to the vast majority of the Australian community.” Australia was represented at the talks by the emissions reduction minister, Angus Taylor, but he left on Wednesday, leaving the final negotiations to officials from the Department of Foreign Affairs and Trade. On Monday, Taylor said Australia had “reconfirmed” its commitment to the Paris agreement and would continue to work through the UN process to deliver the only outstanding element of the Paris rulebook. He said the latest data showed national emissions were coming down. According to the government’s quarterly greenhouse accounts, emissions dipped by 0.1% over the year to June, mainly due to a slump in agriculture linked to the drought and Queensland floods. Emissions from industry and resource extraction continued to rise. The Morrison government released emissions projections during the talks that showed it was relying on the use of carryover credits, which it now describes as “overachievement”, to meet its Paris goal. The government assessment found without the credits Australia was expected to achieve just a 16% cut below 2005 levels by 2030. Government advisers previously found Australia’s fair share under a meaningful global deal would be at least 45%. A survey of Australian businesses by the Carbon Market Institute released at the talks suggested three-quarters did not support relying on carryover credits. Carryover accounting rules were allowed under the Kyoto protocol to encourage countries to be as ambitious as possible. They were not mentioned in the original text of the Paris agreement. This year’s talks focused on what is known as Article 6, governing the workings of the global carbon markets, which are meant to allow countries to pay for emissions cuts where in the globe they are cheapest. Few countries came with updated plans to reach the Paris goals. Analysts say much deeper cuts than promised at Paris are needed if countries are to achieve the goals of limiting warming to well below 2C and as close to 1.5C as possible. There were fears the issue of future emissions cuts would be sidelined at the talks, but a “high ambition coalition” of the EU and many smaller developing countries pressed for a resolution to ask all governments to formulate stronger national plans. The next major round of talks is in Glasgow next November."
"What characteristics would your ideal home have? A sauna? Lots of natural light? An open-plan kitchen?  Whatever your answer, you probably didn’t consider how the things you wanted would affect the energy you use. The link between comfort and energy is not something that troubles most people, but actually it’s very important. In the UK, our houses consume up to 27% of the energy we produce.  Governments encourage us to save energy through things such as turning off the lights and taking shorter showers; better insulation and boiler upgrades; and installing renewable energy sources like solar panels in the home. But none of this pays attention to the comforts we expect, and how they have changed over time. To give one example, indoor temperatures in the UK rose from 12°C to 17.5°C between 1970 and 2010. Despite all our efforts to bring it down, the amount of energy we use at home is not much different to 40 years ago. As the world digests the outcome of the Paris climate talks, it’s time our desire to be more comfortable came under the spotlight.  Until the 18th century, comfort was far less about physical pleasure than spiritual satisfaction, well-being and consolation. Seating was designed to aid sitting respectfully with a refined posture. The equivalent of today’s La-Z-boy chair was created on medical grounds for invalids, pregnant women, and men with gout (see image below) – what we think of as comfortable was not even intended for normal able-bodied people.   The shift in our expectations happened for a couple of reasons. There was a consumer revolution between 1700 and 1850, which saw people filling their homes with objects – clothes, accessories, furnishings and so on. And humanitarian reformers began to see comfort as one of our basic human needs, and gave it more of a physical emphasis. Basic standards of comfort came to be seen as a benchmark for social equality – elevating an adequately heated home to a human right, for example.   The trouble is that once one basic need is met for everyone, there is always scope for improvement. Turn comfort into a commodity and it becomes part and parcel of a high-consumption society. With the best of intentions, this is what has happened to us.  In Glasgow in 1850, for instance, each person used an average of 3.73 litres of water per day for drinking, bathing and so forth. Today’s average is roughly 150 litres. This reflects how social conventions have evolved alongside technical innovations, such as the development of the bathroom and new hygiene standards.  In the UK, the years between 1890 and 1920 marked a dramatic transformation in our expectations of home comfort with the arrival of central heating, indoor plumbing, running hot and cold water, electric light and power. Connecting homes to these networks of water, sewage, gas and electricity unsurprisingly transformed domestic life and the layout of homes. Alongside these changes, our energy requirements skyrocketed.  The past few decades have seen further crucial changes. The pie charts below give a flavour of them. You can see a big rise in appliances, reflecting all the mobiles, tablets, consoles and so forth in modern homes. Energy for home computing more than doubled between 2000 and 2014, for instance.   Energy use in UK homes, 1970-2011  We also use more hot water, having shifted from weekly bathing to daily showering, and more light bulbs. But the energy shares of water and lighting are down thanks to more energy-efficient technology. Cooking is down too, but don’t be fooled here. We are eating more takeaways and ready meals, so the energy for preparing them has just been outsourced. On the other hand, we now actually use more energy to heat space. This is despite the fact that central heating has become very common since the 1970s. It is a more efficient way of making a room warm, but we heat more rooms and to higher temperatures.  Where householders were once brought together by the warmth of the fireplace in the living room, it became possible for them to do individual activities in individual rooms. Hence individual privacy became a fundamental expectation of home comfort, meaning that more rooms needed to be warm enough to spend time in. One consequence has been that the amount of living space per person in the UK has been rising. And house and household size are some of the biggest determinants of energy demand. The change in our view of what constitutes a normal indoor temperature in the past 20 years is down to the spread of air conditioning, central heating and thermal regulations. Which is an example of why we need to be aware that changes in technology and improvements in efficiency don’t always reduce consumption in the ways we might expect. Indeed, many researchers have been led to suggest that the 5.5°C rise in 40 years is grounds for switching our focus to indoor climate change.  In short, governments and academics need to pay much more attention to what people want from their homes. They need to think about how these expectations of “normal” home comforts have been changing, and the influence of improvements in efficiency and low-carbon technologies. What we see from the Paris climate talks is that governments are focusing on technical fixes to our carbon problem, rather than challenging the richest 10% of the population to question the sustainability of their desire for more and more comfort. Since they are responsible for half the world’s carbon emissions, we won’t succeed until that finally changes."
"
Share this...FacebookTwitterRenowned Princeton physicist William Happer told New York Times science journalist Andrew Revkin in an online video conference that he believes the world has got it all wrong when it comes to the implications of CO2 emissions into our atmosphere.

 
Happer told Revkin that “any dispassionate weighing of the facts would give you a negative cost of carbon” and that “more CO2 is good for the world“.
Moreover Happer believes that the whole climate issue has “distracted people from real problems” like massive pollution in places like China and India.
Happer adds that he thinks “enormous damage has been done to the environment by diverting money from real problems to completely made up problems.”
He tells the New York Times journalist that he absolutely sees CO2 as a “non-problem” and that he even sees the trace gas “as good“. He reiterates: “Let me be clear: It think it’s not a problem. I think it’s a good thing.”
 
Share this...FacebookTwitter "
"It’s all change at the most important climate science body in the world, the Intergovernmental Panel on Climate Change (IPCC). Hoesung Lee of South Korea was named the new chair – and it’s fair to say he is much less well-known than his European and American rivals. Raising his profile will be one challenge, but much more important will be improving the way the IPCC communicates with its many audiences. Lee has promised to do exactly that, but so far he has been short on specifics and new ideas. He will have to get up to speed quickly as the crucial Paris summit is almost upon us. In the run-up to the last (potentially) breakthrough UN summit in Copenhagen in 2009, the IPCC was very slow to rebut the challenges to mainstream science launched by sceptics. As the president of the Copenhagen meeting, Connie Hedegaard, was quoted as saying: “Millions were put into international campaigns, yet when Climategate emerged the IPCC had almost no one employed to take care of communications.  They did not even have a communications team.” The IPCC has come a long way since its inept handling of the Climategate and Himalayagate controversies.  For a start, it now has professional communications staff, but it has an equally long way to travel. Academics and others have identified some of the obstacles to more effective IPCC communication – a lack of resources, over-reliance on technical language, and failure to take advantage of new media have all been identified. To his credit, Lee did mention in his first press conference as chair one area of communication he wants to develop: he will increase the amount of outreach work directed at a wider audience around the world. This is one of the recommendations coming out of a recent survey of users of the IPCC’s blockbuster volumes known as the assessment reports, which the IPCC publishes every five or six years. In this survey (to be published soon as part of a research project analysing how the IPCC reports inform policy making) my colleagues and I interviewed 30 representatives of the groups identified by an independent review of the IPCC as their target audiences – policy makers, the business sector, NGOs, higher education and the media. We wanted to know their views on the usefulness of the IPCC reports, their language and clarity, and recommendations for the future. One of the recommendations is that one highly effective way of communicating the science is when IPCC authors talk directly to local, regional or sector-specific users, particularly when they combine their own expertise and scientific rigour to communicate the findings clearly. But another clear message from the research is that although the IPCC reports sets the standard for high-quality science, overall they still suffer from low-quality communication. Part of the problem is that the often impenetrable or jargon-ridden language used by the scientists may be fine for other scientists in their peer group but not for policy makers and other non-expert groups. Many of the interviewees recommended bringing in specialist writers (who are familiar with the science) early in the writing process. Another issue is the appropriate level of resources for communication. The IPCC rightly parades the large numbers of scientists (running into the thousands) who write and review its reports. But it is not as widely known that the communications team consists of just one head, former Reuters journalist Jonathan Lynn, backed up by one or two colleagues. It may not be the best use of IPCC funds to substantially increase its permanent media staff as demands on them peak mostly at the time of publications. However, a strong case can be made for increasing selected funding in the following areas: outreach work, building an online and social media strategy, graphics development, learning good practice from other reports and developing better metrics for assessing how widely the IPCC reports are used. Lee wants more input from the finance and business sectors into the IPCC reports. He’s right, but how should he do it? Again, our survey recommends that policy makers and businesses should have more input into the early stages of scoping the reports to help ensure that policy concerns are flagged more clearly in the final reports. More so-called “derivative products” would also be very helpful. These are reports aimed at specific audiences that take parts of the IPCC reports and communicate them in formats that work for those audiences. Those produced by the Cambridge Institute for Sustainability Leadership are a good example. The challenge is to adapt the IPCC process to allow more deployment of IPCC authors to work with these types of reports, perhaps instead of devoting so much effort to the mammoth assessment reports. The IPCC could provide some accreditation and recognition to authors and universities for participating in this manner. A huge body of climate science is now agreed upon by the large majority of scientists. Of course, the most important knowledge gaps need to be identified and reduced – but just as much intellectual energy needs to be directed at the thorny challenge of how best to communicate the science, particularly in a digital world."
"Many bat species suffered severe population declines in the UK and elsewhere during the 20th century mainly due to their habitats being fragmented, damaged and destroyed, particularly in woodland areas. Though many species have stabilised or even increased slightly in the past couple of decades, numbers are still much lower than they were in the early 1900s.  The woodland destruction has made it harder for many bats to hunt and now they are also having to deal with other emerging threats such as wind turbines, artificial lighting and in North America, a disease known as white nose syndrome. One of the difficulties for many bats is that they don’t necessarily like to feed where they roost. This is because they need very different things from each environment. Bats can roost in small places such as a tree crevice or an attic in a house, the main requirement being that they provide a stable micro-climate with optimum humidity and little variation in temperature.  But they need much bigger spaces to get enough food to keep their fast metabolisms functioning – flight requires lots of energy. Good foraging areas don’t need that stable micro-climate, but do need to provide lots of invertebrate prey such as moths and midges, plus a conducive hunting environment – areas without much vegetation are little use to species like the brown-eared bat, for instance, since they glean their food from it.  You might think that being able to fly makes bats highly mobile animals that would find commuting to good hunting ground easy, but it’s not that simple. The mobility of bats very much depends on the shape of their wings. Species with long narrow wings such as noctules are usually well adapted to fly fast across open spaces, while others such as the common pipistrelle forage in moderately cluttered areas such as woodland edges. It can also commute long distances and catches its insect prey in the air.   Bats with shorter wider wings, such as the brown long-eared bat, are better suited to being highly manoeuvrable. This comes in very handy for getting hold of your dinner off vegetation in a cluttered woodland, but not so much when it comes to getting from habitat patch to hunting ground.  Roosting preferences also play a role in how species respond to environmental changes. While species like the brown long-eared bat are quite fussy about their requirements and only roost in or near trees, the likes of the common pipistrelle quite happily use human-made structures such as houses or bridges as their homes. More adaptable species are more comfortable with changes to their environment – most bats are not. The upshot is that some bat species find the prospect of commuting long distances more severe than others. Slow and highly manoeuvrable fliers like the brown-eared bat don’t travel long distances to their foraging sites and are often reluctant to fly across open spaces. So they are very sensitive to woodlands being destroyed and fragmented.  Even species like the highly mobile common pipistrelle suffer from insensitive human development. It is less affected by deforestation, but still influenced by both the quality of the woodlands in which it forages and what is in their surroundings too. Landscapes which include tree lines, rivers and grasslands make it easier for these bats to commute than intensively farmed areas with nothing more than crops. We humans are making efforts to restore woodlands, having recognised how much bats depend on them – not to mention many other species, including ourselves. One promising mechanism for reversing or at least slowing down the damage is woodland creation and management schemes. These typically involve governments providing financial incentives for farmers to increase the amount and quality of woodland on their land. They are most common in certain European countries and Australia – for example in the UK, they have helped increased woodland cover from a low of 5% in 1900 to 13% today.  Unfortunately newly planted woodland areas are often of limited value for biodiversity. They tend to benefit highly mobile species, but not the fussier woodland specialists, since they don’t have the sort of good-quality undergrowth that develops over time in wooded areas. This means for example that they are not very attractive to moths, which are the preferred food for many bat species, including the brown long-eared bat, compounding its restricted mobility.  How to get around this problem? We should be using our knowledge of bat ecology to inform these interventions. We need to include efforts to increase undergrowth, for example, and recognise that most bat species like big old trees. Even for more flexible species, we also need to increase habitat connectivity by creating wooded corridors between woodland areas.   The same thing applies on a smaller scale to the likes of beetles and voles, and even lichens and mosses. They depend on high-quality local habitat too, as well as connections between wooded areas. Get these actions right and we will be far more successful at helping bats and other species. Get them wrong and our efforts to protect biodiversity and maintain the populations of bats and other creatures will not make much difference."
"Bond villains have always been interesting characters: sophisticated, intelligent and supremely well-equipped with futuristic and cutting-edge toys.  Aptly, the new official car of evil, a Jaguar C-X75 driven by henchman Mr Hinx in the latest Bond movie Spectre, is as advanced as it gets. A 850-horsepower hybrid with four electric engines and diesel-fuelled micro turbines, it can reach a top speed of more than 200mph. The prototype was too costly to go into full production but has been dusted off specially for the movie. It can cover the first 60km of any journey in purely electric mode, and only ever emits 89g of carbon dioxide per kilometre – comparable to the emissions of even the greenest petrol-powered family hatchback. On the other side of this is James Bond, who need only load up a conventionally-powered Aston Martin or Bentley with Q’s best clandestine technology in order to vanquish evil. And in Spectre, Bond’s back driving a silver Aston Martin with an unashamedly petrol V8 engine.  It is called the DB10 – and you won’t find it in any show rooms as it was designed specifically for the film. Why would this kind of car be all it takes for Bond when the bad guys are clearly choosing their wheels with higher ideals in mind? The underlying message of this is perhaps supposed to be that “British values will stand” – but are the makers of the film missing something important? The Jaguar C-X75, notwithstanding its sinister driver, is actually a “green car” – while Bond’s is anything but. Perhaps henchman Hinx is really a kind-hearted environmentalist who lovingly maintains extensive hydroponic hobby gardens and supports the cause of the African rhino when not murderously chasing protagonists down the streets of Rome? I haven’t seen the film yet, but I already like Mr Hinx a little more than Bond when I imagine this. Alas, I don’t think we are supposed to side with the henchman.  Instead, the fact that fast electric vehicles are being used by the ultimate baddies shows we are ready to take them seriously. As recently as 2008, when Quantum of Solace was filmed, the only electric sports car was the friendly-looking Tesla Roadster, which was quick, but not menacing enough to stir James Bond and his audience. The grunt of the C-X75 is taking electric capability and street cred to a whole new level. A slightly different question might be why off-the-shelf cars no longer seem to be good enough for the transport needs of good and evil now. Both Bond’s Aston Martin DB10 and Hinx’s Jaguar C-X75 are bespoke vehicles. As an old Bond veteran, this rubs me up slightly the wrong way, as these films historically always used to showcase the cutting edge at its most dramatic and advanced, but always seemed to say: “this technology is coming your way, folks. One day, you will be using stuff like this yourselves.”  But it doesn’t seem that way now. You may like the Aston Martin DB10, and you may like the Jaguar C-X75, but they can never be yours. They are cars for the demi-gods of good and evil now.  But clearly the future is electric. Though you might never get to drive that eco-Jaguar, a Tesla is still realistic enough. So, when are we going to see James Bond electrified? The coming film will raise questions as to why henchmen should get a fancy hi-tech hybrid-turbine, while Bond still makes do with a Victorian steam engine that does nothing for the survival of those rhino. If Bond wants to hold the continued respect of his audience, a conversation with Q will be required to stuff some batteries into the DB11. But that’s still one movie away."
"One of the final obstacles in the way of a binding agreement at the Paris climate talks comes down to a simple number: 1.5. Limiting warming to a 1.5℃ temperature rise above pre-industrial levels is one of three potential targets on the table as negotiations approach the crucial final days. The other options are a firm limit of 2℃ and a limit of 2℃ with an aspiration to reduce to 1.5℃ in the coming years. Releasing the latest draft text on Wednesday afternoon local time, the summit’s president Laurent Fabius listed the target as one of three outstanding major issues, alongside finance and the question of how to differentiate the responsibilities of developed and developing countries. Many industrialised countries have surprised the world at the talks with a new-found fondness for 1.5℃. The target has long been a key demand of most poor nations, particularly small island states and least-developed countries.  Scientists consider that as 1.5℃ is breached, we will risk passing critical tipping points. In particular, sea level rise associated with that level of temperature increase poses an existential threat to low-lying island states.  Despite more than 100 developing nations being firmly in favour of a 1.5℃ limit, countries came to a political agreement in 2010 to collectively set themselves a 2℃ threshold. If a temperature limit of 1.5℃ is fixed in the new Paris agreement, that raises the question of what countries will need to do to stay below that level of warming.  The UN’s top climate science body has shown that carbon dioxide (CO2) emissions are cumulative, with residence times in the atmosphere of thousands to tens of thousands of years. Temperature rise has a linear relationship with carbon emissions, so we can estimate the remaining amount of CO2 that can be emitted before we risk passing any temperature limit with some probability. For a 50% probability of staying below 1.5℃, there was a remaining carbon budget of 550-600 gigatonnes CO2 in 2011. At current annual global emissions of around 36 gigatonnes CO2, this budget will be used up in less than two decades. What does staying below 1.5℃ mean in practice? Nothing less than full decarbonisation of the global economy by 2050. We must stop burning all fossil fuels before the middle of the century, along with a massive effort to keep forests standing and protect biodiversity.  That is no small feat. While some say limiting warming to less than 1.5℃, or even 2℃, is out of reach, ultimately 1.5℃ is a political signal for greater ambition, and a more serious global engagement in addressing climate change. Late in the day as this signal might be, it is important that a new international agreement does not include a temperature limit that even the UN has recognised is not a safe guardrail. But what does this mean in real terms – if a temperature goal is agreed that requires rapid decarbonization: who must do what, and by when? At the heart of the standoff in the climate talks are fundamental differences over who has more responsibility to act, and what a fair approach to drive greater ambition looks like. A broad coalition of NGOs set out to define a methodology to answer that question, taking into consideration the remaining carbon budget, historical emissions (as impacts on temperature are cumulative, historical emissions matter), and differing capacities between countries.   Their numbers show that the ambition – UNFCCC jargon for emission reduction efforts – of all developed countries falls well below their fair share of what is needed to stay within the remaining budget. Top of the list of offenders are Russia and Japan who are making little to no contribution to what would be considered their fair share of effort, while the US and the EU have pledged around a fifth of their fair share.  In this context, we start to understand why many developing countries might not want to commit to a 1.5℃ limit without clear rules on how to divide up the effort. The current emissions trajectories of developed countries will take up far more than their fair share of the remaining budget, seriously impeding the poverty alleviation and sustainable development aspirations of developing countries. But development trajectories that exceed the global carbon budget will not work for the planet – regardless of who has done what historically, all countries are now bound by the very limited carbon budget remaining. This means that even for countries who have pledged what is basically their fair share of global action, such as China or India, they will need to do a lot more to keep the world anywhere near a 1.5℃ pathway.  For poorer countries (India ranks 135 on the Human Development Index), committing to do more than their fair share needs to be in the context of international commitment to support.  In the end, the 1.5℃ conversation is not the real debate. The real challenge in Paris is to agree on language for emissions reductions that is even remotely compatible with achieving whatever temperature goal is set. This is referred to as the “collective global goal”. Options for a global goal include peaking emissions, zero emissions, or decarbonisation or climate neutrality. But without a differentiated long-term goal – one that puts increased ambition in the context of more support for developing countries – whether the goal is for peaking or zero, 2050 or 2100, all becomes meaningless. Ultimately, the call for 1.5℃ must not become a distraction from the real challenge: agreeing a collective goal that includes both ambition and equity. Without a clear sense of who needs to take the lead, who needs support to do more than their fair share, and how this will collectively keep global emissions within a carbon budget – everyone will lose."
"Even the best-case scenario following the Paris climate agreement will still lead to rising sea levels, harsher droughts and more destructive storms – all of which will hit those with least protection the hardest. So are we going to see waves of “climate refugees” pushing on affluent countries’ gates? Will hordes of climate change victims jeopardise international security, exacerbating existing crises and spurring armed conflicts? One would think so, at least judging from the way the media talks about the overlap between climate change and migration. Time after time, again and again, climate refugees are mobilised to provide dangerous global warming with a human face.  Usually this is to highlight the security implications of climate change. Recently, this narrative has surfaced in relation to the Syrian tragedy and the way that the conflict and the related displacements have been attributed to climate change by research papers – and even Prince Charles. Such alarmism might be appealing, but it’s at odds with most of the research on how climate change will interact with migration. The figures of hundreds of millions of climate refugees have been widely echoed in the media but the headline numbers are at the least controversial if not outright scientifically unsound. In any case, the entire concept of “climate refugees” is evocative but misleading. Let’s begin with the obvious: people migrate for lots of different reasons and, in most cases, it is impossible to single out environmental degradation. When people do move in response to a sudden storm or flooding, they usually stay in the same region and return home as soon as they can. A growing number of interventions point out that migration, in presence of the right conditions, can also represent a proactive strategy to cope with stress or adapt to change. Finally, there’s no simple link between climate change, displacement and security. Environmental stress can exacerbate tensions, but also increase cooperation. And we should not conflate things playing out at different scales: the idea that food stress (and the poor) cause war is very problematic – a quarrel over a loaf of bread is not the same as an armed conflict between states. None of this means the issue is unimportant. Climate change will have the biggest impact on the weakest and most exposed – whether they are migrants or those without the means to move. Indeed, (im)mobility will be one of the currencies through which vulnerable people will pay the price of the international community’s failure to avoid climate change. The Paris agreement establishes a “task force” to “develop recommendations” on displacement. Some hoped for stronger wording – an earlier draft included the creation of a “coordination facility”, presumably with more powers. This was only removed in the last days of the summit. Yet in order to keep the issue on the table, a mention in the treaty is a step in the right direction. However, I am not sure we can expect too much from the UN’s climate process. An emissions deal was clearly the highest priority for this phase of diplomacy. With a “refugee crisis” shaking European institutions and the reaction to the terror attacks in Paris adding to the international tension over migration, the topic was just too controversial. In this context, it wasn’t exactly realistic to expect states in Paris to accept any legally-binding obligations to facilitate the movement of vulnerable people.  But, on top of the question of political feasibility, it is also worth asking whether UN climate policy should even be addressing migration at all. Environmental discourse has always been haunted by a fear of dangerous, unruly populations in the “global south” – a spectre that arguably  still lingers in climate politics. This leads to apocalyptic talk, usually with a strong racial undercurrent, of hordes of refugees threatening “our” security. Not exactly a good starting point. The idea we should “solve” climate migration is rooted in a view of mobility as pathological, as the result of a failure to develop, to adapt to climate change, or to be more resilient. But in reality, migration is an ordinary social, economic, and political process. It’s neither inherently good nor bad. Of course, it would be naive to overlook the divisive questions that migration brings to the surface. And we should always remember that people on the move (or stuck somewhere they don’t want to be) can suffer and are often exposed to many wrongs.  Relying on the UN’s climate governance machinery to sort these matters out only obfuscates their inherently political character and will lead to poor policies. To make a provocative comparison: would we ever expect the UNFCCC to “solve poverty”? Yes, it is important that migration was mentioned in the Paris agreement. And we should talk more about it in the climate change arena. But more as a matter of climate justice than one of security. And not as a contingent problem to be solved (or that can be solved) – rather as one of the ways in which we deal with the highly political question of the kind of mobility and society we want for the decades to come."
"Thursday’s Queen’s speech is Boris Johnson’s second in just over two months. The more than 30 pieces of legislation will be the basis of his political agenda for the year. Described as “radical” by the prime minister, it leads on his law to formally take the UK out of the EU. There are also plans to overhaul immigration and put into law investment in the NHS.  The European Union (withdrawal agreement) bill will ratify the deal the prime minister struck with EU leaders in the autumn and which was voted down by parliament repeatedly. He is set to put this bill to MPs on Friday and hopes to have this passed by 31 January. This legislation also includes an implementation period where the UK remains aligned with the EU until 31 December 2020. An agriculture bill will result in Britain leaving the EU’s common agricultural policy. Direct payments to farmers will be phased out. The fisheries bill removes the UK from the common fisheries policy and means foreign fishing boats will not be able to have automatic access UK waters. The immigration and social security co-ordination (EU withdrawal) bill proposes an Australian-style points based system that would end free movement in UK law. Also, from 2021, EU citizens arriving in the UK will be subject to the same immigration controls as non-EU citizens. This is the first time a government has enshrined in law its spending on the NHS, which is £33.9bn in cash terms by 2023-24. Their NHS long-term plan also includes delivering 50,000 more nurses, which was a controversial part of Johnson’s manifesto messaging. There is no specific social care bill, but a section of the speech was dedicated to reform and how they want to find a “cross-party” consensus on devising a strategy. They pledge to modernise the Mental Health Act and improve processes for detention. And there is a pledge to remove hospital parking charges. The sentencing bill includes tougher sentences for those who commit violent and sexual offences and terrorism. The automatic release point for prisoners will be moved from half of their sentence up to two-thirds. Johnson said he would bring in legislation on this in November following the London Bridge terror attack, where the killer, Usman Khan, had been automatically released after serving half of his 16-year term. The most serious terrorist offenders will receive a 14-year minimum sentence. The speech also reaffirms the earlier commitment to recruiting an additional 20,000 police officers. An employment bill is promised that will protect and enhance workers’ rights when the UK leaves the EU. The government will create a new single enforcement body that gives workers being treated unfairly the right to redress. A renters’ reform bill is also set out with the promise of giving tenants more security by removing “no-fault” evictions and reforming the grounds for possession. A lifetime deposit scheme that can be moved between properties is intended to stop tenants having to save up every time they move house. . The government says it plans to expand the national living wage to those aged between 21 and 25 over a five-year period but does not set out legislation to do so. A pensions scheme bill includes a “pensions dashboard” so people can access information on schemes online and there will be protection of the triple lock. There is no provision for Waspi women set out in the speech. The science, space and research bill sets out plans to boost funding for research to tackle the UK’s contribution to climate change. An environment bill will set legally binding targets, including a commitment to improving air quality and banning the export of plastic to countries outside the OECD. There will be tougher sentences for animal cruelty of up to five years. It will also be enshrined in law that animals are sentient beings and the government has a duty to protect them from harm.  The government will not raise rates of VAT, income tax or national insurance, which they claim will help working families. A new no-fault divorce category will end one spouse having to make an allegation about the other’s behaviour to end the marriage. The government will stop public institutions, including councils and universities, from imposing their own views on international relations with boycotts and sanctions. The prime minister said he wants to end institutions developing their own “pseudo-foreign policy” against countries that, “with nauseating frequency, turn out to be Israel”. There are proposals to significantly beef up existing espionage laws in the aftermath of the novichok nerve agent attack in Salisbury. One plan under consideration is to adopt a form of registration for foreign agents, updating the Official Secrets Act and treason laws. This is to make it tougher for adversaries operating in the UK. This bill is a legacy from the Theresa May era as it was constantly beset by delays. It makes it easier for the courts to prosecute for domestic abuse by creating a statutory definition that means harm caused is not just physical or sexual, but can also involve emotional, and economic abuse, and controlling behaviour. "
"
Share this...FacebookTwitterThe sun in January 2017, and: a “pause” or not?
By Frank Bosse and Fritz Vahrenholt
Translated/condensed by P Gosselin)
In the previous month our sun was very quiet. A month earlier there had been little activity at first, but then picked up some later in the month. On average the sunspot number SSN was 25.8, which was 47% of what is normal 97 months into the cycle – calculated from the previous 23 solar cycles. 
Figure 1: The monthly activity of solar cycle 24 since December 2008 (red) compared to the mean solar cycles 1-23 (blue) and the very similar SC 5 (black).
A comparison to solar cycle 5 (the second weakest solar cycle so far) shows that the current cycle has been much weaker over the past 23 months. Indeed during this particular period no solar cycle was ever as weak as solar cycle 24 now is. An overall comparison of the activity of all solar cycles, 98 months in, is as follows:

Figure 2: A comparison of all observed solar cycles. SC 24 is safely in 3rd place for low activity. Cycle No. 19 (1954…1964) had 2.5 times more sun pots than the current cycle thus far.
In our last solar report we wagered a look into the future by looking at the gradually growing solar polar fields. The fundamental data has been corrected slightly downwards (a normal quality management step) and we wish to present here once again the updated comparison of all the cycles for this observed magnitude:

Figure 3: The polar fields of solar cycles 21…24 (clockwise) each up to 1400 days after the zero-point (black) for the sun’s southern pole (red) and of the northern pole (blue).
We’ve already seen the maximum on average. You’ll find the best website here when it comes to solar data. The behavior of SC 24 is so far very remarkable!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Pause or no pause?
A controversy erupted in early February: A retired former NOAA employee – John Bates – wrote in a lengthy post at Judith Curry’s blog about how NOAA head Tom Karl used unclean data in a study from the year 2015. The study supported the position that a “pause”, i.e. a considerably slower rise in global temperature after 1997, hadn’t occured. A rather tumultuous quarrel then ensued, as the claims made by John Bates have since been refuted. Fuel was added to the topic, when an article appearing in the “Mail on Sunday”, which contained some inaccuracies.
Apparently whistle blower John Bates had found some NOAA data quality management deficiencies. First it was determined that a computer program that had been used to compute the temperature was lost and thus the calculations were no longer reproducible. The study had a huge impact on the political discussion during the run-up to the Paris Climate Treaty. Bates later stated that data manipulation could not be shown.
In the course of this heated discussion, a new “official” sea surface temperature series dubbed ERSSTv5 was released. Here a small part of the warming of the previous series was recalculated beginning in the year 2000. A great amount of controversy has swirled about the new series, so it is important to keep the focus on where it really counts.
All decisions made today are based on models from the IPCC AR5. Let’s compare what the models projected to the the ERSSTv4 series – the current warming of the global ocean surface:

Figure 4: Comparison of ERSSTv4 series (blue) to the model mean 1979…2016 (red).
The global trend of the temperatures for the ocean surface is over 70% too high!
ERSSTv4 shows 0.109°C per decade warming while the model is far more generous, showing 0.154°C/decade over the time period 1979-2016.
Here it has to be taken into account that in the real world an El-Nino occurred at the end of the measured period, which skews the trend upwards. In two or three years the deviation between the real world and the model world will grow. The models are calculating excessive warming and overstating the effect by CO2. That is the core of the truth that you can take away from this.
 
Share this...FacebookTwitter "
"We asked Guardian readers around the world to tell us what you think of our climate coverage, and what you’d like to see more of. We received several hundred responses from readers in India, the UK, Japan, the US (everywhere from Maryland to Alaska), Mexico, Istanbul, Spain, Canada, Malaysia, Switzerland, New Zealand and Wales - to mention just a few. Here is a small sample of what we heard. The rising human population needs to be addressed. There are too many of us; we are living longer, therefore something needs to be done to encourage smaller families, choosing to adopt, or to remain child-free. The exploding population is an ecological emergency.Tanya, 41, Yorkshire, UK  I was onboard already. But the Polluters series helped focus my attention on what needs addressing first - systemic changes are much more critical right now, but governments and corporations are trying to shift the focus and blame onto consumers. It’s vital we hold them to account.Pritam, 49, Jaipur, IndiaI think the Guardian is doing a fantastic job on reporting the climate emergency - you’re really leading the field!Pamela, 54, Southern AustriaI’d like to read about calls for government investment in research and development of technologies that can help ameliorate the climate crisis and its effects, such as gene editing of plants to resist drought and solar radiation management.Brittany, 29, Georgia, USThe pollution and lack of resilience of the value chain of electronics, including the choice of most nations to consume more electronics in the year to come.Elie, 33, Strasbourg, FranceI’d like to see more coverage of mass climate migration happening now and in the future, with a focus on solutions to the problem.Karolina, 23, Copenhagen, DenmarkI hope the Guardian will continue to cover deforestation – especially the Amazon. This needs to be covered enough to continue pressure on Bolsonaro. As you’ve reported, we cannot combat global warming with the ‘carbon bomb’ that is continued Amazon deforestation. Leah, 36, CanadaOverpopulation is such a key issue. It should be curtailed by women’s emancipation, education and free family planning advice and contraception.Nile, 58, London, UKI’d like to see more in depth coverage of global harvest fluctuations, and food security in different regions.Matthew, 33, Wales Local councils are still making climate unfriendly development decisions such as ripping up much loved parks to expand airports, for example, or investing in massive roads and car-dependent estates at a time when we should be banking on there being fewer planes and cars. If each branch of local government really cared about their green environment, they’d respect and value established wild spaces. What would it take to properly protect our green estate, so local government acts as guardians rather than vandals?Bekki, 42, Luton, UK The elephant in the room is how we can make sweeping changes without provoking economic collapse. I live in Japan where the media is politically controlled and climate change is only rarely mentioned. Even when the subject of single-use plastic finally made the news this summer, the idea of buying less was not highlighted. How can we have an economic system based on growth whilst also stopping or slowing down climate change?Helen, 49, Japan The climate crisis needs dealing with right now. And declaring a climate emergency means that the government ought to be making every decision, including Brexit decisions, through the lens of how this affects the climate. I hope they will be held to account. Mika, 40, Switzerland Education is key. We need coverage that helps prepare young people for an uncertain future - more focus on employment opportunities for the future outside of those generated by the fossil fuel-oriented market place.Mel, 80, Costa Rica Making the link to impacts on human health, both globally and locally, may engage more people. Furthermore, drawing more of a focus on climate solutions and the co-benefits in terms of tackling other public health concerns such as lung disease, obesity, cancer rates, mental health disorders, social isolation etc helps people to see how combating climate change need not be all about negative impacts on their quality of life.Dr Hayley Pinto, 51, Norfolk, UK I would like to know more about the issue of land ownership (and land grab) . How the lands are used and who owns them is directly linked to the carbon emission of the land and social equity.A reader, Kuala Lumpur, Malaysia The species becoming extinct or facing future extinction. Australia has lost 11,000 bats that were adapted to high temperature which could not survive the heat.Christopher, 32, Aberdeen, Scotland I think the Guardian does well in this area. I’d like to read more details of the way the pesticides work … and their very widespread presence in our food chain.Sue, 79, Munich, Germany I think the role of human overpopulation in the current climate (and ecological) crisis is often neglected. The means to achieve a reduction in population are simple and humane: empower women and girls; improve access to and acceptance of contraception (inc vasectomy); alleviate poverty; improve education worldwide and help people to understand the obvious link between population and carbon emissions.Helen, 56, Melbourne, Australia I think it would be so useful to highlight that the average person can cast their vote for the society they want to live in by opting to only buy from companies that are making an effort, and celebrating companies that make it easy to shop low waste (unpackaged vegetables, bulk bins of grains etc.). I think a lot of people feel overwhelmed by the information being broadcast to them, especially when they have busy lives, so we need to make sustainable lifestyles feel accessible.Rose, 23, Sheffield, UK Voters should have an opportunity to assess the carbon footprint of those who are standing for election in the same manner as their financial involvements. It would give voters, particularly the younger ones, an incentive both to vote and to prioritise the issues that concern them. It would identify the individuals and also, when aggregated, the parties, whose behaviour reflects their stated environmental aspirations.A reader, 77, Dublin, Ireland I’d like to hear more on climate refugees - the people who are displaced because of the climate crises.Yusuf, 22, Istanbul, Turkey I’d love to hear the true story of carbon offsets. There is a whole network of brokers and accreditation actors and others in this market. What makes a good offset and which offsets are ultimately not helpful?A reader, 35, Nairobi, Kenya I think reporting on how the climate emergency affects all aspects of Australian society, and capturing the views and perspectives from those parts of society that do not see this as an issue, or at least not one that is more important than their job security or other concerns, would be really important.A reader, 35, Sydney, Australia An issue I feel passionately about is the connection between pollution and health. I’m part of a recently-formed group of Irish doctors aiming to bring attention to the climate crisis from our patient’s perspectives. We believe that environmental health is human health. We are the air we breathe, the water we drink, and the food we eat. We feel that our patients’ underlying pathologies can be worsened by pollution in our cities.Dr Vincent Wall, 32, Ireland, Irish Doctors for the Environment (www.ide.ie) I’m interested in the disproportionately damaging effects of short trips by cars, especially SUVs. As someone who does not own a car, it is incomprehensible why so many people automatically take their car for short trips that could easily be done on foot, by bicycle or public transport.Mark, 58, Hamburg, Germany I’m interested in knowing more about how the arts can raise awareness and help humans reduce their ecological footprints.Indran Amirthanayagam, 58, Maryland, US I want to keep being informed about: how to improve one’s consumption, the best ways to recycle, what to do locally, in your community, interviews with local people who act to make their city greener.Manon, 27, London, UK "
"We might have a new energy superpower to talk about. Guyana, the former British colony on the northern edge of South America, apparently controls vast amounts of offshore oil and gas. That, at least, is Exxon-Mobil’s view. In May 2015 the American major announced it had discovered huge potential reserves at its Liza-1 well in the Stabroek Block – some 120 nautical miles off the Guyanese coastline. Exxon-Mobil claims 700m barrels of oil might be recoverable and, even despite depressed oil prices, analysts have spoken about the Stabroek Block being worth US$40 billion. With fewer than a million Guyanese citizens, such a windfall could go a long way. If shared evenly it would work out to around US$60,000 each – in a country where per capita income is currently just US$4,170. But sudden oil wealth is rarely distributed smoothly or equitably, and ordinary Guyanese worry their nation will become the latest victim of the resource curse. Guyana also has a long-running border dispute with its larger, wealthier neighbour Venezuela. Not long after the oil discovery, Venezuelan president Nicholas Maduro issued a decree reiterating a historic claim over western Guyana and large parts of Guyana’s Atlantic waters – including much of the Stabroek Block. Nonetheless, Guyana’s government is naturally upbeat. Raphael Trotman, minister of governance, described the find as “transformational” – a common view when such news is released, nourishing a bonanza political-economic model of hydrocarbon exploitation and development. You would have heard similar terms being bandied about back when the Falklands were being described as a “South Atlantic Kuwait” or Equatorial Guinea was set for an “economic explosion”. Guyana’s president has reassured Exxon Mobil that its operations wont be disrupted by talk of disputes and controversies involving Venezuela.  The international boundary between Guyana and Venezuela remains a source of tension for the latter. An 1899 arbitration panel in Paris settled the current borders but, as any visitor to Venezuela will attest, you can easily find maps and even tea towels that depict the country’s borders extending into a significant portion of Guyana to the east. The spat has even made it onto the internet – Guyana recently protested Google Maps’ choice of Spanish (Venezuelan) place names in the disputed Esequiba region. Since 1899, international law including the Law of the Sea Convention has granted additional sovereign rights to coastal states. And international maritime boundaries can take on added significance when potentially thousands of square miles of sea and seabed are at stake. The Guyanese government is eager to ensure oil and gas exploration continues without controversy and has initiated a new round of diplomacy designed to garner support for the international status quo. After a meeting at the UN in New York on September 29 the leaders of the two countries agreed to resume diplomatic relations, though we can expect a great deal more presidential speech making and backroom diplomacy at the UN and regional summits. The two nations have plenty of history. The Guyanese government will be mindful of an incident in 2013 when the Venezuelan navy detained a survey ship operating in what it considered to be disputed waters. The ship was owned by Malaysia and operated on behalf of an American company.  At home, Maduro is under pressure to be seen as defending the “fatherland”. He also faces elections in December and Venezuelan voters may not be in a forgiving mood given food shortages and chronic inflation. The end result is what we might describe as “hot nationalism”, a situation where political leaders talk grimly about the dangers facing their countries, or conversely talk about the historic opportunities to make a notable difference to their countries. Either way, “oil talk” can and does inflame the passions, especially when at least one party thinks the discovery was made in disputed waters."
"
Share this...FacebookTwitterGermany appears poised to make a fundamental course correction in its climate and energy policy.
Germany has long been a steadfast and influential proponent of “climate protection”. Also the country’s Potsdam Institute for Climate Impact Research (PIK), directed by climate doomsday professor Hans-Joachim Schellnhuber, has been one of the most influential European players in underpinning the science that has shaped Europe’s stringent  climate policy. The PIK has worked relentlessly in close partnership with the UN and North American climate institutes.
That construct, however, may soon be dealt a serious blow as one of Angela Merkel’s closest ministers, Peter Altmaier, told a group of industry leaders that Germany’s days of “going-it-alone on climate protection” are about to end — this according to the highly reputable online Die Welt here.
As Germany’s power industry reels from massive multi-billion euro record losses and power consumers get left in the dark by the hundreds of thousands as power supply gets cut off, the German government may finally be realizing that its climate and energy policy has only wrought tremendous pain and no benefit.
Daniel Wetzel of Die Welt writes:
In climate protection Germany has always played the roles of a front-runner and a model pupil. This now appears to be over.”
Last Friday at the ritzy Hotel Adlon in Berlin, Chancellery Minister Peter Altmaier spoke before a group of business leaders and CEOs, and reportedly reaped thunderous applause when he signaled “the expensive climate-political go-it-alone” by Germany “may soon be over“.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to Die Welt, Altmaier said: “I am totally convinced that the path of national targets is false” and what’s needed in the near future are “European and international targets“.
So far Germany’s approach has not worked, and has been sharply criticized by industry and environmental economists, who say it “has not saved one extra gram of CO2 under the roof of the European Emissions Trading.”
Whether Altmaier’s views get implemented by the Merkel government remains to be seen. However, the movement to relax the country’s draconian climate protection policies appear to be gaining steam. Die Welt writes that Altmaier’s position are also in agreement with the recently minted “energylab 2030” energy concept by leaders of Merkel’s CDU party:
Special national targets for climate protection are counter-productive and thus fundamentally should be dropped.”
Die Welt writes that the German government finally may have realized that its grandstanding target of reducing CO2 emissions twice as fast as the rest of Europe had been “over-ambitious”.
What could have led to these signals of fundamental course change? Die Welt’s Wetzel ends the article by writing:
Among experts it is sure that the federal government’s bold promise made in 2010 of cutting back CO2 emissions 40% by the end of the decade will be significantly missed.”
 
Share this...FacebookTwitter "
"The animal kingdom contains a huge diversity of colour patterns, from the near-perfect camouflage of the cuttlefish to the extravagant displays of birds of paradise. Evolution has shaped this diversity, but exactly which selective pressures are at work is still controversial.  While some theories propose that such patterns evolved specifically for camouflage, other theories link them to things like attracting mates, regulating body temperature and giving off warning signals.  One common pattern of animal colouration that has been the subject of this kind of debate is called countershading. Found across air, land and water on many different animals – from tigers to tuna – it features a darker skin or fur on the surface of the animal’s body that faces the sun, and a lighter colour on their underside.  Countershading has typically been considered beneficial for protection against ultraviolet. This is because the dark colour of the skin or fur is due to melanin, a pigment that strongly dissipates potentially damaging ultraviolet radiation. A dark body colour also often helps animals to gain more heat from sunlight.  Yet it has also long been suggested that this pattern of colouration evolved to enhance visual camouflage. This goes back to one of the oldest theories in the evolution of camouflage, originally put forward in the late 19th and early 20th centuries by the British evolutionary biologist Sir Edward Bagnall Poulton and the American artist/naturalist Abbott Thayer. They suggested that shading might counteract the effects of light and make animals harder to see.  But how could the countershading pattern contribute to visual camouflage? That was the question that we sought to answer in two recently published papers. To understand our work, start by considering how light interacts with objects and viewers.  In nature, more light comes from above than from below. It doesn’t matter whether we are talking about open country, below a dense canopy of trees or underwater. Three-dimensional objects with a uniform colour are brighter on the top and darker on the parts that are exposed to less light.   This interaction between shape and light provides a source of 3D information for our visual systems known as shape from shading. It is a powerful visual cue, exploited for centuries in art. Leonardo Da Vinci’s drawings of 3D figures show us just how sensitive we are to this kind of information, for example. In the picture on the right, Lady of Dishevelled Hair, notice how the forehead and top of the nose are bright, while the areas under the eyes, lips and chin are dark. It is the shading, using a technique called sfumato, that allows us to perceive the graceful shape of the woman’s head on the two-dimensional plane of the drawing.  Shading is also an important cue for animals. Predators can potentially use shape from shading to reveal the 3D shape of their prey, even if this victim is patterned or coloured to match their background.  Countershading is a possible defence. If an animal is darker on top and lighter below, this can offset shading from light and make it harder for predators to detect them. To give you an example, below are two photographs of an Actias luna caterpillar feeding on birch leaves. The first shows it back-uppermost, a position it does not favour, while the second shows it hanging below the branch, its most common pose.  The caterpillar is harder to spot in the second image because the effects of shading are counteracted by the countershading. It happens to be the very example that Abbott Thayer used to illustrate his theory more than 100 years ago. In reverse of the usual countershading rule, the caterpillar’s back is paler than its belly. This is because in its most common pose, hanging below the branch, its belly is uppermost.  A key question is what countershading pattern is the best for evading detection. The answer is complex, because it depends on the three-way interaction between object shape, the quality of light and the location of the viewer. Our interdisciplinary group of researchers from the universities of St Andrews, Abertay and Bristol developed a computational model to predict optimal shading in a given situation.  We simulated a three-dimensional world in which we could place an animal of our choice, and choose the location of the viewer. To take account of different habitats and lifestyles, we used realistic sun and sky lighting conditions which could be set up to emulate sunny or cloudy weather at any latitude, time of day or year.  We duly demonstrated that the best pattern to choose depends on weather, time of day and where in the world the animal is located. For example in a sunny location, an animal should have a sharp transition between their light and dark regions with a dark strip down the spine. The axis deer or chital (pictured), found across the Indian subcontinent, carries a good example of this kind of dark strip, which our work suggests might optimise camouflage in open grassland.  This is different to animals that live in woodland or under cloud and therefore experience less direct sunlight. They should have a more gradual transition between the light belly and dark back. A study from 2012 that looked at the coat patterns of ruminant animals supported this prediction. Our model should now allow experimenters to test just how specific camouflage needs to be to prove effective in different environments.  Finally a word on the other theories about the evolutionary reasons for countershading that we mentioned near the beginning, in relation to a related problem: why some animals turn to orient their bodies in a particular direction. Much has been made of the benefits of this for both regulating body temperature and protecting against ultraviolet light. Our model showed that all three theories make predictions that lead to similar animal orientations. This suggests that camouflage could be a crucial evolutionary explanation for how animals orient themselves as well."
"
Share this...FacebookTwitterAfter a record of more than 10 years without a major hurricane strike on the US, the NOAA must be getting hurricane desparate. The US climatology agency perhaps is demonstrating once more that records are not made by natural events occurring but rather by counting them differently.
At yesterday’s WeatherBell Daily Update, veteran meteorologist Joe Bastardi accused the NOAA of going out in the “middle of nowhere” to name anything that moves. Joe also discusses this further at today’s Daily Update.
It used to be that the NOAA stayed within certain Atlantic regions to count hurricanes – regions that positioned the hurricane for a possible US strike, or having an impact along the coast,  and with water surface temperatures 26°C and higher. But now Joe notes that they are looking at “eyesores near the Azores”, which have no chance of ever impacting the US coast and where water temperatures are just over 20°C.

Image cropped from Weatherbell Daily Update, April 18, 2017.
The veteran meteorologist suspects the NOAA may have abandoned the conventional hurricane counting standards, perhaps in order to sex up the statistics. Joe calls it “climate paranoia where every little thing that goes on turns into something bigger than it actually is.”
One could speculate: perhaps the NOAA wants to produce an awesome hurricane statistic this year in the hopes putting political climate science pressure on Washington. Politicized science unfortunately is something that has been going on quite some time at the US climate and weather agencies, critics say.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Bastardi calls the naming of a disturbance way out “in the middle of nowhere” over water that is 5°C under traditional hurricane-temperature waters “ridiculous”.
If the agency is just going to throw convention out the window, it might as well just start naming every North Atlantic storm that occurs every fall and winter off Europe. Why wait until April and stop at the Azores? Might as well include the North Sea and its heavy storms, too.
While the NOAA scurries to name any wind anomaly it can find, the situation in Europe continues to be bitter cold and nothing of sort you’d expect from global warming.
Some say that yesterday was the coldest April 18 on record, as snow and freezing temperatures gripped wide swaths of Central and Eastern Europe and Scandinavia.
The 5-10 day forecast shows no let-up in the frigid conditions.

Joe adds that the Alps will continue to be pounded my heavy snowfalls, thus defying predictions of the end of skiing at European ski resorts due to global warming. This year they’ll be skiing well into May.
 
Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitterComprehensive Analysis Crushes
100% Renewable Energy Fantasy


While fully accepting the perspective that fossil fuel energy production and consumption must be dramatically reduced to save the planet from dangerous CO2-induced global warming, four Australian researchers have compiled a comprehensive rebuke of the premise that renewable energies (wind, solar, biomass, etc.) can feasibly supplant fossil fuels to become the dominant power source for the world.
The authors’ analysis zeroes in on the devastating conclusion that each and every one of the 24 previous attempts to substantiate the claim that a 100% renewable energy grid is achievable have failed to satisfy even the most basic feasibility criteria.
Further, a commitment to all-renewable energy sources means there will need to be a massive and unprecedented increase in grid extensions (for new power distribution systems), as well as realized plans for extreme and unrealistic land-use expansion (for biomass production especially) that would threaten ecosystem preservation, biodiversity, and land conservation efforts.
From a humanitarian standpoint, it is conceded that attempts to “decarbonize” energy sources seriously hampers efforts to provide electricity generation to the world’s most impoverished people. In fact, Heard and colleagues conclude that a commitment to renewable-only energy supplies “appears diametrically opposed to [the] eradication of poverty … and social justice for indigenous people.”
Again, these damning conclusions have been advanced by researchers avidly committed to reducing or eliminating fossil fuel energy production for the sake of mitigating global warming.  And yet even staunch renewable energy advocates cannot find a way to substantiate the claim that 100% renewable power generation is feasible.
A very brief summation of the highlights from the analysis — as well as the link to the full paper — is provided below.

Heard et al., 2017
Burden Of Proof: A Comprehensive Review Of The
Feasibility Of 100% Renewable-Electricity Systems

Of 24 Analyses Of The Prospects Of Achieving 100% Renewable Energy, Zero Met Basic Feasibility Criteria

“While many modelled scenarios have been published claiming to show that a 100% renewable electricity system is achievable, there is no empirical or historical evidence that demonstrates that such systems are in fact feasible. Of the studies published to date, 24 have forecast regional, national or global energy requirements at sufficient detail to be considered potentially credible. We critically review these studies using four novel feasibility criteria for reliable electricity systems needed to meet electricity demand this century. [N]one of the 24 studies provides convincing evidence that these basic feasibility criteria can be met. Of a maximum possible unweighted feasibility score of seven, the highest score for any one study was four. … On the basis of this review, efforts to date seem to have substantially underestimated the challenge and delayed the identification and implementation of effective and comprehensive decarbonization pathways.”

Reducing Fossil Fuel Consumption Will ‘Raise Problems’ For ‘Poverty Alleviation’

“Our review of the 100%-renewable-scenario literature raises substantial concerns. The widespread assumptions of deep cuts in primary energy consumption defy historical experience, are generally inconsistent with realistic projections, and would likely raise problems for developing countries in meeting goals of poverty alleviation.”
“[E]conomic growth and poverty reduction in developing countries is crucially dependent on energy availability. A reduction in primary energy is an unlikely pathway to achieve these humanitarian goals. To move beyond subsistence economies, developing nations must accumulate the necessary infrastructure materially concentrated around cement and steel. That energy-intensive process likely brings with it a minimum threshold of energy intensity for development. Across a collation of 20 separately modelled scenarios of primary energy for both India and China, Blanford et al. found a range of energy-growth pathways from approximately +50 to +200% from 2005 to 2030. None of those scenarios analyzed for these two countries — with a combined population of almost 2.5 billion people — suggested static or reduced primary energy consumption.”

100% Renewable Energy Demands Unrealistic Grid Extensions, Land-Use Commitments

“The remaining feasibility gaps lie in the largely ignored, yet essential requirements for expanded transmission and enhanced distribution systems, both to transport electricity from more sources over greater distances, and to maintain stable system operations. Fürsch et al. suggested that a cost-optimized transmission network to meet a target of 80% renewables in Europe by 2050 would demand an additional 228,000 km of transmission grid extensions, a +76% addition compared to the base network. … Rodríguez et al. [83] concluded that to obtain 98% of the potential benefit of grid integration for renewables would require long-distance interconnector capacities that are 5.7 times larger than current capacities. Becker et al. found that an optimal four-fold increase in today’s transmission capacity would need to be installed in the thirty years from 2020 to 2050. An expansion of that scale is no mere detail to be ignored.”
“Perhaps our most concerning finding relates to the dependence of 100% renewable scenarios on biomass. The British scenario is a typical example; even with the assumption of a 54% reduction in primary energy consumption, biomass requires 4.1 million ha [hectares] of land to be committed to the growing of grasses, short-rotation forestry and coppice crops (17% of UK land area). … The WWF scenario demanded up to 250 million ha [hectares] for biomass production for energy, along with another 4.5 billion m3 of biomass from existing production forests to meet a scenario of an absolute reduction in primary energy from today.”
“[I]n applying so many assumptions to deliver changes far beyond historical precedents, the failure in any or several of these assumptions regarding energy efficiency, electrification or flexible load would nullify the proposed supply system. As such, these systems present a fragile pathway, being conceived to power scenarios that do not exist and likely never will.”

Wind-Watch.Org Image “Steel Winds“

Summarizing Statements:  Proposition Of 100% Renewable Energy Must Be…’Discarded’

1.      “To date, efforts to assess the viability of 100% renewable systems, taking into account aspects such as financial cost, social acceptance, pace of roll-out, land use, and materials consumption, have substantially underestimated the challenge of excising fossil fuels from our energy supplies. This desire to push the 100%-renewable ideal without critical evaluation has ironically delayed the identification and implementation of effective and comprehensive decarbonization pathways. We argue that the early exclusion of other forms of technology from plans to decarbonize the global electricity supply is unsupportable, and arguably reckless.”
2.      “The realization of 100% renewable electricity (and energy more broadly) appears diametrically opposed to other critical sustainability issues such as eradication of poverty, land conservation and reduced ecological footprints, reduction in air pollution, preservation of biodiversity, and social justice for indigenous people.”
3.     “The evidence from these studies for the proposition of 100% renewable electricity must therefore be heavily discounted, modified or discarded.”
 
Share this...FacebookTwitter "
"Temperatures in the Arabian Peninsula, Iraq and Iran could soar to uninhabitable levels during the course of this century, according to a new study.  Already, places such as Al Ain and Kuwait can experience temperatures of up to 52℃. But the study predicts that the effects of global warming and the increase in greenhouse gases could push the average temperature up to the mid 50℃s or lower 60℃s.  Currently, many residents of the gulf can find refuge in air-conditioned homes, shopping centres and cars. But as temperatures increase, so does the need for cheaper, more sustainable, less energy-intensive ways of staying cool. Fortunately, the region’s past offers a rich source of architectural inspiration.  Historically, the inhabitants of the Gulf were either farmers living near oases in agricultural villages, Bedouins living in tents in the desert, or urban dwellers living in cities. Given the global trend toward urbanisation, it makes sense to take a closer look at how the latter group coped with the heat.  Traditional buildings in the gulf’s cities and villages are designed to maximise shading, reduce thermal gain of the sun radiation, regulate building temperature and enhance air circulation. These effects are achieved through a clever combination of building materials, placement and design. Natural materials such as limestone and mud – in some cases mixed with local desert plants – provide a construction material with the capacity to regulate building temperatures. The material itself is capable of absorbing moisture in humid conditions, which can later evaporate during hot and sunny days to provide a slight cooling effect. And the sandy texture and colour of the buildings reduces both the absorption and emission of radiating heat.  Traditional buildings are placed adjacent to one another, with narrow roads and alleyways in between. This means that the ratio of the area exposed to the sun relative to the building’s total volume is minimised, which in turn limits heat increases during the day time.  Many traditional structures feature an internal courtyard, often containing trees and a water well. The courtyard is typically surrounded by rooms or walls on all sides, maximising the area in shadow throughout the day and creating a space for socialising in the evenings. When the sun bears down at midday, the courtyard works as a chimney for the hot air to rise and be replaced by cooler air from the surroundings rooms – this promotes air circulation and creates a cooling effect. Glass is not a common material in traditional buildings. A typical room has two external windows: one very small window, located high up the wall, which is kept open to allow air to circulate and let in natural light. The second is larger, and closed by wooden shutters, with grooves to allow the flow of air inside the room while maintaining privacy. Rooms also have windows towards the internal courtyard for improved cooling. Finally, a mushrabiya – a projecting window with carved wooden latticework, typically located on the upper stories of a building – allowed for better air circulation and a view.  Some buildings also have a wind tower, which creates natural ventilation by circulating cool air. The narrow streets allowed them to be covered in most cases by light material from date palm trees to avoid direct sun light. This allowed for better air circulation between streets and courtyards of buildings, via the rooms. All of these features helped to keep traditional buildings cool. But the question remains, how can we apply them in today’s cities?  Modern buildings in the Gulf are built predominantly from reflective glass, concrete and asphalt, which means that temperatures really soar during day time, due to high reflection or high absorption and emission of radiated heat.  But with research and improvements in building and pavement materials, designs, urban planning, insulation and the use of renewable energy, cities in the Gulf could maintain a comfortable lifestyle, with a lower level of carbon emission and fossil fuel use.  For example, Masdar city in the United Arab Emirates has attempted to combine some of the lessons learned from the past with modern technologies by increasing shaded areas, creating narrow streets and constructing a wind tower.  The use of insulation would also reduce the need for air conditioning and lower electricity consumption. Meanwhile, natural or new materials which absorb moisture and increase thermal capacity (meaning the material can maintain lower temperatures in higher heats) could regulate heat gain and facilitate the natural cooling process.  I have developed a new patented technology to regulate building temperatures in extremely hot conditions using a heat sink in the ground. The heat sink will allow the ground to exchange heat with the envelope of the building, thereby reducing its thermal gain on hot days.  In recent years, the Gulf countries have sat up and paid attention to renewable energy and sustainability measures. Research and development is expected to progress further in this area if people are to live comfortably at the expected high levels of temperature, while reducing their dependency on fossil fuel consumption and carbon emissions. Read more: Adrian Pitts, professor of sustainable architecture at the University of Huddersfield, looks at the impact on cities."
"The Persian Gulf is already one of the hottest parts of the world, but by the end of the century increasing heat combined with intense humidity will make the region too hot for habitation, according to research published in Nature Climate Change. Heating and air conditioning currently permit humans to live everywhere from Siberia to the Sahara. However the extreme heatwaves predicted for the Gulf, where temperatures will regularly hit 50℃ or even 60℃, will reach the limits of the thermal adaptation that buildings can provide.  Our ancestors lived without the sophisticated thermal control systems we typically use in modern buildings; they implicitly used different “bioclimatic designs”, such as natural ventilation or south-facing windows, and these skills are still valuable in many climates today. But the latest data suggest this will not be enough.  So is there a future for habitation in the hottest regions of the world? It seems mass migration is less likely than staying put and taking on the challenge. However figuring out how to live comfortably and sustainably while it’s hot enough to fry an egg on the sidewalk may provide a fillip for environmentally sensitive design and urban development throughout the world. The climate is a problem but does offer some opportunities. The amount of sunshine available means there should be no shortage of solar electricity, though we need to develop efficient storage systems too. We could also take advantage of day-to-night ambient temperature variations using “thermal mass” techniques to even out temperature fluctuations. We will have to make significant changes to building design – highly glazed structures that soak up heat will become architectural dinosaurs. Traditional ideas from hot regions of the world will resurface: thick walls giving thermal stability (but enhanced with smarter materials such as composites with layers of insulation or perhaps embedded “phase-change” materials), used together with small windows. Building surfaces will need to be coated with smart materials that reflect heat gain – these already exist and researchers have looked at their perfomance in the hot summers of cities such as Athens.  We’ll need to optimise where and when we occupy buildings, to seek out the coolest spots and take advantage of less intense night time conditions. We may find ourselves living partly underground in order to benefit from lower and more stable temperatures to be found a few metres below the Earth’s surface.  In intense heat, finding some shade becomes essential. Buildings, streets, services and even entire transportation systems need to be entirely shaded or even fully underground. Some of these features are already showcased in the Masdar City development in Abu Dhabi, though the project (which had significant design input from Norman Foster and partners) is not yet fully operational. Expect an air conditioning boom. This will cost a lot both to build and to operate, and we’ll have to come up with systems specially designed for extreme temperatures. The thermodynamics of current designs which rely on temperature differences between heat absorption and heat rejection mean it would be very difficult to achieve sufficient and efficient heat removal as these change and narrow.  One opportunity would be to use the Earth or the sea/rivers as “heat sinks”, rather than the external air, as these will be at lower temperatures and have the ability to absorb the heat, though perhaps with as yet unknown long term effects. It is also likely that air conditioning might most effectively be used during the night-time to pre-cool the building; night-time air temperatures will allow more efficient refrigeration. Urban design and the ways in which cities are used at time of extreme heat will also need to be considered. Moving around outdoors without protection could become as unimaginable as walking unprotected from a polar research station in winter.  This obviously causes significant problems for those who must work outside: places of refuge may need to be constructed and the very act of building may need to be restricted to the “winter” (or rather slightly cooler) months. Construction products will also be obliged to change in order to cope with more extreme thermal stresses and expansion effects. The shape of cities and the massing of their major buildings will change so that groupings offer a degree of self-protection. Streets will be designed to optimise shading and, when available, cooling air ventilation. The spaces between buildings will need to be carefully designed and uses (such as what might happen underground) considered alongside services provided to citizens. Shopping malls could be submerged and used as links between areas, just as the underground streets found in northern latitude cities like Montreal are used in winter. Cities themselves may shift away from coastal to inland zones due to the problematic combination of high temperatures with high humidities near to water masses. In drier atmospheres, technologies such as evaporative cooling (in their simplest form fountains and water sprays) can be used to reduce temperature.  A technological alternative to this might be the use of moisture absorbing materials (regenerated desiccants) to dehumidify the atmosphere, but this would be a significant and complex task on the scale required. Moving whole cities can only be a long term plan but its something worth thinking about now, while there is time.  Read more: could turning to traditional techniques provide a solution? Amin Al-Habaibeh, professor of intelligent engineering systems at Nottingham Trent University, thinks so."
"A “lifeline” for the planet that “will steer the world towards a global clean energy transition”, was how European Commission president Jean-Claude Juncker hailed the Paris agreement. He also claimed it to be “a success for the European Union” itself. The EU’s demand for a legally binding document was realised. However the agreement carries less weight than a full treaty (though a Kyoto-style treaty wouldn’t be approved by the US Congress). Ahead of the summit the EU had called for global average temperatures to be kept below 2°C above pre-industrial levels and it will be satisfied with the revised 1.5°C goal. This unexpectedly ambitious target is not accompanied by clear emissions reductions targets and therefore does not reflect the three main targets in the EU’s 2030 climate and energy framework: to cut greenhouse gas emissions by at least 40% from 1990 levels; for renewable energy to compromise at least 27% of electricity generation; and an “indicative” target of at least 27% more efficient energy use. The framework contains a flexibility clause that allows the EU to reconsider the 40% target. In the absence of clear targets in the agreement it is likely that eastern European countries such as Poland that are heavily dependent on fossil fuels will seek to renegotiate this commitment downwards. The previous UK government accepted the 40% target but current government policies are incompatible with it. In typically vague language, the Paris agreement calls for global greenhouse gas emissions to peak “as soon as possible”. The EU wants this to occur by 2020 but that’s not going to happen. It also wants global emissions reductions of at least 50% by 2050 compared to 1990 levels, but that would require unprecedented levels of global cooperation. Even within Europe, member states will have to move smartly to accomplish the EU’s aim of 95% emissions reductions by 2050.  To have any chance of success, energy policy will have to be driven by Germany, Scandinavian and other greener nations, rather than the likes of the UK and Poland. If the Paris agreement truly marks the end of the fossil fuels era, as some commentators have claimed, the EU will have to send clear signals that continued investment in coal, oil and gas is counterproductive and business as usual is no longer possible. During the summit the EU formed an alliance with 79 African, Caribbean and Pacific countries that effectively endorsed its negotiating position, a grouping that later expanded to 134 countries and doubtless facilitated the agreement. The alliance pushed for a legally binding, inclusive and fair deal to be reviewed every five years, and a strong transparency and accountability mechanism to track whether each country is hitting its targets. The EU agreed to provide €475m to support adaptation in partner countries before 2020, far less than needed. The EU secured provisions that require countries to ratchet their adaptation and mitigation commitments upwards every five years and to have clear stringent transparency and accountability. However the agreement appears to be mainly enforced through simple naming and shaming – which doesn’t inspire confidence. The agreement reflected the EU’s willingness to contribute its share of a minimum of US$100 billion that developed countries have pledged to make available to developing countries every year from 2020 from public and private sources. It will have to find these funds in a period of slow growth to put its money where its mouth is, and the time has surely arrived to stop all fossil fuel subsidies and consider an EU-wide carbon tax.  Under pressure from small island states and other developing countries suffering from climate change through no fault of their own, the EU accepted the inclusion of an article on loss and damage caused by global warming. However it then conspired with the US to insist that the article does not provide a basis for liability and compensation. The EU continued its historically positive role as a major actor in climate negotiations in Paris. Its ability to act collectively facilitated agreement and contributed to France’s diplomatic success.  But the agreement is long on ambitious rhetoric and short on detail. It makes no mention of fossil fuels and is weak on corporate accountability and human rights. It is a step in the right direction but a decade too late. To place itself on the right side of history, the EU must now demonstrate that aspiration can be turned into achievement through action rather than words."
"On September 28, The Conversation published an article: “Don’t fall for the deep-sea scaremongers – wild fishing is healthy and sustainable” by Magnus Johnson, a senior lecturer in Environmental Marine Biology at the University of Hull. The article criticised a paper by marine biologists at the University of Glasgow and Marine Science Scotland on the regulation of deep-sea fishing. The lead authors of the study, David Bailey and Francis Neat, respond here. Since publishing our study on “A scientific basis for regulation deep-sea fishing by depth” we’ve been subjected to criticism online and in print from fisheries organisations and most recently on this website in an article by Magnus Johnson. Johnson makes general points about the benefits of sustainable fisheries, that we agree with, but his specific critique of our work falls well wide of the mark. Our work suggests that stopping deep-sea trawling at a depth of around 600m makes sense, because deeper than this the proportions of total and elasmobranch bycatch species (sharks and rays) in the assemblage increase significantly. At the same time indices of biodiversity are still increasing and the value of the species present falls.   Fisheries leaders and the author of the article claim that our study, being based on research survey data, is not representative of the effects of commercial fishing and, because bycatch is a “nuisance”, fishermen are able to avoid it. But what does the actual evidence say for deep-sea trawling? Our previous work showed that deep-sea fishing is unselective in its impacts on deep-sea fish. Unusually for a fishery, we were able to compare before and after deep-sea fishing in an area off Ireland. Fish numbers were cut in half in less than 20 years – and non-target species were just as likely to be depleted as targets. Any fish species whose depth range reached into the fishing grounds was affected.  As for the selectivity of recent catches, a collaborative project between the French fishing company SCAPECHE and the French government research organisation IFREMER looked at the options for being selective through changes to gear and by identifying areas of high discarding which could be avoided. They had little success in this endeavour. The modified trial gears caught as much bycatch as the normal gear and the authors dismissed as unfeasible the sort of work required to design the highly-selective gears used in shallow fisheries. There was little spatial pattern in most elasmobranch bycatch species, so no feasible avoidance strategy was possible for these species. The authors concluded that a depth-based avoidance strategy was as likely to succeed as other more complex spatial measures.  For now at least there is little evidence that deep-sea trawling is highly selective. As a result, any method that shows trends in what species were available to be hit by the trawls would provide a fair representation of the trends in impact of commercial fishing at different depths. Remember, it is the trends with depth that are the issue, not whether one net catches more than another. To disprove our study our critics would need to show that not only is commercial fishing very much more selective than surveys, but that they get relatively more selective with depth. Neither Johnson nor our other critics has provided any evidence for this. Johnson further argues that our study was flawed because we failed to analyse any effect of time over the period of the study. Actually we have already done temporal studies in both the Irish and Scottish datasets that indicate following the initial depletion of stocks, the populations have been generally stable, thus showing little sign of recovery. The criticism that we used “pseudo-commercial nets rather than data from fishing boats” – and that this invalidates our results – would be extremely weak in any case. The scientific trawls are modified commercial nets with finer mesh in the cod end (the part where the fish are ultimately collected after being herded into the net) and therefore catch a wider range of fish sizes than commercial nets. This will influence indices of biodiversity, but will not affect retention of the larger species that contribute most to the biomass indices or catches of sharks for instance.  One of the gears (Jackson Trawls of Peterhead model BT195) is identical to commercial fishing gears used by Scottish vessels targeting monkfish. The Scottish monkfish survey was specifically developed together with the fishing industry so that direct comparisons between survey vessels and fishing vessels could be made. Despite variation in gear type the trends in the indices were not significantly different. This is all set out in the paper or the many works underpinning it. It is little surprise then that our study also shows a very similar pattern of species richness with depth to those recorded from commercial trawls by on-board observers. It is also worth noting at this point that the Scottish and French fishing industries had already agreed to an 800m limit before our paper came out – so now the question is whether this was the appropriate depth to choose. Our paper suggests not, because it demonstrates that trawling at depths beyond 600m the detrimental impacts on the fish community become increasingly adverse; an 800m limit would not be precautionary and risks continued ecosystem degradation.  A common argument put by industry is that this will be the “thin end of the wedge” and that NGOs will soon be back asking for the 200m and 400m limits for which they originally campaigned. We can say now that our study would not support the ban being moved shallower than 600m and would argue strongly against any NGO that proposed this. We follow the evidence – supported by the methodical collection of research data going back decades. Now we just want the science to be used. This article was co-authored by Dr Francis Neat of Marine Sciences Scotland."
"
Share this...FacebookTwitter
75% Of Total Modern Glacier Melt Occurred Before 1950

“[T]he retreat of the glaciers after about 1925 became rapid.  It was almost entirely during the [pre-1950] twentieth century warming that the Alpine glaciers disappeared from the valley floors up into the mountains.  Similarly great retreats occurred in Scandinavia, Iceland, Greenland, in the Americas, and on high mountains near the equator.”  — H.H. Lamb  Climate, History, and the Modern World (1982), pg. 248

A new scientific paper indicates that the pronounced warming that occurred during the years stretching from the 1920s to the 1940s melted Northern Iceland glaciers much more extensively and at a far more rapid pace than has been observed in recent decades.
During the 1960s to 1980s, glacier melt rates not only decelerated relative to the 1920s to 1940s, the ice actually advanced in some cases due to decades of cooling.   It has only been since about the mid-1990s that glaciers have consistently begun melting again — but with far less alacrity than they did in the first half of the 20th century.
Fernández-Fernández and co-authors (2017) indicate that the Icelandic glaciers they studied melted by more than 1,000 meters (1,062) on average between the late 1800s and 1946.  But from 1947 to 2005, these same glaciers only retreated by an average of 272 meters more.  In other words, about 75% of the total glacier melt production since the end of the Little Ice Age (the late 19th century) occurred prior to the mid-1940s.
Below are some key points and graphs from the paper.

Fernández-Fernández et al., 2017
Summary:
“The abrupt climatic transition of the early 20th century and the 25-year warm period 1925–1950 triggered the main retreat and volume loss of these glaciers since the end of the ‘Little Ice Age’. Meanwhile, cooling during the 1960s, 1970s and 1980s altered the trend, with advances of the glacier snouts. Stötter et al. (1999) indicate that the coldest period after the LIA was from the early 1960s to the mid-1970s, when temperatures fell to levels equivalent to the warmest recorded in the 19th century. This cooling is the reason given by Caseldine (1983, 1985a, 1985b, 1988) to explain the advance of the Gljúfurárjökull between the mid-1970s and the mid-1980s  … Studies of aerial photographs and satellite images show that the glacier snouts have retreated by more than 1300 m on average since the LIA maximum (considered to be AD 1898 in Gljúfurárjökull and AD 1868 in both Western and Eastern Tungnahryggsjökull), with an altitudinal rise of more than 100 m. The retreat accelerated rapidly (15.3 m yr−1) during the first half of the 20th century.  In the second half of the 20th century, the retreat decelerated considerably, reflected in the lowest values around 1985 (5.2 m yr−1) and a trend shift in 1994, with an advance observed in Gljúfurárjökull. … The retreat rate intensified in the period 2000–2005 compared with 1994–2000, but did not reach the rates recorded before 1946.”

Gljúfurárjökull, West Tungnahryggsjökull, and East Tungnahryggsjökull Glaciers:
1. During the period 1898–1946, the snout of Gljúfurárjökull retreated 635 m, almost two-thirds of the total distance from the LIA maximum (1898–1903) to 2005, at an average rate of 13.2 m yr−1. 
2. The trend in Western Tungnahryggsjökull during the first half of the 20th century was a more rapid retreat, showing the highest average rates of the whole period (19.5 m yr−1). By 1946, this glacier had retreated almost 90% of the total recorded between the LIA maximum (1868) and 2005.
3. Just as in the glaciers described above, the retreat of the Eastern Tungnahryggsjökull from its LIA position was more intense during the first half of the 20th century, and in 1946 its snout was only 200 m from its current position. … The 2000 aerial photograph shows that an advance of at least 41 m had taken place since 1985. Nevertheless, between 2000 and 2005, the snout retreated 17 m, even more slowly than Western Tungnahryggsjökull. 



No Net Warming In North Iceland Since 1920s-1940s



Similar Or Less North Iceland (Arctic) Sea Ice During 1920s-1950s

Ran et al., 2010


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Holocene Icelandic Climate 4-5°C Warmer, Changing 2-3°C Per Century 

Andersen et al., 2004 
“Our results show that the Nordic Seas circulation system is highly sensitive to the large-scale insolation [surface solar radiation] changes as the general Holocene climate development follows closely the Northern Hemisphere insolation. … Century-scale surface current variability for the Holocene is shown to be 1 – 1.5°C for the Vøring Plateau and East Greenland shelf, and 2.5– 3°C on the North Ice-land shelf. … The first cooling [East Greenland Shelf SSTs] from 2400 to 2000 cal years BP was introduced by a 1.5°C temperature drop starting at 3000 cal years BP which culminated in an SST low around 2100 cal years BP. The second cooling occurred around 300 cal years BP and preceded a rapid warming [during the 1700s A.D.], where SSTs rose with more than 1.5°C within 70 years. The third cooling took place in the second half of the last century. Until the last three centuries, SST variability at this site has been 1°C, while SSTs varied with amplitudes of 1.5– 2°C during the last 300 years.”


Not Just Iceland: Global Glacier Melt Rates More Rapid, Pronounced 1920s-1950s

Gregory et al., 2013


Globally, glaciers melted 69% more rapidly from 1921-1960 (12.5 meters/year) than from 1961-2000 (7.4 meters/year).

Leclercq et al., 2014  A data set of worldwide glacier length fluctuations
“The data set contains the glacier length records for 471 [global] glaciers and it covers the period 1535–2011. There are glacier length records from all continents and at almost all latitudes.   For the observed glaciers, the 20th century retreat was strongest in the first half of the 20th century.”
“[T]he retreat is strongest in the period 1921–1960 rather than in the last period 1961–2000, with a median retreat rate of 12.5 m yr in 1921–1960 and 7.4 m yr in the period 1961–2000.”

A Significant Non-Correlation Between CO2 Emissions And Glacier Melt

Advocates of the position that humans exert a profound and dangerous influence on the Earth’s temperatures, glacier melt, sea level rise, extreme weather patterns . . . point to the rapid increase in human CO2 emissions (purple trend line) as the condemnable culprit.



But consider that the trend in anthropogenic CO2 emissions was essentially flat and very low (averaging just 1 gigaton of carbon [GtC] per year) from about 1900 to 1945, when most modern glacier recession occurred.  Also consider that explosive growth in human emissions occurred after 1945, when a significant deceleration in glacier melt (and even decades of advancing glaciers) occurred.  This historical evidence would not appear to support the position that anthropogenic CO2 emissions drive warming, glacier melt, and sea level rise.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGerman electrical power analyst Verivox here issued a press release announcing that electricity will be more expensive in the coming months for many German households: 75 primary utilities are increasing their electricity prices by an average of 3.4% in February alone – this according to a study by Verivox experts.
For a family of four with an annual consumption of 4000 kWh, that means extra costs of 42 euros per year. Already tens of thousands of households are living in energy poverty.
At the start of the year some 354 power utilities cranked up the prices. This means that about half of all utilities have increased their power prices during the first months of 2017.
Rising feed-in charges, grid fees and costs
One reason for the increased prices is the higher renewable energy feed-in charges, reports Verivox. At the start of the year they climbed to a record 6.88 cents per kilowatt-hour. Verivox writes that the prices for power are now at “record levels”.
Wind and solar power disappeared in January
Meanwhile the online Die Welt N24 here reports how wind and solar power practically completely disappeared over a period of weeks during the dead of winter in Germany — as a high pressure system with fog and windless days persisted over much of central Europe — and “brought Germany’s power supply at the limit“.
The German site writes that renewable energy lobbyists prefer to be silent during the long and dark winter months, adding: “In January the German green energy systems as power suppliers went almost totally AWOL weeks long“:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Chart above shows Germany’s total power consumption in January (upper curve) compared to solar (yellow) and wind (blue) energy. From January 16 to January 26 wind and solar power almost disappeared entirely. Chart source: Agora here.
Over the past years Germany has taken a number of conventional power plants offline, and now officials worry that there is no longer sufficient steady base load available, and that there thus needs to be an incentive to install new gas power plants. Currently no power companies are investing in such new plants, and are in fact taking more and more offline due to a lack of profitability. This is increasingly putting the grid at risk. The consequences? Die Welt N24 reports:
The lack of controllable power plants put the grid operators during the January doldrums already under heavy stress.”
According to Stefan Kapferer, Head Director of the BDEW German Association for Energy and Water Management: “The German government itself sees that that the current market system is not adequate to guarantee supply security. Otherwise it would not be keeping different power plant reserves on the market and adding new ones.“
In summary, Germany is still taking more conventional power plants offline, but ordering them to remain on standby (at a loss) as reserves for cases like those we saw last month. Policymakers are playing Russian Roulette with Germany’s power grid.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterModern Solar Grand Maximum Ends
‘Little Ice Age’ Cooling On The Way


During the 20th and early 21st centuries, Earth’s inhabitants have enjoyed an epoch of very high solar activity that is rare or unique in the context of the last several thousand years.  The higher solar activity and warmer temperatures have allowed the planet to briefly emerge from the depths of the successive solar minima periods and “Little Ice Age” cooling that lasted from the 1300s to the early 1900s.  Unfortunately, solar scientists have increasingly been forecasting a return to a solar minimum period in the coming decades, as well as the concomitant cooler temperatures.
In several newly published (2017) papers, scientists have suggested that a substantial deterioration into solar minimum conditions and global cooling may be imminent (see, for example, here and here and here).  What follows is a collection of dozens of other papers that have also projected a solar minimum-induced “Little Ice Age” climate for the foreseeable future.
The analysis concludes with references to recently published papers that indicate the North Atlantic region has already begun cooling rapidly within the last decade.  Scientists have long suggested that what happens in the North Atlantic may have global-scale implications, and thus the observed North Atlantic cooling trend may be a harbinger of the climate that is to come.

The Modern Grand Maximum Of Solar Activity A ‘Rare’ Or ‘Unique’ Event

Usoskin et al., 2014     “[T]he modern Grand maximum (which occurred during solar cycles 19–23, i.e., 1950–2009) was a rare or even unique event, in both magnitude and duration, in the past three millennia. Except for these extreme cases, our reconstruction otherwise reveals that solar activity is well confined within a relatively narrow range.”


Lockwood et al., 2009     “[T]he Sun has been unusually active over recent decades (Solanki et al. 2004; Vonmoos et al. 2006; Muscheler et al. 2007; Steinhilber et al. 2008). Solanki et al. (2004) used the 14C isotope abundance found in tree trunks and concluded that the Sun has been more active recently than at any time in the previous 8000 years and that it was as active as in recent decades for only 10% of the past 11000 years.”

Chen et al., 2015     “We explored the sources and characteristics of each pigment, reconstructed an 800-year record of ultraviolet radiation (UVR) and total incoming light intensity, and identified the possible factors that may have influenced historical UVR changes in this region. The results indicated at least four UVR [ultraviolet radiation] peaks during the past 800 years, corresponding to c. AD 1950–2000, 1720–1790, 1560–1630 and 1350–1480, with the intensity from the most recent [1950-2000] sediments being the highest.”



The Modern Grand Maximum Of Solar Activity Has Recently Drawn To A Close

Wang et al., 2010      “It is seen that a very active period that began in 1920, the so-called ‘current grand solar maximum’, will probably end during 2011-2027, since a variety of indices related to solar activity have significantly shifted since 1987. … [T]he current grand solar maximum has already lasted for eight 11-year solar cycles and might end in the coming one/two 11-year cycles; a grand solar minimum might prevail in the next 100–200 years.”

Zharkova et al., 2015     “The longest direct ervation of solar activity is the 400-year sunspot-number series, which depicts a dramatic contrast between the almost spotless Maunder and Dalton minima, and the period of very high activity in the most recent 5 cycles [1950s – 2000s], prior to cycle 24. … The records show that solar activity in the current cycle 24 is much lower than in the previous three cycles 21–23 revealing more than a two-year minimum period between cycles 23 and 24. This reduced activity in cycle 24 was very surprising because the previous five cycles were extremely active and sunspot productive forming the Modern Maximum.”
“We predict correctly many features from the past, such as: 1) an increase in solar activity during the Medieval Warm period; 2) a clear decrease in the activity during the Little Ice Age, the Maunder Minimum and the Dalton Minimum; 3) an increase in solar activity during a modern maximum in 20th century. .. We note, in particular, a decreasing activity for solar cycles 25 and 26 coinciding with the end of the previous 350–400-year grand cycle and then increase of the solar activity again from cycle 27 onwards as the start of a new grand cycle with an unusually weak cycle 30. Hence, cycles 25–27 marks a clear end of the modern grand period that can have significant implications for many aspects of solar activity in human lives including the current debate on climate change.”

press release     A new model of the Sun’s solar cycle is producing unprecedentedly accurate predictions of irregularities within the Sun’s 11-year heartbeat. The model draws on dynamo effects in two layers of the Sun, one close to the surface and one deep within its convection zone. Predictions from the model suggest that solar activity will fall by 60 per cent during the 2030s to conditions last seen during the ‘mini ice age’ that began in 1645. … Results will be presented today by Prof Valentina Zharkova at the National Astronomy Meeting in Llandudno. … Zharkova and her colleagues derived their model using a technique called ‘principal component analysis’ of the magnetic field observations from the Wilcox Solar Observatory in California. They examined three solar cycles-worth of magnetic field activity, covering the period from 1976-2008. In addition, they compared their predictions to average sunspot numbers, another strong marker of solar activity. All the predictions and observations were closely matched. “Combining both waves together and comparing to real data for the current solar cycle, we found that our predictions showed an accuracy of 97%,” said Zharkova. “Effectively, when the waves are approximately in phase, they can show strong interaction, or resonance, and we have strong solar activity. When they are out of phase, we have solar minimums. When there is full phase separation, we have the conditions last seen during the Maunder minimum, 370 years ago.”

‘All Proponents Of Planetary Forcing Have Forecasted A Solar Grand Minimum For The Upcoming Decades’

Sánchez-Sesma, 2015     “Solar activity (SA) has non-linear characteristics that influence multiple scales in solar processes (Vlahos and Georgoulis, 2004). For instance, millennia-scale solar oscillations have been recently detected, like those of about 6000 and 2400 years, by Xapsos and Burke (2009) and Charvátová (2000), respectively, with important and interesting influences in the near past and future climate. These millennial-scale patterns of reconstructed solar activity variability could justify epochs of low activity, such as the Maunder Minimum, as well as epochs of enhanced activity, such as the current Modern Maximum, and the Medieval Maximum in the 12th century. Although the reason for these solar activity oscillations is unclear, it has been proposed that they are due to chaotic behavior of non-linear dynamo equations (Ruzmaikin, 1983), or stochastic instabilities forcing the solar dynamo, leading to on-off intermittency (Schmittet al., 1996), or planetary gravitational forcing with recurrent multi-decadal, multi-centennial and longer patterns (Fairbridge and Sanders, 1987; Fairbridge and Shirley,1987; Charvátová, 2000; Duhau and Jager, 2010; Perry and Hsu, 2000). It should be noted that all proponents of planetary forcing have forecasted a solar Grand Minimum for the upcoming decades, but one of them has also forecasted a Super Minimum for the next centuries (Perry and Hsu, 2000). In addition, during recent decades, statistical forecasts (with physically-based spectral information of reconstructed records) of solar magnetic activity predict a clear decrease in solar activity, reaching a minimum around AD 2100 (Steinhilber et al., 2013; S13, hereafter, Velasco et al., 2015)”

Liu et al., 2011     “Climate events worldwide, such as the MWP and LIA, were seen in a 2485-year temperature series. The largest amplitude and rate of temperature both occurred during the EJE [Eastern Jin Event (343–425 AD)], but not in the late 20th century. The millennium-scale cycle of solar activity determined the long-term temperature variation trends, while century-scale cycles controlled the amplitudes of temperature. Sunspot minimum events were associated with cold periods. The prediction results obtained using caterpillar-SSA showed that the temperature would increase until 2006 AD on the central-eastern Plateau, and then decrease until 2068 AD, and then increase again.”


Steinhilber and Beer, 2013     “Our methods are able to predict periods of high and low solar activities for a few centuries in the past. However, they are less successful in predicting the correct amplitude. Then, the methods were used to predict the period 2000–2500. Both methods predict a period of low activity around 2100 A.D. Between 2100 and 2350 A.D., the results are inconsistent regarding the duration of the low-activity state in 2100 A.D. and the level of activity until 2250 A.D.”


Lüdecke et al., 2015     “The Earth’s climate shows a rather regular oscillation of ∼ 200 year period during the last millennia. However, frequency, phase, and strength of the oscillation are found to vary in different time series of temperatures and for different times (see Figs. 4–6, and 5 8). Nonetheless, the relative historic stability of the cycle suggests that the periodic nature of the climate will persist also for the foreseeable future. Disregarding other conceivable forcings e.g. anthropogenic influences, an approximate prediction of the climate for the next 100 years suggests itself. Figure 9 shows the Tsine representation from AD 1800 to AD 2100 derived from the ∆Tsine representation by a π/2 phase shift.  It gives correctly the 1850–1900 temperature minimum and shows a temperature drop from present to ∼ AD 2080, the latter comparable with the minimum of 1870, as already predicted in the studies (Steinhilber and Beer, 2013; Liu et al., 2011) on the grounds of solar activity data alone.”

Herrera et al., 2015     “Of particular interest now is the fact that the behavior of the solar cycle 23 minimum has shown an activity decline not previously seen in past cycles for which spatial observations exist: this could be signaling the start of a new grand solar minimum.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Evans, 2016     “Four manifestations of unconventional climate influences are identified, each with at least as much effect on surface temperature as the direct heating effect of changes in total solar irradiance (TSI): external-driven albedo; countervailing cooling during TSI peaks, implied by the absence of corresponding peaks in the surface temperature record (the “notch”); the long-term sensitivity of surface warming to TSI increases; and the delay of ∼11 years between changes in underlying or smoothed TSI and the corresponding changes in surface temperature. We hypothesize these are all manifestations of a single force whose exact mechanism is unknown but whose crucial properties can be deduced: “Force X” modulates the Earth’s albedo, and lags TSI by one sunspot cycle or half the ∼22-year cycle of the Sun’s hydromagnetic dynamo. A second, alternative hypothesis is of “force N” for the notch and “force D” for the delayed force causing the other three manifestations. The notch-delay solar model can explain the global warming of the last few decades and centuries in terms of force X/D. Several solar indicators including TSI peaked ∼1986, but surface warming continued until ∼1998, which is explained by the delay. The notch-delay hypothesis predicts sustained and significant global cooling starting sometime in the period 2017 to 2022, of ∼0.3°C but perhaps milder (TSI estimates vary), as force X/D falls off in response to the marked decline in underlying TSI from around 2004—one of the three biggest and fastest falls in TSI since sunspot records began in 1610.”

Abdussamatov, 2015     “A long-term negative deviation of the Earth’s average annual energy balance from the equilibrium state is dictating corresponding variations in it’s the energy state. As a result, the Earth will have a negative average annual energy balance also in the future. This will lead to the beginning of the decreasing in the Earth’s temperature and of the epoch of the Little Ice Age after the maximum phase of the 24-th solar cycle approximately since the end of 2014. The influence of the consecutive chain of the secondary feedback effects (the increase in the Bond albedo and the decrease in the concentration of greenhouse gases in the atmosphere due to cooling) will lead to an additional reduction of the absorbed solar energy and reduce the greenhouse effect. The start of the TSI’s Grand Minimum is anticipated in the solar cycle 27±1 in 2043±11 and the beginning of the phase of deep cooling of the 19th Little Ice Age for the past 7,500 years around 2060±11.  … Thus, the long term variations of the solar constant (allowing for their direct and secondary impacts, with the latter being due to feedback effects) are the major and essential cause of climate changes because the Earth’s climate variation is a function of longterm imbalance between the solar radiation energy incoming into the upper layers of the Earth’s atmosphere and Earth’s total energy outgoing back to space.”


Yndestad and Solheim, 2016     “In 1890´s G. Spörer and E. W. Maunder (1890) reported that the solar activity stopped in a period of 70 years from 1645 to 1715. Later a reconstruction of the solar activity confirms the grand minima Maunder (1640-1720), Spörer (1390-1550), Wolf (1270-1340), and the minima Oort (1010-1070) and Dalton (1785-1810) since the year 1000 A.D. (Usoskin et al. 2007). These minimum periods have been associated with less irradiation from the Sun and cold climate periods on Earth. An identification of a three grand Maunder type periods and two Dalton type periods in a period thousand years, indicates that sooner or later there will be a colder climate on Earth from a new Maunder- or Dalton- type period. …. The result shows that the TSI variability and the sunspots variability have deterministic oscillations, controlled by the large planets Jupiter, Uranus and Neptune, as the first cause. A deterministic model of TSI [total solar irradiance] variability and sunspot variability confirms the known minimum and grand minimum periods since 1000. From this deterministic model we may expect a new Maunder type sunspot minimum period from about 2018 to 2055. The deterministic model of a TSI ACRIM data series from 1700 computes a new Maunder type grand minimum period from 2015 to 2071. A model of the longer TSI ACRIM data series from 1000 computes a new Dalton to Maunder type minimum irradiation period from 2047 to 2068.”

Torres and Guzmán, 2016     “Conclusions Based on our results, we propose the use of the Wolf’s Number Oscillation Index (WNOI) – as a more uniform alternative to the ONI – in the range over 30 and below -30. The analysis of the material presented and the arguments discussed allows us to define a possible relationship between phenomena related to Solar Cycle, the ENSO, climatic conditions, as well as some criteria for the establishment of public policies for preservation and remediation of the environment in the long run. We can conclude that solar activity oscillations impact the earth climatic conditions to such a extent that they become measurable only in the long run. The magnitude of the Solar Cycle – from 7 to 17 and a mean of 11.2 years – seems to support this statement. Based on the similarities of the Solar Cycles 5 and 24 we can expect a longer period of cold weather for the years 2022 y/o 2034, corresponding to the Solar Cycles 24 and 25.”

Sanchez-Sesma, 2016     “This empirical modeling of solar recurrent patterns has also provided a consequent multi-millennial-scale experimental forecast, suggesting a solar decreasing trend toward grand (super) minimum conditions for the upcoming period, AD 2050–2250 (AD 3750–4450). … Solar activity (SA) has non-linear characteristics that influence multiple scales in solar processes (Vlahos and Georgoulis, 2004). For instance, millennia-scale solar oscillations have been recently detected, like those of about 6000 and 2400 years, by Xapsos and Burke (2009) and Charvátová (2000), respectively, with important and interesting influences in the near, past and future climate. These millennialscale patterns of reconstructed SA variability could justify epochs of low activity, such as the Maunder minimum, as well as epochs of enhanced activity, such as the current Modern Maximum, and the Medieval maximum in the 12th century.  … We can conclude that the evidence provided is sufficient to justify a complete updating and reviewing of present climate models to better consider these detected natural recurrences and lags in solar processes.”

Riley et al., 2015     “[W]e suggest that the Sun evolved from a 2008/2009-like configuration at the start of the Maunder Minimum toward an ephemeral-only configuration by the end of it, supporting a prediction that we may be on the cusp of a new grand solar minimum.”

Abdusamatov, 2012     “The Earth as a planet will have a negative balance in the energy budget in the future as well, because the Sun is entering the decline phase of the bicentennial luminosity changes. … A deep bicentennial minimum in solar constant is to be anticipated in 2042 ± 11 and the 19th Little Ice Age (for the last 7500 years) may occur in 2055 ± 11.”


Solheim et al., 2012     “No significant trend is found between the length of a cycle and the average temperature in the same cycle, but a significant negative trend is found between the length of a cycle and the temperature in the next cycle. This provides a tool to predict an average temperature decrease of at least 1°C from solar cycle 23 to solar cycle 24 for the stations and areas analyzed. We find for the Norwegian local stations investigated that 25–56% of the temperature increase the last 150 years may be attributed to the Sun. For 3 North Atlantic stations we get 63–72% solar contribution. This points to the Atlantic currents as reinforcing a solar signal.”

Roth and Joos, 2013     “In contrast to earlier studies, periods of high solar activity were quite common not only in recent millennia, but throughout the Holocene. Notable deviations compared to earlier reconstructions are also found on decadal to centennial timescales. We show that earlier Holocene reconstructions, not accounting for the interhemispheric gradients in radiocarbon, are biased low. Solar activity is during 28% of the time higher than the modern average (650 MeV), but the absolute values remain weakly constrained due to uncertainties in the normalisation of the solar modulation to instrumental data. A recently published solar activity–TSI relationship yields small changes in Holocene TSI of the order of 1 W m−2 with a Maunder Minimum irradiance reduction of 0.85 ± 0.16 W m−2. Related solar-induced variations in global mean surface air temperature are simulated to be within 0.1 K. Autoregressive modelling suggests a declining trend of solar activity in the 21st century towards average Holocene conditions.”

Ahluwalia, 2014     “The Sun has emerged from a grand maximum for SSN cycles; it includes cycle 19, the most active cycle ever observed in 400 y. The grand minima are associated with cooler Earth temperatures (Eddy, 1976, 1981). The trend line indicates that we have entered a period of low solar activity; Ahluwalia and Jackiewicz (2012) suggest that we are at the advent of a Dalton-like minimum. The Earth was cooler then, made worse by Mt Tambora volcanic eruption on 5 April 1815.”

Salvador, 2013     “Using many features of Ian Wilson’s Tidal Torque theory, a mathematical model of the sunspot cycle has been created that reproduces changing sunspot cycle lengths and has an 85% correlation with the sunspot numbers from 1749 to 2013. The model makes a reasonable representation of the sunspot cycle for the past 1000 yr, placing all the solar minimums in their right time periods. The forecast is for a solar minimum and quiet Sun for the next 30 to 100 yr.”

Mörner, 2015     “By about 2030-2040, the Sun will experience a new grand solar minimum. This is evident from multiple studies of quite different characteristics: the phasing of sunspot cycles, the cyclic observations of North Atlantic behaviour over the past millennium, the cyclic pattern of cosmogenic radionuclides in natural terrestrial archives, the motions of the Sun with respect to the centre of mass, the planetary spin-orbit coupling, the planetary conjunction history and the general planetary-solar-terrestrial interaction. During the previous grand solar minima—i.e. the Spörer Minimum (ca 1440-1460), the Maunder Minimum (ca 1687-1703) and the Dalton Minimum (ca 1809- 1821)—the climatic conditions deteriorated into Little Ice Age periods.”

Duhau and de Jager, 2010     “[S]olar variability is presently entering into a long Grand Minimum, this being an episode of very low solar activity, not shorter than a century. A consequence is an improvement of our earlier forecast of the strength at maximum of the present Schwabe cycle (#24). The maximum will be late (2013.5), with a sunspot number as low as 55. … Solar activity is believed to be associated with climate change (De Jager and Duhau, 2009; De Jager et al., 2010; Miyahara et al., 2010). Sunspot activity can be concentrated in the two solar hemispheres and they appear to fluctuate for 11 year cycles. However, prolonged episodes of reduced sunspot activity, such as the Maunder Minimum, were clearly linked with an episode of extreme cooling and bitingly cold winters in Europe and North America, known as the ‘little ice age‘.”

Russell et al., 2010      “If we were to guess what the next solar cycle was going to be like from the behavior of the declining phase of solar cycle 23 to date, we would select solar cycle 4 beginning in 1785 as the analog of solar cycle 23 and solar cycles 5 and 6 as the analogs of the upcoming cycles 24 and 25. At this writing, the similarity of the inability of the new cycle to take hold with significant new cycle activity at high latitudes is striking. The epoch of cycles 5 and 6 has also been called the Dalton minimum, during which the sunspot number maximized at close to 50. It was also a period of global cooling.”


Miyahara et al., 2010     “Specifically, the “Little Ice Age” covers a cyclic period of cooling and glaciation which began in the 13th century and which continued into the 16th to 19th centuries, when glaciers began advancing southwards in Greenland and the North Atlantic, and perhaps worldwide. These episodes of global cooling appear to be linked to reduced solar activity. By contrast, the Medieval Warm Period occurred during a period of heightened solar activity. If these associations are valid, then future cyclic alterations would be expected to impact global temperatures including perhaps triggering another period of global cooling if sunspot activity is again reduced to a minimum. … The Sun is currently showing slightly different behavior compared with recent decades (Livingston & Penn, 2009). Consequently, concern has emerged regarding whether the Sun is approaching the next Maunder Minimum of reduced activity. Given this scenario, it has been suggested that global temperatures may decrease by about 0.3 °C as a result of a reduction in total solar irradiance (Feulner & Rahmstorf, 2010).”

Scafetta, 2012     “The model forecasts a new prolonged solar grand minimum during 2020-2045, which would be produced by the minima of both the 61 and 115-year reconstructed cycles. Finally, the model predicts that during low solar activity periods, the solar cycle length tends to be longer, as some researchers have claimed. These results clearly indicate that solar and climate oscillations are linked to planetary motion and, furthermore, their timing can be reasonably hindcast and forecast for decades, centuries and millennia.”

Archibald, 2007     “Our forecast for global average temperature to 2030 has been updated for the progression of Solar Cycle 23 and the contribution that will be made by increased carbon dioxide in the atmosphere. The increased length of Solar Cycle 23 supports the view that Solar Cycle 24 will be weak, with the consequence of increased certainty that that there will be a global average temperature decline in the range of 1° to 2° C for the forecast period [by 2030]. The projected increase of 40 ppm in atmospheric carbon dioxide to 2030 is calculated to contribute a global atmospheric temperature increase of 0.04°C. The anthropogenic contribution to climate change over the forecast period will be insignificant relative to natural cyclic variation.”

Landschiedt, 2003     “Analysis of the sun’s varying activity in the last two millennia indicates that contrary to the IPCC’s speculation about man-made global warming as high as 5.8° C within the next hundred years, a long period of cool climate with its coldest phase around 2030 is to be expected. It is shown that minima in the 80 to 90-year Gleissberg cycle of solar activity, coinciding with periods of cool climate on Earth, are consistently linked to an 83-year cycle in the change of the rotary force driving the sun’s oscillatory motion about the centre of mass of the solar system. As the future course of this cycle and its amplitudes can be computed, it can be seen that the Gleissberg minimum around 2030 and another one around 2200 will be of the Maunder minimum type accompanied by severe cooling on Earth. This forecast should prove skillful as other long-range forecasts of climate phenomena, based on cycles in the sun’s orbital motion, have turned out correct as for instance the prediction of the last three El Niños years before the respective event.”

The North Atlantic Region – Linked To Global Climate – Has Already Been Cooling Rapidly

Chafik et al., 2016       “The multidecadal variability of the North Atlantic Ocean has a strong signal in the sea surface temperature with many global climate linkages [Enfield et al., 2001; Knight et al., 2006]. An even stronger multidecadal signal can be found in the subpolar temperatures and salinities, where the Atlantic Water inflow variations constitute an essential part in the variability [Hátún et al., 2005; Häkkinen et al., 2011a; Reverdin, 2010]. The atmospheric forcing in the subpolar North Atlantic Ocean is dominated by the variability of the North Atlantic Oscillation (NAO), i.e., the leading mode of atmospheric variability in the North Atlantic sector, which modulates the atmosphere-ocean momentum and heat exchanges on a range of temporal scales. The subpolar ocean variability thus appears to be tightly connected to atmospheric forcing and associated basin-scale circulation changes, which together force the subpolar ocean properties toward extremes [Lozier et al., 2008, 2010], either to warm-saline or cold-fresh conditions on multidecadal scales. These regime changes [in the North Atlantic] have recently been argued to be important for global mean surface temperature warming acceleration and hiatus [Chen and Tung, 2014; Drijfhout et al., 2014].”


Duchez et al., 2016       “[C]old ocean temperatures were the most extreme in the modern record [since 1948] over much of the mid-high latitude North-East Atlantic. … we consider the exceptionally cold ocean surface anomaly that was already in place prior to the onset of the 2015 heat wave. The SST anomaly field for June 2015 shows temperatures up to 2 °C colder than normal over much of the sub-polar gyre with values that are the coldest observed for this month of the year in the period 1948–2015 indicated by stippling. The cause of this cold anomaly has been the subject of widespread interest in the media, we now show for the first time that it can be attributed to a combination of air–sea heat loss from late 2014 through to spring 2015 and a re-emergent sub-surface ocean heat content [cold] anomaly that developed in preceding years.”

Robson et al., 2016       “In the mid-1990s the North Atlantic subpolar gyre warmed rapidly, which had important climate impacts such as increased hurricane numbers and changes to rainfall over Africa, Europe and North America. Evidence suggests that the warming was largely due to a strengthening of the ocean circulation, particularly the Atlantic Meridional Overturning Circulation. Since the mid-1990s direct and indirect measurements have suggested a decline in the strength of the ocean circulation, which is expected to lead to a reduction in northward heat transport. Here we show that since 2005 a large volume of the upper North Atlantic Ocean has cooled significantly by approximately 0.45 °C or 1.5 × 1022 J, reversing the previous warming trend.”

Share this...FacebookTwitter "
"Never has a song epitomised conspicuous consumption so tellingly as the [Twelve Days of Christmas](https://en.wikipedia.org/wiki/The_Twelve_Days_of_Christmas_(song). And the gifts mentioned come at quite a price. Last year, Fortune’s Christmas Price Index estimated that the cost of all of the presents mentioned in the song – from the patridge in the pear tree to the gold rings – was $27,673 (£18,500), or $116,273 (£80,000) if you calculate the cumulative total of 364 gifts, taking into account all of the repetitions. So perhaps we should use this popular seasonal song to help us think specifically about our own choices and our planet’s future as we enter the festive period of bingeing and consumption. The “fowl”-heavy gift list would suggest that the recipient is a robust, game-eating omnivore. Partridge, hens and geese are traditional festive foods, but the rearing and consumption of all of these has an impact in terms of sustainability. Partridges are a red-listed species and need to be managed effectively in order to maintain their declining populations. Chickens are in no such immediate danger, but many live miserable lives, even with the new UK rules on husbandry. The choice of a goose for Christmas dinner is likely to be a more sustainable one, however, since most are bred in small flocks by small-scale farmers and their production has yet to be overly mechanised. Milk and cream consumption peaks at Christmas, but the milkmaids of the song hark back to a pre-mechanical era – and these days most milk is produced in high-tech dairies. The spectre of industrial mega dairies containing tens of thousands of cows is increasingly likely as farmers struggle to make a living out of small-scale production. We should also remember that milk is not produced without various unfortunate by-products, including calves.  Given the animal welfare, social and environmental impacts of festive fodder, perhaps the best, most sustainable choice would be to have a vegetarian or even vegan Christmas dinner. Failing that, we could all consider Arnold Schwarzenegger’s advice and eat less meat – not just at Christmas but throughout the year. Doves have been a Christian symbol of love and peace since biblical times and are universally associated with hope. It is almost impossible to put a price on peace, but the costs of unrest and war in 2015 have been estimated by the Institute for Economics and Peace at more than 13.4% of global GDP, or around £9.21 trillion. Turtle doves, like global peace are in decline – and there is a real fear for their extinction.  The blackbirds, the calling birds of the song, are common and their song is heard almost everywhere. Sadly, most of us don’t listen – one gift to ourselves would be to pay more attention so that we are more in tune with the natural world around us. The five gold rings are thought to refer to ring-necked pheasants or even goldfinches, but most of us think about jewellery when we hear this – and most of us would like to receive something precious as a Christmas gift.  Sadly, gold is rarely a sustainable choice and Stephanie Boyd’s film The Price of Gold, certainly makes disturbing viewing. Perhaps it should make us reconsider the desirability of giving or receiving this precious metal. A long running myth is that the Queen owns all the “swans-a-swimming” in England, but the story probably stems from old traditions such as swan-upping, the annual census of swan numbers on the Thames.  The notion of privilege is a strong theme in the song with “ladies dancing” and “lords a-leaping”, bringing a vision of old-fashioned privilege to our minds. Certainly privilege is apparent in the UK, the most unequal country in the EU – and few of us will ever reach Lord or Lady status, never mind enjoy the associated wealth or influence.  Instead of feeling marginalised and resentful about our own limited material wealth or power, however, perhaps we should reflect on our privilege. The Twitter hashtag #firstworldproblems, has possibly been overused of late, but the sentiments behind it are increasingly relevant. In a world of unrest, ill-health, war and disaster, there has never been a better time to count our blessings and use our emotional energies to find solutions. The finale of the song sees gifts of music from pipers and drummers. This year we may have something to make a noise about. The Paris Climate agreement gives the world hope that we can find solutions to climate change, and prevent the worst-case climate scenarios. The power of civil society in pressurising governments around the world to agree to ambitious targets has been demonstrated, and perhaps we, the public, are now calling the tunes. It’s time politicians the world over began marching to a different drum beat."
"Ask the average person what they know about Easter Island and those monumental statues with their inscrutable expressions would likely top the list. For many this is the sum total of their knowledge, for the excellent reason that Easter Island is a very small and exceptionally remote spec in the eastern Pacific.  Administered by Chile 3,600km to the east, and some 2,000km from its nearest inhabited neighbour, Pitcairn Island (a UK overseas territory), Easter Island is in fact one of the remotest inhabited places on Earth. Apart from statues and inaccessibility, the other notable thing about Easter Island is the ecological disaster that led society there to collapse into warfare and starvation several centuries ago. We still don’t know exactly what happened, but the classic and still convincing story says that Easter Islanders chopped down all their trees to erect statues. The result was soil erosion, loss of fertility and the collapse of food production. And with no trees to make boats, fish were hard to catch on the rugged wave-tossed, cliff-lined coasts and the people became cut off from the rest of the Pacific.  For a place surrounded by trackless seas, Easter Island’s stories have remained resolutely land-bound. But that may soon change. Plans are afoot to turn a vast area of neighbouring ocean into a marine protected area. An announcement from Chile’s president, Michelle Bachelet, is expected on October 5.  Conservationists who have spent years campaigning for protection, like the Pew Environment Group’s Global Ocean Legacy program, hope the protected area will be very large, and enforced by Chile’s navy. If current plans are realised, Easter Island will become one of the biggest marine protected areas in the world with industrial fishing by non-islanders banned for 200 miles in all directions.  Locals still haul their lines in by hand which limits their catch. Their fishing association supports the marine park as it will give them some protection from illegal competition – islanders will still be able to fish up to 50 miles offshore. But what is special about these seas? It is that isolation again. The island’s remote setting has so far spared its seas from the worst depredations of the world’s distant water fishing fleets. In places that are easier to reach, populations of big fish such as tuna, swordfish and sharks have been driven down by intensive industrial long-lining and purse-seine nets. Long-lines may be tens of kilometres long and can carry tens of thousands of hooks, while purse seine nets are used to surround whole schools of fish and anything else that happens to be with them, such as turtles and dolphins. Such fishing has led to losses of 90% or more in vulnerable species like oceanic whitetip sharks or leatherback turtles. Isolation also means that Easter Island, although not as rich in species as places further west in the Pacific, has a bevy of sea creatures found nowhere else in the world including colourful dwarf angelfish, hermit crabs, tiny starfish and a slipper lobster. It’s a tightly connected web – some of these endemic species feed mainly on other endemic species. If they disappear from here, they disappear everywhere, so safeguarding them is a priority.  If Easter Island’s waters receive the protection they deserve, this place will join a growing number of very large marine protected areas being set up today. There is a long overdue wave of conservation action going on in the sea that has parallels with pioneering efforts to create the national parks of North America and Africa in the late 19th and 20th centuries.  The UK established 640,000km2 of protection around its Indian Ocean Territory of the Chagos in 2010, and has promised an even larger area around Easter Island’s “neighbour”, Pitcairn. New Zealand has just announced a 620,000km2 protected area around the Kermadec Islands, halfway between Auckland and Tonga. Back in Britain the Conservative government has pledged to create a “Blue Belt” of protection around all 14 of its overseas territories during this government. Even with these welcome developments, we may still fall short of the 10% coverage of marine protected areas that the world agreed to establish by 2020 under the UN Convention on Biological Diversity. Nonetheless, at long last, we seem to be heading in the right direction. There is good news at last for embattled ocean life."
"Plans to shift Europe’s coal plants to burning wood pellets instead could accelerate rather than combat the climate crisis and lay waste to woodland equal to half the size of Germany’s Black Forest a year, according to campaigners. The climate thinktank Sandbag said the heavily subsidised plans to cut carbon emissions would result in a “staggering” amount of tree cutting, potentially destroying forests faster than they can regrow.  Sandbag found that Europe’s planned biomass conversion projects would require 36m tonnes of wood pellets every year, equal to the entire current global wood pellet production. This would require forests covering 2,700 sq km to be cut down annually, the equivalent of half the Black Forest in Germany. The majority of wood pellets are imported from the US and Canada, “meaning that there’s a huge added environmental cost in transporting the wood from the other side of the Atlantic”, said the report’s author, Charles Moore. The planned biomass conversions – with Finland, Germany and the Netherlands leading the way – would emit 67m tonnes of carbon into the atmosphere, which would be unlikely to be reabsorbed by growing trees over the timescales relevant to meeting the targets set by Paris climate agreement, warned Sandbag. In return, the forest-hungry power plants would produce less than 2% of the EU’s electricity needs – the same generation capacity built in Europe every year by wind and solar farm developers. “It’s impossible to believe coal companies when they argue that the switch to burning forests could be good for the climate,” Moore said. EU regulators consider biomass as a carbon neutral renewable alternative, saying that the growth of new trees can absorb as much carbon as wood pellets release when they are burned to generate electricity. The Drax energy complex in North Yorkshire has used this logic to underpin its plan to become the world’s first “carbon negative” company within 10 years by burning biomass in conjunction with technology that can capture carbon from its power plant flues. Drax robustly defends the sustainability record of its biomass supply chain. Its wood pellets, shipped from the US, are made mostly from sawmill residue and forest overgrowth, which is carefully cleared to improve the quality of forests. Drax has pledged never to source biomass from farming practices that lead to deforestation. But Alex Mason, from WWF’s EU office, said burning forests was “literally the opposite of what we should be doing” to help tackle the climate crisis. “As 800 scientists pointed out last year, converting coal plants to biomass will increase emissions for decades, if not centuries. This new report is yet more evidence that the EU must use the new EU Green Deal to fix EU bioenergy rules before this ticking time-bomb of a policy does any more damage,” he said. Prof Michael Norton, a director at the European Academies Science Advisory Council, said large-scale forest removal to meet the demand for biomass would be “horrifying from a climate perspective” and already risks overshooting the Paris agreement targets. He said European countries were moving ahead with plans for giant biomass plants despite reports showing “the counter-productive nature of biomass” and the urgent need to stop deforestation. A Drax spokesperson said: “Drax only uses sustainable biomass sourced from managed forests that are replanted and stay as forests, absorbing carbon as the trees grow. Drax will not use biomass that drives harvesting decisions which would adversely affect the long-term potential of forests to store carbon. These commitments are central to our new biomass sustainability policy, launched in October. We also have a new advisory board – an independent group of scientists, academics and forestry experts, which will ensure our biomass sourcing meets the highest standards using the latest science and best practice.” This article was amended on 16 December 2019. Due to an editing error an earlier version suggested Drax was one of the planned biomass conversions referred to in the Sandbag report. Drax has already completed its biomass conversion works. This has been corrected. A statement from the company has also been added."
"
Share this...FacebookTwitterWe’ve been hearing bits and pieces coming out of Ontario concerning its renewable energy debacle.
Now I read at the CBC an opinion piece by Robin Urback from late November on just how bad the situation is getting. Man, and we thought things were bad in Germany and Europe!
It turns out that Ontario prime minister Kathleen Wynne is the real deal when it comes to energy policy incompetence. The Ontarian version of the Energiewende is probably outdoing Germany’s very own.
Rex Murphy sums it up here at the National Post:
It cannot have escaped the attention of many that Ontario is most unsettled these days. That its industries are anxious, its debt colossal, its citizens not in a pleasant mood. Ontario is in a lot of pain.”
For one, Ontarians are up in arms over the skyrocketing electricity prices:

Groundwork for an uprising? Ontario electricity used to be a low-priced commodity. Now prices are skyrocketing. Source: Ontario Energy Board here.
And according to the CBC, Wynne now says she is very sorry about the mess she has created with energy consumers. The CBC quotes Wynne:
Our government made a mistake. It was my mistake. And I’m going to do my best to fix it,”
If there’s one thing I like about Donald Trump, it is his advice that you can’t expect the very people who created the mess to later be the ones to fix it. They are the last people who should be involved in the solution. Their rightful place is in the unemployment line, in exile, or in a political gulag.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




So why wasn’t this debacle prevented from happening? After all this is not the sort of thing that just pops in out of the blue. The answer is that Wynne and her team ignored and dismissed the constant chorus of warnings, thinking they knew much better. Urback writes (sarcastically):
In any case, we probably shouldn’t blame this one on the Liberals. Indeed, besides the dozens of reports, years of increasing consumer prices, dire financial warnings and protests over unaffordable hydro bills — there was no way they could have seen this coming.”
If any one has doubts about Wynne being way out of touch, check out what she said concerning coping with high electricity prices in a recent interview posted at FaceBook by KeepHydroPublic here:

Source of news clip: www.facebook.com/keephydropublic/?fref=nf
Note how she says she got her the energy costs under control by having her home renovated to make it energy efficient. In other words, she is telling viewers if you find it’s difficult to pay your monthly energy bills, then just spend thousands of dollars (that you don’t have, but she does) on renovating your entire house!
The site writes:
The Ontario Government has made it impossible for residents to pay their bills. When asked if she ever looks at her bill the Premier stumbles and says she’s privileged to have a house better renovated for less consumption. In 2017 we will fight the Ontario Government’s every attempt to blame residents about consumptions. The Government tries to blame residents for the bad deals they made which is costing people more. And now they want to sell people’s asset to pay for their mistakes. Ontarians do not have the privilege to lose their biggest utility.”
And what is especially stunning is that over 80% of Ontario’s electricity supply already comes from carbon-free sources (nuclear and hydro), making the mad rush into wind and sun, and all the social problems they bring, completely unnecessary. It’s all a big green show with huge cost and practically no benefit.
And these people think it’s the Russians?
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSome years ago German warmist climatologist Mojib Latif complained over our changing climate, reminding us how in Germany we used to get snow sometimes for Easter.
Well this year, in mid April, Easter is relatively late, and the forecast is now calling for snow to hit large parts of Europe as a low pressure system (OTTO) centered over the Baltic sea will pump polar air across the continent — thus ushering in a nasty and possibly protracted spell of winter.

Germany’s DWD forecast for April 15. Otto’s cold front will pump in cold and moist polar air to kick off an unusual wintery April cold wave: Source: www.wetteronline.de/wetterfronten/europa.
German weather and climate site wobleibtdieerderwaermung.de here provides a good analysis of the situation. Ahead for the coming days are frost and snow. What follows are the GFS snow forecast charts from wetteronline.de for April 17, 18 and 19, which show widespread snowfall across Central Europe, even reaching down to the Mediterranean by Wednesday:



Chart sources: wetteronline.de
According to the WBDE site, temperatures in Europe will plummet by up to 12°C below normal.
NOAA caught by surprise, revise forecast
The April cold wave took the NOAA by surprise. The US weather and climate organization had predicted an outright balmy April back on March 22, 2017:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





CFSv2 April temperature prognosis of March 22, 2017. Source: www.cpc.ncep.noaa.gov/products/CFSv2/htmls/euT2me3Mon.html
Obviously the NOAA weather models had some major blind spots back in March (which is understandable), as much of Europe was projected to be 2°C warmer than the long-term mean.
But later on when the cold became obvious, the NOAA was forced to update its April 2017 forecast:

CFSc2 temperature forecast for April 2017. Much of the forecast was corrected significantly downward. Source: www.cpc.ncep.noaa.gov/products/CFSv2/htmls/euT2me3Mon.html
On the other hand March 2017 across Central Europe was very warm, and had a number of media outlets blaming it on global warming. Germany even saw a new warm record set for the month of March. Perhaps that skewed the forecasters into thinking the warmth would continue, all in line with their global warming beliefs.
Trend: spring in fact coming later and later
The German DWD then added that spring was starting earlier and earlier – due to climate change, but did not mention that you have to go back some 60 years to get an overall warming trend line. However over the past 30 years, German springs have in fact been starting later and later – a reality that the DWD conveniently omitted.
This year it appears winter will be pushing spring back to May. Midterm forecasts show the cold wave will persist at least another week.
Warmists will naturally be quick to point that late-April snow in Central Europe is really nothing that unusual, which is true — if the cold spell lasts only a matter of days. However, as Wetter24 here notes, what is about to hit the continent will persist and thus be indeed unusual. It writes of April weather in Germany:
On the other hand what is unusual is a longer-lasting phase with significantly below or above normal temperatures. And it is such a phase that is now approaching with an anticipated long period of below normal temperatures.”
The bottom line: “thing-of-the-past” snow and frost are still ignoring “global warming” and are still showing up in April. Earlier predictions that they wouldn’t are wrong.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMeteorologist Paul Dorian of Vencore Weather here presents an analysis of the just now ending winter of 2017. It’s nothing you’d expect from a world that is supposedly warming.
===========================
As the following Environment Canada chart shows, snow is running at well above normal levels across the Northern Hemisphere”

Europe had an extended period of colder-than-normal weather in April accompanied by lots of snow.
Now much of the US is experiencing an extended period of colder-than-normal weather as we transition from early-to-mid May.
Snowfall has been running at above normal levels this winter across the Northern Hemisphere and continues at those higher-than-normal levels as we head towards the middle of May.
Arctic now cooler than normal
In addition, temperatures in the Arctic region – which have been generally running at above-normal levels in recent weeks – have actually dropped to below-normal in recent days and, if this trend continues, it should prevent any chance for sea ice extent to reach record lows up there this summer.

Temperatures in the Arctic region (>80 degrees N) have fallen to below-normal levels (circled area) in recent days following several weeks at generally above-normal levels; map courtesy Weather Bell Analytics/Dr. Ryan Maue




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




One of the main factors contributing to this late season cold across much of the Northern Hemisphere is a blocking pattern in the upper part of the atmosphere centered over Greenland and Iceland and this tends to contribute to cold air outbreaks into the land mass areas on both sides of the Atlantic Ocean.
&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img src=”https://static1.squarespace.com/static/56530521e4b0c307d59bbe97/t/5911cbf79de4bbb96b923fae/1494338560165/”  alt=”Temperatures in the Arctic region (&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;80 degrees N) have fallen to below-normal levels (circled area) in recent days following several weeks at generally above-normal levels; map courtesy Weather Bell Analytics/Dr. Ryan Maue”&amp;amp;amp;amp;amp;lt;/p&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;p&amp;amp;amp;amp;amp;gt;During the month of April, Europe experienced a persistent colder-than-normal pattern and significant snow piled up in the Alps across the central part of the continent. &amp;amp;amp;amp;amp;nbsp;The air was so cold, in fact,&amp;amp;amp;amp;amp;nbsp;that many vineyards from England-to-Italy suffered serious losses as the battle with freezing conditions was relentless in many areas. &amp;amp;amp;amp;amp;nbsp;In the US, a colder-than-normal pattern has kicked in for much of the nation and should continue into the middle of the month and there has been some accumulating snow in the western US and across portions of the Northern Plains and interior Northeast. &amp;amp;amp;amp;amp;nbsp;In fact, the next ten days or so will see more in the way of accumulating snow in the western US and many ski resorts in that part of the country will have good conditions right into the month of June. &amp;amp;amp;amp;amp;nbsp;The Sierra Nevada Mountains of eastern California, for example, will get more substantial snowfall over the next ten days or so to add to the massive totals that they received this winter.&amp;amp;amp;amp;amp;lt;/p&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;/div&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;/div&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;div id=”block-yui_3_17_2_1_1494338383854_30669″ class=”sqs-block image-block sqs-block-image sqs-text-ready” data-block-type=”5″&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;div id=”yui_3_17_2_1_1494352393596_136″ class=”sqs-block-content”&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;div id=”yui_3_17_2_1_1494352393596_135″ class=”image-block-outer-wrapper layout-caption-below design-layout-inline”&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;div id=”yui_3_17_2_1_1494352393596_134″ class=”intrinsic”&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;lt;br /&amp;amp;amp;amp;gt;&amp;amp;amp;lt;br /&amp;amp;amp;gt;&amp;amp;lt;br /&amp;amp;gt;&amp;lt;br /&amp;gt;&lt;br /&gt;<br />
&amp;amp;amp;amp;amp;lt;div id=”yui_3_17_2_1_1494352393596_133″ class=”image-block-wrapper has-aspect-ratio” data-description=”&amp;amp;amp;amp;amp;amp;lt;p&amp;amp;amp;amp;amp;amp;gt;500 millibar height anomaly pattern with strong blocking (in red) over Greenland and Iceland and deep upper-level lows over the Northeast and Southwest US; map courtesy AER/Dr. Judah Cohen&amp;amp;amp;amp;amp;amp;lt;/p&amp;amp;amp;amp;amp;amp;gt;”&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;amp;lt;noscript&amp;amp;amp;amp;amp;gt;&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img src=”https://static1.squarespace.com/static/56530521e4b0c307d59bbe97/t/5911cc58b8a79bdefbbf44fc/1494338658163/”  alt=”500 millibar height anomaly pattern with strong blocking (in red) over Greenland and Iceland and deep upper-level lows over the Northeast and Southwest US; map courtesy AER/Dr. Judah Cohen”  /&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;



500 millibar height anomaly pattern with strong blocking (in red) over Greenland and Iceland and deep upper-level lows over the Northeast and Southwest US; map courtesy AER/Dr. Judah Cohen





The upper-level pattern across the Northern Hemisphere is playing a big role in this late season cold. Indeed, blocking is now well established over Greenland/Iceland as indicated by the latest 500 millibar height anomalies (red region) and this type of pattern can force cold air southward from northern latitudes into land mass areas on both sides of the Atlantic Ocean.






&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;lt;img src=”https://static1.squarespace.com/static/56530521e4b0c307d59bbe97/t/5911ccb5cd0f680bde94f908/1494338748886/”  alt=”Arctic Oscillation (top) and North Atlantic Oscillation (bottom) index values for the current time and past few months (in black) and forecasted values are shown in red through the month of May; data courtesy NOAA”  /&amp;amp;amp;amp;amp;amp;amp;amp;amp;amp;gt;


Arctic Oscillation (top) and North Atlantic Oscillation (bottom) index values for the current time and past few months (in black) and forecasted values are shown in red through the month of May; data courtesy NOAA








Two indices that meteorologists can track in order to monitor the pressure patterns over the northern latitudes are the Arctic Oscillation (AO) and North Atlantic Oscillation (NAO).  When these indices drop into negative territory for extended periods this time of year, the result is often an upper-level blocking pattern across the northern latitudes.
There is some hope that later this month this blocking pattern will fall apart and the computer model forecasts of the AO and NAO indices (shown in red) do suggest a return to positive territory in the near future.
Text by Meteorologist Paul Dorian, with some editing by NTZ.
vencoreweather.com
 


Share this...FacebookTwitter "
"Global demand for coal has fallen this year for the first time in two years as Europe and the US turn their backs on coal-fired power plants in favour of cheap gas and renewable energy. A report from the International Energy Agency (IEA) found that the world’s appetite for coal declined in 2019 after a two-year resurgence following the steepest ever drop in the use of coal-fired power plants.  The world’s energy watchdog said it is too soon to say whether the global appetite for coal would continue to decline because the fate of the industry rests largely in the hands of China’s policymakers. Coal remains the world’s single largest source of electricity generation, half of which is produced in China and used to power Chinese power plants. The IEA’s annual report on the coal industry revealed that the largest ever decline in the use of coal-fired electricity was led by steep cuts in coal demand from Europe and the US. Western countries are weaning their energy systems off coal power due to abundant cheaper alternatives such as renewable energy and gas, and flatlining energy demand. Keisuke Sadamori, a director at the IEA, said “this is not the end of coal” because Asia’s demand for electricity is continuing its steep ascent fuelled by strong economic growth and a growing number of homes with access to electricity. “The region’s share of global coal power generation has climbed from just over 20% in 1990 to almost 80% in 2019, meaning coal’s fate is increasingly tied to decisions made in Asian capitals,” he said. The IEA expects coal-fired electricity to rise only marginally between 2020 and 2024, at less than 1% a year, which should see its share of the global electricity mix fall to 35% in 2024 from 38% last year. “Coal is disappearing in many advanced economies, but it remains resilient and is even continuing to grow in developing Asia,” he said. But the forecasts could deviate widely, depending on China’s energy policy decisions in its next five-year plan, covering 2021 to 2025. The fossil fuel faces rising public opposition due to concerns over air pollution and the climate crisis. Many governments are now considering stronger climate and environmental policies as renewables and gas become cheaper to use. “If China changes – everything changes,” Sadamori said. India bucked the trend for rising coal use in Asia this year. The IEA said the fast-growing economy is expected to record its first drop in coal-fired power in the last 45 years. The low coal power generation in India this year was due to “unusually low growth in electricity demand and exceptionally high hydropower output,” according to Sadamori. “It is not at all clear that it will be repeated,” he said."
"
Share this...FacebookTwitterMuch has been written about growing power grid instability in Europe as more and more volatile wind and solar energy have come online over the years.
Earlier today European news outlets reported how Brussels, a major centre of the European Union, plunged into darkness late yesterday evening.
So far it’s not known what’s behind the outage. The New York Post writes that the cause  is a “mystery”, but according to the BBC here that “a spokesperson for Brussels’ power supplier, Sibelga, later told The Sun that the blackout was the result of an electric network distribution problem”.
City gripped by fear
It’s one thing if some rural area blacks out, but quite another when a center of political power like Brussels gets paralyzed and is left totally vulnerable. The UK Mirror wrote of a “security alert” after a “massive blackout” plunged the “entire centre of EU capital into darkness“, adding:
The loss of electricity across the Belgian capital has sparked terror attack fears, although the cause of the outage has not been confirmed.”
Brussels has been the target of terror attacks and is still considered a hotbed of potential terrorists. The Mirror writes that the blackout had Belgian security forces scrambling to boost their manpower at main sites around Brussels.
Volatile wind and sun wreak havoc on grid stability


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Although it may turn out that the Brussels blackout problem had little to do with the haphazard supply from wind and solar energies, the outage once again highlights the European power grid’s growing instability the since greater amounts of the volatile energy have been getting fed in.
The following chart, for example, shows just how irregular the supply from wind and sun can be in Belgium’s neighbor, Germany:

German wind and solar power supply compared to German total demand over the past 15 days. Source: Agora.
The upper curve depicts Germany’s total consumption. Keeping the grid stable is becoming an increasingly formidable challenge, and the likelihood of overloads is ever higher. Blackouts like the one in Brussels, and the disruptions they cause, will likely become a part of Europe’s future.
There’s one positive aspect about the blackouts: they could serve to help a bit to alleviate one big problem in Europe. The OE24 here writes:  “In the social media networks, jokes were made about a possible boost in the birthrate in 9 months.”
Strangely, Germany’s mainstream media is totally absent with the news of the blackout.
 
Share this...FacebookTwitter "
"Australia’s fossil fuel industry would stump up for a national climate disaster fund levy to help cover the costs of escalating natural disasters, under a new thinktank proposal. The Australia Institute has released a plan to have some of the nation’s biggest polluters pay a $1 levy per tonne of carbon pollution from fossil fuel production, which it estimates would raise at least $1.5bn per year. Putting the nation back together again after flood, storm or fire is an increasingly costly exercise, as climate change exacerbates the strength and duration of events, draining local, state and federal coffers. Mark Ogge, the principal adviser at The Australia Institute, said with costs only forecast to increase, the nation needed to look at new ways to cover them, while also holding fossil fuel producers responsible. “The frequency and intensity of natural disasters such as bushfires and floods will keep increasing while we keep pumping more greenhouse gases into the atmosphere,” he said. “Australia urgently needs a dedicated, independently administered fund to cope with the ever-increasing costs of these disasters. A $1 per tonne levy would have virtually no effect on energy prices or coal jobs, but would be a huge help to everyone being affected by the damage these activities are causing.” Ogge said polling undertaken by the institute, as part of its Climate of the Nation report, found 62% of Australians supported the introduction of a fossil fuel levy. Last year, the International Federation of the Red Cross and Red Crescent Societies’ World Disasters report costed Australia’s damage bill over the past 10 years at $37bn. Various estimates have put Australia’s economic disaster recovery cost at between $13bn and $18bn a year, as the ongoing drought and extreme weather events hit the nation harder and with increased frequency. The Insurance Australia Group warned in 2017 the economic cost was forecast to grow by 3.4% a year, before doubling by 2038 and reaching $39bn a year in real terms by 2050. Ogge said the policy would help “communities to prepare for and recover from natural disasters, but it would also be great for creating jobs and boosting the economy”. A group of mayors, faced with steering their communities through the devastating impacts of the most recent and ongoing bushfire crisis, also lent their support to the proposal, including the Glen Innes mayor, Carol Sparks. “Every tonne of coal mined ends up as more greenhouse gas in the atmosphere, fuelling climate change and making catastrophes like these fires worse,” she said. “It is staggering that the coal and gas companies that profit from this don’t have to pay for any of the costs. Our communities are paying the price for their activities. It’s high time they started paying for the damage they are causing.” Sign up to receive the top stories from Guardian Australia every morning Bellingen mayor Dominic King said it was not fair that the burden of paying for communities to be prepared, and authorities to be properly resourced, fell on “ordinary people and our volunteers” while fossil fuel companies continued to profit “from the activities that are fuelling climate change”."
"
Share this...FacebookTwitterHere’s an addendum to what I wrote here about German electric power a couple of days ago. Apparently things are worse than we thought. The climate protection scam is truly a colossal cash-cow for the government and a narrow special interest.

German power now costing consumers tens of billions of euros. Chart above shows Germany’s average household price per kilowatt-hour. Image: BDEW.
According to manager magazin, power consumers are now paying 35 billion euros in taxes and feed-in tariffs annually:
Households in Germany are paying with their electric bills more than 35 billion euros for taxes, surcharges and feed-in tariffs this year. The biggest share is the EEG renewable energy feed-in tariff with 24 billion.”
The taxes, tariffs and surcharges represent 55% of the German power bill, almost double what it was in 1998. manager-magazin reports the average kilowatt-hour of electric power has now reached 29.16 euro-cents, and blames the feed-in act as the main price-driver.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




German households are currently paying over 100 euros a month just for their electric bills – a “record level”. The manager magazin reports that the average household now pays 1223 euros a year for power, up 2% from a year earlier.
The vast majority of analysts say the price spiral will continue, with no end in sight over the next few years.
Investing in Mexico
Not only electricity consumers are being hit, but so is Europe’s green power sector, which was once touted as a jobs creation machine for the future. German national daily Die Welt here reports that electrical engineering giant Siemens will close a wind energy production equipment facility in neighboring Denmark, thus costing 430 jobs. The closure comes at the heels of the company announcing the lay off 150 workers at its rotor blade facility in Aalborg. Siemens cites a streamlining of its operations and reports of record orders for wind turbine equipment this year.
The company also announced plans to invest some 200 million dollars in Mexico over the coming decade, which according to Chairman Joe Kaeser will create 1000 jobs.
It’ll be interesting to see if the equipment will be exported from Mexico and into the United States.
Share this...FacebookTwitter "
"The main drivers of species extinction are habitat loss and human-wildlife conflict, but it still takes a lot for these events to hit international headlines. They did recently, however, when the world famous Marsh Pride lions were allegedly poisoned by Maasai tribesmen.  These lions were the stars of the BBC’s Big Cat Diary TV series and a popular tourist attraction in the Maasai Mara National Reserve in Kenya. At least two lions were reported to have been killed and two local men have been arrested and could face life imprisonment if found guilty of harming them. The motive given was retaliation. It is thought that the men’s cattle had been grazing in the park the day before and were killed by lions. It was then easy to poison the carcass, knowing the lions would return to the kill.  Unfortunately though, this is not a rare event. People kill wildlife for similar reasons throughout this part of Kenya. My work on the western border of the Maasai Mara has recorded over 500 examples of crop raiding by elephants in the last two years. This led to at least two elephants being killed in retaliation last year alone. These acts are often heavily criticised by foreigners and city dwellers but sharing land with wildlife is not easy. Many of the people are poor and feel powerless when animals eat their crops or livestock. These feelings then turn to animosity towards wildlife when their concerns are ignored. So, the illegal and ruthless killing of the Marsh Pride lions sends a clear message that conservation in the Mara ecosystem is working neither for wildlife nor people. Part of the problem is human population growth. Kenya’s population size has tripled in the last 50 years and people’s lives are changing. In the Mara ecosystem many Maasai people are shifting from being pastoralists to farmers. They are converting their land to crops but still have strong economic and cultural links to cattle herding. This spread of farming reduces natural habitat and increases elephant crop raiding. It also reduces pasture land, so many people now take their cattle into the Maasai Mara Reserve. The fact that so many cattle are illegally grazing in the reserve shows that conservation management is also currently weak. Just as significantly, it also shows that many communities around the Maasai Mara Reserve do not see any benefits from the wildlife it contains. This is despite the law stating that these people should receive a percentage of the reserve revenue each year. At the moment, almost none of this money goes into the pockets of the poor, despite the land originally belonging to the Maasai before it was taken for conservation. Solving these problems can only happen with action at a higher level. A key component is better spatial planning that incorporates the needs for conservation. Potential options could involve zoning the landscape, so areas are set aside for settlements and farming but also for livestock and wildlife. In particular, we need to ensure that key wildlife areas and corridors are protected through effective management and enforcement. Finally, we need to improve park revenue sharing. It seems crazy that someone makes more money from growing a field of maize, or keeping a small herd of cows, than by living next door to one of the world’s most famous conservation areas. The poisoning of the Marsh Pride lions is indeed shocking but it is nothing new in the Maasai Mara or other parts of the world. Human-wildlife conflict is a grim reality which poses graver threats than many people realise. The story highlights an escalating problem but there will be many more “Marsh Pride” lion incidents unless we come up with long-term solutions."
"Do you walk the walk, or just talk the talk? Can you put your money where your mouth is, or are you all mouth and no trousers? According to a new study it seems that it’s mouth or trousers – we can’t have both.  In the animal kingdom evolution often provides males with beefy bodies, sexual weaponry such as big teeth, horns or antlers, or bold colours in order to attract a female’s attention and out-compete rivals. But as females often mate with multiple partners, males also need to generate numerous fast and healthy sperm to ensure that they are the most likely to sire offspring. So males are left facing competing demands, between finding a mate and fertilising eggs.  The problem is that these traits are costly, so males may be unable to invest in both.  There is evidence to suggest that species do face these “trade-offs” over reproduction, where it’s impossible to improve one trait without detracting from another. For example, in humans it’s thought that there may be a trade-off between growth and reproduction in women. Women who go through puberty earlier, or have children at an earlier age, are shorter as adults.  Similarly men may face a trade-off between investing in reproduction or resisting diseases. Those with higher levels of testosterone have been shown to have weaker immune responses. The same trade-off between investment in either bigger bodies and sexual weaponry or bigger testes and genitals is found in other animals, such as seals and sea lions, dolphins and whales, and many other birds, primates, ungulates and even insects. In a new study, published in Current Biology, we were interested in examining this evolutionary trade–off in howler monkeys. These monkeys, of which there are ten species distributed from Mexico to Argentina, live in a wide range of habitats and show big differences in social organisation.  Howler monkeys are among the loudest animals on the planet, yet they weigh just 7kg – about the size of a small dog, and lighter than a big Christmas turkey. They produce powerful, low frequency calls using a highly modified larynx, with extremely long vocal folds and a greatly enlarged cup-shaped hyoid bone. In most animals the hyoid is a very small, horseshoe-shaped bone that sits in the neck above the larynx and supports the tongue, but in howler monkeys it has evolved to become a large resonating chamber to amplify their roars. These evolutionary adaptations allow howler monkeys to produce extremely loud and incredibly low-frequency calls like those produced by animals ten times their size.  Remarkably, there is a huge amount of variation in the size of the hyoid bone among the howler monkeys species. Our new research aimed to try and describe this variation quantitatively, as well as understand both the evolutionary pressures that led to the observed variation, and the acoustic consequences of having large versus small hyoids.   We found that among males, hyoid volume varied widely among species – in fact the largest hyoid was 14 times the size of the smallest. We also found a large amount of variation in the size of the testes among species, with the largest testes 6.5 times bigger than the smallest. Overall, species living in small groups in which there tends to be just one male tended to have extremely large hyoids and very small testes. Those living in large groups, with many competing males, tended to have very small hyoids and very large testes. So it seems that males either invest in one reproductive trait or the other, but not both. We studied the acoustics of the howler monkey’s roars and found those with larger hyoids produced lower frequency roars that made them seem much bigger than they really are. Presumably this is important in those species where it’s common for a single male to reign over a harem of females, and needs to scare off rivals. In species where there are many males living in mixed groups there is perhaps less need for such vociferousness, but on the other hand the males need to produce more and faster sperm.  This is the first known example of a trade-off between investing in vocalising and increased sperm production, which opens the door to many other potential studies on the trade-offs between sexually-selected traits. It’s hard to say exactly how the trade-off works. Developing a large vocal organ and roaring may be so costly that there is simply not enough energy left to invest in testes. Alternatively, such a roar may be so effective at deterring rival males that there’s no need for capacious, hard-working testes to generate large amounts of quality sperm.  So it seems that, in howler monkeys at least, males are either all mouth and no trousers, or all trousers and no mouth. When it comes to sex and reproduction, evolution says you can’t have it all."
"The UN climate talks in Paris have ended with an agreement between 195 countries to tackle global warming. The climate deal is at once both historic, important – and inadequate. From whether it is enough to avoid dangerous climate change to unexpected wins for vulnerable nations, here are five things to help understand what was just agreed at COP21. The most striking thing about the agreement is that there is one. For all countries, from superpowers to wealthy city-states, fossil fuel-dependent kingdoms to vulnerable low-lying island nations, to all agree to globally coordinate action on climate change is astonishing.  And it is not just warm words. Any robust agreement has to have four elements. First, it needs a common goal, which has now been defined. The agreement states that the parties will hold temperatures to “well below 2°C above pre-industrial levels and to pursue efforts to limit the temperature increase to 1.5°C above pre-industrial levels”. Second, it requires matching scientifically credible reductions in carbon dioxide and other greenhouse gas emissions. The agreement is woollier here, but it does state that emissions should peak “as soon as possible” and then be rapidly reduced. The next step is to: Achieve a balance between anthropogenic emissions by sources and removals by sinks of greenhouse gases in the second half of this century, on the basis of equity … Third, as current pledges to reduce emissions imply a warming of nearly 3°C above pre-industrial levels, there needs to be a mechanism to move from where countries are today, to zero emissions. There are five-year reviews, and “the efforts of all parties will represent a progression over time”, which means at each step countries should increase their levels of emission cuts from today’s agreements. Finally, this all means developed countries need to rapidly move from fossil fuel energy to renewable sources. But the challenge is larger for the developing world: these countries must leapfrog the fossil fuel age. They need funds to do so and a key part of the agreement provides US$100 billion per year to 2020, and more than that after 2020. There is a lot to like about this agreement: it gives a common goal to avoid the worst impacts of climate change, the overall emissions cuts stated are reasonably credible, there is a mechanism to increase national emissions cuts over time towards “net zero”, and there is funding secured to help poorer countries harness the power of the sun, wind and waves instead of coal, oil and gas. It provides a roadmap to get the world off its dangerous addiction to fossil fuel energy. What constitutes dangerous climate change is different for different people. For some poor people climate change is already beyond dangerous, it’s deadly. The threats escalate as the cumulative emissions of carbon dioxide in the atmosphere increase. Because this deal has been so long in arriving, the window of opportunity to limit temperature rises at 1.5°C is closing fast; this spells trouble for many low-lying areas. Even the most ambitious pathways to zero emissions in the coming decades for a carbon budget associated with a reasonable (66%) chance of keeping 2°C above pre-industrial levels are extremely challenging. Countries have a long way to go to get to these levels of reductions. Importantly, there are no penalties, except public shaming, for countries that do not meet their commitments to reduce emissions. To implement this deal the public, civil society organisations, opposition parties in politics and businesses will need to keep government policies in check. Essentially, it is the will of the people, most governments and enlightened businesses, pitted against the deep pockets of the fossil fuel industry. One future fear is that when the “global stocktake” happens in 2023, some countries may see that others aren’t doing their bit, and may themselves then stop reducing emissions and the agreement will fall apart.  The warming we see from greenhouse gas emissions is dominated by the cumulative emissions of carbon dioxide. Given the emissions so far, limiting warming to “well below” 2°C, and anywhere near 1.5°C means reducing CO2 emissions to near zero extremely quickly.  Then society will need to continue further, to negative emissions. That is, removing carbon dioxide from the atmosphere and storing it somewhere else. There are various options here, from planting trees and keeping restored forest in perpetuity, enhancing uptake in soils, or using biomass energy in power plants then storing the carbon dioxide underground (so-called Bio-Energy with Carbon Capture and Storage). Expect to hear a lot more about this. To get to zero emissions this century requires many policy changes. Fossil fuel companies must have their subsidies stripped. Investments in high-carbon emitting infrastructure must end, particularly World Bank loans and other regional multilateral bank support for countries. Zero emissions buildings will become the norm. Tropical forests will have to be protected to reduce and then eliminate deforestation.  Expect a greater push on the technological limitations on renewable energy, with big new investments, mostly improving how to store power, for when the wind is not blowing and the sun is not shining. Expect the cost of renewables to sink much further as these technologies are scaled up and implemented worldwide. Expect significant areas of the world to be given over to wind turbines and solar farms. Paris was a high-stakes game of geopolitical poker. Surprisingly, those countries with the poorest hand came out better than expected. The climate talks were subject to a series of shifting alliances going beyond the usual income-rich northern countries and income-poor global south countries. Central to this has been US-Chinese diplomacy, both agreeing to limit emissions, and more recently the new Climate Vulnerable Forum grouping of countries. From nowhere, the forum has forced keeping global temperatures to 1.5°C high on the political agenda.  We haven’t heard the last of this level of ambition – one of the decisions in the Paris agreement is to invite the Intergovernmental Panel on Climate Change to produce a special report on the impacts at 1.5°C, and emissions pathways consistent with this level of warming.  These countries didn’t get everything they wanted – the US would not accept liability in financial terms for states that may lose their territory to rising sea levels in the future. But they played their hand extremely smartly."
"The Labour party is reeling from a devastating election defeat in which many of its traditional voters turned their backs on the party. If it is to rebound, Labour must take the time to understand what went wrong. And its analysis must go beyond the defenders of Jeremy Corbyn arguing that it was solely down to Brexit, and his detractors pinning all the blame on the leader and “Corbynism”. It is also likely that the election result reflects a much longer and deeper trend, in which the party has lost the trust of communities it has long represented yet who have now lost faith in the political system to change their lives for the better. Without a radical policy platform Labour stands no chance of winning back voters Whatever the final verdict, the Labour party will have to change if it is to reconnect with the broad coalition of voters it needs to win back power. But as it does this, it must not lose sight of the one thing it got right in this election. Labour was right to grasp the scale of the economic and environmental challenge the country faces and offer ambitious solutions. Against the backdrop of the longest squeeze in living standards for generations, economic growth that has passed many communities by, entrenched poverty and a climate emergency, Labour offered a manifesto that began to rise to the challenge. It contained flaws, but it would have undoubtedly begun the process of transforming our economy. Those eager to reject Corbyn would be wrong to abandon this ground as well. But Labour must learn from this election. Policies that all the polling indicates are individually popular with voters simply did not cut through: 64% of people support significant increase in public spending to invest in the green economy; 66% believe companies should be required to share their profits with employees; and 61% believe that austerity has damaged vital public services. The manifesto should have resonated with many voters and yet it didn’t. In part, this was because an ambitious reform agenda was presented as a collection of giveaways that felt too good to be true. A 10-year economic agenda was shoehorned into a five-year programme for government and voters rightly questioned whether it could all be delivered. There was no attempt to prioritise or highlight key policies. And not enough groundwork was done in advance of the campaign to convince the public that this scale of change was not only desirable but deliverable.  Critically, too much of the change that Labour sought to achieve was top-down. Rather than pushing power out to communities, it sought change through an expanded national state with regional offices. The absence of a radical agenda on devolution was a striking omission in the manifesto. An ambition to democratise the economy too often boiled down to state ownership through renationalisation. For communities distrustful of promises from Westminster, Labour failed to tell the story of how it could deliver radical change by giving them more power and control. As Labour dissects what went wrong, the factions defending and attacking Corbyn must learn these lessons and build from here. Abandoning Labour’s entire policy programme – as some of those who reject Corbyn wish to – and replacing it with an agenda that seeks incremental changes to the status quo would be a big mistake. There is clear political consensus that for too many people the economy just isn’t working, and also that the threat of the climate crisis is real and imminent. Future elections will be fought and won on who has the answers to these seismic issues. Without a radical policy platform Labour stands no chance of winning back voters who despair of a system that is failing. But Labour’s response must be rooted in the people whose lives it seeks to change. The next election will be fought after we have left the European Union and the promise to “get Brexit done” has inevitably but tragically failed to deliver the positive change those who voted for it want. All the issues that are bubbling underneath the Brexit vote will have punched through the surface – as will the anger and frustration of millions who will feel let down. If Labour can go into that election having done the groundwork, and with a manifesto that offers real change, it may just find a route back to power.  • Miatta Fahnbulleh is chief executive of the New Economics Foundation"
"The revelation that Volkswagen deliberately circumvented emissions tests on many of its diesel vehicles has provoked a huge storm of controversy. This diesel deception has understandably angered car owners. And some have suggested that VW’s management either must have known about the scandal, or effectively lost control of the company. The allegations are severe. According to the Environmental Protection Agency, VW deployed a “defeat device” enabling its cars to meet emissions standards under official test conditions, even though they can release up to 40 times the legal level of nitrogen oxides (NOx) under normal driving conditions. Worse was to come though. VW went on to admit that 11m vehicles worldwide had been fitted with the device. An analysis by the Guardian puts the collective impact of this number of cars at nearly one million additional tonnes of air pollution per year. In the EU, it increasingly seems that there is more to this scandal than car manufacturers using underhand tactics to “hotwire” official emissions tests. Leaked documents have revealed that three powerful member states – the UK, France and Germany – have all recently lobbied for the inclusion of loopholes in a new emissions test planned for roll-out in 2017. Germany, it seems, even called for this new test to be conducted on a sloping downhill track. In Brussels itself, my own conversations with EU officials have exposed a tendency to accept carmakers’ behaviour as an unavoidable part of the regulatory “game”. On more than one occasion I have heard the argument that what vehicle manufacturers are doing can’t really be classed as cheating, because – after all – wouldn’t any rational economic actor seek to “exploit the flexibilities” in this kind of regulatory test to their advantage? All of this should give us serious pause for thought. Circumventing an emissions test is one thing. But if member states are actively calling for Brussels to enable the continuation of this behaviour, and EU officials themselves see it as a natural part of the “game”, then we must ask who – if anybody – is left to represent the interests of the public, or indeed the climate, in the development of the EU’s environmental agenda. The scandal in fact reveals deep-seated pathologies in the way the EU’s environmental policies are made. It is, crucially, the EU’s privileging of “expert”, industry-generated data on these emissions, produced by a supposedly objective, repeatable test, that has allowed VW to deceive its customers and the wider public. Yet these are the same industry experts who stifle debate about the sustainability of petrol and diesel carmakers’ contributions to the EU’s economy. This, even as Europe faces growing crises of urban air pollution, obesity, and of course climate change. Meanwhile, on-the-road emissions data, such as that painstakingly assembled by the International Council on Clean Transportation, is all too often dismissed as unscientific, and open to the corrupting influences of a messy and complex “real world”. These data are effectively crowdsourced from thousands of drivers and other road users, many with an economic interest in averting the depreciation of their vehicles. And it is these road users – and the wider public at large – who have no choice but to subject themselves to urban air pollution across Europe.  According to a recent Transport & Environment report, this “invisible killer” leads to 500,000 premature deaths a year. And diesel vehicles are the principal cause of those deaths. VW’s diesel deception doesn’t just point to an urgent need for a better vehicle emissions test; it highlights the requirement for a more open and inclusive approach to dealing with environmental problems in Europe. As the EU seeks to address and move on from this scandal, Brussels must break the stranglehold exerted over its vehicle pollutant emissions legislation by an inner circle of hubristic industry experts. Instead, it must embrace the ideas, concerns and knowledge of those who most suffer in the face of air pollution – the European public."
"The 2015 Paris Climate Conference (COP21) is in full gear and climate change is again on everyone’s mind. It conjures up images of melting glaciers, rising sea levels, droughts, flooding, threatened habitats, endangered species, and displaced people. We know it threatens biodiversity, but what about linguistic diversity?  Humans are the only species on the planet whose communication system exhibits enormous diversity. And linguistic diversity is crucial for understanding our capacity for language. An increase in climate-change related natural disasters may affect linguistic diversity. A good example is Vanuatu, an island state in the Pacific, with quite a dramatic recent rise in sea levels. There are over 7,000 languages spoken in the world today. These languages exhibit enormous diversity, from the number of distinctive sounds (there are languages with as few as 11 different sounds and as many as 118) to the vast range of possible word orders, structures and concepts that languages use to convey meaning. Every absolute that linguists have posited has been challenged, and linguists are busy debating if there is anything at all that is common to all languages in the world or anything at all that does not exist in the languages of the world. Sign languages show us that languages do not even need to be spoken. This diversity is evidence of the enormous flexibility and plasticity of the human brain and its capacity for communication. Studying diverse languages gives us invaluable insights into human cognition. But language diversity is at risk. Languages are dying every year. Often a language’s death is recorded when the last known speaker dies, and about 35% of languages in the world are currently losing speakers or are more seriously endangered. Most of these have never been recorded and so would be lost forever. Linguists estimate that about 50% of the languages spoken today will disappear in the next 100 years. Some even argue that up to 90% of today’s languages will have disappeared by 2115.  There are many reasons why languages die. The reasons are often political, economic or cultural in nature. Speakers of a minority language may, for example, decide that it is better for their children’s future to teach them a language that is tied to economic success. For example, the vast majority of second-generation immigrants to the United States do not speak their parents’ languages fluently. It is economically and culturally more beneficial to speak English.  Migration also plays a large role in language change and language death. When speakers of Proto-Indo-European migrated to most of Europe and large parts of Asia between 6,000 and 8,000 years ago, they probably brought about massive language change and language death. In Western Europe, Basque could possibly be the only modern language that survived the influx of the Indo-Europeans.  In the coming centuries, we may experience an increase in climate-related migration. It is already clear that climate change influences modern migration patterns. Climate-related disasters displaced an estimated 20m people in 2008.  The areas affected by climate-related disasters are often ones that exhibit great linguistic diversity and include languages with small numbers of speakers, which are especially vulnerable. The threat facing islanders in Vanuatu is not just due to rising sea levels.  Recent tectonic movements have also caused parts of some islands to sink. As a result, a whole coastal village had to be relocated further inland from 2002 to 2004. This prompted a 2005 United Nations Environment Programme press release to call these villagers the world’s first climate change refugees. These climate change refugees happen to be living in a country that has one of the highest levels of linguistic diversity in the world.  Vanuatu is the third most linguistically diverse country in the world, as measured by the Greenberg index. The index shows the likelihood that two randomly selected speakers in a country have different native languages. Vanuatu’s Greenberg index is a staggering 97.3%. Vanuatu has 110 indigenous languages spoken in an area of about 15,000 square kilometres (about 6,000 square miles) – that’s about one language for every 136 square kilometres. Half of the languages spoken on Vanuatu have 700 speakers or less.  Some of the countries affected by the earthquake and tsunami that killed about 230,000 people in 2004 are also very linguistically diverse. India has 447 indigenous languages and a Greenberg diversity index of 91.4% and Indonesia has 706 indigenous languages and a Greenberg diversity index of 81.6%.  Researchers had just discovered the Dusner language, which had only a handful of remaining speakers, when flooding in 2010 devastated the Papua region of Indonesia, where the Dusner village is located. Luckily, some of the speakers had survived, and the language could be documented. Often, we do not know precisely what effect natural disasters have on the languages spoken in affected areas. What we do know though is that environmental pressures increase mobility and migration and that migration affects language change and death. A further increase in climate-related disasters may further accelerate the disappearance of languages. This would be a tragic loss not just for the people and cultures involved, but for cognitive science as well."
"When I think about 2019, there is one scene that springs to mind, something that sums up the milieu so perfectly that it almost seems art-directed. There we were two weeks ago at Rose Bay on the water’s edge, waiting for a private boat to take us to a harbourside mansion for a wine tasting. It was one of those days when Sydney’s air quality was among the worst in the world. The boat emerged from the pea soup gloom with the words “VIP” on the side. We were all in our party dresses and chunky trainers, phones fully charged to maximise the Instagrammable location, only coughing a little bit although peoples’ eyes were red and I noticed some fellow guests pulling on Ventolin inhalers. Influencers posed by the swimming pool, seeing but refusing to see – this red-raw sun, that dirty brown sky At the mansion there was a DJ, sommeliers and a chef, who explained in great detail the origin of the scallops on the canapes and a recent, inspirational trip to Oaxaca. Later there was a wine tasting where we gathered around to swirl and spit. Every varietal had notes of bushfire. Various people wandered up to us and said “great day for it!” and “beautiful weather” without irony. How could they say that? The sun was (there was only one word for it) demonic, a burning red eye in a thick smoky sky. The Sydney Harbour Bridge and the Opera House were out there … somewhere, obscured in a brown haze. We stood near the pool, eating tiny food, drinking wine from large balloon glasses while ash flew from the sky, some of it landing in my drink. The DJ played on but the tunes – Tones and I, Mark Ronson – were nervy, jangly and strangely discordant. The smell of the smoke had an almost chemical taint, and in between trying the pinot and moving on to the tempranillo, I wondered about the alchemy at work in this commingling of the elements: the ancient forests and its animals turned to columns of ash, collapsed and drifting through the air, settling on the water and soil; and later in and on my body after swimming in the dirty sea that morning and now swallowing particles of ash floating in my wine at the party on the harbour’s edge. (“At the end of the world,” my friend and I nervously joked.) More wine was poured and more people commented on the great weather (except for a sommelier who confessed sotto voce that he felt afraid), and influencers posed in the gloom on the jetty and by the swimming pool, seeing but refusing to see what was all around them: this red-raw sun, that dirty brown sky. The cognitive dissonance would have been funny had I not been so scared. It brought to mind F Scott Fitzgerald, a writer who understood more than most that decadent parties prefigure societal collapse. Had his novel The Great Gatsby been written now, the scene that day in Point Piper would not be out of place. Returning to shore in the haze, we could have been excused for thinking we were crossing the Styx – the mystical Greek crossing into the Underworld – and in this heightened state the day seemed more than the sum of its parts. Instead it served as both an elegy for the lost world that had disappeared beyond the haze and a portent of the world to come. Sign up to receive the top stories from Guardian Australia every morning That is what 2019 has come to mean to me: not the landslide elections and the global protests and Fleabag season 2. But the year some undeniable bomb dropped and dispersed its truth all around us in the form of dark particles in the air that didn’t just sit around us – but entered our bodies in unholy communion, its fine matter an anti-sustenance that made us sick and afraid. The truth bomb came in various forms: in the form of a girl (Greta Thunberg) whose eloquent rage finally caught the world’s attention and inspired millions around the globe to strike for climate action. The truth also came in the form of heat, smoke and fire. Even then, some people tried to ignore it. Ernest Hemingway had this famous line from his 1929 book The Sun Also Rises, which speaks to me of where things washed up in 2019: “How did you go bankrupt?” Bill asked. “Two ways,” Mike said. “Gradually, then suddenly.” 2019 is the year of suddenly. Many of us were shaken awake from our cognitive dissonance this year as our weather patterns and climate conditions become ever more extreme. When wine turns to ash in your mouth, you can’t deny the new reality anymore. Yet some still live in a land of cognitive dissonance: the lump of coal brought to parliament; the haze over the city obscuring the flashing Christmas lights; dead bats falling from the sky because their sophisticated and highly evolved sonar systems are overheating and confused; beekeepers being traumatised and needing counselling after hearing the sounds of animals screaming as they burn to death; new types of megafires devouring entire ecosystems; the NSW premier opening a new zoo during these megafires with a commitment to “protecting wildlife”; and the prime minister disappearing without a word about the climate catastrophe – last seen boarding a business-class Jetstar flight bound for Hawaii; the Instagrammers posing on the jetty under the eye of Sauron, hoping that with the right filters, we can pretend the sky is blue. Cognitive dissonance is natural – it can make you feel safer, like the world is a more orderly, stable place than the reality, which is chaos. The end of this year makes me wonder how much during the years prior we have been engaged in unintentional acts of disassociation and dissonance. Maybe we had to, to survive the barrage of nonstop news – the dozen major scandals that emerge each week from Trump’s White House, the way that Brexit is important, boring and confusing all at once. It’s all too much so we just disassociate. It’s no wonder the hot illegal drug of 2019 – ketamine – is an anaesthetic, numbing your body and making you feel separate from your environment. People disappear, aptly, into the k-hole, the chemical equivalent of our political situation. “Like you’re watching your own life happen instead of living it,” said New York magazine, calling it “the party drug for the end of the world”. But 2019 was in many ways, for many of us, Year Zero. It was the year many of us stopped disassociating, woke up and realised the party is over."
"UK banks and insurers will be forced to reveal how exposed they are to the climate crisis and how they would respond to the effects of a temperature rise of up to 4C under the Bank of England’s first climate stress tests. The Bank has put forward proposals to test the performance and health of the UK financial system for a range of climate-linked financial risks, including the failure of governments and consumers to take action. The tests are expected to uncover the extent of the financial sector’s exposure to climate risks, and gauge company responses that could cause spillover effects for the global economy. However, the Bank will not identify individual businesses through the tests and will release only aggregate results for the banking and insurance sectors. Threadneedle Street has, however, not ruled out releasing individual results in the future, and plans to use the initial reports to inform how it supervises each company. The tests, to be released for the first time in 2021, will cover the same UK banks subject to financial stress testing, including HSBC, Barclays, Standard Chartered, Royal Bank of Scotland, Santander UK, Lloyds and Nationwide. By 2021, CYBG – rebranded as Virgin Money – will also be included. About 39 insurers are expected be tested on their climate resilience. The testing will cover three scenarios, including “early policy action”, where the transition to a carbon-neutral economy is clear and decisive, resulting in the global temperature rise staying below 2C, in line with the 2015 Paris climate agreement. In a second “late policy action scenario”, global climate targets will also be met, but the transition will have been delayed by 10 years, leading to more drastic and immediate action that could cause an economic shock. In the final scenario, governments fail to introduce policies to address the climate emergency, and companies and consumers do not change their behaviour. Global temperatures increase “substantially” – by about 4C – by 2080, resulting in rising sea levels and more frequent, extreme weather events such as flash floods. Drastic environmental changes around the world would damage property, infrastructure and farmland, disrupt business supply chains, and lead to mass migration and deaths, the Bank said. “This reduces asset values, results in lower profitability for companies, damages public finances and increases the cost of settling underwriting losses for insurers,” it said. Spillover effects such as lower output and productivity would compound those problems. The environmental risks of climate change are already affecting financial companies in the UK, with about 10% of domestic mortgages exposed to properties in flood-risk zones. Some British banks are also exposed to regions extremely vulnerable to climate change, such as south-east Asia. Countries along the equator are expected to be uninhabitable for much of the year due to high humidity under a 4C-rise scenario. If temperatures increase to that level, rising ocean acidity would wipe out coral reefs, shellfish and plankton, starving the oceans of oxygen and leading to a decline in sea life, environmental experts have warned. Saharan deserts are expected to expand into southern and central Europe, while the vast majority of the global population would have to migrate to northern regions, where farming would be viable. According to a study by Solomon Hsiang and Edward Miguel of University of California, Berkeley, and Marshall Burke of Stanford University, unmitigated global warming would lead to a 23% loss in per capita earning globally by the end of the century. The Bank’s proposals will go out for consultation until March and it is requesting feedback from financial companies, climate scientists, economists and other industry experts. The Bank’s governor, Mark Carney, said the tests were a “pioneering exercise, which builds on the considerable progress in addressing climate-related risks that has already been made by firms, central banks and regulators. Climate change will affect the value of virtually every financial asset.” He added that the tests would “help ensure the core of our financial system is resilient to those changes”. Carney is taking on the role of UN special envoy for climate action and finance after he steps down from the Bank next month. His main focus will be on mobilising private finance to invest in schemes that will help achieve the Paris goal of limiting global temperature rises to 1.5C."
"
Share this...FacebookTwitterTranslated/edited from wobleibtdieerderwaermung.de. 
A huge hole in the magnetically hot corona of the sun in the coming weeks will lead to a powerful solar wind and initiate hefty polar lights in the earth’s magnetic field. This will be a brief pause in the solar activity slumber that has taken hold over the past year and thus allowed cosmic rays to penetrate almost freely into the earth’s atmosphere.
NASA writes: BIG CORONAL HOLE TURNS TOWARDS EARTH!

“Coronal holes are places–big places–where the sun’s magnetic field opens up and allows solar wind to escape,” NASA writes. “A wide stream of solar wind flowing from this coronal hole is expected to reach our planet on March 23rd. The impact of the solar wind should produce magnetic activity around Earth’s poles and could spark the first auroras of northern spring.“  Source NASA.
In the HMI magnetogram the coronal hole today appears as a large dark spot on the left side (east side) of the sun and over the coming days as the sun rotates (Bartel’s Rotation) will be aimed at the earth, see the following image:

HMI magnetogram from March 17, 2017 shows a large dark hole with little magnetic activity on the sun’s surface (CH/Coronal Hole). As the sun rotates the coronal hole will be aimed at the earth and a large solar wind of electrically charged solar plasma will strike our planet. Source: sohowww.nascom.nasa.gov/sunspots/
Even though there have not been any solar sunspot activity in 2 weeks, meaning galactic cosmic rays (GCRs) have been easily reaching into the earth’s atmosphere. Now these galactic cosmic rays will be deflected away temporarily from the earth by the expected powerful solar winds.

The SILSO chart from March 17, 2017 above shows the daily solar sunspot count over the past 30 days. In early March there was a plummet from 55 to zero on March 4 and March 6-17. The month’s average (blue line) has fallen below SN 10. Source: sidc.oma.be/silso/home
Whether this results in a so-called Forbush event, where a strong fall in high energy cosmic rays such as the sort of a solar eruption, coronal mass ejection(CME), remains to be seen.
The impacts can be monitored daily using the Finnish University’s OULU which measures galactic cosmic rays (GCR).


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Because of the unusually weak solar sunspot beginning in 2016, GCR intensity has increased significantly:

The above Oulu plot shows the daily strength of galactic cosmic rays (GCR) as a percent of mean value from January 2015 until March 17, 2017, top right. Due to the increasingly weaker solar sunspot activity galactic cosmic rays has increased significantly since 2015. The temporary large drop in June 2015 was caused by a so-called Forbush event, where powerful solar winds shielded the earth from cosmic rays. Source: cosmicrays.oulu.fi/
Wikipedia describes “Coronal Holes“:
Coronal holes are areas where the Sun’s corona is colder, hence darker, and has lower-density plasma than average because there is lower energy and gas levels. Coronal holes are part of the Sun’s corona and are constantly changing and reshaping because the corona is not uniform. The Sun contains magnetic fields that arch away from areas in the corona that are very thin due to the lower levels of energy and gas,[1] which cause coronal holes to appear when they do not fall back. Thus, solar particles escape at a rate great enough to create a lower density and lower temperature in that area.”

In the areas designated by A, the magnetic flied lines are closed and trap the plasma of the corona. In the area designated B (coronal hole) the magnetic flied lines extend out into space and plasma can escape.“ Source: Coronal Hole, Sebman81, CC BY-SA 3.0.
The shielding of the earth against cloud-initiating cosmic rays during the solar winds coming from the coronal hole will however be only temporary. Recall that CERN measured that cosmic rays enhances cloud formation by to 100 times.
The solar minimum of 2019/20 will bring extra cosmic rays, pink auroras, and much more.

“Dec. 26, 2016: Christmas Day 2016 brought a fantastic display of auroras to the Arctic Circle. A great many of them were pink. James Helmericks sends this picture from the Colville River Delta in northern Alaska.“ Source: pink auroras.
We will continue to watch how long the sun continues its sunspot strike, excluding coronal holes, as was the case in February 2017: Eastern Limb of Sun Feb 18th and 19th 2017 – YouTube.
Yours, Schneefan2015
Share this...FacebookTwitter "
"We tend to assume that travel today is fundamentally different from what it was half a century ago. We have easier access to faster forms of transport, and we expect to be able to move quickly and easily whenever we wish. But a recent overview of travel behaviour in England – celebrating 50 years of data from the National Travel Survey (NTS) – shows that while some things have certainly changed, much remains the same.  According to the authors of the report, the most striking change to our travel habits is that “we are travelling further but not more often”. In other words, though the individual trips we take are longer in terms of distance, the number of times we travel has remained much the same over the past 50 years. What’s more, there has been little change in the total time spent travelling, due to faster travel speeds. And the purposes of our trips have changed only slightly: the biggest change has been an increase in the number of journeys we take to escort others.  Predictably, we’ve seen an increase in car use, as a result of their greater availability and affordability. This has been accompanied by a decrease in travel by bus and bike. None of these trends will be surprising to anyone who has thought carefully about the nature of everyday travel in Britain. But if we dig behind the survey data, some less obvious patterns and trends are revealed. Although the NTS is an unparalleled set of data, even this has its limitations. As the authors recognise, walking trips tend to be under-recorded, and it is not possible to gain fully comparable data on walking as a means of everyday travel over the full 50 years. What is clear, however, is that our feet remain one of our most important forms of transport.  In 2014, according to the survey, 22% of all trips were made on foot, and walking constituted 76% of all trips under one mile. Though we walk less than we did in the past, travel on foot remains an important means of travel – but one that tends to be neglected in both official statistics and transport planning. All too often, the needs of the pedestrian are ignored.  And while there may not be data available beyond the 50 years covered by the NTS, it is possible to gain some insights into even longer-term travel trends by using oral history and survey techniques. Research using these methods suggests that the distance and time spent travelling has remained reasonably stable over the last century, and perhaps beyond.  Historically, most trips were over short distances, and the time that people have been willing to commit to travelling has remained much the same. Obviously faster forms of transport, especially the private car, have allowed longer distances to be covered, and there are more very long journeys than in the past, but for most people, most of the time, everyday travel takes place relatively close to home. Why have travel trends remained so similar over long periods of time? Answers to this question almost certainly lie in the nature of society and human relationships: something that cannot be revealed by statistics. In essence, human societies across the ages seek to fulfil certain aspirations: to provide income, food and shelter; to be near and protect family; to socialise and to be with friends. Most of these needs and aspirations can be met close to home, and therefore shape our travel behaviour.  Certainly, as families have become more dispersed and labour mobility has increased, this has led to some people making ever longer journeys. But most of us are still able (and indeed prefer) to fulfil most of our everyday needs close to home.  One other aspect that statistics such as the NTS cannot reveal is the experience of travel. What is it like to travel today and how has this changed over time? Arguably, this is one area where there has been significant change. The advent and widespread use of the private car has meant that comfortable, convenient and private transport has become the norm for most people.  A century ago, only an elite could travel privately and in relative comfort, with most using shared space on various forms of public transport. For those who walk or cycle, the experience of travel will have changed less, though increased traffic has probably made the experience less pleasurable for many.  Half a century of the NTS reminds us of the importance of travel in our lives, and challenges assumptions that everyday mobility has changed dramatically over time. But it also shows us that, when it comes to what’s important to us, some things never change."
"The final days of climate negotiations in Paris will hopefully see an agreement to seriously tackle global emissions. But haven’t we been here before? Declarations from previous climate summits promised so much but, in truth, delivered so little. We have to reduce our dependency on fossil fuels and, 25 years on from Kyoto, the longer we leave it the harder it will get. Paris should be viewed as our last hope. Part of the problem though is how to get politicians to deliver on their words when they return home and face very imminent and daily domestic challenges. How could we enforce a voluntary agreement? Here are three proposals that might work: There have been lots of international environmental treaties, but only one had effective sanctions: the Montreal Protocol, signed in 1987 to reduce the use of CFC gases which were causing a hole in the ozone layer. These days, the ozone layer is on the mend. CFCs used in refrigerators or aerosol cans were replaced with HFCs, a group of related gases that don’t harm the ozone (though they still add to the greenhouse effect). Montreal worked because it enshrined trade sanctions against those countries that did not join and also against members that did not comply with their obligations. Trade sanctions were imposed on all goods which used CFCs in production or released CFCs during consumption. Of course, using this idea as a blueprint for the enforcement of carbon targets is inherently more difficult. All goods require energy for production and hence release greenhouse gases. There’s no simple switch to low-carbon production. Trade sanctions would have to be imposed on all goods and services that are produced by a country which does not become a member of a climate agreement. A trade war could ensue. How realistic it would be to impose such sanctions against the US for instance, if it didn’t join a climate agreement? In the case of the Montreal protocol this was much easier as America was in fact an initiator and driving force. This is less clear for Paris. Countries who signed up to a Paris climate agreement could impose a tariff on all imports produced in countries with higher greenhouse gas emissions. This is known as a “border tax adjustment”. Non-members could no longer benefit from a kind of eco-dumping at the expense of members. The agreement could also be linked to development aid, another credible way to get developing countries on board. Last year US$135 billion was spent on development aid, in the form of direct payments, in-kind transfers or technology sharing. Much of this could be linked to performance under a climate agreement. Threats over aid might work against poorer countries but clearly it is much more difficult to discipline industrialised nations. There simply aren’t many credible options for deterring non-compliance. One compelling proposal is that all members contribute to a fund, a kind of deposit scheme, which would be managed by the secretariat of the climate agreement. As long as countries comply with their obligations, they receive interest payments from their deposit. If they violate the agreement, these interest payments stop and some or all of their deposit is paid out to the complying countries. This is certainly a credible threat and appeals to national self-interest. The only problem is whether members could be convinced to stump up the money in the first place. After all, the amount must be large enough – tied to national GDP – to be able be to change the behaviour of governments. Economically-speaking, such a system is appealing. But the reality is any Paris agreement will be voluntary, without sufficient financial mechanisms in place that would encourage compliance. The onus is on the big, industrialised countries to agree to ambitious pledges, and these targets need to be pegged to per capita emissions. Richer nations have to make a significant contribution to a climate fund in order to help poorer countries cope with the consequences of climate change which will – most likely – be unavoidable whatever happens at Paris. Finally, putting a proper price on carbon may not be popular with individual people who don’t want to pay more for their food, flights or heating. However collectively it makes a lot of sense. If energy is too cheap we use too much. If carbon-intensive energy is too cheap we have no incentive to develop and deploy renewables. A first (but critical) step towards that would be to stop subsidising dirty energy production."
"
Share this...FacebookTwitterThe summit of Germany’s tallest mountain, Zugspitze, located in the Bavarian Alps near the Austrian border, is 2,962 meters high and thus well isolated from any temperature data corruption sources, such as urban sprawl.

The weather station at the “Top of Germany” has measured 3°C of cooling for the month of January over the past thirty years. Photo cropped here.
The Zugspitze’s peak find itself at an elevation where global warming theory tells us the warming would really be most noticeable. However the January data over the past 30 years tell us a very different story. Instead of warming, the atmosphere at that location above Europe has been cooling, and doing so quite impressively.
Josef Kowatsch, a self proclaimed “active environmentalist and independent researcher” has crunched the data for January from Germany’s DWD National Weather Service himself and found the following for the Zugspitze station:
 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





January mean temperature at the summit of the Zugspitze over the past 30 years has plummeted over 3°C. Chart: Josef Kowatsch.
He comments that our supposedly independent media — the DPA and the AFP — have maintained that “winter has been continuously warming. But this is how the warming looks at the Zugspitze.”
Another interesting aspect about the Zugspitze is the movement of its Höllentalferner glacier. According to Wikipedia here, “the Höllentalferner reached its greatest around 1820 with an area of 47 hectares. Thereafter its area reduced continually until the period between 1950 and 1981 when it grew again, by 3.1 hectares to 30.2 hectares. Since then the glacier has lost (as at 2006) an area of 5.5 hectares and now has an area of 24.7 hectares.”
That means the glacier GREW during the 1950 to 1981 period – fully in line with the global cooling period of the 20th century, which NASA has recently been trying to fudge out. Also it tells us the retreat began well before the start of the industrial revolution, and thus natural factors are more at play.
 
Share this...FacebookTwitter "
"When the French entrepreneur Jacques Mouflier visited the remote Alpine village of Val d’Isère in 1935, he saw the future before him. “A miracle is going to happen,” Mouflier told his young son, as he gestured towards the mountains encircling the village. “Ski champions from every country will come to compete where we’re standing right now.” He was right. In 1948 Val d’Isère produced France’s first Olympic ski champion, and ever since, professional athletes have flocked to the village, which sits 1,850 metres above sea level, to train and compete. They are joined by tens of thousands of amateurs. Last year the resort sold 1.3m ski “days” to tourists, and more Britons visit Val d’Isère each year than any other ski resort in the world.  For a long time, the source of Val d’Isère’s enduring attraction – aside from its almost oppressively picturesque surroundings, five-star hotels and 300km of pistes, each one as groomed as a Surrey garden – has been that it is, in the parlance of the skiing industry, “snow certain”. Year in and year out, the arrival of the first snowfall, in mid-November, was as reliable as a Swiss watch. In 1955, when the resort began hosting an annual ski competition called the Critérium de la Première Neige (“the competition of the first snow”), its organisers boasted that Val d’Isère was the only French resort able to guarantee snow throughout December. Villagers claim to be able to predict the year’s coming snowfall by the berries on the local rowan trees. Plump clumps in summer promise deep snow in winter. For decades, the branches drooped under the berries’ weight. But in the mid-1980s, locals began to notice a change. The date of the first snowfall began to drift later. Patches of bare ground appeared on slopes that, in previous years, had been covered in an uninterrupted white drift. Some ski seasons would have an abundance of snow; others, a scarcity. More consistent was the retreat of the Pissaillas glacier, whose run-off water feeds the surrounding forests; each year it withdrew a little farther up the Pointe du Montet mountain, which dominates the jagged horizon. By 2014, snow was arriving so late to Val d’Isère that, for the first time in its history, the Critérium de la Première Neige was relocated, to a more snow-reliable resort in Sweden. For reasons scientists don’t fully understand, the Alps are warming faster than the global average. The 1.4C rise in the average global temperature since the end of the 19th century has translated into a 2C rise in the Alps. In the past hundred years, the number of hours that sunshine hits the mountains each year has increased by 20%. The heat and light cause snow to melt, or not to fall at all. In 2017 the Swiss Federal Institute for Snow and Avalanche Research recorded that less snow fell in the Alps during the winter months than in any year since 1874. In April a report by the European Geosciences Union showed that 90% of glacier volume in the Alps – an essential source of drinking water, crop irrigation and ski runs – could be lost by the end of this century. For the Alpine ski industry, which hosts 35% of the world’s ski resorts across eight countries, and serves an estimated 120 million tourists each year, this is potentially an extinction-level event. Val d’Isère is one of the mountain range’s highest resorts, so it will be one of the last to feel the full effects of the climate catastrophe. But farther down the mountains, the disappearance of snow has already begun to devastate the ski industry, as well as the communities that rely on it. Since 1960, the average snow season has shortened by 38 days, while “seasonal drift” has pushed the coldest weather from December to the early months of the year, throwing the ski season out of sync with the lucrative Christmas holidays. In November 2017 the EU launched the Prosnow project, whereby scientists advise Alpine resorts on how to “maintain the same season duration with 30% less snow”. Such efforts have not been entirely successful. According to some reports, as many as 200 ski resorts now stand abandoned across the Alps, where bankrupt hotels have been left unoccupied, and forsaken ski lifts dangle in the wind. The disaster encroaching on Val d’Isère has been obvious to Olivier Simonin, the director of tourism at the resort, since the infamous 2006-7 season, when a scarcity of snow caused a 7% decline in revenues across Alpine resorts. This September, for the first time, the French ski industry’s main union, Domaines Skiables de France, held an emergency meeting of directors from France’s most important resorts to discuss the existential challenges they face. Twenty-five directors attended the meeting, which was held in the valley of Chambéry. The mood, according to Simonin, was sombre. “This is now the main topic of conversation among us,” said Simonin. “Nobody wants to die.” Unlike the islanders of Kiribati, whose homes will be swallowed by the Pacific Ocean in the coming years, or the farmers of rural Bangladesh, whose crops fail whenever their fields are flooded by saltwater, the Alpine ski industry, which turns over billions of euros every year, is disproportionately well-equipped to fight for its survival. And resorts like Val d’Isère have invested tens of millions of euros in the most straightforward solution imaginable: when the snow stops falling, it’s time to make your own. “You need four things to make snow,” Pierre Mattis told me in September as we toured the control centre of the snow-making operation he runs in Val d’Isère. “Water, air, cold and talent.” One morning in 1995, Mattis, who was then a 28-year-old ski-lift engineer, was told he was being redeployed to look after the resort’s handful of snow machines. Four years later, he began building his snow-making factory, or atelier neige, installing a 70km network of pipes beneath the mountain that now, after years of expansion and improvement, can cover 65 sq km of slopes in artificial snow at the touch of a button. It is one of the most sophisticated snow-making operations in the world. The first snow-making machines in Europe appeared in Italy in the early 1980s, just before the locals in Val d’Isère began to notice the seasons shifting. (In 1963 snow-making equipment was installed at Mar Lodge in Scotland, but the project was abandoned after two seasons as the water kept freezing.) As winters with unreliable snow became more common in the Alps, so did the machines. Most were based on a design by a Pennsylvanian man named Herman K Dupré, who in 1968 had fitted a water sprinkler to an air compressor system he bought at a scrapyard. Dupré pumped the air and water at high pressure through a lance-like nozzle to create a fine spray that, at sufficiently low temperatures, turned to snow before it hit the ground. The HKD snowmaking system, as Dupré named his invention, became the industry standard. The first one arrived in Val d’Isère not long before the snow-scarce winter of 1986. Warm winters had occurred before the mid-1980s, Robert Steiger, an economist and tourism researcher at the University of Innsbruck, told me, “but at that time Alpine communities had not been so dependent on ski tourism.” Today, 95% of Italian, 70% of Austrian, 65% of French and half of Swiss ski resorts are reliant on snow machines for their continued survival, according to estimates from Claus Dangel, CEO of Bächler, a snow-machine maker that supplies more than 200 resorts across the Alps. It takes an awful lot of technology, water and energy to manufacture the amount of snow that might have naturally blanketed the Alps two or three generations ago. Mattis’s control centre in Val d’Isère is housed in a cavern chiselled into the mountainside, like the bunker of a Bond villain. It is large enough to house some 40 double-decker buses, and home to six 10ft tall pumps, water filters, and a phalanx of computer screens – all maintained by Mattis’s 12-member “snow team”. Using software developed in-house, the team controls a vast network of snow machines via a bank of 10 computers. Like the timer on a boiler, the software allows the team to set “on” and “off” periods for the snow machines, ensuring a consistent covering of snow throughout the season. Forecasts fed into the bunker from weather stations on the mountains help the team to adjust their schedules. During the ski season, three people monitor the system throughout the night, like security guards watching over a bank vault. They check the correct positions of the cannons in relation to the prevailing wind, watch the quality of snow, and ensure that the pump rooms are working satisfactorily. If a patch of ground appears in the melting snow, they can cover it before sunrise. The snow is shot on to the mountains at a speed of 250km/h via 650 snow cannons. Ten years ago the cannons could be spaced 80 metres apart from one another and still create an unbroken blanket of snow, but climate change has since forced Mattis to cut that distance in half. The system has to be continually upgraded to keep pace with the effects of climate change. The current iteration was completed in 2014 at a cost of €2m, and can produce 8,000 cubic metres of snow per hour – eight times the capacity of five years ago. The plant is one of the largest in the Alps, and differs from most of its rivals in that all of the equipment (bar HKD’s nozzles, which are imported from Quebec) was designed in-house. Mattis claims his system is unique as it allows the team to control the density of the snow on a sliding 10-point scale, enabling him to create a more compact, “faster” snow, ideal for professional competitions. This technology comes at a major financial and ecological cost. Today, one in every 20 euros spent anywhere in Val d’Isère goes into the snow factory, covering energy costs, staffing, maintenance and upgrades (a hidden “artificial snow” tax that is continually increasing). Although snow machines are becoming increasingly efficient, a typical snowmaker still uses about the same amount of energy as a boiler in a family home. When multiplied into the tens of thousands across the Alps, snowmakers become something of a self-defeating invention: they worsen and sustain the climate problems they’re supposed to solve. And yet, for life in the Alps as we’ve come to know it, they remain essential. Steiger’s most recent simulations suggest that unless every ski resort in the Alps installs state-of-the-art snowmaking facilities like the ones Mattis operates at Val d’Isère, by the 2050s up to half will no longer be able to sustain their businesses. Only the wealthiest resorts, like Val d’Isère – where chalets can sell for more than €23,000 per sq metre, five times the average cost of property in London’s most expensive borough, Kensington and Chelsea – are able to make the necessary investments to continually update and retool their snow-making facilities. Less-moneyed resorts rely on a cheaper source – snow farming, whereby snow is gathered or made in January and February, when manufacturing snow costs less than in warmer months. The snow is then placed under a 40cm layer of wood chippings, which absorb and release moisture and keep the snow cool, compact and manageable during the summer months. The wood chippings are then removed at the end of October, allowing the snow to be deployed on the slopes in time for the skiing season. Artificial snow, be it farmed or sprayed, is not only the would-be saviour of the ski industry, however. This is a region where, as the International Commission for the Protection of the Alps, Cipra, puts it, “there is an urgent need for innovative ideas and solutions”. One Dutch professor believes artificial snow may also hold the key to saving glaciers, in the Alps and beyond – along with the communities that rely on them for their food and water. On the morning of 11 July 2000, after a night of unexpectedly heavy summer snow, Hans Oerlemans went to check his weather station on the Morteratsch glacier, near the village of Pontresina, Switzerland, 400km north-east of Val d’Isère. The Morteratsch is one of the largest glaciers in the Alps, and a popular attraction for sightseers and thrill-seekers, many of whom come to ski along its 6km back. Since 1860, though, the glacier has shrunk by 2.5km – an average of nearly 16 metres per year. Oerlemans believes lessons learned by studying the Morteratsch can aid anyone interested in saving snow and ice across the Alps. A Dutchman who grew up in Utrecht, Oerlemans is tall and handsome, and wears the thin-rimmed glasses of a Hollywood therapist (studiously removing them for photographs). He has been studying glaciers since 1980, when he earned his PhD from Utrecht University, where he is an emeritus professor. His weather station on the Morteratsch, which he personally built in 1995, was one of the first in the world designed to measure the effects of climate change on glaciers. By monitoring the Morteratsch’s vital signs – fluctuations in the depth and temperature of its ice, as well as the ambient humidity – he hoped to solve a number of basic, yet unanswered, questions. “If the climate becomes one degree warmer,” he told me recently, “what happens close to the surface of a glacier: do you have 1 metre more of ice melt, or 10cm, or 10 metres? Nobody knew.” When Oerlemans crested the mountain that overlooks the Morteratsch that July morning two decades ago, he expected to see the glacier in its state of typical summer resplendence – a great frozen river, flowing in imperceptible slow-mo down the mountain. Instead, he saw nothing but snow, covering the glacier in a half-metre-deep drift. In the weeks that followed, he noticed something even more surprising in the weather station readings: the glacier’s thaw had halted almost entirely. Two processes melt ice: the transfer of heat from warm air, and solar radiation from the sun. Oerlemans’s readings suggested that the latter had a much greater effect than scientists previously understood. The covering of snow from the unseasonable summer storm had apparently acted as a reflective shield, fending off enough solar radiation that it was equivalent to dropping the air temperature by a full degree. He wrote up his findings in a paper published in 2004 by the International Glaciological Society. Then, for a while, he put what happened to the back of his mind. This autumn, as Oerlemans and I took a bobbing cable car up to a viewing station overlooking the glacier and mountain-top restaurant – home to “probably the most expensive plate of spaghetti in Europe,” he said – he explained what happened next. About five years after his paper was published, the villagers in Pontresina learned about an experiment in which polyester fleece has been used to cover snow to preserve it during warm weather. They laid the fleece on to the glacier in two-metre wide strips, like a blanket shorn from a massive sheep. “They put it out in the middle of May, and covered the ice till September,” he said. Not only did the fleece blanket stall the effects of melting, it actually reversed them: measurements showed that, over the course of the summer, ice in some of the areas under the fleece grew in thickness by up to two metres. When news of this ice reversal reached Oerlemans, he immediately thought of the weather station reports following the heavy snow drift in July 2000. If it were possible to cover a glacier in a protective barrier during the spring and summer months, might this counteract a century of decline? “The scale is totally different,” Oerlemans recalled. “You could not use fleece on a glacier the size of the Morteratsch, which moves, because it will be destroyed quickly. But, I thought: it might just be possible to use artificial snow.” To test the theory, in the summer of 2017 Oerlemans and his team sprayed a 2.5 metre-deep blanket of artificial snow over a small section of the Diavolezzafirn glacier, one of the Morteratsch’s diminutive neighbours. The experiment, which ran to the autumn, was successful: further melting was prevented, and in some places the ice even grew. With positive results in hand, Oerlemans and his collaborators began to consider the much greater challenge of how to blast a sufficient amount of artificial snow over the much larger expanse of the Morteratsch. Snow cannons such as those installed in Val d’Isère could not be placed on to the glacier, as they would be caught in the slow-moving current of the ice and torn from their pipes. Instead, Oerlemans and his colleague Felix Keller considered using a cable car equipped with a snow machine to travel above the glacier, dropping artificial snow as it went. (Oerlemans and Keller’s partnership is not short on creative thinking – the pair also play in a two-piece tango band called Tango Glaciar and often splice musical performances into their lectures on glacial retreat; once they even performed on a glacier, which one onlooker drolly likened to the musicians on the Titanic stubbornly playing while the ship sank.) This idea stalled when it came to supplying a moving cable car with the necessary water to make the snow. Finally, in a eureka moment, the team settled on an ingenious invention: a “snow rope”, stretched in a zigzag pattern across the width of the glacier, hundreds of feet across. Acting like a sprinkler system, the rope could deposit snow from altitude while the glacier trundled conveyor belt-like beneath it. After two years of preparatory studies, finding willing engineering partners and filing patents, on 1 October 2019 Oerleman received a 2m Swiss franc grant from the Swiss Innovation Agency to begin work on his extravagant snow blanket scheme. “We have passed the point of no return,” Oerlemans told me. “It’s no longer just theory; it’s happening.” On a warm morning this past summer, I hiked with Hans Oerlemans along a dirt path from the village of Pontresina up to the Morteratsch glacier. Perhaps to convince sceptical visitors of the scale of the Morteratsch’s retreat, the village council had erected 2.5 metre-tall markers along the path to show how far downhill the tip of the glacier stretched in certain years. With an accumulating sense of dread, we walked from the marker for 1865, which sits close to a car park at the base of the mountain, and past the ones for 1940, 1960, 1980. The farther we walked, the farther away the next marker was – the glacier’s retreat was accelerating over the decades. The effect was like trekking along a countdown to the oblivion of the glacier, or perhaps even our own. Along the steep-sided valley carved out by the glacier over millennia, the cliff walls most recently vacated by the shrinking floe are packed with “dead ice”, a dark grey substance that looks like granite. Dead ice poses a major threat to sightseers because it can cause massive rock falls; last summer a boy ignored a set of warning signs and wandered less than 50 metres from the main tourist path. He was crushed to death by a falling boulder. The villagers of Pontresina are distressed by the likely effects of the erosion of the ice on the village’s tourist economy, Oerlemans told me. But not everyone is convinced that his snow-blanket scheme is the best use of 2m francs. “I am sceptical of the entire project,” an employee from the local council said. “It’s such a huge amount of money, and it’s not clear what effect it will have.” Even if the scheme meets expectations, there is a sense that the funding behind the glacier-saving technology has essentially been awarded to prop up the skiing industry, the recreational embodiment of extreme privilege – just like the artificial snow operation in Val d’Isère. Oerlemans and his team argue, however, that if the wealthy ski resorts of the Alps can facilitate the development of these technologies, they will have a knock-on effect in the coming years, enabling poorer communities around the world to benefit from these advances. The professors’ snow rope system may provide a solution, ensuring the survival, not only of expensive tourist resorts, but also farming communities, such as those in India and Tibet, whose crops are reliant on glacial water. “There are 230,000 glaciers in the world, and it’s unthinkable that you could use our technique on a scale that would, for instance, stop glaciers from contributing to sea-level rise,” says Oerlemans. “But at a local level it could prove invaluable for local economies that depend on melt water from glaciers for their survival.” That technologies developed for the rich will one day help the poor is a familiar refrain among tech idealists – and a dubious one. “Assuming that western technologies can be easily implemented in developing countries is a bit naive,” said Robert Steiger, from the University of Innsbruck. “Poor regions in poor countries lack the institutional background that is required to implement new technologies and, even more importantly, to provide the knowledge and money to maintain this technology.” Besides, Claus Dangel, the CEO of the snow machine company Bächler, which is currently developing Oerlemans’ snow sprinkler, estimates that the company needs an additional 3.5m Swiss francs to fully develop the system – far more investment than is provided by the Swiss Innovation Agency grant. Dangel’s hope is to make the system as low-energy as possible, perhaps by using gravity to feed the sprinkler system from lakes high in the mountains, above the snow rope. “We want it to work without using energy,” he told me. “But this is very complicated because you need high water pressure, and the system will probably need to be heated in one way or another, to prevent it from freezing.” In the long term, it seems unlikely that artificial snow will save even the wealthy Alpine ski industry. Resorts are beginning to consider how they might make more fundamental changes to their businesses in order to adapt to, rather than stave off, the effects of the climate crisis. For many resorts, this means reorienting themselves around non-skiing activities: hiking, mountain bike-riding, nature-watching, sightseeing. “We can see what is coming for us,” said Olivier Simonin, the director of the resort at Val d’Isère. “There will need to be a complete change.” By 2050 Simonin hopes that 30% of the resort’s income will be derived from activities other than skiing. The number of tourists visiting the Alps during the summer is already increasing year on year, according to the World Wide Fund for Nature. Changes in climate are being matched by changes in what visitors, especially millennials, are looking for. But hiking and other summer activities are less profitable than skiing, so although tourism may endure, the stratospheric revenues of the heavy snow decades may not. “We may have a bit more time compared to others but, then again, we are a big resort,” Simonin said of Val d’Isère. “We have a greater economic challenge in order to maintain our current levels of profit.” For a few moments Simonin held his head in his hands. “It will require solidarity between the villagers, the resorts, the hotels,” he said, finally. “But people who live in the mountains are hardy. We are used to having to adapt.” Perhaps, he wondered, with a note of surprise at what appeared to be a fresh afterthought, whether in 50 years, people might come to Val d’Isère, not to ski but simply to see snow – human-made or otherwise – precisely because of its scarcity. With a dry laugh, he added, “Maybe the mere sight of snow will become a privilege.” • This article was amended on 20 December 2019. Owing to a unit conversion error, an earlier version stated that property prices in Val d’Isère were 20 times higher than in Kensington in London. It has been corrected to five times. A reference to an early snow-making programme in Scotland has also been added. • Follow the Long Read on Twitter at @gdnlongread, or sign up to the long read weekly email here."
"
Share this...FacebookTwitterAre Modern Rates Of Sea Level Rise 
Too Slow For Optimal Coral Growth?

Since the 20th century began, global sea levels have been rising at rates of about 1.7 – 1.8 mm/year, or about 0.17 to 0.18 of a meter (~7  inches) per century.

NOAA 


Zerbini et al., 2017
“Our estimated rates for the northern Mediterranean, a relatively small regional sea, are slightly lower than the global mean rate, + 1.7 ± 0.2 mm/year, recently published in the IPCC AR5 (Intergovernmental Panel on Climate Change 5th Assessment Report) … Our regional results, however, are in close agreement with the global mean rate, + 1.2 mm/year, published by Hay et al. (2015) which is currently being discussed by the oceanographic community.”

Svendsen et al., 2016
“From our reconstruction, we found that the Arctic mean sea level trend is around 1.5 mm +/- 0.3 mm/y for the period 1950 to 2010, between 68ºN and 82ºN. This value is in good agreement with the global mean trend of 1.8 +/- 0.3 mm/y over the same period as found by Church and White (2004).”

Parekh et al., 2017
“Sea level change in the Indian Ocean is about 1.5 mm/year in the past sixty years or so, whereas the global sea level trends are a bit higher [1.7 mm/year].”

McAneney et al., 2017
“Global averaged sea-level rise is estimated at about 1.7 ± 0.2 mm year−1 (Rhein et al. 2013), however, this global average rise ignores any local land movements. Church et al. (2006) and J. A. Church (2016; personal communication) suggest a long-term average rate of relative (ocean relative to land) sea-level rise of ∼1.3 mm year.”

Wenzel and Schröter, 2014
“Global mean sea level change since 1900 is found to be 1.77 ± 0.38 mm year on average. …   [T]he acceleration found for the global mean, +0.0042  ±  0.0092 mm year, is not significant“

In contrast, during the middle Holocene, sea levels rose at rates of 9.6 mm/yr (0.96 of a meter per century) during the 350 years between 6,850 to 6,500 years ago (Meltzner et al., 2017), and relative sea levels (RSL) were about 1 to 2 meters higher than present during that time.  During the Early Holocene (~12,000 to 8,000 years ago), sea levels rose at rates of about 0.74 of a meter to to almost 1.1 meter per century (7.4 mm/yr to 10.9 mm/yr), which is about 5 to 6 times the modern rate (Khan et al., 2017).
Corals, thought to be biologically fragile and highly susceptible to abrupt sea level changes and high sea temperatures…survived these much higher rates of sea level rise from the geological past.
Scientists have apparently found that coral communities do not grow as well, but instead they “shut down” — even reaching very high mortality rates (85%) — when sea levels fall rapidly.  Falling sea levels (and cooling) are suggested to be more lethal to corals than high-temperature bleaching events during El Niño years or rising sea levels (Eghbert et al., 2017).
These findings would not appear to support the current perspective that modern coral communities are threatened by “global” warming and rapidly rising sea levels.

Recent Rapid Sea Level Fall Induced Higher Coral Mortality Than Bleaching

Eghbert et al., 2017
“In September 2015, altimetry data show that sea level was at its lowest in the past 12 years [Indonesia], affecting corals living in the bathymetric range exposed to unusual emersion. In March 2016, Bunaken Island (North Sulawesi) displayed up to 85% mortality on reef flats dominated by Porites, Heliopora and Goniastrea corals with differential mortality rates by coral genus.”
“[R]apid sea level fall could be more important in the dynamics and resilience of Indonesian reef flat communities than previously thought. This study reports coral mortality in Indonesia after an El Niño-induced sea level fall. The fact that sea level fall, or extremely low tides, induces coral mortality is not new, but this study demonstrates that through rapid sea level fall, the 2015–2016 El Niño has impacted Indonesian shallow coral reefs well before high sea surface temperature could trigger any coral bleaching. Sea level fall appears as a major mortality factor for Bunaken Island in North Sulawesi, and altimetry suggests similar impact throughout Indonesia.”

Reefs ‘Turn Off’ (Stop Growing) When Sea Levels Fall And Seas Cool

Dechnik et al., 2017
“[I]t is generally accepted that relative sea level reached a maximum of 1–1.5 m above present mean sea level (pmsl) by ~7 ka [7,000 years ago] (Lewis et al., 2013).”
“Over the last few decades, the global decline of modern reefs has been linked to environmental and climatic changes in response to anthropogenic activities.  However, recent geological and ecological research on fossil reefs in the Great Barrier Reef (GBR) and wider Indo-Pacific identified intervals of significant reef ‘turn-off’ in response to natural environmental forces earlier in their development during the mid- to late Holocene.”
“Increased upwelling, turbidity and cyclone activity in response to increased sea-surface temperature (SST’s), precipitation and El-Nino Southern Oscillation variability have been ruled out as possible mechanisms of reef turn-off for the mid-outer platform reefs. Rather, a fall (~0.5 m) in relative sea level at 4–3.5 ka is the most likely explanation for why reefs in the northern and southern regions turned off during this time.”
“Similar hiatuses in Holocene reef growth were identified in Japan from about 5.9 to 5.8 ka, 4.4 to 4.0 ka and from 3.3 to 3.2 ka. They were attributed to oscillating sea level and relatively cold sea-surface temperatures.”
 


Corals Survived Sea Level Rise Of 6 – 13 mm/yr During Middle Holocene – But ‘Killed’ When Sea Levels Fell Rapidly

Meltzner et al., 2017
“Half-metre sea-level fluctuations on centennial timescales from mid-Holocene corals of Southeast Asia … RSL [relative sea level]  history between 6850 and 6500 cal years BP that includes two 0.6 m fluctuations, with rates of RSL change reaching 13±4 mm per year.”
“Here RSL rose to an initial peak of +1.9 m [above present] at 6,720 cal years BP, then fell rapidly to a lowstand of +1.3 m, remaining at about that level for ∼100 years, before rising to a second peak at +1.7 m shortly after 6,550 cal years BP.  Around 6,480 cal years BP, RSL appears to have fallen again to +1.3 m before rising to a third peak at +1.6 m or higher. … The peak rate of RSL rise, averaged over a 20-year running time window over the period of study (∼6,850–6,500 cal years BP), is +9.6±4.2 mm per year (2σ); the peak rate of RSL fall is −12.6±4.2 mm per year.”
“The central dome of each microatoll grew during a period when RSL was high; RSL then fell rapidly, killing the upper portions of the corals; RSL then stabilized at a lower elevation, forming a series of low concentric annuli ∼0.6 m higher than present-day analogues; RSL [relative sea level] then rose ∼0.6 m in less than a century, allowing the coral to grow upward to 1.2 m higher than modern living corals.”

During The Early Holocene, Sea Levels Rose At Rates 5 – 6 Times Higher Than Today

Khan et al., 2017
“Only Suriname and Guyana [Caribbean] exhibited higher RSL [relative sea level] than present (82% probability), reaching a maximum height of ∼1 m [above present] at 5.2 ka [5,200 years ago].”
“Because of meltwater input, the rates of RSL change were highest during the early Holocene, with a maximum of 10.9 ± 0.6 m/ka [1.09 meters per century] in Suriname and Guyana and minimum of 7.4 ± 0.7 m/ka [0.74 meters per century] in south Florida from 12 to 8 ka [12,000 to 8,000 years ago].”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe online Berliner Morgenpost here reports that electric cars in Germany are going to lead to even higher electricity prices for the country’s already massively burdened consumers. Hat-tip Gerti B.

NAEB power price projections for 2020. Note that the horizontal scale changes at the year 2010 in order to condense the chart. The upper curve shows German electricity prices in euro-cents per kilowatt-hour, the middle curve shows the price for France and the lower curve for the USA. Source: NAEB.
The original plan was to put one million electric cars on the streets by 2020, but so far the country is nowhere near being on that trajectory, and very likely will fall very far short of the target. So far only 34,000 of Germany’s 45 million vehicles are electric. The plan for 2030 calls for 5 million vehicles!
What would cause electricity rates to climb if more electric cars come on the market? Citing the Bundesnetzagentur, the Morgenpost writes:
The power grid needs to be expanded for a million electric cars. Consumers will feel it through surcharges imposed on the price of electricity.”
Germany’s infrastructure for electric cars continues to be extremely limited and patchy, thus making electric cars impractical in most situations and areas.
A massive investment is necessary just to expand the charging station network in order to overcome the huge charging infrastructure obstacle — never mind the limited range of electric cars, long charging times, high life-cycle costs and environmental impact.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Morgenpost also cites Germany’s National Platform for Electro-Mobility in stating: “for 1 million e-cars by 2020, about 70,000 charging locations and 7100 rapid charging stations are needed” and that currently “only about one tenth of that exists“.
According to experts, writes the Morgenpost, just the grid expansion (without charging stations) is estimated to cost 30 billion euros over the coming years. That figure may be enormously conservative, as recent German infrastructure projects have shown.
Another problem is that despite hundreds of billions in investment, Germany’s power grid is still nowhere near being green, and is still heavily reliant of coal and fossil fuels. Charging cars with electricity that is produced mostly by fossil fuel does nothing for reaching the greenhouse gas reduction targets. It could in fact be counter-productive.
Germany’s Energiewende (transition to renewable energies) is a classic case of a mad, activistic rush into something without first thinking it through.
They can’t even build an airport
Transitioning an entire economy to renewable energies is a worthy target, of course, if allowed the appropriate amount of time (some generations) to do so. But it is absolutely insane for a country to believe it can accomplish this in a decade or two, especially in light of the fact that it cannot even handle the construction of an airport in the same timeframe. Yes, these are the very same people who claim Trump is unfit to be president.
In a nutshell: These bozos can’t even build a simple airport, and so how can they be trusted to rebuild the nation’s entire energy supply system?
So far they are proving that they can’t, and that the Energiewende may very well turn out to be the Berlin Airport times 1000, or worse!
 
Share this...FacebookTwitter "
"As the third-largest emitter of greenhouse gases globally, the pressure is on India to offer something meaningful at the Paris climate talks. Yet the country demands the right to develop and lift its population out of poverty.  In its official submission to the summit, the so-called INDC (Intended Nationally Determined Contributions) which every country had to provide before negotiations began, India pledges to reduce the emissions intensity of GDP by 33 to 35% by 2030 based on 2005 levels. It proposes to achieve this by investing significantly in low-carbon technologies. But do these numbers stack up? It may have the third highest greenhouse gas emissions on the planet, but India’s emissions per person are much lower than those of all so-called developed countries. This is why stakeholders insist on India’s right to develop.  Key concerns are energy poverty – one in five Indians lacks access to electricity  – and the need to provide jobs for the fast-growing population. Both will involve the expansion of energy-intensive industries. Although renewables will contribute up to 40% of India’s electricity by 2030, the country is also forecast to become the largest source of demand growth for coal globally.  The renewables targets, and India’s leadership on solar power, have rightly been lauded for their ambition. Yet
important concerns remain.  India has significant growth potential for hydropower, and the INDC contains a pledge to “aggressively pursue” its development. There is no clarification made about what type of hydropower this will be. Of the existing installed capacity in hydro of 46.1 gigawatts (GW), only 4.1 GW is small hydro. There are concerns especially about the 292 dams that are supposed to be built in the Indian Himalaya region, which is extremely earthquake-prone. Large dams affect millions of lives, none more so than those displaced by construction. The Narmada valley project is a classic case. Land is grabbed from small farmers and rural communities, increasing the pressure on already expanding urban centres. In one state alone, some 100 dams have displaced 700,000 people according to the government’s own figures. The electricity generated by large hydro projects is always destined for the national grid. The rural poor living with energy poverty rarely see any benefit. No wonder movements such as the Narmada Bachao Andolan have focused on alternatives to big dams. At the Paris climate talks, a coalition of 300 civil society organisations from 53 countries released a manifesto asking for climate initiatives to preclude large hydropower projects. The most glaring aspect of India’s INDC is the classification of coal as a “clean” source of energy. The submission states that India generates 60.8% (167.2 GW) of its power using coal; the mention of mandating the use of “highly efficient supercritical technology” for coal plants indicates that coal will continue to be at the centre of its power generation strategy. There is a fundamental contradiction between this coal usage policy, which requires a massive expansion of homegrown extraction, leading to large-scale deforestation in India’s coal belt, and its plan to meet  carbon emissions reduction target by offsetting 100 million tonnes of CO2 per year by planting trees. The INDC goes so far as to commit to increasing the forest cover by between 2.5 million and 3 million tonnes of CO2 equivalent by 2030. This is despite evidence that Indian forests are significantly degraded and that between 1980 and 2007, 1,140,177 hectares of forest land were diverted for non-forest purposes with another 180,000 hectares having been diverted in the past five years.  India’s pledges do not effectively reconcile the needs of development with sustainability. Even renewable energy can have severe social and environmental implications, and it is glaringly obvious that coal can never be clean, even with massive carbon offsetting.  India is not alone in this conundrum. As the developing world tries to catch up with countries that have already emitted carbon for centuries, while replicating their energy strategies, the fundamental contradictions of the world’s dominant approach to development become obvious. The Paris climate talks will not provide new answers to these deep-seated challenges. Countries like India will continue to insist on their right to narrowly defined development. Their elites do not realise that they are following a failed and fatal model."
nan
"The UN’s ambitious new Sustainable Development Goals include a target to halt biodiversity loss by 2030. The SDGs have generated a great deal of comment, with questions raised as to whether the lofty aspirations can be turned into realistic policies. An article in The Lancet even dismissed the SDGs as nothing more than “fairy tales”. So is halting biodiversity loss a fairy tale? “Biodiversity” refers to the diversity of life on Earth. It includes diversity within species, between species, and of ecosystems. There are any number of statistics that confirm its decline across the globe. For instance, the Red List of threatened species, developed by the International Union for the Conservation of Nature (IUCN), identifies 22,784 that are at risk of extinction – almost 30% of the species that have been assessed. By other measures, habitats continue to be destroyed and degraded, and population sizes of most wild species are in decline. This is bad news not only for nature lovers but for all of us since we rely on biodiversity to deliver many crucial services such as pollinating crops and providing medicines. By projecting current trends forward in time, a study published in Science last year concluded we are already on course to miss most of the international community’s other main targets for biodiversity – the “Aichi Targets” – which were adopted in 2010 under the Convention on Biological Diversity (CBD) and aspire to improve things by 2020. So why might the new SDG biodiversity target be any more achievable than those that have gone before? The inclination is to be extremely pessimistic, but there are some reasons to be hopeful. The same Science paper also looked at indicators of societal responses to the biodiversity crisis. Here the trends are much more in the right direction. Coverage of protected areas is increasing across the planet, sustainable management practices in industries such as fishing and forestry are taking root, and public awareness of biodiversity issues is rising. There has been real progress in the policy arena. To date 184 of 196 parties to the CBD have developed National Biodiversity Strategies and Action Plans, which set out actions such as promoting laws and providing funds to help achieve the convention’s goals. The establishment in 2012 of the Intergovernmental science-policy Platform on Biodiversity and Ecosystem Services (IPBES) also provides an important new mechanism to inject sound scientific advice into policy making. In business as well, biodiversity conservation and the related concept of “natural capital” are becoming mainstream. For instance, the Natural Capital Coalition is developing the economic case for valuing natural ecosystems and includes buy-in from some of the biggest players in business, accountancy and consulting. And the financial industry is moving toward more responsible investing. The UN Principles for Responsible Investment, which commit investors to act in accordance with conventions such as the CBD, now has almost 1,400 signatories who manage assets with a combined total of US$59 trillion. These are major positive changes that have come to the fore in the past decade or so. And there are conservation success stories that illustrate how such changes can turn things around for biodiversity. For example, the latest update to the IUCN Red List reports that conservation action has bolstered populations of the Iberian lynx, which had only 52 mature individuals in 2002. And the Guadalupe fur seal, which had twice in the past been thought to have gone extinct due to hunting, is also making a comeback. More generally, there is an overall positive trend among populations of almost 1,000 bird and mammal species across much of the northern hemisphere.  These instances of good news still leave us a long way from halting global biodiversity loss. I don’t mean for a moment to underestimate the magnitude of the problem. Habitat loss, climate change, pollution, overexploitation and the spread of invasive species all remain huge threats that will require extraordinary efforts to tackle. But time has not yet run out. Although many plants and animals are threatened with extinction, we have in fact lost only a few percent of known species over recent centuries. It is heartening that there is still an astonishing amount left to save. It will take time to slow and turn around the juggernaut that is biodiversity loss, and everyone must pull in the same direction in order to shift course. The period over which the new SDGs will run, from now until 2030, will be absolutely crucial for making this happen. There are indications that things are beginning to turn around. Hints that we can do this. It would be a big mistake to dismiss the biodiversity target as a fairy tale. And anyway, fairy tales usually have happy endings, don’t they?"
"Governments both in Australia and internationally are not moving fast enough to avoid 2C warming, according to the former head of Scott Morrison’s department, and Australia is also creating a significant problem for itself down the track by deploying carryover credits from Kyoto to meet the Paris target. In a frank and wide-ranging interview on Guardian Australia’s politics podcast, Martin Parkinson – the former secretary of the prime minister’s department and the bureaucrat at the centre of policymaking at the federal level on climate change during the Howard, Rudd and Gillard governments – reflected on the experience he describes as the worst of his professional life. Parkinson said John Howard pursued constructive climate action towards the end of his prime ministership, pursuing an emissions trading scheme, but progress was halted because of a “civil war” inside the Coalition and because of “truly appalling” behaviour by the Greens in sinking Kevin Rudd’s Carbon Pollution Reduction Scheme. The former top bureaucrat excoriated the Greens, declaring that from his vantage point, they “never wanted to see anything succeed. If you are the party of protest, you don’t want to take away your protest platform. Maybe I’m being a cynic, but I think that’s what happened.” Parkinson said the Greens didn’t accept that you could put a mechanism in place and then dial targets up and down depending on where the community was at and the demands on Australia, courtesy of being signatories to international agreements. “I can’t see inside their minds but I’ve never heard anyone from the Greens apologise for what they have done. “And let’s be blunt about it, 12 years on the [emissions reduction] targets are no more ambitious – if anything, they are watered down from where we should be, and that’s not the current government’s fault, that was Tony Abbott. “We have missed a decade of mitigation action and adaptation action.” Parkinson said the decade of inaction had prompted business to try and seek its own solutions to lowering emissions, rather than wait for the government to end the hyperpartisan war. He said business in 2019 was acutely conscious that climate change meant the risk of stranded assets, more natural disasters and a potential “tsunami” of liability when superannuation funds and pensions funds turn on companies for failing to manage carbon risk. He said the outlook was really challenging. “I cannot see governments here or overseas moving fast enough to avoid 2C, let alone 1.5C, just to be really blunt about it. “The International Energy Agency, which is hardly a bunch of crazy climate [change] believing leftists, says we are on track for 2.7C to 3.5C even if countries do what they are committed to do for Paris – and they are not doing what they have committed to do.” Parkinson said the Morrison government’s decision to use carryover credits from the Kyoto period to account for about half the abatement required under Australia’s 2030 target was going to create significant problems down the track. Using the Kyoto-era accounting means Australia can meet the Paris target nominally while delaying a significant amount of practical emissions reduction. “If you use the carryovers, then at the end of 2030 the gap you’ve got to close, as you go into whatever comes next, is that much bigger,” he said. Parkinson retired from his position in August. Before heading the prime minister’s department, Parkinson was the secretary of the Treasury department and the climate change department. Under John Howard, he ran the Shergold review, which cleared the path for the Liberals to adopt the policy of emissions trading, and he remained at the centre of policymaking in the Rudd and Gillard eras, before being sacked from Treasury by Tony Abbott. He was brought back to run the prime minister’s department when Malcolm Turnbull took the Liberal leadership. Asked whether the climate policy failure was the worst experience of his professional life, Parkinson said: “Yes, it was. It was awful on a number of fronts. We were so close [with the CPRS].” Coupled with all this, Parkinson said he inherited responsibility for managing the fallout from the home insulation scheme. “We’d had four young Australians tragically die, and it was awful”. He said he and his colleagues had “many, many sleepless nights”. “That whole period was absolutely terrible,” he said. Parkinson said the broader cause of reform in Australia had faltered because there was no longer a consensus, either in the political class or the economic profession, about what needed to be done. He said some participants in public life wanted to “pretend that really complex problems are really simple” when the reality was there were a number of problems that government couldn’t fix. While he maintained a positive view of ministers and their advisers, including the current prime minister, Parkinson said ministers often came to their posts significantly unprepared. Ministers were asked to assume awesome responsibilities without proper training. Sign up to receive the top stories from Guardian Australia every morning He expressed disappointment that the Morrison government has rejected some of the central recommendations of the recently released Thodey review, such as adopting a code of conduct for ministerial advisers. “I think the vast majority of people who go into parliament or ministerial offices are trying to do the right thing, so I don’t see training or a code of conduct for them as any way a negative – it would be about helping them do their jobs better and positioning them much better,” Parkinson said. He says there was some antipathy in the government about the Thodey review process. “I think there’s a reasonable number of people in the government who took the attitude that this was a Malcolm Turnbull/Martin Parkinson frolic, and were never really committed to it, and definitely didn’t want to do anything that would have impacted on their freedom to operate.”"
"The city of Chennai – a coastal metropolis of 8.7m people and capital of India’s Tamil Nadu region – has been flooded by an extreme weather event. The city experienced incessant rain, in what has been its wettest November for over a century: December 1 broke local records, with 490mm of rainfall.  The results have been catastrophic: the Adyar and Cooum rivers overflowed, 35 major lakes breached their banks and large parts of the city – including the international airport – were submerged. Schools and hospitals were shut down, electricity and electronic networks were unavailable for days, and life was turned upside down not just for residents, but also for flagship IT and automobile companies such as Tata Consultancy Services, Infosys, Cognizant, Yamaha, Renault Nissan and BMW India.  The confirmed death toll from the flooding is 270 and rising, and a trade body has estimated that monetary losses will be in the region of Indian Rupees 15,000 crores (£1.5 billion). While the flood waters have now receded, health epidemics ranging from malaria to cholera and typhoid may well be imminent. It is widely believed that Chennai’s misery was brought on by climate change, and that such extreme weather events are going to increase in frequency and impact. World leaders have blamed the event on global warming, even as the COP21 climate change conference plays out as expected in Paris. As the climate battles rage in the natural and political worlds, Chennai represents the human dimensions of disaster. Climate change is not the only guilty party: the scale of the disaster at Chennai was magnified by a rampant disregard for town planning, and the basic principles of ecology and hydrology. To name just a few of the violations: the international airport is built on the floodplain of the Adyar river; the Mass Rapid Transit System sits atop the Buckingham Canal; the government allowed buildings to be erected over more than 273 hectares of the Pallikarni marshland to the south of the city; and the city’s famed Information Technology and Knowledge Corridors encompass wetlands and marshlands that would normally act as a sink for flood water.  Modern states have always used urban and infrastructure planning as a way to control and exploit nature’s more unruly tendencies: whether it’s water flowing down a river, waves battering the coast or food sources growing on the land or in the sea. There have been countless examples: from the colossal web of transport lines and ports built throughout colonial East Africa and South Asia, to the extensive damming of the Tennessee River System, which inspired similarly ambitious projects in the Mekong River Basin and the Narmada Valley.  But the planning distortions of contemporary Chennai show that the state can take it too far, especially when it is attempting to meet the demands of a growing population and a competitive economic climate. Since economic liberalisation in 1991, Tamil Nadu has competed with other sub-national units in India – as well as productive regions in neighbouring countries such as China – to attract private investment. In the words of a retired Tamil Nadu bureaucrat, whom I interviewed for my research in 2012: Companies are like bridegrooms. If they are bringing an iconic brand into the [sub-national] state, they come with a huge list of demands, the primary one being land. In the case of [an automobile manufacturing company], we had large, vacant … plots, which we could transfer to them in a short period. In addition, they wanted road, rail and port access. They wanted to be near a metropolis. They wanted all sorts of social infrastructure, like land for an international school and sporting facilities for families of executives… Overall, there were 80-90 parameters related to land, tax concessions and clearances for water, electricity, etc. With increasing competitive pressures on states, land and natural resources become pliable reserves for meeting the exacting demands of national and international capital. But recent events in Chennai are a reminder that nature is flexible only to a point. It does strike back. While governments work formally with private entities to change the face of our cities, there is also a great deal of informal development going on behind the scenes. Private firms, India’s booming real estate industry, and middle class consumers work with unregulated brokers, middlemen, government touts, moonlighting officials, political strongmen, and various other intermediaries to acquire and build on land. The government acknowledges that there are 150,000 illegal structures in the city, and that 300 tanks and lakes have simply been built over. The actual number of breaches is probably much higher. Chennai is by no means the only city where space is more often allocated informally than through the “logic” of planning. Privatisation of the commons, filling of water bodies, encroachment on ecologically sensitive wetlands and the illegal alteration of maps to reflect these changes is evident in my field sites in east, west and south India. This is a translation of a quote from a Kolkata land broker, interviewed in 2014: Changing a pond record is backdoor work, and this is totally illegal. Every time it is changed, it happens under the table. The government office will have to be managed. All buyers (e.g. real estate developers) have a setting arrangement in the government office, and they all have a civil lawyer…. Politics also plays a role in our work … if there is a pond to be filled politicians will not leave us. They will demand Indian Rupees 10 lakhs to 20 lakhs (£10,000 to £20,000)… Besides, how will you fill the pond? You need mud, sand, and ash. Organisations affiliated to the locally powerful political party will supply this. As Chennai emerges from the water and takes a fresh look at itself, poorer residents and slum settlers will probably be the first to be evicted, in order to free up illegally acquired space for development. But if the city teaches us one lesson, it is that we are in this together. We are reaping what we have sowed as consumers, voters, home owners – not to mention the role of politicians, government officials and private companies. To pass the blame would be as shortsighted as world leaders blaming each other for climate change."
"Next year’s United Nations Climate Change conference (COP26) will be held in Glasgow, with Boris Johnson in the chair. It will be the largest gathering of world leaders in Britain since the opening ceremony for the 2012 Olympics in London, in which Mr Johnson also played a leading role. Unlike the Olympics, conditions are hardly propitious for a successful UN conference in 2020. The COP25 conference in Madrid at the weekend ended with despair about the lack of progress in reducing greenhouse gas emissions. To avoid repeating what was widely criticised as one of the worst outcomes in 25 years of climate negotiations, Mr Johnson will have to display hitherto unknown diplomatic depths. The irony is that he needs a global green deal while pursuing a post-Brexit British trade policy to outcompete the European Union by undercutting green standards.  Madrid was a depressing example of how not to do international diplomacy. This is not the fault of Spain, which took over the running of the conference at short notice after Chile, which had been due to host, pulled out following bloody unrest at home. Understandably distracted, Chile’s lack of leadership saw a coalition of states with strong links to fossil fuel industry – the United States, Brazil, Australia and Saudi Arabia – seize the opportunity to undermine the talks. Their success was to render meaningless the summit’s final declaration. This is a snub to science and strikers in a year of unprecedented climate activism. If this climate denialism persists we will pay a heavy price. Under the Paris agreement 190-odd countries have plans which, if implemented, would still see Earth’s temperature rise by 3.2 degrees. Scientists have warn that beyond 1.5 degrees of warming there’s a real risk of extreme heat, drought and floods becoming the norm. Next year countries will have to bridge the gap between the policies now in place and what is required to stop global heating with a round of new, bolder climate pledges. As the impact of the emergency becomes more evident, so does the scale of the challenge ahead. The UN now says that countries must increase their ambitions fivefold. Mr Johnson does not want a rerun of the UN summit in Copenhagen in 2009, which ended in failure amid clashes between 100,000 environmental protesters and Danish police. To ensure that the Glasgow conference passes off smoothly, he will first have to show that he is cleaning up his act at home. At present the government won’t hit carbon reduction targets after 2028, hardly inspiring confidence that the UK will reach net-zero by 2050. This needs more than just a new government department. Mr Johnson’s newfound green zeal can be politically useful: his manifesto promised to spend £6bn on improving the energy efficiency of 2.2m social homes, which may be allocated – brazenly – to the constituencies of new northern Tory MPs. But whatever his own approach, Mr Johnson’s fate is in the hands of others. Most important are US voters who might deliver a Democratic president just days before the Glasgow summit takes place. This would halt the Trump White House’s attempt to withdraw from the Paris agreement. EU leaders hope to strike a bargain with Beijing next September, so efforts to cut emissions remain meaningful even without the US. The Paris agreement has Mr Johnson facing one way on climate, but Brexit has him facing the other way. He will have to choose, perhaps symbolically by cracking down on City financing for dirty coal abroad. The world is not short of ideas to realise climate goals. We urge and encourage the prime minister to secure a global response that matches the scale of the crisis. "
"Douglas Tompkins, the pioneering entrepreneur who created the outdoor company The North Face and fashion chain Esprit, and who spent his riches creating the world’s largest network of privately owned nature reserves, died at the age of 72 following a kayaking accident.  His conservation philanthropy made him a polarising figure in Chile and Argentina, where he spent the last three decades purchasing more than a million hectares to create a series of privately-owned parks and reserves. Lauded by some as a conservation hero, criticised by others as an abrasive imperialist, it became clear during my two years studying private reserves in Chile and speaking to the key actors, that his remarkable story shows both the potential and limitations of wealthy philanthropists in saving nature. Tompkins’ youth was spent skiing, mountaineering, surfing and climbing, including a six-month expedition in 1968 to Chilean Patagonia with his friend Yvon Choinard, founder of outdoor brand Patagonia Inc. Kris McDivitt, CEO of Patagonia Inc for several decades, would become Topmkins’ second wife.  Early business success came when he established The North Face, which he sold after a few years, and much greater success came when he created Esprit with his first wife and saw the company become a massive global brand. Tensions within the company, and within his marriage, saw him retire from business in 1990 and move to southern Chile.  Inspired by the long US tradition of wildland philanthropy, he began purchasing parcels of land for conservation in Chaiten province, Patagonia, using intermediaries to evade attention and avoid price inflation. In 1994, he publicly announced the creation of Parque Pumalín (Puma Park), covering 275,000 hectares. By comparison, Lake District National Park, England’s largest, covers 220,000 hectares.  The announcement was immediately controversial. Parliament debated whether Tompkins was undermining national sovereignty. Chile had just emerged from a long military dictatorship, during which it nearly went to war with Argentina over the location of the frontier in Patagonia. A “gringo” buying land on this scale was not well received.  Crucially, Pumalín stretched from the Pacific Ocean to the Argentine border, effectively cutting the country in two. The military and Patagonian senators raised objections over whether this challenged national territorial integrity and whether it would prevent the construction of crucial infrastructure, such as roads and powerlines, that would link Patagonia with the rest of Chile.  Tompkins was accused of ignoring the rights of smallholder farmers who had lived on his newly purchased properties for generations, but who lacked proper land titles. His aim of conserving forests was seen as undermining Chilean economic development, which was (and remains) heavily dependent on natural resource extraction.  Wildland philanthropy was unknown in Chile, and some suspected ulterior motives. Conspiracy theories circulated that Pumalín was a front for CIA operations or Zionist plots, or an attempt to seize control of the region’s water supplies – this is reminiscent of the 2008 James Bond film, Quantum of Solace, in which the villain uses private reserves as a front for seizing control of Bolivia’s water supply. The “Bolivian” scenes were filmed in Chile.  The resulting political tensions led to Tompkins signing an agreement in 1996 with president Frei promising to desist from purchasing further properties and agreeing to infrastructure crossing his land. Foreign forestry and utilities companies have similar properties bisecting Chile, but have not attracted similar criticism, and no infrastructure has been built because of the challenges of the vertiginous and landslide-prone terrain.  This agreement was later mutually annulled, and Tompkins subsequently more than doubled his Chilean land holdings, and purchased even more in Argentina. Although he promised to later donate all his land to the state, lingering mutual distrust limited donations greatly. Tompkins became less politically toxic with time, although he remained uncompromisingly and vocally critical of what he saw as the environmental damage of salmon farming, forestry and hydroelectricity. While Tompkins remains Chile’s best-known owner of private reserves, hundreds of others have been established since 1994. They now cover over 2% of Chile, ranging in size from a dozen to 300,000 hectares. Owners include middle-class families, luxury eco-resorts companies, forestry companies, and national and international NGOs.  The best vindication of Tompkins’ approach came in 2005, when Chilean airline and credit card billionaire Sebastián Piñera, who served as Chile’s president from 2010-14, established the 112,000 hectare Tantauco private reserve. Yet the wider private reserve movement in Chile hesitated from close engagement with Tompkins, wary of his political toxicity. It was Tompkins’ wife, not him, attended Tantauco’s opening. Tompkins’ activities raise bigger questions about conservation philanthropy. First, Tompkins’ purchases have been seen as eco-colonialist land grabs, and there are legitimate concerns over powerful foreigners controlling large swathes of land.  Others within the Chilean conservation movement feel that the controversy over sovereignty has hampered their own efforts to get legal recognition for private reserves, and there are similar controversies in other countries. One international organisation specialising in private reserves always works through local partner NGOs and never owns land itself, to avoid accusations of colonialism and to ensure local support for its work.  Second, are private actors better than the state at conservation? Proponents argue that they are more motivated, flexible and innovative than governments, although there are few studies that explore this in detail. We do know that private reserves in Chile are more likely to be located in places with high levels of endangered species than government reserves, although Tompkins’ properties are not in this category. His purchases were largely driven by landscape aesthetics, not the density of biodiversity within them.  Tompkins purchased large wild areas which could be easily conserved through benign neglect, rather than the arguably more important challenge of conserving species in landscapes shared with humans. If private reserves are to be most effective, then they need to be planned carefully using assessments of what places are the greatest priority, rather than on the whims of wealthy philanthropists. Can private reserves create a vibrant green economy in places such as Patagonia? Several companies have tried to make money from conservation, through tourism, carbon sequestration and other initiatives, but successes are rare. Tompkins never bothered making money from his reserves – entrance fees were minimal – but was more interested in exporting US conservation philanthropy to Patagonia. It has proven difficult to make money from saving nature, so it is perhaps best to view it as a public good, worth doing even if it costs money. Either way, we are in a time where private actors, be it corporations, NGOs or philanthropists, are increasingly replacing governments’ role in saving nature. The successes and failures of Doug Tompkins contain lessons on how to do this fairly and effectively."
"The Scottish government has been warned it will miss its next climate target after failing to take sufficiently radical and urgent action. The Committee on Climate Change, which advises the UK and devolved governments on their targets and policies, said Scotland’s credibility would be damaged unless it took action before Glasgow hosts next year’s global climate talks.  The COP26 negotiations have been billed as the most important since the Paris talks in 2015. Nicola Sturgeon, Scotland’s first minister, has invested her personal and party’s reputation in taking action on the climate. Lord Deben, the CCC’s chair, said Scotland’s rapid progress on cutting emissions was in danger of stalling because its policies on transport, farming and home heating were insufficiently far-reaching. It risked missing its target of cutting overall emissions by 56% compared with 1990 levels by 2020, he said, and it needed to take urgent and significant action to enable it to hit its target of net zero by 2045. “Scotland has set an ambitious world-leading net zero target of 2045. Now Scotland needs to walk the talk,” Deben said. “The new legally binding target for 2030 – a 75% reduction in emissions compared to 1990 – is extremely stretching and demands new policies that begin to work immediately. “The spotlight is now on Scotland’s plan to deliver meaningful reductions across all sectors of the economy, including buildings, road transport, agriculture and land use. Scotland has outperformed the rest of the UK in cleaning up its economy, resting on the rapid closure of coal. As this chapter closes, the Scottish story must change. But so far we haven’t seen the same progress in other sectors.” He said both the Scottish and UK governments – the latter has a net zero target of 2050 for the UK as a whole – needed to collaborate closely to help each other hit their goals, particularly over heavy industries, green energy generation and carbon capture and storage. Green campaigners welcomed the CCC’s warnings but the Scottish government insisted it was committed to taking the necessary action. “We strongly agree [we] must walk the talk and adopt policies over the coming year that make those targets a reality,” a spokesman said. “The global climate emergency and a green new deal for Scotland are at the centre of our programme for government. However, we recognise that even more will need to be done for Scotland to reach net zero emissions by 2045.”"
"
Share this...FacebookTwitter“Do we have the next Solyndra at hand?”
I had to shake my head when reading the recently published Fox News report: Another taxpayer-funded energy company files for bankruptcy.

Image cropped from Aquion Energy.
Hat-tip: Indomitable Snowman
According to Fox News, Pennsylvania-based Aquion Energy had received “a $5.2 million stimulus-tied grant” (not a loan) from the U.S. federal government and that the company had once been “touted as a rising star in the energy storage business”. It even attracted “an investment from Microsoft founder Bill Gates“.
On Wednesday Aquion Energy filed for Chapter 11 bankruptcy.
“North American Company of the Year”
Fox News adds:
In January, the company was named ‘the North American Company of the Year Award’ at the annual Cleantech Forum in San Francisco…”
This is a classic example of how a house of cards gets built and begins to collapse. It should remind us of what can happen whenever bureaucrats and politicians get so caught up in a pie-in-the-sky idea that they literally become deaf to technical, scientific and economic reason.
Multi-tiered subsidy debacle


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




There was certainly no lack of warnings from skeptics that renewable energies (mainly sun and wind) were fraught with daunting technical and economic obstacles, and that the technology for overcoming these obstacles still remained decades out into the future.
But green energy proponents wanted to hear none of it, and so embarked on a blind and reckless money give-away of the sort never seen before. Already trillions have been earmarked worldwide — one trillion in Germany alone.
Today the green energy subsidy folly has since made its way down through multiple supply tiers as the government funds tens of billions of dollars to prop up the junk science that tells us us we need the green energies, which in turn also receive hundreds of billions in subsidies. This in turn has led to billions in subsidies made to companies claiming to have the technologies for overcoming the technical hurdles that the rest of us had long warned about.
What’s next? As expected these companies are now folding. It was a scam all along, as they were never as close to solutions as they led many of us to believe. Now the government will have to subsidize the many workers who are losing their jobs, at least for awhile, as scheme implodes on itself. What a folly.
Driven by rampant cronyism
Naturally almost everyone supports funding for the development of new energy technologies, but there is a huge difference between pitch-forking tax dollars, by the billions, into a huge crony feeding trough, and wisely and strategically allocating precious funds to the right places.
Unfortunately the green industry has been one driven by cronyism, and not technical or scientific merit — and certainly not economics. It has been a huge bonanza for very few at the great expense of the common good. The hundreds and hundreds of billions wasted would have been far better invested elsewhere.
The storage solutions come from the past, not the future
When it comes to efficient energy storage, putting a man on the moon is in fact easy compared to finding a new way that stores energy even a fraction as well as a chunk of coal, a bottle of gas, or can of petroleum does. In fact we find the storage solution millions of years in the past in the form of fossil fuels, and not the shady, over-hyped half-baked technologies of today.
There are all kinds of future energy storage solutions out there. But so far most of them hold little or no promise of even coming close to being economical. It’s going to take years or decades to develop them, and we have to be smart about how we do this. We cannot continue pouring money on something that will never work.
Yet, until bureaucrats wake up to this truth, expect many more Solyndras and Acquion Energy debacles in the years ahead.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitter Temperatures, Sea Levels ‘Naturally’ Rise
 30 – 40 Times Faster Than Today’s Rates

Modern Temperatures Only Rising 0.05°C/Decade

Since 1850, CO2 concentrations have risen from 285 ppm to 400 ppm.  During these ~165 years, the IPCC has concluded that surface temperatures have warmed by 0.78°C.  This is a warming rate of only 0.05°C per decade for 1850-2012 — which happens to be the same rate of warming over the 1998-2012 period.

IPCC AR5 (2013):     “The globally averaged combined land and ocean surface temperature data as calculated by a linear trend, show a warming of 0.85°C over the period 1880 to 2012, when multiple independently produced datasets exist. The total increase between the average of the 1850–1900 period and the 2003–2012 period is 0.78 °C, based on the single longest dataset available 4 (see Figure SPM.1). … [T]he rate of warming over the past 15 years (1998–2012; 0.05 °C per decade), which begins with a strong El Niño, is smaller than the rate calculated since 1951 (1951–2012; 0.12 °C per decade).”

Modern Sea Levels Only Rising 0.17 Of A Meter/Century

IPCC AR5 (2013):     “[T]he rate of global averaged sea level rise was 1.7 mm yr between 1901 and 2010“

Historical Hemispheric Temperatures Rose 2.0°C/Decade

According to a new paper, the Bølling Warming event 14,700 years ago raised the surface temperature for the entire Northern Hemisphere by 4 to 5°C within a few decades.  This is a hemispheric warming rate of approximately 2.0°C per decade, which is 40 times faster than the 0.05 °C per decade global warming rate since 1850 (and 1998).

Historical Sea Levels Rose 5.3 Meters/Century

Central Greenland’s surface temperatures rose by as much as 12°C during this time frame (14,700 years ago to 14,500 years ago).  Consequently, glaciers and ice sheets disintegrated rapidly and sea levels rose by about 18 meters (“12-22 m”) in 340 years.  An 18 m rise in 340 years is the equivalent of 5.3 meters per century, which is more than 30 times faster than the rate of sea level change (0.17 m per century) between 1901 and 2010.

Ivanovic et al., 2017     “During the Last Glacial Maximum 26–19 thousand years ago (ka), a vast ice sheet stretched over North America [Clark et al., 2009]. In subsequent millennia, as climate warmed and this ice sheet decayed, large volumes of meltwater flooded to the oceans [Tarasov and Peltier, 2006; Wickert, 2016]. This period, known as the “last deglaciation,” included episodes of abrupt climate change, such as the Bølling warming [~14.7–14.5 ka], when Northern Hemisphere temperatures increased by 4–5°C in just a few decades [Lea et al., 2003; Buizert et al., 2014], coinciding with a 12–22 m sea level rise in less than 340 years [5.3 meters per century] (Meltwater Pulse 1a (MWP1a)) [Deschamps et al., 2012].”


Bølling Warming/Sea Level Rise Occurred With Stable CO2


CO2 record for 25 kya-present courtesy of Kawamura et al., 2003

Greenland Warmed By 10°C Within 3 Years 14,700 Years Ago


Steffensen et al., 2008     High-Resolution Greenland Ice Core Data Show Abrupt Climate Change Happens in Few Years 
“A northern shift of the Intertropical Convergence Zone could be the trigger of these abrupt shifts of Northern Hemisphere atmospheric circulation, resulting in changes of 2 to 4 kelvin in Greenland moisture source temperature from one year to the next.”
“The d18O warming transition at 14.7 ka [14,700 years ago] was the most rapid and occurred within a remarkable 3 years, whereas the warming transition at 11.7 ka [11,700 years ago] lasted 60 years; both correspond to a warming of more than 10 K.”


Greenland Warmed By 8-15°C Within Decades During Last Glacial

CO2 concentrations remained essentially stable  and dangerously low (~180 parts per million) throughout the last glacial (roughly 80,000 to 15,000 years ago).  And yet despite the lack of CO2 flux, Greenland’s surface temperatures often warmed by about 10.0°C within a matter of decades during this period.  This indicates that CO2 variability is not a detectable factor in abrupt climate changes.

Sánchez et al., 2017


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Schmidt and Hertzberg, 2011     “There are twenty-five of these distinct warming-cooling oscillations (Dansgaard 1984) which are now commonly referred to as Dansgaard-Oeschger cycles, or D-O cycles. One of the most surprising findings was that the shifts from cold stadials to the warm interstadial intervals occurred in a matter of decades, with air temperatures over Greenland rapidly warming 8 to 15°C (Huber et al. 2006).”

In Contrast, There Has Been No Net Warming In Greenland For 80 Years

Zhao et al., 2016


Hasholt et al., 2016      “We determined that temperatures for the ablation measurement periods in late July to early September were similar in both 1933 and the recent period [1990s – present], indicating that the temperature forcing of ablation within the early warm period and the present are similar.”


van As et al., 2016     “JJA [summer] temperatures were higher in 1928 and 1929 than in any other year of the Qaqortoq record, both attaining values of 9.2°C. This suggests that ablation in those years may have exceeded the largest net ablation measured on the Greenland ice sheet (2010).”


Box et al., 2009     “The annual whole [Greenland] ice sheet 1919–32 warming trend is 33% greater in magnitude than the 1994–2007 warming.”


Conclusion

Modern rates of temperature change and sea level rise are quite modest and unremarkable relative to the magnitude of the changes in the geological past (that are 30 to 40 times larger or faster).  The abrupt and pronounced historical temperature and sea level rise events occurred without any significant changes in atmospheric CO2 levels.
In contrast, during the last 100 to 150 years there has been a dramatic rise in anthropogenic CO2 emissions and atmospheric CO2 concentrations…but no accompanying dramatic rise in temperatures or sea level.
Thus, the conceptualization that human activity or CO2 concentration changes are the primary drivers of temperature changes and sea level rise does not  seem to be supported by the geological evidence.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterUPDATE! “Arctic outbreak kills dozens… “
===============================================
Some impressive winter events have been taking place all across the northern hemisphere lately. Especially eastern and southeastern Europe have been pounded by massive snowfalls and tremendously cold temperatures. Turkey has been buried by heavy snows and extreme temperatures have gripped the entire USA and vast areas of Russia.
The global warming climate appears to have been hacked by natural factors.

Extreme cold and snow pound the northern hemisphere as some scientists warn of the potential for ice age conditions. Photo of Greenland by NASA (public domain)

In Russia Moscow celebrated the coldest orthodox Christmas in 125 years.
Snowfall paralyzed the city of Istanbul, Turkey.
Massive snow falls across the Balkans, Italy and Greece.
Dozens of Europeans have since frozen to death.
Northern Albania villages have been cut off by 120 cm of snow.
A temperature of -62°C (-80°F) was recorded in Chanty-Mansijsk (Russia).

Arctic conditions spread deep into the Mediterranean
These are all odd events when considering the “consensus” forecasts made 15 years ago, which warned that snow and ice would become rare.
In fact many scientists warned that Mediterranean conditions would spread into northern Europe. Lately, however, just the opposite has happened: Arctic conditions have plunged down into the Mediterranean!
Even worse, there is no end in site for the harsh European winter conditions, German mass circulation daily Bild writes here.
Warning of an impending ice age


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




So in the face of all the earlier global warming predictions, it is now only ironic that yesterday the German-language Pravda TV site here published an article warning of an impending ice age. The article cites Yale scientist Wei Liu and a recent paper he published on the “overlooked possibility of a collapsed Atlantic Meridional Overturning Circulation“. Should the ocean heat conveyor collapse, then there would be “a prominent cooling over the northern North Atlantic and neighboring areas, sea ice increases over the Greenland-Iceland-Norwegian seas and to the south of Greenland.”
Note: Pravda is a rebel-type German site, and so could be viewed to be in similar ranks as climate alarmist sites, but with an opposite view. A collapsed AMOC is still speculative.
Useless models
The Pravda report summarizes Liu’s paper as follows:
CO2 has nothing to do with it, rather the influence of the sun is the dominant factor: less sunspots (Climate: solar physicists project global cooling (video)), weakening of the earth’s magnetic field, impact on the jet stream are decisive factors that can quickly lead our climate into an ice age (Scientists: Consensus 2016: the climate models are useless (Video)).”
Pravda also describes how some experts say today’s climate models fail to take the known ocean and solar factors in account.
UPDATE:
Snow forecast for Europe for the next 10 days!:

Note how far south that snow cover reaches, all the way deep into the Mediterranean – covering Sicily, Greece, southwestern Turkey and North Africa.
Share this...FacebookTwitter "
"Writing in these pages last month, Robert Del Naja of Massive Attack articulated many of the concerns that the music industry is grappling with over its effect on the environment. The survival of the classical music industry relies very heavily on international touring. My colleagues and I at talent agency HarrisonParrott are this year celebrating our 50th anniversary; over the past five decades we have booked tens of thousands of concerts and performances around the world, for musicians from sopranos to saxophonists, conductors to cornet players.  In recent decades globalisation has opened markets and created audiences for western classical music far from its original roots in Europe. In the last 12 months alone HarrisonParrott has organised 38 international tours to more than 200 countries, many involving American and European orchestras travelling to Asia, which usually entails well over 100 people flying to different cities. Our roster is around 190 musicians, and many of them perform upwards of 100 concerts a year around the world. But now, faced with undeniable scientific evidence of manmade climate change, music and arts professionals must take a stand rather than blindly continuing with business as usual. We have a responsibility to galvanise our industry and question the established way of working in order to mitigate its ecological impact. Welcome work by the Tyndall Centre for Climate Research examines all the areas of impact touring has on the environment and recognises that the issue is complex: it cannot be solved by planting a set number of trees per tour. From audiences travelling to concerts to the power required by the halls, this crisis is the responsibility of all of us. Everyone must be conscious of their behaviour and acknowledge the active part they have to play. Planning permission for all new concert halls, for example, should only be given if the buildings will be carbon neutral. Existing concert halls must make radical changes to ensure they are as close to carbon neutral as possible. I’m proud of our musicians who are leading by example. Violinist Patricia Kopatchinskaja last season partnered with the musicians from the Orchester des Wandels (the Orchestra of Change) and performed works written as a reaction to the climate crisis, with all proceeds donated to environmental projects. Kopatchinskaja now organises her schedule so as to travel by train as much as possible, and our touring department plan tours that allow orchestras to avoid taking flights. As so often in debates about climate change, the Scandinavians are leading the way. The Norwegian conductor Tabita Berglund recently wrote: “Travelling back and forth, visiting a new orchestra every week, is not ultimately sustainable. There are more clever ways of organising ourselves, and these might bring new perspectives and values to our musical life. They might even create possibilities that we haven’t even thought about.” Her mix of urgency and optimism strikes exactly the right chord. So much of this debate takes place within a frame of comfort, with most of us kidding ourselves that we can keep on as we always have, and that by being a bit smarter – no single-use plastic bottles! – we can fix this. In truth, that time has long gone. Musicians and artists need to be disruptive in challenging assumptions about how our industry operates – and we all need to make real changes. Jasper Parrott is co-founder and executive chairman of HarrisonParrott Ltd"
"Bullfighting appears to be facing tough times once more. As many as 76% of the Spanish public may oppose it receiving public funding. What’s more, the conservative Partido Popular has just lost its absolute majority in the Spanish parliament, which it had been using to support bullfighting. This follows the loss of key city councils to allies of Podemos, which recently resulted in Madrid scrapping its longstanding subsidy to the oldest of the country’s 52 bullfighting academies.  The European parliament also recently voted to prevent Common Agricultural Policy (CAP) subsidies going to breeders of fighting bulls – potentially affecting bull-breeding estates in France and Spain, where bulls die in the arena.  Opponents see bullfighting as a barbarous and medieval relic which has no place in modern Europe. But who are these 21st-century “barbarians” who breed fighting bulls? And what do we know about the lives of the animals themselves, beyond their deaths on the torero’s sword? Probably not very much, in most cases. But as an anthropologist who worked for 15 months on a bull-breeding estate in Andalusia, I can offer some insight into the people who care for and know these animals.  “Care” and “know” are the right words here, incidentally. The job of the foreman on bull-breeding estates is to care for (“cuidar”) the herd. To care for fighting bulls means to know (“conocer”) them, so the foreman is often referred to as the “conocedor”: the one who knows. The conocedor is in charge of the everyday well-being of the bulls, with a particular focus on feeding up and exercising animals which will bear the colours of the estate at bullfights.  I worked closely with Joaquín, the conocedor of the Partido de Resina bull-breeding estate. He was an animal lover. His little dogs, Mona and Mono, were sleek working animals. They got more cuts of cured ham than I did. And while Joaquín was aware that raising bulls was a commercial endeavour, caring and good animal husbandry were central aspects of his job.    The bulls’ psychological and physical well-being is part of what determines whether they perform to their potential. This encourages breeders to raise them as “naturally” as possible: in herds, with varied grazing, space, shade, dust baths, water and hidden spots to which they can retreat. These formidable creatures are incredibly sensitive to change. To ensure proper care and minimise disruptions, the foreman works with a team of cowhands, working horses, the estate owner/manager, secretaries, grounds staff, vets, ethologists and even nutritionists. As with any industry, standards can vary. I cannot speak for all bull breeders, but I certainly saw how seriously people took correct care and a modern approach in Andalusia. The world of the bulls is often labelled “traditional”, but breeders don’t oppose modernity. These “barbarians” have their own vision of the future, which actually complements the CAP in some respects. Aside from food production – and let’s not forget fighting bulls are high-quality beef animals – CAP subsidies are intended to support the sustainable management of natural resources and rural economies. Partido de Resina is an island of biodiversity: around 500 hectares of open woods and marshland surrounded by a sea of monotonous orange, olive and peach plantations.   You could of course argue that commercial horticulture employs more locals, or that there are other ways of protecting biodiversity which do not involve bullfighting. You might be right. Right now though, outside Seville – and across Spain, France, Portugal and Latin America – there are vast stretches of bull breeding land that are already spaces of biodiversity. The Common Agricultural Policy is modern: progressive, science-based, future-oriented and bureaucratic. So are many estates in the world of breeding fighting bulls. Whatever your view, the European parliament’s decision to ban subsidies for bull breeders will be diffiult to enact. It would require legistlative change to the CAP, which is a sticky area of EU politics. After the vote, the European Commission informed the parliament that there was no legal basis upon which to enact the amendment. Every such challenge pushes the scattered bullfighting lobby to unite and strengthen its legal position. That could be important in future battles, but for now the victory for the European Greens who tabled the budget amendment is purely symbolic.  As for the the state of bullfighting more generally, things are more complicated than they might appear. Recent attendance figures from the Spanish ministry of culture don’t support a simple narrative of decline. Though there was a clear dip during Spain’s economic crisis, attendance in the year 2014/2015 overtook pre-crisis figures. The industry was also placed under government protection in Spain after the government voted in 2013 to give bullfighting intangible cultural heritage status. We are certainly not talking about a one-way losing battle.  So we should take care when it comes to derogative rhetoric, particularly about poorly understood traditions. It’s worth noting that attacks on bullfighting, while often out of genuine concern for the suffering of animals, also come from a tradition of northern moral supremacy. Not surprisingly, the European parliament vote on the anti-bullfighting amendment largely divided along a north-south axis, with 57% of Spanish MEPs voting against.  There is still a large public out there who appreciate bulls and bullfighting: 9.5% of Spaniards attended events involving fighting bulls in 2014-15. These people live in the same modern Europe as the rest of us. Anyone who condemns bullfighting as barbaric should not judge until they have looked beyond the arena to the wider world of the bulls."
"If the prophets of technology are to be believed, the best hope for solving the climate crisis is ever more efficient batteries. But the race to produce enough materials for this energy-storage revolution is creating a host of other environmental problems, as cobalt-producing nations like the Democratic Republic of the Congo, Zambia and Cuba are discovering.Lung disease and heart failure have been linked to high levels of this element, while the mines that produce it are blamed for devastated landscapes, water pollution, contaminated crops and a loss of soil fertility. Scientists are also investigating a possible link to cancer.As with any chemical, the risks depend on the amount and duration of exposure. Cobalt is a metal that occurs naturally in rocks, water, plants, and animals. It is less toxic than many other metals. At low levels, it is beneficial to human health and is a component of vitamin B12.  But the dangers of high doses are increasingly apparent. They were first discovered in the 1960s, when a Canadian brewer started adding cobalt to beer to ensure a consistently foamy head. A surge of fatal heart attacks among heavy drinkers, who also had poor diets, was linked to the cobalt additive. More recently, German doctors have questioned whether surgical implants containing cobalt might also be causing hypersensitivity reactions.Cobalt is used in alloys, semiconductors, fertiliser, as a drying agent for varnish and enamel coating for steel. In the form of cobalt sulphate, it is particularly important in lithium batteries, where it acts as a cathode stabiliser.These lithium-ion batteries are increasingly in demand for electric cars, laptops and mobile phones, which means cobalt – once deemed a worthless chemical – is now the object of a geo-strategic rivalry between the world’s biggest economies. It is also potentially exposing humans and other species to greater doses.A study this year noted that global production had increased more than sevenfold between 2008 and 2015 with an increasingly evident impact. “The appearance of cobalt levels exceeding the environmental threshold levels has led, however, to disturbances in the proper functioning of living organisms,” the paper concluded. Another paper said extended blood concentrations of more than 700 µg led to heart problems and impaired eyesight and hearing. It considered pregnant women who ingest food or drinks containing high levels of the chemical at greatest risk. Earlier research has detected side-effects including diarrhoea, headaches, blood pressure changes and damage to the immunological system. High concentrations of cobalt have been linked to the death of crops and worms  vital for soil fertility. The Centers for Disease Control and Prevention in the US warns that chronic exposure can cause “hard metal disease” and even skin contact with cobalt salts or hard metals can result in rashes. They say the safe workweek limit is 0.1 milligrams per cubic metres.The environmental impact extends through the life-cycle of the product from refineries, battery plants, consumers goods manufacturers, electronic recycling facilities and waste dumps. Among the most affected are workers at poorly-regulated mines. This has allegedly reached alarming levels in the Congo, which produces more than 60% of the world’s cobalt. Concerns have also been reported in many other countries, where the mineral is often mined in tandem with nickel, copper or silver. In Australia, which is the world’s second biggest producer, authorities issued the Whim Creek mine in Pilbara with an environmental protection notice after floods led to levels of cobalt, copper and other metals significantly above water quality guidelines. In Cuba – which has the world’s third biggest cobalt reserves – satellite analysis of the huge open-cast nickel and cobalt mine at Moa in Holguín Province appears to show what researchers have described as a “lunar-like landscape” devoid of life over 570 hectares (1,408 acres), while they say their research shows pollution plumes have contaminated 8km of coastline and 10km of the Cabañas River. Despite these environmental problems, cobalt production is seen as the key to rapprochement with the US, which needs the mineral for its electric car industry and wants to ease Chinese domination of the global supply chain.In Zambia, studies of soil and mango fruit grown near copper and cobalt mines have revealed metals above the safety limit. NGOs say miners in the country are also prone to silicosis and tuberculosis. It is a similar story at Madagascar’s biggest foreign investment project – the $8bn (£5.9bn) Ambatovy nickel and cobalt mining complex near Toamasina, which has been blamed for air and water pollution, as well as health problems among the local population. Official data, independent reports and scientific studies are scarcer in other producing countries, though the authorities appear to be concerned. In China inspections by the Ministry of Ecology and Environment in June 2018 temporarily halted production in Jiangxi province, which is the global centre of cobalt refining. Two years ago, the Philippines closed or suspended 17 nickel mines – several of which also produce cobalt – because of environmental concerns.The concerns are likely to grow along with production. It is an exaggeration to say lithium-ion batteries will become the new oil, but a low-carbon future will almost certainly mean high-cobalt energy storage. In 2017, the world’s battery makers used 41,000 tonnes of cobalt (a third of total production). By 2025, this is expected to increase to 117,000 tonnes. The surge in production will increase the dangers of exposure to high doses. To prevent this, more studies and better safeguards are needed now – particularly in DRC and other countries where people and habitats are most at risk. Failure to do this will mean batteries wreck lives rather than saving the climate. "
"
Share this...FacebookTwitterThe ‘Energiewende’ (transition to green energies) risks leading to a complete meltdown of Germany’s power generation sector.
The latest news is that German electricity giant Eon expects to post a massive 12.4 billion euro loss for the year 2016, NTV news site writes here. Careful not to link the loss to Germany’s failing renewable energy bid, NTV blames it on Eon subsidiary Uniper and its write-downs for “spun-off nuclear power plant business” and the “strongly fallen wholesale power prices“.

Photo: Eon
Eon share prices plummeted from €7.57 a share earlier this weak to €6.98 by early Thursday morning, before clawing back up to €7.15 in Friday trading.
The figure is only a preliminary estimate, and the final figure will be released on March 15. But the Handelsblatt writes that the loss could even be higher: “It’s going to be even higher,” say those within the company.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Handelsblatt reports that “at least 1000 jobs” are planned to be slashed by Eon in an effort to get the cost situation under control.
Massive financial trauma
Just days ago NTZ wrote here that another of Germany’s major power producers, RWE, also posted staggering losses of 5.7 billion euros.
Eon’s latest loss comes in the wake of a 7-billion euro loss the German power giant posted a year earlier, in 2015.
Once steady makers of profits and providers of solid, high-paying technical and engineering jobs, Germany’s traditional power industry has been bleeding profusely since the Energiewende (transition to renewable energies) has really took hold. Jobs have been lost by the thousands.
The German power grid used to be considered as one of the most stable worldwide, providing low-cost and reliable electricity to consumers, but has since deteriorated due to distorted market conditions and the wildly fluctuating wind and solar power that is required to be fed in.
 
Share this...FacebookTwitter "
"The 2019 Guardian and Observer climate emergency charity appeal, aimed at planting trees and protecting forests and woodlands, has raised more than £250,000 in less than a fortnight. The appeal is supporting four charities which promote environmental and social justice through natural climate solutions, ranging from safeguarding the Amazon rainforest to rewilding parts of the Scottish Highlands, to planting trees in Britain’s towns, cities and countryside  The four charities are: Woodland Trust, Trees for Life, Trees for Cities and Global Greengrants Fund UK. Responding to the news, Steve Micklewright, the chief executive of Trees for Life, said he was overwhelmed by the generosity of Guardian and Observer readers. “Through their support, Trees for Life will be able to do more in the fight against climate chaos through natural solutions and enable wildlife to flourish and communities to thrive.” The chief executive of Trees for Cities, David Elliott, said: “The amazing support for this appeal will not only result in thousands of trees being planted across the UK and internationally, but also demonstrates that the climate and our natural environment are loud and clear priorities in the public’s mindset.” Guardian and Observer journalists will be taking phone donations in person at the annual charity telethon between 10am and 6pm this Saturday. Those taking readers’ calls include: Katharine Viner, Polly Toynbee, Owen Jones, Gary Younge, Marina Hyde, George Monbiot, John Crace, Anushka Asthana, Jonathan Freedland and Sali Hughes. Introducing the appeal earlier this month, the Guardian editor-in-chief, Viner, said that while it was crucial to remain focused on the giant steps that governments and corporations must take to combat the climate crisis, our partner charities highlighted practical actions that citizens could take to renew nature and the planet. She wrote: “Planting and protecting trees is a positive way that we can help. Trees are vital in producing oxygen and absorbing carbon dioxide from the atmosphere. They provide a natural habitat for animals, birds and insects and stem the decline of biodiversity. “They can prevent flooding and soil erosion. They provide shelter and shade, and reduce air and noise pollution. Forests and woodlands are natural sources of beauty, wellbeing and peace.” "
"Biological evolution, the changes in living organisms over time, is often considered an elusive and long process that cannot be observed during a human lifespan. But is that really the case? And is there evidence that we can see it happening right before our eyes? Evolution is a process that occurs at a different pace in different organisms. For instance, paleontologists have shown, thanks to the fossil record, that it took a million years for whales to evolve from their land-dwelling mammalian ancestors.  But evolution can also be observed and monitored in living organisms within a human lifetime. This is true for infectious agents, such as bacteria and parasites, that can evolve extremely quickly to resist the drugs we use to fight them. But it is also the case for larger organisms, such as vertebrates – the back-boned animals. One of the most famous examples was documented in a population of finches living on Daphne Major island in the Galapagos archipelago. In this case, ground finches Geospiza fortis evolved larger beaks after a major drought in 1977. During this harsh period, the small seeds on which the ground finches were feeding on became scarcer, and most of the birds died.  However, scientists noticed that the mortality rate was lower among larger birds, with a larger beak. They were able to crush bigger and harder seeds to feed on while the small seeds were depleted. Large-beaked finches had a great advantage over their small-beaked relatives to survive these tough conditions. They reproduced more and transmitted this trait to their offspring. Following the drought, scientists observed a shift towards larger beaks and body size among subsequent generations.  Strikingly, researchers reported a reversal towards small body and beak size after large rain falls and abundant small seed supply in 1983. Monitoring the finch population over the years has thus allowed scientists to observe their rapid evolution and to link it to different environmental changes.  The fact that evolution can be rapid not only allows scientists to observe it in action, it also means that they can perform real-time experiments in the field to test their hypotheses by changing specific environmental parameters.  Recently, a team of scientists in Florida demonstrated that rapid evolution of a species can be triggered by a negative interaction with a competitor. To do so, the scientists introduced an invasive species of anole lizard to a group of small islands that shared the same lifestyle and diet as the native one, Anolis carolinensis.  The invader anoles forced the native ones to move from their original habitat on the forest floor and into the trees. Scientists were not only able to follow the rapid shift in the lifestyle of the native anole species (they perch higher and higher in the trees over time), but also observed that it involved rapid changes to their body shape. Within only 15 years (20 generations), the native anole species evolved larger toe pads with stickier scales, enabling them to climb more efficiently in their new, higher habitat. Closer to home, many invertebrates change quickly, too. Bed bugs, for example, have rapidly evolved in the last few decades, developing tougher exoskeletons to protect them from the insecticides and other poisons in their increasingly urban environment. In his On the Origin of Species, Darwin considered evolution as a very slow process, the outcome of which would have taken much more time than an human lifespan. Of course, Darwin’s assumption was making sense of things in the scientific context of his epoch, but the field observations and experiments conducted over the past 40 years have shown that animals often evolve very rapidly indeed. Life, it seems, never stays still."
"
Share this...FacebookTwitterIt’s good to see that I am not the only person looking critically at Germany’s rather inept attempt to switch over to green energy sources in order to reduce CO2 emissions.
The environmentalprogress.org site here presents a good overview of Germany’s recent performance when it comes to reducing so-called “greenhouse gases”. Unfortunately German citizens have not seen any success recently for the tens of billions of euros they are paying extra for the “Energiewende” (transition to renewable energy).
A new Environmental Progress analysis finds that “German emissions increased in 2016 for a second year in a row“, blaming the result on “the country closing one of its nuclear plants and replacing it with coal and natural gas“. Obviously wind and sun failed to step in and do the job.
Environmental Progress reports the shocking result:
Not only did new solar and wind not make up for the lost nuclear, the percentage of time during 2016 that solar and wind produced electricity declined dramatically.
Germany added a whopping 10 percent more wind turbine capacity and 2.5 percent more solar panel capacity between 2015 and 2016, but generated less than one percent more electricity from wind and generated one percent less electricity from solar.”
The site describes Germany’s wild variability that the country has to deal with producing power from sun and wind.
2016’s rise to 916 gigatonnes of CO2 extends Germany’s streak of failing to lower its CO2 emissions to 8 years. The following chart goes to 2014. The year 2015 saw 908 gigatonnes CO2 emissions compared to 902 in 2014.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Chart source: UBA Umweltbundesamt (Federal Office of the Environment). 
This means Germany literally has made virtually no progress at all over the past decade. The latest jump in CO2 emissions make the chances of Germany reaching its 2020 CO2 reductions target even far more remote. Add to this that subsidies for wind and solar power recently have been watered down and the surge of up to 2 million refugees will boost demand for energy. Germany’s commitment to fulfilling the Paris Agreement is looking like a real farce.
Another fact that shows that solar and wind will never work: Environmental Progress points out that even if Germany adds 50% more solar panel capacity by 2030, it will boost solar’s share of power from 6% to 9 percent.
Germany’s Energiewende has only succeeded in massively elevating Germany’s consumer power prices, making its power almost twice as expensive as power in neighboring France, which relies heavily on nuclear. While France’s power is half the cost, the country also emits far less CO2 from electricity production:
 Chart source: http://www.environmentalprogress.org.
That’s what one would call success. Why some countries are still racing into the renewable energy foray despite the German debacle, remains a mystery.
Read all of the Environmental Progress report here.
 
Share this...FacebookTwitter "
"Like grave-robbers, they come at the dead of night, wearing camouflage and dark clothes to avoid detection. Armed with increasingly powerful metal detectors, they work their way across the fields, digging holes wherever they find a target. Landowners wake to find their crops trashed and dotted with holes. Nobody can ever know what they found, as any artefacts are rapidly sold through online auctions or smuggled out of the country. They are called nighthawks – and they are the bane of archaeologists across the country. The English landscape is filled with ancient sites – from prehistoric forts and barrows, to Roman towns and villas, medieval villages and industrial remains. Each archaeological site has a unique story to tell and will often contain buried artefacts that help us to understand our history. Around 37,000 of these sites have been identified as ancient monuments: protected from development and treasure hunters.  For many years, archaeologists have been deeply divided on the subject of metal detecting. Some see detectorists as an army of keen amateurs, who go brave all weathers in the hope that one day, they will strike lucky. Provided that they work within the law and with the permission of landowners, they are generally seen as harmless, even beneficial.  Detectorists are encouraged to report their finds to the Portable Antiquities Scheme – a massive recording operation run through the British Museum – which maintains a database of every item that has been reported. The website contains pictures of more than 1m objects, based on more than 700,000 records. This huge amount of data has helped archaeologists to find new sites and to better understand little-known periods of our history as represented by artefacts, rather than buildings and physical remains. Some suspect that this is just the tip of the iceberg of the many important finds that have been made – possibly as many as 4m – in recent years. But there is a dark side to this seemingly harmless hobby. A small minority of treasure hunters try to evade permissions and go onto well-known, protected sites, wielding powerful metal detectors with the intention of stealing valuable artefacts.  England and Wales are unusual in that metal detecting is legal, provided that detectorists avoid ancient monuments and declare any treasure (defined as gold and silver or prehistoric metalwork) to the Coroner. In Scotland and Northern Ireland, detectorists must obtain a licence to search anywhere, while in most of continental Europe, metal detecting is a crime.  The rather more liberal approach taken in this country means that we now know about many more sites than archaeologists alone could have discovered. But it also means we have a serious problem with looting which, until now, authorities have largely failed to face up to: police often neglected to prosecute and magistrates were reluctant to convict. In the past, the ambiguous legal position on heritage crime has often allowed those arrested to plead ignorance, by claiming they didn’t realise that the site was protected, or that they even needed permission. In a joint investigation between the University of Bristol and the BBC, we set out to discover just how prevalent night-hawking is. Fortunately, we now have new motion sensing, infrared camera traps, which can film at night time without artificial lighting – a technology largely developed for wildlife photography.  We set up six of these cameras around a well-known Roman settlement and protected ancient monument in the Cotswolds, and retired for a week to see what we might capture. There were, of course, several deer and foxes, but to our amazement our cameras also caught the full details of a night-hawking operation.  The group arrived at 10.30pm, wearing full camouflage and beanie hats, and armed with powerful metal detectors. They stayed for around four hours, and we filmed them scanning the fields and digging holes across the site. A getaway car finally picked them up at 2am. We have no idea if they found anything significant or not but they were clearly equipped with the intention of looting, just as a burglar with a crowbar is equipped to steal. The investigation aired on Inside Out West, and you can view the whole episode on BBC iPlayer. Coincidentally, around the time of our investigation, the Sentencing Council – which produces independent guidelines on sentencing for the judiciary – revised its recommendations on heritage crime. Now, night-hawking is classed as an aggravated harm, along with stealing from war memorials and stripping church roofs.  We hope that stiffer sentences will deter the nighthawks, and that new technologies will make it much easier to collect evidence of wrongdoing. Now, for the first time, it looks like we might just have the tools we need to defeat the nighthawks, and save our heritage for future generations."
"
Share this...FacebookTwitterIt’s time for wind energy proponents to admit that their well-intended idea of wind energy has in fact had disastrous ecological consequences.
No technological development has ever so negatively impacted the environment and landscape like wind turbines have. Not only do they blight the scenic landscape and make people living near them ill, they are a serious killer of avian wildlife, as made evident by a recent German ZDF Terra X documentary shows (starts at 34:15 min). Hat-tip: Alessandra E.

Wind turbines in fact do pose serious threat to endangered birds. Image cropped from ZDF Terra X.
One of Germany’s most protected bird species is the endangered red kite hawk. Today it faces a threat that is unprecedented: towering wind turbines strewn across the German landscape. The ZDF public television documentary reveals that the measures enacted by government wind park approval authorities have done nothing to protect this predatory bird.
The segment focusses on the southwest German state of Baden Württemberg, where its Green state minister is attempting to force through the construction of thousands of turbines on the regions idyllic landscape in a bid to go green.
To survive, the red kite finds its meals on the ground, and so it’s only natural that its sharp eyes remain focussed downward, and not ahead. That habit spells huge trouble for the bird in wind turbine regions. According to environmental journalist Andreas Kieling: “Ornithologists and experts have called wind turbines bird shredders.”
Worldwide, the ZDF reports, only about 25,000 pairs of the red kite remain — 60% of them are in wind-turbine country Germany.
Ignorance, corruption and criminal sabotage
Using a fake owl (owls are the enemies of red kites) as bait (37:20), researchers caught a red kite and tagged it with transmitter, thus allowing them to later track the bird’s flight patterns and the actual living space the bird really requires. As the results will show, the living space required by red kites is far greater than what is claimed by the wind industry and the officials who approve the parks.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Wind turbine approval boards have the responsibility of keeping wind turbines at a safe distance away. Unfortunately, likely due to a mixture of ignorance and outright corruption, the wind turbine rules in many cases call for a setback distance of a mere 1000 meters from a nest. We reported here last year of how stork nests were likely criminally sabotaged in order to clear the way for wind park construction approval!
Need 12 sq. km of space, and not 3 sq km.
Just how far the birds fly from their depends strongly on how far they have to go to find their prey. In the ZDF Terra X documentary, days later the researchers provided a graphical image of the flight activity of the tagged bird.

Flight area and plot of red kite activity after 30 days. Image cropped from ZDF Terra X.
The result is that the endangered red kite needs far more than a single measly 1 kilometer setback distance and 3 sq km of safe activity area as often claimed, but rather it needs some 12 sq km of space. In fact the examined bird located near Lake Constance flew as far as 19 km away from her nest (41:05). Other bird species showed similar patterns and space needs, yet turbine approval boards insist the current requirements are enough.
The experts disagree and summarize that the now specified setback distances offer “certainly no effective protection” for the birds.
Sooner or later every red kite ends up in the area of a turbine. The risk of a collision is hugely large.”
The expert then adds that in the areas where there is a large population, as is the case near Lake Constance, there should be “absolutely no wind turbines“, or to shut them down when the birds are hunting.
The ZDF Terra X report says that no one knows just how many red kites fall victim to turbines each year. Counting is difficult because a struck bird is often quickly taken away by foxes or other scavengers. One thing is sure: turbines are killing the endangered birds, and likely in numbers that wind lobby hopes will never be known.
 
Share this...FacebookTwitter "
"Australian businesses are calling for a more ambitious national climate policy, backing a target of net zero emissions by 2050 and raising concerns about the lack of a coordinated energy policy and the government’s proposed use of carryover credits. The findings are contained in a Carbon Market Institute survey of more than 200 businesses, to be released on Thursday, which reveals 96% of those surveyed believe Australia should not delay the transition to a decarbonised economy.  About a third of businesses surveyed are emissions intensive companies that have obligations under the National Greenhouse and Energy Reporting Act, and include the mining, oil and gas and manufacturing industries. Others surveyed include investors, carbon project developers, carbon market experts and professional service providers. The survey finds widespread concern among business and industry groups about the government’s current policy settings, with 94% saying the approach is insufficient to meet Australia’s 2030 Paris commitment to cut emissions to 26%-28% of 2005 levels. This was an increase from the 92% who expressed the same view in 2018 when the survey was last undertaken. A similar number of respondents were concerned that current policies were also inadequate to help business manage the risks and capitalise on the opportunities in the transition to a net-zero emission economy. In October, the Reserve Bank of Australia used its financial stability review to warn that it was becoming increasingly important for investors and institutions to actively manage their carbon risk. Corporate regulators, the Australian Securities and Investments Commission (Asic) and the Australian Prudential Regulation Authority (Apra) have also warned that climate change is a foreseeable risk for corporate Australia. The findings come as Australian officials return from the UN climate change conference in Madrid after defending the country’s plan to use 411 million tonnes of emissions credits from the Kyoto protocol to meet its Paris targets. On Wednesday, the energy minister, Angus Taylor, told the Australian Financial Review that Australia could possibly meet its abatement targets without the use of carryover credits, claiming the government was already “over delivering”. But a government report released last month showed the Coalition was relying on the accounting loophole negotiated, with Australia expected to achieve just a 16% cut below 2005 levels by 2030 if they did not use the credit. The carryover credit comes from Australia achieving a better result than it agreed to under the first Kyoto target, which allowed for an 8% increase in emissions between 1990 and 2010. The CMI survey finds that about three-quarters of business respondents (76%) do not believe that Australia should be able to use the carryover units to achieve its 2030 emission reduction target, joining critics and other countries who want the practice banned. Also heaping pressure on the government to set more ambitious mid-century targets, which the Coalition has indicated will be outlined next year, the vast majority of businesses (83%) support a national target of net-zero emissions by 2050. Almost all of those surveyed (96%) agreed that the longer Australia delays decarbonisation, the more “abrupt, forceful and disruptive” the policy response will need to be, especially for carbon-intensive industries. When asked what Australia’s long-term policy should look like, the business leaders surveyed nominated a legislated net-zero 2050 target, coupled with a coordinated national climate policy suite to meet the target with a clear trajectory that was regularly reviewed. They also called for “sectoral decarbonisation strategies” that identified abatement potential, structural barriers and economic opportunities, a price on carbon, and a plan to ensure orderly closure of old coal plants and their replacement with clean energy. The survey shows support for changes to the safeguard mechanism, which sets emissions caps for high emitting facilities, with 83% of businesses wanting the baselines set under this scheme to be reduced. About three-quarters (74%) want lower-emitting facilities also to be captured under the mechanism. Australia has been left without a cohesive national energy policy after Scott Morrison dumped the national energy guarantee that helped terminate Malcolm Turnbull’s leadership. In a sign that the issue of climate change and carbon emission reduction is becoming more pressing, 84% of survey respondents reported that their organisation recognises the financial and strategic risks of climate change at a board and executive level. Just under half (42%) reported increased shareholder engagement regarding climate change for their organisation in the past 12 months. The chief executive of CMI, John Connor, said there was a gap between business expectations and government policy that was concerning business. “This survey tells us that many in Australian business – including Australia’s highest-emitting companies – are already planning to transition to a net-zero emissions world,” Connor said. “Business is looking for more ambitious climate policies to set a defined pathway and assist them in managing this.” Connor said Australian businesses were grappling with the knowledge that science required net-zero emissions by 2050, while also dealing with “policy volatility, evolving global carbon markets, investor calls for action and reporting requirements”."
"Climate change has reduced Australian farms’ average annual profitability by 22%, or around $18,600 per farm, in the past two decades, according to the agriculture department. In a report released on Wednesday, the Australian Bureau of Agricultural and Resource Economics and Sciences has found that since 2000 changes in climate have reduced the revenue of Australian cropping farms by a total of $1.1bn a year. The report notes that average temperatures increased by about 1C since 1950 and compares Australia’s climate over the period 2000 to 2019 with the period from 1950 to 1999 by holding other variables, including farm output and commodity prices, constant. Abares, the Department of Agriculture’s science and economics research division, has developed a statistical model called Farmpredict using data from 40,000 farm observations to simulate differences in more than 50 physical and financial farm variables. Since 2000, climate change has had a negative effect on the profitability of broadacre farms in Australia. Only Northern Territory farms improved profitability, up 8.7%, with massive cuts to profit in Victoria (–37.1%), Western Australia (-25.8%) and New South Wales (-25.5%) attributed to climate change. Cropping farms were the worst hit, with revenue down 8% or around $82,000 a farm, and a 35% reduction in profits, or $70,900 for a typical cropping farm. Report co-author David Galeano said adaptation to climate variability “is certainly helping” – and without it farms would have experienced a 26% reduction in profit, and cropping farms’ profits would be down 49%. Sheep farms experienced an 18.2% reduction in average annual profit, or $6,100 per farm. Beef farms were “less affected overall” with a reduction in average profits of 5%, although some areas – including south-western Queensland – were more affected than others. Climate conditions have “also contributed to increased risk in terms of more variable cash income and profitability, particularly for cropping farms”, the report says. Climate change increased downside risk, with the chance of “very low” profits – below 2% – more than doubling since 2000. The Abares report says that the current drought across much of eastern Australia “has demonstrated the dramatic effects that climate variability can have on farm businesses and households”. It says that drought-affected NSW recorded “large falls in profit in 2018–19” but less drought-affected regions, including Western Australia, increased profits due to high commodity prices for grain and livestock. Abares warns that drought policy faces “an almost unavoidable dilemma: that providing relief to farm businesses and households in times of drought risks slowing industry structural adjustment and innovation”. “In some cases, well-intentioned policies can also disadvantage farmers who have been better prepared – or luckier – than farmers who are provided assistance and relief, diluting management incentives and raising difficult equity issues.” Sign up to receive the top stories from Guardian Australia every morning It recommends that in addition to supporting farm households experiencing hardship, drought policy should “promote resilience and improved productivity”. Climate change is making drought worse in Australia, although senior government figures including the Nationals leader, Michael McCormack, tend to emphasise that Australia’s climate has always been characterised by intermittent drought and flood. The centrepiece of the Coalition’s drought policy is a $5bn drought future fund that will make annual payments of $100m to improve resilience. In November the government announced an extra $1.5bn for drought relief, consisting of a $1bn concessional loan package for farmers and small businesses affected by the drought and $500m for “direct investment into communities”. Modelling the effect of drought, the Abares report says a cropping farm will see profit decrease from around $230,000 in a typical year to a loss of $125,000 in a dry year. For an Australian beef farm, profit falls from $60,000 in a typical year to a loss of $5,000 in a dry year."
"In the arid lands that have seen one of the most brutal wars of the 21st century so far, green shoots of peace may finally be appearing. In the hot Darfur fields farmed by Adam Ali Mohammed, these green shoots are alternating rows of lentils and melons. “We tried lentils before, but there was not enough water,” the farmer says. Here in the Sahel, water is the key to life, but there is precious little of it – just 20cm of rain a year – and it is the source of much of the conflict. The climate crisis is making marginal existences even more fragile. It is no future threat here, with the Sahara marching southwards, temperatures rising and precious annual rains becoming ever more erratic. But a new approach is bearing fruit. The seasonal river that runs by El Fasher, the capital of Sudan’s North Darfur state, has been transformed by community-built weirs. These slow the flow of the rainy season downpours, spreading water and allowing it to seep into the land. Before, just 150 farmers could make a living here: now, 4,000 work the land by the Sail Gedaim weir. Crucially, the weirs are not just promising a more bountiful future, but a more peaceful one. Communities of farmers and nomadic camel herders, deadly enemies during the war, are coming together to plan and build them. This has often meant meeting face to face for the first time since the conflict began in 2003, but recrimination has turned into cooperation over shared water, and even resulted in wedding invitations. “There was a lot of killing here – there isn’t enough time to tell you about it all,” says Sheik Abdoelhman Saeed, part of the Sail Gedaim weir committee. “But now we are planning among ourselves to reach new areas with weirs.” Millet and sorghum were the staples, but Ali Mohammed has been able to expand into cucumbers and okra, lemons and grapefruit, and is trying sunflowers for the first time, all of which are valuable cash crops. “You give me the seed, and I will test it,” he says. Millions were forced to flee the violence in Darfur that killed as many as 400,000 people during a decade of conflict from 2003. Many people remain in huge camps today. “But if the fields are green like now, nothing could force me to go anywhere else,” says Ali Mohammed. The weir project on the Wadi El Ku river has also brought women, who do much of the farming work, to the fore. “Before, I was not able to sit with these men, and to speak like this,” says Azaz Mohammed, as the dam committee from 22 villages meets, sitting on carpets in the shade of a tree and sharing a meal harvested from the surrounding fields. The weirs are a “pioneer project”, says Enaam Ismail Abdalla, director general at the ministry of production in North Darfur, adding that the timing of the rains has completely changed due to climate change. The weirs are enabling people to return to their villages and adapt to the changing climate, which would otherwise drive them away once again, she says. She hopes they will be replicated in other parts of Darfur, Sudan and beyond. The collaborative climate-proofing provided by the Wadi El Ku project shows a way to tackle the complex mix of climate impacts, conflict and migration that are thought to be rising around the world. Ever wondered why you feel so gloomy about the world - even at a time when humanity has never been this healthy and prosperous? Could it be because news is almost always grim, focusing on confrontation, disaster, antagonism and blame? This series is an antidote, an attempt to show that there is plenty of hope, as our journalists scour the planet looking for pioneers, trailblazers, best practice, unsung heroes, ideas that work, ideas that might and innovations whose time might have come. Readers can recommend other projects, people and progress that we should report on by contacting us at theupside@theguardian.com The Darfur conflict was labelled “the first climate change war” by some observers, with the then-UN secretary general Ban Ki-Moon saying in 2007: “Amid the diverse social and political causes, it began as an ecological crisis, arising at least in part from climate change.” Research has shown that climate impacts such as drought and increasing temperatures increase the risk of armed struggles, particularly in regions where populations are already divided. Bitter divisions are starting to dissolve 50 miles (80km) north of El Fasher along the Wadi El Ku, where the next phase of the project is taking place. Until very recently, project staff needed a convoy of dozens of heavily armed soldiers to visit. “Now we can go on our own: that is a real sign of improvement,” says Atila Uras, head of the United Nations Environment Programme (UNEP) in Sudan, which oversees the €16m EU-funded project, which is aiming to help 180,000 people. In the semi-desert encampment of Mamora, the pastoralists are reluctant to talk about the war. But after a traditional greeting meal of camel milk and goat meat inside an ornately decorated tent, Omer Ali Mohammed says: “For sure, during the conflict there was a breakdown of relations between the different communities.” He is a former member of the Rapid Support Forces, a government paramilitary group that grew out of the Janjaweed militias used by the former Sudanese regime to fight rebels in Darfur. In April, a revolution deposed President Omar al-Bashir after a 30-year rule. He is now in jail in Khartoum and faces genocide charges at the international criminal court in the Hague. “The government fuelled us to fight against each other, but we have realised we were being misused,” says another Mamora nomad, Mohammed Ahmed. “We got sick of the conflict. Now we want to live in peace. Our fathers and grandfathers used to live in peace.” The Wadi El Ku project began work in this area in September with a six-day peace conference of seven pastoralist groups and 44 farming villages. “At first, they were all very angry and shouted a lot. The farmers said these [pastoralists] have killed our people,” says Awadalla Hamid Mohamed, of NGO Practical Action, which is implementing the UNEP project. “But we gave them time and the tensions slowly reduced. It took two months,” says Hamid Mohamed, who managed to escape from Janjaweed kidnappers nearby in 2015, when working on the early part of the project. “They realised coexisting was good for them,” he says. The nomads need clear routes for their 600-mile (1,000km) migrations, which were getting blocked by farms, while the farmers need milk, meat and safety for themselves and their crops. The nomads also say that they feel marginalised, with little access to medical care and deaths during childbirth common. The key was enabling the communities to come to an agreement on how to share the water and land. “There are layers and layers of conflict, so we started with what they could agree on, and everyone agrees there is a problem with the environment, with water by far the biggest priority,” says Uras. “But if you look like you are dictating things, that is a killer.” The peace meeting led to a breakthrough: for the first time in years, the nomads invited farmers to a wedding in September. More than 800 people attended, including many young people who had never met, with some guests travelling from 25 miles (40km) away. “It was an opportunity to rebuild the old relations,” says Ibrahim Abdalla, the nasir (leader) of the pastoralists. In nearby Kafod, the hundreds of donkeys gathered on the edge of the town show it is market day. Farmer Abdelrahman Hamad grows potatoes, radishes and onions on the Wadi El Ku, which runs nearby, and says he lost people to the conflict: “But the project has brought us together. Now I can go to the pastoralists’ area no problem. There were a lot of problems to overcome, of course, but everybody needs peace.” Downstream, at the village of Shagra, a colourful crowd of women and children have gathered to see the star entertainer Sasa. As the crowd processes around her, clicking their fingers above their heads, she sings a favourite tune: “Look at the widows and the little children / They have drained our tears / Forwards, oh Darfur.” The gathering is celebrating 9,000 new trees being planted by a local women’s community association, replacing the many destroyed for firewood during the war. The shady spot is a now a meeting place, and the gum arabic trees a future source of income. “The men tried to plant trees – they failed,” says Fathia Hamed Xagod, chair of the women’s association. They lacked the patience, she says. In El Fasher, Fuzia Abass, chair of the Women’s Development Association Network, says the Wadi El Ku project is having a big impact on women’s lives. More widespread access to water means much less time carrying it to their homes, while the greater incomes from the farms means more girls are going to school. “But while women are doing most of the work, the men are dominant in the decisions,” she says. The Wadi El Ku project has not been trouble-free. In 2018, the long Korga weir, built five miles from El Fasher, was sabotaged. “All the communities upstream and downstream had agreed to the weir, whether they benefited or not,” said Adam Mali, a member of this weir’s committee. “It worked really well in the first year and everyone was very happy. But then a few people [downstream] became jealous.” A night-time raid with a mechanical digger fatally weakened the weir. Despite repairs, when the unusually intense rains came this year, the resulting torrent ripped a 50-metre hole in the structure. This ruined its impact and forced farmers to abandon the unwatered fields. The prime suspects were linked to the deposed regime, but with no witnesses, they were released from police custody. But the revolution has brought new people to power. The new deputy wali (governor) of North Darfur, Mohammed Ibrahim Abdelkareem, says: “This sabotage was a crime. We have issued a decree to protect all the projects – the current ones and all the future ones.” His office will also fund the restoration of the Korga weir. “These projects contribute to the repair of Darfur society. Water projects are usually in the areas where the war happened.” This represents a significant change in tone, says Uras: “I have met a few walis, but this is the first time I have heard one talk about peace.” Omer Abdelrahman, at the groundwater and wadi directorate in North Darfur, is clear about the critical importance of such water projects: “Water is the key to our life – if we are breathing, we need water. If it is not equally shared, then again we will have more war and more killing.” But Hamid Mohamed, from Practical Action, is cautious about the future. “Security is 99% better now. But the situation is still fragile – the tension is still there – and nobody really knows what is going to happen tomorrow.” • The UN Environment Programme assisted with travel for the Guardian This article is part of a series on possible solutions to some of the world’s most stubborn problems. What else should we cover? Email us at theupside@theguardian.com "
"Noise pollution, generally an unintended byproduct of urbanisation, transport and industry, is a key characteristic of human development and population growth. In some cases, it is produced intentionally, for example when seismic surveys are being carried out using powerful airgun arrays to explore and map the seafloor, or active sonar, which uses sound waves to detect objects in the ocean.  All of this noise – whether intentional or not – has the ability to alter the acoustic environment of aquatic and terrestrial habitats. This can have a dramatic effect on the animals that live in them, perhaps even driving evolutionary change as species adapt to or avoid noisy environments. The dramatic and comparatively recent rise in noise levels is marked in both magnitude and extent, with an estimated 30% of the European population exposed to road traffic noise levels greater than 55dB (decibels) at night, well above the 40dB target recommended by the World Health Organisation. Even remote natural areas do not escape the reach of anthropogenic, or manmade, noise. One study across 22 US national parks demonstrated that this kind of noise was, on average, audible more than 28% of the time. Noise is not just irritating; we have known for some time that it can have direct human health impacts. Indeed, chronic exposure to noise levels above 55dB dramatically increases the risks of heart disease and stroke, while aircraft noise has been shown to impact the development of reading skills in children attending schools close to busy airports. The WHO estimates that in Europe at least a million healthy life years are lost every year due to traffic noise. But what are the implications for wildlife, particularly given how important sound production and hearing are for a range of behaviours, such as locating food, avoiding predators and finding a mate? For example, bats and dolphins rely on high frequency sonar to detect highly mobile prey, while great tits, red deer and grasshoppers are among the many species that advertise their dominance and desirability using vocalisations. Elephants can even use sound to determine the threat presented by different human groups.  Scientific interest in the effects of noise pollution on wildlife has intensified over the past decade and we are now developing a better understanding of how noise can impact behaviour, population and community level processes across a range of animal species. Using experimental and observational approaches to characterise and explore the specific effects of different noise sources, the evidence generated from these studies is considerable, particularly among songbirds and marine mammals, which rely heavily on sound and vocal communication.  We now know, for example, that the foraging, vocal behaviour and physiological stress of cetaceans – whales, dolphins and porpoises – can be impacted by ship noise. This is of particular concern for species such as the endangered North Atlantic right whale that inhabits coastal US waters that experience very high levels of shipping traffic. Furthermore, in addition to shifts in distribution and vocal behaviour, military sonar has also been linked to the stranding of cetaceans.  The impacts are not just limited to marine mammals, considerable negative effects of noise are also documented in marine and freshwater fish and invertebrates. These include recent studies that have demonstrated compromised anti-predator behaviour in crabs and eels exposed to ship noise. In terrestrial habitats, bird diversity and abundance has been shown to decline as a result of chronic noise levels around cities and along roadways. A number of species have demonstrated adjustments to their vocal behaviour in an attempt to adapt to the cacophony of human noise. Urban great tits for example, are able to raise the frequency of their calls to reduce acoustical masking by predominantly low-frequency urban noise, while European robins adjust the timing of their singing to coincide with quieter periods in the city. Meanwhile, black-chinned hummingbirds and house finches appear to actively select noisy areas near active gas wells to avoid nest predation by more disturbance sensitive species. Roads are a major source of terrestrial noise due to their spatial extent and the volume of traffic. A 2003 study calculated that 83% of the lower 48 states of the US was within about 1km of a road. I have been working with colleagues at Colorado State University and the National Park Service to explore the effects of road noise on the prairie dog, a social mammal.   Our research demonstrated that prairie dogs, which commonly live in habitats near roads and urban areas, significantly reduced their foraging and increased their vigilance behaviour when exposed to road noise. Such shifts in behaviour could have impacts on their long-term population health particularly in combination with other stressors such as disease and habitat loss.  Road noise has also been shown to impair the foraging efficiency of bats and alter vocal communication in frogs and invertebrates. Studying noise isn’t an easy thing to do. First of all, sound levels cannot accurately be measured and defined using a single absolute scale, such as those used for temperature, rainfall and wind speed. For simplicity we often just refer to a decibel level, but this does not take into account the duration and frequency of the acoustical signal. The specific effects of noise also need to be disentangled from the sources of disturbance that often accompany it, including human presence, habitat fragmentation and chemical pollution.  The need to further understand the complex biological effects of noise and establish scientifically relevant thresholds of noise exposure is a priority for human health and wildlife conservation. Rapid development, urbanisation and population growth are set to continue into the future. As a result we need to ensure a collaborative effort between scientists, industry and government to protect natural soundscapes where possible, while also promoting new technology and approaches that mitigate the effects of noise. Man made noise is a relatively recent phenomenon, particularly in evolutionary terms, but scientific studies have demonstrated that it has the potential to adjust behaviour, alter physiology and even restructure animal communities. Ultimately, such a strong selection pressure could drive evolutionary change. These are complex questions that are now being explored by experts across a range of disciplines from animal behaviour to bioacoustics."
"
Share this...FacebookTwitterModern ‘Warmth’ A Brief Excursion From
8,000-Year (Continuing) Cooling Trend

The scientific literature is replete with evidence that the geological record for the Holocene (the last 10,000 years) fails to support the concept that rising atmospheric CO2 concentrations cause ocean and land temperatures to rise.
Actually, the scientific literature strongly suggests that the correlation between rising CO2 and temperature would appear to veer off in the opposite direction: as CO2 rises, temperatures decline.
So if there is a correlation for the Holocene, it may be the inverse of climate model expectations.

Modern ‘Warmth’ Excursion Has Had Little Or No Effect On The Overall Long-Term Cooling Trend 

According to an estimate of global sea surface temperature (SST) changes during the last 2,000 years (“Robust global ocean cooling trend for the pre-industrial Common Era“), the addition of the last 2 centuries (1800 to 2000 C.E.) of relatively modest SST warming only changes the overall per-millennium global cooling trend (~0.4°C) by one tenth of one degree.  In other words, using a long-term perspective, the Holocene cooling trend has continued largely uninterrupted during the last two centuries.

McGregor et al., 2015
“Our best estimate of the SST cooling trend, scaled to temperature units using the average anomaly method (method 1), for the periods 1–2000 CE is –0.3°C/kyr to –0.4°C/kyr, and for 801–1800 CE is –0.4°C/kyr to –0.5°C/kyr“


Overall cooling has been ongoing for most of the last ~8,000 years, mixed in with temporary warming “spikes” that last for a century or two.  The modern warming that emerged in the early 20th century will, if history is a guide, eventually revert back to the cooling trajectory of the last several thousand years.  Gerhard (2004) facilely illustrates this overall global cooling trajectory — with swerves and spikes along the way.

Gerhard, 2004



CO2 Concentrations Rose Steadily Throughout The Last 8,000 Years…While Earth Cooled

While the planet has been steadily cooling (with brief warming excursions) for the last 8,000 years, atmospheric CO2 concentrations have tilted in the opposite direction, rising from about 260 parts per million (ppm) ~8,000 years ago to about 280 ppm in ~1800 C.E.
So if CO2 rises as temperature drops, the correlation suggested by climate models (temperature should rise as CO2 rises) is not supported by by a large portion of the available scientific evidence.
Listed below are 50 inverse “hockey stick” graphs featuring a long-term global cooling trend that is largely uninterrupted by modern era temperatures.  These reconstructions illustrate the unheralded disconnect between CO2-driven climate models and the geological record.




Jiang et al., 2015


Lecavalier et al., 2013


Luoto et al., 2014


Abrantes et al., 2017



Esper et al., 2014


Jalali et al., 2016
 


Renssen et al., 2009


Rosenberg et al., 2004


Rosenthal et al., 2013


Khiyuk and Chilingar, 2006


Rinne et al., 2014


Gennaretti et al., 2014


Fudge et al., 2016


Harning et al., 2016


Munz et al., 2015


Tyson et al., 2000


Mark, 2016


Steinman et al., 2016


Bertrand et al., 2014


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






 



Yamamot et al., 2016


Shevenell et al., 2011


Bostock et al., 2013


Kim et al., 2007


Viau and Gajewski, 2009


Thienemann et al., 2017
“[P]roxy-inferred annual MATs [annual mean air temperatures] show the lowest value at 11,510 yr BP (7.6°C). Subsequently, temperatures rise to 10.7°C at 9540 yr BP followed by an overall decline of about 2.5°C until present (8.3°C).”


Schneider et al. 2014


Sepúlveda et al., 2009


Böll et al., 2014


Brocas et al., 2016


 
Shevenell et al., 2011


Mulvaney et al., 2012
“A marine sediment record from off the shore of the western Antarctic Peninsula also shows an early Holocene optimum during which surface ocean temperatures were determined to be 3.5°C higher than present. Other evidence suggests that the George VI ice shelf on the southwestern Antarctic Peninsula was absent during this early-Holocene warm interval but reformed in the mid Holocene.”


Krawczyk et al., 2017



Foster et al., 2016


Andersen et al., 2004
 



Fortin and Gajewski, 2016


Caniupán et al., 2014


Birks and Seppä, 2004


Rella and Uchida, 2014


Kawahata et al., 2017


Levy et al., 2013


Weldeab et al, 2005


Dupont et al., 2004

Share this...FacebookTwitter "
nan
"Like many political neologisms, “Green New Deal” became de rigueur so fast that it had multiple variations, passionate disciples, critics (some measured, others fierce) and endless namechecks before anyone had said definitively what it meant. The “why” was clear: after decades of the business-as-usual answer to the climate crisis, the environmental movement was more or less united in its conviction that more profound change was needed than awareness-raising and intergovernmental target setting. The precedent was Franklin D Roosevelt’s New Deal of the 1930s, with which he successfully combatted the Great Depression. But does this green version essentially correspond to the bid Jeremy Corbyn made for the Labour leadership in 2015: a national investment bank and 1m jobs in green energy, to simultaneously upskill the population and reach towards a zero-carbon economy? Or is it Alexandria Ocasio-Cortez’s vision of environmental justice wrapped into social justice, the private sector swept up in the enthusiasm of a radical state? Is it Keynesianism – except instead of digging the hole and filling it up, you put a tree in it? Or is it a plan so root-and-branch post-capitalist that none of the old words will do? These books by Ann Pettifor and Naomi Klein have similar titles and are similar, too, in respect of their urgency. Pettifor delivers a sober, technical but readable account of the framework, as she – among a handful of economists and/or environmentalists, including Richard Murphy (the main architect of Corbyn’s 2015 programme), Larry Elliott (the Guardian’s economics editor) and Jeremy Leggett (solar entrepreneur) laid it out more than a decade ago. It was devised in the wake of the global financial crash, which had two obvious effects: to give it an internationalist perspective, since never more than in 2008 were economists aware of the irrelevance of borders; and to put the focus squarely on systems, rather than individual actors.  Pettifor’s case is pretty straightforward: there is a climate crisis, and it may be too late to avert it, yet to surrender means nihilism. While she directs the occasional weary sideswipe at the climate-change denier, her true enemy is defeatism, and she is very convincing on this: whether or not the planet can be saved, there is no alternative but to try. In such a context money is no object, but it’s not so much “you can’t put a price on our habitat”, rather it is the rallying cry of the heterodox economist, echoing Keynes, Roosevelt, through to US policy wonk Demond Drummer: “we can afford what we can do.” Money is not a finite natural resource, handed us by the mountains or the seas: it is a social construct based on trust and cooperation, created through credit, which is itself backed by the toil of today’s citizens, and the citizens of the future (an idea explored in her last, very readable book, The Production of Money) Deploying examples of the sheer limitlessness of money, when a government really puts its mind to it, Pettifor points to Roosevelt (a fascinating experiment in social ambition, with its own environmental element: over the nine years of the New Deal, 5% of the total male population was engaged in the Civilian Conservation Corps, planting among other things, 2bn trees). She also points to the Marshall plan, to the moon landings – all the classic examples of the hope genre, though given a different spin by climate catastrophe. If we can, as a species, muster all that effort, iconoclasm and single-mindedness just to get to the moon and have a poke about, imagine what we’re capable of when our children’s lives are at stake. Nothing will be realised, however, without systems change: the problem is not simply that “private financial firms have for decades now displaced governments in the financing of … water, transport, education, housing, environmental services and health”, leaving elected politicians without leverage or agency, and an electorate crying out for strength (hence the inexorable rise of the strongman). It is not just that governments are increasingly impotent in the face of “dollarised financial capitalism shifted off-shore”, powerless before speculative finance which demands high returns on low effort, and therefore is by definition extractive The block on progress is all those things, underpinned by something more fundamental: you cannot, as George Lakoff once spelt out, put profit in a cost benefit analysis against nature. Pettifor has a rare approach, both radical and intricate., and is never more enthusiastic than when she is spelling out the potentially transformative effects of a global transaction tax, or capital controls, or the management of interest rates by public authority, or an alternative to the dollar standard. She can persuade the reader to abandon growth as a goal in the blink of a page, and adopt instead the idea of an economic “Plimsoll line” (what’s the most a vessel can carry before compromising its seaworthiness?). The book’s purpose, though, is more than a manifesto for the climate, while stopping short of fully costed fixes it sets out to show which elements of the world as it is are incompatible with meaningful change, and how manageably (if not necessarily easily) they could be overturned. Quoting the American abolitionist Frederick Douglass, Pettifor notes: “Power concedes nothing without a demand.” Naomi Klein’s On Fire, a collection of her environmental essays over the past decade, follows the same principles. There are differences in emphasis between the UK’s Green New Deal and the US’s – Britain’s is oriented more internationally, the American version more focused on Roosevelt’s template of transformation through social justice and democratic agency, which by definition is bordered. Fundamentally, though, their prescriptions are the same, and the depth and uniqueness of Klein’s work is in the human beings she brings to the party. Philosophers, flood victims, students, conservationists – she has a reporting style that is rooted in her decades of activism; everybody’s voice is given the same dignity, the same weight. This pluralism alone presents a vast horizon of possibility, a sense of limitless creative energy, all engaged on the same question. None of us is alone, and nor do we have to leave it all to Greta Thunberg. This sweetens what is otherwise quite a bitter pill, a globe that knows its peril but can’t respond. From the floods of Hebden Bridge to the fires of British Columbia, from the oil spill in the Gulf of Mexico to cobalt mines in the Democratic Republic of Congo, the harder you look, the more cause there is to despair. Klein finds hope not in large motivational assertions, but in the detail: so she quotes the geophysicist Brad Werner, talking an audience through his computer modelled conclusion that “global capitalism had made the depletion of resources so rapid, convenient and barrier-free that ‘earth-human systems’ were becoming dangerously unstable in response”. When pressed by a journalist for a clear answer on the “are we fucked” question, Werner set the jargon aside and replied: “More or less.” Wait, though: there is one source of friction that could slow down and even derail the machine – mass resistance movements. Direct action by environmentalists, say; or hundreds of thousands of school children striking; resistance is not only germane to the dynamic, it is a powerful countervailing force. This isn’t a book about heroes: Klein has an equally keen ear and roving eye for the deniers, the obstructionists, the defeatists, the status quo-ists. She creates vivid and terrifying portraits of the fossil fuel industry in full sail, of the Republican party completely subservient to it (this feels new and Trumpian, but isn’t: Newt Gingrich unveiled the slogan “Drill Here, Drill Now, Pay Less,” in 2008), of the victims of corporate carelessness and catastrophic climate events. Klein can sink your spirits with an analogy: she draws a parallel between the extinction peril of “mismatching”– the process whereby “warming causes animals to fall out of step with a critical food source” – and our own cultural mismatch, where the greatest collective action is required of us just as we are at our most socially atomised. Yet she can lift them again with a metaphor, a parable, the sight of a whale, the feeling of the wind. Pettifor works extremely hard to describe the mechanisms by which capitalism and corporatism created the climate crisis and, more recently, the degradation of democratic politics. Klein is bolder, tearing through these ideas – the connection between “climate crisis, wealth concentration and racialised violence”, the “violence of othering in a warming world” – on her way to somewhere both more urgent and more nourishing: the sites of resistance, and how each grain might turn into enough sand to stop the machine. These Green New Deals dovetail so well as companion works that they seem designed to be read together. Or is it simply that this is an idea whose time has come – not a moment too soon, and quite possibly too late? • The Case for the Green New Deal is published by Verso (RRP £12.99); On Fire: The Burning Case for a Green New Deal is published by Allen Lane (RRP £20). To buy copies go to guardianbookshop.com. Free UK p&p call 020-3176 3837."
"
Share this...FacebookTwitterProfessor Friedrich Indra has been retired since 2005 and is considered to be one of the world’s leading engine developers. The 76-year old used to work for Audi and General Motors.

Electric mobility is an environmental fraud, says world leading expert in engine technology. Image: Tesla
“Doesn’t solve single environmental problem”
In a recent interview with the online FOCUS news magazine he raised a lot of eyebrows by stating that he thinks electric mobility is a “dangerous false path”, claiming that the electric car “does not solve a single environmental problem” and that it “contributes nothing to climate protection”.
Indra calls the claims that electric cars are CO2-free “absurd”.
Fake efficiency
Citing an earlier stiudy by a Professor Spicha, Indra says that the well-to-wheel-CO2 of an electric car in Germany is in fact 1.6 times worse than the conventional internal combustion engine. The CO2 perforamnce of an electric car in China is even four to five times worse when it comes to consumption, and that does not mention the huge energy quantities needed for manufacturing the batteries that electric cars need, which would be enough to power a conventional automobile 30,000 kilometers, he told FOCUS.
Electric cars also have the problems of recycling the batteries, as they are a long way from being fully recyclable.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to Indra, internal combustion engines have made “very impressive progress“, saying: “The motors are continuously getting more powerful and more fuel efficient.” The engine expert believes that the final solution is “CO2-neutral synthetic fuels. They need as much CO2 for for their manufacture as emitted when in operation.”
The “second greatest environmental fraud”
When it comes to hybrid automobiles, Indra opinion is harsh, calling the plug-in-hybrids “the second greatest environmental fraud because the determination of the fuel consumption does not even include the power that was previously needed to charge up the car.” This is how “sportscars using the technology come up with perverse values like 3.1 liters consumption per 100 km [80 mpg]”.
In the interview Indra rails against what he calls “widespread hatred against internal combustion engines” among the media and policymakers, who he says exploited the VW emissions test cheating affair to spread more hate against the internal combustion engines. He thinks the scandal was played up by the media and is “completely disassociated from fact“. Never has “industry and policymaking acted so irrationally“. He believes politicians are in for a rude awakening once the true costs start coming in.
Toy for the rich
On the current a future trend of electric cars, Indra tells FOCUS:
In the meantime in some countries the market share by pure electric cars is already retreating. That’s also going to happen with the plug-in-hybrids after all the ‘rich people’ are supplied with these cars.”
Massive government subsidies
He says the claimed “success” of electric cars in China and Norway is due to massive government subsidies: “No country in the world can afford that over the long-term. That will level off once again, as is already the case in Norway.”
 
Share this...FacebookTwitter "
"The bangs and fizzes of fireworks are rapidly replacing the chimes of Big Ben as the defining sound of New Year’s Eve celebrations in London, while around the world, city landmarks are becoming stages for increasingly spectacular pyrotechnic displays. Since the millennium, the popularity of fireworks has even extended into back gardens, where smaller fireworks or sparklers are lit up at the stroke of midnight. Fireworks are great fun. We all enjoy guessing the colours of the rockets before they ignite in the sky, hearing the explosions echo off nearby buildings, or writing our names in light with hand sparklers.  But there is an environmental price to pay. Firework smoke is rich in tiny metal particles. These metals make firework colours, in much the same way as Victorian scientists identified chemicals by burning them in a Bunsen flame; blue from copper, red from strontium or lithium, and bright green or white from barium compounds.  There is more smoke from potassium and aluminium compounds, which are used to propel fireworks into the air. Perchlorates are also used as firework propellants; these are a family of very reactive chlorine and oxygen compounds, which were also used by NASA to boost space shuttles off the launch pad. Fireworks can lead to substantial air pollution problems. There are well documented examples from cites around the world. In Spain, metal particle pollution from Girona’s Sant Joan fireworks fiesta can linger in the city for days. Across India’s cities, the annual Diwali fireworks cause pollution that is far worse than Beijing on a bad day.  Guy Fawkes is regularly the most polluted day of the year in the UK, although scientists from King’s College London have found that pollution from bonfires – the traditional way of marking Guy Fawkes – is also a part of this mixture. Fireworks can have significant effects on air pollution in enclosed spaces, too. In Germany, tests have shown how goal and match celebrations with flares, smoke bombs and other pyrotechnics can fill football stadiums with high concentrations of airborne particles.    And of course, what goes up has to come down. Fireworks that fall to the ground contain residues of unburnt propellants and colourants, while particle pollution in the air eventually deposits on the ground or gets washed out by rain. Some of this finds its way into lakes and rivers , where percolate has been linked to thyroid problems, causing limits to be set for drinking water in some US states.  This is a major concern for lakeside resorts and attractions that have frequent firework displays. Researchers in London have collected airborne particles from Diwali and Guy Fawkes. These were found to deplete lung defences far more than pollution from traffic sources, suggesting a greater toxicity. Across India, Diwali fireworks have been linked to a 30% to 40% increase in recorded breathing problems. Like New Year’s Eve, fireworks are a relatively new phenomenon at Diwali.  Traditionally, Diwali was celebrated with the lighting of ghee burning lamps – but this changed with the opening of India’s first firework factory in 1940. An Indian court petition is demanding better public safety information and restrictions on the sale and use of fireworks – but this came too late to limit the smog caused by this year’s celebrations. Some simple steps can be taken to reduce our exposure to firework pollution. For one thing, setting them off in enclosed spaces is a very bad idea, as are hand-held sparklers. Positioning crowds upwind of fireworks displays is another obvious way of reducing their negative health impacts. Yet fireworks are already the largest manufactured source of some types of metal particles in the UK atmosphere. And the proportion of pollution from fireworks will only increase, as huge investments are made to reduce other sources of urban pollution. Particle filters are present on nearly all modern diesel vehicles and factory emissions across the developed world are continually being tightened  – but firework pollution remains unchecked.  Perhaps the best way to tackle the pollution caused by fireworks is not to have them at all. But this seems rather extreme (not to mention a lot less fun). The high-precision, controlled displays that we see at international landmarks on New Year’s Eve demonstrate the great innovation of the fireworks industry. It’s time for this innovative approach to be applied to reduce the environmental impact of fireworks, so that we can continue to enjoy the excitement of displays for years to come."
"
Share this...FacebookTwitter
“It is generally accepted that the climate warms during periods of strong solar activity (e.g., the Medieval Warm Period) and cools during periods of low solar activity (e.g., the Little Ice Age).” — Lyu et al., 2016

Graph Source: WoodForTrees.org
Scientists are increasingly tuning out the claims that the Earth’s temperatures are predominantly shaped by anthropogenic CO2 emissions, or that future climate is destined to be alarmingly warm primarily due to the rise in trace atmospheric gases.  Instead, solar scientists are continuing to advance our understanding of solar activity and its effect on the Earth system, and their results are progressively suggestive of robust correlations between solar variability and climate changes.
For example, in 2016 alone, there were at least 132 peer-reviewed scientific papers documenting a significant solar influence on climate.  Among them there were 18 papers that directly connected centennial-scale periods of low solar activity (the Little Ice Age) with cooler climates, and periods of high solar activity (the Medieval Warm Period and the Modern Warm Period [20th Century]) with high solar activity levels.  Another 10 papers warned of an impending solar minimum and concomitant cooling period in the coming decades.
And this trend of scientists linking climate changes to solar forcing mechanisms — and bypassing an anthropogenic explanation — continues to rage on in 2017.
A Seminal New Paper Unveils The ‘Cause Of Causes’ Of Climate Change
In their groundbreaking New Astronomy paper, Norwegian professors Harald Yndestad and Jan-Erik Solheim indicate that the modern (1940-2015) Grand Maximum of very high solar activity — the highest solar activity levels in 4,000 years — has just ended.   Within 10 years, or by 2025, these scientists project the next solar minimum period (which will be similar in character to the late 18th Century’s Dalton Minimum) will exert its cooling effect on the Earth’s climate.
Yndestad and Solheim have been working together on this project for more than 2 years.  Although Dr. Yndestad was “skeptical about the idea of ​​sunspots as climate indicators” initially, the two discovered “for the first time” a strong long-term correlation between Total Solar Irradiance (TSI) and sunspots for periods of 84 and 210 years, confirming the “Cause of causes” of climate change.  Details can be found in their illuminating new paper.

Yndestad and Solheim, 2017
Summary
“Deterministic models based on the stationary periods confirm the results through a close relation to known long solar minima since 1000 A.D. and suggest a modern maximum period from 1940 to 2015. The model computes a new Dalton-type sunspot minimum from approximately 2025 to 2050 and a new Dalton-type period TSI minimum from approximately 2040 to 2065. … Periods with few sunspots are associated with low solar activity and cold climate periods. Periods with many sunspots are associated with high solar activity and warm climate periods.”
1940-2015 Grand Maximum Of Solar Activity, Highest In 4,000 Years, Just Ended
“Studies that employ cosmogenic isotope data and sunspot data indicate that we are currently leaving a grand activity maximum, which began in approximately 1940 and is now declining (Usoskin et al., 2003; Solanki et al., 2004; Abreu et al., 2008). Because grand maxima  and minima occur on centennial or millennial timescales, they can only be investigated using proxy data, i.e., solar activity reconstructed from 10Be and 14C time-calibrated data. The conclusion is that the activity level of the Modern Maximum (1940–2000) is a relatively rare event, with the previous similarly high levels of solar activity observed 4 and 8 millennia ago (Usoskin et al., 2003). Nineteen grand maxima have been identified by Usoskin et al. (2007) in an 11,000-yr series.”
Solar Activity Minimum/Maximum Periods Linked To Colder/Warmer Climates
“Twenty-seven grand minima are identified with a total duration of 1900 years, or approximately 17% of the time during the past 11,500 years (Usoskin et al., 2007). An adjustment-free reconstruction of the solar activity over the last three millennia confirms four grand minima since the year 1000: Maunder (1640–1720), Spörer (1390–1550), Wolf (1270–1340) and Oort (1010–1070) (Usoskin et al., 2007). The Dalton minimum (1790–1820) does not fit the definition of a grand minimum; it is more likely a regular deep minimum that is observed once per century or an immediate state between the grand minimum and normal activity (Usoskin, 2013).  Temperature reconstructions for the last millennium for the Northern Hemisphere (Ljungquist, 2010) show a medieval maximum temperature at approximately the year 1000 [Medieval Warm Period] and a cooling period starting at approximately 1350 [Little Ice Age], immediately after the Wolf minimum and lasting nearly 500 years, with the coldest period in what is referred to as the Little Ice Age (LIA) at the time of the Maunder minimum. A cold period was also observed during the time of the Dalton minimum. The Maunder and the Dalton minima are associated with less solar activity and colder climate periods. In this investigation, minimum solar activity periods may serve as a reference for the identified minimum irradiations in the TSI oscillations.”

Other scientists have just published papers in peer-reviewed journals documenting a robust correlation between solar activity and surface temperatures in the paleoclimate record.  Zawiska et al. (2017) have found that the amplitudes of the warming and cooling periods — modulated by changes in solar activity and the North Atlantic Oscillation (NAO) — during the last 1,000 years far exceeded the temperature changes that have occurred since about 1950, or since anthropogenic CO2 emissions began rising at an accelerating pace.  For example, these scientists point out that within a matter of 100 years (1050-1150 to 1150-1250), summer temperatures rose from 9.2°C during a low solar activity period (Oort Minimum) to 12.0°C in concert with the subsequent rise in solar activity.
Zawiska and colleagues also point out that the rise in modern era temperatures began around 1800, not the 20th century.  In fact, they find that temperatures rose by 4.3°C (from 8.5°C to 12.8°C) within 75 years starting at the beginning of the 19th century (+0.57°C per decade), and this warming “correlates with the positive NAO index and increased solar activity.”   The authors further indicate that the warming in the 20th/21st centuries has been “less pronounced” by comparison.
During the 19th century, of course, anthropogenic CO2 emissions rates were but a tiny fraction of what has been observed since the mid-20th century, strongly suggesting that temperature changes associated with natural variations in atmospheric/oceanic cycles (NAO) and solar activity far exceed the forcing strength of anthropogenic CO2 emissions.

Zawiska et al., 2017
Summary
“The chironomid-based temperature reconstruction from Lake Atnsjøen in Eastern Norway with mean resolution of 30 years provided evidence that large-scale processes, such as the NAO fluctuations and solar activity modified local climate, and subsequently affected lakes functioning. The three minor cooling periods were reconstructed in the first half of the Millennium: 1050–1150, 1270–1370, 1440–1470 CE, that coincide with solar activity minima: Oort, Wulf, and Spörer respectively. Furthermore, a two peaked cooling period in the second half of the Millennium was identified that coincided with the LIA. These changes co-occurred with the prevailing negative NAO index.”
Cold Periods (Temp. Average 9.2 °C) Correlate With Low Solar Activity, NAO
“At 1050–1150 CE the first of the short-term cooling periods of the last Millennium began and the mean July temperature in the Lake Atnsjøen region dropped to 9.2 °C. The beginning of this cooling coincided with the Oort solar activity minimum. The reconstructed climate deterioration agrees very well with temperatures revealed for Europe (PAGES 2k Consortium, 2013) and Finland (Luoto and Helama, 2010), and partly with tree-ring based temperature trends from Northern Sweden (Osborn and Briffa, 2006). … The climate cooling around 1100 CE has been observed also in Northern America, Russia and Central Asia (Osborn and Briffa, 2006; Wanner et al., 2008), but intrestingly not in Greenland (Osborn and Briffa, 2006). … The beginning of the 1270–1370 CE cooling coincide with Wulf solar activity minimum suggesting that the climate was responding to Sun activity. The climate cooling synchronous to this solar minimum had almost global range and it has been recorded from Europe, Arctic, North America and Antarctica (Osborn and Briffa, 2006; PAGES 2k Consortium, 2013) but again not in Greenland (Osborn and Briffa, 2006). … The beginning of the 1440–1470 CE cold period is synchronous to the pronounce negative NAO phase (Trouet et al., 2009). … Maunder solar minimum caused a very deep negative NAO index phase (Shindell et al., 2001), which consecutively lead to significant drop in the reconstructed temperature.”
Warm Periods (Temp. Average 12°C) Correlate With High Solar Activity, NAO 
“According to presented reconstruction, climate shifted towards warmer conditions during 1150–1250 CE, as mean July temperature raised to 12 °C. Studies from Finland and Sweden also indicate short climate warming around 1200 CE (Luoto and Helama, 2010; Osborn and Briffa, 2006)  … The above described time interval 1000–1250 CE coincides with the MCA [Medieval Climate Anomaly] that occurred around 950–1250 CE and was regarded as a generally warmer and drier period (Mann et al., 2009).
The temperature reconstruction from Lake Atnsjøen indicates that recent and ongoing climate warming began already in 1800 CE following the LIA. Temperatures increased very fast, from 8.5 to 12.8 °C during the first 75 years, but in the 20th century the increase became less pronounced.
The warming at the beginning of 19th century in the region of Lake Atnsjøen coincides with a reconstruction from Southern Finland (Luoto, 2013), and a record from Northern Sweden (Osborn and Briffa, 2006).  Its onset correlates with the positive NAO index and increased solar activity.”


Another scientist just published a paper in the journal Palaeogeography, Palaeoclimatology, Palaeoecology that also concludes solar activity drove variations in the East Asian Monsoon (EAM), El Niño Southern Oscillation (ENSO), and the centennial-scale cooling periods corresponding to the Oort, Wolf, Spörer, and Maunder sunspot minimums.
In his graph of Western Tropical Pacific sea surface temperatures (SSTs), notice how Park (2017) also documents a dramatic warming event occurred beginning about 1800, with the SST warming rate and amplitude far exceeding that which has occurred in recent decades, once again demonstrating the lack of correlation between anthropogenic CO2 emissions and surface temperatures relative to natural variation.

Park, 2017
“Late Holocene climate change in coastal East Asia was likely driven by ENSO variation.   Our tree pollen index of warmness (TPIW) shows important late Holocene cold events associated with low sunspot periods such as Oort, Wolf, Spörer, and Maunder Minimum. Comparisons among standard Z-scores of filtered TPIW, ΔTSI, and other paleoclimate records from central and northeastern China, off the coast of northern Japan, southern Philippines, and Peru all demonstrate significant relationships [between solar activity and climate]. This suggests that solar activity drove Holocene variations in both East Asian Monsoon (EAM) and El Niño Southern Oscillation (ENSO). In particular, the latter seems to have predominantly controlled the coastal climate of East Asia to the extent that the influence of precession was nearly muted during the late Holocene.”


The year has just begun, and, in addition to the 3 papers introduced above, there have already been several other 2017 scientific papers published in scientific journals documenting a robust correlation between solar activity and climate changes.  With the rapidly growing body of evidence that has been accumulating within the last few years, it can no longer be said that it is “settled” science that the Sun and its modulation of natural atmospheric/oceanic oscillations (NAO, ENSO, PDO, AMO) has only a negligible influence on climate.  The claim that we human beings predominantly drive climate changes with our CO2 emissions is increasingly being challenged, if not categorically undermined, in the peer-reviewed scientific literature.

Sun et al., 2017
“[A]t least six centennial droughts occurred at about 7300, 6300, 5500, 3400, 2500 and 500 cal yr BP. Our findings are generally consistent with other records from the ISM [Indian Summer Monsoon]  region, and suggest that the monsoon intensity is primarily controlled by solar irradiance on a centennial time scale. This external forcing may have been amplified by cooling events in the North Atlantic and by ENSO activity in the eastern tropical Pacific, which shifted the ITCZ further southwards. The inconsistency between local rainfall amount in the southeastern margin of the QTP and ISM intensity may also have been the result of the effect of solar activity on the local hydrological cycle on the periphery of the plateau.”

Deng et al., 2017
“The results indicate that the climate of the Medieval Climate Anomaly (MCA, AD 900–1300) was similar to that of the Current Warm Period (CWP, AD 1850–present), which contradicts previous studies. … As for the Little Ice Age (LIA, AD 1550–1850), the results from this study, together with previous data from the Makassar Strait, indicate a cold and wet period compared with the CWP and the MCA in the western Pacific. The cold LIA period agrees with the timing of the Maunder sunspot minimum and is therefore associated with low solar activity.”
Zielhofer et al., 2017
“Western Mediterranean Holocene record of abrupt hydro-climatic changes … Imprints of North Atlantic meltwater discharges, NAO and solar forcing …Early Holocene winter rain minima are in phase with cooling events and millennial-scale meltwater discharges in the sub-polar North Atlantic. … [A] significant hydro-climatic shift at the end of the African Humid Period (∼5 ka) indicates a change in climate forcing mechanisms. The Late Holocene climate variability in the Middle Atlas features a multi-centennial-scale NAO-type pattern, with Atlantic cooling and Western Mediterranean winter rain maxima generally associated with solar minima.”
Matveev et al., 2017
“An increase in atmospheric moisture for the warm period of the year (May–September) since 1890s, and mean annual temperatures since the 1950s was identified. During the same time period, there was a marked increase in amplitude of the annual variations for temperature and precipitation. … These fluctuations are consistent with 10–12-years Schwabe–Wolf, 22-years Hale, and the 32–36-years Bruckner Solar Cycles. There was an additional relationship found between high-frequency (short-period) climate fluctuations, lasting for about three years, and 70–90-years fluctuations of the moisture regime in the study region corresponding to longer cycles.”
Share this...FacebookTwitter "
"As heavy rain continues to contribute to the devastating flooding in Cumbria, there have once again been calls – notably from the environmentalist George Monbiot – for the reforestation of our uplands, to help tackle rural flooding. The government has stated that it is funding the planting of 11m trees over the next five years to this end. It has also been suggested that trees could help reduce the number and severity of flash floods in cities, such as those that devastated Hull in June 2007.  To determine whether the humble tree really can provide such robust defences, we first need to understand the role they play in soaking up excess rain water. All floods, whether fluvial (when rivers burst their banks) or pluvial (when rainfall overwhelms drainage systems before it reaches rivers), are caused because the rain cannot soak into the soil fast enough. Instead, it runs rapidly over the surface of the land.  And while climate change is causing bigger and bigger storms, our alterations to the environment – especially to the ground surface – have been one of the major causes of the increased frequency of flooding events in modern times.  Cities offer the most obvious example of how human development is making flooding worse. In urban areas, the ground surface is covered by impermeable buildings and roads, which rapidly divert rainfall into gutters and drains. When these reach capacity, flooding occurs.  Computer modelling of water flows in cities suggests that for every extra 1% of impermeable land that is converted to woodland, runoff would be reduced by less than 0.5%. So even large-scale urban tree planting would only reduce runoff by a small amount – far lower than the 80% increase in storm size that climate change models predict for the UK. But these estimates assume that trees don’t affect how much water runs into drains from buildings and roads. Recent research we carried out in Manchester has suggested that trees planted on the streets can have a much greater effect than predicted, largely because rainfall can run from pavements into their planting holes.  Trees which are planted as a part of Sustainable Urban Drainage Systems (SUDS) schemes – in which rainfall is deliberately diverted into swales, hollows and soakaways – could be even more effective. Unfortunately, though SUDS schemes are increasingly popular, little research has been carried out to monitor their effectiveness at reducing runoff. Rural areas of the UK have also undergone a massive transformation at the hands of humans. Forests, which would have provided natural vegetation cover, have been removed and replaced with arable crops (in the lowlands) or grass pasture (in upland areas such as the Lake District). Both of these types of agricultural land shed much more runoff than forests. Their thin soils are compacted by heavy farm machinery and the hooves of cattle and sheep. This reduces their permeability, making it more difficult for rain to penetrate the soil, while short-cropped grasses and flat fields offer little resistance to the overland flow of the runoff.  Reforesting such areas can have several benefits. For one thing, the tree canopy can intercept some rain, which can then evaporate before it even reaches the ground.  But this only reduces the effective rainfall by a few millimetres, and the effect would be negligible in winter, when low temperatures reduce evaporation and deciduous trees have shed their leaves.  The effects of trees on the soil are much more significant. Fallen tree leaves build up a deeper, humus-rich soil, which is criss-crossed by thick surface roots that intercept the overland flow of rain water. Meanwhile, sub-surface roots penetrate deep into the soil, drying it out and increasing its permeability. These mechanisms are well-established, and seem to point to trees as a possible solution to flooding.  Yet in rural areas, the effectiveness of reforestation in preventing flooding is still uncertain. A recent study at Pontbren, in Wales, showed that planting trees on former pasture can increase the rate at which water infiltrates the soil by a factor of around 70 in just seven years, thereby reducing overland flow. Unfortunately, the planting was done on a relatively small scale, and there was no way of comparing catchments with and without trees, so it was impossible to tell whether these changes had significantly reduced the speed at which water drained into the local streams, the water which would cause fluvial flooding downstream.  Ultimately, we lack the strong research base necessary to accurately quantify the anti-flooding benefits of planting trees: large scale studies cost money, and scientists have difficulty repeating experiments to confirm their findings, because no two catchments are the same. Most studies therefore depend on modelling, but even this is unreliable, because the models cannot be validated by experiment. There are also a range of other factors, which might be affecting our results, such as soil type, slope, and whether the trees are positioned next to streams and rivers. But based on what we know, it seems unlikely that reforestation would be a total panacea; after all, forested areas still flood.  And so it seems unlikely that reforestation alone would have been able to prevent the current floods in Cumbria. But by finding ways to measure the benefits of trees, we will be able to use them to their full potential, as a part of our engineered flood prevention schemes. By incorporating trees as part of the solution, we could add some green to the concrete jungles in which so many of us live, and transform our countryside into a lush and varied environment."
"In cities around the world, trees are often planted to help control temperatures and mitigate the effects of the “urban heat island”. But while trees have been called “nature’s air conditioners”, in practice, scientists often have difficulty demonstrating their cooling properties.  The most obvious way to measure the cooling effect of trees would be to compare the air temperature in parks with that in nearby streets. But this method often comes up with disappointing results: even in large, leafy parks, the daytime air temperature is usually less than 1°C cooler than in the stuffy streets, and at night the temperature in parks can actually be higher. To explain this contradiction, we need to think more clearly about the physics of heat flows in our cities, and the scale of the measurements we are taking.  Theoretically, trees can help provide cooling in two ways: by providing shade, and through a process known as evapotranspiration. Locally, trees provide most of their cooling effect by shading. How warm we feel actually depends less on local air temperature, and more on how much electromagnetic radiation we emit to, and absorb from, our surroundings. A tree’s canopy acts like a parasol, blocking out up to 90% of the sun’s radiation, and increasing the amount of heat that we lose to our surroundings by cooling the ground beneath us.  All up, the shade provided by trees can reduce our physiologically equivalent temperature (that is, how warm we feel our surroundings to be) by between seven and 15°C, depending on our latitude. So it’s no surprise that, in the height of summer, people throng to the delicious coolness of the shade provided by London parks, Parisian boulevards, and Mediterranean plazas. Trees can also cool down buildings – especially when planted to the east or west – as their shade prevents solar radiation from penetrating windows, or heating up external walls. Experimental investigations and modelling studies in the USA have shown that shade from trees can reduce the air conditioning costs of detached houses by 20% to 30%.  But air conditioning is more common in some places than in others: for example, while three out of four Australian households have an air conditioner, they’re much less common in Northern Europe, leaving the population there more vulnerable to the harms of urban heat. During the 2003 European heatwave, there were 70,000 more deaths recorded, compared with equivalent cool periods. We urgently need more research to find out how much shade from trees could cool down the terraced houses and apartment blocks, where so many less well-off people live. Trees can also be used to tackle a bigger problem: the urban heat island. During periods of calm, sunny weather, the air temperature of cities can be raised above that of the surrounding countryside by up to 7°C, especially at night. In cities, the hard, dark asphalt and brick surfaces absorb almost all the incoming short-wave radiation from the sun, heating up to between 40°C and 60°C, and storing energy which is then released into the air during the still of night, when it can be trapped in the narrow street canyons.  Urban trees can counter this process by intercepting the radiation before it reaches the ground, and using the energy for evapotranspiration. Evapotranspiration occurs when the sun’s rays hit the trees’ canopy, causing water to evaporate from the leaves. This cools them down – just as sweating cools our skin – thereby reducing the amount of energy left to warm the air.  The effects of evapotranspiration can be quantified in two ways. First, you can measure the temperature of the tree canopy, which is typically much cooler than built surfaces – only 2°C to 3°C above air temperature. Unfortunately, we can’t really claim that this temperature difference is evidence of cooling capacity; leaves would be cooler than built surfaces even if they weren’t losing water, because they are cooled more effectively by convection. A better method is to calculate the cooling effect of a tree directly, by measuring how much water it is losing. You can do this by measuring the sap flow up its trunk, or the water loss from single leaves. These methods show that tree canopies can divert over 60% of the incoming radiation to evapotranspiration. Even a small (4m high) Callery pear tree – a commonly planted species in Northern Europe – can provide around 6kW of cooling: the equivalent of two small air-conditioning units.  But there’s a catch: trees only provide this cooling effect when they are growing well. By measuring water loss from individual leaves, we showed that sparser, slower-growing plum and crab apple trees provided only a quarter of the cooling effect of the Callery pears. What’s more, the effectiveness of trees can be greatly reduced if the growing conditions are poor. We found that the transpiration of Callery pears could be reduced by a factor of five, if the roots were growing through compacted or poorly aerated soil. Much more research is needed on the relative performance of large and small trees, whether they’re planted on streets or in parks. One final difficulty in working out the cooling power of trees is to determine how much a given tree’s evapotranspiration will actually reduce the air temperature. As so often in science, a modelling approach is needed, with physicists, engineers and biologists working together. We need to put realistic trees into detailed regional climate models, which can mimic the complex daily movements of air and energy through the city. Only then can we determine the regional benefits of the urban forest, and work out how to use trees to make our cities cooler and more pleasant places to live in."
"We should thank Volkswagen for the wake-up call. The scandal that has engulfed the company has highlighted how an overwhelming focus on carbon dioxide emissions has oversimplified the debate about the negative impacts of all our combustion engines.  Yes, looking at CO2 works well to quantify effects on global climate and fossil resource depletion, but health impacts are a more complex story. “Dieselgate” is forcing people to realise that most vehicles also produce harmful chemically reactive substances such as nitrogen oxides or tiny particulate matter.  This insight has reached the highest ranks of UK government, where diesel subsidies may soon become re-examined. In fact particulate matter may be responsible for as many as 3m prenatal deaths globally every year, according to a recent study in Nature. No one can tell at this point if this is the end of the diesel engine but surely now is the right moment to look towards cleaner and more sustainable ways to power a car. Two key technologies are on the rise: electric vehicles, including hybrids, and fuel cell vehicles which run off hydrogen. The problem for electric vehicles is most people like to stay in their comfort zone and are worried about charging stations and mileage. The industry recently passed the threshold of 1m global sales in total, half of these sold since July 2014, but it is still behind targets set by the US and other governments.  Fuel cell vehicles are a better match with existing habits. Their energy comes from hydrogen stored in a high-pressure tank which then reacts with water to produce electricity that powers the drive train. This allows for mileages similar to those of conventional cars while being refuelled within a few minutes. Hyundai and Toyota already have small numbers of these vehicles on the market, and some other brands are not far behind.  Hydrogen suffers from a long-standing damaged reputation since the Hindenburg disaster in the 1930s. But lots has changed in the past eight decades. These days, the hydrogen isn’t stored in a flimsy airship but in a tank made of a highly stable carbon composite so the risk of it catching fire is minimal. Hydrogen cars can now be considered as safe as petrol or diesel cars, even in crashes. The more recent fuelling stations extract hydrogen from water by running a current through it, effectively converting electrical energy into hydrogen fuel (you may remember doing this exact water electrolysis experiment in school). This all takes place on site, next to where the hydrogen is then stored ready for drivers to use. Doing everything in the one place – essentially all you need to bring is electricity and water – helps avoid transporting hydrogen fuel around in trucks.  A point commonly raised in this context is the fact that electricity production still largely relies on fossil fuels and that hydrogen production through electrolysis is not the most efficient way of using that primary energy. And, if one really wished to have hydrogen, the “cheaper” way was large-scale production out of natural gas. But this leads back to the important differentiation between localised emissions that harm your health and global emissions that damage the atmosphere: even if the hydrogen production involves fossil fuels, fuel cell cars are still considerably better for your lungs. Even the global emissions will benefit from a hydrogen economy in the long run: hydrogen can be stored in tanks, thus allowing for the production of more hydrogen at times of electricity oversupply. Hence, hydrogen fuels will become an essential buffer to help smooth out increasing gaps between supply and demand in the electric grid of the future. That grid will be increasingly dominated by solar and wind power – which follow weather and daylight patterns – and nuclear power, which provides a solid base supply but cannot dynamically react to demand fluctuations either. Economically, all three technologies are dominated by capital expenditure rather than fuel costs, so producing hydrogen at times when no one else needs the electricity may become even cheaper than today.  Hydrogen refuelling stations are stuck in the same chicken-egg problem that battery-charged vehicles had to overcome. This calls for large strategic investments to ensure that a critical mass of cars powered by fuel cells can be reached and operated, which will then drive down the costs of refuelling stations.  Given such stations can be developed and produced in the UK, rolling out hydrogen refuelling infrastructure will serve a double purpose: it paves the way for cleaner air along our roads and it gives the country an opportunity to lead rather than to react in a rising technology. We should be more than a market for the hydrogen technology that is already embraced and pushed forward by the big technology nations: Japan, Korea, China, and the US. The recent discussion around the proposed nuclear power plant at Hinkley, French-owned and Chinese-funded, had a similar ring to it. Why is the country that once built the first civil nuclear power plant in the position of a technology-importing customer? On hydrogen, it’s time to take the lead."
"We are standing at a pivotal moment in the UK’s relationship with the rest of the world. As parliament reassembles post-election, nations around the world, both within the EU and beyond, are waiting to see what direction the UK will take.  The past three years have been dominated by Brexit. By deals forged and then lost. By a string of votes in parliament. By demonstrations and debates and disunity. Whatever side of the fence you fall on, it’s hard to disagree that our country has lost its united national purpose. Looking from the outside, many nations – even while accepting the referendum result – have been truly puzzled and dismayed by our handling of it. We cannot afford another three years of navel-gazing. While digesting the impact of the election on pressing national issues, it’s time that Britain confounded that puzzlement abroad and reaffirmed its place as an outward-facing, global leader. And there’s no better place to do that than within international development. The UK has a long and proud legacy of supporting and investing in the world’s most vulnerable communities. From Bolivia to Bangladesh, our investment has saved the lives of millions, and is helping them reshape and rebuild shattered communities. But while we’ve made huge progress in reducing extreme poverty worldwide, there is still a long way to go. Climate change is taking hold, natural disasters are becoming more deadly and frequent than ever before, new wars are erupting and mass displacement is growing. The world is becoming a more dangerous place, especially for children. They can’t wait for Britain to get its act together. I served as minister of state for the Department for International Development (DfID) until earlier this year; I’ve seen first-hand what a difference aid makes. With the full backing of a parliament that is often bitterly divided on other matters, we helped deliver £30 million to rebuild hospitals, schools and other vital buildings destroyed by Islamic State in Iraq. As a result, families torn apart by the terror group’s brutality have been able to start moving back home. Aid is more than just platitudes by governments. It transforms lives. It’s because of this proven success that we can’t back away from our international commitments. In southern Africa, the worst drought in more than three decades has put a record 45 million people across 16 countries at risk of food shortages. Aid agency World Vision has estimated that put together, this is enough people to stretch around the world one and a half times. Across the globe, the impact of quakes, tsunamis, typhoons, floods and droughts is slowing economic growth, undermining development and trapping millions of people in poverty. Just this year, Mozambique suffered its two most severe cyclones on record within weeks, while devastating floods tore through Asia. These crises need urgent intervention if we are to avoid thousands of needless deaths. I hope the government will not make a hasty decision on merging DfID and the Foreign Office. A standalone DfID has been excellent for the UK’s reputation abroad, and those who work for it truly represent global Britain. As we enter this new season, my message to our new political leaders is this: use that unity between parliament and people as an anchor for rebuilding our national purpose, and demonstrate that we will not forget the world’s poor. They’re counting on us. Alistair Burt is a former minister of state for international development and former Conservative MP. "
"Jaguar Land Rover has become the latest car manufacturer to announce its entry into the world’s first fully electric racing series – the FIA Formula E World Championship. It is reported that the racing series will serve as a platform for the development of an electric-powered road car – perhaps an SUV to rival Tesla’s Model X.  As the nations of the world pledge action on climate change, the automotive industry will face renewed pressure to come up with alternative energy solutions. Consumer demand for passenger cars which reduce harmful emissions without sacrificing performance will be on the rise – more so in the wake of the VW scandal,   Against this backdrop, the potential of both hybrid electric vehicles (HEVs) and battery electric vehicles (BEVs) certainly needs to be considered. But they are not our only clean energy alternative.  The internal combustion engines of both petrol and diesel-fuelled cars can be hybridised by adding electric components – such as motor-generators – together with a small amount of energy storage. Hybridisation offers an excellent opportunity to optimise the way we use the internal combustion engine. It enables the engine to operate at a higher average level of efficiency, and gives cars a way to recover the kinetic energy produced by braking, which is otherwise wasted.  It’s reasonable to expect that a majority of vehicles will be hybridised to some extent in the not-so-distant future, since these small modifications can yield big returns in terms of energy use.  The BEV is a much more challenging proposition as it requires large, expensive, resource-intensive batteries to deliver the kind of power that drivers expect. By contrast, combustion-powered cars are affordable because they are built from cheap materials using cost-effective processes and have a very inexpensive energy storage system – a liquid fuel tank. As a result, the extra costs associated with BEVs will be a major turn off for manufacturers.  What’s more, BEVs only offer a marginal reduction with regard to in-use and life-cycle CO₂ emissions, compared with their combustion-powered competitors. This is because – in Europe at least – almost half of our electricity is generated by burning fossil fuels. Of course, we’ll need to re-evaluate this assessment as our electrical grids become less carbon intensive. And one of the best arguments for EVs is that they help us to develop our infrastructure and technology, in anticipation of a time when renewable electricity becomes commonplace.  Even so, there are a number of competing technologies in the passenger car space – and it’s critical that we research all possible routes to clean, sustainable transport.  Electrofuels – which are fuels manufactured using renewable electricity – offer one plausible alternative to BEVs and HEVs. The idea of using hydrogen gas (H₂) made with renewable electricity to power cars has been around for a long time. The attraction is that releasing energy from H₂ produces only water as a by-product, making it a very clean fuel. But unfortunately, it presents some serious challenges around distribution and storage.  It’s currently thought that H₂ will have to be stored at a very high pressure to get a reasonable amount of energy on board a vehicle – and even then, its density is only comparable to styrofoam. To be sure that H₂ storage tanks are crash- and fire-proof, they have to be extremely thick, carefully-made composite structures. For comparison: to contain the same amount of energy as a 10 US gallon liquid fuel tank, a hydrogen storage tank would have to weigh about 170kg to 180kg. This inevitably drives up costs, and that’s not even considering the problem that H₂ – being the smallest molecule – has a tendency to leak out of tanks and storage systems, and can cause steels to become brittle.  Arguably, a more exciting and practical alternative is to use this technique in power plants. The H₂ generated using renewable energy can then be combined with waste CO₂, in order to synthesise methane. The methane is then injected into the national gas grid, to be used by compressed natural gas (CNG) powered cars. The ultimate goal for this approach is to use CO₂ extracted from the atmosphere. If this can be done, the approach would yield a truly renewable fuel which takes out as much carbon from the atmosphere as it puts in. This process points the way to a sustainable future which retains the low-cost, high-utility internal combustion engine.  It is also possible to produce liquid fuels in a similar way, by using H₂ and CO₂ to synthesise methanol – an alcohol related to methane, which is the simplest liquid energy carrier. While liquid fuels take more energy to produce, they also tend to have a higher energy density than most gas fuels.  Importantly, methanol can also be blended with gasoline and ethanol, and synthesised into pure hydrocarbon fuels, which can act as substitutes for gasoline, diesel and kerosene. Creating these types of high energy density fuels will be the only practical way to decarbonise aviation, for instance. What’s more, methanol can also be made into plastics and other petrochemicals, allowing many different industries to harness excess CO₂.  There’s one sticking point, though: currently, the extraction of CO₂ from the atmosphere on an industrial scale remains a futuristic goal. Still, it is a known, practical process which would enable the mass use of renewable energy in some of the poorest nations on earth, while providing a supply of liquid energy to meet the world’s transportation requirements. It also permits mass uptake of wind and solar power within existing economies, since fuel production provides a means of converting and storing renewable energy, which the electricity grid currently lacks.  At the present time, it makes more sense to use renewable electricity in fixed applications which do not need storage batteries and to reserve fossil fuels for mobile applications, where their energy density is of most use. Because electrofuels can be blended with the fossil fuels we already use, they don’t require us to radically change our energy infrastructure and they don’t decrease utility for drivers.  Both approaches need funding, but electrofuels represent the minimum change to the status quo. They will also require no investment in infrastructure from governments, while yielding the same amount of tax revenue. For all these reasons, electrofuels seem a much more probable route to cleaner driving than BEVs."
nan
"
Share this...FacebookTwitter
Global Temperature Data Manipulation
 Thousands Of Non-Urban Thermometers Removed 
0.3°C Of Pause-Busting Warmth Added Since 1998 
0.5°C Of Warming Removed From 1880-1950 Trend

Over the course of the last few decades, overseers of the 3 main 19th century-to-present global temperature data sets — NOAA, NASA, and HadCRUT — have been successfully transforming the temperature record to the shape dictated by climate models.  Namely, there has been a concerted effort to cool down the past — especially the 1920s to 1940s warm period — and to warm up the more recent decades, especially after about 1950.  In this way, a trend of steep linear warming emerges that looks similar to the linear shape of anthropogenic CO2 emissions for the 20th and 21st centuries.  A better fit between anthropogenic CO2 emissions and surface temperature helps to imply causation, and this ostensible correlation-turned-causation can then be used to justify policy decisions aimed at eliminating fossil fuel energies.

75% Of GHCN Temperature Stations Removed Since 1970s

One of the most unheralded means by which this temperature “shaping” occurs has been the tendentious and wholesale removal of thousands of weather station land thermometers from remote, high altitude, and/or non-urban locations since the 1970s.  These are stations which do not show the warming trends predicted by models, as they are not affected by proximity to artificial or non-climatic heat sources (pavements, buildings, machinery, industry, etc.) like urban weather stations are.  (As detailed below, locating thermometers near urban heat sources can cause warming biases of between 0.1 and 0.4°C per decade.)
If a highly disproportionate number of non-urban weather stations are removed from the global temperature archive, the urban-based thermometers will be weighted much more heavily than they were before the non-urban stations were removed.  And therefore, the temperature record will show (much) more warming — even though the additional warmth is not climatic, but artificial.
And this is exactly what has happened.  The Global Historical Climatology Network, or GHCN, is the primary source for temperature data records from all over the world.  NOAA, NASA, and HadCRUT heavily rely on GHCN for temperature histories in constructing their global data sets dating back to the 1800s.  According to McKitrick (2010), there were still between 5,000 and 6,000 weather stations across the globe contributing to the GHCN temperature archive as recently as the 1970s.  Today (or as of 2009), there are only a little over 1,000 left — 75% of the thermometers used in the 1970s have disappeared.  There are now fewer weather stations contributing to the GHCN than there were in 1919.
Astonishingly, as many as half (49% as of 2009) of the weather stations across the globe used by the GHCN are now located on the grounds of airports.

McKitrick, 2010
“There are three main global temperature histories: the combined CRU-Hadley record (HADCRU), the NASA-GISS (GISTEMP) record, and the NOAA record. All three global averages depend on the same underlying land data archive, the Global Historical Climatology Network (GHCN). Because of this reliance on GHCN, its quality deficiencies will constrain the quality of all derived products.”
“The number of weather stations providing data to GHCN plunged in 1990 and again in 2005. The sample size has fallen by over 75% from its peak in the early 1970s, and is now smaller than at any time since 1919.”




Growing bias toward airport sources
“The collapse in sample size has increased the relative fraction of data coming from airports to about 50 percent (up from about 30 percent in the 1970s). … The change in the sample was not uniform with respect to source type. For instance it has biased the sample towards airport locations. GHCN had already been heavily-weighted towards airports, which, for many reasons, are not suitable for climatic monitoring. A problem with airports is that they are often in urban or suburban locations that have been built up in the past few decades, and the increase in global air travel has led to increased traffic, pavement, buildings and waste heat, all of which are difficult to remove from the temperature record. … [A]t the global level, as of 2009 49% of all GHCN data came from airports (46% NH, 59% SH), up from just over 20 percent in the late 1920s.”   —  McKitrick, 2010


NOAA’s Tom Karl Was Once Concerned About Urban/Airport Warm Bias

During the late 1980s, the warm bias of 0.1°C to 0.4°C per decade attributed to the urban (or airport) siting of temperature stations was thought to severely compromise the global temperature data sets, with “a substantial portion of the overall trend of global and regional temperatures” directly reflecting this warm bias.   The “artificial warming in the primary station network” never went away.  But it is now just ignored.

Karl and Quayle, 1988
“Karl et al., 1988) has shown that at some ‘sun belt’ cities in the West, the rise of temperature that can be attributed to the urban heat island is as much as 0.3 to 0.4°C per decade. In the East, the rise is over 0.1°C per decade. … The artificial warming in the primary station network, relative to the climate division data, is nearly 0.17°C over the past 34 years [since ~1950]. Such trends are at least as large as any of the observed trends over the United States (Karl, 1988) or the globe (Jones and Wigley, 1987).”
Karl and Jones, 1989
“Results indicate that in the United States the two global land-based temperature data sets have an urban bias between +0.1°C and +0.4°C over the twentieth century (1901-84). … At present, only rough estimates of the potential impacts of urbanization can be given.  This includes an urban bias in the Hansen and Lebedeff (1987) [NASA] data over the United States between 0.3°C and 0.4°C over the 20th century, which is larger than the overall trend in the United States over this period. … To our knowledge, the United States is the only large area of the globe where the magnitude of this bias has been thoroughly studied.”
“The magnitude of this urban bias in two global, land-based data sets was found to be a substantial portion of the overall trend of global and regional temperatures.”
Kukla, Gavin, and Karl, 1986
“Meteorological stations located in an urban environment in North America warmed between 1941 and 1980, compared to the countryside [cooling], at an average rate of about 0.12°C per decade.  Secular trends of surface air temperature computed predominantly from [urban] station data are likely to have a serious warm bias. … [W]e compared trends of the 34 urban/rural station pairs…urban stations show a warming with respect to the countryside throughout most of the year.  
The average annual difference of the trends is about +0.11°C per decade [of non-climatic warming due to urban location]. … The average difference between trends [urban siting vs. rural] amounts to an annual warming rate of 0.34°C/decade.  … The reason why the warming rate in subset D is considerably higher [may be] that the rate may have increased after the 1950s, commensurate with the large recent growth in and around airports. … Our results and those of others show that the urban growth inhomogeneity is serious and must be taken into account when assessing the reliability of temperature records.”

Growing bias toward lowland sites
“The steady increase [in the mean altitude of temperature stations above sea level until the 1980s] is consistent with a move inland of the network coverage, and also increased sampling in mountainous locations. The sample collapse in 1990 is clearly visible as a drop not only in numbers but also in altitude, implying the remote high-altitude sites tended to be lost in favour of sites in valley and coastal [urban] locations. This happened a second time in 2005. Since low-altitude sites tend to be more influenced by agriculture, urbanization and other land surface modification, the failure to maintain consistent altitude of the sample detracts from its statistical continuity.  … GHCN has progressively lost more and more high latitude sites (e.g. towards the poles) in favour of lower-latitude sites. Other things being equal, this implies less and less data are drawn from remote, cold regions and more from inhabited, warmer regions.” —  McKitrick, 2010



The Results: Artificial Land Warming Since 1980


NOAA Global Land vs. Sea 


HadCRUT Land vs. Ocean Temperature Anomalies

NOAA Adds +0.3°C Of Warming (Relative To Satellites) Since 1998

Earlier this month, the Karl et al. (2015) “pause-buster” paper was once again subjected to significant criticism by another former NOAA scientist (Tom Karl was NOAA’s Director during 2015) due to allegations there were political motivations to rush the paper to press before the (December) 2015 Paris Climate Change Conference without requisite quality checks.  The motivation was obvious: If the inconvenient pause in global warming reported by the IPCC in 2013 could be eliminated, it would be a significant development that might encourage government leaders to pledge to reduce CO2 emissions.   Unfortunately, the original temperature data used to compute the new trend (“For 1998–2014, our new global trend is 0.106± 0.058°C dec−1“) in the NOAA publication has been “lost” on a faulty computer that had undergone a “complete failure,” leaving little chance for independent replication or verification.
Since then, the New York Times has issued a defense of the NOAA controversy by claiming that the 1998-2014 trend used in the Karl et al. (2015) paper has been independently verified by other scientists, as well as by satellite data, to show that the +0.11°C per decade trend (+0.2°C overall) between 1998-2014 was consistent across all data sets.
This claim is false, of course.   Using the raw data available and the WoodForTrees interactive tool, we see that the trend discrepancy for the period under consideration (1998-2014) in the Karl paper is nearly 0.3°C when comparing the recently created NOAA trend to satellites (RSS).  There is as much as a 0.5°C difference between the NOAA/NASA GIS and RSS trend line end points (December, 2014).  The -0.1°C cooling that emerges in the satellite data has been transformed into a +0.2°C warming by Karl et al. (2015).  Almost immediately after its publication, the new warming trend for 1998-2014 was accepted by NASA and HadCRUT as well, allowing all three long-term data sets to now show significant warming when there had previously been a pause, even cooling.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Source: WoodForTrees

HadCRUT Erases 1998-2012 Slight Cooling Trend By Changing Versions

Changing unpalatable temperature trends in time for an event of intergovernmental and public policy significance has happened before.
The combined Hadley Centre and Climatic Research Unit (HadCRUT) data set — which is featured in the Intergovernmental Panel on Climate Change (IPCC) reports — underwent a revision from version 3 to version 4 in March of 2012.  This was about a year before the latest IPCC report was to be released (2013).  At the time (early 2012), it was quite inconvenient to the paradigm that HadCRUT3 was highlighting a slight global cooling trend between 1998 and 2012, as shown in the graph below (using HadCRUT3 and HadCRUT4 raw data from WoodForTrees).
Graphs used by the IPCC depicting a slight cooling trend since 1998 would not be acceptable to policymakers wishing to emphasize the urgency of addressing dangerous global warming.  So, just in time for the 2013 edition of the IPCC report, about 0.1°C was added to the 1998-2012 HadCRUT trend.  The effect was to transform the slight cooling into what the IPCC called a “hiatus” from warming.  To achieve the removal of the slight cooling trend found in HadCRUT3, the more recent anomalies in HadCRUT4 were warmed up (by 0.1 to 0.2°C), whereas the past warmth (especially around 1998) was left intact.  The effect was to warm the present and cool the past.


Source: WoodForTrees

IPCC (2013) analysis of the 1998-2012 “hiatus” from warming:
“For the period 1998–2012, 111 of the 114 climate-model simulations show a surface-warming trend larger than the observations.”
“During the 15-year period beginning in 1998, the ensemble of HadCRUT4 GMST trends lies below almost all model-simulated trends.”
“Almost all CMIP5 historical simulations do not reproduce the observed recent warming hiatus.”

NASA Has Removed Almost 0.5°C From 1880-1950 Warming Since The 1990s

As recently as 1990, it was widely accepted that the global temperature trend, as reported by NASA (Hansen and Lebedeff, 1987), showed a “0.5°C rise between 1880 and 1950.”

Pirazzoli, 1990


This 0.5°C rise in global temperatures between 1880-1950 (and 0.6°C between 1880 and 1940) can clearly be seen in the NASA GISS graph from 1987:


Schneider, S. H. 1989. The greenhouse effect: Science and policy. Science 243: 771-81.

Today, it is no longer acceptable for the HadCRUT, NASA, and NOAA global temperature data sets to graphically depict a strong warming trend during the first half of the 20th century.  This is because anthropogenic CO2 emissions were flat and negligible relative to today during this abrupt warming period, as shown here:



So as to eliminate the inconvenience of a non-anthropogenic warming trend in modern times, NASA and NOAA have removed all or nearly all the 0.5°C of warming between 1880 and 1950.  If past raw temperature data do not fit the narrative that human CO2 emissions drive climate change, the raw data must be changed.  In this way, the paradigm is kept alive.


NASA GISS graph


 
Share this...FacebookTwitter "
nan
"When I was growing up in the 1960s, December marked the onset of winter with regular falls of snow, even in the London suburbs. But recent Decembers have bucked the historical trend, being mild and wet, and none more so than December 2015. Indeed, this was not just the wettest December, but the wettest month ever recorded across the UK, with close to twice as much rain as the long-term average. This was largely due to the arrival of three Atlantic storms from the west: Desmond, Eva and Frank. These contributed to an average rainfall across the UK of 230mm (a shade over 9in), beating the previous monthly high set in November 2009.  The prevailing south-westerly airstream also made December 2015 the warmest December on record, with highs of over 17C (63F) in Gravesend, Kent, warmer than Athens and Lisbon. In Dorset, holidaymakers took advantage of the unusually warm weather to bathe in the sea. More ominously, a record night-time temperature of 14.2C (58F) was logged in Devon. The record highs were the result of a warm airstream reaching the UK from the Azores; with an unusually powerful El Niño leading to warmer sea temperatures, which had a knock-on effect on air temperature readings in the south-west."
"Goldman Sachs has ruled out future financing of oil drilling or exploration in the Arctic and said it would not invest in new thermal coal mines anywhere in the world. The new environmental policy, which was released by the US bank on Sunday, was praised by environmentalists, though many warned that it was only a first step.  In its statement, Goldman Sachs also “acknowledged” the scientific consensus on the climate crisis, which it said was one of the “most significant environmental challenges of the 21st century” and said it planned to more effectively help its client manage climate impacts, including through the sale of weather-related catastrophe bonds. Jason Opeña Disterhoft, a climate and energy campaigner at Rainforest Action Network (RAN), which helped to lobby for the change, said the decision to rule out direct financing for Arctic exploration made Goldman the first US bank to establish a “no-go” zone in the oil and gas sector. “Goldman Sachs’s updated policy shows that US banks can draw red lines on oil and gas, and now other major US banks, especially JPMorgan Chase – the world’s worst banker of fossil fuels by a wide margin – must improve on what Goldman has done,” he said. If other banks followed suit, he added, coal financing would become “unbankable”. An investigation by the Guardian earlier this year found that the world’s largest investment banks had provided about $700bn in financing for the most aggressive fossil fuel companies since the signing of the Paris climate agreement. That financing was led by JP Morgan Chase, which has provided $75bn to companies expanding fracking operations and Arctic oil and gas exploration since 2016. RAN and other activists, including veteran Bill McKibben, singled out the “tireless Indigenous-led resistance for pressing Goldman Sachs to make the change, including the Gwich’in Steering Committee, which represents more than a dozen indigenous Gwich’in communities in Alaska and Canada. The new policy was seen as an important development in part because, environmentalists said, the US had been lagging behind European peers and Asian banks that have been making the most rapid progress in addressing the climate crisis. Even as Goldman Sachs won some praise, however, it is clear that the company was not fully committed to backing away from its involvement in the oil and gas sector. The bank reportedly lobbied aggressively last summer to win a seat at the table ahead of the initial public offering of Saudi Aramco, the world’s worst state-owned polluter. Recent reporting on the IPO indicated that Goldman Sachs, among other banks, was likely to miss out on an anticipated fee “bonanza” after the size of the offering was scaled back. Citing people with knowledge of the matter, Bloomberg News recently reported that Goldman Sachs was among the banks that were expected to make less than it had anticipated after foreign investors opted not to participate in the share sale. While Goldman Sachs suggested that its motive in refraining from Arctic drilling was an environmental one, it was not the first time the bank has suggested it was opposed to the idea. In 2017, one of the bank’s natural resource experts said that the allure of tapping the Arctic for new resources had been “dispelled” by the other “enormous cheap, easier to produce and quicker time-to-market resources in the Permian onshore US” resources, referring to western Texas and southeastern New Mexico. Michele Della Vigna, head of energy industry research at Goldman Sachs, said in 2017: “We think there is almost no rationale for Arctic exploration … Immensely complex, expensive projects like the Arctic we think can move too high on the cost curve to be economically doable.” The move on Sunday nevertheless won plaudits from the Sierra Club, among others, which said it had met with Goldman Sachs representatives and other major banks in recent months, along with the Gwich’in Steering Committee, to discuss the dangers of Arctic drilling. “The Trump administration may not care about ignoring the will of the American people or trampling Indigenous rights, but a growing number of major financial institutions are making it clear that they do,” said Ben Cushing, a Sierra Club campaign representative. “We hope other American banks will follow their lead.”"
"As recently as 6,000 years ago the Sahara was green and fertile. We’ve found evidence of large rivers crossing the region, lined by flourishing settlements. Then suddenly things changed. Trees died and the land dried up. Soil blew away or turned into sand and those rivers were no more. In just a few centuries, the Sahara was transformed from a region similar to modern South Africa into the desert we know today. This is an example of a “tipping point”. Just think of the climate like a chair. It takes a strong push to tip over a chair stood on four legs, but when it’s leaning on only two legs the required push becomes smaller. Indeed, if the inclination becomes large enough, it will tip over by itself.  Today, climate change inclination is increasing – and we know it could suddenly tip over, as our planet has previously witnessed several abrupt switches between different states. Along with what happened to the Sahara, there are also the flip-flops between ice ages and moderate conditions which happened every 1,000 years, before things settled down 10,000 years ago.  The idea that global warming might destabilise many climate systems and give rise to abrupt transitions was explored in the movie The Day After Tomorrow, in which melting ice shelves caused a sudden reversal in Atlantic currents – and a worldwide catastrophe. The idea of climate tipping points was explored more rigorously by a team of scientists led by myself for a study recently published in the journal PNAS. We looked at all the simulations performed by 37 climate models that had been used to inform the Intergovernmental Panel of Climate Change (IPCC) – together with their historical and pre-industrial simulations. That gave us a gigantic amount of data: around 1015 bytes divided over several computer servers around the world.  We detected 37 cases of abrupt change, distributed over three different climate change scenarios. These include the Arctic becoming ice-free even in winter, the Amazon rainforest dying off and the total disappearance of snow and ice cover on the Tibetan Plateau. There’s a 30% chance that at least one of these tipping points will be crossed over the next 200 years. This increases to 50% in the most aggressive warming scenario. However, the likelihood of crossing any individual tipping point is much lower, only a few percentage points. So the Himalayas will probably still retain at least some of their glaciers. You should still be able to stand on the North Pole in January. But, taken together, there’s a decent chance that something major will happen. One of the most important findings is that 18 out of 37 abrupt changes are likely to occur when global temperature rises are 2℃ or less, often presented as an upper level of “safe” global warming. Our results imply that there is no window of “safe” global warming and no threshold separating safe and dangerous climate change. Every 0.5℃ temperature increase is similarly dangerous. Many of the tipping points we found apply to sea ice and ocean circulation. Because seawater reflects less sunlight than ice – and absorbs more heat – disappearing sea ice means further local warming, which in turn means more melting sea ice. This process may quickly amplify the effect of global warming. Most climate models simulate an abrupt disappearance of all summer sea-ice in the Arctic at some point this century. Sometimes models predict the reverse process will occur, with sea-ice forming in regions that were previously open water. For instance, water draining from the Greenland and Antarctic ice sheets, combined with increased precipitation and melting sea ice may lead to ocean surface waters becoming fresher and lighter than usual. In the far north Atlantic, this would prevent the mixing between colder surface water and heat from the deep ocean that usually takes place in the region. With heat remaining deep in the ocean, the resulting cooling would be more widespread – one model predicted that by 2060 the Baltic Sea could almost entirely freeze over every winter. In two scenarios this process is associated with a collapse of the Atlantic circulation that brings warm water from the Southern Hemisphere to cold seas around Greenland where it sinks. A collapse of all sinking shuts this circulation down.  This is The Day After Tomorrow scenario. I recently wrote a separate paper analysing the possible effects of such a collapse in oceanic currents – it’s more plausible than you might think and it really would lead to global cooling. In fact, depending on continued emissions levels, the effects could even outweigh global warming for decades to a century, especially in the Northern Hemisphere. Such sudden transitions are more rare on land, but some models predict that a 2.5℃ warming could cause the Amazon rainforest to disappear within 200 years. Forests contain a lot of moisture, and evaporation keeps the local climate cool. If trees start dying the region will grow warmer and drier, which will kill more trees.  Most climate models still don’t even factor in how vegetation will respond to changes in climate – and improvements in this respect would probably lead to more predictions of land-based “tipping points”. Likewise, ice sheet collapses and carbon and methane release from thawing permafrost could also lead to abrupt transitions but aren’t yet included in climate models. For these reasons my colleagues and I believe that the catalogue of abrupt shifts we found is actually at the lower end of what might occur in reality. Dangerous climate change isn’t restricted to 2℃ global warming or more – to avoid unpleasant surprises we should limit it as much as possible."
"
Share this...FacebookTwitterThe German online Nordwest Zeitung (NWZ) reports here how mainly German Socialists and Greens (of all people) are moving to relax strict laws designed to protect nature and endangered species.
The aim is to clear the way for the industrialization of the North German rural countryside and natural areas with wind turbines.

Pushed by Germany’s Greens and Socialists, the country’s nature protection act to be watered down to make the industrialization of natural areas far easier. Image cropped from here.
Journalist Marco Seng reports that under the existing law a planned wind park near the town of Zetel, for example, will have to remain shut down for 6 months every year in order to protect the area birdlife. However, denying wind park construction and operation in order to protect nature and wildlife has become just too much to ask of Germany’s socialists and environmentalist greens.
They are now pushing through a watered-down law.
Each year in early spring a number of bird species transit through or nest in north German regions, which wind park developers and operators happen to find ideal wor wind energy generation. That’s a big problem. Under the current federal law wind turbines located in sensitive areas are required to shut down from March 1 to August 30 in order to comply with § 44 of the German Nature Protection Act.
Seng reports how a number of turbines are planned to be erected in different areas this year. For example the county of Friesland gave its approval in early January to rezone the areas by the end of March and allow the construction of turbines. Citizens groups however have protested, claiming that the turbines will not be profitable due to the summer shutdown period. Yet the mayors insist they will still make a profit and the projects will go ahead.
All this is highly controversial as the NWZ writes that recent studies and expert assessments have concluded that “many bird species are threatened, foremost predatory birds because they do not avoid turbines“.
Also the Deutsche Wildtier Stiftung (German Wildlife Foundation) estimated that approximately 250,000 bats and over 12,000 predatory birds fall victim to wind turbines annually, with a high number being killed over northern Germany. Recently some courts found in favor of the red kite hawk, and thus some planned wind parks were denied approvals to be constructed. The reason, NWZ reports, “a high risk of death to birds and adverse feeding conditions for predatory birds.”
So it’s little wonder that wind energy proponents are adamantly pushing for relaxing Germany’s nature protection laws.
At other locations, wind park projects are being given the green light anyway, angering nature-protection activists. The NWZ quotes Monika Oetje-Weber of the Kammersand citizens’ action group:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




If all the information and documentation on the presence of important bird species had been taken seriously, then the approvals would have never been issued.”
The municipalities and project proponents, however, insist that the the turbines that are to be erected will pose no threat to bird life.
Watering down the nature protection laws to allow the turbines to run all year.
Because of the intensifying collision course between wind projects and birdlife and nature, and the increasing protests against wind parks in rural areas, the German government is now moving to alter Germany Federal Nature Protection Act to make it easier to build and operate wind parks and highways. The NWZ writes:
You read that correctly. In the future the Federal Nature Protection Act’s § 44 Section 1 No.1 ban against killing will be valid for interventions and projects if the risk of death for especially protected species in unavoidably signficantly high.”
This means the bar will be significantly lowered for wind projects. The reaction from nature activists came swiftly and harshly. The NWZ:
‘The amendment leads to a dramatic threat increase to birdlife and bats by wind turbines, and that is unacceptable,’ says Fritz Vahrenholt, Chairman of the German Wildlife Foundation. The killing of birds is thus no longer a principle reason for obstructing wind turbine parks.”
Other leading traditional environmental protection groups such as NABU are outraged, writes the NWZ:
We see absolutely no necessity for the planned amendment. We demand that lawmakers do not pass the amendment as it currently stands,’ says NABU President Olaf Tschimpke.”
Others accuse the government of having hollowed out the country’s nature protection laws and caving in to industry lobbyists. Others say that approval committees have not been strict enough when it comes to species protection assessments, claiming that the planning of the projects violates the law.
The NWZ concludes that a major collision between nature protection and the wind industry is now more unavoidable than ever. But the trend is clear: in Germany nature and birdlife are losing the battle against the powerful industrial wind lobby and climate protection activists.
Germany risks seeing the worst government-steered environmental disaster since the collapse of Communism late last century.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhat follows is a wrap up of an article written by skeptic climate and weather site wobleibtdieerderwaermung.de here.
It writes that for thousands of years it has been the solar and ocean cycles that have been influencing the weather worldwide and in Germany.
And looking at data objectively, it is pretty clear that there is little relationship between weather/climate and the rising CO2 concentrations in the atmosphere, as the global warming pause between 1997-2016 shows:

Linear trend of RSS temperatures. No warming in 224 months despite the current powerful El Niño-event. “The least-squares linear-regression trend on the RSS satellite monthly global mean surface temperature anomaly dataset shows no global warming for 18 years 8 months since May 1997, though one-third of all anthropogenic forcings have occurred during the period of the Pause.“ Source: The Pause hangs on by its fingernails.
Naturally climate models continue to grossly overstate the trend for global temperature:

IPCC climate models obviously have assumed an excessively high value for CO2 climate sensitivity. Source: On Natural Climate Variability and Climate Models.
The IPCC climate model projections diverge increasingly from the measured reality, year after year. 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In fact new studies have clearly exposed three decisive errors in the programming of climate models:
1. The cooling effect of aerosols has been over-estimated by a factor of 2: Hamburg Max Planck Institute for Meteorology: Aerosols cool less than originally thought.
2. The warming effect of CO2 in in the atmosphere is as a result overestimated by a factor of 2 or three. See: Die kalte Sonne site here (German).
3. The complex effect of fluctuations in solar activity are poorly accounted for in climate models. Solar Forcing of Climate – NIPCC
The consequences: All parameters when used realistically lead to a considerably lower global and regional warming — especially in the future, see following chart:

Source: Peer-reviewed pocket-calculator climate model 
It’s time to end the hysteria surrounding CO2 and its grossly exaggerated effects on climate and the ridiculous efforts of protecting the climate on every point on the planet every day for 30 years (whose statistical average is the World Meteorological Organization’s definition of climate). Very little can be accomplished trying, and the price would be enormous and ruinous.
We can argue over whether the pause has ended or not, but one thing is clear: the observations are all well below the model projections.
 
Share this...FacebookTwitter "
"Two weeks ago, as I was walking west through my neighbourhood in the early morning, I was struck by the eerie copper tone in the atmosphere. I turned and looked to the sky and was stunned by the glowing red sunrise. It was utterly disorienting – I stared, took photos, checked the sky in all directions, confused about what I was seeing. I knew from its position that it had to be the sun but it looked nothing like it. To the west of the city, and north along the coast, bushfires raged out of control. The intense red light bounced off concrete and shined off street poles. There were a few other early risers on the street, all of us stopped in our tracks, faces turned to the sky. Many raised their phones and snapped. And then we went on with our day. Unsettled, disoriented and looking over our shoulder every few steps, but for the most part operating as we usually would. It is a bizarre position in the landscape to hold, living at the edge of calamity. Paying closer and more considered attention to the natural world has been a personal project of mine over the last 18 months, which I have chronicled at times in journal entries. It began as a somewhat inward-looking exercise to help myself feel more grounded in times of stress. For the most part, those journal entries unfurled like plants themselves, forming at the root with whichever plant or flower I identified with at the time of writing, and reaching out towards the underlying feeling as if towards the sun. It has, at times, caused me significant emotional distress. When I noticed certain plants blooming months after they usually do, when I noticed the persistent greens right through the winter months, when I noticed cold-weather blooms coming out later because of the steadfast heat – these things prompt awareness of the future of the planet and I have given in many times to despair. I discovered the true potential of this project recently in reading Jenny Odell’s How to Do Nothing, a meticulous and wide-ranging treatise on rejecting modern capitalism’s notions of productivity and optimisation. In the book, Odell describes discovering, among many other things, that embracing bioregionalism can be a way of returning to community, which in turn ensures more effective activism. Odell writes: “Observation and simple conviviality should be recognised not only as ends in and of themselves, but as inalienable rights belonging to anyone lucky enough to be alive.” The summer I experienced when I first moved to Sydney three years ago was full of days spent in a near-sensual anticipation of heading outdoors. I fell in love with the air in all its sickly sweet promise, thick and nourishing with humidity. Before this year, the idea of being outdoors represented a promise of bright expanse, the sky felt wide and infinite. By December, hedges of unruly jasmine start curling and browning in the heat, wilting and heavy after their springtime explosion. The fragrance of frangipani emerges and mingles with that of hot, wet concrete. The jacarandas turn and the bright purple blooms start dropping to the streets. What I love most about the jacarandas is their capacity to surprise you, particularly in built-up urban environments, dotted as they are throughout the city, in pockets between apartment buildings, warehouses and garages. This year, that anticipation of moving outdoors at the end of the day has transmuted to dread. I heed health advisory warnings that instruct us to stay indoors. I cancel classes and appointments. I notice the subtle tightening in my chest. Looking to the jacarandas outside my office, I am startled by the colour contrast – the bright purple against a shock of orange sky. When afternoon comes, the light turns and an ominous red light starts stretching across the floors, through windows that are dusted with a thin film of ash. A week ago – before the day the thickest smoke choked Sydney and thousands of protesters took to the streets in particle respirator masks – I walked through my neighbourhood on my way to meet a friend. The sky was a deep tangerine and I watched as crowds of office and retail workers on their way to Christmas parties rushed through the street in groups, wearing felt reindeer ears and Santa hats, clutching at each other in what I intimated was a perverse, confused joy. I walked past outdoor dining tables, people eating with their pollution masks suspended from their chins. I overheard one man talking to his friends as they waited at a pedestrian light, “I can’t stop thinking about the dinosaurs.” I looked up at the glowing sky as he crowed, “This is it!” We in the cities are experiencing now what those in areas afflicted by drought, floods and fire have felt for some time: solastalgia. Solastalgia is a term coined by the philosopher Glenn Albrecht while researching the impact of open-cut coalmining in New South Wales’ upper Hunter region. It describes a sense of grief, of existential dread and distress, caused by significant environmental change. I find myself refusing to accept that this is the new normal by insisting on another normality Alexis Wright has written of the new language of climate catastrophe and the powerful nature of this country. Indigenous people have long argued of the responsibility we humans have to the land. The sense of connection we feel to the natural world is vital, and it is no less so for those of us living in cities and built-up environments. In recent weeks I catch myself making matter-of-fact asides about the end of days, and I’m working to pull myself up, because I worry what it does to any sense of purpose or resilience I might need. It has become clear to me that going forward, nothing will be more important than sensitivity and hope – and nothing will be more dangerous than resignation. A phrase I’ve heard often over the past fortnight is, “the new normal”. Most of us are questioning, but I worry that some of us are, already, accepting. I’m guilty of this tendency, too. I share photos of the impossibly red sun on my Instagram stories and I caption them “normal”. “Normal sun, normal planet.” I text my houseshare group chat pictures of the P2 masks I bought for us and caption it “just Anthropocene things”. A year or so ago I started joking that my gym membership was less about managing my mental health (it was) and more about preparing for the end of days (it started to feel possible). Of course, part of this is a natural inclination to revert to humour, when to submit to the overwhelming sense of catastrophe would be too much to bear. But beneath the jokes is a very real fear. My hope is that I have a few ways of pushing against this sense of resignation within myself, the first of which is to remain aware of the ways in which politicians and mining corporations benefit from these exact feelings of hopelessness. The second way feels open to dismissal as frivolous but it’s for that very reason I want to hold on to it – it is a refusal to be denied the pleasure of nature. It’s not a solution on its own and it must necessarily take place in context of sustained protests and strikes. But part of what has made these strange orange days so distressing is the fact that life does go on. It feels absurd that life should be so normal. I find myself refusing to accept that this is the new normal by insisting on another normality. Insisting on the right to an unencumbered existence outdoors means insisting on a planet that is not merely habitable, but one that is joyful, nourishing and sustaining. I don’t want for my friends to adjust their toddlers’ playtime routines to navigate playgrounds covered in ash, to seek out respirator masks that will fit their small and ever-changing faces. I want the prospect of going outside at the end of a work day to feel thrilling and rejuvenating. This is not denial – I know that if I have a child, their summer will be markedly different from any that I knew. But I hope for all of us to know the pleasure of slow, early mornings, to walk through urbanised spaces and still be reinvigorated by jacarandas lining the streets. To know unfettered access to green, public spaces, and to be able to breathe, freely and deeply. Léa Antigny is a Sydney-based writer and publishing professional"
"The energy regulator has warned the operators of the UK’s electricity networks that it will cut investor returns in a push to keep a cap on household electricity bills. Ofgem says the networks will provide lower company returns in the next price control period, from 2023, and it will push them to invest more in building a carbon neutral energy system. The regulator’s drive to force networks to deliver more while making less comes after it admitted companies had been allowed to make “unjustified” returns for their owners to the detriment of household bills. Cathryn Scott, the acting head of networks at Ofgem, said the regulator’s “stable and predictable regulatory regime” would allow companies to attract the investment they needed to “go further in decarbonising the system whilst saving consumers money by keeping returns as low as possible”. Scott is filling the position on an interim basis after the previous head of networks, Jonathan Brearley, was promoted to become Ofgem’s chief executive from February next year. The regulator is under pressure to prove that it can fully support the UK’s 2050 climate targets after Britain’s biggest business group, the CBI, said the regulator was failing to prioritise the climate emergency and should be given new statutory duties by the government. The CBI said Ofgem must place the climate crisis at its core to ensure that it did not unintentionally undermine the UK’s green agenda. The calls have been echoed by major energy companies, green groups and the Committee on Climate Change. Ofgem says it will overhaul its regulatory approach to enable companies to meet new sources of demand on local grids, such as electric vehicles, and help energy users to manage their demand. It will also help companies to invest in anticipation of rising demand on the grid for car charging, even while this demand is uncertain. Earlier this year Keith Anderson, the chief executive of Scottish Power, accused Ofgem of hindering the rollout of electric vehicles by refusing to allow the company to invest an extra £42m in upgrading its networks in anticipation of an electric boom. He told the Guardian there was a “colossal disconnect” between the government’s policy of accelerating the uptake of electric vehicles and the regulator’s policy on supporting investment in charging. Ofgem said electricity networks would be “crucial” to help the UK to meet its climate targets as the energy system increasingly relies on renewables “to generate the electricity to power the country, our vehicles and potentially heat our homes too”. The regulator said it planned to impose “tough scrutiny” of energy firms’ plans. Ofgem made the warning just days after Labour’s plans to take energy networks back into public control were dashed by the Conservatives’ election victory. Earlier this week the regulator of the water industry – which was also included in Labour’s wide-ranging nationalisation agenda – handed water companies the toughest price controls since privatisation. • This article was amended on 18 December 2019. Due to an editing error, an earlier version referred to “energy suppliers” in the headline and text when “energy networks” was meant. This has been corrected."
nan
"Two volunteer firefighters have been killed and three have been taken to hospital with severe burns as the bushfire emergency raging across the east coast of Australia reached a new crisis point on Thursday. The two NSW Rural Fire Service volunteers were killed when a truck believed to have been travelling in convoy near the town of Buxton late on Thursday hit a tree and rolled off the road. The driver and front passenger died at the scene, police said, while three other firefighters were injured. The fatal accident occurred at the end of an exhausting day for firefighters in which it’s feared some 40 homes could have been lost in Buxton, Balmoral, Bargo and surrounds, as the Green Wattle Creek blaze tore through the Wollondilly Shire on Thursday. The NSW RFS officially says 20 homes may have been lost but there are reports 40 buildings were destroyed. “The Service’s thoughts are with all the firefighters’ family, friends and fellow brigade members,” the RFS said in a statement early on Friday. “This is an absolutely devastating event in what has already been an incredibly difficult day and fire season.” The premier, Gladys Berejiklian, said on Twitter the news was “devastating”, and NSW had “tragically lost two heroes”. Earlier on Thursday, three firefighters were treated for burns after their truck was enveloped by the bushfire. Two members of the crew, a 36-year-old man and a 56-year-old man, needed to be intubated to protect their breathing as they were airlifted from the scene with serious facial and airway burns. Fitzsimmons said the two men also suffered burns to their arms, elbow, upper chest and leg. A 28-year-old woman was also treated for smoke inhalation and superficial burns and was taken to hospital by road ambulance. Record temperatures and gusty, damaging winds combined with the prolonged drought crippling this part of the world to create what the commissioner of the Rural Fire Service, Shane Fitzsimmons, described as “volatile and erratic” conditions as more than 100 fires continued to burn across New South Wales. A day that began with Berejiklian declaring a second week-long state of emergency in a little over a month ended with Fitzsimmons telling media that three firefighters had been hospitalised after a crew of volunteers was “overrun” and “enveloped” by fire while trying to protect homes. Fitzsimmons, whose press conferences have become an increasingly common sight, appeared shaken as he described how the five-person crew had been overwhelmed as a fire burning to Sydney’s south-west changed from metre-high flames to a towering inferno in a matter of minutes. “I have had field reports from out there that very quickly they saw lots of fire activity, from metre-high flame heights to flames burning through the tops of trees [and] crowning fires, under very strong winds,” Fitzsimmons said. “It was very volatile, very dynamic and, unfortunately, emblematic of much of the fire behaviour we’ve seen, under the hot, dry, windy conditions.” It came amid a backdrop of growing anger at prime minister Scott Morrison’s handling of the bushfire emergency. Morrison has been criticised for his initial reluctance to link the worsening bushfire conditions with climate change, and more recently for his decision to take an overseas holiday in the midst of the crisis. In the tiny village of Itchenstoke in the state’s Blue Mountains the defence force was mobilised to rescue residents who became isolated when fire cut off the only road in and out of the town. Aerial footage from Bargo to the south-west of Sydney, where the three firefighters were overwhelmed, showed dozens of burning buildings and Fitzsimmons told reporters he feared dozens of properties had been lost to a separate fire burning to Sydney’s south-west. “We’ve got indications of quite a considerable amount of property being impacted,” he said. Fitzsimmons said he believed some of the homes lost belonged to firefighting volunteers. “They’re devastated by loss no matter what, but it just goes that little further when it’s your own home, or the colleague you’ve got sitting on the fire truck next to you, having lost their home, while they’re out saving others,” he said. “So it’s a tough afternoon. It will be another very emotional, very draining day for our firefighters.” As Sydney again woke to a now-familiar blanket of thick smoke on Thursday, hundreds of protesters gathered at the prime minister’s official residence, Kirribilli House, angry at his perceived lack of leadership. A NSW Greens MP, David Shoebridge, was arrested at the protest for refusing to obey a move on direction by police. But speaking after the protest the deputy prime minister, Michael McCormack, dismissed their concerns, telling protesters they were “wasting your time” and that the prime minister was “entitled to a holiday”. “Go and do something productive,” McCormack said to protesters. “Those people who are shouting and screaming … go and help someone out in need. Do a good turn rather than shouting and screaming and holding up placards that not always the words are spelt correctly on.” Before Thursday both Berejiklian and Fitzsimmons had warned that fire crews across the scorched state would again face an “enormous challenge” in the coming days during a fire season in which six people have already died and more than 750 properties have been destroyed. Australia’s all-time record average temperature has been broken twice already this week, with the more than 50 fires continuing to burn out of control across the state quickly fanned by temperatures exceeding 40C coupled with strong, gusting winds. Throughout Thursday four major fires stretching from the state’s south coast to the south-west of Sydney and the central coast reached “emergency” levels. One of those blazes, at Gospers Mountain on the state’s central coast, north of Sydney, has burned through more than 400,000 hectares already. And after a brief reprieve on Friday, conditions are expected to deteriorate further on Saturday. “The temperatures will be higher, and the wind turbulence more severe,” Berejiklian said. Fitzsimmons echoed that concern, saying strong winds from the west were expected for “10 to 15 hours”. “Saturday will be a very, very difficult day,” he said."
"Want to talk about the climate crisis with George Monbiot or discuss tumultuous recent political events with Polly Toynbee, Owen Jones or Marina Hyde? Or talk food and drink with Felicity Cloake, beauty with Sali Hughes, or movies with Peter Bradshaw? A team of Guardian and Observer journalists will be taking calls and donations at our annual charity telethon this Saturday. The cause is the climate emergency and we’re raising money for four charities that plant and protect trees, forests and woodlands.  The charities – Woodland Trust, Trees for Life, Trees for Cities and Global Greengrants Fund UK – promote environmental and social justice through natural climate solutions, from safeguarding the Amazon rainforest to rewilding parts of the Scottish Highlands to planting trees in Britain’s towns, cities and countryside. Readers have told us why they felt compelled to give this year: because the climate crisis is the most important issue affecting the planet, governments are failing to act and future generations must be safeguarded – and because they love trees. As one reader put it: “No trees. No future. No-brainer.” We’ve already raised more than £300,000, but we want to raise a lot more, and with your help, we can. You can call (+44) 0203-353 4368 between 10am and 6pm (GMT) on Saturday 21 December to make a donation by credit or debit card, and have a chat with our journalists. Others on hand to take calls include the Guardian’s editor-in-chief, Katharine Viner, political sketch writer John Crace, the columnists Gary Younge, Zoe Williams, Jonathan Freedland and Tim Dowling, and the daily podcast presenter, Anushka Asthana. If you don’t have time to call on Saturday, you can donate online here or send a cheque (payable to the Guardian and Observer charity appeal 2019) to: The Guardian and Observer charity appeal 2019, Charities Trust, Suite 20-22, Century Building, Tower Street, Liverpool, L3 4BJ."
"With reference to your report on the COP25 climate talks in Madrid (13 December), we have just returned from Madrid, where we displayed a large banner saying “War causes climate change and climate change causes war”. Thousands of passing delegates expressed a great interest in, and approval of, the message. Scientists for Global Responsibility estimates that 6% of global greenhouse gas emissions result from military-related activity – apart from the unfathomable human devastation – so at first sight it appears astonishing that the subject of war does not feature in the COP negotiations; nor are its emissions taken into account when reduction targets are set.  Perhaps this absence can be explained by the fact that military-related emissions have been excluded by some of the largest polluters from the global north whose delegates, as government officials, will naturally avoid jeopardising lucrative arms and military aid contracts, and whose people do not suffer the catastrophic wars and climatic devastation that directly affect the global south. Evidently we cannot rely on government negotiators to address the subject of war and militarism. We have to stop believing that war is inevitable and accept that international climate finance offers better value in both resolving conflict and sustaining the environment than the equivalent spent on military operations.Hilary Evans Movement for the Abolition of WarDavid Collins Veterans for Peace UK • I was delighted to see Greta Thunberg announced as Time magazine’s person of the year (Report, 12 December). For me, after so many years of campaigning on environmental issues, it has been a huge relief that now, in 2019, the future of the planet has finally entered the political mainstream – and not a moment too soon. This is thanks, in no small part, to the vision and actions of Greta herself, but also to those many others whom she has inspired to take up the fight. The world is realising the scale of the threat posed by every aspect of our destructive exploitation of our lovely planet. Now we need to see some real political leadership so that the leading nations of the world, our own included, can ensure a real revolution in practice, to match the fiery ambitions that have been lit up in our hearts by this inspirational Swedish teenager.Catherine RowettGreen party MEP, East of England • I’m writing in reference to your use of the term “global heating”. I understand the motivation is probably to draw attention to the fact that we are actively changing the climate, a laudable goal. However, the term should be used correctly. In an article about the disappointing results of the COP25 climate negotiations (Discord at climate talks branded a betrayal, 16 December) it was noted that: “Experts say more ambitious emissions cuts are needed globally if the Paris pledge to hold global heating to no more than 2C is to be met.” However, heating involves a change in energy and is measured in joules. Warming, on the other hand, is a change in temperature and is measured in degrees celsius. So “global warming” would have been more apt here. I know that climate change deniers, some of whom have some knowledge of physics, keep a lookout for inconsistencies like this. Better not to give them any extra ammunition. Keep up the good environmental reporting – I’m a fan.Prof Joe LaCasceUniversity of Oslo • This article was amended on 17 December 2019 to add David Collins as a co-signatory to Hilary Evans’ letter. His name had been omitted due to an editing error. • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"
Share this...FacebookTwitter
Source: http://www.woodfortrees.org/plot/rss/from:2015.4/to:2017.1/plot/rss/from:2015.4/to:2017.1/trend
“Climate models are unable to predict extreme events because they lack spatial and temporal resolution. In addition, there is no clear evidence that sustained or worldwide changes in extreme events have occurred in the past few decades.”    —- IPCC AR4 (2007) Section 8.3.9.3  Page 232


According to no less of an authority than the UN Intergovernmental Panel on Climate Change (IPCC), there is a significant lack of evidence connecting anthropogenic global warming to changes in the frequencies or intensities of extreme weather events (such as storms, hurricanes, droughts, floods, and tornadoes).   In Chapter 2 of the most recent IPCC report (AR5, 2013), for example, we find these (7) conclusions affirming the the lack of clear observational evidence linking extreme weather events to human activity.

IPCC AR5, Chapter 2:
1. “Current datasets indicate no significant observed trends in global tropical cyclone frequency over the past century”
2. “No robust trends in annual numbers of tropical storms, hurricanes and major hurricanes counts have been identified over the past 100 years”
3. “In summary, there continues to be a lack of evidence and thus low confidence regarding the sign of trend in the magnitude and/or frequency of floods on a global scale”
4. “The statement about the absence of trends in impacts attributable to natural or anthropogenic climate change holds for tropical and extratropical storms and tornados”
5. “In summary, there is low confidence in observed trends in small-scale severe weather phenomena such as hail and thunderstorms”
6. “In summary, the current assessment concludes that there is not enough evidence at present to suggest more than low confidence in a global-scale observed trend in drought or dryness (lack of rainfall) since the middle of the 20th century.”
7. “In summary, confidence in large scale changes in the intensity of extreme extratropical cyclones since 1900 is low”

The IPCC conclusions summarized above are supported by references from the peer-reviewed scientific literature extending through 2013. Since the 5th IPCC report was released 3 years ago, many more scientific papers have been published that also endorse the position that there is not an established link between increases in the frequency or intensity of extreme weather events and anthropogenic climate change.  For example:

van der Wiel et al., 2016       “[N]o evidence was found for changes in extreme precipitation attributable to climate change in the available observed record.”
Boos and Sterelvmo, 2016       “Thus, neither a physically correct theoretical model nor a comprehensive climate model support the idea that seasonal mean monsoons will undergo abrupt, nonlinear shifts in response to changes in greenhouse gas concentrations, aerosol emissions, or land surface albedo.”
Guo et al., 2016       “[T]he combined spatial-temporal variability of U.S. tornado occurrence has remained nearly constant since 1950.”
Chang et al., 2016       “With increasing greenhouse gases, enhanced high-latitude warming will lead to weaker cyclone activity. Here we show that between 1979 and 2014, the number of strong cyclones in Northern Hemisphere in summer has decreased at a rate of 4% per decade.”
Chen et al., 2017       “[T]here is a close linkage between the weakening of cyclonic activity after the early 1990s and the nonuniform surface warming of the Eurasian continent.”
Sugi et al., 2015       “Recent review papers reported that many high-resolution global climate models consistently projected a reduction of global tropical cyclone (TC) frequency in a future warmer climate.”
Chenoweth and Divine, 2014       “Our results suggest that nineteenth century [tropical cyclone] frequency is comparable to that for the same area during the entire satellite era from 1965–2012.”
Cheng et al., 2016       “The results thus indicate that the net effect of climate change has made agricultural drought less likely and that the current severe impacts of drought on California’s agriculture have not been substantially caused by long-term climate changes.”
Hoerling et al, 2016       “[A]ppreciable 35-yr trends in heavy daily precipitation can occur in the absence of forcing, thereby limiting detection of the weak anthropogenic influence at regional scales.”
Kundzewicz et al., 2014       “It has not been possible to attribute rain-generated peak streamflow trends [floods] to anthropogenic climate change over the past several decades. … [P]resently we have only low confidence in numerical projections of changes in flood magnitude or frequency resulting from climate change.”
Benito et al., 2015       “[I]n most cases present flood magnitudes are not unusual within the context of the last millennium … [T]he frequency of extreme floods has decreased since the 1950s“
Delworth et al., 2015       “In our simulations the tropical wind anomalies account for 92% of the simulated North American drought during the recent decade, with 8% from anthropogenic radiative forcing changes. This suggests that anthropogenic radiative forcing is not the dominant driver of the current drought“
McCabe and Wolock, 2015       “[F]or the past century %drought has not changed, even though global PET [potential evapotranspiration] and temperature (T) have increased.”
van Wijngaarden and Syd, 2015       “Changes in annual precipitation over the Earth’s land mass [through 2013]… The trends for precipitation change together with their 95% confidence intervals were found for various periods of time. Most trends exhibited no clear precipitation change. … A change of 1% per century corresponds to a precipitation change of 0.09. mm/year.”
Cai et al., 2014       “Recent drought in 1993–2008 was still within the frame of natural climate variability based on the 306 yr PDSI reconstruction.”
Doerr and Santín, 2016       “[M]any consider wildfire as an accelerating problem, with widely held perceptions both in the media and scientific papers of increasing fire occurrence, severity and resulting losses. However, important exceptions aside, the quantitative evidence available does not support these perceived overall trends. Instead, global area burned appears to have overall declined over past decades, and there is increasing evidence that there is less fire in the global landscape today than centuries ago.”

So although the science — indeed, the IPCC — is rather clear in documenting the lack of evidence affirming the anthropogenic global warming/extreme weather link, just about every day we are nonetheless barraged with claims that human-caused droughts will destroy all 888 million trees in the US Southwest by 2100, that we humans are causing “weather whiplash” with our CO2 emissions, or that this past year we humans caused eight 500- or 1000-year floods.    In other words, when it comes to advocating for the anthropogenic global warming cause, the observations and evidence contradicting the narrative that says humans have caused more frequent and severe floods, droughts, hurricanes, storms, tornadoes . . . is largely ignored.
Just as the leading temperature graph above illustrates, a warm temperature anomaly is, according to an alleged “consensus” of climate scientists, caused by humans, not natural factors (i.e., the 2015-’16 Super El Niño event).  A cooling temperature anomaly, on the other hand, is just called “natural variability.”   No need to substantively support this “explanation” of human vs. natural attribution with actual scientific evidence.   It is enough just to claim it is so.
Likewise, when severe drought conditions parch the US Southwest — or, as of today, “catastrophic flooding” deluges the very same region — all that needs to be reiterated is that we humans double drought frequencies and triple flood frequencies with our CO2 emissions — regardless of whether this reiteration is supported by observational evidence.  (It is not.)  This way, catastrophic floods and devastating droughts which occur at the same time and in the same place can be said to be human-caused, and each single event can necessarily be claimed to have been driven by anthropogenic climate change.  Those who question (or deny) the “truth” of these human attribution pronouncements deserve to be marginalized as “climate deniers” and “anti-science.”  This seems to be how modern-day “climate science” works.

A Wake-Up-Call Scientific Paper
Perhaps no paper found in a reputable journal (American Meteorological Society’s Weather, Climate, and Society) has been as openly critical of the narrative “science” of extreme weather human attribution as the one just published by University of Manchester’s Janković and Shultz (2017).   The authors pull no punches in boldly asserting that the brand of human attribution science as currently practiced by climate activists such as Michael Mann and Michael Oppenheimer “contradicts the scientific evidence“ and engenders a “massive oversimplification” or even “misstatement” of the “true state of the science.”  They further question the claims that a pre-industrial or “below 350 ppm [carbon dioxide]” climate is necessarily more benign or less affected by extreme weather, and they warn that “unachievable” CO2 emissions reduction policies are at risk of being classified as “ill advised, ineffective, and disingenuous” if and/or when the public eventually recognizes how flimsy the evidence is upon which these policies are based.
Janković and Shultz even dare to reference the late Dr. Stephen Schneider’s heartfelt rationalization for climate change advocacy by invoking his stated position that climate scientists must necessarily “offer up scary scenarios, make simplified, dramatic statements, and make little mention of any doubts we might have” so as to “capture the public’s imagination” by “getting loads of media coverage” as a means to advance the cause.  This, of course, is not science.  It is political activism.  Unfortunately, this is all too often the direction that modern “climate science” has been headed in recent years.
What follows are selected excerpts (all direct quotes) from the Janković and Shultz (2017) paper entitled, “Atmosfear: Communicating the Effects of Climate Change on Extreme Weather“.   Considering there were  500 papers supporting a skeptical position on global warming alarm published in scientific journals during 2016, perhaps the publication of wake-up-call, borderline-iconoclastic scientific papers such as this will become more and more commonplace in the near future.  For the sake of salvaging at least some credibility for what has come to be known as modern-day “climate science,” one can only hope.

Janković and Shultz (2017)
‘”[C]limate Change Means More Extreme Weather” Is A Massive Oversimplification—If Not Misstatement—Of The True State Of The Science’
In 2011, the nonprofit science and outreach organization Climate Communication—whose staff and science advisors include, among others, Richard Sommerville, Jerry Melillo, Ken Kaldeira, Kerry Emanuel, Michael Mann, and Michael Oppenheimer—issued the following statement:
“As the climate has warmed, some types of extreme weather have become more frequent and severe in recent decades, with increases in extreme heat, intense precipitation, and drought. …  All weather events are now influenced by climate change because all weather now develops in a different environment than before.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Yet, this statement, as well as numerous others in the popular literature and media stories, contradicts the scientific evidence.
[R]educing the complexity of climate change (as if a single outcome were known) into the soundbite of “climate change means more extreme weather” is a massive oversimplification—if not misstatement—of the true state of the science.
–
‘Policy Based On Attribution Claims … Run The Risk Of Being Ill Advised, Ineffective, And Disingenuous’
[A] preindustrial climate may remain a policy goal, but it is unachievable in reality.  … [A]ttribution science appears to have a unique potential to boost motivation for climate action because of its appeal to responsibility to prevent socioenvironmental impacts of the anthropogenically charged atmosphere…. [S]ome commentators resort to the language of human rights, government’s malfeasance, and corporate liability. …  [A]ttribution claims allow policy-makers to put forward a case for morally robust policies based on mitigation of greenhouse emissions. Weather extremes are proxies of climate crisis, dismantling the climate complexity into the simpler and more visible conventional idiom of atmospheric hazard. …  It is assumed that a new postanthropogenic atmosphere will be graced by a more benign weather than the anthropogenic one preceding it. … [I]t remains to be determined whether such [CO2 emission reduction] plans ought to be legitimized by a presumed rise in future weather extremes and whether a successful implementation of such plans would result in a demonstrable reduction of socioeconomic damages caused by supercharged weather. If neither of these results is justified, a policy based on attribution claims (and [fear]) runs the risk of being ill advised, ineffective, and disingenuous. 
–
‘Climate Change Is Not Manageable By A Policy Based On A Mere Scientific Consensus’
Scientists and policy-makers sometimes refer to the status of the unadulterated climate by the preindustrial levels of carbon dioxide, under the assumption that staying below 350 ppm would entail a climatically safer world characterized, among other things, by a decrease of anthropogenically driven extremes. Does a world under the 350-ppm limit (or any other limit) automatically translate into one characterized by a more favorable climate? …  Reducing carbon emissions, regardless of how effective, cannot of itself reduce weather impacts (e.g., Schultz and Janković 2014). …  Climate change is not a discrete problem independent of development imperatives, nor is it manageable by a policy based on a mere scientific consensus (Prins et al. 2010). [E]ven if anthropogenic climate change were effectively stopped, extreme weather would continue. Members of the public and governmental representatives who had been sold on the idea that “stopping climate change will reduce extreme weather events” would understandably question their bill of goods, reducing scientific credibility.
–
‘Uncritical Attribution Claims … Bolstered By The Cultural And Media Propensity For Hyping Extreme Events’
We believe that the weatherward rather than landward attention results in part from an uncritical adoption of attribution claims that, in turn, shape the perception of climate change as a long-term weirding of weather, bolstered by the cultural and media propensity for hyping extreme events (Leyda and Negra 2015). Attribution claims and atmosfear have helped to consolidate the representation of climate change as a material threat with origins in an adulterated atmosphere, safety from which must be sought in tackling that threat. As a result, in popular parlance, climate change is often represented as a carbon-driven entity (or agency) endowed with a causal power that alters social life and the natural environment (Fleming and Janković 2011; Hulme 2015).
With such events seemingly outside the expected natural range of possibilities, the media increasingly turned to blaming climate change for the severe weather (e.g., Janković 2006; Hulme 2014).
“The good cause—one that most of us support—can all too readily corrupt the conduct of science, especially science informing public policy, because we prefer answers that support our political preferences, and find science that challenges them less comfortable” (Kellow 2008).
In 1989, Stephen Schneider, one of the leading twentieth-century climate scientists, summarized the need for this particular form of scientific-cum-moral double engagement to Discover magazine.
“[W]e [scientists] are […] working to reduce the risk of potentially disastrous climate change. To do that we need to get some broad based support, to capture the public’s imagination. That, of course, means getting loads of media coverage. So we [scientists] have to offer up scary scenarios, make simplified, dramatic statements, and make little mention of any doubts we might have.”
Share this...FacebookTwitter "
"There’s a buzz in the air at the moment, and it’s all about “entomophagy”. If you’ve not heard this word before, it simply means the human practice of eating insects. Western governments are keen as it has huge potential for feeding growing numbers of people (and the livestock they eat) sustainably, while on the street people are daring to try novel and exotic foods. Despite the exotic label, entomophagy is nothing new. Two billion people eat insects every day, just not in the West. In fact, insects are extremely good for you and eating them is good for the planet too. That’s why Andy Holcroft and I are starting up Grub Kitchen, the UK’s first restaurant with insects on the menu full-time.  We want to champion insects as a sustainable source of protein in modern diets and have been planning the collaboration for some years. I’m a scientist and farmer, researching sustainable food production and the importance of insects in agriculture. In 2013, I set up Dr Beynon’s Bug Farm, a research and education centre and 100-acre working farm, combined with a visitor attraction all about insects and sustainable agriculture. Andy is an award-winning chef, who has become more and more disillusioned with the unsustainability of conventional restaurants. Working together gives us the opportunity to explore the food chain from field to fork. But why try changing people’s eating habits? By 2050 humans will require 70% more food, 120% more water and 42% more crop land. Meat production is predicted to double and, to meet current environmental targets, impacts of livestock on the environment will need to halve. Conventional livestock production is land and water thirsty: farmed animals graze 30% of the earth’s land and consume 8% of all water usage mediated by humans. This comes at a drastic cost to our environment and is why we need additional, or alternative, protein sources with lower environmental costs. Bring on the insects. A recent Food and Agriculture Organisation report suggested that there are more than 1,000 known species of edible insect, offering an Aladdin’s Cave of flavours and textures. Insects breed quickly and require very little space, or water. This makes farming them extremely efficient. For example, it takes about 3,290 litres of water to produce a 150g beef burger: the equivalent insect burger requires less than a pint. Insects are also extremely nutritious. They contain lots of calcium, zinc, and omega-3 fatty acids and are low in cholesterol. They’re also packed full of protein. Weight for weight, crickets can contain more protein than beef and are 12 to 25 times more efficient in converting their feed into food for us. Some insects such as black flies can even convert our own waste into food, or at least into feed for farmed animals. Indeed, feeding insects to livestock may be a first step to incorporating them into the UK food chain. Using insects to feed chickens, pigs and fish is one thing, but convincing the British public to try them will be more challenging. At Grub Kitchen, we want to move away from the idea of eating insects as novelty items, or as a dare, as popularised by certain television programmes. Diners will be able to eat insects in all forms, from an insect taster plate to our signature bug burgers or cricket cookies. There will be whole insects on the menu, but many people will be put off by the various legs, antennae and eyes so we will offer options where insects are incorporated into dishes: ground up and used as flour or burger mince.  Though the industry is growing there are still several barriers to mass production. Currently the UK allows you to farm insects for human consumption. However, insects are categorised as “farmed animals”, which means we can’t slaughter them where they are reared. Parts of insects, such as legs or wings, are considered novel foods and so undergo stringent safety testing but we can use whole insects in food so long as we carry out “due diligence”. We’re also banned from feeding insects to livestock entering the human food chain.  It’s clear we still have a lot to learn. We’re still not sure whether humans have the correct gut microflora to make the most of insect protein, for instance, and we need to find out more about potential allergies. For now, if you’re allergic to house dust mites or shellfish then it’s best to avoid eating insects – but this isn’t yet based on much research. In the UK, we’re awaiting a decision as to whether the Food Standards Agency counts insects as “novel food”; a decision which will impact the entire industry. If the agency agrees that there is enough evidence that insects were eaten before 1997 then the food will be subject to fewer regulations. So, brace yourselves, you may be seeing insects on the supermarket shelves before long and you’re welcome to come and dine at Grub Kitchen later in the year. However, even if you don’t think that you want to veer into the world of entomophagy, I’m afraid I’ve got news for you: you already are. You may be eating up to 60 fragments of insects in every 100g of chocolate and whenever you eat a fig, you are eating remnants of a fig wasp."
"
Share this...FacebookTwitterThe sun in March 2017
By Frank Bosse and Prof. Fritz Vahrenholt
(Translated/edited by P. Gosselin)
Our source of energy continued to be especially quiet last month. The mean sunspot number (SSN) was 17.7 and the sun was completely blank for 16 days.
It is important to recall once again that the SSN is not simply the sum of the observed sunspots, rather it is generated by the number of spots multiplied by the 10-fold of the observed sunspot regions. When one single spot is observed in an active region, this yields an SSN of 11.
The mean SSN for all cycles recorded so far, up to month 100 into the cycle, is 48.6, which means that the current cycle has seen a solar activity that is only 36% of the mean. It’s a weak cycle.

Fig. 1: The current solar cycle (SC) 24 is shown in red and is compared to the mean of the previous 23 cycles (blue) and the similar SC 5 (black).
What follows is a comparison of all cycles observed thus far:

Fig. 2: The accumulated sunspot anomaly between each cycle and the mean (depicted in blue in Figure 1). 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




As the chart above shows, the current cycle is the 3rd quietest overall since observations began in the 17th century. Overall only SC 5 and 6 (Dalton-Minimum) were quieter (so far). What is especially remarkable is that the 75 – 100 month period of the current cycle is the quietest of the such ever.
A real drop off in activity
Compared to the 1930 – 2000 period, the current cycle in fact represents a real drop off in activity. If we smooth the curve over 4 cycles, this is what activity looks like since systematic sunspot observations began:

Fig. 3: 44-year smoothed sunspot curve using Loess filter 44 SIDC (orange) and the mean value since 1700 (brown). In amplitude and time period, the 1930-2000 years were the most active of the past 300 years. The current drop-off has a strong similarity to that seen during the Dalton period. 
We are of course keeping an eye on the solar polar fields. At this point into the cycle, its strength is an indicator of the activity may be in the upcoming SC 25. Since December not much has changed, and so we will continue to stick to our prognoses from last month: The coming cycle will be approximately 1/3 weaker than the current SC 24.
The next few billion years
Over large timescales, the sun’s thermonuclear furnace strengthens at its core as the sun ages. The “solar constant” is currently ca. 1362 W/m², but is in fact not constant because it is increasing. There are a number of publications about this, and one recent study has come to the following result: Over the next 1.3 billion or so years, it is gradually going to get warmer as the sun will gain about 12% more strength compared to today. For the climate system that will result in about 41 W/m² in effective greater forcing (compared that to about 3.8 W/m² for a doubling of CO2, according to scientific literature). This will lead to a new modus for the earth’s climate, as temperatures will rise about 20°C. Naturally this is nothing to worry about, as by then we’ll be long gone.
That of course will not mean the end of life on earth as water will continue to exist and the earth will stabilize at its new plateau. And as the sun gains another 10% in strength, water will rapidly be lost into space. That will be the case in about 2.1 billion years. Later after that life as we know it will cease to exist on earth. And another 4 billion years later the sun will engulf the parched earth as it expands into a red giant.
But as far as we are concerned today, there is no need for pessimism! And don’t forget: there will continue to be an ice age every 100,000 or so years – just as this has been the case over the recent geological past (2 million years). And even if man should succeed in doubling the atmospheric CO2 concentration, the earth will not turn into Venus. For that an additional forcing of 72W/m² would be necessary.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
Climate Model Errors = 20 W m-2
CO2 Climate Forcing = 0.2 W m-2



Scott Pruitt, the new head of the U.S. Environmental Protection Agency, has recently been characterized as a climate science “denialist” by world news organizations.   A UK Guardian headline, for example, has claimed that “EPA head Scott Pruitt denies that carbon dioxide causes global warming“.  
The “denialist” characterization stems from an interview with CNBC’s Joe Kernen in which Pruitt was asked whether he believes that CO2 has been proven to be the climate’s “control knob”.  Pruitt replied that “we don’t know that yet” and that “there’s tremendous disagreement about the degree of impact.”  But he also said, no, he doesn’t think CO2 is a primary contributor to climate change.  Apparently that is all it takes to unleash the climate “denialist” name-calling.
Scott Pruit:   “No. I think that measuring with precision human activity on the climate is something very challenging to do, and there’s tremendous disagreement about the degree of impact.  So no, I would not agree that it’s a primary contributor to the global warming that we see. But we don’t know that yet. … We need to continue the debate and continue the review and the analysis.”
In a Washington Post analysis of Pruitt’s comments entitled “EPA Chief’s Climate Change Denial Easily Refuted…”, the host’s reply to Pruitt’s last statement about the need to continue debating the degree of human impact was included:
“That’s the whole point of science. You keep asking questions.”
Responding to this rather fundamental point, Washington Post political journalist Philip Bump seemingly agreed with the need to keep questioning and debating the science (since that is indeed the “whole point of science”).  But then he immediately contradicted himself.
“Well, sure. But the point of science is also to accept the answers to those questions once determined. And in the scientific community, the answer to the question of the link between greenhouse gases and warming has been determined.”
So apparently because it “has been determined” that CO2 causes warming or cooling when increased or decreased, therefore we should not question the degree to which the climate models accurately record the effect of increasing or decreasing CO2, or how much warming or cooling is caused by CO2 fluctuations relative to other climate-forcing factors.
And why should we refrain from asking questions about the relative influence of CO2 forcing on the climate?  Because those questions have not been determined…or answered.  Not even close.  After all, the uncertainty and error margins associated with modeling the radiative energy changes in the Earth system are 10 to 100 times  greater than the entirety of the forcing attributed to CO2 changes.

1. CO2 Radiative Forcing Effect Just 0.2 W m-2 For 2000-2010

As the Intergovernmental Panel on Climate Change (IPCC) has indicated, “global climate is determined by the radiation balance of the planet.”  If the balance in the radiative energy budget (incoming vs. outgoing energy) tips positive (as expressed in Watts per square meter, or W m-2), warming occurs.  If it dips negative, cooling occurs.  The IPCC presumes that positive energy balances have been ongoing for decades, driven almost exclusively by the increase in anthropogenic CO2 emissions.
According to climate models, the total climate forcing effect of the roughly 120 parts per million (ppm) increase in atmospheric CO2 during the ~165 years since 1750 is 1.8 W m-2.
As assessed in a 2015 paper published in the journal Nature, the CO2 concentration increased by 22 ppm during the first 10 years of the 21st century.  The radiative forcing (warming) effect of this 22 ppm CO2 increase was modeled to be 0.2 W m-2.  So of the 1.8 W m-2 of total radiative forcing since 1750, 0.2 W m-2 was added during the first decade of this century.

Feldman et al., 2015 

2. The Radiative Energy Imbalance For 2000-’10 Was 0.6 W m-2

In a 2012 Nature Geoscience paper entitled “An update on Earth’s energy balance in light of the latest global observations” by Stephens et al. (2012), the radiative energy imbalance for the 2000-2010 decade was determined to be positive, as expected.  Interestingly, though, the positive energy balance of 0.6 W m-2 was 3 times larger than the forcing value (0.2 W m-2) attributed to the CO2 increase during the same period.

Stephens et al., 2012
“The current revised depiction of the global annual mean energy balance for the decade 2000–2010 is provided … For the decade considered [2000-2010], the average imbalance is 0.6 Wm–2 when these TOA fluxes are constrained to the best estimate ocean heat content (OHC) observations since 2005.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






3. 67% (0.4 W m-2) Of The 2000-’10 Energy Increase Not From CO2

If the imbalance in the energy budget was 0.6 W m-2 during 2000-2010, and the modeled CO2 radiative forcing estimate was 0.2 W m-2 during the same period, that means that there was a positive forcing of 0.4 W m-2 that was not due to the increase in CO2 concentration.  What this indicates is that the IPCC’s conclusion that all or nearly all of recent global warming is due to the increase in anthropogenic CO2 emissions is not supported by the surface energy imbalance estimates.  Two-thirds of climate forcing must be due to some unknown mechanism or mechanisms that the IPCC has somehow failed to identify in etiological analyses.  And if only 33% of recent climate forcing is anthropogenic, and 67% cannot be accounted for, where does the certainty that humans are driving climate change come from?

4. Energy Change Uncertainty 10-100 Times Larger Than CO2 Forcing

Speaking of certainty — or, more appropriately, uncertainty — in climate forcing or energy imbalance values, Stephens and colleagues emphasize the requisite uncertainty in the estimates of the energy imbalance for 2000-2010: an enormous ±17 W m-2.
A 17 W m-2 uncertainty range in the energy balance estimate (0.6 W m-2) means that the actual energy balance could be anywhere from -16.4 W m-2 to +17.6 W m-2.   This range of uncertainty effectively renders the 0.2 W m-2 CO2 forcing estimate meaningless, as the uncertainty in the volume of energy change during 2000-2010 is 85 times greater than the forcing attributed to CO2 for the same period.

Stephens et al., 2012
“This small imbalance [0.6 W m-2] is over two orders of magnitude [100 times] smaller than the individual components that define it and smaller than the error of each individual flux.”
“The net energy balance is the sum of individual fluxes. The current uncertainty in this net surface energy balance is large, and amounts to approximately 17 Wm–2.  This uncertainty is an order of magnitude [10 times] larger than the changes to the net surface fluxes associated with increasing greenhouse gases in the atmosphere.”
“The quoted value of the sensible heat flux is a combination of the land and ocean sensible heat fluxes  with a simple weighting based on land/ocean surface area. The flux value of 24 Wm–2 is also larger than previously assumed and remains highly uncertain, as exemplified by the range of 14–34 Wm–2 that results from different land flux estimates. No definitive measure of the uncertainty of this flux exists and the uncertainty range given merely reflects a judgement on where the value most likely lies.”

Even the IPCC acknowledges that the uncertainty in heat flux estimates reaches up to 20 W m-2, and that this uncertainty dwarfs the less than 2 W m-2 of total radiative forcing attributed to anthropogenic CO2 emissions during the last few centuries.

IPCC AR4 (2007)
“Unfortunately, the total surface heat and water fluxes are not well observed. Normally, they are inferred from observations of other fields, such as surface temperature and winds. Consequently, the uncertainty in the observational estimate is large – of the order of tens of watts per square metre [20 W m-2] for the heat flux, even in the zonal mean.”

IPCC AR5 (2013)
“The overall uncertainty of the annually averaged global ocean mean for each term is expected to be in the range 10 to 20%. In the case of the latent heat flux term, this corresponds to an uncertainty of up to 20 W m–2. In comparison, changes in global mean values of individual heat flux components expected as a result of anthropogenic climate change since 1900 are at the level of <2 W m–2  (Pierce et al., 2006).”

Frank, 2008
“It turns out that uncertainties in the energetic responses of Earth climate systems are more than 10 times larger than the entire energetic effect of increased CO2.”

5. IPCC Hides Uncertainty, Errors In Radiative Energy Change

Advocates of the position that CO2 is the climate’s “control knob” would like to divert attention away from the uncertainties and errors in climate modeling, of course.  Likewise, the IPCC has notoriously buried data that might cast doubt on the “consensus” position (which states that most climate changes have been driven by anthropogenic CO2 emissions since the mid-20th century).
To find the uncertainty and error ranges in the climate model estimates of radiative forcing, one must deliberately set out to locate the esoteric “Supplemental Material” documents from each report.  The IPCC would not dare publish estimates of massive climate modeling errors and uncertainty in locations where they are most likely to be viewed.

Frank, 2008
“One must go into Chapter 8 and especially Ch 8 Supplementary Material in the recently released IPCC AR4 to find GCM [General Circulation Model] errors graphically displayed in W m-2. Such forthright displays [of error/uncertainty, as shown in the graphs below] do not appear in the SPM [Summary for Policy Makers] or in the Technical Summary; i.e., where public bodies are more likely to see them.“
Supplementary Material from Chapter 8, IPCC AR4
“Figure S8.5 shows that GCM errors in ‘mean shortwave radiation reflected to space’ range across 25 W m-2.”


“The errors in outgoing longwave radiation, Figure S8.7, are similarly large [~20 W m-2]…”


6. ‘From Where Comes The Certainty Of A Large CO2 Impact On Climate?’

So if the models are so hopelessly riddled with errors and uncertainty that an anthropogenic radiative forcing signal cannot be distinguished from noise, or if the total magnitude of the warming attributed to humans is one-tenth to one-hundredth of the error or uncertainty ranges, why are those who dare question the degree to which humans affect the Earth’s climate branded as “deniers” of science?
Exactly what is the truth that climate “deniers” are actually denying?
“If the uncertainty is larger than the effect, the effect itself becomes moot. If the effect itself is debatable, then what is the IPCC talking about? And from where comes the certainty of a large CO2 impact on climate?“                                                   –Dr. Patrick Frank, “A Climate of Belief“
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNote: Due to the very positive feedback of this post, I’ve decided to leave it up at the top spot for another day. -PG
==============================================

In 1981, James Hansen was the Director of the NASA Goddard Institute for Space Studies.  He was also the lead author of a seminal paper published in the prestigious journal Science entitled “Climate Impact of Increasing Atmospheric Carbon Dioxide“.  In the paper, Hansen and his colleagues reported (and illustrated with multiple graphs) the widely accepted 100-year (~1880-1980) record of hemispheric and global temperature changes.  At the time, most climate scientists were reporting that the Northern Hemisphere’s (NH) temperatures had undergone a rapid warming of between +0.8 and +1.0°C between the 1880s and 1940.  Then, after 1940 and through 1970, NH temperatures were reported to have dropped by about -0.5 to -0.6°C, a decades-long cooling trend which at the time had fomented widespread debate about global cooling in the scientific community.
Like their peers, NASA’s Hansen and his co-authors indicated that the Northern Hemisphere had warmed by ~0.8°C between the 1880s and 1940, and then cooled by ~0.5°C between 1940 and 1970.

A graph of “observed temperature” for the Northern Hemisphere was included in the paper to illustrate these climatic trends.

Today, NASA’s Goddard Institute for Space Studies is directed by Dr. Gavin Schmidt, a trained mathematician.  (James Hansen retired from the position in 2013.)   Schmidt’s version of the Northern Hemisphere’s temperature record for 1880-1980 looks vastly different than what his predecessor had illustrated in 1981.  Instead of leaving the historically observed temperatures alone, NASA has invented new ways to portray the pre-1981 temperature history of the Northern Hemisphere.
2017 NASA Hemispheric Graph

To subjectively summarize the wholesale adjustments to past temperature data, the +0.8°C warming between 1880 and 1940 has been reduced to +0.35°C.  The -0.5°C cooling between 1940 and 1970 has been reduced to -0.2°C.  And in NASA’s 2017 version of Northern Hemisphere temperatures, 1980 is now even with 1940.  Neither year was warmer than the other.  In the original 1981 NASA graph, however, 1980 was -0.3°C colder than 1940.

If the originally recorded observations for the Northern Hemisphere had not been erased from the temperature record, the pre-1981 trend would look like it does in the graph below (black trend line).  In other words, if the temperature observations as they appeared in 1981 had not been tampered with, it would be clear the Northern Hemisphere’s surface temperatures have undergone an oscillation, or warming-cooling-warming cycle, with no significant net change from the earlier warming amplitude or rate (1880-1940) to the more recent one (1980s-present).

Why Did NASA Eliminate The Early 20th Century Warming And Mid-20th Century Cooling?
The fundamental reason why NASA has manipulated past temperature data is so that the historical climate record may conform to the IPCC models that presume variations in surface temperatures are predominantly determined by anthropogenic CO2 emissions.  Fossil fuels consumption in particular and anthropogenic CO2 emissions in general plodded along steadily at about 1 GtC/year (gigatons of carbon per year) during the 1900 to 1945 period.  Then, after 1945, human emissions exploded.  They reached 4 GtC/year by the 1970s, 6 GtC/year by the 1990s, and 10 GtC/year by 2014.

NASA recognized that (a) anthropogenic CO2 emissions were not rising much at all while the surface temperatures were rising dramatically (1880s-1940s), and that (b) surface temperatures were cooling (1940s to 1970s) while anthropogenic CO2 emissions were surging upwards.  These observed trends did not support climate modeling; instead, they undermined the models.  So, to counteract this, NASA has undergone a decades-long effort to change past temperature data that do not adhere to modeled expectations.  In other words, NASA has sought to suppress the 1880s to 1940 warming amplitude and rate, and they have warmed up the 3 decades of NH cooling by about +0.3°C.  In this way, the overall 1880s-present trend will look linear rather than oscillatory, and it will also look more and more like the trends in anthropogenic CO2 emissions (above graph).   When the facts don’t fit the models, NASA apparently changes the facts.
Non-Adjusted Temperature Data Appear To Correlate With 20th Century Solar Forcing
In a paper just published in the journal New Astronomy, scientists Yndestad and Solheim (2017) have released a reconstruction of solar activity (Total Solar Irradiance, or TSI) for 1700-2013.  As explained here, the 20th Century contained the so-called Modern Grand Maximum of very high solar activity.

Taking a closer look at the 20th Century solar irradiance trend only, the (a) rapid rise in TSI for 1900-1950, the (b) dramatic drop in TSI during the 1950s to 1970s, and then the (c) abrupt 1980s to early 2000s increase in TSI all seem to correspond generally to the non-adjusted temperature trend for the Northern Hemisphere — prior to the NASA temperature data manipulation.


In fact, many other recently published surface temperature reconstructions indicate that the warming-cooling-warming oscillatory 20th Century trend may correlate with this solar forcing trajectory.
Rydval et al. (2017), for example, include several graphs of surface temperatures for Northern Hemisphere locations that show warming and cooling periods largely correspond to multi-decadal- and centennial-scale records of high (warming) and low (cooling) solar activity.  In the NH graphs below, for example, notice how the temperature records follow a similar track that correspond with the non-adjusted (pre-1981) NASA temperature record: (a) rapid warming from around 1900 to the mid-20th Century, (b) rapid cooling for a few decades, and then (c) another warming ascent from about the 1970s or 1980s onward.  Also notice that the mid-20th Century peak warmth is not significantly different than the warmth achieved in the last decade or two, again affirming an oscillatory pattern rather than a linear one.

Rydval et al., 2017
“[T]he recent summer-time warming in Scotland is likely not unique when compared to multi-decadal warm periods observed in the 1300s, 1500s, and 1730s … [E]xtreme cold (and warm) years observed in NCAIRN appear more related to internal forcing of the summer North Atlantic Oscillation. … There is reasonable agreement in general between the records regarding protracted cold periods which occur during the LIA and specifically around the Maunder solar minimum centred on the second half of the seventeenth century and to some extent also around the latter part of the fifteenth century coinciding with part of the Spörer minimum (Usoskin et al. 2007).”








<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Temperature records for many other regions within the Northern Hemisphere (as well as several from the Southern Hemisphere) may also align with the original (non-adjusted) NASA temperature observations and recent reconstructions of TSI.   So as not to cross the threshold of excessiveness, only a small portion of the many similarly correlative warming-cooling-warming temperature reconstructions available are included below.

Yamanouchi, 2011 (Arctic)

Box et al., 2009  (Greenland Ice Sheet)

Hasholt et al., 2016  (Southeast Greenland)
“We determined that temperatures for the ablation measurement periods in late July to early September were similar in both 1933 and the recent period [1990s – present], indicating that the temperature forcing of ablation within the early warm period and the present are similar.”

Kobashi et al., 2011  (Greenland Ice Sheet)

Chafik et al., 2016  (Atlantic, North)

de Jong and de Steur, 2016 (Irminger Sea, North Atlantic)

Reynolds et al., 2017 (Central England, North Atlantic)

Saenger et al, 2009 (Bahamas, Northern Hemisphere)
 

De Jong et al., 2016  (Andes, South America)
“[T]he reconstruction…shows that recent warming (until AD 2009) is not exceptional in the context of the past century. For example, the periods around AD 1940 and from AD 1950–1955 were warmer. This is also shown in the reanalysis data for this region and was also observed by Neukom et al. (2010b) and Neukom and Gergis (2011) for Patagonia and central Chile. Similarly, based on tree ring analyses from the upper tree limit in northern Patagonia, Villalba et al. (2003) found that the period just before AD 1950 was substantially warmer than more recent decades.”

O’Donnell et al., 2016 (Southeast Australia)

de Jong et al., 2013 (Chile)

Gouretski et al., 2012  (graph) (Global Ocean 0-20 m)


To summarize, then, there seems to be no scientific justification for NASA’s conspicuous temperature data tampering.  From all appearances, the removal and/or doctoring of observed temperature data from the pre-1981 period was a tendentious act designed to change the appearance of graphs to fit climate models that presuppose a deterministic anthropogenic influence.  NASA’s apparent manipulation of climate science endangers the reputation of scientists across all disciplines.  It should be stopped immediately before even more credibility is lost.
Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitterThe Frankfurter Allgemeine Zeitung (FAZ) — Germany’s version of the Washington Post — reports here that the country’s Energiewende (transition to green energy) has been fraught with “serious errors” and that the government has lost control of its energy policy.
The FAZ cites a report released by the Bundesrechnungshof (federal accounting office).
Out-of-control costs
The report unloads criticism on Economics Minister Sigmar Gabriel, who is also vice chancellor to Angela Merkel.
The federal accounting office report slams Gabriel’s Economics Ministry, concluding, that it “has no overview of the financial impacts of the Energiewende.” In short, the government has lost control over the project – similarly like it lost control of the construction of Hamburg’s Elbphilharmonie concert hall, which originally had been estimated to cost less than 80 million euros, but wound up costing a scandalous 789 million euros before finishing years behind schedule!
“Serious organizational deficiencies”
The accounting office report also accuses Germany’s energy policy of being fraught with “serious organizational deficiencies” that are “difficult to comprehend“.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In the earlier days of the Energiewende, proponents such as Green Party member Jürgen Trittin boasted that the green energy project would be affordable, costing the average German citizen about as much as the cost of “one scoop of ice cream each month“. Since then Germany’s electricity costs for consumers have exploded and are now among the highest in the world, averaging near 30 cents per kilowatt hour.
The stability of the supply has also taken a serious hit.
Price spiral continues
Even worse, the prices of German electricity bare projected to increase substantially over the coming years. The FAZ adds:
The federal accounting office sees a risk that it will get more expensive to advance the Energiewende.”
Germany’s shocking electricity price spiral shows no signs of slowing. A week ago the online Kieler Nachrichten here reported in a separate story that “electric bills for consumers will be significantly higher in 2017” and that if things do not change, prices will continue to rise until at least 2023.
 
Share this...FacebookTwitter "
"Former emergency leaders who have been pushing the Morrison government to take action on the climate say they will “go it alone” and convene their own summit on the bushfire crisis. The Emergency Leaders for Climate Action say they will hold the summit after the current bushfire season because of their “huge disappointment in the lack of national leadership during a bushfire crisis”. It comes as fires raged across New South Wales and Western Australia on Monday and as Australia was named as one of a handful of countries responsible for thwarting a global deal on the rulebook of the Paris climate agreement. A week ago, former fire chiefs Greg Mullins, from NSW, and Lee Johnson, from Queensland, called for a national summit on how the country should prepare for and resource bushfire emergencies in a changed climate. Both men are part of Emergency Leaders for Climate Action, a group of former fire and emergency chiefs who had warned the government that Australia faced a disastrous fire season. The group’s ranks have expanded from 23 to 29 members since it first warned the government earlier this year that Australia was unprepared for the escalating climate threat. Sign up to receive the top stories from Guardian Australia every morning Late last week the prime minister, Scott Morrison, moved to reassure voters he understood the fires were a national emergency and said climate change was one of many contributing factors to the current fire season. But Mullins said those “many factors are all related to climate change”. “What we feel is that there’s just still this denial of the problem and where we have denial of the problem, there’s not going to be any action,” he said. “So we’ll go it alone. We’ll arrange a national summit that will look at building standards, fuel management practices, response capability and national coordination arrangements. “We’ll invite the prime minister and we hope that he comes too.” The Emergency Leaders for Climate Action said Australia had “embarrassed” itself through its performance at the United Nations climate conference in Madrid at a time when people around the world were watching reports about the country burning. Mike Brown, a former chief officer for the Tasmanian Fire Service, said the outlook for the next three months was for drier and hotter than average conditions for much of the country. “That doesn’t stand well for how things develop into the summer,” he said. Brown said the eastern half of Tasmania, including all of the east coast and the Derwent Valley, was particularly dry. It follows the summer of 2018-19, when huge fires hit world heritage forest. “I’m a big fan of fuel reduction but the weather window in which to do fuel reduction is becoming narrower due to hotter and windier weather due to climate change,” Brown said. “You also can’t do fuel reduction in wet forest types. We think that due to the changing climate there needs to be a fresh approach to manage fires and just how people in communities are going to be managed into the future when we’re facing increased fire weather.” The proposed summit would include fire service workers, Indigenous landowners, the military, the insurance industry and local governments. Mullins said it would occur in late March, but the timing was subject to change if the bushfire season ran for longer than usual.    "
"The Paris deal generally got a very good press. Most reporting in the immediate aftermath had a similar focus on a few key headline points: this was a “landmark victory”, albeit one with a few cautionary notes. Yet a closer look reveals some telling differences.  The left-leaning Guardian called it an “ambitious agreement” and “an end to the fossil fuel era”. While criticisms were recognised, the tone was generally positive, even euphoric, emphasising the historic nature of the achievement. There was mention that NGOs “could never have envisaged a deal that was so ambitious” and, although it was still not ambitious enough, “campaign groups were broadly positive about the outcome”. Yet, negative points were made about “the weakening of the agreement when it came to dealing with the irreparable damage of climate change”.  The more centrist Independent similarly emphasised the historical and revolutionary nature of the moment, offering stronger cautionary notes, such as that of UCL’s Chris Rapley who pointed out that only “time will reveal the true nature of the Paris agreement”. On the political right, the Telegraph was much more cautious. It referred to the success of the agreement, but chose to outline what had been agreed, rather than emphasise the historic significance of the moment. The paper was interested in what this will mean for UK policy and in what NGOs think of the agreement, balancing positive judgements from Christian Aid with negative evaluations from Friends of the Earth. The Times and the Sunday Times however, were less positive. Writing just before the announcement, the agreement was being presented in the Times as a success for small island states in holding the UK and the rest of the world to a tougher deal. The cost of technological solutions was of more interest than marking the seminal moment. The Sunday Times (Irish edition) the following day was more appreciative of the agreement, claiming it was “historic”, but not as significant as asserted elsewhere. The article views technology and self-interest as the forces that will beat global warming. Aside from the nuts and bolts of the agreement – the financial mechanisms, pledges made, and so on – one of the strong messages of the news coverage was that investors and governments could now make choices based on a collective commitment to emissions reduction; something regarded as a very positive step. Another emphasis was the role of the US in pushing for a deal and France in brokering it.  However over in the comment pages, strongly sceptical/negative voices were also included, particularly in the Guardian. George Monbiot, the paper’s high-profile environment columnist, claimed that: “By comparison to what it could have been, it’s a miracle. By comparison to what it should have been, it’s a disaster”. Similarly former NASA climate scientist James Hansen emphasised the failures: “It’s a fraud really, a fake. […] It’s just bullshit for them to say: We’ll have a 2℃ warming target and then try to do a little better every five years.” Then we have coverage that was hostile to the entire idea of a grand environmental summit. The Daily Mail, for example, investigated the environmental impact of the conference itself and concluded it was “a prime example of what wasteful lives the green lobby lead”. Meanwhile in the Telegraph veteran journalist Christopher Booker ridiculed COP21 as the moment “political panic” over climate change began to collide with the reality of a fossil fuel-based global civilisation. But this sort of climate denial – or policy “realism” – is increasingly rare in the mainstream media across the world. In our research we’ve looked at climate coverage in Russia, one of the world’s major carbon emitters and a country with every reason to avoid high-profile debate. Yet even there things are changing. The usually reluctant media joined the positive coverage of the Paris announcement, perhaps a logical outcome of the strong statement delivered by Russia’s president, Vladimir Putin, on the summit’s first day.  For example, the state-owned newspaper Rossiyskaya Gazeta discussed the successes of the Russian delegation, which managed to achieve all its aims. Russian reporters did criticise the legal aspects of the agreement, while activists and NGOs voiced some doubts over COP21’s achievement, pointing out, for instance, the increased likelihood of controversial low-carbon policies (such as China’s potential switch to nuclear) and Russia’s ambiguous position between the developed and developing camps. But these criticisms are a positive sign of engagement with the process, rather than simple denial or misinformation.  For climate change communication, 2015 has been crucial – the media played an instrumental role in translating environmental risks for a wider audience. The awards for specific climate communication heroes and villains haven’t yet been handed out, but the whole media deserves a pat on the back for at least giving the historic achievement in Paris the column inches it deserves. This article was co-authored by Teresa Ashe."
"French wine lovers have always taken their soil very seriously. But now the country’s government has introduced fresh reasons for the rest of the world to pay attention to their terroir. As industrial emissions of greenhouse gases continue to increase and concerns about climate change grow, scientists and policy wonks are searching for potential solutions. Could part of the answer lie in the soil beneath our feet? French agriculture minister Stéphane Le Foll thinks so. Soil stores vast amounts of carbon, far more than all the carbon in the world’s forests and atmosphere combined. Plants take carbon out of the atmosphere through photosynthesis and when they die the carbon they stored is returned to the soil.  This forms part of the soil’s organic matter: a mix of undecayed plant and animal tissues, transient organic molecules and more stable material often referred to as humus. It is food for organisms in the soil that play a vital role in cycling nutrients such as nitrogen and phosphorus. These organisms decompose the organic material and return much of the carbon to the atmosphere leaving only a small proportion in the soil. In the UK alone, soils store around 10 billion tonnes of carbon – that’s about 65 times the country’s annual carbon emissions. Increasing the amount of carbon in our soils has the potential to suck CO2 out of the atmosphere. At a March 2015 conference on Climate Smart Agriculture, Le Foll proposed the ambitious target of increasing French soil carbon contents by 0.4% year-on-year (“4 pour mille”). How France will meet the target is currently unclear but by throwing down the gauntlet Le Foll clearly wants to stimulate French farmers and researchers into action.  A 0.4% increase might not sound like a lot but, given the scale of carbon storage in soil and the fact that small increases add up over the years, meeting the target would have a significant impact on atmospheric CO2 concentrations.  Le Foll hopes that protecting carbon-rich soils (like those in natural bogs, permanent grassland or wetlands), better use of organic manures and farming that returns more plant biomass to the soil (such as by using cover crops and ploughing their residues into the earth) together with the use of bioenergy crops such as short rotation willow coppice, can contribute towards a 40% reduction in France’s CO2 emissions by 2030. He plans to bring forward an international programme to promote increases in soil carbon and to propose it to the UN climate talks in Paris. Such a programme would include research, innovation and engagement with farmers. There is no doubt this is a bold move. Research has shown raising soil carbon contents is not that easy due to much of the organic matter added to soils being lost to the atmosphere as it is decomposed by soil microbes. However, protecting the carbon we already have in our soils and just storing a little more could make a big difference.  In the UK most soil carbon (by far) is found in peaty soils under bogs, followed by soils under grass, woodland and arable agriculture. Protecting this carbon should be the first priority. That means maintaining and restoring bogs, avoiding conversion of grassland and forestry to arable land, or even reconverting arable land to grassland. These measures would all have a positive effect on soil carbon stocks.   Whether all this can deliver the 0.4% increase year-on-year that the French want is open to debate. What is clear though is that not only does soil offer a way to store carbon and help mitigate climate change, carbon-rich soil has numerous other benefits. It is more fertile and helps to promote food production, it improves soil’s physical properties – it protects against soil erosion and increases water-holding capacity – and it enhances biodiversity.  Promoting practices that increase soil carbon contents really is a win for both the soil and the climate."
"Next year is likely to be another of the hottest on record, with global temperatures forecast to be more than 1.1C above the pre-industrial average, according to estimates from the Met Office. The forecast for 2020 is based on observations of trends over recent years that have seen a series of years more than 1C above pre-industrial levels, and bearing what meteorologists said was the “clear fingerprint” of human-induced global heating.  That trend is likely to continue in 2020, the Met Office predicted on Thursday, barring unforeseeable events such as a major volcanic eruption, which would have a cooling effect from the dust thrown into the atmosphere. Next year is also unlikely to see a strong natural warming event, with no El Niño predicted. El Niño is the weather system in the Pacific that can result in unusually high temperatures, as it did in 1998, which until 2005 held the crown of the warmest year since records began in 1850. For years, that fuelled false claims from some quarters that climate science was wrong and global heating was not occurring. The hottest year on record currently is 2016, when there was an El Niño effect, and the years since have all been close to the record. “Natural events, such as El Niño-induced warming in the Pacific, influence the climate system,” said Prof Adam Scaife, head of long-range prediction at the Met Office. “In the absence of El Niño, this forecast gives a clear picture of the strongest factor causing temperatures to rise: greenhouse gas emissions.” If the forecast is correct, the world will come even closer to the brink of climate breakdown next year. Scientists have warned that warming of more than 1.5C above pre-industrial levels would have damaging effects on the world’s climate. The first year in which temperatures were certified to be more than 1C above the average from 1850 to 1900 was 2015, so the rate of change has been rapid. If current trends continue, we could breach the 1.5C threshold within two decades. Greenhouse gas emissions show little sign of abating, however: research published during the UN climate talks earlier this month showed that annual carbon emissions were now 4% higher than they were in 2015, when the historic Paris agreement on climate change was signed. The Met Office used the same methods last year to forecast 2019 temperatures, and observations this year show that temperatures tracked its central estimate closely. Its forecast for 2020 is for an increase in global average temperature of between 0.99C and 1.23C, with a central estimate of 1.11C. Temperature rises have been uneven across the globe, with the Arctic heating far faster than the average. Greenland ice is melting seven times faster than in the 1990s, according to research."
"The Paris climate deal shows that the international community finally gets the science. Our leaders have publicly committed to the idea that we need to decarbonise our energy supplies and undertake a radical transformation of the global economy. But the challenge that Paris has presented the world with is how to convert that rhetoric into the laws and regulations needed to make the goal of the agreement a reality. The final text provides little detail on implementation, just a complex web of pledges with no certainty of when or if they will be fulfilled. One of the biggest gaps between the reality of our climate situation and the text of the Paris Agreement is in the absence of two sectors that are major contributors to the world’s greenhouse gas emissions. Shipping and aviation were referred to in the world’s previous climate change deal, the Kyoto Protocol, and were still referred to in the draft of the Paris Agreement until just a few days before it was signed. But they disappeared from the final text, perhaps in an attempt to secure a stronger agreement. This is important, because in combination they are a large and growing share of total CO2 emissions. Under current policy and projections, assuming that the world’s total carbon emissions fall by enough to prevent more than 2℃ of warming, by 2050 shipping and aviation could contribute 40% of our CO2 output. Failure to control these sectors will jeopardise the fulfillment of the Paris “well below 2℃” ambition. Had shipping and aviation been included in the deal, it would most likely have obliged the international bodies responsible for the sectors – the International Maritime Organization (IMO) and the International Civil Aviation Organisation (ICAO) – to develop emissions policies to meet the Paris targets. It would have sent a clear signal about the importance of the sectors in the world’s efforts to combat climate change, to two organisations that have a poor track record of action on greenhouse gas emissions. Under current policy, shipping’s CO2 emissions are expected to rise by 50-250% by 2050. Paris gives us a target of reaching net-zero carbon emissions around that time, giving us little more than a ship’s economic working lifetime (typically around 30 years) to turn things around. Exactly what contribution shipping will make is unclear but there will certainly be no room for the sector’s currently expected 1.2-2.8 gigatonnes of carbon emissions in 2050. Fortunately for shipping, there are plenty of opportunities to address CO2 emissions. The efficiency of both the world’s trade system and the ships that power it can be substantially improved with better logistics and technologies such as friction-resistant coatings and lubrication, and even simply reducing ship speeds. There is a fantastic potential for wind andsolar-powered ships. And ships have the storage capacity for alternative fuels such as hydrogen and ammonia, which are typically less energy dense and so take up more space than fossil fuels. For aircraft, the timescale of the challenge is similar. Commercial aircraft have a lifespan of around 30 years and demand is growing. But the scale of the technological challenge is greater. There are some further energy efficiency opportunities such as making planes lighter using more composite materials, more aerodynamic designs to reduce the amount of fuel needed, and alternative propulsion systems such as high-bypass turbofans and open-rotor engines. But unlike with ships, we cannot substantially reduce a flight’s CO2 by reducing aircraft speed or using on-board renewable energy sources. And the weight and space limitations make anything but the most energy dense fuels extremely costly. As a result, biofuels are regularly suggested as a key way to decarbonise aviation. But these cannot solve the non-CO2 climate impacts of flying. For example, aircraft contrails can impact cloud formation and deposit aerosols into the atmosphere, a problem that as yet has no straightforward solution.  The other major challenge for the sectors is that none of these technological solutions will occur without further meaningful regulation. This will have to be led by specific targets and trajectories defined by the sectors’ governing bodies and could include objectives for vehicle CO2 emissions, or new market-based mechanisms to drive companies to change their new and existing craft. Oil remains a fantastically cheap and reliable source of energy, and fuel is a key component of a ship or plane’s operating costs. So without such regulatory changes, the industry is highly unlikely to simply accept more expensive fuel costs. Achieving that regulation in the shipping sector will be difficult for at least two reasons. By recognising a difference between rich and poor countries, the Paris Agreement contradicts the International Maritime Organisation’s non-discrimination principle, which treats all countries equally, creating a conflict that could hamper change. There are also fears that mitigating greenhouse gases from shipping could increase the costs of transport in a way that might damage world trade and economic growth. This is likely one of the reasons the sector was left out of the Paris text. These two regulatory hurdles must be overcome, and for the sake of the shipping industry – and the planet – they must be overcome fast. Any procrastination will only increase the rate of change required by the sector and so the turbulence it will experience. Fortunately, the IMO and ICAO are UN agencies driven by governments and so we could see the mood and rhetoric of the Paris summit percolate into these bodies. But that requires governments to be consistent, something they are not historically good at in these sectors. The world needs to watch and hold its politicians and businesses to account more than ever. And these two sectors need to prepare for some fascinating and rather dramatic changes."
"
Share this...FacebookTwitterCritical German climate site wobleibtdieererwaermung.de (WBDE) reports that the earth’s surface is cooling, and presents the latest chart from NCEP:

 
As of April 11, the measured global values continue to decline (black curve) as do the computed values for April 18. Source: www.karstenhaustein.com/climate.php.
The time-delayed post El Niño cooling is now showing up in the UAH and RSS satellite data.

 Source: UAH Global Temperature Update for March, 2017: +0.19 deg. C
Foremost the atmosphere over the ocean – the largest storage of energy on the planet – cooled significantly over the month of March.
Especially remarkable is the 0.29°K drop in temperature above the global oceans measured by the UAH, and is now only 0.09°K above the WMO 1981-2010 climate mean.




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The plot shows the anomaly from the 1981- 2010 mean, UAH satellite temperature in the atmosphere 1500 meters over the sea surface. (TLT). The rose colored curve shows the 37-month running mean of the ARGO buoys which measure the water temperature 2.5 meters below the sea surface. Source: www.climate4you.com/
The RSS satellite data also showed a significant drop in global surface temperature above the seas falling from +0.38°K above the mean to 0.18°K above the mean — a drop of 0.20°K.

Chart: Woodfortrees.org
Although there have been some ups and downs over the past months, the overall global surface temperature trend remains steeply downward, dropping more than 0.6°K since early 2016.
Moreover, the surface temperature above the oceans is significant as the oceans cover more than 70 percent of the earth’s surface.
The overall negative linear trend will likely continue over much of 2017 as the delayed effects of the disappeared El Niño work their way into the satellite data.
So is the pause over? WBDE writes:

Despite the warming effect of the powerful 2015/16 El Niño, the unfalsified satellite date show that the year 2016 did not produce any new significant global heat record compared to the 1998 El Niño year. […]
The claimed global warming by the IPCC climate models has been missing for almost 20 years! And that with continuously rising atmospheric CO2 concentrations!”


The question remains: what happens in the years and decade that follow? A new slightly higher plateau, or stuck at the current old plateau?
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe earth is greening and 16 other comments on climate hysteria
By Simon Rozendaal
(Translation from his article in Netherlands Elsevier’s weekly Magazine, January 21st, 2017, with author’s permission)
In fact vegetation is thriving, figures for wind power are misleading, “sinking” islands are not sinking, safer nuclear energy is in the offing, and more that can be said loudly now that there is a real climate skeptic in the White House.
When Donald Trump was elected as president of the United States of America, the first thing that the Dutch media reported with unconcealed revulsion was that he was a ‘climate skeptic’.
The exact nature of this exotic species may not have been immediately clear to the reader or viewer of the Dutch media, because climate skeptics are consistently being ignored by them. But everyone should understand that it is something awful – even worse than a populist.
In Europe, and certainly in the Netherlands, global warming is seen as a threat, outclassing all other threats, viewed as being even much more dangerous than the rise of Islamic terrorism. One doesn’t need to be a fan of Donald Trump to frown upon this presumption.
Skeptics have been mislabeled
Much of what people daily hear about climate and climate skeptics is demonstrably wrong. The climate adviser to former President Barack Obama, Steven Koonin, tried in 2014 to infuse some nuance into the debate by arguing in The Wall Street Journal that the science is not unambiguous: not all experts believe global warming is caused entirely by man.
Nor is it certain that the current, fairly mild warming will continue unconstrained in the coming decades. What is certain is that the earth is rapidly greening, courtesy of the infamous carbon dioxide (CO2). And that’s just one of the many comments one could make on climate hysteria.
Ice melting everywhere, but not around Antarctica
Sea ice around Antarctica is growing by about 1.5 percent per decade. Even the IPCC (Intergovernmental Panel on Climate Change – the climate panel of the United Nations), which hardly ever shies away from a little exaggeration – confirms this in its reports.
The most likely explanation – presented by Richard Bintanja of the Netherlands Royal Met Office (KNMI) – is that the melting of the ice caps on the main land of Antarctica produces a layer of fresh water on the surrounding seawater. According to the laws of physics fresh water freezes more quickly than seawater. Therefore, we sprinkle salt on our roads in winter. Thus, warming may lead to more ice. If this theory is correct, this phenomenon should disappear over thirty years, so that the sea ice would melt at the Antarctic as well.
The Earth isn’t out of whack
> The land area of the Marshall Islands – a chain of volcanic atolls in the Pacific Ocean – is not sinking, but rising. The sea level rise is offset by the washing ashore of sand.
> The rate at which the concentration of CO2 increases in the atmosphere, has slowed down since 2000. Presumably, as has been published in Nature Communications a few months ago, because plants absorb more carbon dioxide from the air.
> The same magazine also recently stated that the carbon stored in peat and bogs, is contained more firmly than previously thought. The probability that global warming will reach a tipping point because this carbon is released from the peat and swamp methane (which causes a 28 times stronger greenhouse effect than CO2) is small.
10 the cost to put man on the moon for 0.17 Celsius
Critics claim that the Netherlands Energy Agreement [comparable with the Energiewende in Germany], which aims at a share of 16 percent renewable energy by 2023, will cost 100 billion euros — more than a couple of major projects together, such as the Delta Works, the Betuwe railway, the tunnel under the Green Heartland and the acquisition of JSF fighter plane.
The annual costs of the international climate agreement, concluded in Paris last year, is estimated to be between $ 1,000 and $ 2,000 billion. In comparison: the man-on-the-moon-program cost in today’s value approximately $100 billion. On the Manhattan Project, which produced the American atomic bomb, 24 billion was spent (adjusted for inflation).
That means that international climate policy costs each year ten times more than the man-on-the-moon-program and the development of the atomic bomb together. If climate policy intentions come true, the result will be only a net 0.17 degrees less warming by 2050, as has been calculated by the Danish (skeptical) environmentalist Bjørn Lomborg, founder of the think tank ‘Copenhagen Consensus Center’.
This enormous expenditure will not only affect the wallets of citizens, but also the environment. After all, economic growth in the second half of the twentieth century, did not only produce more disposable income for many, but also generated the money to tackle the pollution of forty years ago.
Geed news: the earth 14% greener than 1980
The concentration of carbon dioxide (CO2) in the atmosphere has increased from 280 ppm (parts per million) in 1800 to over 400 now. In percentage terms this rise looks less scary: from 0.028 to 0.04 percent of the total atmosphere.
This increase does not only have negative consequences. To the contrary, plants convert sunlight using CO2 into carbohydrates which become part of their mass. For them, carbon dioxide is a yearned-for fertilizer. The increase in carbon dioxide has greened the earth, said Ranga Myneni of Boston University in a lecture in 2011. On the basis of satellite images he concluded that the earth had become 14 percent greener over the past thirty years. The increase manifests itself everywhere, even in arid regions such as the Sahel.
Myneni’s paper appeared in April last year in Nature Climate Change. 32 researchers from 24 international institutions had participated in the exercise. In 2011 Myneni still believed that the half of the increase in plant growth could be attributed to CO2.
Currently, he estimates that this figure should be 70 percent. One of his co-authors, Zaichun Zhu from Beijing University, points out that a green continent of the size of two times the U.S. has been added to the earth because of CO2 fertilization.
Bonus of warming outweighs the negative factors
The Dutch should know better than anybody else that plants love CO2. Since 2005 the Shell refinery in Pernis (near Rotterdam) supplies carbon dioxide to greenhouses in South Holland through pipelines. Thus, hundreds of Dutch growers can achieve higher yields.
The Swedish Nobel Prize winner for chemistry, Svante Arrhenius, who more than a century ago was the first in the world who presented the theory of global warming, was also aware that an increase in CO2 would have beneficial effects.
In his book ‘Worlds in the Making’ (1908) he predicted that the earth would warm up and that agricultural yields would rise. As the discoverer of the greenhouse effect, this global greening was more important to him than global warming. He might haven been surprised to learn that today the reverse is the case. In fact, the positive effects haven been skillfully swept under the carpet.
Climate skeptics are being ignored, vilified and badgered by their universities
William Happer (77) is emeritus professor of physics at Princeton University (USA). He was dismissed in 1993 from the US Energy Department as Vice President Al Gore did not like his critical views. Greenpeace is conducting an ongoing slander campaign against Happer on the Internet.
Judith Curry (63), former professor at the Georgia Institute of Technology (USA), believes that there is some man-made global warming, but in her view the role of nature is dominant. A few weeks ago she resigned, partly because there is too much ‘insanity’ and ‘alarmism’ in climate science.
The Swedish Professor Lennart Bengtsson (81) was director of the European ECMWF weather bureau and the Max Planck Institute for Meteorology. In 2014 he joined the advisory council of skeptical Global Warming Policy Foundation (GWPF). He became the target of an fierce orchestrated campaign of mud-slinging, and so he felt forced to withdraw from the council within two weeks.
A study by Roger Pielke Jr. (48), professor at the University of Colorado (USA), showed that the number of storms and hurricanes has not increased. Subsequently, Pielke – who believes that humans contribute to global warming – was so vilified that he has chosen a different field of research.
Trump: ‘Sometimes it gets warmer, sometimes cooler.’
The president of the United States, Donald Trump, is called a climate skeptic (in The New York Times even a ‘climate denier’). He has appointed several people in his cabinet, who are known to be climate skeptics.
He wants step out of the Paris’ climate agreement as soon as possible and said: ‘Sometimes it gets a little warmer, sometimes cooler.’ That is called weather. It has often been alleged that Trump said that man-made global warming was a Chinese fabrication. But it is ignored that he emphatically said that this was meant as a joke.
However, he did say: ‘I think climate change is just an expensive, very expensive way to raise more taxes.’
Many journalists are not objective about climate
Alan Rusbridger, former editor of the British newspaper The Guardian, said recently in an interview with NRC Handelsblad [a Dutch daily] that his newspaper had decided in 2014 to take action against climate change. The newspaper was campaigning against oil companies under the motto: ‘Keep it in the ground.’
Rusbridger, who is now at the University of Oxford, admits that his newspaper thereby clearly exceeded all boundaries of objectivity and independence, but in this case the goal justifies the means.
Jelmer Mommers, reporter on climate and energy for the internet newspaper ‘Correspondent’, says and writes repeatedly that objective reporting like the ‘old media’ is not a priority for him. With his articles he wants to contribute to the fight against global warming.
Henk Hagoort, until recently head of the Dutch Public Broadcasting Corporation, has admitted several times that he does not want objective reporting on climate. He thinks that the television network should encourage Dutch politicians to take urgent action against climate change. During a radio discussion Hagoort stated he refused to make programs that questioned the existence of a climate problem.
The many hidden costs of offshore wind
Offshore wind technology is progressing rapidly. For instance, Shell believes it can build wind farms that are profitable at 5.45 cents per kilowatt hour. Four years ago that figure was still 17 cents. Good news, partly because offshore wind blows twice as often and twice as hard. And partly because the learning curve leads to more efficient production.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




And thus ‘only’ 300 million subsidy has to be spent on wind farms, cheers Minister Henk Kamp (minister of economic affairs, Classical Liberals, VVD). But it should be noted that, ultimately, the real price of major projects is often twice as high than the budgeted one. Also, the low price of offshore wind power is still well above the market price, which is now just over 3 cents, and will fall further below 2 cents according to experts.
The integration of wind power also requires additional investment. For example, the high-voltage network has to be improved and strengthened earlier than planned. Backup must be secured by gas plants that can quickly respond to rising demand when the wind is not blowing. Storage is required in case the wind blows, but there is no demand. The cost of all this is not attributed to wind, but ‘socialized’, i.e. passed on to the consumer.
Producers and government hold out false hopes of low electricity prices of wind power. But the reality in Denmark and Germany proves to be different, since electricity prices in these countries are among the highest in the world. It is nice that prices for wind power have fallen so rapidly, but in the mean time citizens will be facing rising energy bills by up to thousands of euros per year.
It’s like a salesman who tries to palm off a cooking-plate on you, a little bit more expensive, but very fashionable. Just before you leave the store, the friendly smiling man tells you: ‘You do realize, however, that you need to purchase a new set of cookware for this wonderful cooker?’ Oops! And just when you are about to leave the shop, he adds: ‘It is also advisable to buy a new extractor … indeed even a new kitchen.”
Fossil fuels are more subsidized than wind power
Mark Rutte (Netherlands Prime Minister, Classical Liberals, VVD) said in 2010 during the election campaign: ‘Wind turbines are not running on wind, but on subsidies.’ Proponents of wind are embarrassed by these comments. And so they reciprocate with the statement that fossil fuels are even more heavily subsidized.
In a sense this is true. But it is like comparing apples with oranges. In countries such as Venezuela, Indonesia and Mexico, poor people are being subsidized so that they can buy petrol.
In Western countries, the generation cost of electricity amounts to a few cents per kilowatt hour. However, in addition to all kinds of taxes and surcharges, the citizen has to pay 20 cents. These surcharges are partly explainable (transmission and distribution), but they also are in reality simple taxation. To promote the interests of national industry in international competition, these are excluded from these disguised taxes. Companies pay half the price for power than consumers.
It’s sloppy reasoning to compare these two forms of ‘subsidy’ with the subsidies to wind turbines, solar cells and electric cars, which are currently not (and maybe never) competitive without subsidies.
Back to prehistory: chop down trees. Green!
Most of the ‘green’ electricity generated in the Netherlands, does not come from wind turbines or solar cells, but from coal plants. In these plants so-called ‘biomass’ is mixed with coal. Wood pellets, the size of a suppository, constitute the major form of biomass.
Take the Amer-9-coal power plant in Geertruidenberg. It is even considering burning more wood pellets than coal. To that end, trees are being chopped and turned into wood pellets in the southern United States. Subsequently they are being transported in containers by ocean liners to Rotterdam and then by barges to Geertruidenberg via the Bergsche Maas.
The owner of the coal power plant, the German energy company RWE, will receive an estimated yearly subsidy of 1 billion euros. All this to achieve the renewable energy objectives of the Netherlands Energy Agreement.
This illustrates just how misguided energy policy has become under the influence of climate hysteria. Thus, the export of timber from the United States to the European Union has quadrupled in recent years. Wood – traditionally fuel of primitive societies – is back in Europe.
Today there are more polar bears than ever before
The polar bear is the favorite poster child of the melting of Arctic ice, as predicted by climate activist and former vice president Al Gore. He stated in 2009 that the Arctic would be ice-free in the summer of 2013. This would imply that the polar bear – which lives around the North Pole – would gradually become extinct.
The truth is that polar bears are doing fine. Of course, the bears suffer from melting sea ice and they have partly moved to more populated areas in Alaska and Canada to find food. But there are more polar bears than before. In 1966 there were only 10,000, now more than 25,000. According to the Canadian zoologist Susan Crockford, it is because the hunting of polar bears is better restricted than before. So hunting was a bigger problem than global warming.
Better nuclear energy is in the offing
Nuclear power is already safe and clean. Of all energy the atom is also the most energy intensive: a wheelbarrow uranium can generate as much electricity as an entire battery of wind farms in the North Sea. The problem is that so much misinformation has been disseminated that many people do not realize that although the nuclear energy does represent certain risks, it still has a very good safety record, despite Harrisburg, Chernobyl and Fukushima.
The good news is that there are new types in the offing (the thorium and the molten salt reactor) that are even safer. Even the environmental movement, traditionally a fierce opponent of nuclear energy, has to admit that it is not easy to come up with objections to the new nuclear power. The problem is that it will take another twenty years before various options become available.
Ideal transition fuel
Natural gas (and shale gas because that is the same substance: methane) produces 50% less CO2-emission than coal. So replacing oil and coal with natural gas is a good option to achieve reduction of CO2-emissions. Yet, in his recent Energy Agenda minister Henk Kamp (VVD) announces that new homes will not be connected to the gas grid and that existing homes will become gas free. All homes must be gas-free in 2050.
This is a bizarre decision. Because of its low CO2 emissions, easy and wide availability and relatively low price, natural gas is the ideal transition fuel to bridge the period until 2050 and even 2100, when alternative energy options (socially acceptable nuclear power, more efficient solar cells) will probably be competing without subsidy with cheap coal power.
How shale gas was thwarted 
Shale gas has boosted the U.S. economy and made a major contribution to the decline of American CO2 emissions since 2007. In ‘Between pride and hysteria’ (2015), energy journalist Remco de Boer explained why shale gas did not succeed in the Netherlands. Some environmental activists were looking for a new issue, people living near drilling sites feared value losses of their homes, politicians and administrators had weak knees. De Boer on the ability of citizens to influence policy: ‘Three people with a banner and an alarming message in front of the town hall, attended by the local newspaper, and you have already made a lot of progress.’
Pinstripe activism versus multinationals
Climate activism is no longer confined to public demonstrations. They go to court (as the Dutch action group Urgenda did in 2015) or the stock market, such as the Dutch ‘Follow This’ (with 1,800 members and 6 million shares) and the British ‘Share Action’-groups. They are particularly targeting Shell.
The emergence of pinstripe activists as Mark van Baal (founder of ‘Follow This’) seems to have success. Shell, Unilever and pension fund ABP, are increasingly posing as green and sustainable businesses.
By some this is seen as an argument that wind and solar energy represent the future. But that’s nonsense. Earlier Shell has invested in nuclear energy, but stepped out of it again. Ditto for solar cells. Shell has invested in windmills and bio alcohol. It is putting bets on several horses and watching how the markets (read: subsidies) will develop.
It is above all green window-dressing with which multinationals adorn themselves. At a climate conference it was suggested that CEO Paul Polman of Unilever should have a chat with president Trump about sustainability. Yet, Unilever manufactured margarine with trans-fatty acids, which has caused many people to die prematurely. With its production of palm oil in Southeast Asia, Unilever has since contributed to the extinction of the orangutan. In an interview Polman advised people not to shower for too long, and in having done so, his company is now suddenly on record as being sustainable.
Relationship between CO2 and climate is not one-to-one
Even when our ancestors had no cars, there was climate change. CO2 is only one of many factors that drive the climate. This is evident from the graph that shows the relationship between CO2 and temperature since 1900.
The rise of CO2 concentration in the atmosphere shows a relatively straight line, but the temperature varies. From 1900 to 1940 it increased, between 1940 and 1970 it slightly declined, between 1970 and 1998 the temperature rose again, but since 1998 it seems to have stabilized, although alarmists try to ignore, deny or qualify this (‘at sea, the warming continues’, so they say).
When the temperature in 2015 and 2016 reached new highs – partly due to a strong El Niño, and a spike in periodically oscillating ocean currents – it was said that the warming was back again.
Now that El Niño is over (late 2016), the global temperature has dropped again and it is generally expected that 2017 will not break any records. All in all, it seems that global warming pause or hiatus has lasted now almost twenty years.
Conclusion
Keep a cool head – there is time to think.
The earth has indisputably warmed up. With the caveat that this process has been going on for nearly 20,000 years, since the last ice age. It accelerated since the Little Ice Age – the period from 1500 to 1800 – when Hendrick Avercamp and other masters of the Low Lands painted their famous winter scenes.
The human race had no impact on the alternation of ice ages and warm periods in the geological past. These processes were the result of the position of the Earth’s axis and oscillations in the orbit in which the Earth moves around the sun. Nor had our ancestors anything to do with the warming over the last few thousand years.
The period starting with 1900 is a different story. Then the warming was undoubtedly reinforced by the burning of fossil fuels. Almost everyone agrees on that. — even climate skeptics. It is not true that they deny the existence of global warming and the fact that man contributes to it.
The debate is about the share of man in global warming. The IPCC, the alarmist prone climate panel of the United Nations, concluded in a recent report: ‘It is extremely likely that more than half of the observed increase in the surface temperature between 1951 and 2010 has been caused by man’. In other words, maybe almost half of the current warming was not caused by us.
The IPCC itself indicates that the science is not yet settled. Climate change is not black and white. Between ‘climate change is a fairytale disseminated by the Chinese’ and ‘the science is settled, leave those fossil fuels in the ground’, there are fifty shades of gray. Consequently, there is no justification for the current hysteria, whereby any kind of weather phenomenon is framed as evidence that the climate is upset and politicians of left and right, activists groups, multinationals and even generals, pretend that climate is world problem number 1, and so suggest that we could control weather with higher taxes.
Of course, ultimately we need to switch to non-fossil fuels. Yet we still have a lot of time to do so. For the moment it seems that the earth is more robust than the alarmists believe. For almost twenty years we are experiencing mild warming and CO2 appears to have a beneficial, greening effect.
There are plenty of reasons telling us that keeping a cool head is the reasonable thing to do.
=============================================
Simon Rozendaal is a chemist (honorary member of the Royal Dutch Society of Chemists, KNCV), and has been writing on science for over forty years, first for NRC Handelsblad and for Elsevier, the leading Dutch weekly news magazine, for thirty years now.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany’s Deutsche Welle (DW) here presents a commentary by Hans Joachim Schellnhuber, the director of German ultra-alarmist Potsdam Institute for Climate Impact Research.
Professor Schellnhuber fears that the planet could warm even as much as 12°C if man does not act quickly to totally eliminate greenhouse gases. He adds that he “has all the evidence” and that climate scientists “are only trying to do a job” for us.
Hat-tip: Reader Dennis A.
With the US Administration pledging to back out of the Paris climate treaty, Schellnhuber is now calling on scientists “to take to the streets to counter climate denial“.
If we want to hold the 1.5 degrees [Celsius; 3.6 degrees Fahrenheit] line, which is the ambitious goal of the Paris agreement, we have maybe 300 billion tons left – more or less the budget of 10 years – if we do business as usual. If we want to hold the 2 degrees line, which is more realistic, we have another 20 to 30 years to go, but no more actually. So it’s a very tight budget.
It’s quite mind-boggling – for example, by 2030, we have to phase out the combustion engine. And we have to completely phase out the use of coal for producing power. By 2040 we will probably have to replace concrete and steel for construction by wood, clay and stone.
We are at the crossroads now: We either say: this thing is too big for us, this task cannot be done. [Then] we will be transformed by nature, because we will end up with a planet warming by 4, 5, 6 or even 12 degrees. It would be the end of the world as we know it, and I have all the evidence.”
In short, the eccentric professor from Potsdam is essentially claiming that unless we return to living in mud huts with thatched roofs and forego the fundamental amenities of modern life, our great grandchildren will end up living in super tropical hot-house conditions.
Fortunately Schellnhuber’s view is a rare one that is out on the remote fringe. Other climate scientists hold a far more sober view, like Prof Judith Curry. Interestingly, climate hardly seems to be a concern for Schellnhuber’s boss, Angela Merkel, who yesterday did not mention climate change once during her press conference with President Trump. In fact much of the discussion was about trade, economy …along with a little fake news and wire-tapping.
 
Share this...FacebookTwitter "
"It has become a mantra here that Paris 2015 is not Copenhagen 2009. This time, the US and China are on board; the price of renewables has dropped by more than half; the vast majority of countries here have already pledged emission cuts and Paris is seen as a “staging post” not a final destination. But how different is Paris 2015 for the 3,700 media representatives accredited here? Like Copenhagen, where there were 4,000 from nearly 120 countries, the sheer volume of journalists makes the summits two of the most media-covered political events ever. So it’s a daunting task for anyone analysing the bewildering array of content the journalists are producing.  A preliminary look at some of the hundreds of articles already published by the mainstream media suggests that, as in Copenhagen, the main angles are the process of the negotiations, and the political wrangling behind the sticking points. So in Paris, much has already been published about the position of India, whereas in Copenhagen there was more about China. More interesting are the other aspects of the climate change “mega-story” that journalists choose to cover beyond the negotiations. One strong impression is that since Copenhagen, as one veteran agency reporter put it to me recently, “climate change has moved from being just an environment story to a business and energy story”.  The Financial Times, for instance, has long been interested in climate change for its business readers (often presenting it a risk issue). It covered the Copenhagen summit extensively. But this time round, like many legacy media organisations, the FT has added a live blog, videos, a beginners’ guide, and a special index on the Paris talks. Another difference is that journalists here receive an endless stream of announcements of new initiatives on renewables, technology and business risk. And many of them have received extensive coverage – the new initiative by Bill Gates and Mark Zuckerberg to boost clean energy research in the new “Breakthrough Energy Coalition” predictably hit the headlines beyond the business press. But so did the pledge by the US and 18 other countries to double funding for similar research, India’s International Solar Alliance aiming to boost the use of solar power, and the announcement of an international Financial Stability Board, chaired by Michael Bloomberg, to manage threats from climate risks. In the same vein, the Washington Post headlined a recent piece as possibly “the biggest news yet to come out of the Paris climate meeting”.  It was not about some breakthrough in the negotiations, but about a new initiative to deliver at least 300 gigawatts of electricity-generating capacity to Africa by 2030, all from clean or renewable energy. Such stories are one indication of how media narratives about climate change are becoming more about hope and opportunity and less about the more traditional doom and gloom. In part, this may be due to a realisation that the transition to a low-carbon economy is inevitable, even though the pace of it is uncertain. But for some media organisations, such as the Guardian, more messages of hope form part of a deliberate editorial policy driven in part by readers’ wishes. Another major change since Copenhagen is the boom in niche sites about climate change and the rise of successful “digital natives” such as Huffington Post, Vice and BuzzFeed giving priority to environment coverage. At first sight, BuzzFeed is offering its traditional diet of listicles, photo galleries, quizzes and humorous content. But a closer look shows that much of its coverage is positive and hopeful. They and other new players seem to offer no space to sceptical voices. The “Climategate affair” received considerable coverage at the time of the Copenhagen summit, offering plenty of traction to deniers particularly in the UK and US. But this time round there seems to be a consensus that deniers have become much more marginal. Unilever boss Paul Polman recently described them as “the only endangered species”. Matt Ridley, the Conservative hereditary peer who describes himself as a “lukewarm” sceptic, is an exception. He has appeared in several right-leaning newspapers in the US, UK and Australia. But several climate scientists have come out fighting, laboriously picking holes in a recent interview he gave to the BBC. A crucial test remains for the media at the end of the summit. The wise money is on some sort of deal being signed here. The outcome is likely not to be enough to keep warming below 2℃, but nevertheless an important step on the path. It is a truism that journalists like binary stories with winners and losers, and success or failure – nuance will be more of a challenge."
"It is an awe-inspiring and terrifying sight, a volcano spewing lava and millions of tons of ash and rock into a blackened sky. Mexico’s “fire volcano”, Mount Colima, recently began erupting … again, a reminder of the spectacularly destructive forces that can be unleashed by nature.  But dramatic as online footage of this Mexican volcano is, the eruption is a mere trifle compared to some of the little-known natural disasters that have been predicted. From supervolcanoes to towering megatsunamis, these catastrophic events could affect millions – and occur sooner than you think. The threat posed to the world by the Yellowstone supervolcano in the United States is well documented. Less well-known (or acknowledged), however, is that it is just one of many posing a catastrophic threat to the planet.  The Lake Toba supervolcano, on the Indonesian island of Sumatra, is currently home to the largest volcanic lake on Earth, formed 74,000 years ago when it last blew in the biggest eruption for 25m years. It is estimated that around 2,800 cubic kilometres of volcanic ash and lava were thrown into the atmosphere, 12% more than was ejected by the last Yellowstone eruption of 2.2m years ago.  And it may be about to erupt again. As with any super-eruption, the vast quantities of ash and sulphur dioxide produced can have a devastating effect on the global climate. But a number of factors make the prospect of a Toba super-eruption much more intimidating than one at Yellowstone. Toba is located on the densely populated island of Sumatra, home to over 50m vulnerable people, and is only 40km from the Indian Ocean in which catastrophic tsunamis (of which we have recent experience) would certainly be generated. Additionally, in recent months, reports of volcanic gases and heating of the ground surface have led to suggestions that the sleeping giant may again be waking up. Forget the widely-publicised megatsunami threat that has been attributed to the potential collapse of the Cumbre Vieja volcano on La Palma in the Canary Islands. A far greater danger is posed by the possible collapse of the southern portion of Kilauea Volcano on the Big Island of Hawaii. Termed the Hilina Slump, this could drop 12,000 cubic kilometres of rock into the Pacific Ocean, generating a megatsunami that would propagate around the Pacific Ocean and reach the western seaboard of North America in a matter of hours, inundating coastal communities. There is evidence that a similar collapse at nearby Mauna Loa around 120,000 years ago generated a tsunami with a run-up height of over 400m. Even as recently as 1975, movement of the Hilina Slump generated a smaller, yet destructive tsunami that reached California. Given that the slump is continually active and moving, it might only take a jolt from an earthquake in the tectonically active state to set in motion this catastrophic chain of events. The North Sea may seem an unlikely place for a devastating tsunami but climate change has led to concern that a submarine landslide in the region might lead to just this.  There is a precedent. Scientists have suggested that over 6,000 years ago, a sharp sea-level rise, attributed to a changing climate and a rapid melting of ice, added weight to the submarine glacial deposits at the edge of the Norwegian continental shelf, destabilising them and causing a 300km long landslide. This generated a tsunami that reached heights of up to 20 metres in the Shetland Islands, ten on the Norwegian coast and six metres off the northern and western coast of Scotland.  Should Earth experience such a rapidly warming climate again, and experience the associated melting of the Greenland and/or West Antarctic ice sheets, a similar event might well be possible which, today, would affect the coastal populations of Scotland and Norway (around 3m) – and perhaps even London. At the bottom of the Pacific Ocean, just off the west coast of North America and running from northern California to Vancouver Island, is a subduction zone – a place where the Pacific Ocean floor is being forced beneath the North American landmass.  The rate of movement of the ocean floor here is currently just 40mm a year but the upper part of the system is currently stuck, meaning that the North American plate is being compressed. At some point, the pressure being built up has to be released and this will be in the form of a massive earthquake, perhaps up to a magnitude 9. This could cause subsidence of the coastal region of up to 2m and a possible horizontal displacement of 30m.  Shortly after the intense shaking subsides, the riling coastal community will be struck by a tsunami that could dwarf that of the 2011 Japanese wave. Around 7m people live in this region, from Vancouver, though Seattle, to Tacoma and Portland.  How feasible is it? Well scientists have calculated that in the last 10,000 years, the region has suffered 41 large earthquakes, occurring with an average interval of 244 years – the last was a magnitude 9 and that was 315 years ago.  Perhaps the biggest threat to the modern world is posed by our own star. Periodically, the sun emits a solar flare, an intense cloud of energetic photons and particles with the energy of millions of hydrogen bombs exploding at once. Once released, these clouds arrive at Earth’s upper atmosphere within a day or two and, in many cases, most ordinary people on Earth would be none the wiser.  If intense enough, however, a solar storm could devastate electrical systems both in orbit, for example, satellites, and on the ground, as the energetic electrons cause a charge build-up.  One of the largest known events was in 1921, which knocked out the US telegraph service; but scientists have calculated that should a similar event happen in today’s technology-reliant society, it could knock out many satellite systems, disabling global communications, the internet and the global positioning system. Chaos could ensue. The intensity of solar flares varies on a roughly 11-year cycle and fortunately, 2014 saw the most recent peak come and go without significant impact. We can only hope that the same can be said for the future."
"
Share this...FacebookTwitterMojib Latif: Climate models fail to simulate tropical Pacific. No detectable anthropogenic signal
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
Prof. Mojib Latif is a widely sought out speaker for events and the German media, and he never passes up the opportunity to warn the public of the impending climate catastrophe. However at his his daytime job he is also a scientist, and there he publishes research results on a regular basis. On many occasions we have noticed that in his scientific papers he appears to be far less dramatic and more balanced than he is in the media. Some examples follow:

Mojib Latif in a presentation in USA: CO2 climate sensitivity is set to high by the IPCC
Late realization: Mojib Latif abandons CO2-fingerprint in the stratosphere and finally focusses on ocean cycles
Mojib Latif: Models must account much more for natural variability

On April 5, 2017, in the Geophysical Research Letters there’s yet another example to behold. With his colleagues Latif examined the tropical Pacific. In the eastern and central parts temperatures have cooled over the past two decades. Climate models are having a hard time recreating this development. Latif and his group looked at this case and assumed that natural climate variability is behind it. They have not been able to find an anthropogenic impact on the temperature development in this region.
They conclude that the climate models would be too uncertain to make forecasts concerning the acting circulation in the region.
With that in mind, wouldn’t it be nice if Latif mentioned this the next time he appears on a talk show? But don’t hold your breath thinking this will happen anytime soon.
It’s the two faces of Mojib Latif. It’s unclear how her goes about justifying this scientifically and ethically. What follows is the abstract with the highlighted main points:
Role of Internal Variability in Recent Decadal to Multidecadal Tropical Pacific Climate Changes
Mohammad Hadi Bordbar, Thomas Martin, Mojib Latif and Wonsun Park
While the Earth’s surface has considerably warmed over the past two decades, the tropical Pacific has featured a cooling of sea surface temperatures (SSTs) in its eastern and central part, which went along with an unprecedented strengthening of the equatorial Trade Winds, the surface component of the Pacific Walker Circulation (PWC). Previous studies show that this decadal trend in the Trade Winds is generally beyond the range of decadal trends simulated by climate models when forced by historical radiative forcing. There is still a debate on the origin of and the potential role that internal variability may have played in the recent decadal surface wind trend. Using a number of long control (unforced) integrations of global climate models and several observational datasets, we address the question as to whether the recent decadal to multidecadal trends are robustly classified as an unusual event or the persistent response to external forcing. The observed trends in the tropical Pacific surface climate are still within the range of the long-term internal variability spanned by the models but represent an extreme realization of this variability. Thus, the recent observed decadal trends in the tropical Pacific, though highly unusual, could be of natural origin. We note that the long-term trends in the selected PWC indices exhibit a large observational uncertainty, even hindering definitive statements about the sign of the trends.
Highlights:

Pacific Walker Circulation strongly varies internally
Anthropogenic signals in the tropical Pacific sector are hard to detect
There is large model uncertainty about the future of the Pacific Walker Circulation”


Share this...FacebookTwitter "
"The finding of an ancient disposable cup that dates back 3,500 years shows that the idea that throwaway vessels for drinks is a modern habit is not true and even ancient civilisations didn’t want “to do the washing up”, experts say. The Minoans, one of the first advanced civilisations in Europe, used the cup to drink wine in Greek island of Crete where they resided. Thousands of the handleless, conical clay cups have been discovered on archeological sites on the island and the palace of Knossos. They will go on display from Friday at the the British Museum, which has been under pressure from environment campaigners over its sponsorship by oil giant BP.  Julia Farley, is a curator at the museum, said: “People may be very surprised to know that disposable, single-use cups are not the invention of our modern consumerist society, but in fact can be traced back thousands of years. Minoans gathered at the palace for parties, feasts and gatherings such as bull-leaping festivals – a “more risky” version of “hurdles”. Farley said: “The elite were showing off their wealth and status by throwing these great big parties, feasts and festivals. “People were getting together in large groups and much like today, nobody wants to do the washing up. As well as being convenient, the cup was a means of showing off wealth because of all the resources “poured into making it”. Farley said she hoped the display would make visitors think creatively about reducing waste, instead of just feeling guilty. “Human beings have always produced rubbish. Making some rubbish is an unavoidable by-product of being human. We are tool-using animals. We wear clothes. Nothing lasts forever. It’s in the very nature of our existence that we make rubbish.” But she said: “This is a sobering message about scale and consumption and I think we need to find that balance, which humans have never been very good at finding.” The ancient object will be shown alongside a waxed paper cup from the early 1990s – made at around the same time modern disposable cups were taking off. Other objects will include a yellow fishing basket made from plastic wrapping and photographs from across the Pacific, showing the extent of plastic pollution Farley said: “We have thousands of these Minoan, disposable cups and that’s a lot. But today we are making over 300 billion papers cups globally every year. The Minoan civilisation is tiny compared to the global consumerist economy that we have now. “Now we are doing what human beings have always done but we are doing it on an unprecedented scale with materials that are going to take hundreds, if not thousands of years, to biodegrade. “We think of ancient people as being in touch with their environment but if you cut down trees to make charcoal and burn it to fire clay that’s releasing a lot of carbon dioxide.” British Museum director Hartwig Fischer said: “We hope that this display will make people think about their relationship with rubbish, then, now and in the future.” The Asahi Shimbun Displays Disposable? Rubbish And Us opens on Friday 19 December and runs until 23 February, 2020 at the British Museum."
"
Share this...FacebookTwitterSea Levels Meters Higher While
CO2 Levels Were Below 300 ppm
 
Image Yoon et al., 2017

Before the advent of the industrial revolution in the late 18th to early 19th centuries, carbon dioxide (CO2) concentrations hovered around 280 parts per million (ppm).
Within the last century, atmospheric CO2 concentrations have risen dramatically.  Just recently they eclipsed 400 ppm.
Scientists like Dr. James Hansen have concluded that pre-industrial CO2 levels were climatically ideal.  Though less optimal, atmospheric CO2 concentrations up to 350 ppm have been characterized as climatically “safe”.  However, CO2 concentrations above 350 ppm are thought to be dangerous to the Earth system.  It is believed that such “high” concentrations could lead to rapid warming, glacier and ice sheet melt, and especially catastrophic sea level rise of 10 feet within 50 years.
It is interesting to note these prognostications of impending deluge are predicated on the assumption that CO2 concentrations are a driver of sea level fluctuations.
Scientists have determined that during the interglacial 400,000 years ago (MIS 11), CO2 peaked at a very safe 280 parts per million (ppm).  Despite such a low and “ideal” CO2 concentration, scientists have determined that sea levels during that interglacial were 20 meters higher than than they are now.

Guo et al., 2017
“The upper 250 meter-long sediment core of Site U1391 (1085 m water depth) retrieved from the Portuguese margin in the Northeast Atlantic Ocean was adopted for the benthic foraminiferal analyses to disclose the variations in Mediterranean Outflow Water (MOW) intensity over the last ~ 0.9 Ma [900,000 years]. The strongest MOW [Mediterranean Outflow Water]  intensity during MIS 11 [400,000 years ago] confirms the climatic influence of waving sea level on the MOW current by its +20 m high-stand above the present sea level.”

CO2 graph courtesy of NASA.gov

Sea Levels 6-8 Meters Higher 6-9 Thousand Years Ago (~260 ppm CO2)

Although most scientists have found that the Holocene’s (~11,700 years ago to present) sea level peaks (highstands) were between 1 and 4 meters higher than present, there are some who have found that Early Holocene sea levels reached as high as 6 to 8 meters above mean sea level today.

Prieto et al., 2016
“Analysis of the RSL [relative sea level] database revealed that the RSL [relative sea level] rose to reach the present level at or before c. 7000 cal yr BP, with the peak of the sea-level highstand c. +4 m [above present] between c. 6000 and 5500 cal yr BP [calendar years before present] … This RSL [relative sea level] curve was re-plotted by Gyllencreutz et al. (2010) using the same index points and qualitative approach but using the calibrated ages. It shows rising sea-levels following the Last Glacial Termination (LGT), reaching a RSL [relative sea level] maximum of +6.5 m above present at c. 6500 cal yr BP [calendar years before present], followed by a stepped regressive trend towards the present.”


Hodgson et al., 2016
“Rapid early Holocene sea-level rise in Prydz Bay, East Antarctica … The field data show rapid increases in rates of relative sea level rise of 12–48 mm/yr [+1.2 to 4.8 meters per century] between 10,473 (or 9678) and 9411 cal yr BP in the Vestfold Hills and of 8.8 mm/yr between 8882 and 8563 cal yr BP in the Larsemann Hills. … The geological data imply a regional RSL [relative sea level] high stand of c. 8 m [above present levels], which persisted between 9411 cal yr BP and 7564 cal yr BP [calendar years before present], and was followed by a period when deglacial sea-level rise was almost exactly cancelled out by local rebound.”


Recent Sea Level Rise Undetectable When Viewed In Its Long-Term Context

Despite the surge in anthropogenic CO2 emissions and atmospheric CO2 since the 20th century began, the UN’s Intergovernmental Panel on Climate Change (IPCC) has concluded that global sea levels only rose by an average of 1.7 mm/yr during the entire 1901-2010 period, which is a rate of less than 7 inches (17 cm) per century and an overall rise of just 0.19 of a meter in 110 years.
According to Wenzel and Schröter (2014), the acceleration rate for the sea level rise trend since 1900 has been just +0.0042 mm/yr, which is acknowledged by the authors to be “not significant” and well within the larger range of uncertainty (+ or – 0.0092 mm/yr), effectively putting the overall 20th/21st century sea level rise acceleration rate at nearly zero.
As mentioned, most scientists have found that sea levels were about 1 – 4 meters higher than they are now between 4,000 and 6,000 years ago (when CO2 concentrations were about 260 to 265 ppm).  It may therefore be enlightening to visualize the overall nineteen hundredths of a meter (0.19) rise in sea levels since 1901 in its long-term (Holocene) context.  Assuming a sea level highstand of about 2.5 meters above present during the Mid-Holocene, notice how modest the recent rise appears.




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




10 More New Papers Affirm Sea Levels Were Much Higher 4-6 Thousand Years Ago

In the last few years alone (2014 to 2016), there were at least 35 papers published in the peer-reviewed scientific literature indicating that sea levels were substantially higher than they are now just a few thousand years ago…when CO2 concentrations are thought to have been “safe”.
In 2017, there have already been another 10 scientific papers published that can be added to this growing list.
It is becoming more and more apparent that sea levels rise and fall without any obvious connection to CO2 concentrations.  And if an anthropogenic signal cannot be conspicuously connected to sea level rise (as scientists have increasingly noted), then the greatest perceived threat (rising sea levels) promulgated by advocates of dangerous anthropogenic global warming will have lost its impact.

1.  Das et al., 2017  (India)
“In the absence of any evidence of land-level changes, the study suggests that at around 6 ka to 3 ka [6,000 to 3,000 years ago], the sea was approximately 2 m higher than present.”

2.  Fontes et al., 2017   (Brazil)
“During the early-middle Holocene there was a rise in RSL [relative sea level] with a highstand at about 5350 cal yr BP [calendar years before present]  of 2.7 ± 1.35 m [higher than present], which caused a marine incursion along the fluvial valley.”


3.  Yoon et al., 2017  (Korea)
“Songaksan is the youngest eruptive centre on Jeju Island, Korea, and was produced by a phreatomagmatic eruption in a coastal setting c. 3.7 ka BP [3,700 years before present]. The 1 m thick basal portion of the tuff ring shows an unusually well-preserved transition of facies from intertidal to supratidal, from which palaeo-high-tide level and a total of 13 high-tide events were inferred. Another set of erosion surfaces and reworked deposits in the middle of the tuff ring, as high as 6 m above present mean sea level, is interpreted to be the product of wave reworking during a storm-surge event that lasted approximately three tidal cycles. … The reworked deposits alternate three or four times with the primary tuff beds of Units B and C and occur as high as 6 m above present mean sea level or 4 m above high-tide level (based on land-based Lidar terrain mapping of the outcrop surface).”

 

4.  Marwick et al., 2017  (full pdf)  (Thailand)
“Sinsakul (1992) has summarised 56 radiocarbon dates of shell and peat from beach and tidal locations to estimate a Holocene sea level curve for peninsula Thailand that starts with a steady rise in sea level until about 6 k BP, reaching a height of +4 m amsl (above [present] mean sea level). Sea levels then regressed until 4.7 k BP, then rising again to 2.5 m amsl at about 4 k BP. From 3.7 k to 2.7 k BP there was a regressive phase, with transgression starting again at 2.7 k BP to a maximum of 2 m amsl at 2.5 k BP. Regression continued from that time until the present sea levels were reached at 1.5 k BP. … Tjia (1996) collected over 130 radiocarbon ages from geological deposits of shell in abrasion platforms, sea-level notches and oyster beds and identified a +5 m [above present] highstand at ca. 5 k BP in the Thai-Malay Peninsula. …  Sathiamurthy and Voris (2006) summarise the evidence described above as indicating that between 6 and 4.2 k BP, the sea level rose from 0 m to +5 m [above present] along the Sunda Shelf [+2.8 mm/yr], marking the regional mid-Holocene highstand. Following this highstand, the sea level fell gradually and reached the modern level at about 1 k BP [1,000 years ago].”

5.  May et al., 2017 (W. Australia)
“[T]he mid-Holocene sea-level highstand of Western Australia [was] at least 1–2 m above present mean sea level. … Between approximately 7000 and 6000 years BP, post-glacial RSL [relative sea level] reached a highstand of 1-2 m above the present one, followed by a phase of marine regression (Lambeck and Nakada, 1990; Lewis et al., 2013).”

6.  Kane et al., 2017 (Equatorial Pacific)
“The high stand is documented across the equatorial Pacific with peak sea-level values ranging from 0.25 to 3.00 m above present mean sea level (MSL) between 1000 and 5000 yr BP (Fletcher and Jones, 1996; Grossman et al., 1998; Dickinson, 2003; Woodroffe et al., 2012). Woodroffe et al. (2012) argues that Holocene sea-level oscillations of a meter or greater are likely to have been produced by local rather than global processes.”


7.  Khan et al., 2017 (Caribbean)
“Only Suriname and Guyana [Caribbean] exhibited higher RSL [relative sea level] than present (82% probability), reaching a maximum height of ∼1 m [above present] at 5.2 ka [5,200 years ago]. … Because of meltwater input, the rates of RSL change were highest during the early Holocene, with a maximum of 10.9 ± 0.6 m/ka [1.9 meters per century] in Suriname and Guyana and minimum of 7.4 ± 0.7 m/ka [0.74 meters per century] in south Florida from 12 to 8 ka [12,000 to 8,000 years ago].”

8.  Meltzner et al., 2017  (Southeast Asia)
“Half-metre sea-level fluctuations on centennial timescales from mid-Holocene corals of Southeast Asia … RSL [relative sea level]  history between 6850 and 6500 cal years BP that includes two 0.6 m fluctuations, with rates of RSL [relative sea level] change reaching 13±4 mm per year. … Here RSL [relative sea level] rose to an initial peak of +1.9 m [above present] at 6,720 cal years BP, then fell rapidly to a lowstand of +1.3 m, remaining at about that level for ∼100 years, before rising to a second peak at +1.7 m shortly after 6,550 cal years BP. Around 6,480 cal years BP, RSL appears to have fallen again to +1.3 m before rising to a third peak at +1.6 m or higher. … The peak rate of RSL rise, averaged over a 20-year running time window over the period of study (∼6,850–6,500 cal years BP), is +9.6±4.2 mm per year (2σ); the peak rate of RSL fall is −12.6±4.2 mm per year. … To put the ∼0.6 m mid-Holocene fluctuations in context, annual mean sea level in some modern tide-gauge records is seen to change by as much as 0.2–0.3 m on interannual timescales, and the interannual s.d. of sea surface height between 1979 and 2013 approached 0.1 m in some portions of the western Pacific.  The central dome of each microatoll grew during a period when RSL was high; RSL then fell rapidly, killing the upper portions of the corals; RSL then stabilized at a lower elevation, forming a series of low concentric annuli ∼0.6 m higher than present-day analogues; RSL [relative sea level] then rose ∼0.6 m in less than a century, allowing the coral to grow upward to 1.2 m higher than modern living corals.”

9.  Leonard, 2017 (Great Barrier Reef)
“The resultant palaeo-sea-level reconstruction revealed a rapid lowering of RSL of at least 0.4 m from 5500 to 5300 yBP following a RSL [relative sea level] highstand of ~0.75 m above present from ~6500 to 5500 yBP. RSL then returned to higher levels before a 2000-yr hiatus in reef flat corals after 4600 yBP. The RSL oscillations at 5500 yBP and 4600 yBP coincide with both substantial reduction in reef accretion and wide spread reef “turn-off”, respectively, thereby suggesting that oscillating sea level was the primary driver of reef shut down on the GBR.”

10.  Dechnik et al., 2017 (Tropical Western Pacific)
“[I]t is generally accepted that relative sea level reached a maximum of 1–1.5 m above present mean sea level (pmsl) by ~7 ka [7,000 years ago] (Lewis et al., 2013).”
Share this...FacebookTwitter "
"Europe’s fish populations will continue to be over-exploited despite a longstanding 2020 deadline for setting fishing quotas at sustainable levels, after ministers from across the EU forced through higher limits than scientists advised. Key species such as cod in the west of Scotland and Irish Sea, some herring stocks, sole and plaice in the Celtic Sea, pollock in western waters, and ling and tusk in the north-east Atlantic, will all be under renewed and unsustainable pressure, according to campaigners. Quotas for some species were increased from last year, despite advice that they should be brought down.  “The limits agreed by ministers suggest that progress to end overfishing has stalled or even reversed,” said Andrew Clayton of the Pew Charitable Trusts. “This is especially disappointing for 2020, the legal deadline in the common fisheries policy to end overfishing. Missing the deadline means putting stocks such as cod under heavy pressure in 2020, even though their populations are at critical levels.” The quota for haddock in the North Sea for the UK was raised by 23% and UK catches of sole in the western Channel raised by 19%. George Eustice, the UK fisheries minister, defended the decisions made at a tense meeting that ended early on Wednesday morning: “This year there has been some very challenging science for cod stocks in many parts of the north-east Atlantic, and we have responded to conserve stocks. I know that some of the quota reductions will be very difficult for some sectors of the industry – however, we know that to protect the profitability of fisheries in the future, we must fish sustainably today.” He condemned the EU’s “outdated method for sharing quota” among member states, saying it meant the UK got a “very small share of the cod in our own waters”, but pledged that would be reconsidered after Brexit. The UK would also put in place its own policies to ensure fish catches were managed sustainably, he said. The UK will still have to negotiate with EU member states and non-EU nations such as Norway and Iceland over shared fishing grounds after Brexit. In an all-night meeting in Brussels, the ministers at the Agriculture and Fisheries Council failed to meet their own targets and deadlines on sustainable fishing, under pressure from their national fleets. Under reforms to the EU’s common fisheries policy, enacted in 2013 after two years of intense talks, fishing ministers were supposed to gradually phase out the too-high quotas that had been the norm for decades and contributed to steep declines in key fish populations. By 2020, all quotas were meant to be based on a maximum sustainable yield – the most fish that can be caught without damaging the ability of the species to recover itself – and there was to be an end to the wasteful practice of discarding dead fish at sea. But Tuesday night’s meeting, at which the quotas for 2020 were set, showed little departure from the pattern that has been set for years, in which ministers ignored science and fought bitterly for their own vested interests. “Everybody must comply with the law – and politicians are no exception,” said Andrea Ripol, fisheries policy officer at Seas At Risk. “Ministers decided today to breach the law, allowing overfishing even beyond 2020. This decision represents a betrayal of European citizens, and breaks their trust.” At the recent UN climate change talks, which ended amid discord and disappointment on Sunday, governments were told that ending overfishing could improve the prospects of dealing with the climate emergency. Protecting fish stocks restores a healthy balance to the seas that enables them to store more carbon and absorb heat, vital functions in the Earth’s natural processes. “They’re just not getting it,” said Rebecca Hubbard, programme director at Our Fish. “Demonstrating a shocking ignorance of the global biodiversity and climate crisis, the EU council of fisheries ministers refused to follow scientific advice. Ending overfishing would be a rapid, achievable act that would bolster the health of the ocean in the face of the climate crisis, securing futures for coastal communities, as well as being a firm response to calls from EU citizens for climate action.”"
"Yet again, distressing images of flood damage and destruction in northern England are prompting calls for further investment in UK flood defences and fearful talk of climate change.  There is a particularly worried tone to the commentary, because this flooding occurred after installation of new hard flood defences (completed in June 2010) that simply could not cope with the flow and – despite millions spent on glass flood walls and hydraulic modelling of the options – these defences failed. Or at least this is what we are hearing in the press. This verdict is too severe, flood defences have worked in places and have bought people – and the emergency services – more time and reduced flood risk.  But for those with homes covered in wet, polluted mud, these arguments sound hollow. The simple fact is that with record-breaking rainfall (341mm in 24 hours at Honister Pass) on a landscape which has been managed for centuries to be efficient at encouraging rainwater to flow into rivers, you would expect flooding – and the more extreme the rainfall, the more extreme the flooding. A key question being asked by all is: “What do we mean by extreme flooding?” Already we have heard repeatedly the common misconception “this is a flood that should only happen every 100 years”. This is incorrect. The science of flood extremes attempts to use the woefully short records of river flow (which has been around for about 30 years) and rainfall (which has been recorded for about 200 years) to estimate a probability: the chance of a flood of a given size happening.  A 100-year flood is actually better described as a flood that has a 1% chance of occurring within any given year. It does not mean that we expect one every 100 years – sadly as the people of Cumbria have found, a flood with a 1% chance of occurring can occur more than once in 100 years and quite possibly within the same year. In fact the chances of another 100-year event occurring in 2016 remains 1%. After the 2009 Cumbrian floods, the Natural Environment Research Council funded a study to look at using lake sediments to track any changes in flood frequency and magnitude. The lake sediment record from our lakes  can provide a long perspective on flood magnitude and frequency spanning thousands of years.  The mud covering the flooded homes and roads have been washed down rivers from the mountains – and in Cumbria they end up in the lakes. Each flood can leave a distinct sediment layer. Research by scientists from the universities of Southampton, Liverpool and Durham suggests that the floods of 2005 and 2009 in Cumbria were the largest for 600 years (the results of this analysis are yet to be published) and that these sorts of events had a probability of occurring 0.001% or one in every 1,000 years (substantially rarer than the one in 200-year value arrived at using the 30 years of measured river flows).  What is worrying is that the lake sediment flood record shows that two-thirds of the very largest floods experienced in Cumbria have happened in the past 15 years, a period characterised by warmer northern hemisphere temperatures (an index for moisture and energy in the atmosphere) and positive North Atlantic Oscillation Index – a measure of the direction of storm tracks over the UK (including Storm Desmond). Such conditions last occurred 800 years ago during the medieval climatic anomaly, a time when the Cumbria landscape was quite different from today with less intensive agriculture and more extensive woodlands. In the Howgill Fells a lack of trees and steep slopes have created conditions for landslides – sediment from which is then fed into the river channel creating changes in the river. A wooded valley would make the slopes less susceptible to landslides and would reduce the movement of sediments and water downstream. As it is, the huge rainfall that came with Storm Desmond has resulted in landslides around the valleys of Borrowdale, Thirlmere, Ullswater and the Howgill Fells."
"If you’re dreaming of a white Christmas you might look to the bookies to check the odds. Despite reports that this will be the coldest winter since 1963, with less than a week to go the odds of a flurry in London on the big day were hovering around 7/2, one of the lowest chances of snow for several years.  But perhaps mathematicians know better. When it comes to forecasting the likelihood of a snow blizzard, our weather presenters know what to say – predicting the odds of snow falling during the week ahead is relatively easy. However, predicting if there will be enough snow for festive frolicking with snowmen, sledging and snowball fights is much harder. We can tell if snow will fall, but not how much, which is arguably the most important Christmas weather question of all. Weather forecasting is based on computer modelling, but surprisingly these models do not actually predict snow. A single variable is used to predict whether water will visit as liquid, vapour or ice so other information, such as air temperature is needed to stack the odds of snow. Computer models are able to forecast the amount of water produced when air rises above the height at which water vapour begins to condense. Known as the Quantitative Precipitation Forecast (QPF), when it comes to snow prediction this is an important variable. But there are many sensitive factors that can affect the odds in favour of rain, or make it very difficult to distinguish between different types of snow, from a disappointing slush to our traditional fluffy festive flurry. If temperatures are low enough, rain will fall as snow. And then forecasters need a way to translate the QPF into an equivalent snowfall. We use a ratio of about 1 to 10 to calculate how much snow will be produced from an amount of rainwater. If the QPF predicts one inch of rain, we’d be admiring a pretty good ten-inch covering of snow! Sounds simple? Think again. As with so many things in life, it’s not all about quantity, but quality; the quality of the snow that is. This magic 1:10 rain to snow ratio can vary depending on whether the snow is “wet” or “dry.” Dry snow is composed of those small powdery flakes that make for great skiing; it is less dense and contains less water. It forms when there is very little moisture available. Under these circumstances, the rain to snow ratio can be considerably higher, quite often 1 to 20! Then there is “wet” snow. This is the heavier, moisture-packed variety that can quickly turn into ankle-twisting ice patches. Here, there is abundant moisture, and the snowflakes are bigger and wetter. The typical ratio becomes 1 to 5. To know if we’ll be getting the “right” kind of Christmas flurry, we therefore need to have very accurate forecasts of moisture levels in the atmosphere, plus an understanding of the variation of temperature with altitude. Our forecast models describe a snapshot of the weather at a given moment using vast arrays of numbers to describe the atmosphere. This array of numbers takes into account a host of basic variables such as moisture and temperature. Calculating how these many millions of “weather pixels” will interact and adapt requires superfast computation and large amounts of memory. This resource-heavy computational model leads to inevitable limitations when predicting snowfall. So there is a trade-off between the geographical coverage of the models and the detail that we can expect from them.  It simply requires too much computer power to accurately predict snow (and importantly, what kind of snow) across the country. This trade-off is critical when it comes to calculating reliable QPFs, and therefore working out the chances of a proper white Christmas. Forecasters often turn to the lessons learned at college – dew points, temperature soundings from meteorological balloon ascents and real-time reports from weather stations to assess the impact of a snow storm. So whether you turn to the bookies, TV weather presenters or even us mathematicians, getting an expert to predict snow – one of our most loved, and occasionally loathed, weather features – is a really tough call. But in any case it always depends on number crunching and the power of mathematics. We may be able to capture the beauty of a perfect snow-covered Christmas day with high-resolution digital cameras, but capturing the mystery behind snowfall in our sophisticated weather prediction models is much more challenging. Whether you should take a flutter on a flurry this year comes down to “seat of the pants” knowledge, a little hopeful wishing and, sometimes, a sprinkling of Christmas magic."
nan
"I’ve been at the climate summit in Madrid for the past two weeks. The question I was constantly asked was: “What will it take for Australia to treat the climate crisis seriously?” International friends, colleagues and strangers looked on in horror at the effects of the bushfires and outright amazement at the Morrison government’s denial of the link between the fires and Australia’s coal industry, and seeming lack of concern at this extreme impact of climate change. Morning after morning I woke to check the news and the “fires near me” app. Seeking updates from friends. Was the Katoomba fire close enough to force evacuation of one? Had another been able to return to their house yet? How was the air pollution in Sydney? Was my partner, who is an asthmatic, coping? This is not normal. This is life lived under a climate emergency. And yet the Australian government acted like business as usual in Madrid. Focused on watering down Australia’s ambition. Pushing for dodgy accounting tricks that would halve Australia’s (already completely inadequate) climate effort, with flow-on effects to weaken ambition of other countries. Analysis released during the summit showed that if Australia, China and Brazil used their hollow Kyoto units to meet Paris agreement targets, global ambition would decrease by 25%, delaying the transition to new energy systems and resulting in more global heating. Despite a coalition of countries coming out to oppose this weakening, the issue remains unresolved, with talks being carried into next year. This approach is entirely aligned with the interests of the coal lobby, who were stalking the meeting halls of COP25. They were no doubt very pleased with the Australian government strategy. This strategy works directly against the interests of the rest of us living the climate emergency: the farmers facing worsening drought conditions, the firefighters battling more ferocious bushfires, the towns at risk of evacuation as they run out of water, and those struggling to breathe from air pollution. This is the first annual climate summit where the general mood was panic and climate grief Championing the Australian coal industry sells out not just Australians, but also sells out our Pacific Island neighbours who did little to cause the climate crisis and have few resources to cope with the impacts. They face not only the creeping threat of sea level rise but also stronger and more devastating cyclones. When Cyclone Pam hit Vanuatu in 2015 with wind speeds never before experienced there, it caused loss and damage worth US$600m – 64% of Vanuatu’s GDP. In just one storm. Solidarity for vulnerable countries dealing with extreme climate impacts was one of the key outcomes expected of the Madrid meeting. In the example of Cyclone Pam, Vanuatu received international support of 10% of the costs. The rest was left for the Vanuatu government and subsistence farmers and fisherpeople to deal with. This is typical of extreme climate disasters around the world. It is not only deeply unfair (after all, these countries did not cause the climate crisis), it will also likely eventually result in a series of failed states. Vulnerable countries desperately need more funds to help them cope. Yet the Australian government stymied and blocked, joining the United States in ensuring that any progress was the smallest possible, tiny and incremental. Nothing like what vulnerable people need. This lack of responsibility for the climate crisis filled me with despair. The Australian government scored a zero for climate policy in a global ranking of countries released at the Madrid summit. They should also rate a zero for compassion and a zero for international citizenship. The climate crisis will get worse – past emissions have baked heating into the system; and unless we radically transform our economy to clean energy it will get inconceivably worse. Unless we act together as a community we face polarisation and extremism. A situation which works for no one, not even the coal billionaires. This is the first annual climate summit where the general mood was panic and climate grief. It’s the first COP where I’ve seen tears in meetings and the corridors at the terrible impotence of not knowing how to grasp the power back from the big polluters. The ray of hope is the youth, demanding their future back. The rest of us have a responsibility to join them, to back their calls however we can. Force our government to show compassion. Demand genuine climate action. We can do this. Other governments are – New Zealand is showing us up. It is our government that is failing us, failing our neighbours, failing our youth. We’ve got no choice but to demand they act, and refuse to give up until they do. See you at a youth-led climate rally soon. • Julie-Anne Richards is executive director of Climate Action Network Australia"
"
Share this...FacebookTwitterThe largest city of my home state of Vermont — Burlington — was buried by a record-shattering 30.4 inches (ca. 80 cm) of snow from recent storm Stella.

Burlington, Vermont area gets buried by record-smashing snow as bitter temperatures grip region. Image cropped from Westford Webcam.
Hat-tip: reader Indomitable Snowman
Amusingly the reader Snowman just informed me by e-mail that 10 years ago Former Vermont governor Peter Schumlin (then Senate President) warned the state would need to plaster its beautiful green mountains with 500-foot tall industrial wind turbines in order to prevent massive warming. He said:
Any reasonable scientist will tell you that we’re going to rise anywhere between another two and three degrees in the next 30 years. That means that New Jersey’s climate is moving to Vermont in the next decade. That has tremendous implications in our economy’s ski, maple-sugar making, leaf-peeping and the list goes on and on. So we are — I at least am — looking at this with a major sense of panic.”
Well, it looks like the maple sugaring and ski season will be extended well into April — at least for this year. Schumlin’s prediction is yet another that is exposed as just plain idiotic and silly.
The massive snowstorm dumped 30.4 inches at the Burlington airport, making it the greatest March snowstorm on record and the 2nd largest all-time (records date back to 1883) in terms of snowfall. The biggest snowfall was 33.1 inches in January 2010.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




A daily record snowfall of 17.8 inches was set at Burlington, VT on March 14. This smashes the old record of 10.0 inches set in 1980. Also with 12.6 inches on March 15 the snowfall record was shattered for the date — previous record was 4.1 inches set way back in 1940.
For those claiming that it just doesn’t snow like it used to in Vermont, the statistics show that 4 of the top 10 snowfalls in fact occurred over the past 10 years, with 7 of the top 10 in the past 31 years!
What follows are the statistics provided by Snowman.
Top 10 greatest snowstorms (inches of snow) at Burlington, Vermont:
(1) 33.1 Jan 2-3 2010
(2) 30.4 Mar 14-15 2017
(3) 29.8 Dec 25-28 1969
(4) 25.8 Mar 6-7 2011
(5) 25.7 Feb 14-15 2007
(6) 24.7 Jan 13-14 1934
(7) 22.9 Mar 5-6 2001
(8) 22.4 Mar 13-14 1993
(9) 20.0 Nov 25 1900
(10) 19.7 Jan 25-28 1986
Top 4 March snowstorms for Burlington:
(1) March 14-15, 2017…30.4″
(2) March 7-8, 2011…..25.8″
(3) March 5-6, 2001…..22.9″
(4) March 13-14, 1993…22.4″
Top 5 Snowiest March`s at Burlington:
(1) 47.6 2001
(2) 39.9 1993
(3) 37.0 1896
(4) 33.1 1971
(5) 31.8 2017 thru 3/15
Top 5 daily snowfalls at Burlington for March 14:
(1) 17.8 2017
(2) 10.0 1980
(3) 6.9 1993
(4) 4.1 1956
(5) 4.0 1897
Top 5 Daily snowfalls at Burlington for March 15
(1) 12.6 2017
(2) 4.1 1940
(3) 3.5 1998/1933
(4) 3.4 1958
(5) 3.0 1901
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe Globe Has Not Been Warming . . .
So Why Is It Called ‘Global’ Warming?

There were at least 60 peer-reviewed scientific papers published in 2016 demonstrating that  Today’s Warming Isn’t Global, Unprecedented, Or Remarkable.
As of the end of January, another 17 papers had already been published in 2017.  17 New (2017) Scientific Papers Affirm Today’s Warming Is Not Global, Unprecedented, Or Remarkable
Within the last month, another 14 papers have been published that continue to cast doubt on the popularized conception of an especially unusual global-scale warming during modern times.
Yes, some regions of the Earth have been warming in recent decades or at some point in the last 100 years.  Some regions have been cooling for decades at a time.  And many regions have shown no significant net changes or trends in either direction relative to the last few hundred to thousands of years.  In other words, there is nothing historically unprecedented or remarkable about today’s climate when viewed in the context of natural variability.


Goursaud et al., 2017


Wilson et al., 2017



Cai and Liu et al., 2017
“2003– 2009 was the warmest period in the reconstruction. 1970– 2000 was colder than the last stage of the Little Ice Age (LIA).”


Tegzes et al., 2017
“The objective of this study was to investigate northward oceanic heat transport in the NwASC [Norwegian Atlantic Slope Current] on longer, geologically meaningful time scales. To this end, we reconstructed variations in the strength of the NwASC over the late-Holocene using the sortable-silt method. We then analysed the statistical relationship between our palaeo-flow reconstructions and published upper-ocean hydrography proxy records from the same location on the mid-Norwegian Margin. Our sortable-silt time series show prominent multi-decadal to multi-centennial variability, but no clear long-term trend over the past 4200 years. … [O]ur findings indicate that variations in the strength of the main branch of the Atlantic Inflow may not necessarily translate into proportional changes in northward oceanic heat transport in the eastern Nordic Seas.”




Fernández-Fernández et al., 2017
“The abrupt climatic transition of the early 20th century and the 25-year warm period 1925–1950 triggered the main retreat and volume loss of these glaciers since the end of the ‘Little Ice Age’. Meanwhile, cooling during the 1960s, 1970s and 1980s altered the trend, with advances of the glacier snouts.”


Tejedor et al., 2017

 

Guillet et al., 2017


Köse et al., 2017
“The reconstruction is punctuated by a temperature increase during the 20th century; yet extreme cold and warm events during the 19th century seem to eclipse conditions during the 20th century. We found significant correlations between our March–April spring temperature reconstruction and existing gridded spring temperature reconstructions for Europe over Turkey and southeastern Europe. … During the last 200 years, our reconstruction suggests that the coldest year was 1898 and the warmest year was 1873. The reconstructed extreme events also coincided with accounts from historical records. …  Further, the warming trends seen in our record agrees with data presented by Turkes and Sumer (2004), of which they attributed [20th century warming] to increased urbanization in Turkey. Considering long-term changes in spring temperatures, the 19th century was characterized by more high-frequency fluctuations compared to the 20th century, which was defined by more gradual changes and includes the beginning of decreased DTRs [diurnal temperature ranges] in the region (Turkes and Sumer, 2004).”



Flannery et al., 2017
“The early part of the reconstruction (1733–1850) coincides with the end of the Little Ice Age, and exhibits 3 of the 4 coolest decadal excursions in the record. However, the mean SST estimate from that interval during the LIA is not significantly different from the late 20th Century SST mean. The most prominent cooling event in the 20th Century is a decade centered around 1965. This corresponds to a basin-wide cooling in the North Atlantic and cool phase of the AMO.”


Mayewski et al., 2017


Rydval et al., 2017
“[T]he recent summer-time warming in Scotland is likely not unique when compared to multi-decadal warm periods observed in the 1300s, 1500s, and 1730s“

Reynolds et al., 2017


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->






Rosenthal et al., 2017
“Here we review proxy records of intermediate water temperatures from sediment cores and corals in the equatorial Pacific and northeastern Atlantic Oceans, spanning 10,000 years beyond the instrumental record. These records suggests that intermediate waters [0-700 m] were 1.5-2°C warmer during the Holocene Thermal Maximum than in the last century. Intermediate water masses cooled by 0.9°C from the Medieval Climate Anomaly to the Little Ice Age. These changes are significantly larger than the temperature anomalies documented in the instrumental record. The implied large perturbations in OHC and Earth’s energy budget are at odds with very small radiative forcing anomalies throughout the Holocene and Common Era. … The records suggest that dynamic processes provide an efficient mechanism to amplify small changes in insolation [surface solar radiation] into relatively large changes in OHC.”




Li et al., 2017
“We suggest that solar activity may play a key role in driving the climatic fluctuations in NC [North China] during the last 22 centuries, with its quasi ∼100, 50, 23, or 22-year periodicity clearly identified in our climatic reconstructions. … It has been widely suggested from both climate modeling and observation data that solar activity plays a key role in driving late Holocene climatic fluctuations by triggering global temperature variability and atmospheric dynamical circulation“




Dong et al., 2017


Nazarova et al., 2017
“The application of transfer functions resulted in reconstructed T July fluctuations of approximately 3 °C over the last 2800 years. Low temperatures (11.0-12.0 °C) were reconstructed for the periods between ca 1700 and 1500 cal yr BP (corresponding to the Kofun cold stage) and between ca 1200 and 150 cal yr BP (partly corresponding to the Little Ice Age [LIA]). Warm periods (modern T[emperatures] July or higher) were reconstructed for the periods between ca 2700 and 1800 cal yr BP, 1500 and 1300 cal yr BP and after 150 cal yr BP.”


Samartin et al., 2017


Thienemann et al., 2017
“[P]roxy-inferred annual MATs[annual mean air temperatures] show the lowest value at 11,510 yr BP (7.6°C). Subsequently, temperatures rise to 10.7°C at 9540 yr BP followed by an overall decline of about 2.5°C until present (8.3°C).”


Li et al., 2017
“Contrary to the often-documented warming trend over the past few centuries, but consistent with temperature record from the northern Tibetan Plateau, our data show a gradual decreasing trend of 0.3 °C in mean annual air temperature from 1750 to 1970 CE. This result suggests a gradual cooling trend in some high altitude regions over this interval, which could provide a new explanation for the observed decreasing Asian summer monsoon. In addition, our data indicate an abruptly increased interannual-to decadal-scale temperature variations of 0.8 – 2.2 °C after 1970 CE, in terms of both magnitude and frequency, indicating that the climate system in high altitude regions would become more unstable under current global warming.”


Krawczyk et al., 2017



Kawahata et al., 2017
“The SST [sea surface temperature] shows a broad maximum (~17.3 °C) in the mid-Holocene (5-7 cal kyr BP), which corresponds to the Jomon transgression. … The SST maximum continued for only a century and then the SST [sea surface temperatures] dropped by 3.5 °C [15.1 to 11.6 °C] within two centuries. Several peaks fluctuate by 2°C over a few centuries.”


Saini et al., 2017


Dechnik et al., 2017
“[I]t is generally accepted that relative sea level reached a maximum of 1–1.5 m above present mean sea level (pmsl) by ~7 ka [7,000 years ago] (Lewis et al., 2013)”


Wu et al., 2017
“The alkenone-based SST reconstruction shows rapid warming in the first 1500 years of the Holocene … an increase of sea surface temperature from c. 23.0 °C to 27.0 °C, associated with a strengthened summer monsoon from c. 10,350 to 8900 cal. years BP. This was also a period of rapid sea-level rise and marine transgression, during which the sea inundated the palaeo-incised channel … In these 1500 years, fluvial discharge was strong and concentrated within the channel, and the high sedimentation rate (11.8 mm/yr [1.18 m per century]) was very close to the rate of sea-level rise.”


Sun et al., 2017
“[A]t least six centennial droughts occurred at about 7300, 6300, 5500, 3400, 2500 and 500 cal yr BP. Our findings are generally consistent with other records from the ISM [Indian Summer Monsoon]  region, and suggest that the monsoon intensity is primarily controlled by solar irradiance on a centennial time scale. This external forcing may have been amplified by cooling events in the North Atlantic and by ENSO activity in the eastern tropical Pacific, which shifted the ITCZ further southwards. The inconsistency between local rainfall amount in the southeastern margin of the QTP and ISM intensity may also have been the result of the effect of solar activity on the local hydrological cycle on the periphery of the plateau.”


Wu et al., 2017


Park, 2017
“Late Holocene climate change in coastal East Asia was likely driven by ENSO variation.   Our tree pollen index of warmness (TPIW) shows important late Holocene cold events associated with low sunspot periods such as Oort, Wolf, Spörer, and Maunder Minimum. Comparisons among standard Z-scores of filtered TPIW, ΔTSI, and other paleoclimate records from central and northeastern China, off the coast of northern Japan, southern Philippines, and Peru all demonstrate significant relationships [between solar activity and climate]. This suggests that solar activity drove Holocene variations in both East Asian Monsoon (EAM) and El Niño Southern Oscillation (ENSO). In particular, the latter seems to have predominantly controlled the coastal climate of East Asia to the extent that the influence of precession was nearly muted during the late Holocene.”
 
 


Pendea et al., 2017 (Russia)
“The Holocene Thermal Maximum (HTM) was a relatively warm period that is commonly associated with the orbitally forced Holocene maximum summer insolation (e.g., Berger, 1978; Bartlein et al., 2011). Its timing varies widely from region to region but is generally detected in paleorecords between 11 and 5 cal ka BP (e.g., Kaufman et al., 2004; Bartlein et al., 2011; Renssen et al., 2012).  … In Kamchatka, the timing of the HTM varies. Dirksen et al. (2013) find warmer-than-present conditions between 9000 and 5000 cal yr BP in central Kamchatka and between 7000 and 5800 cal yr BP at coastal sites.”

Stivrins et al., 2017  (Latvia)
“Conclusion: Using a multi-proxy approach, we studied the dynamics of thermokarst characteristics in western Latvia, where thermokarst occurred exceptionally late at the Holocene Thermal Maximum. …  [A] thermokarst active phase … began 8500 cal. yr BP and lasted at least until 7400 cal. yr BP. Given that thermokarst arise when the mean summer air temperature gradually increased ca. 2°C beyond the modern day temperature, we can argue that before that point, the local geomorphological conditions at the study site must have been exceptional to secure ice-block from the surficial landscape transformation and environmental processes.”

Bañuls-Cardona et al., 2017 (Spain)
“During the Middle Holocene we detect important climatic events. From 7000 to 6800 [years before present] (MIR 23 and MIR22), we register climatic characteristics that could be related to the end of the African Humid Period, namely an increase in temperatures and a progressive reduction in arboreal cover as a result of a decrease in precipitation. The temperatures exceeded current levels by 1°C, especially in MIR23, where the most highly represented taxon is a thermo-Mediterranean species, M. (T.) duodecimcostatus.”

Åkesson et al., 2017 (Norway)
“Reconstructions for southern Norway based on pollen and chironomids suggest that summer temperatures were up to 2 °C higher than present in the period between 8000 and 4000 BP, when solar insolation was higher (Nesje and Dahl, 1991; Bjune et al., 2005; Velle et al., 2005a).”
Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitterCorrection: Reader Fred informs that the SRF is not a German radio station, but instead belongs to Switzerland: “And yes, all people living in Switzerland are forced to pay around 300 US dollars a year for that crap, even if you never watch or listen the SRF […] it is just another leftwing propaganda machine.”
==================================================
The German public radio and television network is funded by mandatory annual fees made by every German citizen. It is massive and it dominates the country’s media landscape. Unfortunately it is not at all objective and balanced, though it may be claimed to be so at Wikipedia and elsewhere.
German public television, for example, works closely with CNN. It is unabashed totally anti-Trump. On November 9 when it became clear that Trump would be the next president, total shock and meltdown spread across all of the German public media.
Like the BBC, German public media are also very much universally climate alarmist, insisting the science is settled (even though it is less so than ever today). Some have argued quite convincingly that Germany is now firmly under a media-political opinion dictatorship – but that’s a topic for another day.
The latest example of climate propaganda and fake science purveyed by the elitist German politico-media comes from SRF German public radio, so reports Africa-geology expert Dr. Sebastian Lüning at his Die kalte Sonne site.
===========================================
SRF Africa correspondent gets it all wrong in Ghana: Embarrassing mixing up of coastal processes and climate change
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
On December 7, 2016, Patrick Wülser at Radio SRF went off on weepy sea level climate alarmism:
Climate change in Ghana: The ocean is swallowing Totope piece by piece
What climate scientists are predicting is already happening in Ghana: The fishing village has already in part sunken into the sea.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Rising sea level and ever more powerful tidal waves are eating away at the coast of West Africa and threatening fishing villagers. The consequences of climate change and the construction of deep-sea harbors and dams have accelerated the erosion of the coastline over the past 20 years. The fishing village of Toto in Ghana has already in part sunken into the sea.”
A rather cheap piece of propaganda theater, as just a critical glance at the map will clearly shows that this village is located in the Volta Delta on a typical coastal sand dune island, which because of the sand dune shifting and sea erosion — also without sea level rise — is always undergoing change naturally. The sediment-transport processes in the region were already comprehensively described in detail back in 1998 by Nairn et al. (pdf here).
Back then coastal protection measures were proposed, but obviously were never implemented.
But there’s more to the story as the huge Volta-water reservoir is pressing down the entire area of the Volta-Delta and its Akosombo dam is preventing the Volta’s land mass from reaching its old Delta area. This means sea erosion can no longer be compensated. Therefore it is easy to demonstrate that the situation described in Totope/Ghana has very little to do with climate change and rising sea level rise, and in fact has much more to do with changed land-use and natural coastal erosion processes.


Moreover, this new SRF propaganda piece is only a rehash of an older Zeit article from 2012.
When one looks at the Wikipedia entry on Song(h)or-Lagune, one cannot find the claimed huge danger through climate change anywhere. Rather the concerned focus is much more on unsustainable use, e.g. through over-fishing, cutting down of the mangroves and drainage in order to create more farmland:
Threats and possible consequences
The main threats to the site exist as varied forms of excessive utilization. Some common cases are over-fishing, extreme harvesting of mangroves, extensive drainage and cultivation for farmland, heavy grazing by cattle and livestock, and an unsustainable level of salt winning. These threats are difficult to neutralize because the human communities surrounding the lagoon are largely poor and over-populated. In effect, the local people are dependent upon their harvesting of the lagoon for survival. Although ecotourism provides an ecologically friendly source of income, the practice is not extensive enough to sustain the local communities. Additional threats originate from the use of pesticides and herbicides, the damming of creeks and channels for the purpose of expanding infrastructure, and rubbish dumping.[16] These threats can and, in some instances, have had dire consequences. The breeding cycles of nesting species, like the several sea turtle species hosted by the lagoon, can be disturbed by exaggerated human activity. Furthermore, the eggs of such species are often trampled by grazing cattle and livestock. Another realized effect of human exploitation is the apparent shrinking of the lagoon, which can be easily observed in the satellite photo comparison shown at the opening of this article. Further disturbance of the lagoon could result in not only the loss of species that inhabit the site, but also the loss of nutritive and moderating benefits provided by the site. Aside from purifying ground water, acting as a reservoir for nutrients, and supporting the local food chain, the lagoon regulates water flow, staggers and lessens the effects of flooding, and disperses the extreme erosive forces exerted on the shore by the Atlantic Ocean.[17]
re

Share this...FacebookTwitter "
"
Share this...FacebookTwitterAt today’s Weatherbell Daily Update, meteorologist Joe Bastardi looks at the forecast over the next 15 days for Europe. The following chart depicts the forecast accumulated snowfall by January 27, 2017.

Image cropped from Weatherbell 11 January 20017 Daily Update.
As the chart makes clear, plenty of winter snow is in the pipeline. The cold that Europe experienced earlier this month was likely just a preview of remains ahead for the continent. The widespread snow cover threatens to send nighttime temperatures to harsh levels. Bastardi even goes on to say that the snowfall over Europe will be “a big headline maker”.
Bastardi, a veteran in the forecasting business, also shows the GFS temperature outlook for January 22-27, which will follow 10 days of below normal tempertaures:

Almost the entire European continent will gripped by cold during the period. Joe promises that we are going to be seeing weather headlines coming out of Europe, and may well be similar to what happened in 2013.
That likely means a very late spring. The gardening industry should take note.
 
Share this...FacebookTwitter "
"Australia recorded its hottest day on record on Wednesday, with an average maximum temperature of 41.9C (107.4F), beating the previous record by 1C that had been set only 24 hours earlier. Tuesday 16 December recorded an average of 40.9C across the continent, beating the previous record of 40.3C set on 7 January 2013. But it held the record for just 24 hours.  Wednesday was even hotter across the country, with the highest maximum temperature reached in Birdsville, Queensland, which hit 47.7C (117.8). On Wednesday the lowest maximum was 19C at Low Head, Tasmania. On Thursday, Nullarbor in South Australia set the record for the hottest December day on record, recording 49.9C (121.8). To calculate the average maximum, the Bureau of Meteorology takes the maximum temperatures recorded in about 700 locations, puts them into a grid, calculates an average, and then cross-checks this against its long-term quality controlled record, known as ACORN-SAT. So why is Australia so hot? Dr Karl Braganza, manager climate monitoring at the bureau, told Guardian Australia: “Natural variability and global warming are pushing in the same direction. That’s why we have broken records.” Dr Andrew Watkins, head of long-range forecasts at the bureau, identified three key factors that have pushed temperatures to record levels – two of them natural, and one of them not. Australia is currently feeling the impacts of one of the strongest Indian Ocean Dipole events on record. When the IOD is positive, the waters off Australia’s north-west are cooler, dragging moisture away from the continent and leaving very dry conditions. On the flipside, Watkins said parts of east Africa had seen devastating impacts from flooding rains, in particular in Somalia, Ethiopia and South Sudan. “That positive IOD has kept things very dry in winter and spring,” Watkins said. “That sets us up with an extremely dry environment. It has been the second driest year to date and the warmest year to date.” A second natural driver, Watkins said, was a negative phase of the Southern Annular Mode that was kicked off by warming of the atmosphere high above Antarctica. The SAM had helped drive the extreme heat in NSW and Queensland, Watkins said, adding to the extreme fire danger. This has also brought drier and warmer air across the continent on westerly winds. SAM events usually only last a few weeks, but Watkins said this event had been present since October. “All of this is leading to central Australia baking,” he said. “There’s nothing there to evaporatively cool the air.” He said an example of this heat was revealed in forecast temperatures in recent days of between 43C and 45C for Alice Springs. “When I see those forecasts I say, ‘wow.’ Because Alice Springs is 550m above sea level. 45C half a kilometre up is pretty insane. “Meteorologists will say that you get roughly 1C per 100m of elevation so we know that means the air at the surface would have been in the high 40s.” Underlying these two major drivers of the heat is climate change – the simple physics of loading the atmosphere with extra greenhouse gases, mainly by burning fossil fuels. Australia’s latest State of the Climate report shows the country has warmed by just over 1C since 1910, leading to more extreme events. Watkins said: “That long-term warming sees the bar lifted up so that it’s easier to get extreme conditions now than it was 50 or 100 years ago,” “One part of me says that this is amazing but then another says that we have seen this in other parts of the world so we’re not especially surprised.” He pointed to France’s heatwave of June 2019, when Montpellier hit 43.5C, breaking its previous all-time heat record set in August 2017 by a huge 5.8C. “I’m not sure we are shocked by much any more.” Dr Sarah Perkins-Kirkpatrick, a climate scientist at the University of New South Wales specialising in extreme events, said climate change had given the natural drivers of Australia’s record -breaking heat “extra sting.” She said without the extra CO2 in the atmosphere “it would still have been warm”, but, she added: “I doubt very much we would have seen a record on Tuesday and then another one on Wednesday. And we are still at the beginning of the summer with a long way to go.” On Thursday, she was driving through thick smoke haze in north-west Sydney with her family. She said: “It is frightening and a little frustrating, but this is what climate scientists have been saying for decades. “I’m bordering on saying ‘I told you so’ but I don’t think anyone really wants to hear that.”"
"
Share this...FacebookTwitterReader Indomitable Snowman sent a link to an AccuWeather report telling us of the intense winter weather gripping eastern Europe and how it has claimed close to 60 lives thus far. German weather site wetteronline.de also reports of close to 60 cold deaths so far from the current Eastern European cold blast.
Although we get scattered reports of cold deaths here in Europe, it’s been tough to find a total tally from the German global warming-devout mainstream media.
Accuweather writes:
Millions of people from Baltic states and Poland southward to the Mediterranean Sea have endured dangerous cold and bouts of snow. Thousands of refugees have also had to endure the bitter cold which is expected to last through at least Thursday. Temperatures plummeted to the lowest level in years in Warsaw, Minsk, Budapest and Moscow.”
Rescue from cold for the birds?
Entering the German term “Kältetote” (cold deaths) in Google, one gets few reports of the total deaths in Europe (at the time this post was written) from the German mainstream media. Online daily Bild did wrote here 2 days ago how the intensely cold conditions posed a dangerous threat to refugees in transit. Indeed this was true, and it still is.
Yet, another site here seem to think the real story of the day was how one man rescued a bird from freezing to death — as if poor citizens do not matter so much?
Die Welt reports 50 victims
To its credit, the online Die Welt here reported on the eastern European cold deaths earlier today:
Especially in the east and south of the continent several dozen people have frozen to death, in Belarus, Ukraine, in Hungary and Slovakia, in Bosnia, Austria, Belgium and Italy. Especially hard hit is Poland, where the mercury fell at times to -30°C. […] In total the cold wave in January has claimed so far about 50 victims, since November the number is close to 70 people.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The most vulnerable unable to afford heat
Moreover it appears that Europe’s socialist, compassionate systems aren’t really doing their job of helping society’s weakest. Die Welt comments that “pensioners, the unemployed and the homeless often cannot afford heating” and thus are the ones paying the price of a low-energy society with their lives.
Die Welt has been reporting regularly on the story, writing four days ago how the cold was claiming the lives of refugees and the homeless.
Cold wave forecast to spread, continue
Unfortunately there is going to be no let up in people freezing to death. The cold and wintry mix will spread across central Europe by the weekend, according to wetteronline.de.
 
Western Europeans need to brace themselves. Image: wetteronline.de
The German weather site writes:

A powerful high over the Baltic Sea and a strong Mediterranean low will flood the continent with Siberian cold air across all of Central Europe next week. Even highs of -10°C are within the range of possibility. […] Temperatures will fall into the cellar. With the exception of coastal areas and maybe northwest Germany, permanent frost conditions will persist for almost the entire week.. In the south high temperatures will range from -10 to -5°C.”

 
Share this...FacebookTwitter "
nan
