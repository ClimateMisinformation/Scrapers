"
Dr. Roger Pielke Sr. has started up his Climate Science blog again, sans comments, as an informational source only. This is some very good news. See his post below.
November 27, 2007: Climate Science Is Relaunching As An Information Source
As a result of very positive encouragement from many Climate Science readers, I have decided to relaunch the website. The format will be different than in the past, however, in that comments will not be permitted. The posting of information will not be on a schedule, but when new information on a climate science issue is available that is otherwise not very visible, or has been misrepresented in the media.
The presentation of climate science in the media, unfortunately, remains biased, as has been documented numerous times on Climate Science. Thus, I have decided to reenter this mechanism of providing information. While comments will not be permitted on the website, guest presentations will be invited when there is value in providing this source of information.
Climate Science will thus provide a source of information on climate that, hopefully, will be useful to others, as part of a much needed effort to provide a balanced view of climate science.
Thanks to those who have found my website of value and take the time to read it!


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea298c767',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"The Pacific yew tree is a fairly small and slow growing conifer native to the Pacific Northwest. The Gila monster is a lizard with striking orange and black markings from the drylands of the Southwestern US and Mexico. Two very different organisms, but with a fascinating connection. They’ve both given us drugs that have saved and improved the lives of millions of people. Paclitaxel, originally isolated in 1971 from the bark of the Pacific Yew tree, is so important for treating various cancers that it is one of the World Health Organisation’s “Essential Medicines”. This compound has been studied in more than 3,000 clinical trials. It’s safe and effective and it generates sales of around US$80-100m per year. Exenatide, a synthetic version of a compound found in the saliva of the Gila monster, is an injected treatment used by as many as two million people with type 2 diabetes. In 2014, exenatide products generated sales of US$767m. Not only that, but exenatide has also been shown to have potential in the treatment of Parkinson’s Disease. These two examples illustrate how significantly compounds sourced from nature can benefit public health, but they also tell a deeper story of how we fail to protect nature. Up until fairly recently, paclitaxel had to be isolated from the bark of wild Pacific yew trees, which meant stripping the bark and killing these rare and slow growing trees.  In 1977, demand for the drug generated an order for 7,000lbs (3,175kg) of bark, which yielded a mere 132 grams of paclitaxel. This demand destroyed 1,500 trees, damaging the native environments in which they grow. This destruction continued until 1994 when chemists came up with a way of synthesising paclitaxel. The production of exenatide does not require the maceration of thousands of Gila monsters, thankfully. However, despite the huge sums generated by the sale of the compound, the delicate habitats where this lizard and countless other species live are threatened by development and climate change. When it comes to discovering medicinal products found in nature, we’ve barely scratched the surface. With every habitat that falls to the chainsaw or disappears under the plough or concrete, we impoverish nature and deprive ourselves of potential medicines.  The molecular diversity of life on Earth is effectively limitless, but it is under threat. Conservative estimates suggest that we are losing one important drug every two years because of our onslaught on the natural world.  Perversely, this onslaught comes amid a new golden age of discovery. Tools, such as DNA sequencing, can reveal “new” species hiding in plain sight, while advances in mass spectrometry, genomics and genetic engineering have allowed us to harness their molecular diversity without excessive harvesting of wild specimens. Although the potential of natural products is undisputed, the enormous amount of effort and resources required to bring a promising molecule to market is offputting. Not only that, but unscrupulous “bioprospectors” have illegally collected living material, often from developing countries. These predatory practices prompted legislation that now hinders legitimate natural products research that seeks to protect biodiversity.  


      Read more:
      Drugs from bugs: the next blockbuster medicine could be lurking inside an insect


 Magainin was the first anti-microbial protein discovered in an organism, isolated from the skin secretions of the African clawed frog. The discovery stems from the observation that surgical wounds on these frogs rarely become infected despite non-sterile procedures and conditions. Efforts to commercialise this molecule were mired in difficulties and today, despite the promise of a potentially transformative drug to treat infections, no magainin products are available. Natural products give us a compelling angle for the protection of overlooked species and their habitats, but we need an ethical and transparent approach for developing them. To some extent, this is the goal of the Convention on Biological Diversity and the Nagoya Protocol – international agreements on sharing the benefits derived from biodiversity fairly.  But as a result of these treaties, the academics working to find new drugs in nature must meet the same regulatory requirements as companies with commercial intent. Extensive permitting requirements mean many academic scientists are avoiding international collaborations to study biodiversity altogether – hampering the discovery of new molecules.  Governments need to support research efforts and collaboration between scientific disciplines such as ecology and biochemistry, with investment and infrastructure. Building trust with communities that live where natural products are sourced is also critical. These steps could create a system of natural product research and development with a greater appreciation of nature’s value. Ultimately, the equal sharing of benefits derived from drug discoveries will help conserve nature. However, the clock is ticking and with every day that passes species and their unique chemistry are lost forever. Nature is a public library of information waiting to be accessed. The science, technology and political will to read this library is being ignored while destruction continues and companies hoard resources that have been harnessed from nature for profit. We are destroying the best library in the world in order to build a writer’s workshop, open only to the few."
"
One of the most surprising things I’ve learned from the surfacestations.org project is that for some odd reason, there are a number of climate monitoring stations of record in the USA at sewage treatment plants. If you’ve ever driven by one of these in the wintertime, they tend to look like steam saunas. They are localized heat bubbles from the waste-water processing.
At Orangeburg, SC not only is the official USHCN climate station of record at a sewage treatment plant, it’s also a nonstandard thermometer (a climate station normally looks like this), and strapped to the side of a telephone pole. I don’t know about you, but experience with creosote treated telephone poles tells me that they’d tend to create a hotter local measurement environment.

Photo by www.surfacestations.org volunteer surveyor Don Kostuch. See the complete image gallery here.
Then there’s the brick building to radiate heat at night, the asphalt parking lot, the effluent channel running nearby, and the overall sewage treatment plant waste heat to consider. I doubt there is an easily applicable set of equations which can untangle the myriad of potential microsite biases.
Then there’s sewage. As population growth occurs, sewage plants add more vats and equipment to handle the increased volume. The increased volume of effluent loses some of it’s heat at this location during the purification process.

Click graph for larger version, data from NASA GISS
The real question is: What are we actually measuring at this location? Are we measuring temperature as an indicator of climate change or are we measuring waste heat from increases in sewage processing that mirrors local population growth?
UPDATE and CORRECTION:
I made an error, this is not a sewage treatment plant. It does treat water, and the description in the site survey from the surveyor was “water filtration plant” which I mistook to mean “sewage treatment” since so many other locations have been at sewage treatment facilities. For example, one of the worst is Titusville, FL, which has been highlighted in this blog in Part 31 and also surveyed by the same volunteer. I looked at the photos he provided, and did not discern initially that the tanks were not for sewage treatment.  Some sharp eyed readers have pointed out the identification problem, which I’m happy to correct.
The questions about the validity of the temperature measurement environment in the midst of a sewage treatment plant are still valid, but do not apply to this location.  So the question we now have for this location is; do the large water filtration pools on this site provide an evaporative cooling effect or do they release heat?
The water vapor impacts at the facility are likely a factor, possibly for Tmin overnight, which is more prone to such effects. Note that there has been new construction at this location, and given the apparently new water filtration pools added on site, there may still be an effect of measuring the local population increases by proxy.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea279d29e',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

The _Washington Post_ recently ran a shocking above‐​the‐​fold article warning us of “Escalating Ice Loss Found in Antarctica.” A new paper by Eric Rignot of NASA’s Jet Propulsion Laboratory shows a net loss of ice where most scientists thought the opposite would occur.



The _Post_ went full‐​bore with this one, spreading the article on to an entire interior page. The piece ends by noting that Rajenda Pachauri, head of the United Nations’ Intergovernmental Panel on Climate Change (IPCC), is so concerned that he’s is personally going down to inspect the situation.



He should. Before he even gets to Antarctica, Pachauri is going to see something even more surprising than Rignot’s finding. Despite a warming Southern Ocean, the amount of ice surrounding Antarctica is now at the highest level ever measured for this time of the year, since satellites first began to monitor it almost thirty years ago. This represents a continuation of the record set last winter (our summer).



Thanks to the miracles of modern technology, we can also look at the departure from the average for ice mass in a given month. At present, the coverage of ice surrounding Antarctica is almost exactly two million square miles above where it is historically supposed to be at this time of year. It’s farther above normal than it has ever been for any month in climatologic records. Around now, because it’s summer down there and the ice is headed towards its annual low point, there should be about seven million square miles of it. That means, as data in University of Illinois’ web publication Cryosphere Today shows, that there is nearly 30% more ice down in Antarctica than usual for this time of the year.



All of the IPCC’s models of Antarctica in the 21st century forecast a gain in ice, as a warmer surrounding ocean evaporates more water, which subsequently falls in the form of snow when it hits the continent. It’s simply too cold for rain in Antarctica, and it’ll stay that way for a very long time.



Concerning Antarctica as a whole, the IPCC’s new climate compendium notes “the lack of warming reflected in atmospheric temperatures averaged across the region.” Other studies, such as Peter Doran’s in _Nature_ in 2003, show actual cooling in recent decades. (There is a small area of significant warming in the peninsula that points towards South America, but this is less than 2% of Antarctica’s total land mass.)



There’s brand new evidence, just published in mid‐​January in _Geophysical Research Letters_ , of a striking increase in snowfall over that peninsula. The few snowfall records that are available elsewhere in Antarctica show considerable variation from decade to decade, so discriminating the “signal” of increased snowfall caused by global warming from all the rest of the “noise” may be very difficult indeed.



We see the same problem with hurricanes and global warming. Their strength and numbers vary considerably from year to year. 2005 was the most active year ever measured in the Atlantic Basin, while 2007 was one of the weakest in history. How do you find the fingerprint of global warming amidst such variation?



So it’s not warming up, and the snowfall data are equivocal, yet the continent is experiencing a net loss of ice. How can this be, and is it even important? The current hypothesis is that warmer waters beneath the surface are somehow loosening the ice. That’s plausible, but again, there’s precious little proof of it.



And further, the bottom line is that there is more ice than ever surrounding Antarctica.



One of the tired tropes that reverberate throughout global warming reporting is that inconvenient facts get left out. In this case, it’s blatant. Midway through the _Post_ ’s page‐​long article comes a statement that “these new findings come as the Arctic is losing ice at a dramatic rate.” Wouldn’t that have been an appropriate place to note that, despite a small recent loss of ice from the Antarctic landmass, the ice field surrounding Antarctica is now larger than ever measured?
"
"The average family throws away about £700 worth of food each year. This is not just a drain on our finances, but also has significant environmental impacts – both in terms of production and waste management – and Christmas is no different. A report by Unilever said that each year in the UK the equivalent of 4m Christmas dinners are wasted – the equivalent to 2m turkeys, 74m mince pies and 5m Christmas puddings. And that is before you consider the before and after Christmas buffets, teas and food from other social gatherings. Research from Loughborough University explored the reasons behind all of this consumer food waste. It is not inherently anybody’s fault, but a symptom of the way that the UK’s food provisioning system has evolved. And it turns out that many of the reasons are solvable. With this in mind, here are some practical approaches that you can take to reduce your food waste this Christmas (and the rest of the year), which will also save you money and reduce your carbon footprint. The primary reason for food waste is overbuying. If you are having a large Christmas gathering, plan how much food you will need for the number people attending. Don’t buy extra just in case: you are very unlikely to have too little.  If you feel it absolutely essential to keep some food in reserve, then make sure you buy food that will keep longer. Serve your short shelf life food first, and then if it is eaten, bring out the longer life food – when the prawn ring runs out, bring out the cheese and crackers. Before you even set foot in the supermarket (real or online) make sure that you write your shopping list. Then stick to it. Don’t get drawn in by buy–one–get-one-free (BOGOF) or special offers. They are not normally as good a deal as you think and you will buy more food than you need. You will likely end up wasting it, or consuming too much. Either way, there’s no benefit. When buying meat or dairy or other fresh products, be conscious of “use by” dates. Make sure the food you buy will still be good to eat when you plan to eat it. These dates are an important indicator for when food may become harmful to eat due to bacteria growth. You do not want to get your turkey curry buffet and find that your raita sauce is not safe to eat. Do not however confuse “use by dates” with “best before dates”. Best before dates are a rough guide to indicate when food might have gone past its best, but they are very conservative and for most foods, quite unnecessary. In most countries, best before dates do not exist. Assuming the food is not several years old, it is likely to be perfectly safe to eat and still delicious long past its best before date. We should reinstate common sense in determining when food is good to eat or not. Most fruit, vegetables and cooked meats will last longer if stored in their packaging and in the fridge, so you should keep them there. A full festive fruit bowl might look good, but you are likely to end up throwing items away which have gone past their best. Partially consumed refrigerated items should be placed in a reusable, resealable tub and put back in the fridge. Refrigeration slows down the growth of bacteria and will therefore keep your food edible for longer. But there are certain foods that don’t fare so well in the fridge, such as bananas, avocados, cake and melon. So it’s worth checking to get the most out of your food. It might sound like common sense, but take time to consider how much people might want to eat and cook that amount. Don’t cook extra, it will not only take longer, but it will also cost you more and it won’t get eaten. Many people end up leaving food on the plate. So think about the right amount for a nice meal, not to force your guests to over-consume and struggle with indigestion from those three extra roast potatoes and two pigs in blankets. Christmas may be about feasting, but it is not about gluttony. Despite your best efforts, there may be some food remaining. Make sure you cover it and once cooled store it in the fridge rather than leaving it to fester on the counter top. To me “leftovers” is a dirty word. They are not leftovers, they are delicious ingredients for your next meal. If you really have too much, invite some friends around and get them to help you eat it. They will thank you for it and you will have a better Christmas. Most importantly, once you have tried these easy approaches to reducing food waste, continue to use them. You will be sure to save money – and help save the planet at the same time."
"The UK foreign secretary, Dominic Raab, has called on Australia to work with other countries to bring down carbon pollution as it works towards the “challenge” of achieving net zero emissions by 2050. Raab, who met with Australia’s foreign affairs minister Marise Payne on Thursday, said the pair had a “good constructive conversation” about Britain’s goal to reduce emissions as it prepared to host the United Nations climate summit, COP26, in Glasgow later this year.  The visit to Australia is the first overseas visit for the UK foreign secretary since Britain officially exited the European Union six days ago. When asked about Australia’s policy record on climate change, which was a “politically contentious” issue in the wake of the summer bushfire crisis, Raab said the UK’s approach was to “try to make a success” of COP26. He said Britain wanted a “step change” in the international response to climate change, which he described as the “challenge of our times”. “We are going to talk to all the countries about their contributions in getting emissions down,” Raab said. “I think there is an exciting opportunity, there is a challenge but there is also an opportunity, and we are want to lead in rising to that challenge and we have had a really good conversation about it today.” He said there was potential for Australia and the UK to be “natural collaborators” on reducing carbon emissions, naming the greening of financial services and “technical cooperation” as possible areas. While he declined to comment on whether more ambitious climate policy would be a requirement of the post-Brexit free trade agreement to be signed between Australia and the UK, he said Britain was looking for a “team effort right across the board”. “We hope to be leading by example with our commitment to get emissions down to net zero by 2050 but there is a whole range of other things that we need to talk about and what we have got to try to do is make it a win-win,” he said. “It is a huge challenge … but we have got, and I know that Australia has got, the innovators, the entrepreneurs who can come up with green technology which can help find a way forward. “We have had a really good constructive conversation about it and we will continue that conversation with our Australian friends, but also all of the other big players in that debate.” Payne said in the lead-up to COP26, the Australian government would be looking at what “practical climate action we can take together”. Raab was also due to meet with the prime minister, Scott Morrison, on Thursday afternoon. Morrison has refused to back the goal of net zero emissions by 2050, despite signing on to a communique at the Pacific Islands Forum that committed to develop a 2050 strategy this year. Following calls from the UK prime minister, Boris Johnson, for other countries to join Britain in striving for net-zero 2050 target, Morrison said the Australian government would not adopt policies that were about “putting taxes on people, putting their electricity prices up or driving industries out of regional areas”. “I would never make a commitment like that if I couldn’t tell the Australian people what it would cost them,” Morrison said. The prime minister is under pressure from within his own party room to increase the government’s climate change action, but moderate MPs are facing pushback from conservatives. On Thursday, Morrison was asked how he would balance a proposed transition to cleaner energy with calls from Queensland Nationals MPs to build new coal-fired power stations and retrofit existing coal plants to reduce emissions. The prime minister said the government had adopted a “common sense position” that recognised that the reliability of Australia’s electricity system depended on coal. “It understands the need for the maintenance and sweating of those assets which are providing reliability to the system,” Morrison said. “And where those types of assets in the future can be developed in the way that would be required under the environmental standards, then that’s not ruled out either. So it’s common sense. It’s a common sense, well-balanced policy. And I think that embraces everybody, not just in the Liberal party room, but right across the Coalition.” When asked if this meant the government could use taxpayer funds to retrofit existing coal-fired power stations to reduce emissions, Morrison left the option open. “We work with all the energy companies because we know that we don’t want to force people’s power prices up and we don’t want to see a loss of capacity out of the system that is unnecessary. And so we take all of these decisions in the national interest.”"
"

On May 28, Ali Larijani, former nuclear negotiator and close confidant of Iran’s Supreme Leader Ali Khamene’i, won the position of speaker of the Majlis, Iran’s parliament. Larijani is a member of the mainline conservative faction in Iran — which is different from the more radical faction led by President Mahmoud Ahmadinejad. (Iranian political observers have aptly borrowed the American term “neoconservative” to refer to the Ahmadinejad faction.)



Larijani’s rise was the first of a series of political changes in Iran. At about this time next year, Iran will hold a presidential election. Its outcome could depend, in part, on the outcome of the 2008 elections here in the United States. Given the serious disputes between the two countries and the prospect of another war in the Middle East, Americans — and American presidential candidates — should take a moment to think about how our election could influence Iran’s.





Despite soaring oil prices, Iran’s economy is in shambles. 



(Obligatory “to be sure” qualifier: Iranian elections are by no means free or perfect. Candidates for office in Iran can be approved or barred from running based on the whims of the clerical leadership. Even so, they reflect the direction of the political winds within the country’s controlled political climate.)



In the years preceding the last Iranian presidential election, which produced Ahmadinejad, American neoconservatives repeatedly minimized the differences between members of the Iranian leadership. Michael Rubin, for example, told _National Review_ readers in 2002 that then‐​President Mohammed Khatami was “neither a reformer nor a democrat” but rather “a fraud.” President Bush subsequently slotted Iran into the Axis of Evil and settled in for an indefinite occupation of neighboring Iraq, making little effort to reach out to Khatami’s government and spurning its offer of negotiations. What Rubin, Bush, and others failed to grasp was that, despite Khatami’s faults, things could get worse.



And get worse they did. During his 2005 campaign for the presidency, Ahmadinejad did not emphasize foreign policy, focusing instead on economic populism. Still, a vote for Ahmadinejad, a former member of the Islamic Revolutionary Guard Corps, was widely viewed as a vote for confronting America. And Ahmadinejad wasted no time proving that view right, from his “world without Zionism” conference to his flamboyant defiance of the United States.



In recent months, by contrast, Khatami has been busy making biting reformist speeches throughout Iran. In Tehran in March: “People want freedom … Freedom means people be allowed to question the ruling system and change it without use of force if the establishment doesn’t respond to their demands.” In Gilan in May: “What did the imam [the founder of the Islamic revolution, Ruhollah Khomeini] mean by exporting the revolution? Did he mean that we take up arms, that we blow up places in other nations and we create groups in other countries to carry out sabotage in other countries? The imam was vehemently against this and was confronting it.”



Disparaging Khatami and convincing ourselves that there is no difference between him and Ahmadinejad is foolish and counterproductive. Unless we want war or a nuclear‐​capable Iran, America needs a negotiating partner, and so much the better if he is similar to Khatami — or even Larijani — rather than Ahmadinejad.



Now, mercifully, the economic demagoguery of Ahmadinejad and his compatriots has been shown to be a disaster. Despite soaring oil prices, Iran’s economy is in shambles. But if anything can save the hardliners from the consequence of their own bumbling stewardship of the economy it is a vague sense that war with America looms just over the horizon. As early as January 2006, Ahmadinejad’s economic policies were wreaking havoc, but as one legislator critical of the president pointed out, “as the [foreign] pressure has increased, the safety margins for him to operate have widened.”



And so it may be in the coming presidential elections. In all likelihood, Iran’s neoconservatives will blame their economic woes — in the mold of Fidel Castro — on the American Colossus, which stands athwart Iranian development.



But there are even bigger prizes than the presidency in Iran. The aptly named position of supreme leader — the ultimate center of power in Iran — eventually will be at stake, and probably sooner rather than later. The current supreme leader, Ali Khamene’i, has been in office since 1989 and will be 69 years old this summer. Speculation about his health has been a parlor game in both Tehran and Washington.



While there are a number of potential candidates to replace him, one, Mohammed Taqi Mesbah‐​Yazdi, is the clerical equivalent of Ahmadinejad and a close spiritual adviser to the firebrand president. Should the international environment remain as poisonous as it is today, it is possible to envision the Assembly of Experts (a body of clerics that selects the Supreme Leader) selecting a hardliner such as Mr. Mesbah‐​Yazdi as Supreme Leader, which would be a hugely negative development in terms of U.S.-Iran relations.



Which man Americans select as their president will likely have a meaningful effect on U.S. foreign policy and on U.S.-Iran relations particularly. He could also have an effect on the nature of the next generation of Iran’s political leadership. One U.S. candidate has sung a song on the campaign trail about bombing Iran, and the other has called for lowering the temperature and making a forthright effort to negotiate.



There is no immutable law of politics that says moderation on one side will lead to moderation on the other. At the same time, it is difficult to see how electing a man wedded to the most wild‐​eyed neoconservative vision of foreign policy would cause Iranians to select more temperate leaders.



Either way, Americans’ choice could influence the nature of the next generation of Iran’s leaders — and with it, the contours of U.S.-Iran relations for decades. With so many Americans ruing the war in Iraq, they would be well‐​advised to consider the prospect of war in Iran, and what they can do to influence whether or not such a war comes to pass.
"
"The inauguration of Brazil’s new president, Jair Bolsonaro, has triggered fears that rates of deforestation in the Amazon will increase. There are indeed good reasons for concern about Bolsonaro’s administration. But several factors, both domestic and transnational, could constrain its ability to wreak environmental damage. First, some bad news: Bolsonaro and his cabinet do seem to view environmental concerns as an obstacle to development. For instance, the new environment minister, Ricardo Salles, said that the debate over climate change was a “secondary issue” and was recently convicted in court of fraudulently favouring mining companies when he was state secretary for the environment in São Paulo. Under Salles’ leadership, the ministry will probably suffer budget cuts, and it has already lost key departments.  Furthermore, Bolsonaro has said he wants to restrict the ability of IBAMA, the forest protection agency, to fine individuals and companies that illegally deforest and pollute. And, while the rate of deforestation in the Brazilian Amazon fell overall by roughly 75% between 2004 and 2017, it has gone back up again even before Bolsonaro took office. Between August 2017 and July 2018, deforestation increased by an estimated 13.7%.  Bolsonaro also recently tweeted that he wants to free Brazilian agribusiness from dependence on imported fertiliser (75% comes from abroad). However, mining the ingredients in Brazil could do further environmental damage. For example, the largest recently discovered deposit of potassium, used to make fertiliser, is on the banks of the River Madeira in the Amazon. The new president also appears to favour more dam-building (there are proposals to build 334 dams in the Amazon). He also backed away from the previous commitment of the Brazilian government to host the next UN climate conference later this year. And, on his first day in office, Bolsonaro signed a provisional measure transferring authority to demarcate indigenous lands from the justice  ministry to the agriculture ministry, thereby making it highly likely that – as he promised – no new indigenous reserves will be created on his watch.  Bolsonaro does face some constraints. The new president speaks as if agribusiness and the protection of the environment are incompatible – and appears to want to sacrifice the environment for farming, mining and logging. But other voices will have a say, and at least some heed will be given to the view that sustainable agriculture which preserves biodiversity is better both for Brazil’s development prospects and for the world’s climate. Before his inauguration, Bolsonaro said that he wanted to subordinate the environment ministry to the agriculture ministry. He was persuaded to drop this idea, due in part to criticisms from environmental NGOs and federal civil servants in environmental agencies. Some agricultural interests even spoke out, because they fear that their international image and access to markets, especially the European Union, could be damaged by being associated with deforestation. Brazil also has an environmental movement that is as old as its counterparts in Europe and North America. It was the strength of this movement that ensured the country’s 1988 constitution has several ecological safeguards in place, including conservation areas, indigenous reserves and the environmental licensing system. José Lutzenberger, an environmental pioneer and former environment minister, helped to organise the Eco 92 conference in Rio and demarcate the huge Yanomami indigenous reserve.  The Rio conference was part of a process that eventually led to the 2015 Paris Agreement, where Brazilian participation was important. And, in his last days in office, outgoing president Michel Temer delivered a report to his successor that recommended that Brazil stay in the Paris Agreement and pursue the goal of achieving a zero-carbon economy by 2060. External actors can also pressure the Bolsonaro administration. For example, the government of Norway has contributed 93% of the money disbursed by the Amazon Fund to 102 different projects, amounting to hundreds of millions of dollars. These funds provide incentives to enforce environmental laws and create sustainable livelihoods in the rainforest.  Norway’s contributions are tied to maintaining rates of deforestation to specified limits, a fact Temer was reminded of by his hosts on a visit to Oslo in June 2017. The Bolsonaro administration is likely to move quietly to achieve some of its objectives. In addition to weakening the environment ministry it could informally signal to state governors and congressional delegations that the laws regarding deforestation will no longer be rigorously enforced. Observers therefore have to be attentive to facts on the ground. Civil society organisations and journalists in the Amazon working for publications such as InfoAmazonia and O Eco are particularly good sources of information. There is some transnational support for these journalists. For example, the Pulitzer Centre is administering a Rainforest Journalism Fund, financed by the Norwegian government, which gives grants to journalists reporting on deforestation. Brazil’s foreign minister Ernesto Araújo claims that initiatives such as the 2015 Paris Agreement are liberal, “globalist” and part of a gigantic “cultural Marxist” propaganda machine. From this perspective, international NGOs and foreign states are violating Brazilian sovereignty by interfering in the Amazon.  But this is a smokescreen. In the Paris Agreement the Brazilian government voluntarily committed to reduce its greenhouse gas emissions by 37% by 2025 and 43% by 2030, with 2005 as the baseline year. The Brazilian Climate Change Forum that produced this commitment had input from 340 different government entities, businesses, NGOs, and academics. And the country already has various advantages when it comes to making the transition to a low-carbon economy, including relatively clean energy and 60m hectares of degraded pasture land that could be reforested.  Preserving the Amazon rainforest is of fundamental importance to the planet, and there are many people in Brazil who want to do that. They reject the notion that development and environmental protection are mutually exclusive, and support reorienting the Amazonian economy towards sustainable livelihoods. It remains to be seen whether their vision will prevail in the years to come."
"Tackling climate change will require huge changes in society. Decarbonising energy, restoring habitat and making food supply sustainable are all critical, but methods for motivating these actions have typically taken the wrong approach – by highlighting the urgency of the issues and the disastrous consequences of failing to act. Research increasingly suggests that trying to promote behavioural change through fear can be counterproductive, leading to anxiety or depression that results in an issue being avoided, denied or met with a sense of helplessness. However, in education, news and fiction, stories with positive role models and which focus on the positive outcomes of solutions are much more likely to inspire action to solve it. I set out to explore the impact of such stories. As part of my research, 91 volunteers were given two stories to read, each concerned with the negative impacts of climate change: one about a woman caught in a flood and the other set at the end of the world.  The same readers were also exposed to two positive stories: one about a terrorist planting a flower bomb, which populates a bare area with flowers, the other about a young boy who, having watched Blue Planet, takes to collecting plastic to stop it entering the oceans – starting with his fish tank. Afterwards the readers were asked how the stories made them feel and to reflect on what kinds of behaviours they inspired. While the negative stories motivated action for a few, most said they were discouraged. “I’d rather not think about it,” said one. “It made me angry and I switched off,” said another. Many also reported a sense of passive despair. “I felt hopelessness. If indeed, the heavy rain was caused by climate change, what can we do about it?”  However, there were no signs of avoidance among readers of the positive stories. “It made me want to flower bomb land and do something positive and I felt happier after reading it,” said one reader.  “I felt inspired by the way the characters behaved … [the story] made me think about what I could do.” This is concerning because almost all stories set in the future, whether in books, films or TV shows, are dystopian. The popular TV show Black Mirror tells cautionary tales about modern life and technology with often terrifying consequences. These stories elicit anxiety, pessimism and a feeling of passive fatalism.  I realised from my research that we desperately need cultural offerings with positive visions of what a sustainable society might look like, to inspire hope and positive change. The University of Southampton runs writing competitions that ask people to read about green solutions and integrate them into stories. These ideas include replacing how much people buy, represented as GDP – the current measure of how successful society is – with a measure of well-being. Another looks at the potential of a “sharing economy”, in which more people borrow goods others have without needing to buy more themselves. It can be hard for politicians to support green policies such as these when green issues evoke catastrophe in the minds of voters they’d rather not think about. Reframing issues in terms of their solutions and highlighting them through engaging characters and stories might be a more effective way to encourage change. One winning short story was Come Help Me by Nancy Lord – a romance about an American fisherman and a Russian marine scientist. The protagonist is inspirational and proactive: he spots a tension between the scientists concerned with the marine environment and the fisherman who needs to make a living. The writer finds a way to help them work together. We also loved the runner up, The Buildings are Singing, by Adrian Ellis, which made us laugh out loud.  This short story imagines a future world where buildings are alive – covered with photosynthesising plants which create energy, light and shade for the occupants. The flora operates an artificial intelligence system which helps occupants live sustainably. Insects drawn to the foliage become nourishing protein bars and life for the humans is low carbon and almost utopian – unless you do something wrong.  Some stories are specifically about sustainable societies, whereas others showcase ideas that would seem radical in otherwise familiar tales, such as Just in Case, which imagines a society where we borrow rather than buy much of our stuff. The woman who runs the “library of things” in the story, plays matchmaker with two customers who she can tell are compatible by their borrowing patterns. The transition to a sustainable society requires profound changes, but to imagine how all of these aspects can come together is currently the domain of creative fiction. If we want a better world then the first step is to imagine one."
"

Representatives of some 160 nations are gathered in Kyoto, Japan, this week to negotiate an international treaty to control emissions of greenhouse gases. While the summit has all the trappings of a substantive event, the gathering in Kyoto is more an exercise in public relations than in serious statecraft. Hot air, rather than cold reason, will dominate the conference and political sleight of hand will be its product. 



That’s because, according to the International Panel on Climate Change (the United Nation’s body of experts devoted to the study of global warming and known as the IPCC), even the most aggressive and costly proposals on the table this week would shave only a fraction of a degree off temperature increases projected by computer models for the year 2100. To achieve those emissions reductions, each American would have to pay an additional $1,000-$3,000 annually in higher energy prices. Such proposals would, according to Yale economist and sometime Clinton adviser William Nordhaus, take us back to the days of semipermanent energy crises like those of the 1970s. Both greenhouse alarmists and skeptics agree that actually preventing the global warming projected by computer models would require the world to reduce carbon dioxide emissions by between 60 percent and 80 percent. Only by virtually abandoning the use of oil, gas and coal could we achieve such reductions. President Clinton’s assurances about “free lunch” climate change policies notwithstanding, nobody is proposing any real policy to prevent climate change because no one wants to usher in a permanent global depression. 



The idea, then, is to get the world to commit to a slow‐​motion control policy, one that would ease us into higher energy costs, a reordered industrial world and, as National Public Radio reporter Richard Harris puts it, “a whole new society” structured around less energy use. 



But if the computer models are correct about global climate change (the data thus far are inconclusive), what choice do we have? Isn’t it prudent to hedge our bets now with a control strategy in order to avoid far more costly economic crash planning later? Well, no. All indications are that the “cure” for global warming is far worse than the “disease” of rising temperatures. 



First, only about 2 percent of America’s economy is sensitive to weather conditions. No matter how ruinous climate change might be, it couldn’t possibly have a serious long‐​term impact on the United States. Even the most alarmist projections of ocean rise (about 3 feet or so) are trivial. If Amsterdam could figure out a way to hold back an even larger sea rise hundreds of years ago, it’s clear a wealthier and more technologically advanced United States could counter a 3‐​foot rise. Foreign aid to help poorer countries adopt would be far less expensive than control policies. 



Second, it’s not altogether clear that a warmer world would be a less habitable world. A temperature rise of 4.5 degrees Fahrenheit (the median computer‐​predicted result of a doubling of atmospheric carbon dioxide in the next 100 years) was exactly what occurred about a thousand years ago (A.D. 850‑1300) in a period climatologists refer to as “the little climate optimum” (note that they don’t refer to it as “the little climate hell”). The result? A longer growing season, rapid economic development, a minor cultural renaissance, an expansion of fertile crop and forestland and a decrease in mortality rates.



Since the data indicate that the small amount of warming we have detected over the last 100 years has largely been confined to winter evenings in the far northern latitudes, we have every reason — both empirical and theoretical — to believe warming would be a benign, not a deleterious, event. 



There are still open questions about how much if anything man has had to do with the slight warming detected over the past 100 years and how much warming might eventually occur (the IPCC estimates range from insignificant to moderately significant). The IPCC report itself states it will be another decade or so before scientists will know for certain. So why not wait? Nature magazine reported last year that waiting 20 years for better scientific information before acting will only cost us .36 degree Fahrenheit, at worst, over the next 100 years. 



In the face of this kind of uncertainty, the best “insurance policy” we could buy is one that increases the amount of wealth at society’s disposal to handle whatever problems might occur in the decades to come. Impoverishing society today to avoid a very uncertain problem tomorrow would harm, not help, future generations.
"
"
Note: This is my analysis of a new paper by Joe D’Aleo, I’ve tried to simplify and explain certain terms where possible so that  it can reach the broadest audience of readers. You can read the entire paper here.
Joe D’Aleo, an AMS Certified Consulting Meteorologist, one of the founders of The Weather Channel and who operates the website ICECAP took it upon himself to do an analysis of the newly released USHCN2 surface temperature data set and compare it against measured trends of CO2, Pacific Decadal Oscillation, and Solar Irradiance. to see which one matched better.
It’s a simple experiment; compare the trends by running an R2 correlation on the different data sets. The result is a coefficient of determination that tells you how well the trend curves match. When the correlation is 1.0, you have a perfect match between two curves. The lower the number, the lower the trend correlation.



Understanding R2 correlation



R2 Coefficient
Match between data trends


1.0
Perfect


.90
Good


.50
Fair


.25
Poor


 0 or negative
no match at all


If CO2 is the main driver of climate change this last century, it stands to reason that the trend of surface temperatures would follow the trend of CO2, and thus the R2 correlation between the two trends would be high. Since NCDC has recently released the new USHCN2 data set for surface temperatures, which promises improved detection and removal of false trends introduced by change points in the data, such as station moves, it seemed like an opportune time to test the correlation.
At the same time,  R2 correlation tests were run on other possible drivers of climate; Pacific Decadal Oscillation (PDO), Atlantic Multidecadal Oscillation (AMO), and Total Solar Irradiance (TSI).
First lets look at the surface temperature record. Here we see the familiar plot of temperature over the last century as it has been plotted by NASA GISS:
 
The temperature trend is unmistakeably upwards, and the change over the last century is about +0.8°C. 
Now lets look at the familiar carbon dioxide graph, known as the Keeling Curve, which plots atmospheric CO2 concentration measure at the Mauna Loa Observatory:


CDIAC (Carbon Dioxide Information Analysis Center – Oak Ridge National Lab) also has a data set for this that includes CO2 data back to the last century (1895) extracted from ice core samples.  That CO2 data set was plotted against the new USHCN2 surface temperature data as shown below:


A comparison of the 11year running mean of the USHCN version 2 annual mean temperatures with the running mean of CO2 from CDIAC. An r-squared of 0.44 was found.
The results were striking to say the least. An R2 correlation of only 0.44 was determined, placing it between fair and poor in the fit between the two data sets.

Now lets look at other potential drivers of climate,  TSI and PDO.
Scafetta and West (2007) have suggested that the total solar irradiance (TSI) is a good proxy for the total solar effect which may be responsible for at least 50% of the warming since 1900. To test it, again the same R2 correlation was run on the two data sets.

In this case, the correlation of TSI to the surface temperature record is better than with CO2, producing an R2 correlation of 0.57 which is between fair and good.
Finally. Joe ran the R2 correlation test on PDO, the Pacfic Decadal Oscillation. He writes:
We know both the Pacific and Atlantic undergo multidecadal cycles the order of 50 to 70 years. In the Pacific this cycle is called the Pacific Decadal Oscillation. A warm Pacific (positive PDO Index) as we found from 1922 to 1947 and again 1977 to 1997 has been found to be accompanied by more El Ninos, while a cool Pacific more La Ninas (in both cases a frequency difference of close to a factor of 2). Since El Ninos have been shown to lead to global warming and La Ninas global cooling, this should have an affect on annual mean temperature trends in North America.
This PDO and TSI to surface temperature connection has also been pointed out in previous post I made here, for former California State Climatologist, Jim Goodridge. PDO affects the USA more than the Atlantic cycle (AMO) because we have prevailing westerly wind flow.
Here is how Joe did the data correlation:

Since the warm modes of the PDO and AMO both favor warming and their cold modes cooling, I though the sum of the two may provide a useful index of ocean induced warming for the hemisphere (and US). I standardized the two data bases and summed them and correlated with the USHCN data, again using a 11 point smoothing as with the CO2 and TSI. 
This was the jackpot correlation with the highest value of r-squared (0.83!!!). 


An R2 correlation of 0.83 would be considered “good”. This indicates that PDO and our surface temperature is more closely tied together than Co2 to surface temperature by almost a factor of 2.
But he didn’t stop there. He also looked at the last decade where it has been commonly opined that the Top 11 Warmest Years On Record Have All Been In Last 13 Years to see how well the correlation was in the last decade:

Since temperatures have stabilized in the last decade, we looked at the correlation of the CO2 with HCSN data. Greenhouse theory and models predict an accelerated warming with the increasing carbon dioxide. 


Instead, a negative correlation between USHCN and CO2 was found in the last decade with an R or Pearson Coefficient of -0.14, yielding an r-squared of 0.02. 


According to CO2 theory, we should see long term rise of mean temperatures, and while there may be yearly patterns of weather that diminish the effect of the short term, one would expect to see some sort of correlation over a decade. But it appears that with an R2 correlation of only 0.02, there isn’t any match over the past ten years.
As another test, this analysis was also done on Britain’s Hadley Climate Research Unit (CRU) data and MSU’s (John Christy) satellite temperature data:

To ensure that was not just an artifact of the United States data, we did a similar correlation of the CO2 with the CRU global and MSU lower tropospheric monthlies over the same period. We found a similar non existent correlation of just 0.02 for CRU and 0.01 for the MSU over troposphere. 


 So with R2 correlations of .01 and .02 what this shows is that the rising CO2 trend does not match the satellite data either.
Here are the different test correlations in a summary table:

And his conclusion:

Clearly the US annual temperatures over the last century have correlated far better with cycles in the sun and oceans than carbon dioxide. The correlation with carbon dioxide seems to have vanished or even reversed in the last decade. 
Given the recent cooling of the Pacific and Atlantic and rapid decline in solar activity, we might anticipate given these correlations, temperatures to accelerate downwards shortly. 

While this isn’t a “smoking gun” it is as close as anything I’ve seen. Time will give us the qualified answer as we have expectations of a lower Solar Cycle 24 and changes in the Pacific now happening.
References: 
US Temperatures and Climate Factors since 1895 , Joeseph D’Aleo, 2008
Persistence in California Weather Patterns,  Jim Goodridge, 2007
Phenomenological reconstructions of the solar signature in the Northern Hemisphere surface temperature records since 1600  Scafetta and West, 2007
The USHCN Version 2 Serial Monthly Dataset, National Climatic Data Center, 2007


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea177569c',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Boris Johnson has set out his vision for forging a new global consensus on the climate crisis promising “we will crack it”, amid news that he approached former prime minister David Cameron to lead the UK’s preparations for a crucial summit. Johnson has brought forward the UK’s phaseout of diesel and petrol vehicles by five years to 2035, and hastened the phaseout of coal-fired power by a year to 2024. He reaffirmed the UK’s pledge to switch to a net-zero emissions economy by 2050, and urged other nations – without naming any – to do the same. “I hope that we can as a planet and as a community of nations get to net zero within decades,” Johnson said at the COP 26 launch on Tuesday. “We’re going to do it by 2050, we’re setting the pace, I hope everybody will come with us. Let’s make this year the moment when we come together with the courage and the technological ambition to solve manmade climate change and to choose a cleaner and greener future for all our children and grandchildren.” But the troubled start to the UK’s presidency of this year’s crunch UN climate talks with the sacking of Claire O’Neill as COP president has unsettled observers, who are hoping Johnson will play a pivotal role in bringing world leaders together with a new resolve to drastically reduce greenhouse-gas emissions before it is too late. On Tuesday night it emerged that Johnson had approached Cameron to take over from O’Neill but he declined the role. Lord Barker of Battle, who served as an energy and climate change minister under Cameron and is a close friend and ally of the former prime minister, said he understood reports that he was offered the role to be correct. “My understanding is that he felt it was just a little too soon for him personally to come back into a frontline political role,” he told BBC Two’s Newsnight. William Hague was also reported to have been offered it but also declined. The appointment last year of O’Neill as president – the official who will take the leading role in convening and chairing the fortnight-long UN talks, and seeing them through to a deal which will require the consensus of 196 nations – appeared to give the UK a good headstart in the talks. O’Neill was formerly an energy minister in the Department of Business, Energy and Industrial Strategy, below the secretary of state level but with rights to attend Theresa May’s cabinet meetings. She resigned as the MP for Devizes, a staunchly Conservative seat, after taking on the role, saying she wanted to concentrate on the COP presidency. Brexit was also a major factor. O’Neill campaigned to remain in the referendum, and was scathing of hard Brexiters, whom she accused of being “hysterical” and “like jihadis”. She rebelled to vote for a Brexit bill amendment that would give parliament the final say on any deal to leave the EU, though she voted with her party on other legislation. She wished Johnson good luck with Brexit when she gave notice last September, well before a election had been called, that she would not contest the seat again. O’Neill was a surprise choice for the president’s role, but the political turmoil last autumn made her a relatively safe pick: with the government preoccupied with Brexit, and Johnson both struggling to get the general election he wanted and filling the cabinet with pro-Brexit supporters of his leadership campaign, to appoint a serving minister would have been tricky. Other possible candidates included Zac Goldsmith, whose shaky reelection prospects were borne out by his defeat in Richmond, or members of the House of Lords. O’Neill’s experience as a transport minister and energy minister seemed to offer some assurance. However, her record was also spotted. In November 2018 three unions wrote to the Department for Business, Energy and Industrial Strategy to raise allegations of shouting and swearing at civil servants. In her post-sacking letter this week, O’Neill rebuffed those allegations. The Guardian was given mixed reports of her conduct in the UN negotiations by people present. She is said to have created a good impression among some countries, and at some meetings at last December’s climate conference in Madrid. However, she fell out with some senior officials in the UK, and gave conflicting messages about the UK’s position and strategy at the talks. O’Neill’s letter to Johnson also gives clues to the concerns over her conduct. In it, she is strongly critical of the COP structure, rules and bureaucracy, but without showing much awareness of what supporters see as the value of the process – which gives all nations an equal voice, and progresses by consensus – or respect for the negotiators, many of whom have served their governments for decades. “COP is difficult, but you need to understand it and work within it,” said one long-time participant in the UN talks. “The French did [when they led the 2015 Paris agreement].” Another former high-level diplomat and COP veteran said: “A good COP president makes all the difference between success and failure. They direct the negotiations, they play the key role in determining the outcome.” It is also clear, however, that O’Neill has suffered from a lack of support within government, and a lack of focus from the prime minister on the UK’s COP 26 plans. She complained that the cabinet sub-committee on climate, supposed to be chaired by Johnson, has not yet met. The relationship between the COP 26 unit and other government departments is also unclear in parts, and it is not apparent that the Foreign and Commonwealth Office has been pushing climate to the top of the agenda in its embassies around the world, as the French did before Paris. Bedevilling all this has been Brexit. Several NGOs and developing country representatives told the Guardian about serious concerns that the UK could not give COP 26 the attention needed while still working out its new relationships and trade deals. Some observers see a potential conflict of interest, as British diplomats seek at once to gain support for a COP 26 resolution that will require other countries to set out stretching goals on cutting emissions, while also negotiating post-Brexit trade deals. “I am very concerned about how they can play this,” said the head of one international civil society group. “This is a very delicate dance.” Paul Bledsoe, a former climate advisrr to Bill Clinton, said: “Sacking O’Neill and making the post more directly reportable to Number 10 increases the pressure on Johnson to appoint an aggressive climate policy figure, especially one who will actually hold the Chinese and Americans accountable.” With O’Neill’ssacking, climate activists and COP participants are hoping that now Johnson and his government can move on to forge a clear strategy and timetable for gaining the support and buy-in they need from capitals across the world. But they warn that the prime minister is running out of time. “The prime minister has given a very clear and strong message, which is good,” said Lord Stern, the climate economist. “He has made a personal commitment, and that is now crystal clear. Now we need someone in a very senior position to be COP president. The challenge now is to accelerate.” • This article was amended on 6 February 2020 because an earlier version referred to O’Neill’s “resignation letter”. As the article and that letter makes clear, she was sacked from her post."
"

**Presidential Power**   
  
  
Op‐​Ed: “New President Won’t Tame Presidential Power,” by Gene Healy in the _Orange County Register._



After seven years of an administration that has recognized few, if any, limits on executive power, it’s only natural that many people look to the Obama‐​Biden ticket to put the presidency back in its proper constitutional place.



Article: “Obama’s the Candid Candidate on Energy,” by Jerry Taylor and Peter Van Doren in _Forbes._



Sen. Obama’s frank confession about what his climate change policies will mean to electricity consumers is one very good reason why so many conservative and libertarian intellectuals are gravitating toward his candidacy. It’s not that right‐​wing thinkers necessarily endorse his climate change policies. It’s that right‐​wing thinkers are increasingly tired of Republican hypocrisy and make‐​believe policy fights.



Article: “Obama’s Tax Deceptions,” by Alan Reynolds in _National Review Online_. 



Barack Obama famously claims, “I’ll give a tax break to 95% of workers and their families.” The Obama team never explained that figure, because they made it up.…Obama said, “If you work, pay taxes, and make less than $200,000, you’ll get a tax cut.” That too is flatly false. Single workers who make more than $80,000 (or joint returns above $155,000) would not get a tax cut under Obama’s plan.



 __  
  
  
Podcast: “The Obama Agenda: Free Political Speech,” featuring John Samples 
"
nan
"We have just 12 years left to reduce emissions and achieve the Paris Agreement’s highest ambition of limiting warming to 1.5°C.  We have been warned, repeatedly, of the high stakes of our present climate gamble. If we continue on our current course, radical solutions are going to be needed sooner rather than later. Champions of solar radiation management (SRM) say this is the answer we’ve been looking for. SRM techniques cool the planet by reflecting sunlight away from it. The most discussed SRM technique involves continuously injecting tiny reflective particles – most often, sulphur – into the stratosphere to evenly cover the planet and shield us from the sun’s rays. Fleets of drones, or sprayers attached to enormous tethered balloons, could deliver these particles. Spray a little more, and the temperature drops; spray a little less, and the temperature rises.  Unlike the other dominant form of climate engineering, carbon dioxide removal, SRM does not extract greenhouse gases from the atmosphere. Rather, it masks the warming caused by those gases. Advocates say that SRM could give humanity a decent shot at getting its act together on mitigation. They also say the costs of SRM would be a fraction of the costs of the climate impacts we are facing without this technology. However, there are reasons for caution, if not outright scepticism, about the wisdom of this techno-fix for climate change. One important worry relates to who governs research into SRM, given the risks it presents and its seductiveness as a “solution” to the climate crisis. There are some proposed self-regulations by SRM researchers, and more attention is being paid to international governance of SRM research, but a vacuum of governance remains. To fill this vacuum in morally acceptable ways requires establishing governance to address the danger of sleepwalking into SRM “lock-in”, where a society becomes locked-in to a technology that has become too costly to abandon, even though alternative technologies may be better. Once SRM deployment has begun, a status quo bias could quickly establish the new normal of a geoengineered world. It could combine with environmental generational amnesia, a phenomenon where generations of people forget previous environmental states and so don’t notice their deterioration. Those with their hands on the global thermostat – political leaders focused on short electoral cycles, and corporate leaders feeding the bottom line – would be tempted to continuously extend deployment to enable more and more business as usual. Imagine we become locked-in to a permanent geoengineered world in which SRM is being widely used but catastrophic climate change has been avoided. What’s the problem?  One potential big risk of widespread deployment of SRM is something called termination shock, where the technology is abruptly stopped, for example, by war, natural disaster, or sabotage. This would cause temperatures to rise very quickly to reflect the atmospheric concentration of greenhouse gases. If societies are locked into the technology, these speedy rises could be truly catastrophic. Even if SRM were to be used only temporarily, the long atmospheric life of C0₂ means that abrupt termination would still lead to a massive, swift warming effect. SRM deployment is not an insurance policy against climate catastrophe. It creates new and terrible dangers of its own. We must not have a Panglossian view of the protection offered to us by existing institutions and the current global order. There needs to be governance of SRM research now that guards against lock in."
"Most African countries have made strong progress in achieving major development goals in the last few years. Despite this much needed progress, the past decade has seen flooding damage or destroy much of this same infrastructure, affecting millions and killing hundreds every year. In 2018 alone – up to September 15 – based on conservative estimates, flooding across Sub-Saharan Africa has destroyed more than 10,000 homes and affected more than 2m people.  A recent study suggested that floods cost Tanzania US$2 billion annually. In 2012, Nigeria experienced one of its largest floods in a century, destroying assets worth nearly US$10 billion. In Mozambique, one of the poorest countries in the world, floods in 2013 were estimated to cost over US$500m – nearly 9% of GDP. These figures are significant, especially when considering that this money could have been invested in other developmental goals. The simple fact remains that people depend on infrastructure to meet their needs. Without roads, people are not able to sell their goods on the market. School closures disrupt learning for millions of children. Damaged roads and bridges restricts access to health services. The destruction of critical infrastructure such as power and telecommunications leads to untold economic costs. Hectares of destroyed farmland and livestock can be killed. Health emergencies, including cholera outbreaks, can emerge due to poor sanitation and a lack of access to clean water.  These examples highlight the implications of these recent floods for the 17 sustainable development goals (SDGs) set out by the UN.  In Africa, about 3,000 people die daily from diseases linked to poor sanitation, poor hygiene and contaminated water, particularly diarrhoea and malaria. This situation is worsened by flooding, which will make it harder to achieve SDG 6– ensuring access to water and sanitation for all.  In order to lessen the consequences of flooding, African societies must make two major changes. First is to place greater focus on adaptation strategies, alongside mitigation. Before now, most of the efforts across Africa have been “hard” engineered routes to mitigate flood impacts. This means working against rather than with nature, for instance by building dams or embankments.  However, there is now a general recognition that while floods cannot be entirely prevented, steps can be taken to minimise their impact and speed up recovery. Such a shift in thinking may inspire donor agencies, who provide aid or rehabilitation post-flooding, to consider using the same amounts of money to fund flood adaptation initiatives as well.  For instance, after a recent flood in Nakuru county, just north of Nairobi in Kenya, the EU alone provided €1.5m to help flood victims. Such funds can be channelled towards helping communities adapt to flooding and increase their resilience. This would mean, for instance, factoring in current and likely future flood conditions when constructing or managing new infrastructure. A particularly good initiative that incorporated such adaptation strategies was the Makoko floating school. The school is a prototype floating structure, built for the historic water community of Makoko, located on the lagoon heart of Nigeria’s largest city, Lagos. As a pilot project, it has taken an innovative approach to address the community’s social and physical needs in view of the impact of climate change and a rapidly urbanising Africa. More efforts should be channelled towards strengthening and scaling up such initiatives. The second major change is to scale up “soft” non-structural adaptation measures, such as ecosystem-based approaches to flooding. These involve measures which work with the natural flood cycle rather that struggling against it. These solutions include the widening of natural flood plains, planting more trees, protecting and expanding wetlands, and investing in urban green spaces to reduce water run off.   This could be beneficial considering that most African countries do not have sufficient finances to justify the costs of dams and other “hard” engineering. As competing with education and agriculture expenditure priorities is unlikely to end well in such a poor economy, “soft” non-structural adaptation measures may provide a more promising route.  While the increased flooding can be linked to climate change, some of the causes have roots in the destruction of ecosystems. Take, for example, the unprecedented land reclamation projects along the coastal areas of Lagos. The result has been enormous environmental damage because much of what is being drained for housing are coastal wetlands, which are traditionally known for their ability to control flooding. Policy makers often see flooding as a humanitarian issue only – they must be reminded that there is an economic dimension too. There is evidence that ecosystem-based adaptations are helping people, particularly women and children, adapt to climate variability and reduce their vulnerability to climate impacts.  By adopting an ecosystem-based adaptation, a recent study showed how Thua Thien-Hue Province in Vietnam was able to introduce cleaner urban areas with more opportunities for recreational activities, all the while reducing damage to infrastructure. Less damage to properties means smaller repair costs and an overall safer environment, whereas increases in tourism, or recreation suitability, can lead to better employment and business opportunities.  With the impacts of flooding increasingly being felt across Africa, there is an urgent imperative to adapt infrastructure to flood hazards while fostering sustainable economic development on local, national and regional levels. Without this, all the developmental achievements made so far will be completely undone."
"The record-breaking, El Niño-driven global temperatures of 2016 have given climate change deniers a new trope. Why, they ask, hasn’t it since got even hotter? In response to a recent US government report on the impact of climate change, a spokesperson for the science-denying American Enterprise Institute think-tank claimed that “we just had […] the biggest drop in global temperatures that we have had since the 1980s, the biggest in the last 100 years.” These claims are blatantly false: the past two years were two of the three hottest on record, and the drop in temperature from 2016 to 2018 was less than, say, the drop from 1998 (a previous record hot year) to 2000. But, more importantly, these claims use the same kind of misdirection as was used a few years ago about a supposed “pause” in warming lasting from roughly 1998 to 2013. At the time, the alleged pause was cited by many people sceptical about the science of climate change as a reason not to act to reduce greenhouse pollution. US senator and former presidential candidate Ted Cruz frequently argued that this lack of warming undermined dire predictions by scientists about where we’re heading. However, drawing conclusions on short-term trends is ill-advised because what matters to climate change is the decade-to-decade increase in temperatures rather than fluctuations in warming rate over a few years. Indeed, if short periods were suitable for drawing strong conclusions, climate scientists should perhaps now be talking about a “surge” in global warming since 2011, as shown in this figure: The “pause” or “hiatus” in warming of the early 21st century is not just a talking point of think-tanks with radical political agendas. It also features in the scientific literature, including in the most recent report of the Intergovernmental Panel on Climate Change and more than 200 peer-reviewed articles. Research we recently published in Environmental Research Letters addresses two questions about the putative “pause”: first, is there compelling evidence in the temperature data alone of something unusual happening at the start of the 21st century? Second, did the rise in temperature lag behind projections by climate models? In both cases the answer is “no”, but the reasons are interesting. Reconstructing a historical temperature record from instruments designed for other purposes, such as weather forecasting, is not always easy. Several problems have affected temperature estimates for the period since 2000. The first of these was the fact that uneven geographical distribution of weather stations can influence the apparent rate of warming. Other factors include changes in the instruments used to measure ocean temperatures. Most of these factors were known at the time and reported in the scientific literature, but because the magnitudes of the effects were unknown, users of temperature data (from science journalists to IPCC authors) were in a bind when interpreting their results. A more subtle problem arises when we ask whether a fluctuation in the rate of warming is a new phenomena, rather than the kind of variation we expect due to natural fluctuations of the climate system. Different statistical tests are needed to determine whether a phenomena is interesting depending on how the data are chosen. In a nutshell, if you select data based on them being unusual in the first place, then any statistical tests that seemingly confirm their unusual nature give the wrong answer. (The statistical issue here is similar to the fascinating but counterintuitive “Monty Hall problem”, which has caught out many mathematicians). When the statistical test is applied correctly, the apparent slowdown in warming is no more significant than other fluctuations in the rate of warming over the past 40 years. In other words, there is no compelling evidence that the supposed “pause” period is different from other previous periods. Neither is the deviation between the observations and climate model projections larger than would be expected. That’s not to say that such “wiggles” in the temperature record are uninteresting – several of our team are involved in further studies of these fluctuations, and the study of the “pause” has yielded interesting new insights into the climate system – for example, the role of changes in the Atlantic and Pacific oceans. There are lessons here for the media, for the public, and for scientists. For scientists, there are two lessons: first, when you get to know a dataset by using it repeatedly in your work, make sure you also still remember the limitations you read about when first downloading it. Second, remember that your statistical choices are always part of a cascade of decisions, and at least occasionally those decisions must be revisited. For the public and the media, the lesson is to check claims about the data. In particular, when claims are made based on short periods or specific datasets, they are often designed to mislead. If someone claims the world hasn’t warmed since 1998 or 2016, ask them why those specific years – why not 1997 or 2014? Why have such short limits at all? And also check how reliable similar claims have been in the past.  The technique of misinformation is nicely described in a quote attributed to climate researcher Michael Tobis: “If a large data set speaks convincingly against you, find a smaller and noisier one that you can huffily cite.” Global warming didn’t stop in 1998. Don’t be fooled by claims that it stopped in 2016 either. There is only one thing that will stop global warming: cuts to greenhouse gas emissions."
"
Share this...FacebookTwitterBy Kirye
and Pierre Gosselin
Today we plot the Japan Meteorological Agency (JMA) data for Northern Europe for the month of August, 2020.
We have selected this region because it is the home of 17-year old climate alarmist/activist Greta Thunberg, who thinks the planet is heating up rapidly and so we’re all doomed.
We plot the data for the stations for which the JMA has sufficient data going back over 2 decades. First we plot the August data for Sweden, Greta’s home country:

Data: JMA
Five of the 6 stations plotted show a cooling trend. So it’s a mystery how Greta thinks her country is warming up. The data suggest that summers have been shortening a bit. Over the course of Greta’s life, she has yet to see warming in August.
Next we examine Norway, Greta’s western neighbor:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Data: JMA
Here we see 6 of the 11 stations have seen an August cooling trend over the past quarter century. The colder stations have warmed somewhat, while the warmer ones have cooled. Overall, no warming to speak of, really.
The story is similar in Finland (further from the Atlantic), but here the colder stations have cooled, while the warmer stations have warmed slightly – but statistically insignificantly:

Data: JMA
Finally we plot the data for the emerald island, Ireland, next to the tempestuous Atlantic:

Data: JMA
Four of the six stations in Ireland have been cooling in August. Those warming have done so insignificantly. Overall the emerald island has been cooling during the month of August since 1983!


		jQuery(document).ready(function(){
			jQuery('#dd_0f4f1e38f8790e798fa8564c196424a6').on('change', function() {
			  jQuery('#amount_0f4f1e38f8790e798fa8564c196424a6').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"

Though well‐​intentioned, international agreements to protect the environment are ineffectual, misguided and very costly for future generations. 



The most pervasive environmental problems are local and regional — not global. Water pollution, waste disposal, groundwater contamination, urban smog and deforestation are manifestations of unique state policies and local geographic, demographic and industrial profiles. They can be effectively addressed only locally. 



International agreements tend to ignore those less ”mediagenic” problems and pursue sexier issues such as climate change and ozone depletion — purported problems of which there is little hard evidence. Result: Scarce resources are misspent, real problems go unaddressed. 



International agreements tend to codify a uniform approach to environmental protection. The world is infatuated with command and control policies that empower armies of bureaucrats no more capable of managing ecological health than they are of managing economic growth. The World Bank, for example, would be charged with administering global environmental programs despite its record of ecological mismanagement. 



Natural resources are better protected by individual owners with vested interests in their property than by absentee bureaucratic managers subject to the winds of political fortune. Treaties that centralize environmental management compound ecological damage. 



Environmental treaties are biased against economic growth (viewed as a “problem” to be “solved” or “managed”) despite the proven correlation between wealthy economies and healthy environments. Treaties that harm growth not only condemn the poor to continuing poverty but doom long‐​term progress in environmental protection.
"
"Moderation is the last thing on people’s minds at Christmas. Shopping, travelling and eating reach peak levels – putting pressure on our planet. Even Santa poses a problem. If you don’t believe in flying reindeers, that sleigh must be rocket-fuelled to reach the supersonic speeds needed to travel around the world to visit hundreds of millions of children in just one night using conventional engineering. The example goes to show just how many presents we buy and send each Christmas –  creating problems with packaging and transport. And as the population increases, so does the pile of presents. To get round this, presents have got smaller and virtual gifts such as an experience day  have risen in popularity.   This has an added benefit of reducing packaging and transport problems. But virtual presents have a carbon footprint too. Electronic downloads still have an impact, as data has to be stored and transferred, using energy.  So everything we buy has some impact, even through the electronic process of buying.  So how can we have a greener, more sustainable but generous Christmas? Here are five gold circular things!  The amount of food wasted at Christmas has a massive carbon (and water) footprint. Using less and storing excess in a winter wonderland – your freezer – is a great way to avoid waste. If leftover food doesn’t go in the freezer, cooked turkey and vegetables will keep for up to three days in the fridge.    However, not producing excess in the first place is the best way to avoid waste. Portion size is a big part of this and so is cooking things you actually like. Just because something is traditional does not make it compulsory. For instance, sprouts can be very controversial – so, if you don’t like them, skip them. You could also try an alternative to the traditional meat option, such as a nut roast. Vegetarian and vegan choices at the Christmas dinner table can massively cut the impact of your Christmas.    Lower the impact of gifts through choices of paper and packaging. A lot of seasonal wrapping is non-recyclable as it is coated in plastic. This is concerning as plastic tends to spread everywhere – it has even been detected at the North Pole. A better approach would be to use wrapping paper made entirely out of paper. Gift bags are another great option – they can be reused and therefore help cut a massive amount of waste.  You can give twice if you buy your presents second hand from charity shops –  supporting worthwhile projects while also reducing consumption. You can also buy locally produced goods and support your local economy. Buying second hand potentially halves the carbon footprint. A typical T-shirt alone has a footprint of around 8.77kg of carbon dioxide and 2700 litres of water. If 1% of the 55.6m people in England alone bought just one second-hand T-shirt instead of a new one, they would be saving around 4.9m tonnes of carbon dioxide, the equivalent of driving 1,049 passenger cars for a year, and a whopping 1.5 billion litres of water. Christmas decorations and fashion are basically the same every year. So celebrate your Christmas collection and reuse it, over and over again. It is a tragedy that only one in four Christmas jumpers are ever reused. According to the Carbon Trust, an artificial tree needs to be used around 10 times to have an equivalent footprint as its real counterpart.    There are few holidays that are so focused on being caring, helpful and generous as Christmas. So celebrate this and try to avoid buying unnecessary stuff that people don’t want anyway. Donations and acts of kindness really lighten the load on that sleigh. A colleague once bought me a toilet for a family in Sierra Leone. No wrapping, no plastic: the best present ever – and Santa didn’t have to lift a finger!"
"

_Global Science Report_ _is a weekly feature from the_ _Center for the Study of Science_ _, where we highlight one or two important new items in the scientific literature or the popular media. For broader and more technical perspectives, consult our monthly “Current Wisdom.”_   
  
Let us see if we can help _New York Times_ ’ global warming reporter Justin Gillis out.   
  
In his article yesterday about the upcoming _Fifth Assessment Report_ of the U.N.’s Intergovernmental Panel on Climate Change (IPCC), Gillis laments that the IPCC seems to be tamping down some of the more alarmist scenarios when it comes to the projected rate of rise of global temperatures and sea level.   
  
Concerning projections of sea level rise, Gillis bemoans that the IPCC looks like (the final version of the Summary for Policymakers of the new report isn’t scheduled for release until the end of the this month at the conclusion of an IPCC editorial meeting in Stockholm) it will discount the “outlier” estimates that the rise this century will exceed five feet. Gillis writes “The drafters of the report went with the lower numbers, choosing to treat the outlier science as not very credible.”   
  
When it comes to how fast the global average temperature is projected to rise, Gillis rues the possibility that the IPCC will lower its assessed value of the climate sensitivity, writing “In this case, the drafters of the report lowered the bottom end in a range of temperatures for how much the earth could warm, treating the outlier science as credible.”



Gillis can’t wait for the explanation:   




…[I]t would be nice to hear an explanation from the drafters of this coming report as to why they made decisions that effectively play up the low-end possibilities. But with the report still officially under wraps, they are not speaking publicly. We are thus left wondering whether it is a matter of pure professional judgment — or whether they have been cowed by the attacks of recent years.   
  
Assuming these decisions withstand final review, it will be fascinating to hear the detailed explanations in Stockholm.



We’ll end the suspense for him.   
  
The reason that the IPCC should discount the possibility that the sea level will rise more than three feet by the year 2100 is that such a possibility has largely been discredited in the scientific literature and well as simply by looking out the window (i.e., the observed rate of sea level rise is only about 1.25 inches per decade and there is A LOT of ice in Greenland and Antarctica that is not going anywhere fast).   
  
We documented this is numerous places, notably here, here, here, and here.   
  
And the reason that the IPCC should lower its estimates of the earth’s climate sensitivity (i.e., how much the earth’s average temperature rises as a result of a doubling of the atmospheric concentration of carbon dioxide) is that the overwhelming majority of the recent findings in the scientific literature show that the most likely value is far beneath what it was assessed at in previous IPCC reports. In fact, the new equilibrium climate sensitivity estimates are so low as to put the IPCC in a quandary—if they were to fully embrace the new findings, they would have to discredit all the future climate projections made in the new report as they were generated by climate models with and average climate sensitivity that is nearly 75 percent higher than the new findings suggest. So if anything, the IPCC will likely be too conservative in lowering its assessment of the climate sensitivity in the final version of its _Fifth Assessment Report_.   
  
Of course, we have explained all of this as well. See here, here, here, and here for starters.   
  
So, pure and simple, the reason that the IPCC should embrace estimates of a slower global temperature increase and a lower global sea level rise is because that is what the current science supports.   
  
Gillis could have saved himself a lot of wondering (and ink) had he only been reading these pages!   
  
  
  
  
  



"
"After a month of tranquillity, fracking has resumed at the Preston New Road site near Blackpool triggering the biggest tremor to date. There have been 12 tremors over a four-day period, including the biggest so far – the 1.5 magnitude quake. In total, 36 earthquakes were recorded in the area between the middle of October and early November. Most of these are too weak to be felt at the surface, but can be measured using seismometers. These are instruments that measure ground motions, caused by such events as earthquakes and volcanic eruptions, among other factors. Local residents are concerned the earthquakes may cause cracks in the fracking well’s casing, which could potentially lead to contamination issues. Some scientists claim the impact of these seismic events at surface is equivalent to dropping a melon onto the floor. But government officials and those in the fracking industry have dismissed the tremors – suggesting they are inconsequential. As a social scientist living in Lancashire, I have been researching the social impacts of shale gas developments since 2015. From what I have seen, there is much more to the tremors than just ground movements. The impact of the quakes that occurred far below ground reverberated strongly throughout the community living on the surface. To understand why this is the case it is important to understand local people’s experiences of shale gas exploration in the UK. The same operator, Cuadrilla, was fracking for shale gas in the area seven years ago. Two bigger and around 50 smaller earthquakes occurred over an eight-month period as a result of injecting fluid into a geological fault zone.  In 2018 – and under new seismicity controls – Cuadrilla was required to halt its fracking operations twice when the monitoring equipment detected tremors bigger than 0.5 local magnitude. The system was introduced to set “gold standard” regulations for this new industry. After the quakes, Cuadrilla’s CEO warned that making fracking commercially viable would be extremely challenging under the existing seismic monitoring system in the UK. He wanted the government to reconsider its position on seismic monitoring within weeks.   Weeks passed by, the activity at the site was subdued for a month and no further seismic events were recorded until December 10 2018. Cuadrilla did not publicly confirm it had suspended hydraulic fracturing between early November and December. But it did say it was planning to engage with the regulators to change the upper limit on seismic monitoring. In the Blackpool area, earthquakes have been on everyone’s radar. Many local residents refresh the British Geological Survey website that records all recent earthquakes in the country almost hourly. At the observation point at Preston New Road known as the “gate camp”, protesters watch and listen carefully for the signs of fracking activity, proudly asserting: “This is the most watched site in the UK.” The reason they are watching so carefully is because they have serious concerns about how regulatory monitoring and corporate transparency works. Take the seismic monitoring system which was originally designed to reassure communities they would be protected from harm. After Cuadrilla’s recent announcements, the prospect of relaxing the seismic controls seems real. For local communities, new seismic thresholds would not be just numbers, but a sign that politicians are willing to further extend the industry’s authority over society. Relaxing regulations because they make business more difficult is a narrowly economic rationale – there’s certainly nothing democratic about it. This is the palpable sense of injustice you get when you talk to people at the side of Preston New Road.  In my experience, the regular liaison meetings with the company and regulators do little to reassure the local communities. Instead, they have made residents dissociate transparency from openness. In their view, the liaison meetings, consultations and the lengthy planning process have become a field of corporate practice. They limit residents’ ability to determine their common future – but the process provides the industry with a veneer of democratic legitimacy.  What this generates for local residents are feelings of disenfranchisement and distrust – and a sense of social injustice. This is why the impact of the earthquakes can’t be separated from the social reality on the surface. For local communities, there is an implicit analogy between the fracking pad with its well bore that extends kilometres out of sight and underground and the non-transparent ways in which the UK government and the industry are perceived to impose hydraulic fracturing on local populations.  Residents worry that the same attitude that the government and industry espouse on the surface, would also govern the way they tackle potential problems that arise underground – as a result of fracking. Of course, it is true that any new industry – such as shale gas exploration – is bound to face hurdles as it tries to identify suitable operational procedures. But to understand why communities in Lancashire have found it so difficult to trust government agencies and industry, it’s important to consider how seismic events operate in the reality of social, rather than merely geological, environments."
"
Share this...FacebookTwitterToday we present two papers on climate reconstruction using proxy data. One about East Antarctica and the other about belize. Hat-tip reader Mary Brown.
AMO behind sea surface temperatures
First we look at a paper authored by a team of German scientists: “Great Blue Hole (Lighthouse Reef, Belize): A continuous, annually-resolved record of Common Era sea surface temperature, Atlantic Multidecadal Oscillation and cyclone-controlled run-off“.
The team looked at 2000 years of proxy data from Belize and found interesting natural cycles at play. According to the authors, the Atlantic Multidecadal Oscillation (AMO) occurred 1885 years back in time and that it controls the SW Caribbean sea surface temperature patterns on multi-decadal time scales.
The authors note that the Holocene (<11.7 kyr BP) has been characterized by several periods of distinct climate changes and that the climate remains difficult to predict “due to the lack of comprehensive, annually-resolved and continuous sea-surface temperature (SST) data”.
So what about them models?
Examining an 8.55 m long sediment core from the bottom of the Great Blue Hole (Lighthouse Reef, Belize), the scientists were able to extract “an annually-resolved, continuous and unique south-western Caribbean climate record for the last 1885 years”.
The result? The data imply a general SST rise within the south-western Caribbean and that the modulation of SST within the time series likely operated on two different time levels: (1) Solar (e.g., “Gleissberg Cycles”) and volcanic activity triggered climate changes, which in turn induced responses of the Atlantic Multidecadal Oscillation (AMO), the North Atlantic Oscillation (NAO) and the El-Niño-Southern Oscillation (ENSO).
The authors conclude further in the abstract:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




We suspect long-term positive AMO and NAO modes as the primary key control mechanisms of the Dark Ages Cold and Medieval Warm Period SST patterns. ENSO mode modulation likely exerted primary control on regional SST variability during the Little Ice Age and the Modern Global Warming. (2) Our δ18O data further indicate a striking secondary control on multi-decadal time scales: δ18O variations occur with 32–64 years periodicity. This signal is clearly evidence of SST modulation controlled by AMO phase changes (50–70 years) over almost the entire Common Era. Our carbon isotope record (δ13C) exhibits two remarkable negative anomalies and a long-term up-core decreasing trend. The first excursion (drop of 0.5‰) occurred with the onset of the Medieval Warm Period, which is reconstructed to be a peak time in south-western Caribbean tropical cyclone (TC) activity. This overlap is stressing a potential context between TC activity, enhanced coastal run-off and increased soil-erosion reflected by 13C-depleted carbon isotopes. A second anomaly (>1900 CE) is more likely the result of the “Suess Effect” (anthropogenic impact of the Industrial Revolution on carbon isotopes composition) than another reflection of a TC peak activity interval.”
But since 1900, man has taken over control of the earth’s climate, the authors seem to be suggesting. That was probably written in witha wink to the funders.
Antarctica suddenly lost 400 meters of ice
In another new paper: Abrupt Holocene ice-sheet thinning along the southern Soya Coast, Lützow-Holm Bay, East Antarctica, revealed by glacial geomorphology and surface exposure dating, a team of Japanese scientists led by Moto Kawamata examined the deglacial history of the East Antarctic Ice Sheet (EAIS).

Image: Figure 1 here.
The authors found that it had thinned from at least 400 m a.s.l. during the Early to Mid-Holocene (9–5 ka) and say the abrupt thinning was likely caused by the natural inflow of modified Circumpolar Deep Water via submarine valleys in Lützow-Holm Bay.
Abstract:
Geological reconstruction of the retreat history of the East Antarctic Ice Sheet (EAIS) since the Last Glacial Maximum (LGM) is essential for understanding the response of the ice sheet to global climatic change and the mechanisms of retreat, including a possible abrupt melting event. Such information is key for constraining climatic and ice-sheet models that are used to predict future Antarctic Ice Sheet AIS melting. However, data required to make a detailed reconstruction of the history of the EAIS involving changes in its thickness and lateral extent since the LGM remain sparse. Here, we present a new detailed ice-sheet history for the southern Soya Coast, Lützow-Holm Bay, East Antarctica, based on geomorphological observations and surface exposure ages. Our results demonstrate that the ice sheet completely covered the highest peak of Skarvsnes (400 m a.s.l.) prior to ∼9 ka and retreated eastward by at least 10 km during the Early to Mid-Holocene (ca. 9 to 5 ka). The timing of the abrupt ice-sheet thinning and retreat is consistent with the intrusion of modified Circumpolar Deep Water (mCDW) into deep submarine valleys in Lützow-Holm Bay, as inferred from fossil foraminifera records of marine sediment cores. Thus, we propose that the mechanism of the abrupt thinning and retreat of the EAIS along the southern Soya Coast was marine ice-sheet instability caused by mCDW intrusion into deep submarine valleys. Such abrupt ice-sheet thinning and retreat with similar magnitude and timing have also been reported from Enderby Land, East Antarctica. Our findings suggest that abrupt thinning and retreat as a consequence of marine ice-sheet instability and intrusion of mCDW during the Early to Mid-Holocene may have led to rapid ice-surface lowering of hundreds of meters in East Antarctica.”
Today, if an ice sheet loses 60 cm, it’s deemed a crisis by climate bedwetters. Just imagine if an ice sheet in Antarctica were to lose 400 meters thickness.


		jQuery(document).ready(function(){
			jQuery('#dd_671ec5cfb78244fc3fa18cd6e7e3d7df').on('change', function() {
			  jQuery('#amount_671ec5cfb78244fc3fa18cd6e7e3d7df').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"
Share this...FacebookTwitter


A new study documents the dominance of internal variability in decadal-scale global temperature changes and suggests we may experience a global cooling trend during the next 15 or even 30 years despite rising greenhouse gases.
Maher et al. (2020) acknowledge that internal variability in global surface temperature variations is “a difficult concept to communicate” because we have very few observations of its impact and so we must rely on assumptions about how the climate system might work.
Those who try to explain how internal variability affects global surface temperature often use the “Butterfly Effect” paradigm; they assume that small changes now can lead to larger changes decades from now.

Because global temperature trends are “largely determined by internal variability”, global cooling or another warming hiatus could very well be observed over the next decade. Actually, as Maher and colleagues explain, “even out to thirty years large parts of the globe (or most of the globe in MPI-GE and CMIP5) could still experience no-warming due to internal variability“.




Image Source: Maher et al., 2020


Share this...FacebookTwitter "
"

Government policies encourage Americans to live in risky places on seacoasts and along flood‐​prone rivers. Disasters happen, governments bail people out, they rebuild in the same places, bad incentives stay in place, further disasters strike and more dollars and lives are lost.   
  
  
The _Washington Post_ reported on recent flooding along the Mississippi River, which I’ve excerpted below.   
  
  
But first, here are some general points about flooding and governments:   




These points are developed further here, here, here, here, here, here, and here.   
  
  
Here is what the _Washington Post_ reported:   




The city [St. Charles, MO] of about 70,000 has long grappled with flooding from the Missouri and Mississippi rivers, as well as rising water from creeks and streams — making it one of the most flood‐​prone regions in the state, with some $18 million in flood insurance claims paid out since 1970 by the Federal Emergency Management Agency.   
  
  
Yet that hasn’t stopped the city from planning a $1.5 billion riverfront development along the Missouri’s banks, 120 acres of upscale shops, restaurants and apartments mostly in the river’s flood plain, an area that has been partly submerged this summer.   
  
  
Several hundred miles to the south, Louisiana is experiencing the fallout from decisions like that one — decades of rampant development behind tall levees that have cut the Mississippi and its many tributaries off from the vast open floodplains the rivers once carved for themselves.   
  
  
Tropical Storm Barry, which made landfall Saturday as a hurricane, is predicted to travel up the Mississippi toward St. Louis, deluging surrounding areas as it goes, with rainfall that will be channeled back toward the Louisiana coast in days to come — the latest potential catastrophe.   
  
  
“The major cause of record, recent flooding is entirely man‐​made — the dramatic constriction of our large rivers by oversized levees, flood plain development and structural narrowing for barge traffic,” said Robert Criss, professor emeritus with the Department of Earth and Planetary Sciences at Washington University in St. Louis.   
  
  
This year’s historic floods throughout the Midwest caused billions of dollars in damages; washed out highways, bridges and dozens of levees; swamped crop lands and cities; sent residents fleeing for their lives; and left a death toll in several states.   
  
  
Decades of development have contributed to the problem. Claims to FEMA’s flood insurance program have increased rapidly in the past two decades and spread beyond coastal regions.   
  
  
… Yet with millions of people living in flood plains and shipping and tourism economies built on these key waterways, there is little political will for change. Environmentalists charge that jurisdictions hungry for tax revenue are continuing to plan risky projects without taking floods’ worsening intensity into account, heedless of the economic and human consequences.   
  
  
“It’s lunacy,” said David Stokes, executive director of the Great Rivers Habitat Alliance. “They’re continuing to build in places where Mother Nature intended water to go. And there’s no end to it.”


"
"
Share this...FacebookTwitterResearchers can no longer blame inconvenient cold winters on Arctic warming. No scientific basis, new study shows.
Image: NASA (public domain)
By Die kalte Sonne
(German text translated by P. Gosselin)
The Arctic is warming faster than the mid-latitudes. It’s the so-called Arctic amplification (AA). According to a study by Polvani et al. 2020, half of the Arctic warming is due to ozone-depleting substances – and not CO2. This was of course a great surprise, as we have already reported here. So no wonder that the climate models are going crazy, since they have so far attributed almost the entire warming to CO2.
CO2 has been hopelessly overbooked, as it now turns out.
In Nature Climate Change, a paper by Cohen et al. 2020 has been published and it shakes another myth. In the past, researchers were too happy to tell us that strong Arctic warming leads to harsh winters in mid-latitudes. However, there is a problem: the models are largely unable to reconstruct this presumed relationship: The paper finds:
Divergent consensuses on Arctic amplification influence on midlatitude severe winter weather
The Arctic has warmed more than twice as fast as the global average since the late twentieth century, a phenomenon known as Arctic amplification (AA). Recently, there have been considerable advances in understanding the physical contributions to AA, and progress has been made in understanding the mechanisms that link it to midlatitude weather variability. Observational studies overwhelmingly support that AA is contributing to winter continental cooling. Although some model experiments support the observational evidence, most modelling results show little connection between AA and severe midlatitude weather or suggest the export of excess heating from the Arctic to lower latitudes. Divergent conclusions between model and observational studies, and even intramodel studies, continue to obfuscate a clear understanding of how AA is influencing midlatitude weather.”


		jQuery(document).ready(function(){
			jQuery('#dd_dd3235f998397df12e765fa01f9ebb45').on('change', function() {
			  jQuery('#amount_dd3235f998397df12e765fa01f9ebb45').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"

In the new Cato study “Long Hot Year: Latest Science Debunks Global Warming Hysteria” (Policy Analysis no. 329), climatologist Patrick J. Michaels reports that Vice President Al Gore’s latest alarmist claim—that 1998’s warmer than normal temperatures resulted from global warming—isn’t supported by the scientific evidence. Michaels, professor of environmental science at the University of Virginia and senior fellow in environmental studies at the Cato Institute, writes that “the record temperatures were largely the result of a strong El Niño superimposed on a decade in which temperatures continue to reflect a warming that largely took place in the first half of this century.” Satellite data show clearly that “the warmth of 1998 is an anomalous spike rather than a continuation of a warming trend.” Michaels notes that “imposing an El Niño upon an already warm decade creates the illusion of rapid global warming,” as he predicted it would in his 1992 Cato Institute book Sound and Fury. The fact is that “observed global warming remains far below the amount predicted by computer models that served as the basis for the United Nations Framework Convention on Climate Change.”



 **Perils of Government Investing**



The questions at the center of the upcoming debate on Social Security’s future will be, What kind of private investment, and who should do the investing? Michael Tanner, director of Cato’s Project on Social Security Privatization, warns in “The Perils of Government Investing” (Briefing Paper no. 43) that those are critical questions because government investment of Social Security funds could make the federal government the largest shareholder in American corporations. Tanner points out that Federal Reserve chairman Alan Greenspan says that it is impossible to “insulate” government investment “from the political process.” Government investment of Social Security payroll taxes would result in a dangerous mix of government involvement in corporate governance and “social investing.” 



**Failed Intervention in Bosnia**



The three‐​year‐​old Dayton Agreement has failed to accomplish its main objective and should be abandoned, writes Cato foreign policy analyst Gary Dempsey in a new study, “Rethinking the Dayton Agreement: Bosnia Three Years Later” (Policy Analysis no. 327). “The Clinton administration’s continued and uncritical devotion to the agreement is compromising U.S. national security and saddling the United States with an expensive yet futile nation‐​building operation of unknown duration.” The study finds that the “goal of creating a unitary, multiethnic Bosnian state is not realistic.” The Clinton administration has refused to consider changing course, however. “The administration needs to jettison its presumption that there are only two options for U.S. policy on Bosnia: adhere to the Dayton Agreement or cut and run. There is another option: a negotiated three‐​way partition of Bosnia overseen by a European‐​led transition force. That is the most politically feasible way to create the conditions necessary to allow the departure of U.S. troops at the earliest possible date.” 



Throw the Other Guy’s Bums Out, Too In the new Cato study “What Term Limits Do That Ordinary Voting Cannot” (Policy Analysis no. 328), Harvard Law School professor Einer Elhauge addresses the questions: Why do the same voters who vote for term limits also routinely vote to return senior incumbents to office? Why don’t they vote the bums out? The answer is straightforward: “Voting your bum out is not a solution when what you want to do is oust the other districts’ bums. For that you need term limits.” The fact that incumbents tend to get reelected at very high rates even though large majorities of voters favor term limits is perfectly logical, he notes. “A district that ousts its senior incumbent suffers a loss of relative clout in the legislature. To avoid that loss of power, it behooves individual districts to vote to retain their incumbents.” The solution is also straightforward: “If all the districts collectively could agree to oust their senior incumbents simultaneously, no district would suffer a loss of relative power, and each district would gain more accurate representation. Term limits are effectively just such an agreement.”



 **U.S. Foreign Policy Spawning Terrorism**



One‐​third of all terrorist attacks worldwide in 1997 were perpetrated against U.S. targets. That is a very high percentage “considering that the United States—unlike nations such as Algeria, Turkey, and the United Kingdom—has no internal civil war or quarrels with its neighbors that spawn terrorism,” writes Ivan Eland, Cato’s director of defense policy studies. “The major difference between the United States and other wealthy democratic nations is that it is an interventionist superpower.” In “Does U.S. Intervention Overseas Breed Terrorism? The Historical Record” (Foreign Policy Briefing no. 50), Eland points out that the Pentagon’s own Defense Science Board finds that “a strong correlation exists between U.S. involvement in international situations and an increase in terrorist attacks against the United States.” Eland recommends that the United States adopt a policy of military restraint: “The United States could reduce the chances of devastating—and potentially catastrophic—terrorist attacks by adopting a policy of military restraint overseas.”



 **Nuke the Test Ban Treaty**



The U.S. Senate should reject the proposed Comprehensive Test Ban Treaty and fund the resumption of limited testing, writes defense analyst Kathleen C. Bailey in a new Cato paper. In “The Comprehensive Test Ban Treaty: The Costs Outweigh the Benefits” (Policy Analysis no. 330), Bailey argues that the treaty is unenforceable, unverifiable, and unwise policy. Signed by President Clinton in September 1996 and to be considered by the Senate this year, the CTBT has limited political benefits and is “not worth the high cost to U.S. national security.” Weapons testing is essential to U.S. national security, according to Bailey, because “evolution in technologies for safety, nuclear delivery systems, and enemy defenses may render the now‐​modern U.S. nuclear arsenal technologically obsolete or less safe.” She notes that “at present, the United States is two years or more away from being able to conduct a nuclear test. This lack of readiness will inevitably worsen as skilled experts retire and die, equipment ages or becomes obsolete, and financial support erodes.” Bailey believes that, “from a purely technical standpoint, it would be most prudent for the U.S. Senate to reject the CTBT and to allocate funds for resumption of U.S. testing and for reconstruction of the U.S. nuclear weapons production infrastructure.” But she notes as well that “it may be politically desirable to undertake some limitations on testing.” 



**Trashing Government Intervention in Refuse**



One of the biggest environmental issues at the state and local levels is garbage—how to collect it, dispose of it, recycle it, and pay for doing so. In a new Cato study, “Time to Trash Government Intervention in Garbage Service” (Policy Analysis no. 331), Peter VanDoren, assistant director of environmental studies at Cato, challenges the reigning orthodoxy that the government must decide those questions for citizens. That belief, VanDoren points out, is grounded in the assumption that economies of scale and collection route density mean the government must have a monopoly on trash collection. VanDoren’s research on the economics of refuse markets reveals that government management of garbage service is unnecessary and counterproductive. He argues that homeowners should be allowed to choose among competing collection firms and that homeowners, not bureaucrats, should have the final say about what kind of service they want.



 _This article originally appeared in the March/​April 1999 edition of_ Cato Policy Report.   
Full Issue in PDF  (16 pp., 317 Kb)



<em><a href=”/people/patrick-michaels”>Patrick J. Michaels</a> is Director of the Center for the Study of Science at the Cato Institute.</em>
"
"

How many hurricanes do you think will hit the East Coast of the United States in 2015? Will the Arctic ice sheet disappear next year? How fast will the U.S. economy grow? What will the level of the Dow Jones stock index be at the end of 2015? Which team will win the World Series?



Go back and look at predictions made by the experts, and then look at what really happened. The climate alarmists 15 or so years ago were forecasting catastrophic events by this time. Yet sea levels have not been rising any faster than they have been for centuries. The major climate models were projecting steady rises in global warming each year, yet average temperatures have not risen for 17 years. Al Gore and his alarmist crowd told us that the Arctic would be free of sea ice during the summer by now and that we would be having more and stronger tornadoes and hurricanes. The Arctic sea ice is still with us, and few ships dare sail there. Many tornado and hurricane records have been broken — not because there were more — but because there have been fewer. Florida has gone a record nine straight seasons without a significant hurricane.



None of the above disproves climate change, but it should caution those who have made many rash predictions. The economist‐​philosopher F.A. Hayek warned about “the limits of knowledge” and the “fatal conceit” exhibited by so many “experts.” The communists and socialists claimed that they could allocate resources and income better than markets. These false claims ultimately destroyed the lives of tens of millions and caused untold human misery. Despite the never‐​ending failures of socialist and other collectivist schemes (such as Obamacare), colleges, governments and the media are still filled with smug — but ignorant or uncaring — individuals (think Jonathan Gruber) who still think they are smarter than markets, and thus have the self‐​appointed right to control your life.



Economists have little to crow about when it comes to forecasting. Most of them missed calling the Great Recession. The Federal Reserve, which employs hundreds of economists, many from the best schools, kept predicting 4 percent‐​plus economic growth each year, after the recession bottomed in 2009. In fact, actual growth has been about half of what they predicted — but perhaps 2015 will be the year of 4 percent growth. Too many of my fellow economists, including many of those in the administration, get things wrong, in part, because they still use Keynesian economic models that treat increases in government spending as a positive rather than a negative, among other errors.



To make an accurate forecast, one needs to know what the Fed will do in regard to monetary policy and what Congress and the administration will do in terms of taxing, spending and regulation. One also needs to know what the economic policies of other countries will be — since the United States is not an island unto itself — and when wars and tsunamis will occur. The impossibility of knowing all of this does not mean that it is not useful to attempt to forecast, but merely that it is not scientific in the way that we can precisely predict the boiling point of water at a specific atmospheric pressure.



Forecasters need to have a good understanding of the major variables that might greatly affect their reasoning. The safest starting point for most forecasts is what happened in the previous period. Tomorrow’s weather is likely to be similar to today’s. One might begin an economic forecast by assuming next year is likely to look much like this year, then alter the forecast based on assumed changes in policy. For instance, if you assume the Republican‐​led Congress is likely to reduce government spending as a share of gross domestic product, and if you believe, as many of us do, that government spending (at the current high levels) is a drag on growth, then it is sensible to boost the growth estimate a bit — other things being equal. This same exercise needs to be repeated with each major variable — taxes, regulations, monetary actions, changes in oil prices — and what Russia’s Vladimir Putin might do next.
"
"

The National Academy of Sciences (NAS) has just issued yet another report on global warming. A substantial part of it is based upon the “U.S. National Assessment” (USNA) of global warming, yet another government report that came out right before the last election. In turn, it was based, in large part, on computer models used in yet another government report on global warming, from the United Nations’ Intergovernmental Panel on Climate Change.



Together, the best I can tell, these were produced by a total of a couple thousand people. Together, they were dead wrong about the most fundamental aspect of climate change, namely how we are changing our atmosphere.



First, a little physics. It has been known since at least 1872 that carbon dioxide–a byproduct of combustion, or the meta‐​respiration of civilization, dependent upon your point of view–traps warming radiation. It has also long been known that its warming effect becomes less at increasingly high concentrations. As a result, a constant increase in atmospheric carbon dioxide results in less and less warming over time.



So, the only way to keep warming the atmosphere at a constant rate is to add carbon dioxide at an increasing, or exponential rate. This is what the U.N., the USNA, and the National Academy all assume … at least inasmuch as the Academy report states its parentage is the USNA, in its section titled “Consequences of Increased Climate Change”.



The fact is that carbon dioxide has not accumulated in the atmosphere at an exponential rate for the last quarter‐​century: This is obvious to anyone with an Internet connection (in order to download a graph of the carbon dioxide history), eyeballs and a ruler. You will see that the behavior of the last 25 years looks a lot more like a straight line than an upward‐​pointing curve. Those with statistical expertise could also enter the data into a program like Excel and see if drawing an up‐​curve through the data results in a significant improvement over a straight line. The answer, for the last 25 years, is no.



This can only mean one thing. The linear change in carbon dioxide for the last quarter‐​century will result in an inevitable and inexorable slowing of global warming in coming decades.



So why isn’t carbon dioxide increasing exponentially, even as the number of people are? Two reasons: We are becoming increasingly efficient, and the planet is getting greener.



We now produce a (deflated) dollar’s worth of stuff using about half as much energy as we used to. Neither the U.N. nor the EU, despite their blustering, forced us to do this. Instead, stockholders made it happen, demanding more output for less cost. There’s every reason to expect this behavior to continue.



The earth got greener because more carbon dioxide made the plants grow better, and a warming, primarily of the winter, lengthened the growing season. Will this greening stop, as some fear, when forests become mature and fall over? Not if they’re turned into houses, which last for hundreds of years. This is one very good argument for managed, as opposed to “natural” forestry.



How could the Academy, the National Assessment Team, and the United Nations fail to notice that they got the basic behavior of carbon dioxide (and therefore, future warming) wrong? Could thousands of scientists simply miss what anyone with a hard drive and a ruler can see? Of course not. But where would my profession be if we couldn’t scare you into funding us any more?



In a world where he who presents the scariest argument gets the most funding, everything is threatening and nothing is benign.



It’s not just in climate science, either. How about cancer? We spend just about as much money there as we do on global warming. The government regales us with impressively weak associations between diet, urban air, polar ozone depletion and death, when the lion’s share of cancer deaths would go away if people would simply choose not to smoke ciggie butts. Which causes more cancer–increasing ultraviolet radiation by 2 percent from ozone depletion (itself maybe too large an estimate) or going to the beach and taking off 98 percent of your clothes? But simple behavior changes cashier armies of regulators, who, thank you, would much rather be employed. So we tout the obscure while ignoring the obvious.



Which, sadly, is why thousands of the best minds in America aren’t eager to tell you that changes in atmospheric carbon dioxide have been so slow that global warming is likely to slow down in future decades. Exactly when, though, no one knows. Please pass the funding until I figure this out.
"
"
Sky note:
 After sunset on Sunday, Dec. 23rd, the full Moon and Mars will rise in the east less than 2 degrees apart. They’ll be two brightest objects in the evening sky, as Mars is very near it’s closest approach (opposition) to Earth, which happened just a couple of days ago. 
It will look something like this:

Note the image is not to scale. Mars is bigger than it will actually appear.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea1dacdc0',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterBy Prof. Fritz Vahrenholt at Die kalte Sonne
(Translated by P. Gosselin)
June 7, 2020
Dear ladies and gentlemen
First, the global mean temperature of satellite based measurements was surprisingly much higher in May 2020 than in April. In contrast, the global temperatures of the series of measurements on land and sea decreased. The difference can be explained by the fact that under warm El-Nino conditions the satellite measurements lag about 2-3 months behind the earth-based measurements.
From November 2019 to March 2020 a moderate El-Nino was observed, which has now been replaced by neutral conditions in the Pacific. Therefore, it is to be expected that also the satellite based measurements, which we use at this point, will show a decrease in temperatures within 2-3 months.
The average temperature increase since 1981 remained unchanged at 0.14 degrees Celsius per decade. The sunspot number of 0.2 corresponded to the expectations of the solar minimum.
The earth is greening


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In August 2019, I reported on a remarkable publication by the Max Planck Institute for Meteorology in Hamburg: “Our main finding,” said Aexander Winkler’s researchers at the time, “is that the effect of CO2 concentration on terrestrial photosynthesis is greater than previously thought and therefore has important implications for the future carbon cycle.
According to this, the CO2 attenuation effect of plants is 60% higher than the average of climate models had assumed.
“In the last two decades, an average of 310,000 km² of additional leaf and needle area – roughly the size of Poland or Germany – has been created every year,” the researchers say. I had shared this important finding with the members of the German Bundestag at the time, which led Stefan Rahmstorf to conclude that I was “trying to fool the German Bundestag“. This assessment was taken up by some media such as the TAZ and ultimately led to my dismissal as sole director of the German Wildlife Foundation.
New confirmation: CO2 uptake by plants is increasing
In April ,2020, a research group led by the Australian scientist Vanessa Haverd published a paper in Global Change Biology which more than confirmed the findings of the Max Planck Institute. The researchers describe that plants have absorbed 30% more CO2 since 1900. The previous estimates were 17%. In their calculation for a mild increase in CO2 in this century (IPCC scenario 2.6), the researchers led by Vanessa Haverd arrived at a net uptake of 528 billion tonnes of CO2 by plants by 2100, compared to the 238 billion tonnes of CO2 previously calculated by climate models.
According to Adam Riese, this is more than twice as much. By way of comparison: In scenario 2.6, a total of 1000 billion tonnes of CO2 (IPCC, Chapter 6, p. 468) will be emitted in this century. Today the plant world absorbs about 30% of the anthropogenic CO2 annually, the oceans another 24%.
In contrast, the statement of the IPCC in its last report from 2013 (p.26 of the Summary for Policymakers) is diametrically different: “Based on Earth system models, there is a high confidence that the feedback between climate development and the carbon cycle in the 21st century is positive. As a result, more of the anthropogenic CO2 emitted will remain in the atmosphere. Maybe I need to write to the German Bundestag again.


		jQuery(document).ready(function(){
			jQuery('#dd_702a1f6ffcce5ac21c82418cd887a235').on('change', function() {
			  jQuery('#amount_702a1f6ffcce5ac21c82418cd887a235').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"

Most economists once believed that monetary policy should aim at achieving full employment, but we now know that holding unemployment below its natural rate has dangerous consequences. Could it be that another supposed economic ideal — zero inflation — is similarly wrong‐​headed?





In his 1997 book _Less Than Zero_ , Cato’s George Selgin first made the case for allowing price levels to vary to reflect changes in productivity. Now, a new edition of _Less Than Zero_ from the Cato Institute updates this important and prescient argument for 2018.



  
In the introduction for this edition, Scott Sumner of the Mercatus Center at George Mason University makes the case that Selgin’s book was “ahead of its time” and that it is time to return to Selgin’s argument for a productivity norm, where prices would rise or fall inversely to changes in productivity.



Selgin himself, however, contends that his idea is not entirely innovative; over the course of his research, he found that similar arguments have been made by other early 20th‐​century economists he admired. “Eventually, it became clear to me that — far from being novel — my understanding of deflation had once been almost orthodox, having been shared by prominent economists of many different schools of thought, only to be flung aside in the wake of the Keynesian revolution,” he writes. Two decades after its first publication, the ideas in _Less Than Zero_ are no longer as radical as they once were, as more economists are arguing for nominal income targeting and speculating about the possibility of “good” deflation. With that new climate in mind, this edition revisits these important and thought‐​provoking ideas.
"
"
Share this...FacebookTwitterHere’s another example illustrating just how volatile and unreliable wind energy really is.
Wind energy proponents like to claim that although turbines installed on land don’t produce so optimally, the ones at sea are wonderful because the wind there is always blowing and so it all kind of evens out.
The chart below shows the output of all wind turbines installed in Germany, both on land and offshore, from the five major German grid operators:

The dark horizontal line denoting 60,000 MW represents the so-called installed total capacity. Readers will note that less than 10% of rated capacity often gets produced. Only rarely does an output of 33% (20 MW) ever get reached.


		jQuery(document).ready(function(){
			jQuery('#dd_47d74c3ef530a413e0a50449d409a405').on('change', function() {
			  jQuery('#amount_47d74c3ef530a413e0a50449d409a405').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"Sahia got married when she was 15 years old – and saw her husband for the first time on their wedding day. Her sense of humour is apparent as soon as we meet: “He is a good husband. I was lucky, but at the same time he must have exaggerated his status a bit to my parents,” she says, laughing. “His market value was put up slightly over his actual value.” She has agreed to talk to us about the ways climate change and environmental stress are influencing people’s lives. She says that after their wedding, she moved in with her husband and father-in-law. Her new home was Singpur – a riverside village in central Bangladesh, only a couple of hundred kilometres from the capital, Dhaka. She had been living here for about a year when she witnessed her first home collapsing into the river.   One day we found cracks in the floor as the land had started to get pulled into the water. We realised that this was a bad sign. The cracks kept growing deeper and deeper for each day that passed. Riverbank erosion usually happens slowly, but occasionally a larger chunk of land suddenly falls into the water. This is what happened the day Sahia lost her first house. As soon as she noticed how deep the cracks were in the ground, she started carrying out their belongings to safety. A few hours later, the house was gone.  Sahia and her family moved in with her husband’s uncle for a while. But it was not long before his house was swallowed by the river, too. They moved into an abandoned house after this, but they are still living too close to the river, Sahia tells me in a worried voice. Sahia’s husband was a fisherman so the family got by on what he managed to catch. They were managing, until one day everything changed. My husband used to catch fish, but when the fish got some disease he had to stop fishing … Nowadays, there is hardly any fish left in the river … There used to be tons of fish, but when the fish started dying from that disease people stopped eating them … All the big and good fish disappeared. Once their main income stopped sustaining them, the family felt forced to change livelihood. They decided to migrate seasonally to work in a brick factory in Aliganj, further up the river. Nowadays, they leave Singpur for six months every year during the rainy season, to avoid being there when the village is flooded. The man who brought us there [to the brick factory] gave us some money, and with that money we managed to survive the six months in Singpur. What we earn we use to feed our family. They usually pay us on a weekly basis, around 2,000-4,000 taka [£20-40]. After feeding my family, consisting of six family members, we manage to save about 1,000 taka [£10] or so per week. That amount is our family’s whole savings per week. When the family return to Singpur, they live on their savings from the brick factory. The work is hard and dangerous. The children miss out on school to work in the factory and it is only a matter of time before someone ends up getting hurt or sick from the hard work. Their savings would not sustain the whole family through a crisis.  The shift of livelihood has not only been hard on Sahia physically. Before the factory work, she was a housewife like the rest of the women in Singpur village. Working outside of the house as a woman has brought social stigma on her. In this village, if you work outside you end up losing your honour… After observing us some people said: ‘The women out there are working! What do they know about work?’ We see those people, we hear them, but we do not fear their words anymore. We work to survive. I can see that she is watching me. My hair, which is tied up in a bun, and the clothes I am wearing. We are two women not that different from one another in a lot of ways, but we are living two completely different lives in very different parts of the world. She says: I am actually not that old. It is the hard work that made me look like this. Did you not see my husband? Nobody thinks I am his wife after meeting him. Her husband is young, in his late twenties or early thirties. When I first met Sahia I thought to myself that she must be about a decade older than me. It turns out that we are about the same age. She had to make the necessary sacrifices in her life to sustain her family.  When I return to the village a year later, I immediately head off to find her. I have thought about her throughout the year. I ask the people I met on my way there, but nobody seems to know anything. I reach the area where her house used to stand, but it is gone. It has fallen into the river. I ask her neighbours if they know where she is, where the family went, but nobody seems to know what has happened to her."
"
In our last episode, we looked at a COOP station on a roof of a fire station operated by the NWS in San Diego. Moving north, we have another COOP station operated by the San Francisco/Monterey Weather Service office that is also on a rooftop. You can see the MMTS sensor in the photo provided.
This station, COOP number 04-1838 is in Cloverdale, CA is just a few feet away from a chimney flue and an exhaust stack of a diesel generator. Note also the rain gauge placement. This station, while not a USHCN station, is part of the “A” network, which does report climate for NCDC.

Photo from NWS SFO/Monterey
For those unfamiliar at spotting NOAA issued MMTS temperature sensors, its the post on the leftmost portion of the lower roof, directly beneath the satellite dish.
To see other stations, try my blogs “weather_stations” link under the categories at right. To see stations in your state see www.surfacestations.org and click on the online image gallery link. You may even wish to signup to help survey a station in your area.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea288d583',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

The Current Wisdom is a monthly series in which Senior Fellow Patrick J. Michaels reviews interesting items on global warming in the scientific literature that may not have received the media attention that they deserved, or have been misinterpreted in the popular press.



The Current Wisdom only comments on science appearing in the refereed, peer‐​reviewed literature, or that has been peer‐​screened prior to presentation at a scientific congress.



This year’s installment of the United Nations’ annual climate summit (technically known as the 16th meeting of the Conference of the Parties to the Framework Convention on Climate Change) has come and gone in Cancun. Nothing substantial came of it policy‐​wise; just the usual attempts by the developing world to shake down our already shaky economy in the name of climate change. News‐​wise probably the biggest story was that during the conference, Cancun broke an all time daily low temperature record. Last year’s confab in Copenhagen was pelted by snowstorms and subsumed in miserable cold. President Obama attended, failed to forge any meaningful agreement, and fled back to beat a rare Washington blizzard. He lost.



But surely as every holiday season now includes one of these enormous jamborees, dire climate stories appeared daily. Polar bear cubs are endangered! Glaciers are melting!!



Or so beat the largely overhyped drums, based upon this or that press release from Greenpeace or the World Wildlife Fund.



And, of course, no one bothered to mention a blockbuster paper appearing in Nature the day before the end of the Cancun confab, which reassures us that Greenland’s ice cap and glaciers are a lot more stable than alarmists would have us believe. That would include Al Gore, fond of his lurid maps showing the melting all of Greenland’s ice submerging Florida.



Ain’t gonna happen.



The disaster scenario goes like this: Summer temperatures in Greenland are warming, leading to increased melting and the formation of ephemeral lakes on the ice surface. This water eventually finds a crevasse and then a way down thousands of feet to the bottom of a glacier, where it lubricates the underlying surface, accelerating the seaward march of the ice. Increase the temperature even more and massive amounts deposit into the ocean by the year 2100, catastrophically raising sea levels.



According to Christian Schoof of the University of British Columbia (UBC), “The conventional view has been that meltwater permeates the ice from the surface and pools under the base of the ice sheet… .This water then serves as a lubricant between the glacier and the earth underneath it… .”



And, according to Schoof, that’s just not the way things work. A UBC press release about his Nature article noted that he found that “a steady meltwater supply from gradual warming may in fact slow down the glacier flow, while sudden water input could cause glaciers to speed up and spread.”



Indeed, Schoof finds that sudden water inputs, such as would occur with heavy rain, are responsible for glacial accelerations, but these last only one or a few days.



The bottom line? A warming climate has very little to do with accelerating ice flow, but weather events do.



How important is this? According to University of Leeds Professor Andrew Shepherd, who studies glaciers via satellite, “This study provides an elegant solution to one of the two key ice sheet instability problems” noted by the United Nations in their last (2007) climate compendium. “It turns out that, contrary to popular belief, Greenland ice sheet flow might not be accelerated by increased melting after all,” he added.



I’m not so sure that those who hold the “popular belief” can explain why Greenland’s ice didn’t melt away thousands of years ago. For millennia, after the end of the last ice age (approximately 11,000 years ago) strong evidence indicates that the Eurasian arctic averaged nearly 13°F warmer in July than it is now.



That’s because there are trees buried and preserved in the acidic Siberian tundra, and they can be carbon dated. Where there is no forest today — because it’s too cold in summer — there were trees, all the way to the Arctic Ocean and even on some of the remote Arctic islands that are bare today. And, back then, thanks to the remnants of continental ice, the Arctic Ocean was smaller and the North American and Eurasian landmasses extended further north.



That work was by Glen MacDonald, from UCLA’s Geography Department. In his landmark 2000 paper in Quaternary Research, he noted that the only way that the Arctic could become so warm is for there to be a massive incursion of warm water from the Atlantic Ocean. The only “gate” through which that can flow is the Greenland Strait, between Greenland and Scandinavia.



So, Greenland had to have been warmer for several millennia, too.



Now let’s do a little math to see if the “popular belief” about Greenland ever had any basis in reality.



In 2009 University of Copenhagen’s B. M. Vinther and 13 coauthors published the definitive history of Greenland climate back to the ice age, studying ice cores taken over the entire landmass. An exceedingly conservative interpretation of their results is that Greenland was 1.5°C (2.7°F) warmer for the period from 5,000‑9000 years ago, which is also the warm period in Eurasia that MacDonald detected. The integrated warming is given by multiplying the time (4,000 years) by the warming (1.5°), and works out (in Celsius) to 6,000 “degree‐​years.” 



Now let’s assume that our dreaded emissions of carbon dioxide spike the temperature there some 4°C. Since we cannot burn fossil fuel forever, let’s put this in over 200 years. That’s a pretty liberal estimate given that the temperature there still hasn’t exceeded values seen before in the 20th century. Anyway, we get 800 (4 x 200) degree‐​years.



If the ice didn’t come tumbling off Greenland after 6,000 degree‐​years, how is it going to do so after only 800? The integrated warming of Greenland in the post‐​ice‐​age warming (referred to as the “climatic optimum” in textbooks published prior to global warming hysteria) is over seven times what humans can accomplish in 200 years. Why do we even worry about this?



So we can all sleep a bit better. Florida will survive. And, we can also rest assured that the UN will continue its outrageous holiday parties, accomplishing nothing, but living large. Next year’s is in Durban, South Africa, yet another remote warm spot hours of Jet‐​A away.



 **References:**



MacDonald, G. M., et al., 2000. Holocene treeline history and climatic change across Northern Eurasia. Quaternary Research 53, 302–311.  
Schoof, C., 2010. Ice‐​sheet acceleration driven by melt supply variability. Nature 468, 803–805.  
Vinther, B.M., et al., 2009. Holocene thinning of the Greenland ice sheet. Nature 461, 385–388.
"
"Ryanair has been accused of greenwashing after the UK advertising watchdog banned an ad campaign claiming that the airline has the lowest carbon emissions of any major airline in Europe. The budget airline, which was named last year as one of Europe’s top 10 carbon emitters in an EU report, later ran a TV, press and radio campaign claiming it was “Europe’s lowest fares, lowest emissions airline”. The ads claim that Ryanair has the “lowest carbon emissions of any major airline”, based on CO2 emissions per passenger per kilometre flown, because it has the youngest fleet, highest proportion of seats filled on flights and newest, most fuel-efficient engines. However, one of the charts Ryanair presented to the Advertising Standards Authority to back up its claims was dated 2011, which the watchdog said was “of little value as substantiation for a comparison made in 2019”. The ASA added: “In addition, some well-known airlines did not appear on the chart, so it was not clear whether they had been measured.” The ASA also said that the ads failed to factor in seating density – the number of seats per plane – which it considered “significant information that consumers needed in order to understand the basis of the claim”. The ASA banned the ads ruling that they were misleading because the airline had failed to substantiate its environmental claims. “The ads must not appear again in their current forms,” the ASA said. “We told Ryanair to ensure that when making environmental claims they held adequate evidence to substantiate them and to ensure that the basis of those claims were made clear.” The environmental group Transport & Environment accused Ryanair of greenwashing instead of tackling its emissions. The airline ran the low-emissions ad campaign just over five months after it became the first non-coal company to be named in the EU top 10 carbon emitters list. “Ryanair should stop greenwashing and start doing something to tackle its sky-high emissions,” said Jo Dardenne, the aviation manager of T&E. Ryanair remained defiant, claiming it had abided by the UK advertising code. “Ryanair is both disappointed and surprised that the ASA has issued this ruling given that Ryanair fully complied with advertising regulations, engaging with regulators and providing documentation that fulfilled all the substantiations needed,” said a spokeswoman. The Ryanair boss, Michael O’Leary, has suggested shooting environmentalists and has repeatedly denied that the climate crisis is driven by carbon emissions, which aviation produces in abundance. Last year, Ryanair claimed it was already the greenest airline in terms of carbon emissions per passenger. The company has also pledged to be “plastic free” by 2023 and set up a voluntary carbon offset payment scheme for customers when booking."
"Climate change news can be incredibly depressing. In 2018 alone, The Conversation covered the loss of three trillion tonnes of ice in Antarctica; Brazil’s new president and why he will be disastrous for the Amazon rainforest; a rise in global CO₂ emissions; and a major IPCC report which warned we are unlikely to avoid 1.5℃ of warming.  Then there were the rogue hurricanes, intense heatwaves, massive wildfires and the possibility we are emitting our way towards a Hothouse Earth. Global warming has left some wintery animals with mismatched camouflage, and it may even cause a global beer shortage. But things cannot be entirely bad, can they? We asked some climate researchers to peer through the smog and highlight a few more positive stories from 2018. Rick Greenough, professor of energy systems, De Montfort University 2018 saw the largest annual increase in global renewable generation capacity ever, with new solar photovoltaic capacity outstripping additions in coal, natural gas and nuclear power combined. This is one of several hopeful signs that the “cleantech” sector is rising to the challenge of climate change. The UK, for instance, set new records for wind generation. And now that subsidy-free solar generation has proven possible, there are plans for the UK’s largest solar farm to provide the cheapest electricity on the grid, thanks to battery backup (crucial for intermittent renewable technology). Tesla, meanwhile, installed the world’s largest lithium battery in Australia and it is set to pay back a third of its cost within one year. Mike Wood, reader in applied ecology, University of Salford Three decades ago, the world experienced its worst nuclear accident to date. The damaged Chernobyl nuclear power plant released large quantities of radioactive material into the environment, necessitating evacuation of an area now known as the Chernobyl Exclusion Zone (CEZ). But forget the popularised imagery of a nuclear wasteland; Chernobyl is now home to an amazing diversity of wildlife, its forests are expanding and the future of this region is looking positive.  In the fight against climate change, there is a global need to reduce greenhouse gas emissions and to increase the removal and storage of carbon dioxide from the atmosphere (a process known as carbon sequestration). The ongoing expansion of Chernobyl’s forests means more atmospheric carbon is becoming incorporated into the trees. Additionally, the central part of the CEZ is now home to a major new solar farm development and wind farm development is being considered. Consequently, this post-accident landscape is now contributing to a sustainable future. Anna Pigott, researcher in environmental humanities, Swansea University The Extinction Rebellion direct action movement might not be the most obvious choice for positivity, what with its use of skull imagery and banners such as the one hung over Westminster Bridge in November reading: “Climate Change: We’re F****d”. But a closer look suggests that the movement’s acknowledgement of personal and collective despair in the face of environmental collapse might be a very positive move indeed.  As its co-founder Gail Bradbrook explains, “grief is welcome here – it is an emotional, physical, and spiritual necessity”. Poets and scholars alike have long spoken about how grief mobilises awareness and action, but rarely has this wisdom found its way into large environmental movements.  Pain usefully alerts us to problems that need our attention, and, in the case of climate change and species loss, our grief is a sign that we care deeply. Now is not the time to turn our back on such emotions. As the poet Mary Oliver has written: “You tell me your despair, yours, and I will tell you mine.” For many, the Extinction Rebellion movement has given them permission to grieve, and to share this grief with others. And this could be the most mobilising force for climate action yet.  Daniele Malerba, honorary research fellow, University of Manchester Expansion in the global economy may have peaked, according to the Organisation for Economic Cooperation and Development. The economic think-tank is worried by the slowdown, but it may actually be good news for the climate and possibly for society too. This is because less global economic growth means less production, less consumption – and lower emissions.  But any slowdown or eventual reversal in growth must happen in an equitable way to make sure that human well-being still increases. This is why an increasing number of researchers, politicians and citizens are advocating for degrowth. Degrowth addresses the issue technological improvements are not enough to avoid climate change and an alternative to capitalism is urgently needed. The recent protests in France show that environmental and social issues need to go hand-in-hand. And this is critical in a situation when populist movements are spreading. Degrowth is the solution. As Ghandi once said, we have enough for everybody’s needs, but not everybody’s greed.  Parakram Pyakurel, researcher, Warsash School of Maritime Science and Engineering, Solent University A lot still needs to be done to reduce global carbon dioxide emissions but not all is doom and gloom. For instance, the US, UK and Japan are among the countries whose total carbon emissions from energy fell in 2017 (the most recent year available), according to BP’s statistical review of world energy.  Interestingly, Ukraine showed the greatest reduction, with its 2017 energy emissions around 10% lower than in the previous year. This was thanks to a big fall in coal use, perhaps part of the country’s grand vision of a 2050 low emission development strategy, though it remains to be seen whether Kiev will take the strategy seriously in the long term.  Other nations that managed to reduce their energy emissions include South Africa, Argentina, Mexico and the United Arab Emirates. We’ll need to carefully monitor the statistics in upcoming years to see whether they continue on this path. Rory Telford and Stuart Galloway, Department of Engineering, University of Strathclyde Renewable generation technologies such as wind turbines or solar photovoltaics are now a familiar sight, but many may not realise that communities themselves are accelerating the transition towards low carbon energy. In Scotland, the government’s programme to support local involvement in renewable energy has been a success. An initial target of having 500MW of community and local owned energy was achieved early and with policy stability and continued effort the new 1GW target by 2020 also looks achievable. The Smart Fintry project based in Stirlingshire is an excellent example of a community approach to decentralised energy provision. The project balances local renewable electricity generation with community energy needs via dynamic energy management technology and an innovative tariff. This offers far greater flexibility to the network and cheaper energy for households.  Click here to subscribe to our climate action newsletter. Climate change is inevitable. Our response to it isn’t."
"
 
Given that the sun is so quiet lately (click image – no sunspots) and there is talk of an ebb in its next solar cycle 24, it bears looking into the details of our primary climate driver.
 The National Geographic Channel has a TV special on the sun, sunspots, climate, etc. They interviewed several people involved in that debate. It includes interviews with Judith Lean, Leif Svalgaard, and others.
It will be shown on the National Geographic Channel. It’s titled: Naked Science ‘Solar Force’.
It goes out on Tuesday 30th October 2007 at 9pm ET and again at midnight ET.
It also rebroadcasts on Thursday 1st November 2007 at 10pm ET.
TV listings can be found on http://channel.nationalgeographic.com/channel/ if you are interested.
UPDATE: description from the NGC website –
The suns energy seems to be constant, but this gigantic nuclear reactor is in a continual state of flux. National Geographic Channel (NGC) reveals the latest scientific information that is uncovering the hidden ways that fluctuations in the suns output influence our climate. See how a radical experiment supports the idea that the suns invisible cosmic rays may have a visible impact on our weather, and find out how a new NASA program could shed new light on how solar wind impacts Earth. 


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea2f7f181',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterThe  green dream, with all its scenic beauty and nature conservation, has arrived in northern Germany. But now that green dream faces more obstacles. 

All is not so wunderbar when it comes to Germany’s wind power outlook.
Germany’s Renewable Energy Sources Act, passed in 2000, was intended to ensure the generation of “green” electricity. Operators of wind turbines were guaranteed subsidies for a period of twenty years  – with the hopes the technology would develop to such an extent that it would operate economically without subsidies.
20 years later, the wind turbines are still not competitive reports trendsderzukunft.de here.
Plagued by high costs
The first problem with the old turbines? The costs. They require comparatively frequent maintenance. “This drives up the costs, which is why operation is not economical in many cases.” reports trendsderzukunft.de. “A study has shown that at an electricity price of 3.375 cents euro per kilowatt-hour, only 23 percent of the old plants can be operated without subsidies.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Feed-in requirement running out
The second problem: “The Feed-in priority” law which forced power grid operators to purchase wind electricity. “However, it is unclear whether this regulation will continue to apply despite the expiration of subsidies,” says trendsderzukunft.de. “This question will probably have to be cleared up by the courts in the end. However, many operators will probably not wait for this and prefer to shut down the old wind turbines instead.”
Sites will have to be abandoned
Trendderzukunft.de. adds: “By 2025, there is a risk of losing 2,300 to 2,400 megawatts of capacity every year.”
Moreover, legal hurdles prevent repowering, which involves “replacing several old turbines with one new and larger one.” The problem, reports trendsderzukunft.de  is that at many existing locations “there is a height limit for wind turbines. The installation of the latest generation of wind turbines is therefore not possible there. However, smaller turbines are no longer available on the market. In many cases, therefore, the sites simply have to be abandoned.”
“Imminent catastrophe”
For that reason, around 1,000 of 1691 wind turbine sites are affected in Lower Saxony alone and are currently not available for so-called repowering. “Lower Saxony’s Minister of Energy and Environment, Olaf Lies (SPD), speaks of an imminent ‘catastrophe’ for wind power in Germany,” writes trendsderzukunft.de.


		jQuery(document).ready(function(){
			jQuery('#dd_4233aa9cba44a662eec750787b2ca3fe').on('change', function() {
			  jQuery('#amount_4233aa9cba44a662eec750787b2ca3fe').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
nan
"

Net primary production (NPP) represents the net carbon that is fixed (sequestered) by a given plant community or ecosystem. It is the combined product of climatic, geochemical, ecological, and human effects. In recent years, many have expressed concerns that global terrestrial NPP should be falling due to the many real (and imagined) assaults on Earth's vegetation that have occurred over the past several decades—including wildfires, disease, pest outbreaks, and deforestation, as well as overly-hyped changes in temperature and precipitation.   
  
The second “National Assessment” of the effects of climate change on the United States warns that rising temperatures will necessarily result in the reduced productivity of major crops, such as corn and soybeans, and that crops and livestock will be “increasingly challenged.” Looking to the future, the National Assessment suggests that the situation will only get worse, unless drastic steps are taken to reduce the ongoing rise in the air's CO2 content (e.g., scaling back on the use of fossil fuels that, when burned, produce water and CO2).   
  
But is this really the case? If growing crops are increasingly affected, damage should also be showing up in the global ecosystem. Is the productivity of the biosphere in decline?   
  
In a word, **_no!_** Observational data indicate that just the _opposite_ is occurring (see, for example, the many studies reviewed previously on this topic here). Rather than withering away, biospheric productivity is _increasing_ , thanks in large measure to the growth-enhancing, water-saving, and stress-ameliorating benefits of atmospheric CO2 enrichment.



The latest study to confirm as much comes from the research team of Li _et al_. (2017). Working with a total of 2,196 globally-distributed databases containing observations of NPP, as well as the five environmental variables thought to most impact NPP trends (precipitation, air temperature, leaf area index, fraction of photosynthetically active radiation, and atmospheric CO2 concentration), Li _et al_. analyzed the spatiotemporal patterns of global NPP over the past half century (1961–2010).   
  
Results of their analysis are depicted in the figure below, which shows that global NPP increased significantly from 54.95 Pg C yr-1 in 1961 to 66.75 Pg C yr-1 in 2010 (Figure 1a). That represents a linear increase of 21.5 percent in the last half-century. In quantifying the relative contribution of each of the five variables impacting NPP trends (Figure 1b), Li _et al_. report that “atmospheric CO2 concentration was found to be the dominant factor that controlled the interannual variability and to be the major contribution (45.3%) of global NPP.” Leaf area index, which is also enhanced by increasing atmospheric carbon dioxide, was the second most important factor, contributing an additional 21.8 percent, followed by climate change (precipitation and air temperature together) and the fraction of photosynthetically active radiation, which accounted for the remaining 18.3 and 14.6 percent increase in NPP, respectively. Li _et al_. also report that the vast majority of the observed rise in NPP occurred in the middle and high latitude regions, with 61.1 percent of the increase occurring between 30 and 60 degrees of latitude and 26.4 percent between 60 and 90 degrees of latitude of both hemispheres (see Figure 1c).   






**_Figure 1_** _. (A) Annual variations in global NPP between 1961 and 2010. (B) Changes in NPP in recent decades that resulted from multiple environmental factors including climate, leaf area index (LAI), fraction of photosynthetically active radiation (fPAR), and CO 2, and the relative contribution rate (%) of each factor during the study period. (C) Spatial distribution of the trend in NPP during the period 1961–2010. Source: Li _et al. _(2017)._



The observed increase in global NPP over the past five decades is quite an accomplishment for the terrestrial biosphere, especially when one considers all the negative stories—nary a day goes by without notice of some environmental disaster (human- or naturally-caused) occurring somewhere in the world and wreaking havoc on nature. Since 1980, the Earth has experienced three of the warmest decades in the modern instrumental temperature record, has weathered a handful of intense and persistent El Niño events, and suffered large-scale deforestation, ""unprecedented"" forest fires, disease and pest outbreaks, and episodes of persistent, widespread, and severe droughts and floods. Yet, despite each of these factors, and every other possible negative influence that has occurred over the past half century, terrestrial net primary productivity has increased by 21.5 percent! And it has done so largely because of the ongoing rise in atmospheric CO2. How ironic it is, therefore, that the supposed chief _culprit_ behind the many real (and imagined) assaults on Earth’s vegetation—rising atmospheric CO2—has been found to be the primary _cause_ of an ever-greener planet.   
  
**Reference**   
  
Li, P., Peng, C., Wang, M., Li, W., Zhao, P., Wang, K., Yang, Y. and Zhu, Q. (2017) ""Quantification of the response of global terrestrial net primary production to multifactor global change."" _Ecological Indicators_ **76** : 245–255.


"
"We are living on the planet of the chickens. The broiler (meat) chicken now outweighs all wild birds put together by three to one. It is the most numerous vertebrate (not just bird) species on land, with 23 billion alive at any one time. Across the world, chicken is the most commonly eaten meat. This has made it a vivid symbol of the Anthropocene – the proposed new geological epoch that marks the overwhelming impact of humans on the Earth’s surface geological processes. The modern bird is now so changed from its ancestors, that its distinctive bones will undoubtedly become fossilised markers of the time when humans reigned the planet.  In a recent study together with colleagues, published by Royal Society Open Science, we compared the bones of the modern meat chicken to the bones of their ancestors dating back to Roman times. Modern broiler chickens are radically different – they have a super-sized skeleton, distinct bone chemistry reflecting the homogeneity of their diet and significantly reduced genetic diversity. This is because a modern broiler is twice the size of a chicken from the medieval period and they have been bred for one thing: rapid weight gain.  The speed of growth accelerated in the second half of the 20th century, with the modern broiler putting on weight five times faster than meat chickens from the 1950s. The result is that at just five or six weeks old they are already slaughter ready. The evidence of this extraordinary growth is preserved in their bones, which are less dense and often deformed. Poignantly, these birds cannot even be “rescued” from their factory farms – the strain of their enormous body means that if left to live even for another month, many birds die from heart or respiratory failure.  The modern chicken only exists in its current form due to human intervention. We have altered their genes to mutate the receptor which regulates their metabolism, which means that the birds are always hungry and so will eat and grow more rapidly. Not only that, their entire life cycle is controlled by human technology. For example, the chickens are hatched in factories with computer-controlled temperature and humidity. From one day old, they live under electric lights to maximise the hours they can feed. Their slaughter by machine allows for thousands of birds to be processed every hour. Domesticated cows, pigs and sheep each number a billion or so, but it is chickens that are the most striking example of the modern biosphere. Their bones are scattered across landfill sites and farms worldwide and therefore have a good chance of being preserved in the rock record as symbols of how our planet and its biosphere has changed from its pre-human state to one dominated by humans and our domesticated animals.  While humans have been selectively breeding chickens since their domestication in south-east Asia around 6,000 years ago, the speed and scale of change in the 20th century is far beyond anything observed in the past. From the 1950s, the chicken population has risen in step with the rise in human population, as has our use of fossil fuels, plastics and other resources: now, this enfeebled and short-lived animal is more numerous than any bird species in Earth history. What does the future hold? Right now, chicken consumption is on the rise. The meat is cheap, and many are moving away from beef and pork in order to reduce their greenhouse gas emissions. Somehow we must adapt to a growing population in a world affected by climate change. But business as usual may be off the cards. In a surprising move, the world’s largest chicken producers – Tyson Foods and Perdue Farms – are now investing in plant-based proteins. Does this mean the era of chickens could be over in a (geological) instant?  Nevertheless, the record of this human-engineered bird will be forever set in stone. Any intelligent species which arises in the far future – hyper-evolved rats or octopuses, perhaps? – will have a puzzle on their hands (or tentacles) in trying to figure out how and why millions of these rapidly-evolved bones lie mixed with the technofossil debris of the huge petrified dumpsites we will leave behind. As these future explorers reconstruct this bird – a creature far more helpless than the dodo – they may well rumble it too as a technological construct."
"A few years ago, I found myself in Gunaikurnai country, in a place more recently given the lusty name Paradise Beach. I was driven there by my own strong settler/coloniser impulse, after googling a list of “cheapest beachside addresses in Australia”. My notion was that, given the unlikeliness of my owning an everyday home, I could skip straight to “beach house”. I was looking to cut off a slice of so called Australia, put a fence around it, and indulge in endless summer. I booked an extraordinarily cheap Airbnb and decided to take a recce. I sped up the highway past the smoking Hazelwood power station and Loy Yang open-cut brown coalmine before turning onto a lonely, unpoliced road through vast swathes of clear-cut pine plantations and agricultural green. I hit Paradise singing country music, taking note of the free but nearly empty RV park, the foreclosed takeaway joint and general store selling nothing but booze and tackle. The action in town was clearly at the two real estate agents, side by side like gunslingers on a dusty main drag.  The whole area smacked of grand enterprise unfulfilled. Fibro shacks, flat pack houses and shanti lean-tos hustled together in the scrubby blocks on streets named Bondi and Clovelly for wealthier beaches. “It’s like the 1970s there,” I’d henceforth tell anyone willing to ignore my 1983 birthdate and nostalgically understand the 70s to mean rebellion, entitlement and AC/DC in any order or combination. My dating of Paradise Beach turned out to be, in part, accurate. In the 19th century the Gippsland Lakes were opened up for the purpose of transport and fishery. As a result freshwater environments turned brackish, and the periodically inundated land between the lakes and Bass Strait dried out, leaving stretches that could be occupied, European style, after centuries of Indigenous custodianship. In the mid-20th century some men from council, development and advertising got together to launch the Golden Beach Club Estate plan, and other assorted dreamland havens; marketing cheap subdivisions on “mile after mile of glittering golden sand” to new Australians looking to purchase a postcard-worthy plot. 1954 advertising copy heralds a holiday haven of fishing, duck shooting, and jaunts on the Tambo Princess cruiseliner. An offset-printed bathing beauty with perfect blonde pin curls and bedroom eyes preens on the shore of a future that would never be. “A New Gold Coast is born!” runs the slogan. Reader, it is not. The dream stalled. And by the 1970s concerns about building homes on a sandy wedge between the ocean and a wet place were conceded. Though many subdivisions were sold, only three areas were approved for decidedly un-Gold-Coastian development. Paradise Beach is, despite mid-century ambitions, a tiny, mostly unoccupied clutch of residential zoning near the middle of the fourth longest uninterrupted beach in the world. Often deserted and unswimmable, the ocean itself is commonly a rough, relentless, reminder that you are standing at the edge of the world. Sometimes though, it can be glassy, flat, grey or green and clotted with weed – a visual image of consciousness. The sand is indeed golden, the scrubland behind virtually indistinguishable mile by mile. I have walked along this looping landscape for so long that my brain clicks, the idea of change becomes wholly theoretical and time plunges into the swell, opening out to infinity. That first trip to Paradise Beach I finished writing a book, danced alone on the sand, read for hours, swam, yelled at the wind; felt wild, young and free. I know that it’s a well-wrung cliché for a writer to walk on a beach and think about infinity and maybe pick up some shells and marvel at all they cannot understand. But I’m trying to bounce between the poetic and the practical here in a way that’s productive. I bring you to this place and hand you this mixed bag of facts and emotions because I want to demonstrate how the places and times we find ourselves feeling in can connect to complicated histories and futures. The emergency of today is also the one we have been producing via colonialism and capitalism for hundreds of years. Writing in an emergency means attending to this complexity, becoming unable to render the world as only a backdrop for individual human drama and aspiration. As the summer of 2019 hit, we all watched places we love burn. Exhausted volunteers worked themselves to husks defending trees, houses and animals. Fire sliced up the map. Fence lines blurred and fell. I scrolled through images of eerie orange cities and koalas venturing onto the hot tar to drink from plastic bottles. I, like many, wondered if Australian summer would ever be the same. Perhaps in denial or determination, I checked the requisite disaster apps, packed up the station wagon and headed to Paradise Beach. But when I vaulted across the empty campground and onto the sand, the beach had changed. It was a hot midweek day, the first of the smoky ones for Melbourne, and there, in the middle of infinity, was an offshore drilling rig. I tried to ignore the thing. I walked along the beach waiting for my angst to melt and my brain to kick into infinity-mode, but it wouldn’t. The massive rig commanded my eye with its ominous steel limbs. It reminded me of all the others I’ve seen. Gas drilling rigs in the Arafura, the Montara oil spill in the Timor Sea, the flaming Deepwater Horizon in the Gulf of Mexico, all reaching back to 1989, when I sat baffled in front of the news watching people clean oil from seals as my mother attempted to explain how we extract oil and gas and burn it to make energy but it’s not safe, or forever, and sometimes things go very wrong. A rig. An anchor for anxiety and finite time. How many parents are attempting these explanations for their children now? The rig off Paradise Beach is an experimental driller for “Carbon Net”, a carbon capture and storage project capable of processing a promotional video extols, “the equivalent of CO2 emissions from around one million cars every year that it operates”. The comparison is misleading however, as Carbon Net will not capture emissions from the air but from high polluting industrial sites in the Latrobe Valley, piping them seaward to inject into layers of sandstone deep in Bass Strait. In this state of emergency, I know that decarbonisation should be our priority. I don’t know enough about CCS to rail against it here, though phrases like “clean coal” juxtaposed with “gradual or catastrophic leakage” pique the imagination in terrifying ways, threatening ugly texts and futures. I can understand why the residents of Paradise Beach have gone full Nimby on the project, which exemplifies ongoing exploitative relationships between urban, regional and rural areas and shows, for at least the second time in 75 years, and the third in 200, how one stretch of ocean can be sized up for an unproven and risky future. The greater argument here though, is not strictly against Carbon Net and CCS per se but against overinvestment in anything, whether material (like infrastructure) or immaterial (like rhetoric), that insists capitalism is an infinite jaunt along golden dunes. Anxiety about our future is not paranoia, but comes from a rising understanding that the way we live now is incompatible with climate action. The grief and pain we feel is our sense of responsibility smashing against our desire for tomorrow to be the same as, or better than, yesterday. We are at a moment in time that smacks of grand enterprise gone awry. We need to back out, decide what to relinquish (perhaps highly polluting industries and a colonial conception of home) instead of scrabbling to scaffold our out-of-date dreams of paradise. And the time to do this is now, was now in 1954, and 1970 and now and now and now – there is no other time. Writing probably doesn’t feel like the most crucial response here, and maybe it’s not. There is lots of other work to be done. But writing can help us see connections, record violence, build empathy, address possible futures. Writing in an emergency means pulling yourself back from the nostalgic deep dive. It means unwriting our lusty paradises, because they never were. As I drove home early through a smoke-hazy sunset, it occurred to me that a new kind of discipline might develop when you are on edge – I am a woman writer at the edge of this era of denial, of her emotional tether, of her store of patience with governance and systems of power. I am also a woman driven to the literal edge of a landmass by double-edged desires for escape and the illusion of home, looking out to imagined infinity and a very real drilling rig. Seeing rare Burrunan dolphins breaching blue waves, flocks of black and white cockatoos crisscrossing a luminous red sky and still only partially comprehending how much is at stake. Lucky Ticket by Joey Bui (Text Publishing) Songspirals by Gay’wu Group of Women (Allen & Unwin) See What You Made Me Do by Jess Hill (Black Inc) The House of Youssef by Yumna Kassab (Giramondo Publishing) Diving into Glass by Caro Llewellyn (Penguin Random House) When One Person Dies the Whole World is Over by Mandy Ord (Brow Books) There Was Still Love by Favel Parrett (Hachette Australia) Here Until August by Josephine Rowe (Black Inc) This is How We Change the Ending by Vikki Wakefield (Text Publishing) The Yield by Tara June Winch (Penguin Random House) The Weekend by Charlotte Wood (Allen & Unwin) Paper Emperors by Sally Young (NewSouth Publishing) The winner of the Stella prize will be announced in Sydney on Wednesday 8 April.  • Briohny Doyle is the author of The Island Will Sink and Adult Fantasy. She is a lecturer in creative writing at Deakin University"
"Jeremy Corbyn has accused Boris Johnson of “failing spectacularly” to measure up to the scale of the climate crisis, after the sacked president of COP 26 revealed the UK was miles behind in getting ready for the November summit. Speaking at prime minister’s questions, Corbyn raised the government’s failure to organise COP 26 properly, after Johnson’s team sacked Claire O’Neill as the summit’s president just days before its formal launch. Corbyn highlighted O’Neill’s criticisms that “there has been a huge lack of leadership and engagement from this government” over the climate crisis conference. But Johnson dismissed the attack, saying all that Corbyn would produce on tackling global heating was “a load of hot air”. “If you look at what this government is achieving and already has achieved on climate change, it is quite phenomenal,” Johnson claimed. The international COP 26 summit is due to take place in November in Glasgow but is without a leader after David Cameron and William Hague both turned down the vacant role of president. Corbyn noted that two former Conservative leaders had turned down the job, joking that “maybe it could be third time lucky”, as he suggested Sir Iain Duncan Smith for the role. Labour said its suggestion would be for Ed Miliband, the former energy secretary and ex-Labour leader, to take over the presidency as he had the experience. Corbyn’s spokesman said: “Ed Miliband is certainly someone who has a strong record and an entirely suitable person. The issue is not exactly who should take on the role but someone with credibility.” The Labour leader went on to criticise Johnson’s record on climate change, highlighting the comments from the prime minister that were sceptical of climate science until as recently as four years ago. “Considering his monumental failure in advance of COP 26, isn’t it really just a continuation of his climate change denial statements that he was regularly making up until 2015?” Corbyn said. Johnson said Corbyn was “talking absolute nonsense” and defended the government’s agenda, saying: “We lead the world in going for a zero-carbon approach. His own approach is utterly unclear and has been condemned by the GMB as a disaster for the UK economy. “He would confiscate people’s cars and prevent them from having foreign holidays.” Corbyn countered that the prime minister had a “very vivid imagination”, adding: “Unfortunately, his vivid imagination seems to have taken over from his memory because he might recall saying that climate change is a primitive fear without foundation.”"
nan
"The world is facing a series of interlinked emergencies that are threatening the existence of humans, because the sum of the effects of the crises is much greater than their individual impacts, according to a new global study. Climate breakdown and extreme weather, species loss, water scarcity and a food production crisis are all serious in themselves, but the combination of all five together is amplifying the risks of each, creating a perfect storm that threatens to engulf humanity unless swift action is taken.  The links among the crises are clear in many cases, but the methods the world has chosen to try to solve them do not take account of these connecting factors. For instance, extreme heatwaves can add to global heating, because they release vast amounts of stored carbon from affected ecosystems, in a feedback loop. It has been seen clearly in the Australian bushfires, which are already contributing significantly to the store of carbon in the atmosphere. The links do not stop there: as the heatwaves damage natural ecosystems, killing off wildlife and flora, they also lead to greater water scarcity, and in turn damage agriculture. These combined effects exacerbate the harm done to people struggling with food and water shortages, in a vicious cycle. Faced with these crises in nature individually, it could be possible to fix the problems causing them. But confronted with multiple interlinked emergencies that in combination amplify one another’s impacts, people are facing unprecedented dangers and many communities cannot cope. The report, which took the form of a survey of 222 leading scientists from 52 countries, conducted by the international sustainability network Future Earth, found that the responses to these emergencies by governments, civil society, business and institutions did not recognise their interlinked nature. Trying to solve the problems individually, without taking account of the “cascading” impacts, was likely to be ineffective, the scientists said. More than a third of the scientists surveyed said the five crisis types would worsen one another “in ways that might cascade to create global systemic collapse”. While the risks are amplified when they are connected, so too are the solutions, however. Whenever action is taken to remedy environmental problems, the benefits also cascade: for instance, nurturing wildlife and flora in a wetland can also reduce water pollution and soil erosion, and protect crops against storm damage, alleviating water scarcity and allowing for more food production. “Despite the ubiquity of connections [between these looming crises] many scientists and policymakers are embedded in institutions that are used to thinking and acting on isolated risks, one at a time,” the report says. “This needs to change, to thinking about risks as connected.” Amy Luers, the executive director of Future Earth, said: “2020 is a critical time to look at these issues. Our actions in the next decade will determine our collective future on Earth.” The authors of the report urged a change in the way risks were handled: “We call on the world’s academics, business leaders and policymakers to pay urgent attention to these five global risks, and to ensure they are treated as interacting systems, rather than addressed one at a time in isolation.” The report also warned of social problems that scientists identified as potential major risks for the future. These included the rise of populism and fake news, trends in migration and the rise of artificial intelligence."
"

Asked recently when the Senate might vote on cap‐​and‐​trade, Senate Majority Leader Harry Reid, D-NV, demurred, muttering about “a busy, busy time the rest of this year.” And yet last week, the Obama administration quietly moved forward with a plan to regulate power plants and other large stationary sources of greenhouse gases.



The Obama team appears to believe it has the authority to implement comprehensive climate change regulation, Congress be damned. Worse still, under current constitutional law–which has little to do with the actual Constitution–they’re probably right.



In a democratic country, you’d think that before the executive branch could regulate CO2–a ubiquitous substance essential to life–the legislature would have to vote on the issue. But you’d be wrong.



In 2007, the Supreme Court ruled that the 1970 Clean Air Act’s definition of air pollutant was broad enough to allow regulation of CO2 emissions from new cars, and that the EPA was required to regulate once it issued a finding that CO2 contributes to global warming. In fact, once the EPA rules that CO2 is a dangerous pollutant–as it did in April–regulation of industrial sources likely becomes mandatory as well.





As Obama’s popularity erodes, he may come to like the idea of being the ‘decider.’



But existing law still leaves the executive branch enormous discretionary power–and thus a hammer to hold over Congress’s head. A report issued in April by the New York University Law School argues that “if Congress fails to act, President Obama has the power under the Clean Air Act to adopt a cap‐​and‐​trade system.”



James Madison believed that there could be “no liberty where the legislative and executive powers are united in the same person.” And yet, here we are, with those powers united in the person of a president who has pledged to heal the planet and stop the oceans’ rise.



This constitutional nightmare is the culmination of a trend many years in the making. The first sentence of the Constitution’s first article says that “all legislative Powers herein granted” are vested in Congress.



The Supreme Court once took that language seriously, as when, in 1935, it struck down a key New Deal program for delegating legislative power to the executive. Yet the Court eventually made its peace with statutes that allow the executive branch to both make and enforce the law.



That paved the way for the modern administrative state, which looks a lot like the situation complained of in the Declaration of Independence, in which “a multitude of New Offices… harass our people and eat out their substance.”



After 9/11, the phrase “unitary executive theory” (UET) came to stand for the idea that the president can do whatever he pleases in the national security arena. But it originally stood for a humbler proposition: UET’s architects in the Reagan administration argued that the Constitution’s grant of executive power to the president meant that he controlled the executive branch, and could therefore rein in aggressive regulatory agencies.



In an era when Republicans held a virtual lock on the Electoral College, that idea had some appeal. But as Elena Kagan, now President Obama’s Solicitor General, pointed out in a 2001 Harvard Law Review article, there’s little reason to think that “presidential supervision of administration inherently cuts in a deregulatory direction.”



How far will Obama push in the other direction? He may be reluctant to stretch his authority as far as the law will allow, in a political climate where even green‐​leaning Democrats scream bloody murder every time gas prices rise.



But as Kagan notes, after the Democrats lost control of Congress in 1994, President Clinton used his regulatory authority unilaterally to show progress, pushing “a distinctly activist and pro‐​regulatory agenda.” As Obama’s popularity erodes, he may come to like the idea of being the “decider.”



Will liberals who decried George W. Bush’s unilateralism object to this staggering concentration of executive power? Don’t hold your breath.
"
"
Share this...FacebookTwitterBy Kirye
and Pierre Gosselin
It’s well known that the United States suffered severe drought and record high temperatures back in the 1930s, which we know resulted in the famous Dust Bowl and economic hardship across North America.
But now, from a climate point of view, that period has become an embarrassment to the scientists who propose the anthropogenic global warming theory. Atmospheric CO2 concentrations were much lower back then, and so according to their theory,  it should have been cooler than it is today. But it wasn’t.
But instead of questioning CO2’s role in driving global temperature, NASA GISS has decided to just rewrite the historical data so that it fits their flakey theory. This of course is scientific fraud.
Today we examine NASA GISS data for the Wellsboro station in Pennsylvania. First we look at the Version 4 “unadjusted” annual mean temperature data and compare it to the new Version 4 “homogenized” data:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Data: NASA GISS
Above we see how NASA scientists simply went back in the old datasets and simply rewrote them so that the hot years of the early 20th century are cooled tremendously – by over two degrees in many years.
Earlier Wellsboro saw a cooling trend. But now since NASA scientists have fiddled with the data, the trend has been forged to fit the AGW theory.
Next is a chart comparing version 3, which starts in 1883 and ends in 2019, to Version 4, which starts in 1882:

Version 4 data source: NASA GISS, Version 3 here.
The earlier Version 3 also showed cooling before NASA rewrote the data and wiped it out. The current Version 4 used to show cooling, but was that too was tampered with and now it shows strong warming.
Many would argue that this is not science, but outright Orwellian scientific fraud.


		jQuery(document).ready(function(){
			jQuery('#dd_03feef225a932a34440c9fc287be9307').on('change', function() {
			  jQuery('#amount_03feef225a932a34440c9fc287be9307').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAs the globe has warmed since the end of the Little Ice Age, alarms concerning retreating glaciers have been sounded worldwide. The reason for the warming remains hotly disputed: alarmists blame it on manmade CO2 while skeptics say natural factors are just as much at play, if not more so.

Image: Norwegian glace, for illustration purpose. Source: NASA/John Sonntag, public domain.
Very little retreat in Norway this past summer
Yesterday Norwegian NRK here reported “several of the largest glaciers have almost not shrunk” during this past summer.
“This year, several places in the country have almost not shrunk,” according to the Norwegian NVE.
Since 1962 experts have been monitoring the Nigardsbreen glacier, an arm of Jostedalsbreen located in Vestland county.  The summer of 2020 has seen the sixth slowest result in about half a century. “If we get more such summers to come, then the glacier front will grow forward again,” says Even Loe in Statkraft.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“The glacier is named after the farm Nigard, which was crushed by the glacier in 1748. At that time the front of the glacier stopped about 4.5 km further ahead than it is today,” reports the NRK.
Experts attribute this past summer’s stagnation to “a good winter with a lot of snow.”
“The Nigardsbreen glacier has actually grown bigger.”
Glaciologist Hallgeir Elvehøywhich said the glacier retreated 4 meters, “something that is very small compared to previous ones.”
“The trend is largely the same elsewhere in the country,” he says.
Although many glaciers have decreased relatively little this year, the Norwegian experts still remain pessimistic about their future, should warming continue as the models project. “But in all the gloom, there is also a small glimmer of light, should the rainfall continue.”
“There is nothing in the way that the climate system can give us several years with so much snow, and then it will have an effect.”


		jQuery(document).ready(function(){
			jQuery('#dd_d715d3c01e279f99b82ff2c7fb93a8ba').on('change', function() {
			  jQuery('#amount_d715d3c01e279f99b82ff2c7fb93a8ba').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"

Advocates for robust American global leadership are having a bad decade. Donald Trump’s election was clearly a wake‐​up call to the foreign policy establishment in Washington. In contrast to decades of bipartisan consensus that the United States was the “indispensable nation,” Trump appears to be monumentally indifferent to America’s role in the world.



His tense relations with longstanding allies and his decisions to withdraw from the Trans‐​Pacific Partnership and the Paris climate treaty have moved critics like former national security adviser Susan Rice to argue that Trump is “undoing American leadership on the international stage.”



Fears about Trump, however, simply echo concerns voiced throughout the Obama administration. Critics point to Obama’s withdrawal from Iraq, his failure to intervene in the Syrian civil war, and his failure to check Russia over Crimea and Ukraine as evidence of unhealthy retrenchment resulting in “the desperation of our allies and the glee of our enemies.”





The United States, and the world, would be better off if America led less often and more thoughtfully.



The real issue, however, is not America’s failure to lead; it is the failure of American leadership. Since the end of the Cold War the United States has flexed its muscles repeatedly. The problem is that this has too often produced resentment, conflict and instability, precisely the opposite of what its proponents have promised. The fundamental reason for this failure is that American officials have too much faith in their power to dictate outcomes around the world, especially through the use of military force.



The past 15 years provide ample evidence of the perils of leadership. After the 9/11 attacks, the Bush administration launched a war on terrorism based on a strategy combining military intervention, regime change and nation building. The goal was to kill terrorists in the short run, destroy their organizations in the medium run, and over the long run to reshape the politics of nations to prevent terrorism from sprouting up in the first place.



The Obama administration mostly followed suit, scaling back in Iraq but pursuing regime change in Libya, surging in Afghanistan and expanding the drone war against terrorists in seven countries. Today the Trump administration has begun to escalate the fight against the Islamic State and al‐​Qaeda, empowering the Pentagon and the military to determine troop levels and make swifter battlefield decisions.



The problem in the Middle East hasn’t been the lack of leadership; the problem has been the failure to recognize that the American strategy has been a failure. Political leaders exaggerated the terrorist threat to the United States and then applied the wrong tools to the problem. Military intervention turned out to be great for getting rid of governments, but completely ineffectual at defeating terrorist organizations.



Since 2001 the number of terrorist groups and jihadist fighters has skyrocketed, al‐​Qaeda franchises continue to operate, and the invasion of Iraq inadvertently caused the chaos that helped the Islamic State take root. Everywhere the United States has intervened — whether by drone or by invasion — since 2001, in fact, is less stable and more violent today than it was before.



Nor has the nation‐​building game gone any better. The United States has spent billions of dollars on nation‐​building efforts in Iraq and Afghanistan rebuilding infrastructure, training the police and military troops, and providing internal defense against terrorists. The hard truth, however, is that neither country is a functioning democracy, neither is stable, and neither would last long without outside support.



Meanwhile, the failure of the war on terror has come with astronomical costs, both for the United States and for the Middle East. The United States has already spent trillions of dollars and seen 7,000 Americans killed in the fighting, while according to NGOs somewhere between 1.3 million and 2 million Iraqis, Afghans and Pakistanis have died. This doesn’t count those in Libya, Yemen, Syria or elsewhere whose deaths are a result of U.S. intervention and its consequences.



Sadly, despite this recent history, there is little sign that Washington is ready to recognize the limits of American leadership. Though the Trump administration may frustrate the foreign policy establishment on certain issues, it is clear that American reliance on military intervention in the Middle East is here to stay.



American leadership can indeed be a powerful influence for good, but the United States is neither all‐​powerful nor faultless. The United States, and the world, would be better off if America led less often and more thoughtfully.
"
"
Share this...FacebookTwitterThe Kyushu region of Japan has been getting lots of rain lately, which has led to flooding and 62 reported deaths because local officials failed to properly heed warnings to evacuate.
The New York Times, however, blames it all on the “collision” of “demographic change and global warming” instead of incompetence by local authorities.
NYT claims: “More torrential rains”
“In recent years, climate change has spurred more torrential rains in Japan, causing deadly flooding and mudslides in a nation with many rivers and mountains,” reports Motoko Rich of the New York Times (NYT).
Unfortunately the NYT neither provides data nor cites any study showing this to be the case.
So we look at Japan precipitation trends going back decades – something the NYT journalists obviously neglected to do themselves (or they did, but then decided not to bring it up).
JMA data tell a whole different story
Using data from the Japan Meteorological Agency (JMA), Japanese blogger Kirye first plotted the annual precipitation anomaly for Japan since 1898:

Data source: here
The plotted data above show how Japan’s precipitation has indeed trended downward somewhat since 1898, and not risen.
The most recent decade in Japan has seen precipitation levels similar to that of the 1950s, and the very early part of the 20th century. Nothing unusual is happening here.
Next we look at the JMA annual precipitation data for Hitoyoshi, Kumamoto Prefecture itself since 1948:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Data source: here
Here we observe very little trend change at all. The recent rainfall in the region over the past decade has been similar to that seen in the 1950s. Extremes are no more intense or frequent today than they were in the past.
No July precipitation trend changes
Going a step further into greater detail, we look at the southern Japan region’s rainfall for July, going back to 1948.

Data source: here
Also the here we have the same story: no major trend changes to speak of. Very wet July months in fact were just as frequent and more intense in 1950s.
Decreasing hot days
Finally we look at the region’s number of days recording a temperature of 30°C or higher.

Data source here
Here as well the REAL trend is in fact bucking what the NYT always likes to suggest: increasingly more hot days because of global warming.
Incompetent authorities after all
Later in the article, Rich does ultimately get around to the real cause of the recent flooding deaths in Kyushu: “The Japanese government issues standardized evacuation protocols, but they do not take into account the unique characteristics or terrain in different parts of the country, said Professor Tsukahara of Kyushu University.”
But all in all, very shoddy journalism here by the New York Times. They would do their readers a service by checking the data instead of lazily repeating old, exaggerated narratives.


		jQuery(document).ready(function(){
			jQuery('#dd_50a36dd65648004a6024adc66f4c2a06').on('change', function() {
			  jQuery('#amount_50a36dd65648004a6024adc66f4c2a06').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"
Share this...FacebookTwitterOur friend “SnowFan” here looks at the claims that September 2020 was the warmest ever recorded. It turns out that other measurement advanced satellites don’t agree.
According to the much ballyhooed data, temperatures in Europe in September this year were on average 0.2 degrees Celsius higher than in the previous record September 2018. The service providing the data is part of the European earth observation program Copernicus.
But the satellite data from the UAH and RSS both agree that this is not really the case!

Above the global satellite data from UAH (left) and from RSS (right) in the tables clearly clearly show the monthly deviations from the WMO mean 1981-2010 (UAH) and from the climate mean 1979-1998 (RSS): September 2020 was not the warmest since satellite measurements began in 1979. At UAH, September 2019 was slightly warmer while at RSS even September 2017 was warmer.
Strong La Nina may be in the works


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Overall the globe’s surface continues to cool since the peak of the 2015/16 El Nino, and that cooling will very likely continue if NASA and the US National Weather Service projections are correct. Both Agencies see a significant La Nina in the pipeline for 2021.

The current ENSO forecasts of NASA (left) and NOAA (right) from October 6, 2020, predict an unusually strong La Niña in the equatorial Pacific with temperature deviations down to -3°C and with unusually long duration until the NH summer of 2021.
Such a strong event would certainly lead remarkable surface cooling. Source: BOM ENSO models with additions.


 


		jQuery(document).ready(function(){
			jQuery('#dd_e2c39a96e5018d087a7844243e936550').on('change', function() {
			  jQuery('#amount_e2c39a96e5018d087a7844243e936550').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"The equivalent of one truck of plastic waste is dumped into the ocean every minute, but what if it could be caught and removed before it drifted out to sea? One such solution, called the Recycled Park Project, is being floated in Rotterdam. Developed over the last five years, the idea is turning plastic waste into islands. The Recycled Island Foundation and the WHIM Architecture firm launched the Recycled Park Project in 2014 with the aim of catching plastic waste in Rotterdam’s New Meuse river before it enters the North Sea. Three floating litter traps with nets attached collect litter in the water while volunteers sweep the riverbank. The retrieved plastic is converted into hexagonal building blocks which have been used to build a floating island park in the river itself. The park is open to the community and filled with plants and benches, giving people a new green habitat to enjoy in the heart of the city. A 140 square metre prototype was opened to the public in July 2018. It’s hoped that five more plastic litter traps can be added to the river, creating an island of at least 190 square metres. If successful, similar islands could be built worldwide, with research ongoing in Indonesia. The River Meuse carries a huge amount of plastic waste which is exposed after high tide on the river banks. By removing plastic from the river, the more costly and difficult job of removing it from the North Sea is avoided. Despite the obvious benefits, however, retrieving plastic waste from the river is technically illegal. Waste in the New Meuse River still legally belongs to whoever discarded it, as EU law states that waste may not be abandoned and littering is a form of abandonment. So, the taking and using of this waste in theory amounts to stealing from its most recent owner. But since there’s no way of identifying to whom the litter belongs and with no way of identifying ownership, it’s socially acceptable for anyone to take and use plastic waste in rivers. In order to encourage more reuse and recycling, we need to start treating waste as our communal property. A communal approach would encourage a sense of responsibility for waste and ensure that the community reaps the benefits of any solution, such as a floating park. So how would communal approaches work in practice? There would need to be a clear stage at which waste becomes communal property. This could be, for example, by making contents in specific bins free for people to take and use. For households in the UK, the contents of a bin belongs to the householder until it is removed by the local authority.  


      Read more:
      A rubbish idea: how blockchains could tackle the world's waste problem


 It’s not free for others to take and use it, either before, during or after collection, including by the employees of the waste management services. In one legal case, waste management workers for a corporation were convicted of stealing goods from bins collected in the course of their duties. Once waste is collected, it becomes the property of the local authority responsible for managing the waste. Communal bins would provide an additional benefit if combined with rules that require the contents to stay within the community. Local dumps already exist, but much of this waste is currently being taken elsewhere for landfill or exported to other countries.  If at least some waste were to stay permanently in the communities in which it’s created, people would be faced by the vast amounts of waste they produce and could see the benefits of producing less of it. The current system of privatising waste is failing to curb the pollution crisis, but with a communal approach, people would have the right to launch creative solutions of their own. We need the freedom to imagine different ways of living with the plastic our modern world accumulates."
"The first International Polar Year, held over 1882–1883, was an important event for science. The year was the brainchild of Austrian explorer Karl Weyprecht who, after a few years on different research missions, realised that scientists were missing the big picture by not sharing information with each other.  In 1875, at the annual meeting of German Scientists and Physicians in Graz, Austria, he proposed the setting up of an observational network of research stations to monitor the Arctic climate. It was the beginning of collaborative research in the region. Today, data collected 134 years ago on temperature, air pressure, or wind speed is still freely available.  There have been two more International Polar Year events since that inaugural one, most recently in 2007–2008, along with numerous other collaborative expeditions and research missions aimed at understanding aspects of Arctic biology, ecology, climate or geology.  But these co-ordinated efforts are the exception rather than the rule. Instead, most research locations north of the Arctic Circle have developed via a range of particular historical contingencies (easy access by boat or road, for instance, or a stable and open political climate), many of which have had nothing to do with scientific considerations.  Since the Arctic covers some 14.5m square kilometers, and conducting research in remote locations is very expensive, time consuming and often dangerous, the result is an extremely uneven concentration of research effort. The region is warming faster than anywhere else on Earth and its polar bears and melting glaciers have become a key symbols of climate change. But the Arctic, it seems, is not as well researched as we think it is.  We wanted to put some hard numbers behind this opinion, and to explore what these geographic gaps may mean in terms of broader scientific understanding. That’s what inspired our research project, carried out with colleagues and published earlier in 2018 in Nature Ecology & Evolution. We looked at 1,840 published studies across the Arctic dating back to 1951.  These studies covered nine broad disciplines in the natural and physical sciences and contained 6,246 sampling locations. We also looked at a total of 58,215 citations that refer to the studies. Citations of a particular study signify the amount of times it has been mentioned in other studies and is one indicator of importance within its discipline.  We found that a third of all study citations originate from sites within 50km of two research stations: Toolik Lake in Alaska and Abisko in Sweden. Our results show that for two important variables, temperature and vegetation density, the present pattern of sampling locations in the Arctic represents the average conditions well, but does not represent extreme conditions that are widespread across the region. The focus on Scandinavia and Alaska means that results from these sites are extended to other locations. The assumption that conditions in two well-studied sites are representative across the Arctic results in the under-sampling of more remote locations. These include vast regions that are relatively colder and warming more rapidly such as Russia’s northern coastline or the thousands of islands that make up Canada’s Arctic Archipelago.  It’s a substantial unknown. Although other parts of Canada and Russia are reasonably well sampled, they too have received considerably less citations, which leads to the poorer dissemination of the knowledge created in these studies. In this way, our understanding of the impact of climate change on the Arctic is biased in favour of sites that are well connected and well resourced.  It is important to note that we are not discounting the wealth of Arctic research conducted in Scandinavia and Alaska. Research at those sites has been, and continues to be, valuable and has enhanced our understanding of Arctic processes within their vicinity. For example, a wetland near Abisko has been studied for three decades during which time there has been an increase in methane emissions as the permafrost (frozen ground) thaws. Similarly, the discovery that the transport of carbon from land to water was much larger in tundra ecosystems than previously thought was uncovered by researchers at Toolik Lake back in the early 1990s.  Regardless of discipline, when looking for scientific evidence, it is habitual to cite research from well known and established locations. One way we could make our understanding of the Arctic more representative is to diversify our research citations by citing research that has been conducted in under-cited or under-sampled locations. Another way is to prioritise research at those under-sampled areas and (try to) convince funding agencies that research in those areas will fill gaps in our knowledge and result in more representative information about the Arctic. We hope our work will aid other scientists in making that point."
nan
nan
"
NOTE: Earlier today I posted a paper from Joe D’Aleo on how he has found strong correlations between the oceans multidecadal oscillations, PDO and AMO, and surface temperature, followed by finding no strong correlation between CO2 and surface temperatures. See that article here:
Warming Trend: PDO And Solar Correlate Better Than CO2
Now within hours of that, Roy Spencer of the National Space Science and Technology Center at University of Alabama, Huntsville,  sends me and others this paper where he postulates that the ocean may be the main driver of CO2. 
In the flurry of emails that followed, Joe D’Aleo provided this graph of CO2 variations correlated by El Nino/La Nina /Volcanic event years which is relevant to the discussion. Additionally for my laymen readers, a graph of CO2 solubility in water versus temperature is also relevant and both are shown below:
   
Click for full size images
Additionally, I’d like to point out that former California State Climatologist Jim Goodridge posted a short essay on this blog, Atmospheric Carbon Dioxide Variation, that postulated something similar. 
UPDATE: This from Roy on Monday 1/28/08 see new post on C12 to C13 ratio here
I want to (1) clarify the major point of my post, and (2) report some new (C13/C12 isotope) results:
1.  The interannual relationship between SST and dCO2/dt is more than enough to explain the long term increase in CO2 since 1958.  I’m not claiming that ALL of the Mauna Loa increase is all natural…some of it HAS to be anthropogenic…. but this evidence suggests that SST-related effects could be a big part of the CO2 increase.
2.  NEW RESULTS: I’ve been analyzing the C13/C12 ratio data from Mauna Loa.  Just as others have found, the decrease in that ratio with time (over the 1990-2005 period anyway) is almost exactly what is expected from the depleted C13 source of fossil fuels.  But guess what? If you detrend the data, then the annual cycle and interannual variability shows the EXACT SAME SIGNATURE.  So, how can decreasing C13/C12 ratio be the signal of HUMAN emissions, when the NATURAL emissions have the same signal???
-Roy
Here is Roy Spencer’s essay, without any editing or commentary:

Atmospheric CO2 Increases:
Could the Ocean, Rather Than Mankind, Be the Reason?
by
Roy W. Spencer
1/25/2008


            This is probably the most provocative hypothesis I have ever (and will ever) advance:  The long-term increases in carbon dioxide concentration that have been observed at Mauna Loa since 1958 could be driven more than by the ocean than by mankind’s burning of fossil fuels.
            Most, if not all, experts in the global carbon cycle will at this point think I am totally off my rocker.  Not being an expert in the global carbon cycle, I am admittedly sticking my neck out here.  But, at a minimum, the results I will show make for a fascinating story – even if my hypothesis is wrong.  While the evidence I will show is admittedly empirical, I believe that a physically based case can be made to support it.
            But first, some acknowledgements. Even though I have been playing with the CO2 and global temperature data for about a year, it was the persistent queries from a Canadian engineer, Allan MacRae, who made me recently revisit this issue in more detail.  Also, the writings of Tom V. Segalstad, a Norwegian geochemist, were also a source of information and ideas about the carbon cycle.

            First, let’s start with what everyone knows: that atmospheric carbon dioxide concentrations, and global-averaged surface temperature, have risen since the Mauna Loa CO2 record began.  These are illustrated in the next two figures.

 

Both are on the increase, an empirical observation that is qualitatively consistent with the “consensus” view that increasing anthropogenic CO2 emissions are causing the warming.  Note also that they both have a “bend” in them that looks similar, which might also lead one to speculate that there is a physical connection between them.
Now, let’s ask: “What is the empirical evidence that CO2 is driving surface temperature, and not the other way around?”  If we ask that question, then we are no longer trying to explain the change in temperature with time (a heat budget issue), but instead we are dealing with what is causing the change in CO2 concentration with time (a carbon budget issue).  The distinction is important.  In mathematical terms, we need to analyze the sources and sinks contributing to dCO2/dt, not dT/dt.
So, let us look at the yearly CO2 input into the atmosphere based upon the Mauna Loa record, that is, the change in CO2 concentration with time (Fig. 3).

Here I have expressed the Mauna Loa CO2 concentration changes in million metric tons of carbon (mmtC) per year so that they can be compared to the human emissions, also shown in the graph.
Now, compare the surface temperature variations in Fig. 2 with the Mauna Loa-derived carbon emissions in Fig. 3.  They look pretty similar, don’t they?  In fact, the CO2 changes look a lot more like the temperature changes than the human emissions do.  The large interannual fluctuations in Mauna Loa-derived CO2 “emissions” roughly coincide with El Nino and La Nina events, which are also periods of globally-averaged warmth and coolness, respectively.  I’ll address the lag between them soon. 
Of some additional interest is the 1992 event.  In that case, cooling from Mt. Pinatubo has caused the surface cooling, and it coincides in a dip in the CO2 change rate at Mauna Loa.
These results beg the question: are surface temperature variations a surrogate for changes in CO2 sources and/or sinks?
First, let’s look at the strength of the trends in temperature and CO2-inferred “emissions”.  If we compare the slopes of the regression lines in Figs. 2 and 3, we get an increase of about 4300 mmt of carbon at Mauna Loa for every degree C. of surface warming.  Please remember that ratio (4,300 mmtC/deg. C), because we are now going to look at the same relationship for the interannual variability seen in Figs. 2 and 3.
In Fig. 4 I have detrended the time series in Figs. 2 and 3, and plotted the residuals against each other.  We see that the interannual temperature-versus-Mauna Loa-inferred emissions relationship has a regression slope of about 5,100 mmtC/deg. C. 
There is little evidence of any time lag between the two time series, give or take a couple of months.

So, what does this all show?  A comparison of the two slope relationships (5100 mmtC/yr for interannual variability, versus 4,700 mmtC/yr for the trends) shows, at least empirically, that whatever mechanism is causing El Nino and La Nina to modulate CO2 concentrations in the atmosphere is more than strong enough to explain the long-term increase in CO2 concentration at Mauna Loa.  So, at least based upon this empirical evidence, invoking mankind’s CO2 emissions is not even necessary. (I will address how this might happen physically, below).
In fact, if we look at several different temperature averaging areas (global, N. H. land, N.H. ocean, N.H. land + ocean, and S.H. ocean), the highest correlation occurs for the Southern Hemisphere ocean , and with a larger regression slope of 7,100 mmtC/deg. C.  This suggests that the oceans, rather than land, could be the main driver of the interannual fluctuations in CO2 emissions that are being picked up at Mauna Loa — especially the Southern Ocean.
Now, here’s where I’m really going to stick my neck out — into the mysterious discipline of the global carbon cycle.  My postulated physical explanation will involve both fast and slow processes of exchange of CO2 between the atmosphere and the surface. 
The evidence for rapid exchange of CO2 between the ocean and atmosphere comes from the fact that current carbon cycle flux estimates show that the annual CO2 exchange between surface and atmosphere amounts to 20% to 30% of the total amount in the atmosphere.  This means that most of the carbon in the atmosphere is recycled through the surface every five years or so.  From Segalstad’s writings, the rate of exchange could even be faster than this.  For instance, how do we know what the turbulent fluxes in and out of the wind-driven ocean are?  How would one measure such a thing locally, let alone globally?
Now, this globally averaged situation is made up of some regions emitting more CO2 than they absorb, and some regions absorbing more than they emit.  What if there is a region where there has been a long-term change in the net carbon flux that is at least as big as the human source? 
After all, the human source represents only 3% (or less) the size of the natural fluxes in and out of the surface.  This means that we would need to know the natural upward and downward fluxes to much better than 3% to say that humans are responsible for the current upward trend in atmospheric CO2.  Are measurements of the global carbon fluxes much better than 3% in accuracy??  I doubt it.
So, one possibility would be a long-term change in the El Nino / La Nina cycle, which would include fluctuations in the ocean upwelling areas off the west coasts of the continents.  Since these areas represent semi-direct connections to deep-ocean carbon storage, this could be one possible source of the extra carbon (or, maybe I should say a decreasing sink for atmospheric carbon?).   
Let’s say the oceans are producing an extra 1 unit of CO2, mankind is producing 1 unit, and nature is absorbing an extra 1.5 units.  Then we get the situation we have today, with CO2 rising at about 50% the rate of human emissions.
If nothing else, Fig. 3 illustrates how large the natural interannual changes in CO2 are compared to the human emissions.  In Fig. 5 we see that the yearly-average CO2 increase at Mauna Loa ends up being anywhere from 0% of the human source, to 130%.  
It seems to me that this is proof that natural net flux imbalances are at least as big as the human source.

Could the long-term increase in El Nino conditions observed in recent decades (and whatever change in the carbon budget of the ocean that entails) be more responsible for increasing CO2 concentrations than mankind?  At this point, I think that question is a valid one.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea1663853',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"World leaders are gathering in Katowice, Poland, to negotiate the world’s response to climate change. The 24th Conference of the Parties (COP24) will last from December 3-14 and its primary aim is to reach agreement on how the Paris Agreement of 2015 will be implemented. In a year which saw record weather extremes and an extraordinary announcement from the UN that we have only 12 years to limit catastrophe, the need for meaningful progress has never been greater. To explain how the COP works and what it means for the fight against climate change, we asked our academic experts to share their views. The urgency to reach key milestones in the Paris Agreement and deal with climate change puts a lot of high expectations on COP24 – Federica Genovese, lecturer in government, University of Essex. Rulebook: this is the conference’s main goal – to establish consensus on how nations should implement the Paris Agreement and report their progress. Emissions targets: COP24 is expected to resolve how emissions will be regulated, although it’s unlikely that sanctions for countries failing to meet their targets will be agreed on. Finance: the rich countries need to find US$20 billion to fulfil their pledge of providing US$100 billion a year in funding to help poorer countries adapt to climate change by 2020. Agreeing when this will be paid is likely to be contentious.  Role of “big” states: the international political climate casts a long shadow over the talks. Domestic politics in the US, the UK, Russia and Brazil threaten to undermine climate change leadership among larger emitters at COP24.  How did we get here? 1997: Creation of Kyoto Protocol, which set binding emissions targets. It failed as the US did not ratify it. 2009: COP15 in Copenhagen failed to yield any agreement on binding commitments. 2013: COP19 in Warsaw failed to finalise any binding treaty. 2015: COP21 in Paris generated considerable optimism with agreement reached on a legally binding action plan. But two years later, US president Donald Trump announced his intention to withdraw the US from the Paris Agreement. We aren’t facing the end of the world as envisaged by many environmentalists in the late 1980s and early 1990s, but if we do nothing to mitigate climate change then billions of people will suffer – Mark Maslin, professor of Earth system science, University College London The world’s poorest and most vulnerable people are most at risk from the effects of climate change, with many having to migrate from sea level rise, crop failure and pollution. Sahia – a woman from Bangladesh – lost her home and her family’s livelihood. As global temperatures near 1.5°C above pre-industrial levels, the limit set in the 2015 Paris Agreement, scientists are increasingly anxious about how changes in the environment could work to accelerate the pace at which the rest of Earth is warming.  The Arctic is warming twice as fast as the rest of the planet and strange recent events here, such as heathland turning brown, could be a sign that previous natural stores of carbon are no longer working properly.  Methane released from Arctic permafrost and other rapid changes could take the matter of limiting greenhouse gas emissions out of our hands in the near future. A paper published in 2018 warned that runaway climate change could lead the planet into a “Hothouse Earth” state: A chain of self-reinforcing changes might potentially be initiated, eventually leading to very large climate warming and sea level rise – Richard Betts, professor of climatology, University of Exeter  Whatever is agreed at COP24 will be what is politically possible,
but experts urge us to bear in mind what the science demands to avoid the worst impacts of climate change and keeping global warming below or at 1.5°C. We’re failing to cut down our emissions, the technologies for NETs [Negative Emissions Technologies] don’t exist at any meaningful scale yet, and there are no political drivers in place to enforce their deployment. There is also a real risk of a dramatic rise in methane in the near future. COP24 will have to consider emergency plans – Hugh Hunt, reader in engineering, University of Cambridge. A more radical approach at COP24 could highlight the ample opportunity there is for slowing climate change by restoring habitats. For many countries, reforestation is a more immediate way to slash emissions and make society happier and healthier in the process. However, while the climate has changed radically since global warming was first declared a man-made phenomenon 30 years ago, international efforts to tackle it haven’t. Many experts argue that the involvement of commercial interests at COP24 limits what is possible for mitigating climate change. Ten years after the financial crisis, COP24 should not legitimise large financial investors as the architects of a transition where sustainability rhymes with profitability – Tomaso Ferrando, lecturer in law, University of Bristol Representatives from pension funds, asset managers and large banks will be lobbying world leaders to favour investments in infrastructure and energy production as part of the transition towards a low-carbon economy. Finance sector sees this transition as an opportunity to generate profit. If climate change is fought according to the rules of Wall Street, says Ferrando, people and projects will be supported only on the basis of whether they will make money. If COP24 can’t save us, what can? At COP24 environmental movements have an opportunity to use their platform to highlight the relationship between economic growth and environmental impact, and even to discuss radical alternative futures that are not dependent on a growth-based economy – Christine Corlet Walker, PhD researcher in ecological economics, University of Surrey To bring about radical action on the environment, many academics believe we need an equally radical social movement. They argue that protesters should seize the initiative to attack the root causes of climate change, such as economic growth. 2018 marks 30 years since climate change was first declared a man-made phenomenon, during a congressional committee in Washington DC. The testimony of NASA climatologist James Hansen was met with both concern and scepticism at the time, but the science is in: anthropogenic climate change is incontrovertible.   Climate change is happening and is being caused by humans. This is the academic consensus, backed by science. But for climate change deniers:  The 97% 97.5% of scientists who had published peer-reviewed research about climate change agreed with the consensus that global warming is human-caused (2010 study from Princeton University). 97.1% of relevant climate papers published over 21 years affirmed human-caused global warming (2013 study involving multiple institutions).  97% consensus in published climate research found to be robust and consistent with other surveys of climate scientists and peer-reviewed studies (2016 study involving multiple institutions). What do the other 3% think? There is no consistent theme among the reasoning of the other 3%. Some say “there is no warming”, others suggest the sun, cosmic rays or the oceans as a reason. Why do some still not believe in human-caused climate change? The fossil fuel industry has spent many millions of dollars on confusing the public about climate change. But the role of vested interests in climate science denial is only half the picture. The other significant player is political ideology – John Cook, research fellow in climate change communication, George Mason University An analysis by American professor Robert Brulle found that from 2003 to 2010, organisations promoting climate misinformation received more than US$900m of corporate funding a year. From 2008, funding through untraceable donor networks (so-called “dark money ATM”) increased. This allowed corporations to fund climate science denial while hiding their support. In 2016, an analysis of more than 40,000 texts from contrarian sources by Justin Farrell, another American professor, found that organisations who received corporate funding published more climate misinformation. At an individual level, however, there is considerable evidence that shows that political ideology is the biggest predictor of climate science denial. People who fear the solutions to climate change, such as increased regulation of industry, are more likely to deny that there is a problem in the first place. Consequently, groups promoting political ideology that opposes market regulation have been prolific sources of misinformation about climate change, as three American academics found.  Five Techniques used by climate change deniers to look out for: Fake experts: create the general impression of an ongoing debate by casting doubt on scientific consensus.  Logical fallacies: logically false arguments that lead to an invalid conclusion. These usually appear in myths, in the form of science misrepresentation or oversimplification. Impossible expectations: demand unrealistic standards of proof before acting on the science. Any uncertainty is highlighted to question the consensus. Cherry-picking: best described as wilfully ignoring a mountain of inconvenient evidence in favour of a small molehill that serves a desired purpose. Myth of global warming ‘pause’ Degrowth is the radical future the UK needs A plastics treaty could clean up our oceans"
"European polling on climate change denial puts Poland towards the top – or bottom, depending on which way you view it – of the leader board. Though the UN’s COP24 climate conference is currently being hosted in its southern city of Katowice, Poland itself has displayed little concern over global warming. Indeed, the EU’s largest coal producer often opposes any attempt to get it to cut its carbon emissions. What’s driving such potent scepticism? With minimal media coverage of climate change, climate impacts, or policy, Poland is an outlier in Europe. This is particularly surprising because EU climate policy, and the possibility of a stiff carbon tax in future, has significant long-term implications for the country’s economy. The issue partly dates back to the collapse of communism in Poland that began in 1989. The resulting industrial decline and overhaul of outdated and highly polluting sectors caused a rapid decrease in CO₂ emissions.  All this meant that when Poland joined the EU and signed up to the Kyoto Protocol it could easily meet its generous emissions targets as they were set relative to 1988, when its polluting industries were still in full swing. However, new EU climate and energy legislation will soon kick in and comparing Polish emissions with a more recent year will make things harder. In our academic research, we have looked at why there is so little coverage of climate issues in the Polish media.  In part, it’s a reflection of the prominence of climate deniers, both politicians and scientists, in the media. Many politicians in Poland have publicly announced scepticism, not only about climate policy but also about the scientific findings on climate change. It is also relatively easy for incompetent people to gain a sizeable platform. We found that, typically, denialist scientists featured in the Polish media are not climatologists, but rather medical scientists, geologists, economists, or engineers from the energy or mining sectors. There is also no publicly-owned media in Poland, except for public television and radio, which has been politicised by the coal-friendly ruling party. Commercial media competes for a small audience, and as a result is much more likely to touch on controversial points of view than to try to analyse them. There has also been little media coverage in Poland of the UN’s IPCC reports on the scientific consensus about climate change, and a complete absence of politicians promptly reacting to the reports. This lack of coverage can be partly explained by the relative scarcity of IPCC authors from Poland. But journalists and editors are unlikely to choose a topic that they know is of little interest to their audiences and it appears that many Poles believe the cure – climate change mitigation – could be worse for Poland than the disease. Much of this can be traced back to the influence of the coal lobby, which has been powerful ever since communist times when exports were a vital source of convertible (foreign) currency. Poland is today the largest coal producer in the EU, and around 60% of the country’s overall energy comes from coal. No wonder sentiment towards fossil fuel remains strong. This is why most Polish politicians will nominally support taking action on climate change, regardless of political orientation – but only as long as it does not mean moving away from coal. They frequently speak of the importance of coal to the economy and energy security, yet they conveniently ignore or downplay the coal-climate link. There is a strong “inconvenient truth” at work as burning coal is, globally, responsible for much of the ongoing climate change.  Even past increases in the price of domestic coal have not helped renewable energies, but rather resulted in Poland importing cheaper coal from abroad while propping up its own industry. Most Poles recognise the benefits of being in the EU and understand that Poland must play by the rules. Yet many other voices are demanding renegotiation of an EU climate and energy package that they say is harmful to their nation. Indeed, many perceived this an externally-driven policy problem, imposed from abroad. They expect more effective action from non-EU countries which emit most of the world’s carbon dioxide. Like other EU members, Poland would eventually like to decarbonise its energy sector. However, concerns remain over the abrupt introduction of a high carbon tax and the threat of “carbon leakage” where coal production and jobs shift eastwards from Poland to countries that are not obliged to reduce emissions under the Kyoto Protocol. For now, a switch from cheap coal to a more costly low-emission economy is politically unpalatable. Popular opinion and a wide range of politicians simply do not support the vision of leaving coal underground and paying more for energy. The country is still poorer than those in Western Europe, and the fear of energy price hikes is overwhelming. Don’t expect Poland or its media to embrace climate action any time soon."
nan
"

I’m taking a few days off blogging for friends and family. Seeing the pandemonium that has gripped the streets of my town while people scurry about trying to pull off that last minute shopping, and seeing my in-laws already getting into a small accident (even though they tried to avoid the traffic glut) and seeing local cycling enthusiast Ed McLaughlin get into a serious biking accident reminds me to remind you to drive, bike, and walk safely this holiday.
Watch for ice, it’s cold out there, don’t slip like the polar bear!
When I return I’ll have an update on my Stevenson Screen paint experiment.
In the meantime I wish each and every one of you a joyous Christmas holiday and I want to thank all of you for the help and support this year on this blog and in the www.surfacetstations.org project.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea1cb16ca',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

Here’s something you don’t see every day; an exploding comet.  In fact the last time this comet did this was in 1892.
Comet 17P/Holmes is now larger than Jupiter. Astronomer Eric Allen of Quebec’s Observatoire du Cégep de Trois-Rivières combined images he captured on three consecutive nights (Oct. 25, 26 and 27) and placed them beside a picture of Jupiter scaled to the same distance as the comet, as shown above. More at www.spaceweather.com
The comet is visible to the naked eye, and looks even better through a telescope. This would be a good excuse to go visit the Chico Community Observatory in upper Bidwell Park Sunday night and have them swing the telescope by for a look. Or if you want to spot it yourself, here is a sky map.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea306c1e4',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"The new Liberal MP Katie Allen has canvassed the need for the government to appoint a dedicated climate change minister, as the Coalition splits on how best to “evolve” its policy response. Allen, who was elected for the seat of Higgins in May, is one of a number of Liberal MPs who have been arguing internally for the government to increase its ambition on climate change against resistance from conservatives in the Coalition.  Allen’s suggestion for a climate change portfolio was made in a group chat of MPs in a discussion about how the government’s policies could be better communicated, sources have confirmed. She did not advocate in the group that the government needed to do more, but suggested there was frustration that voters were not hearing the government’s message. She argued that the “significant investment” being made by the government did not appear to be acknowledged in the community. Allen proposed that her fellow Victorian MP Tim Wilson would be a good advocate to communicate the government’s policies. Both Allen and Wilson declined to comment on the discussion. Wilson was one of the MPs who spoke in Tuesday’s partyroom in favour of more ambitious climate action and has also urged the government to consider nuclear power. His call for more action was backed up by Allen, along with the member for Reid, Fiona Martin, and the North Sydney MP, Trent Zimmerman, who argued that the government needed to ensure it respected divergent views on the issue, and acknowledged the strength of feeling for more action in inner city seats. Nationals MPs George Christensen, Barnaby Joyce and David Gillespie argued that the government should not succumb to pressure from inner city voters to do more on climate, with Joyce saying it was a “hobby horse” that was being pursued through the tragedy of bushfires. On Wednesday morning, following the partyroom stoush, Morrison said he would not “be bullied” into more action on climate change. “We listen to Australians right across the country. Not just in the inner city,” Morrison told Channel Nine. “It’s important to listen to everybody but take people forward on practical, balanced action that doesn’t go and write people’s jobs off, or industries off,” Morrison said. “It’s about technology, not taxation. So we won’t be bullied into higher taxes or higher electricity prices. What we’ll do is take practical action that deals with these challenges.” Morrison also dismissed overnight calls from the UK prime minister, Boris Johnson, for other countries to join Britain in striving for net-zero carbon emissions by 2050. “I would never make a commitment like that if I couldn’t tell the Australian people what it would cost them,” Morrison said. As the Coalition seeks to reposition on climate, Morrison faced questions in Parliament about the government’s response to the bushfires. In response to a question from the Warringah MP, Zali Steggall, asking for a bipartisan approach to climate change in the wake of the crisis, Morrison said Australia was already acting. “Emissions reduction is important. We’re acting on that reduction. I can tell you also resilience to climate is also important,” Morrison said. “Hazard reduction is important, if not more important, than emissions reduction when it comes to protecting people from fire and hotter, drier, longer summers in the future. “Also, in a country ravaged by drought, and the impacts that we have experienced, and that drought continues, building dams is climate action now.” The opposition leader, Anthony Albanese, asked Morrison why the government had not called a meeting of state governments when the bushfire crisis began – a request made in writing to the prime minister by Labor on 22 November. Morrison said the government had responded in an “unprecedented” manner to the fires, and it was “disappointing” that Labor was trying to “politicise the bushfires”. Earlier, Liberal MP John Alexander used his condolence speech on the bushfires to call climate change “the elephant in the room”. “Today is a day for commemoration, not politics. But one thing I would like to say is the need to recognise that these fires are not a warning about climate change – they are climate change,” he said. “The leader of the opposition said that ‘this is not normal’. I fear this is actually the new normal. “In focusing on saving this country for our grandchildren, we risk forgetting we need to save our neighbours. We must obviously mitigate future risks and change our ways, but we also must adapt because these longer, hotter summers will be our new normal.” The challenge facing Morrison to balance the Coalition’s competing constituencies was further highlighted on Wednesday, when the new Nationals party deputy leader, David Littleproud, argued that the government should look to retrofit coal-fired power stations to reduce emissions. Party leader Michael McCormack, who survived a leadership challenge on Tuesday, said the government was taking action on emissions reduction in a “responsible way”. “We don’t want to be sending industry offshore. And there is a future for coal in this country.” But despite the divergent views, home affairs minister Peter Dutton rejected suggestions the party was divided. “I don’t see huge points of difference in our party room,” he told the ABC. “Obviously, as we’ve all pointed out, we’re experiencing hotter weather, longer summers, but did the bushfires start in some of these regions because of climate change? No. It started because somebody lit a match. There are 250 people as I understand it, or more, that have been charged with arson. That’s not climate change.” There is no evidence that anything like that number of people have been arrested over alleged arson in connection with this summer’s bushfires, let alone charged. As the political debate over climate action continues to rage, the RBA governor, Philip Lowe, told the National Press Club that the cost to the economy of bushfires and drought saying they were “a stark reminder that the economic effects of these climate events are material”."
"
Former Virginia State Climatologist Patrick J. Michaels wrote an op-ed about his paper with Ross McKitrick from Canada’s University of Guelph in an American Spectator column today about the surface temperature record. This paragraph really caught my eye: “Weather equipment is very high-maintenance. The standard temperature shelter is painted white. If the paint wears or discolors, the shelter absorbs more of the sun’s heat and the thermometer inside will read artificially high. But keeping temperature stations well painted probably isn’t the highest priority in a poor country.”
The Stevenson Screen experiment that I had setup this summer is living proof of this.
Compare the photo of the whitewash paint screen on 7/13/07 when it was new with one taken today on 12/27/07. No wonder the NWS dumped whitewash as the spec in the 70’s in favor of latex paint. Notice that the Latex painted shelter still looks good today while the Whitewashed shelter is already deteriorating.

Click image for larger view

Click image for larger view

Whitewashed Screen on 7/13/07

Whitewashed Screen on 12/27/07
The whitewash coating I used was from a formula and method provided to me by a chemist at the US Lime Corporation, who is an expert on whitewash. He said the formula was true to historical records of the time when whitewash was used on the shelters. I was amazed to find that after just a few short months, my whitewash coating had lost about 40-50% of it’s surface area. Perhaps there was a mistake in the formula, or perhaps whitewash really is this bad at withstanding weathering.
In any event the statement of Patrick Michaels “Weather equipment is very high-maintenance. The standard temperature shelter is painted white. If the paint wears or discolors, the shelter absorbs more of the sun’s heat and the thermometer inside will read artificially high.” seems like a realistic statement in light of the photos above. The magnitude of the effect in the surface temperature record has yet to be determined, but it seems clear that shelter maintenance, or lack thereof, is a significant micro-site bias factor that has not been adequately investigated nor accounted for in the historical temperature record.
I’ll have more on this experiment soon including temperature time series graphs showing the difference between bare wood, latex painted, and whitewashed shelters.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea1bd3f8a',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterFrom environmental heroes – to national shame
The whole publicity stunt was probably supposed to go something like as follows: To protest against forest clearance to make way for a new stretch of autobahn, a group of 9 masked German tree-huggers would rappel from a speedway overpass and hang a banner demanding that the planned deforestation be stopped. And for their courageous activism, they’d surely make the regional news – maybe even the national news – and draw needed attention to man’s ruthless destruction of nature. Of course they’d be adored by the public as environmental heroes. They’d maybe even hold press conferences – and be surrounded by TV cameras and mikes.
Except for the national attention, things didn’t quite work out that way for the group of German radical environmentalist tree-huggers after tragedy struck.
According German daily Bild here, they ended up causing an 8-kilometer traffic jam and one “horror accident” as a 29-year old driver suffered serious injuries and had to be airlifted to a trauma center.
One German national daily labelled the activists as environmental idiots.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Image cropped from Bild online here: 
According to Bild, the “anti-autobahn activists” blocked the A3 autobahn near Idstein as two of them “rappelled off an overpass” and hung a banner across it. Their publicity stunt caused the fast moving traffic to jam to a sudden halt, causing an 8-kilomter traffic jam. The 29-year old driver mentioned above failed to noticed the end of the traffic jam in time and crashed into the rear of a truck.
“A 29-year-old drove into the end of the traffic jam and his Skoda crashed into the back of a truck – the man was seriously injured,” online Bild reports.
“Horror crash because of this idiot,” was the headline in Bild’s hard copy print edition this morning, with an arrow pointing at a young female activist hanging from the overpass. Another Bild photo showed authorities dragging off one of the protesters.
The online Bild here also reports that one protester is still being detained by the police. But: “Six have been released.”
“A protest that endangers human life has no legitimacy,” said Home Secretary of Hesse, Peter Beuth. “Anyone who endangers his fellow citizen has to be punished severely.”


		jQuery(document).ready(function(){
			jQuery('#dd_0755afe815319cbec0ef6652a11c042f').on('change', function() {
			  jQuery('#amount_0755afe815319cbec0ef6652a11c042f').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"
It’s been awhile since I updated this series, and its not for lack of material. But I got busy with the UCAR conference, publishing a slide show, and other things. But this morning, über volunteer Don Kostuch sent me a note on his latest survey in Titusville, FL near Cape Canaveral and KSC. I’d like to point out that Don has traveled further and surveyed more stations in the USA than anyone. He is a surveying machine. He wrote this in his email to me:
  “On your scale of 1 to 5, this is an 8. Peace, Don Kostuch”
Ok in the past we have seen stations on rooftops, at sewage treatment plants, over concrete, next to air conditioners, next to diesel generators, with nearby parking, excessive nighttime humidity, and at non-standard observing heights.
Imagine a USHCN station that embraces all of that. I give you the Titusville, FL USHCN station:



Ever thorough, Don also provided photographs of the Climate Reference Network site, just 7 miles east at KSC, which demonstrates the correct environment for measurement of near surface air temperature:

Now I know there will be the usual critics who will jump in and say “This can be adjusted for!”. Ok here is your chance, show me the equations to untangle Titusville’s temperature record from microsite bias. Personally, it looks FUBAR to me.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea3cc7da6',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Encompassing swathes of Ethiopia, South Sudan and Kenya, the Omo-Turkana Basin is one of the oldest landscapes in the world that is known to have been inhabited by Homo sapiens and is now one of the world’s most extraordinary examples of ethnic diversity. In the lower Omo Valley alone, a varied history of cross-cultural encounters has played out to produce eight distinct ethnic groups, speaking many languages from Afro-Asiatic to Nilo-Saharan. In a cattle camp on the bank of the ancient Omo River a Mursi elder implored me to “tell our story so that others might know us before we are all dead in the desert”. Where the river ends in Lake Turkana, this sentiment was echoed by local fishermen: “You will find our bones in the desert.” The story of the Omo-Turkana Basin is now that of the Ethiopian state exploiting its periphery in the name of “development”, trampling on the human rights of its citizens in the process. Over the past decade, the Ethiopian government has pushed ahead with a huge hydro-electric dam on the Omo, known as Gibe III. Without any meaningful consultation with the communities affected, the state has also appropriated grazing lands and freshwater, threatening their vital resources and local heritage.  All of this has happened despite the area gaining the status of a UNESCO World Heritage Site in 1980. As Richard Leakey, the Kenyan paleoanthropologist, conservationist and politician put it, “these happenings are profoundly disturbing”. The completion of Gibe III, Africa’s tallest dam to date, has eliminated the annual flood and radically reduced the Omo’s flow, which produces 90% of Lake Turkana’s freshwater input. In doing so, it has reduced sediments and nutrients critical for traditional agriculture, riverside pastures and fish habitat.  Over 30% of the lake inflow will be diverted for commercial irrigation projects. The result could be a fall in lake level comparable to that of Central Asia’s Aral Sea, which has shrunk by over two thirds since the 1960s because of irrigation abstractions  and which has been called “the world’s worst environmental disaster”. To make way for the commercial plantations planned for the Omo Valley, tens of thousands of hectares of land will be expropriated and thousands of local people displaced. The need to see “development” as more than a simple matter of an increase in GDP is well established. In his seminal work, Development as Freedom, the Nobel Prize winning economist, Amartya Sen, demonstrated that sustainable development must be based on universal access to social and economic necessities as well as political and civil rights. The many communities in the Omo-Turkana Basin have suffered a systematic curtailment of their most basic and essential rights.  International agreements which the Ethiopian government signed up to, such as the 1993 International Convenant on Civil and Political Rights and the International Covenant of Economic, Social and Cultural Rights require it to protect and promote the rights of minority cultures and ensure the “right of everyone to take part in cultural life”. Since 1948, Ethiopia has also been signed up to the Convention on the Prevention and Punishment of the Crime of Genocide. Article II provides against the destruction of “a national, ethnical, racial or religious group”. Raphael Lemkin, who coined the word “genocide”, famously defined the specific need to protect against the “disintegration of the political and social institutions of culture, national feelings, religion, and the economic existence of national groups”. It is difficult not to conclude that what we are seeing in the Omo is the wholesale disregard of these commitments by the Ethiopian government. Its development policies are not only transforming landscape and heritage but destroying complex systems of sustainable living that have endured for millennia. The huge injustice of all this is that the ecological costs will be borne by local communities while the profits will be enjoyed by central and international corporations.  Meanwhile, centuries of collective wisdom relating to livestock diversification, flood dependant cultivation and customary obligations and mechanisms of livestock exchange, will be made redundant. This is not to deny, of course, that development, in the sense defined by Sen, is a laudable and necessary enterprise. But we must also recognise that large-scale infrastructure projects are likely to have far reaching consequences for the lifestyles and cultural identities of those they displace.  Projects which set out to increase economic growth without regard for social justice and individual rights are not worthy of the name “development”. Development must benefit locals and for this to happen their voices must not only be heard but also given a central and determining role in any discussions about the future of their lands and livelihoods.  Both cradle and crucible of our species, the Omo-Turkana Basin is unique and precious. Its heritage and history, as well as responsibility for its future, are shared by us all."
"
November 30th marks the official end of hurricane season. Below is some good news, courtesy of Ryan Maue at Florida State University COAPS :
The 2007 Atlantic Hurricane season did not meet the hyperactive expectations of the storm pontificators. This is good news, just like it was last year. With the breathless media coverage prior to the 2006 and 2007 seasons predicting a catastrophic swarm of hurricanes potentially enhanced by global warming a la Katrina, there is currently plenty of twisting in the wind to explain away the hyperbolic projections. The predominant refrain mentions something about “being lucky” and having “escaped” the storms, and “just wait for next year”.
Before we prepare for the obvious impending onslaught of the next “above-average” hurricane season, let’s review some very positive aspects of what 2007 offered:

The 2007 Atlantic Hurricane season was below-normal and tied for 2002 as the most inactive since the El Nino depressed 1997 season in terms of storm energy. Note: Hurricane Energy is measured through the Accumulated Cyclone Energy (ACE) index
The North Atlantic was not the only ocean that experienced quiet tropical cyclone activity. The Northern Hemisphere as a whole is historically inactive. How inactive? One has to go back to 1977 to find lower levels of cyclone energy as measured by the ACE hurricane energy metric. Even more astounding, 2007 will be the 4th slowest year in the past half-century (since 1958) .
Fewest Northern Hemisphere Hurricane Days since 1977. 3rd Lowest since 1958 (behind 1977 and 1973). See the Hurricane Days Graphic below.
When combined, the 2006 and 2007 Atlantic Hurricane Seasons are the least active since 1993 and 1994. When compared with the active period of 1995-2005 average, 2006 and 2007 hurricane energy was less than half of that previous 10 year average. The most recent active period of Atlantic hurricane activity began in 1995, but has been decidedly less active during the previous two seasons.
When combined, the Eastern Pacific and the North Atlantic, which typically play opposite tunes when it comes to yearly activity (b/c of El Nino), brushed climatology aside and together managed the lowest output since 1977. In fact, the average lifespan of the 2007 Atlantic storms was the shortest since 1977 at just over two days. This means that the storms were weak and short-lived, with a few obvious exceptions.

Hurricane Days by Year

2007 Departure from ACE and Climatic norms:


Basin
Current ACE
Climo ACE
% Departure


Northern Hemisphere
373.4
525.2
-28.9%


North Atlantic
67.7
93.8
-27.8%


Western Pacific
209.2
286.8
-27.1%


Eastern Pacific
52.2
131.2
-60.2% 




			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea25e7b10',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

“War is God’s way of teaching Americans geography,” the 19th century American writer Ambrose Bierce sagely observed, and the war in Iraq is no exception. After weeks of intense coverage, one fact is plain: The people of Iraq should be among the richest in the world. 



Iraq has been cursed by brutal politics, but it has been abundantly blessed by geography. Two great rivers bound a fertile plain in a subtropical climate. It possesses a seaport and ready access to major markets. As the repository for many of the world’s greatest archeological sites, it should be a tourist Mecca. And, of course, the country sits on top of the world’s second largest known oil reserves. 



Among his many crimes, Saddam Hussein squandered and stifled the potential wealth of his country by his warmongering and official thievery. The economic policy of his Baathist Party was a kind of thuggish socialism: government control of prices and industry, ubiquitous rationing, arbitrary confiscation of private wealth, and little trade other than arms and oil. 



Saddam’s misrule has left Iraq by far the poorest country in the Persian Gulf region. Its per capita gross domestic product is the equivalent of $2,500 a year, far lower than the per capita GDP of Qatar ($21,200), Kuwait ($15,000), Saudi Arabia ($10,600) or even Iran ($7,000). Iraq’s imports are a fraction of what they were in the 1980s, when it citizens were buying almost $1 billion worth of U.S. farm products a year. 



America’s well‐​earned victory on the battlefield will be in jeopardy if the people of Iraq cannot enjoy the material fruits of their new‐​found freedom. To safeguard our investment of blood and treasure, the United States and Great Britain should ensure that any new Iraqi government protects the economic as well as the political and civil freedom of its citizens. 



An essential part of any plan to establish freedom in Iraq should be a commitment to a free market and the institutions that support it, including a commitment to free trade. Iraqis must enjoy a secure right to property, a stable currency, decontrolled prices, the rule of law and contract, and the freedom to engage in business, at home and through international trade. 



Post‐​war reconstruction of Europe provides a model, although not in a way most people believe. Yes, Marshall Plan aid played a role in reviving Western Europe, but the real story was the continent’s turn toward markets and free trade. In June 1948, Germany’s Ludwig Erhard abruptly repealed price controls and issued a new currency. Tax and tariff cuts soon followed. As one historian noted: “The spirit of the country changed overnight. The gray, hungry, dead‐​looking figures wandering about the streets in their everlasting search for food came to life.” Iraq needs an Arab Ludwig Erhard. 



Study after study has confirmed that nations relatively open to trade grow faster and achieve higher incomes than those that are relatively closed. The model for Iraq’s new leaders should be Ireland, Chile, the tigers of East Asia, and other countries that have achieved sustained growth through expanding trade—not the stagnant and increasingly isolated countries of the Arab Middle East. 



With the Saddam regime now history, UN sanctions should be lifted immediately. If France and Russia insist on keeping sanctions in place to protect the UN’s bureaucratic control over Iraqi oil, the United States should ignore the sanctions and unilaterally allow Americans to trade with the people of Iraq. U.S. markets should be opened to goods made by Iraqis, especially import‐​sensitive textiles, apparel, and farm products. Beyond stimulating growth, trade with Iraq would bring humanitarian relief, cement ties between our two countries, and send a positive signal that Iraq is open to foreign investment. 



Much has been written about the need for political reform in the Arab world, but it also desperately needs economic reform. The Arab world’s share of global trade and foreign investment has been declining in the last two decades. Outside of oil, Arab countries export little that the rest of the world is willing to buy. With a few exceptions, barriers to trade and foreign investment remain high. There are more McDonald’s franchises in the tiny Netherlands than in all the Arab world. 



A vibrant Iraqi economy would give hope to a new generation of Arabs to reclaim their rightful place in the world of trade, science and ideas. An educated, hopeful middle class would in turn create more fertile soil for limited and representative government. But if a post‐​Saddam Iraq fails to prosper, its people will grow frustrated and blame the market and the West for their troubles, creating fertile soil for terrorism. 



The technology, dynamism, and openness of our own market economy helped us win this war; if spread to Iraq, those same market forces can help us win the peace.
"
"Not only is air pollution bad for our lungs and heart, it turns out it could actually be making us less intelligent, too. A recent study found that in elderly people living in China, long-term exposure to air pollution may hinder cognitive performance (things like our ability to pay attention, to recall past knowledge and generate new information) in verbal and maths tests. As people age, the link between air pollution and their mental decline becomes stronger. The study also found men and less educated people were especially at risk, though the reason why is currently unknown.  We already have compelling evidence that air pollution – especially the tiniest, invisible particulates in pollution – damages the brain in both humans and animals. Traffic pollution is associated with dementia, delinquent behaviour in adolescents, and stunted brain development in children who attend highly polluted schools.  


      Read more:
      London air pollution is restricting children's lung development – new research


 In animals, mice exposed to urban air pollution for four months showed reduced brain function and inflammatory responses in major brain regions. This meant the brain tissues changed in response to the harmful stimuli produced by the pollution. We don’t yet know which aspects of the air pollution particulate “cocktail” (such as the size, number or composition of particles) contribute most to reported brain deterioration. However, there’s evidence that nanoscale pollution particles might be one cause.  These particles are around 2,000 times smaller than the diameter of a human hair, and can be moved around the body via the bloodstream after being inhaled. They may even reach the brain directly through the olfactory nerves that give the brain information about smell. This would let the particles bypass the blood-brain barrier, which normally protects the brain from harmful things circulating in the bloodstream. Postmortem brain samples from people exposed to high levels of air pollution while living in Mexico City and Manchester, UK, displayed the typical signs of Alzheimer’s disease. These included clumps of abnormal protein fragments (plaques) between nerve cells, inflammation, and an abundance of metal-rich nanoparticles (including iron, copper, nickel, platinum, and cobalt) in the brain.  The metal-rich nanoparticles found in these brain samples are similar to those found everywhere in urban air pollution, which form from burning oil and other fuel, and wear in engines and brakes. These toxic nanoparticles are often associated with other hazardous compounds, including polyaromatic hydrocarbons that occur naturally in fossil fuels, and can cause kidney and liver damage, and cancer. Repeatedly inhaling nanoparticles found in air pollution may have a number of negative effects on the brain, including chronic inflammation of the brain’s nerve cells. When we inhale air pollution, it may activate the brain’s immune cells, the microglia. Breathing air pollution may constantly activate the killing response in immune cells, which can allow dangerous molecules, known as reactive oxygen species, to form more often. High levels of these molecules could cause cell damage and cell death. The presence of iron found in air pollution may speed up this process. Iron-rich (magnetite) nanoparticles are directly associated with plaques in the brain. Magnetite nanoparticles can also increase the toxicity of the abnormal proteins found at the centre of the plaques. Postmortem analysis of brains from Alzheimer’s and Parkinson’s disease patients shows that microglial activation is common in these neurodegenerative diseases.  


      Read more:
      Your exposure to air pollution could be much higher than your neighbour's – here's why


 The latest study of the link between air pollution and declining intelligence, alongside the evidence we already have for the link between air pollution and dementia, makes the case for cutting down air pollution even more compelling. A combination of changes to vehicle technology, regulation and policy could provide a practical way to reduce the health burden of air pollution globally.  However, there are some things we can do to protect ourselves. Driving less and walking or cycling more can reduce pollution. If you have to use a car, driving smoothly without fierce acceleration or braking, and avoiding travel during rush hours, can reduce emissions. Keeping windows closed and recirculating air in the car might help to reduce pollution exposure during traffic jams as well.  But young children are among the most vulnerable because their brains are still developing. Many schools are located close to major roads, so substantially reducing air pollution is necessary. Planting specific tree species that are good at capturing particulates along roads or around schools could help.  Indoor pollution can also cause health problems, so ventilation is needed while cooking. Open fires (both indoors and outdoors) are a significant source of particulate pollution, with woodburning stoves producing a large percentage of outdoor air pollution in the winter. Using dry, well-seasoned wood, and an efficient ecodesign-rated stove is essential if you don’t want to pollute the atmosphere around your home. If you live in a naturally-ventilated house next to a busy road, using living spaces at the back of the house or upstairs will reduce your pollution exposure daily.  Finally, what’s good for your heart is good for your brain. Keeping your brain active and stimulated, eating a good diet rich in antioxidants, and keeping fit and active can all build up resilience. But as we don’t yet know exactly the mechanisms by which pollution causes damage to our brains – and how, if possible, their effects might be reversed – the best way we can protect ourselves is to reduce or avoid pollution exposure as much as possible."
"
Share this...FacebookTwitterA “potential connection” between anthropogenic global warming and the frequency or intensity of wildfires in California has yet to emerge in the trend observations.
Scientists have found a “lack of correlation between late summer/autumn wildfires” and “summer precipitation or temperature” in coastal California. In fact, “there is no long-term trend in the number of fires over coastal California” in the last 50 years (Mass and Ovens, 2019). 
Image Source: Mass and Ovens, 2019
Fire history in the Western USA has recently declined to the lowest point in the last 1,400+ years (Marlon et al., 2012).

Image Source: Marlon et al., 2012
As CO2 concentrations have risen from 300 ppm to 400 ppm (1900 to 2007), the decline in global burned area has been significant (Yang et al., 2014).

Image Source: Yang et al., 2014
The falling trends in global-scale wildfires can even be dectected over the short-term 2001-2016 period (Earl and Simmonds, 2018).

Image Source: Earl and Simmons, 2018
Share this...FacebookTwitter "
nan
"

There’s a common misconception that people who are in favor of a free market are also in favor of everything that big business does. Nothing could be further from the truth.



As a believer in the pursuit of self‐​interest in a competitive capitalist system, I can’t blame a businessman who goes to Washington and tries to get special privileges for his company. He has been hired by the stockholders to make as much money for them as he can within the rules of the game. And if the rules of the game are that you go to Washington to get a special privilege, I can’t blame him for doing that. Blame the rest of us for being so foolish as to let him get away with it.



I do blame businessmen when, in their political activities, individual businessmen and their organizations take positions that are not in their own self‐​interest and that have the effect of undermining support for free private enterprise. In that respect, businessmen tend to be schizophrenic. When it comes to their own businesses, they look a long time ahead, thinking of what the business is going to be like 5 to 10 years from now. But when they get into the public sphere and start going into the problems of politics, they tend to be very shortsighted.



The most obvious example is protectionism. Can you name any major American industry that has really benefited from tariffs and protection? Alexander Hamilton, in his famous report on manufactures, praised Adam Smith to the sky while at the same time arguing that the United States was a special case in that it had infant industries that needed to be protected, including steel. Steel is still being protected 200 years later.



Commercial banking is another example. At the end of World War II commercial banking accounted for roughly half of the capital market. Today it accounts for about one‐​fifth. Why has it deteriorated? Why is the international financial market in London, not in New York? 



The answer is the long‐​term effect of the of the banking industry’s insistence on special government favors. In the early days, under what was known as Regulation Q, the government set a limit on the interest rates that banks could pay, including a rate of zero on demand deposits. The government‐​imposed interest rate of zero on demand deposits encouraged the emergence of money market funds and the growth of substitutes for and alternatives to banks. The banking industry consistently supported fixed exchange rates. When the dollar got into trouble, President Johnson introduced restrictions on foreign lending and an interest‐​equalization tax. The result was to drive the commercial banking industry to London. Both of those measures reduced the commercial banking industry from the predominant supplier of credit to a minor player. Again, a policy that was very shortsighted.



The easiest shot of all is the way in which corporations make contributions. The oil industry contributes to conservation organizations that are trying to sharply reduce the use of oil. The nuclear industry contributes to organizations that support nonnuclear energy. Recently, Capital Research Center analyzed grants from major corporations to public policy organizations and found that the major corporations made $3 in grants to the nonprofit left for every dollar they gave to the nonprofit right.



Why hasn’t the corporate world followed the excellent example that was set by Warren Buffett? From his earliest days, in sending a dividend check to his stockholders, he said, “We are prepared to distribute X dollars on your behalf for each share of stock to charity, to some organization. Let us know to whom you would like it sent, and we will send it on your behalf.” 



Why should corporations decide the charitable purposes that should be supported by the income of their stockholders? Why shouldn’t each stockholder decide that? And why is the business community in general so insistent on supporting its own enemies? 



Now consider education. As you know, I have long been in favor of trying to privatize schooling through a voucher system. One strong argument in favor of privatization has to do with the values instilled by our public education system.



Any institution will tend to express its own values and its own ideas. Our public education system is a socialist institution. A socialist institution will teach socialist values, not the principles of private enterprise. That wasn’t so bad when elementary and secondary education was more dispersed, so there could be more local control. When I graduated from high school there were 150,000 school districts in the United States. Today there are fewer than 15,000 and the population is twice as large.



What has been the business community’s attitude toward education? Members of the business community have been well aware that schools instill values that are unsympathetic to a free private enterprise system. They are also aware that it’s difficult to get employees with the appropriate skills. But have they been trying to promote a private enterprise education industry? Not at all. Their major activity has been to assign some of their employees to teach in public schools and to contribute computers and other items to public schools. I can’t blame an individual for what he does, but I think it’s tragic that Walter Annenberg contributed hundreds of millions of dollars for government schools, for public schools, not for private schools. I have not seen any movement in the business community in general, until very recently, to try to promote an educational system under which the customer, namely the parent and the child, has a real choice about the schooling the child gets.



Now we come to Silicon Valley and Microsoft. I am not going to argue about the technical aspects of whether Microsoft is guilty or not under the antitrust laws. My own views about the antitrust laws have changed greatly over time. When I started in this business, as a believer in competition, I was a great supporter of antitrust laws; I thought enforcing them was one of the few desirable things that the government could do to promote more competition. But as I watched what actually happened, I saw that, instead of promoting competition, antitrust laws tended to do exactly the opposite, because they tended, like so many government activities, to be taken over by the people they were supposed to regulate and control. And so over time I have gradually come to the conclusion that antitrust laws do far more harm than good and that we would be better off if we didn’t have them at all, if we could get rid of them. But we do have them.



Under the circumstances, given that we do have antitrust laws, is it really in the self‐​interest of Silicon Valley to set the government on Microsoft? Your industry, the computer industry, moves so much more rapidly than the legal process, that by the time this suit is over, who knows what the shape of the industry will be. Never mind the fact that the human energy and the money that will be spent in hiring my fellow economists, as well as in other ways, would be much more productively employed in improving your products. It’s a waste! But beyond that, you will rue the day when you called in the government. From now on the computer industry, which has been very fortunate in that it has been relatively free of government intrusion, will experience a continuous increase in government regulation. Antitrust very quickly becomes regulation. Here again is a case that seems to me to illustrate the suicidal impulse of the business community.



Now I come to the hard part: Why is there that suicidal impulse? Why do business people behave that way? I hope many of you in this room will think about it and try to come up with an answer. I will give you the few suggestions that I have, but none of them seems to me an adequate explanation. One reason was stated more than a century ago by a remarkable man, Gen. Francis A. Walker, a professor at Yale and subsequently president of M.I.T. He wrote:  




When it comes to economics, everybody is an expert who almost always gets it wrong—and business executives are no exception.



Schumpeter gave a very different explanation for this phenomenon. He argued that, within large corporations, the people in charge develop essentially bureaucratic‐​socialist attitudes and institutions. Belief in entrepreneurship and private enterprise tends to be replaced by a bureaucratic approach, leading to the emergence of a socialist system. I don’t believe that’s true. In a competitive society there is enough pressure around to prevent that from happening. But that would be an explanation.



The general climate of opinion, which treats government action as an all‐​purpose cure for every ill, is probably a more important factor. However, over the past 40 years, the climate of opinion has been changing. It is no longer taken for granted, as it used to be, that if there is a problem the way to solve it is to get the government involved. We have been winning the war of ideas even though we have been losing the war in practice. Governments today are far bigger and more intrusive than they were 40 or 50 years ago, at the same time that—partly as effect—the climate of opinion is much less favorable to government control than it was then. But I still don’t think that is an adequate explanation, so I confess that I have no good explanation. Yet I think the phenomenon calls for an explanation and that it’s in your self‐​interest to find one and change the pattern of business behavior in order to get rid of what is a clear suicidal impulse.



 _This article originally appeared in the March/​April 1999 edition of_ Cato Policy Report.   
Full Issue in PDF  (16 pp., 317 Kb)
"
"
Share this...FacebookTwitter

Climate alarmism dissenters getting increasingly vocal.
Yesterday I reported on how science editor Axel Bojanowski at German national daily DIE WELT had written a commentary on the deceptive use of a faulty climate hockey stick by ZDF German broadcasting.
Naturally whenever anything of the sort happens here in Germany, attack dog Stefan Rahmstorf of the alarmist Potsdam Institute rushes out to discredit the dissenter and defend the beloved but flawed chart.
Rahmstorf attacks DIE WELT’s Axel Bojanowski
And Rahmstorf again made the mistake of attacking the messenger of the news (Axel Bojanowski). It was probably the only option left for the ever haughty Rahmstorf, because the diligent DIE WELT editor based his stinging hockey stick commentary on statements made by four experts. Rahmstorf likely had no desire going after the four distinguished colleagues. So it was probably easier and safer for him to just take shots at DIE WELT and editor Bojanowski.
What follows is part of the Twitter exchange between Rahmstorf and Bojanowski, English translation follows:


Hallo Herr Rahmstorf, schade, dass Sie einen Fehler nicht zugeben können, sondern einen drauf setzen müssen.
Ich zitiere in meinem Artikel vier Experten mit Kommentaren zu Ihrer nicht in der Fachliteratur publizierten Kurve, alle fällen ein höchst kritisches Urteil⬇️    1/🧵 pic.twitter.com/pjd2Xl83Zf
— Axel Bojanowski (@Axel_Bojanowski) August 7, 2020


Rahmstorf writes to Bojanowski (see above):
Needless to say – the hockey stick curve is well confirmed by hundreds of scientists after more than two decades of further research – also by the latest data shown above. Its authors have received many awards.
And I’m going swimming now!

Bojanowski reply (in English):

Hello Mr. Rahmstorf, it is a pity you cannot admit a mistake, but even have to put one on top.
In my article, I quote four experts with comments on your curve, which has not been published in the technical literature, all of whom make a highly critical judgment.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Mann jumps in
Even Michael Mann, the creator of the false hockey stick, jumped in as well in typical hothead fashion, offering to “fix” Bojanowaski’s Twitter account:



Like Rahmstorf, Mann too avoided criticizing the four scientists underpinning Bojanowski’s comment, instead resorted to throwing insults and name-calling.
Kachelmann: “potsdumb unscientific nonsense of Rahmstorf”
Moreover, warmist (but non-alarmist) high-profile Swiss meteorologist Jörg Kachelmann got into the fracas, taking a hard shot as well, but at the alarmist camp, tweeting (English below):


Ein #Thread von @Axel_Bojanowski zum potsdämlich-unwissenschaftlichen Unsinn von @rahmstorf und dessen Pressesprecher @terliwetter, der den Sender @zdf als Outlet für die regelmässige Absonderung von Stuss missbraucht.
Wie lange noch? Keine journalistischen Standards mehr @zdf? https://t.co/eqyvz01pXc
— Jörg | kachelmannwetter.com🇨🇭 (@Kachelmann) August 8, 2020

Kachelmann’s tweet above in English:
A #thread from @Axel_Bojanowski on the pots-dumb unscientific nonsense of @Rahmstorf
and his press spokesman @terliwetter, who misuse broadcaster @zdf as an outlet for the regular secretion of bullshit.
How much longer? No more journalistic standards @zdf?”
In summary, there seems to be some progress being made on how science gets conducted in Germany. Increasingly dissenters are seeing victories and the public is growing weary of all the arrogance from certain scientists – especially in the fields of climate, COVID-19 and energy.
But it remains to be seen whether or not this long overdue trend gathers steam.


		jQuery(document).ready(function(){
			jQuery('#dd_fff92674c5c3098e9bc708715a5b22b9').on('change', function() {
			  jQuery('#amount_fff92674c5c3098e9bc708715a5b22b9').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000

Share this...FacebookTwitter "
"

Most every paper in the country is trumpeting today that China has finally agreed to limit its emissions of carbon dioxide, gutting the principal objection of people opposed to unilateral and expensive reductions in ours.   
  
  
Too bad it’s not true.   
  
  
According to the official pronouncement, all China said was that they “intend” to cap their emissions “around 2030”. Anything new here? In November, 2009, prior to the (failed) UN climate fest in Copenhagen, they announced their “intention” to reduce their emissions per unit economic output (called “carbon intensity”) by 40–45% by 2020. Since then, things haven’t appreciably changed—so they now have five years to execute this huge drop, which isn’t going to happen.   
  
  
The road to global warming is paved with China’s good “intentions”.   
  
  
We also note that they “intend” to derive 20 per cent of their energy from non‐​carbon based sources by 2030. No doubt working late into last night (as did we; this story broke at 10:30), the estimable Roger Pielke, Jr., has already calculated that this means that the Chinese will have to put the equivalent of one nuclear power plant _per week_ on line between now and then. As Roger wryly noted, “some people take it seriously”.   
  
  
Don’t. But we should take seriously President Obama’s announcement that the US will double its scheduled emissions reductions by 2025. Thanks to the 2007 Supreme Court (5–4) decision that incredulously said that the 1992 Clean Air Act Amendments gave the President the power to command and control virtually our entire energy economy, he indeed can do what he just said.   
  
  
It would take an act of Congress to prevent him, an act that would most certainly be vetoed, without the necessary two‐​thirds majority to override.   
  
  
One might think that he would care about what the voters think—but that’s not the case. A careful read of election returns reveals that the cap‐​and‐​trade, and not health care, cost his party control of the House in 2010, and, in 2014, the epicenter of electoral carnage was in the coal mining regions of Kentucky and West Virginia, costing his party the Senate.   
  
  
While China has good “intentions” we get real “unemployment”. Such a deal!
"
"
Share this...FacebookTwitterTo all the morons out there who think we ought to defund the police and drag them through the mud. How stupid can you be?







<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->









Readers are welcome to add your own videos of police saving lives.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterSomething is rotten with the GHE
By Erich Schaffer
Introduction
The greenhouse effect (GHE) is a well established theory which most people consider a solid fact, even those who are otherwise “critical” over global warming. On the other side there are some voices who “deny” the GHE with flatearther-like arguments, which seemingly only adds to the credibility of the theory. This is a very odd situation, since the are huge issues with the GHE hidden in plain sight.
“Without GHGs, the Earth would be a frozen planet with a temperature of only -18°C, or 255°K”. This definition is all too familiar to us all and the experts naming it are legion. The 255°K isthe result of a (relatively) simple formula.
(342 x ((1-0.3) / 1)  / 5.67e-8) ^0.25 = 255
342W/m2 is the amount of solar radiation (the exact number may vary), 5.67e-8 is the Stefan-Boltzmann constant and ^0.25 (or the 4th root) represents the Stefan-Boltzmann law according to which radiation is a function of temperature to the power of 4.
Black body assumption trouble
The interesting part however is (1-0.3 / 1). 0.3 is the albedo of Earth and 1-0.3 os thus the absorbtivity, which is the share of solar radiation the Earth absorbs (~70%). The 1 below the comma, which is usually omitted, represents emissivity, which is the share of LWIR emitted by the Earth relative to a perfect black body of the same temperature. In other words, it is being assumed Earth would be emitting just like a perfect black body if it were not for GHGs. And that is where the trouble starts.
The basic problem
Quite obviously there are two factors that “violate” the assumption named above.

The surface of the Earth, mainly consisting of water, is not a perfect emitter, pretty much like any real surface. Although it is not the scope of this article, it can be shown there is a significant deviation from 1 (in the 0.91 to 0.94 range). One needs to look up Fresnel equations, the refractive index of water and so on to sort out this subject.
Clouds interfere massively with LWIR emissions. Actually this is common wisdom, as “clear nights are cold nights” and most people have made the according experience. Even the IPCC states clouds would block a 50W/m2 of SW radiation, retain a 30W/m2 of LWIR and thus have a net CRE (Cloud Radiative Effect) of -20W/m2 [1]. Of course those -50W/m2 of SW CRE are already included in the formula above (part of the 30% albedo), while the 30W/m2 of LW CRE are not.

For this reason we need to make some minor corrections to the GHE as presented above. Basically Earth receives some 240 W/m2 of solar radiation (= 0.7 x 342) and is meant to emit some 390 W/m2 at 288°K at the surface. Next to a temperature of 33°K, the GHE would thus amount to about 150W/m2 respectively (=390-240).
Since in reality the surface is not a perfect emitter, the 390W/m2 are totally inaccurate. In fact it is easy to call it “fake science” whenever someone claims this number, or an even higher one. Rather we need to reduce this figure by at least 20 W/m2 to allow for a realistic surface emissivity. Next we need to allow for the 30 W/m2 that clouds provide and thus our GHE shrinks from 150 W/m2 to a maximum of only 100 W/m2 (150 – 20 – 30).
For the sake of clarity we should rename the GHE to GHGE (greenhouse gas effect) as this is the pivotal question. How much do GHGs warm up the planet? It is important so see that GHGs were attributed with their specific role in a kind of “diagnosis of exclusion”. If it were not for GHGs, what would be the temperature of Earth? Any delta to the observed temperature can then be attributed to GHGs.
Such a “diagnosis of exclusion” is always prone to failure, be it in the medical field or anywhere else. Essentially a large number of variables need to be taken into account and the slightest mistake in the process, will necessarily cause a faulty outcome. For that reason it should be considered an approach of last resort, maybe helpful to treat a patient or solve a criminal case. As a starting point in physics it is a no-go, and as we can see, it delivers wrong results. But maybe that is the reason why it was chosen in the first place. Faulty approaches give a certain freedom of creativity.
GHGE being notoriously exaggerated
Still, we have not broken any barriers so far. Yes, the GHGE is notoriously being exaggerated and anyone who claims Earth would be 255°K cold if it were not for GHGs, is either incompetent, or simply lying. You cannot excuse such a claim as “simplification”, since exaggerating the GHGE by some 50% at least is certainly beyond negligible.
On the other side, this does not deny the global warming narrative at all. One might consider downgrading climate sensitivity a bit, which would only result in climate models better matching reality. Even then, this will only put things on a healthier and more appropriate basis, eventually supporting the theory of CO2 induced global warming.
Digging deeper
So far I have not introduced anything substantially new, but only pointed out to what is known and yet constantly forgotten. Especially the CRE in its quoted magnitude is pretty much an undisputed fact of science. Although I do not know exactly what the origins of these estimates were, experts like Veerabhadran Ramanathan already zeroed in on it in the 1970s. Satellite driven projects like ERBE or CERES later confirmed and specified those estimates.
The net CRE of -20W/m2 thus can be found in the IPCC reports, NASA gives detailed satellite data on it, and even “sceptics” like Richard Lindzen name and endorse it[2]. Such a solid agreement is not just good for my argumentation above, it is also great for the GHGE itself. In fact the negative CRE is pretty much a conditio sine qua non. If clouds were not cooling the planet, the scope for GHGs might become marginal.
There are indeed some issues with the CRE I need to talk about and things are not nearly as settled as I just suggested.

Whatever experts name a net CRE of about -20 W/m2, they refer to the same sources, which are ERBE and CERES satellite data.
This are not satellite data at all, but models which are getting fed with some satellite data, among others.
These models were largely developed by the same people who predicted the negative CRE in the first place. They might not even have a (significant) GHGE if the result would not turn out how it did.
A closer look on these model results show totally inconsistent outcomes over time. Regions with massively negative local CREs turned into having positive CREs, and vice verse.[3]
The only thing which really held constant over time was the overall negative CRE of the named magnitude. Of course, that is a precondition to the GHGE and cannot be put into question, if “climate science” wants to have an agenda.

There is yet another side to it. Obviously the net CRE is the sum SW and LW CREs, which can easily be formulated as CREsw + CRElw = CREnet. Since the CRElw is what is being forgotten so notoriously (as it diminishes the GHGE), we could assume there might be a motivated tendency to minimize the CRElw. Given the logical restrictions, this can be achieved by making the CREnet as negative, and the CREsw as small as possible. In other words, there is a trinity of issues with the CRE.

The -50 W/m2 of SW CRE. This figure is pretty low as compared conventional wisdom, according to which clouds make up for about 2/3s of the albedo, or almost -70W/m2.
The net CRE of some -20 W/m2. We are going to have a look into this hereafter.
The LW CRE of +30 W/m2 which is reducing the GHGE as shown above, but for some strange reason tends to be “forgotten”.

Putting things to the test
Since the net negative CRE is “confirmed” by nothing but models of dubious nature, since logic might suggest the opposite (to cut a long story short) and the whole GHGE theory totally depends on it, this question made a perfectly legit target for fact checking. It is the one pivotal question it all boils down to. Is the CRE negative indeed and how could we possibly put it to the test?
As on my previous works in forensic science it seemed mandatory to pass by any conventional approach subject to predictable restrictions. Rather you will have to go beyond the understanding of those who might conspire so that their possible defences turn futile. And of course this would require brute force of intellect, creativity and a bit of luck to find an appropriate leverage.
At least the latter turns out to be a friendly gift by the NOAA. Under the title “QCLCD ASCII Files” the NOAA provided all METAR data from US weather stations[4]. Regrettably they pulled these valuable data from their site soon after I downloaded it, and the alternative “Global-Hourly Files” is not quite working[5].
The METAR data, as far I understand, are taken at airports and contain, next to usual meteorologic data, cloud conditions originally meant to assist aircraft operating around these airports. The data are anything but perfect for our scope and are subject to a couple of restrictions. As a rule, cloud condition is only reported up to 12,000 ft, yet individual exceptions may occur. Then this cloud condition is reported in 5 different “flavours”, which are CLR, FEW, SCT, BKN and OVC, or combinations of which. For our purpose any combination will be reduced to the maximum cloud condition.
Even if this is not an ideal data pool, it meets a lot of necessary requirements. First it is a totally independent data source, which has never been meant to be used for climate research. Second these data have been collected by many people, who may have made individual mistakes in the process, but were certainly not systemically biased. Third these data are thus “democratic” in nature, not controlled by the bottle neck of a few experts. Eventually, and that is the most important point, we need no models here, but we can look straight onto the empiric evidence.
The Result


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




First I need to tell how such basic research gives you amazing insights otherwise not available anywhere.
You will not get to see what you like to, or expect to see, but what there is. Just like Christopher Columbus searching for India and finding America, you will have to take things for face value. Analyzing the data back and forth, using different perspectives, this was not a simple look up to confirm a certain expectation, but rather a process of continuous learning. Accordingly there are lots of results giving excellent insights into the nature of clouds, or their impacts on climate respectively.

This graph was taken from Harvard’s educational site [6] on the subject. Here, like in later iterations of the ERBE / CERES modelling, the northern Pacific is meant to be one of the areas with a massively negative CRE, which are of special interest to me.
Since the Aleutian islands are US territory, my NOAA data set included 10 stations located right there.

For the years 2016 and 2017, these stations report about 325,000 valid datasets, with almost 60% of which being overcast. So it is indeed a very cloudy region.

Once we resolve the cloudiness/temperature correlation by season, we find a very typical outcome. OVC skies are correlated with lower temperatures in spring and early summer, and with higher temperatures throughout the rest of the year. This pattern has been seen in all subsets featuring distinct seasons and is due to surface temperatures lagging behind solar intensity.

It is an analogy to the day/night cycle, where clouds hold down day time temperatures, while keeping nights relatively warm. It is about the relation of incoming SW to outgoing LW radiation. As clouds interfere with both radiative fluxes, their primary effect will be relative to which of these fluxes is stronger. In spring surface temperatures lag behind solar intensity, LW emissions will be relatively weak and thus clouds are cooling. In autumn this relation naturally reverses and then clouds are warming.
Note: These “tidal effects” are a direct representation of the LW CRE. Although it goes way beyond the scope of this article, such data are very helpful in assessing the actual magnitude of the LW CRE.
A huge surprise
Finally, if we add up the above results and look at the annual average (thus seasonally adjusted), we are in for a huge surprise (or possibly no more at this point). The correlation between clouds and temperature is strictly positive. The more clouds, the warmer it is, and that is in a region where models suggest a massively negative CRE.
Obviously something is totally wrong here.

I am confident the METAR data are correct, and I am certain my analysis is correct, since I have gone over it many times and the outcome is consistent with all the different perspectives. Instead, the ERBE/CERES models are wrong when compared to empiric evidence a.k.a. “reality”. That is not much of a surprise given a track record of inconsistent results.
And as much as the Bering Sea looks like “a perfect match” to fact check these models, the problems go far beyond the region. No matter where ever I looked, a negative CRE could not be found.
Just the tip of the ice berg
Yet this is just the tip of the iceberg. Of course you need to check for biases to see how much a correlation also means causation, and there are a few. Humidity, as much as it may serve as an indicator for the assumed GHG vapour, is indeed correlated with cloudiness (78% rel. humidity with CLR, 85% with OVC), but this delta is a) influenced by rain and b) too small to explain what we see.
More importantly, this analysis is all about low clouds up to 12.000 ft and it is undisputed the net CRE turns more positive the higher up clouds are. Then there is the subject of rain chill, which makes clouds look statistically colder than they are. Finally temperatures are sluggish relative to ever changing cloud conditions and we would certainly see a larger delta in temperatures if respective cloud conditions were permanent.
Systemic GHE failure
Unlike what I named before, this is not just a scratch on the GHE theory, but systemic failure. If clouds warm the planet indeed, and all the evidence points this way, the very foundation of the theory is getting annihilated. Not that GHGs might not play a certain role in Earth’s climate, but the size of the GHGE will be only a fraction of 33°K, and one that is yet to be precisely determined.
[1] 5th AR of the IPCC, page 580
[2] https://wattsupwiththat.com/2020/06/29/weekly-climate-and-energy-news-roundup-414/
[3] https://www.researchgate.net/figure/Comparison-of-annual-mean-SW-LW-and-net-CRE-of-E55H20-E61H22-and-E63H23-to-CERES-40_fig2_335351575
[4] https://www.ncdc.noaa.gov/data-access/quick-links
[5] Documentation does not fit the data format, for some reason I am unable to locate temperature readings, the format itself is hard to read, and finally for some reason these data, station by station, do not correspond to those of the “QCLCD ASCII Files”
[6] https://www.seas.harvard.edu/climate/eli/research/equable/ccf.html


		jQuery(document).ready(function(){
			jQuery('#dd_c8e1fc71e470391995075f099bc5906a').on('change', function() {
			  jQuery('#amount_c8e1fc71e470391995075f099bc5906a').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Kirye
September mean temperature in Sweden has not been warming like alarmists said it certainly would.
Looking at data from the Japan Meteorological Agency (JMA) for the 6 stations with data going back 22 years, we see that 3 of 6 stations have seen cooling September mean temperature over the past 22 years:

Data: JMA.
Europe on the path to societal/energy suicide?
On another note FORBES reported on Prof. Fritz Vahrenholt, the leading German climate science skeptic who I had reported on recently. Here’s an excerpt:
Let us move on to our second piece of evidence, this time from the other side of the “climate emergency” aisle.  Professor Fritz Vahrenholt is a giant among environmental circles in Germany. (The country is well known as the world’s leading champion for all things environmental and for pushing Europe to “net zero emissions by 2050”.) Prof. Vahrenholt holds a doctorate in chemistry and started his professional career at the Federal Environmental Agency in Berlin (responsible for the chemical industry) before joining the Hessian Ministry of the Environment. From 1984 until 1990 he served as state secretary for environment, from 1991 till 1997 as minister for energy and environment in the state of Hamburg.
One day before the publication of the Boston Review article on October 5th, Prof Vahrenholt stated baldly in a German TV interview that climate science was “politicized”, “exaggerated”, and filled with “fantasy” and “fairy tales”. He pronounced that “The [Paris] Accord is already dead. Putin says it’s nonsense. […] The Americans are out. The Chinese don’t have to do anything. It’s all concentrated on a handful of European countries. The European Commission in massively on it. And I predict that they will reach the targets only if they destroy the European industries.” He lambasted Germany as a country “in denial when it comes to the broader global debate taking place on climate science”. He went on to characterize Europe’s recent push for even stricter emissions reduction targets to madness akin to Soviet central planning that is doomed to fail spectacularly.”

Read entire FORBES article here.



		jQuery(document).ready(function(){
			jQuery('#dd_f520153282479aa8bdd5967e8ebb475b').on('change', function() {
			  jQuery('#amount_f520153282479aa8bdd5967e8ebb475b').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"

This year’s installment of the U.N.‘s annual holiday party has come and gone from Cancun, with little to show for it except the massive carbon footprint of thousands of attendees — official delegates of member nations, plus representatives of Greenpeace, the World Wildlife Fund, and their ilk.



Technically, what we have just witnessed is the 16th Conference of the Parties to the United Nations’ Framework Convention on Climate Change, a.k.a. “COP16.” These conferences always take place at this time of year, and often in the tropics or in the Southern Hemisphere, where it is now summer. Next year’s confab will be in Durban, South Africa.



It’s really poor planning to throw these parties in December. The weather in the Northern Hemisphere lately has been downright uncooperative. Cancun witnessed a 100‐​year record low temperature one day as the delegates got down to “business” for two weeks, actually accomplishing little of substance. Last year, when COP15 was held in Copenhagen, the weather was miserable, with frequent snow and unseasonably cold temperatures. The quintessential images from that conference were of Barack Obama pronouncing the meeting a great success, and then rushing back to Washington, only to land in a blinding snowstorm.



Copenhagen was an abject failure. The great “success” was a requirement that each nation submit a schedule for reductions in carbon‐​dioxide emissions. But that requirement was waived by the executive secretary of the Framework Convention, Yvo de Boer. Then he quit.



He was replaced by Costa Rica’s Christiana Figueres, who welcomed the crowd to Cancun, invoking Ixchel, the Mayan goddess of weaving and creativity. Rather appropriate for an organization whose last climate report was made up out of whole cloth.



Predictably, Figueres pronounced the festivities a roaring success. “Cancun,” she said, “has done its job — the beacon of hope has been reignited.”



Sure — as in, Third World nations hope that the developed world’s governments will magically decide to donate them a trillion dollars over the next decade to “cope” with climate change.



Indeed, the delegates did agree to this “green fund,” but they failed to explain where the money will come from. All they agreed upon was how the nonexistent moneys are to be distributed.



Nor did they agree to anything that would commit any nation to reductions in carbon‐​dioxide emissions. However, you are free to submit a schedule that you don’t need to adhere to.



I’m sure that the U.N. can’t wait for the U.S. response on this one. It will appear in the form of some directive from the executive branch, specifically the EPA. But let us not forget — as I’m sure he has not — that the president’s party just got pummeled in the midterm elections. The more stringent the directive is, the more likely it is that Mr. Obama will leave Washington a private citizen in January 2013.



Even if he approves big (and impossible) cuts, it won’t do a measurable thing about global warming unless China and India agree to similar reductions. In fact, they have already informed the world — at both Copenhagen and Cancún — of their intent to raise emissions. China’s are on track to double in the next decade, and India’s look to increase threefold. Together, those two countries could easily be responsible for half of global emissions over the next two decades. The U.S. is currently responsible for about 20 percent of the total, and that percentage is steadily dropping. In 2009, China emitted a whopping 27 percent more than the United States.



The Cancun partiers couldn’t agree on any treaty or protocol to replace the failed Kyoto Protocol, which expires at the end of 2012. That one was supposed to “legally bind” the industrialized world to reduce its emissions to about 5 percent below 1990 levels by now. That language really worked, didn’t it? Emissions rose by more than they were supposed to fall. And even if all nations met their “obligations” under Kyoto, they were so insignificant that their effect could never be found by thermometers.



Kyoto was so unpopular that it was never brought up for ratification by the U.S. Senate. After the unceremonious death of cap‐​and‐​trade, are there going to be the 67 votes necessary to ratify something even more politically damaging?



It’s not easy to see the need for all these annual gatherings. In this fiscal climate, the developed world isn’t going to send a trillion bucks to Africa and a few tropical islands. Nor is any agreement going to be enforceable.



If the U.N. delegates were serious about global warming, at least they could meet by Skype and GoToMeeting instead of burning hundreds of thousands of gallons of Jet A in pursuit of perennial failure.
"
"

Donald Trump’s cabinet of generals and billionaires looks poised to gain another controversial member: Rex Tillerson. The CEO of ExxonMobil is now the secretary of state nominee. His nomination raises several red flags, but the central one is: conflicts of interest. In that, he’s a perfect match for the Trump administration.



Tillerson faces a difficult confirmation process for a variety of reasons, including congressional Democrats’ determination to grill him on climate change issues. Yet some of the key issues cited by the media are actually less problematic than they may seem.



For one thing, while he has no governmental foreign policy experience, Tillerson has spent years running a multinational corporation so vast that various observers have likened it to a privately owned state. ExxonMobil, the world’s eighth‐​largest company, operates on six continents, and as CEO, Tillerson has successfully negotiated a number of complex and high‐​profile international deals.





Donald Trump’s secretary of state pick faces a dizzying level of conflicts of interest. These could pit national security against his personal gain.



While competitor BP was being pushed out of its Russian holdings by the government, for example, he struck an effective compromise with the energy giant Rosneft, allowing ExxonMobil to maintain its presence. Likewise, Tillerson’s effective negotiation with Venezuela meant that the company was one of the few to receive compensation — a whopping $900m — for Hugo Chavez’s expropriation of its assets.



Nor is it clear that Tillerson really is — as Senator Marco Rubio and others have argued — a close friend of Vladimir Putin. The Russian Order of Friendship, which Tillerson received in 2013, has been given to numerous Americans in recent years, and contacts with senior Russian officials are an unfortunate but necessary part of doing business in that corrupt country.



Indeed, in other circumstances, his strong working relationship with the Russian government could be highly beneficial, particularly after eight years of a strained personal relationship between US and Russian leaders.



Unfortunately, the nomination raises other problems. For one thing, it’s not actually clear what Tillerson’s views on foreign policy are. Despite concerns over other candidates for secretary of state — such as John Bolton and Mitt Romney — at least it was clear what kind of foreign policy approach they favored. We don’t know if Tillerson is hawkish or not, nor do we know his views on US alliances or international institutions.



The profit motive underlying Tillerson’s previous experience is also fundamentally different from national security interests. Tillerson may have good relations with some world leaders, but given the nature of the oil industry, many of these are poor, corrupt and authoritarian states; ExxonMobil’s recent agreements include such paragons of corruption as Russia, Guyana, Angola and Nigeria.



As a result, the relationships that Tillerson built during his time at ExxonMobil have the potential to be a double‐​edged sword. How long will his good relations with many of these leaders last when he is required to criticize their human rights records as secretary of state, or to oppose them in negotiations on security issues?



By far the biggest problem with Tillerson’s nomination is the serious conflict of interest created by his long history with ExxonMobil. Even if he cuts all direct ties to the company, he will still have a strong financial interest in its success. According to one estimate, he will still hold stock totaling around $218m, and a pension plan worth $70m. And there are many areas where Exxon’s profit motive conflicts with the US national interest.



The most obvious of these is undoubtedly US sanctions on Russia. ExxonMobil has already lost as much as $1bn from sanctions, and Tillerson has been a frequent visitor to the White House and the Department of the Treasury to lobby against them. But there are plenty of other potential clashes: a recent Exxon deal in Mexico would seem to conflict with Trump’s confrontational approach to that country, and the company last year directed a lobbying firm to monitor US energy‐​related sanctions on Iran for opportunities.



In these and many other cases, Tillerson’s personal financial interests will conflict with his duties as secretary of state. He’s certainly not alone in Trump’s cabinet in having such conflicts: the family of Elaine Chao, nominee for secretary of transportation, owns a shipping firm, and the president‐​elect has come under increasing scrutiny for his refusal to divest himself of involvement in his business empire.



Yet while Tillerson may be an excellent negotiator and a good fit for Trump’s nontraditional cabinet of businessmen and generals, these conflicts of interest call into question whether he can fulfill its duties effectively. The most important question remains unanswered: whose interests will he serve as secretary of state?
"
"

Here’s a roundup of bloggers who are writing about Cato research and commentary: 



Are you blogging about Cato, but not on the list? Drop us a line and let us know!
"
"Controlling the epidemic of tuberculosis in English cattle is a hugely controversial issue. The role badgers play in that epidemic and how to prevent their infection spreading to cattle is also hotly contested.  The recent Bovine TB Strategy Review, known as the “Godfray Review”, described culling badgers as having only a “relatively modest benefit” in reducing the incidence of TB in cattle and described the use of “non-lethal” control of infection in badgers as “highly desirable”.   Culling badgers has been largely unpopular with the public, and since the report suggests it may not be an effective long-term solution, what are the non-lethal alternatives, and do they work?   There are three main approaches to reducing the risk that TB in badgers poses to cattle. We can reduce the number of badgers, reduce contact between badgers and cattle, or reduce infection among badgers.   The idea behind culling is simply to reduce badger numbers so that the amount of badger-to-badger and badger-to-cattle transmission falls, ideally until the infection dies out among the badgers.  The largest trial of badger culling, the Randomised Badger Culling Trial, finished around ten years ago and found that culling caused both a reduction in badger numbers and of TB in cattle. But it also found that a high proportion of the remaining badgers had TB. So once culling stops, a regrowing badger population that’s still infected might pose an even greater risk to cattle. 


      Read more:
      Badger cull didn't kill enough badgers to be effective


 Early trials have suggested another way to reduce badger populations: immunocontraception. This involves vaccinating badgers against their own reproductive hormones so they can’t get pregnant. It may prove more socially acceptable than culling.  But rolling this out is some way off. As it reduces the future birth rate rather than increasing the death rate, contraception will also take longer to reduce badger populations than culling.  Keeping cattle and badgers apart with physical barriers around farm buildings such as badger-proof gates and electric fences – an approach known as “biosecurity” – is relatively simple but can be expensive.  How the disease is transmitted in open environments, through slurry and soil movement or on contaminated farm vehicles, people and wildlife, is less well understood. However, improved biosecurity will also help control other infectious diseases. The TB Advisory Service, which provides free advice to farmers, emphasises integrating TB and other disease control programmes. Badger vaccination requires first trapping the badgers, as it uses the same injectable vaccine, BCG, as is used in humans. It is undertaken by trained and licensed volunteers in England, thereby reducing the cost.  Oral vaccines would be easier to use but are not yet licensed. Small numbers of trials have demonstrated that vaccination reduces both the number of badgers infected and the degree of disease in badgers with only partial protection. However, unlike for culling, there have been no large-scale trials of the effect that vaccinating badgers has on TB in cattle. Most badger vaccination in England has been undertaken in areas in front of the expanding cattle epidemic, where the badgers are believed to be free of bovine TB. This is because vaccination will protect against infection in susceptible badgers but will not stop the development of the disease in those already infected. But vaccination may still be effective at the population level among infected badgers by reducing transmission.  A recent study in Ireland found that vaccination reduced transmission enough that TB should die out among the badgers if reinfection from cattle is prevented. It will be interesting to see if vaccination on the edge of the English cattle epidemic has any effect on the expansion of the epidemic in either cattle or badgers. Determining this, however, will require more surveillance of TB in badgers than at present. In Ireland, the follow-up strategy to culling badgers appears to be vaccination, while a “test-vaccinate-remove” (TVR) approach, in which individual badgers are caught, tested and either vaccinated or killed, is being trialled in Northern Ireland and Wales.  TVR is as labour-intensive as vaccination but might reduce the numbers of infected as well as susceptible badgers. Unfortunately, the current diagnostic tests for TB in live badgers are not very sensitive, so some infected badgers will be left in the population. The Godfray Review discusses how combined approaches to controlling TB might have bigger effects than any single approach. Vaccination plus immunocontraception, or short culls plus vaccination, all combined with better biosecurity may be the answer.  But this would require a more joined-up approach than currently exists and an agile policy, responsive to local differences and capable of changing rapidly as new evidence becomes available. And, of course, whatever approach is used to control TB in badgers, reintroduction of infection is possible if the disease is not better controlled in cattle."
"
Share this...FacebookTwitterBy Prof. Fritz Vahrenholt
The global mean temperature of the satellite-based measurements remained almost unchanged in August compared to July. The deviation from the 30-year average (1981 to 2010) was 0.43 degrees Celsius.

Temperature measurements on land and in the sea continue to decrease, as the graph of the JRC analysis shows, especially in the southern hemisphere (blue).

Approaching La Nina
The research institutes predict with high probability a La Nina in the Pacific Ocean next winter. Therefore, a further decrease in global temperatures is expected until next spring. The following diagram shows the incipient cooling effect in the Pacific.

Share this...FacebookTwitter "
"
One of the things that happens when your work becomes well known is that people send you things to look at. Such is the case for today’s subject. Here we have a NOAA COOP station which is on the side of a mountain, well away from large cities. Only problem is, they put it right next to a parking lot.
A reader of this blog, Brad Herrick, sent me these photos of the Mt. Charleston weather station on State Route 157 west of Las Vegas.  For those that don’t know, Mt. Charleston is the large mountain to the west that overlooks Las Vegas. NOAA lists it on it’s COOP-A list, meaning that it reports for the climatic database. It’s been in operation since 1949. Its been moved 3 times, but all within about 1/2 mile as the fire station changed and grew.
According to NOAA’s MMS database, here is the description: Elevation, 7600 feet. NV DIV OF FORESTRY FIRE STN KYLE CYN OUTSIDE AND 30 MI NW PO AT LAS VEGAS NV. Topographic Details: RUGGED DEEP CANYON .25 – .5 MILE WIDE, RISING TO PEAKS 3000-5000 FEET HIGHER TO NORTH, SOUTH AND WEST A DISTANCE OF 2 TO 4 MILES. Lat/Lon 36.2597, -115.6452 , COOP ID 265400
Seems pretty rural, with a mental image of “way up in the mountains” if you were researching this station. By James Hansen’s figuring, it would also be a “lights=0” station since I doubt there is municipal street lighting for this area.
It’s certainly well enough away from the super sized Las Vegas concrete and asphalt heat island.
Here is the view from Google Earth:

click for larger view
Except for a few houses, it certainly looks “rural”.  Any researcher at NCDC or maybe a university that might use this station in some research report would certainly think this station was well away from the building/concrete/asphalt influence of bustling Las Vegas wouldn’t they?
But then we see this:

and this:

and this:

click for larger images
Unfortunately, I don’t have a time series temperature graph of this station to show you since I haven’t found a place at NCDC yet to graph COOP stations that are COOP-A. If anybody knows of such a link, please let me know. 
There’s nothing like convenient parking to convert a rural station to urban. But lets not forget the maintenance of the Stevenson Screen roof (see pic #2 -large), hillside, shade bushes, fire station building revisions, and portable storage unit. When did all that happen? We have no idea.
Surely, it’s easy to disentangle all that from the temperature record. Quick! Somebody create an adjustment equation.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea1307288',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"
I happened across a NOAA internal training manual a couple of weeks ago that contained a photo of a USHCN official climate station that I thought I’d never get a photo of.  The Baltimore Customs House.
 
Baltimore USHCN station circa 1990’s photo courtesy NOAA, click for more images
What is interesting about this station, is that it is a rooftop station, like we’ve seen in San Francisco, Eureka, and many other US cities. Rooftop stations are suspected to impart a warm bias to the surface temperature records, for obvious reasons. The NWS/NOAA has been reluctant to change these stations to ground-level, wanting to keep a continuous record. The Baltimore USHCN station closed in 1999 and has not been replaced at this location.

From this single photo, and with the help of Google Earth and Microsoft Live Earth, I was able to complete this station survey, post mortem, giving it a CRN 5 rating. Below is one of the aerial photo links:
http://maps.live.com/default.aspx?v=2&cp=qjf9bk8mg9ks&style=o&lvl=2&tilt=-90&dir=0&alt=-1000&scene=7161999&encType=1
The Baltimore customs house is centered in the picture, you can see the old platform for the USHCN station is still there.

Earlier this year, www.Surfacestations.org volunteer John Goetz located an early historical photo of the Baltimore station, seen below:
 
But, this NOAA internal training manual not only cited this example photographically, they also did a correlation study that proved that the rooftop placement was actually warmer. 
Here is what NOAA said about the Baltimore USHCN station in their training manual:
Instrument exposure standards are really compromised with rooftop locations (figure 11).

Figure 11: An Early Rooftop Meteorological Station.
While the number of NOAA rooftop climate stations has remained at about 40 for the last decade, the number of private rooftop stations has grown during that period into the thousands. Rooftop exposures have an advantage of increased instrument security and good exposure for wind sensors (standard height is about 33 feet). However, there are also drawbacks. Access for maintenance can be difficult and exposure for precipitation and temperature instrumentation is clearly non-compliant, being elevated to high above the ground. Additionally the instrument exposure is usually over environmentally nonrepresentative surfaces (metal, black tar, shingle, stone etc.), while at the same time being close to a wide variety of roof surfaces which are subject to change.

No argument there. The trade off is security versus representivity of climate. But climate usually loses in a rooftop station instance.
They go on to say:
The unrepresentative-ness of rooftop temperature and precipitation data was discovered long ago after studies quantified the biases. The late Professor Helmut Landsburg, considered the “father of climatology”, stated in his 1942 “bible of climatology” textbook, “Physical Climatology” that:

“Climate derived from records of roof stations may by no means be representative of those at the ground level.”

In another published paper 28 years later, Professor Landsburg again reiterated his concern about rooftop exposures with respect to the urban warming issue: “They [rooftop stations] are certainly of little value in a full assessment of the climatic changes brought about by urbanization.”
That leads one to wonder why they kept these stations at all, let alone appoint them as “High Quality” USHCN stations for use in climate research. The Baltimore Custom House is also a GISS station. They also write:
Rooftops make good observation sites if you live work, play, or grow your food on a roof. Unfortunately, few people do any of the above. Rooftop exposures have been shown to exhibit biases towards warm temperatures (both maximum and minimum) and lower precipitation when compared to ground based stations. The warm temperature biases likely result from extreme daytime heating of artificial rooftop surfaces, reduced cooling of the roof at night, and from heat flow from within the building, especially in winter. The biases can be substantial. One limited study indicates 5 to 10 degrees on summer days with bright sun and light winds. Biases have been found to vary significantly, depending on many factors (location on the roof, color of roof, type of roof surface (rock, metal, etc.) time of year, etc when compared to standard ground-based sensors. On the flip side, if a station has been on a non-changing roof for decades, the site may have good continuity (value) for tracking climate change and variability. For some climate applications, consistency with a long record can be more important than accuracy with a shorter record. 
The best of both worlds is to have an exposure compliant, long-term station.
But the thing that really hit me was the data they compiled, comparing to other nearby stations, and thus proving the case for rooftop bias with this station:

They cite the table with:
The table to its right summarizes a comparison of 12 months of overlapping data that was collected on the rooftop and at the new relocated site (for data continuity), relocated several blocks away at ground level with other nearby standard, ground based stations. A combination of the rooftop and downtown urban siting explain the regular occurrence of extremely warm temperatures. Compared to nearby ground-level instruments and nearby airports and surrounding COOPs, it is clear that a strong warm bias exists, partially because of the rooftop location.
Maximum and minimum temperatures are elevated, especially in the summer. The number of 80 plus minimum temperatures during the one-year of data overlap was 13 on the roof and zero at three surrounding LCD airports, the close by ground-based inner Baltimore harbor site, and all 10 COOPs in the same NCDC climate zone. Eighty-degree minimum are luckily, an extremely rare occurrence in the mid-Atlantic region at standard ground-based stations, urban or otherwise. Temperatures can be elevated on roofs due to the higher solar radiation absorption and re-radiation associated with many roof surfaces including black tar, shingles, stone, and metal. During the colder months, ongoing upward heat transfer through the roof from the heated interior of the building also can contribute to the warm bias although stronger winter winds tend to create better mixing and minimize this impact.

The table shows that the rooftop station has Tmax >90°F more than twice as often  as other stations and a Tmax >100°F  13 times where no nearby station achieved it. Similarly we have this station recording a Tmin >80°F where no other stations did.
Yet amazingly, knowing all this, stations like this, and stations that have instrumental biases such as Tucson, with its parking lot placement (USHCN) and HO83 problems(GISS) still remain as part of the USHCN and GISS datasets. The official all-time high temperature record of Tucson of 117°F still stands, set by a known faulty HO83 thermometer.
In the case of Baltimore, the question is, in the plot below what really has been measured? Is it city growth, building energy use/dissipation, rooftop albedo variations, nearby building changes, or climate change? Given that it is impossible to disentangle all these things, the data, in my opinion, should be deemed compromised and discarded.
         
GISTEMP Plot of Baltimore City USHCN station #180470
In any other line of scientific study or in engineering, data that has been so badly compromised would likely be forced out by peer review, or the researchers themselves once the errors were discovered. Yet here we are today, keeping this station record for use in climatological study.
Reference: NOAA Professional Competency Unit 6 (PCU6) manual (PDF)


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea1894ab0',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"The Paris Agreement of 2015 has a central aim to keep global temperature rise this century well below 2°C above pre-industrial levels and to “pursue efforts” to limit the temperature increase even further to 1.5°C. This is an ambitious aim – global temperatures are rapidly approaching the 1.5°C target and the 2°C limit is not far away. The path to 1.5°C requires that the world achieve zero emissions before 2050. It is imperative, therefore, that we stop burning fossil fuels, known as mitigation. However, our present trajectory suggests we’re not on track. COP24 can’t take its eye off this ball –- there is no long-term plan that doesn’t include zero fossil-carbon emissions. The scientific consensus is that we need to reach “net zero” CO₂ emissions by 2050. But to tack closer to a scenario of 1.5°C warming, COP24 should set this target for 2035. The United Nations, in the IPCC Special Report on Global Warming of 1.5ºC has accepted that there isn’t any obvious pathway to zero emissions in such a short time frame, so they have pegged their hopes on NETs – Negative Emissions Technologies. These approaches include carbon capture and storage (CCS), which involves sucking CO₂ from the air and storing it deep underground.  Carbon removal along these lines is the second imperative for COP24 in Katowice. Globally we emit around 40 billion tonnes of CO₂ annually, so net zero CO₂ by 2050 will require CO₂ removal of this scale, starting immediately. 


      Read more:
      Explainer: what is carbon capture and storage?


 But CO₂ isn’t the only problem. We emit other greenhouse gases such as methane, nitrous oxide and chlorofluorocarbons (CFCs) which all contribute to climate change. Methane is on the rise and is 84 times more potent as a greenhouse gas than CO₂. It comes from cows, and it leaks from oil wells and coal mines as “fugitive methane”. It is also seeping out of the melting permafrost in the Arctic. This is a worrying form of “positive feedback” where global warming causes the further release of gases that cause further warming.  Nitrous Oxide, which is 300 times more potent than CO₂, is rising too, caused by modern agriculture. And the concentration of refrigerant gases, such as CFCs, which are thousands of times more potent than CO₂, is not falling as fast as we’d hoped. So COP24 has a third imperative, to prevent the rise of non-CO₂ greenhouse gases. If we can stabilise non-CO₂ greenhouse emissions at present day levels we’ll be doing well, but concentrations are rising fast. All of this is going to be hard work. We’re failing to cut down our emissions, the technologies for NETs don’t exist at any meaningful scale, yet and there are no political drivers in place to enforce their deployment. There is also a real risk of a dramatic rise in methane in the near future. COP24 will have to consider emergency plans. One such plan is very controversial. There are so-called “geoengineering” technologies which can be used to cause changes in global temperatures. One of these is Solar Radiation Management (SRM), which involves injecting tiny aerosol particles high in the atmosphere where they reflect sunlight into space. We know from the eruption of Mount Pinatubo in 1991 that stratospheric aerosols caused a cooling of around 1°C over a year. The northern winter of 1992 saw a dramatic increase in sea ice and a stalling of glacial melting. SRM technologies exist and the first sun-dimming experiments are underway. There is a realistic possibility that deploying SRM can buy us some time to enact the essential measures needed to stop warming at or before 1.5°C. The discussions at COP24 must keep all options on the table, and as unpalatable as geoengineering technologies might seem, their deployment may prove to be unavoidable. The indicators are all in the danger zone. We are seeing increasing Arctic temperatures, rapid loss of Arctic sea ice, reduced Arctic reflectivity, rapidly melting ice shelves and methane release from permafrost. These are leading to rapidly rising sea levels, coastal flooding and storm surges, increased hurricane and storm activity, dry and hot conditions conducive to wildfires, and drought and crop failure. The urgency for decisive action is the imperative for COP24. The UN must press on with four major strands for meeting the Paris 1.5°C target: Reduce fossil carbon emissions. Remove carbon from the atmosphere (NETs). Halt the rise of emissions of non-CO₂ greenhouses cases (Methane, Nitrous oxide, CFCs). Investigate techniques for geoengineering, including Solar Radiation Management. All four of these must proceed simultaneously and in parallel. COP24 must make this perfectly clear. There is utmost urgency and no time to “wait and see”."
"When the broadcaster and naturalist David Attenborough launched the latest UN climate talks, COP24, he called for ordinary people to get involved, add their voice, and “take their seat”. A series of #takeyourseat videos were published, featuring people around the world discussing what climate change meant for them. This was a sign of something new at this COP. On Friday, its closing day, a Swedish school girl called Greta Thunberg called for a global climate strike and urged policymakers to hear the voice of the youth. Our children will suffer the consequences of the past actions of their elders and their current lack of climate action. So was the “people’s voice” truly included in the climate talks, or was it still business as usual? One way we can assess this is by looking at some of the pledges to emerge from the conference. In the final days of COP24, for instance, EU members and scores of developing countries pledged to toughen their existing commitments to cut emissions through enhanced Nationally Determined Contributions (NDCs). The NDCs are simply the post-2020 climate actions that nations intend to implement to meet the long-term goal set by the Paris Agreement. Yet, as the talks were taking place, references to human rights in the planning of NDCs were removed by negotiators, including US and Saudi Arabia. This is worrying for climate justice and human rights in general. And it’s particularly worrying for indigenous people, who have hands-on knowledge of the functioning of the natural world and who are often put in jeopardy for the benefit of private interests extracting natural resources. One problem with the power of financial resources is that they give a fake sense of legitimacy to the use of scarce natural resources. Because I pay, runs the argument, I can use it, and the act of paying detaches me from the consequences of my consumption. Hence, there is an urgent need for policymakers and those involved in financing climate to get rid of that sense of legitimacy.  Another element of the pledge is to bring in rapid change by broadening the “coalitions between governments and non-party stakeholders”. But who are the stakeholders? Who appoints them? Who are they accountable to and can we be sure they are genuinely committed to fighting climate change? Undermining the voice of the people is a key element in the failure of top-down policies to bring successful, rapid, and sustainable positive climate actions.  One way to push for more action on climate change is to empower women. And indeed, over the two weeks of COP24 meetings, we did hear the voice of women such as Joanna Sustento, a climate activist from the Philippines. Sustento lost many family members to Typhoon Haiyan in 2013, and is now fighting to hold 47 fossil fuel companies responsible for nearly a quarter of all greenhouse gases, accountable for deaths related to climate change.  We saw at the meetings the commitments of major organisations and development banks to divest from fossil fuel. But whether it will turn into further green washing, feeding speculative bubbles in financial markets again depends on that sense of legitimacy. We also heard the voice of Greta Thunberg, who created a global climate strike despite being herself at the margins of society because she is young, female and has Asperger syndrome. The elite of this world, flying high on corporate benefits and air miles, would do well to listen to the children that are now crying out for action, and to the little voice of the child they once were."
"Humans have cut down half the trees on Earth since the dawn of agriculture – over 3 trillion of them. This huge loss holds the potential for massive reforestation today, which would protect local environments from soil loss, flash flooding and desertification and take up large quantities of atmospheric carbon dioxide. Despite these advantages, reforestation gets very little attention in our fight against climate change. Britain is ideal for tree growth due to its mild winters, plentiful rainfall, fertile soil and hill-sheltered topography, and it has growth rates higher than mainland Europe and Scandinavia.  Britain, without human interference, would be covered by mature oak woodland with some hazel, birch and pine further north. But England’s forest cover dropped as low as 5% after World War I, prompting the government to set up the Forestry Commission, which has helped increase forest cover over the last 80 years to nearly 10%. Overall, UK forest cover is now 13%, nearly 3.17m hectares. This is one of the lowest levels in Europe, which has a forest cover averaging 35%. Japan has a similar population density to the UK, but has maintained 67% forest cover. The UK government already has plans to create new habitats on 500,000 hectares of land by 2043, restoring forests, meadows and wetlands on about 2% of the UK’s area to mitigate and adapt to climate change. Each hectare that is rewilded will absorb the carbon emissions of 30 London buses or 90 cars for a year. If done correctly, this could take up a third of the annual carbon emissions of the UK.  This 2% target lacks ambition considering the government’s own Independent Panel on Forestry concluded in 2012 that the forested portion of England should rise to 15% by 2060 – a return to its Medieval level. This would mean reversing the decline in forest planting that has occurred over the last 30 years. The Climate Change Committee recommends that the UK should have a 2050 zero carbon emissions target. If reforestation occurred across the whole of the UK, increasing the total forest cover to 18% and if all bogs, grasslands, arable and horticultural lands were managed in the best way possible, then these could account for one quarter of the required cuts by 2050. If this mandate moves to a more stringent “zero carbon emissions” target for 2050, as suggested by the recent IPCC 1.5˚C report, then managing the British landscape could provide 25% of the solution.  Managing the natural landscape also has other benefits, from stabilising soils and preventing floods to ameliorating heatwaves and preserving biodiversity.  Using plants to combat climate change is an idea with plenty of supporters elsewhere in the world. Globally, mass forest restoration is already underway, with commitments across 43 countries to restore 292m hectares of degraded land to forest, ten times the area of the UK. The IPCC special report on keeping global warming below 1.5°C makes a compelling case for agriculture and forestry taking a leading role in absorbing and mitigating carbon pollution. Their recommendations include converting up to 8m km2 of pasture and up to 5m km2 of non-pasture agricultural land used for food and feed crops into at least 7m km2 used for energy crops. These energy crops will produce solid and liquid fuel that will replace fossil fuels. They also recommend aggressive global reforestation targets. One suggestion is to take the 1m km2 of forest that has been lost over the last decade and replacing it with 10 million km2 of forest by 2050. We can reduce carbon emissions from human land-use by restoring ecosystems, farming in a more sustainable way and encouraging a shift to less resource-intensive diets – a vegan diet emits a third of the carbon emissions of a meat dominated diet. Massive reforestation is not a pipe dream – there are excellent examples of it being done in the recent past. In the late 1990s environmental deterioration in China became critical, with vast areas resembling the dust bowl of the American Mid-west in the 1930s. Six large forest programmes were introduced during the late 1990s and early 2000s, targeting over 100m hectares of land for reforestation.  Grain for Green is the largest and best known of these programmes. It reduced soil erosion and desertification and stabilised local rainfall patterns. The ongoing programme also helped to alleviate poverty, as payments are made directly to farmers who set aside their land for reforestation. It has also reduced China’s grain surplus, which was depressing prices, and helped to rebalance the inequality between the eastern and western provinces. The Grain for Green programme  shows that widespread reforestation can have a very positive affect on the economy as well as the environment. There is ample opportunity and land on which to reforest. Despite the rising population of the Earth, which is projected to hit 10 billion by 2050, there is a net migration from rural areas into urban areas. Outside of cities, the world is getting wilder as people move into dense urban populations. This opens even more areas that could be considered for rewilding.  Global reforestation should be considered an essential tool to combat climate change at COP24. For the UK delegation, some ambition to revive the country’s beautiful forests is long overdue."
"
Share this...FacebookTwitterA 2006 peer-reviewed scientific paper (Inglesby et al., 2006) on pandemic mitigation policy said the efficacy of 3-feet social distancing is unknown, surgical masks do little to prevent virus droplet inhalation, and closing schools, restaurants, stores…have seriously adverse community consequences.
The paper refers to what policymakers should recommend if there is an influenza pandemic.
Keep in mind that the flu kills about 500,000 people a year worldwide and there have been some years when it has reached pandemic proportions, killing over a million people (i.e., 1957-’58, 1968-’69).
In 1918 the flu pandemic killed 50 million out of 500 million infections worldwide. At the time, that was one-third of the world’s population.
And yet at no time have we ever responded to a pandemic the way we have with COVID-19.

Image Source: Inglesby et al., 2006
Share this...FacebookTwitter "
"It wouldn’t be Christmas without a tree, but which is more sustainable – a real tree or a plastic one? You might expect anything plastic to be the least environmentally friendly option. It’s true that manufacturing plastic trees consumes a lot of energy, and so does shipping them, to the UK from where they’re commonly manufactured in China, for example. Although you can use a plastic tree for many years, most aren’t recyclable and ultimately still end up in landfill. However, real trees aren’t necessarily the greener option. The UK uses as many as 8m natural Christmas trees during the festive period each year and sadly, about 7m of these are discarded. The other million are mainly used as compost, though many people avoid this based on the assumption that the low pH of pine needles (between 3.2 and 3.8) will make the soil acidic.  Christmas trees such as the Norway spruce and Nordman fir have hundreds of thousands of pine needles which take a long time to decompose compared to other tree leaves. When they rot, they emit huge quantities of greenhouse gases. According to The Carbon Trust, the carbon footprint of a 2m-tall real Christmas tree is equivalent to 16kg of CO₂ if it ends up in landfill. That’s 100,000 tonnes of greenhouse gases from the 7m trees that end up languishing in landfills every year. A better solution would be to reuse the pine needles and the trees. My research at the University of Sheffield has been investigating whether there are useful products that we can get from pine needles and how to produce these. Like most plant biomass, 85% of a pine needle is a structurally complex polymer known as lignocellulose, which is rich in carbohydrate and aromatic compounds. The structural rigidity of lignocellulose makes it unattractive and useless in most industrial processes because of the high energy intensity needed to break it down. 


      Read more:
      Now that Christmas is over, what are you going to do with your tree?


 My research is focused on how the complex structure of this polymer can be broken down into simple industrial chemical feedstocks of high value and low molecular weight, such as sugars, organic acids and phenolics – chemicals which are important raw materials in industrial manufacturing. By a process called liquefaction which uses moderate temperatures and environmentally-friendly solvents like glycerol or water, the pine needles are converted into a liquid with a solid byproduct called bio-char. The warm solvent  helps to break down the complex chemical structure of pine needles into smaller chemical molecules, which make up the liquid. This liquid product typically results in glucose, acetic acid and phenol. Glucose is used in the production of sweeteners for food, acetic acid in making paint, adhesives and even vinegar, and phenol in the manufacture of medicines. None of the products from this process are wasted – even the bio-char can be used as a catalyst for other chemical reactions. The tree doesn’t need to be fresh either, as the process applied in this work can effectively handle both dry and wet biomass, eliminating the need for an expensive drying process. This is a key advantage of the liquefaction technique over traditional technologies such as combustion and gasification, whose efficiency depends on the moisture content of the biomass. This method also works well with other forms of biomass waste and can be used for any species of pine. An industry built on this process could convert much of the available biomass waste from food crops and forestry management into vital products. Aside from converting biomass waste into precious materials, this process adds value to otherwise less useful solvents such as crude glycerol – an unwanted byproduct from the biodiesel manufacturing industry. Using glycerol increases how much of the biomass waste can be converted to liquid product compared to the commonly used water process, known as hydrothermal liquefaction. More than 90% of pine needle mass is converted in the presence of glycerol compared to only 60% with water. The benefits of this research are huge. It can help reduce carbon emissions by decreasing dependence on imported artificial Christmas trees and limiting the amount of biomass sent to landfill. If commercially feasible, this could make industrial processes more sustainable by creating new products from something that was previously considered waste. Long after the festive period is over we could continue using this method to recycle forest and agricultural waste on a much larger scale, bringing greater benefits throughout the year."
"The prime minister, Scott Morrison, faces a fresh internal row over climate change policy, with MPs clashing over the issue in the first Coalition party room meeting of the year. After Morrison declared at the National Press Club last week that the government needed to focus on “practical” climate change action with a focus on mitigation and resilience, MPs debated how the government should reposition its policy response.  The debate followed a spill in the Nationals partyroom on Tuesday morning in which former leader Barnaby Joyce failed to topple Michael McCormack after arguing the government should do more to support coal-fired power and warning the party was at risk of losing its voice within the Coalition. In the party room meeting, Joyce also argued against “reactionary” climate policies in response to the bushfire crisis, accusing people of using the tragedy to push the “hobby horse” of climate action. He was backed by NSW National MP David Gillespie who suggested the party’s constituents did not want more action on climate policy, and it was not an issue being raised by voters. But several MPs spoke in favour of more ambitious climate action. The Liberal MP for the seat of Higgins, Katie Allen, expressed support for the “ultimate ambition of carbon neutrality” and an embrace of renewable technology to achieve that goal. Allen’s call for more action was backed by the North Sydney MP Trent Zimmerman, the member for Reid, Fiona Martin, and the Goldstein MP, Tim Wilson, who all supported the embrace of new renewable technologies to cut emissions. Sources say Wilson and Zimmerman also spoke in favour of nuclear power, commending MP Ted O’Brien for his parliamentary inquiry into the issue, which was tabled in December, and advocating for it to be further explored. Zimmerman spoke about the need to do more to address voter concern in seats such as his, pointing to the loss of the Liberal-held seat of Warringah to independent Zali Steggall at the election to highlight the strength of feeling on the issue. He is understood to have argued that the Coalition was not just a coalition of parties, but a coalition of seats with divergent views on the vexed policy matter, and that these different views needed to be respected. In response, the Queensland Nationals MP George Christensen argued his colleagues were sounding like the Greens, and the government was only in power because it won seats in Queensland based on its support for the coal sector and for its support for a new coal-fired power station in the state. This claim was rejected by some MPs. But Christensen’s view was also expressed by Matt Canavan, who addressed the party room after resigning his position from cabinet, telling colleagues the party had become the party for workers. “We have become the party of workers, workers in coalmines, workers in shipyards and workers in factories,” Canavan said. “We represent those people by fighting for their jobs, and defending their jobs.” Canavan is now calling for new coal-fired power stations to be built across the country. In an earlier meeting of just Liberal MPs, Queenslander Andrew Laming slapped down colleagues for publicly denying the science of climate change, saying it was akin to doubting “the science of the planes you fly on” coming to Canberra. He argued that while the party’s MPs should debate the policy response, it was an “impossible position” to be debating science that already underpinned the government’s emission reduction targets. The NSW senator Jim Molan was criticised for saying on ABC’s Q&A program on Monday night that climate change may not be caused by humans and declaring he was “not relying on evidence” for his climate position. Conservative Craig Kelly also came under fire for telling the BBC there was no link between Australia’s bushfire crisis and climate change. Speaking after Tuesday’s meeting, Wilson argued that most MPs agreed with Morrison that the government needed to “evolve” its policies to create the jobs of the 21st century. “We are progressively going to be cutting emissions over the cycle, and that is where most MPs are, which is taking a pragmatic, sensible approach that takes the whole of the Australian community with us,” Wilson told the ABC. Addressing the party room, Morrison urged both the Nationals and Liberals to work together, saying the Coalition had a strong track record of delivering for Australians. “We come to this joint Coalition party room to do things together,” Morrison said. Morrison faces a difficult task to reposition the Coalition on climate change after assuring voters that it wanted to “evolve” its policies and do more to reduce emissions. In January the issue was also discussed in cabinet, where Morrison’s senior ministers agreed not to bolster the government’s current emissions reduction target of 26-28% of 2005 levels by 2030. Speaking in parliament on Tuesday on the government’s response to the summer bushfires, Morrison said there was a need to “heed the lessons” of a natural disaster of such magnitude. “These fires have been fuelled by one of the worst droughts on record, changing in our climate and a build-up in fuel amongst other factors,” he said. “Our summers are getting longer, drier and hotter, that’s what climate change does, and that requires a new responsiveness, resilience and a reinvigorated focus on adaptation.”"
"
Share this...FacebookTwitterGünther Aigner released a German video with the title “Die Alpengletscher im Klimawandel: Status quo“ (The Alps glaciers in climate change: status quo).
Hat-tip: Die kalte Sonne
Today global warming alarmists insist blaming climate change on man-made CO2 emissions. Yet, everywhere we look it’s difficult to find any correlation between CO2 and warming. Pre-industrial history shows that changes in CO2 in fact followed temperature changes.
Today we look at some climate charts of the European upper Ostalpen to look for hints what may be behind the warming since the late 20th century. We know glaciers there have been receding over the recent decades.
First is a mean temperature chart of the region for the May to September period going back 133 years:

Chart cropped from video “Die Alpengletscher im Klimawandel: Status quo“, by Günther Aigner
Plotted are data from the Austrian ZAMG and the Swiss MeteoSchwiez, 5-year smoothed (green) and the linear trend (black). Clearly there’s been a long-term warming., but the vast share of the warming occurred since the late 1970s, after a 30-year period of cooling (since the early 1940s).
What could have happened since the early 1980s?
Of course CO2 emissions rose since 1980, and summer temperatures high in the Ostalpen rose. But is there something else?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




One thing that could cause summertime temperatures to rise and glaciers to melt is sunshine. So Aigner plotted the number of sunshine hours for the May-September period for each year and produced the following chart:

Source: Cropped from video “Die Alpengletscher im Klimawandel: Status quo“, by Günther Aigner
As the above chart shows, the sun has shined considerably more over the recent decades than it used to in the 1970s, or late 19th century. Today the region sees about a whopping 200 hours more sunshine than 120 years ago! More sunshine would mean more warmth.
The plot of sunshine hours indeed looks awfully similar to the plot depicting mean temperatures.
Aigner in the video then superimposed to two plots going back 50 years. Here’s how they compare:

Number of sunshine hours (orange) compared to the mean temperature in degrees Celsius (red). Each curve is 10-year smoothed. Source: Cropped from video “Die Alpengletscher im Klimawandel: Status quo“, by Günther Aigner
The region receives over 100 hours of sunshine more today on average than it did 40 years ago. It shouldn’t be a surprise that the Alps have warmed and glaciers receded.
The real question is why is the region less cloudy today?


		jQuery(document).ready(function(){
			jQuery('#dd_cf0de1bdc5883a7b54f7c33f21051906').on('change', function() {
			  jQuery('#amount_cf0de1bdc5883a7b54f7c33f21051906').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"
I just finished a 150+ mile round trip from Boulder to get Dillon, CO and Cheesman Reservoir USHCN sites in addition to the Boulder NIST/NOAA site.
Cheesman had recently been flooded due to heavy runof from forest fire, the roads were mudpits, and even with 4WD I rented couldn’t get there before sunset. So gave up and returned to hotel at DIA for flight out tomorrow.
Had Vietnamese food with Pielke’s group last night, and that didn’t help my day either. I’m pretty toasted. But it was a heckofa good day even so.
So I’m signing off for a couple days for travel back home and some R&R.
The good news; While driving back on US285 I had another citizen science project idea to disprove Parker’s  2004 and 2006 papers essentially saying “UHI is minimal or doesn’t exist”, which I believe is unsupportable. I think it will work. Got to mull it over. Check back in a day or two.  Pictures and presentation coming when I get back to normal schedule.
Anthony out


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea40bc5a3',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

Until now, most of the surface temperature measurement stations I’ve highlighted as substandard locations for measuring temperature accurately have been in the USA. Today, courtesy of Geoff Sherrington, we are treated to the sight of the main Australian historic site, Melbourne metropolitan, near LaTrobe St, Melbourne. He reports it has max-min temp records daily since 1855 to late 2007.
Yet look at the pictures, this station is only 2 meters from a sidewalk, and a couple of meters more from a major street intersection and voluminous traffic. Hardly the best place to measure temperature. This site demonstrates the growing trend of climate monitoring stations that have been gradually surrounded by increasingly closer urban influences, and demonstrates that the problem is not unique to the USA.
Here are some additional pictures, click for large versions.


And a satellite image of downtown Melbourne showing the intersection is available at Windows Live Maps
UPDATE: Kristen Brynes has offered a couple of photos she had available taken from different angles of the same site, see them below. Thanks Kristen.


Additionally, the Lat/Lon of this station is:
-37.8075, 144.9700
A PDF document from Australias BOM lists the METADATA for this site and is available here


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea334d832',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"A “sustainability charge” on meat to cover its environmental damage could raise billions to help farmers and consumers produce and eat better food, according to a report. The levy, which would increase the price of a steak by about 25%, would be phased in over the next decade. The report focuses on EU countries and was produced for the Tapp Coalition of health, environment and animal welfare organisations. It says “fair pricing” for meat should be included in the forthcoming European “green new deal” and so-called farm to fork strategy.  The report, produced by environmental research group CE Delft, analysed the costs of greenhouse gas emissions, other air and water pollution, and losses of wildlife associated with livestock production. It estimated that covering these costs would increase the price of beef by €0.47 (40p) per 100g. This would increase the cost of a 227g supermarket steak in the UK by about 25%. The levy on pork and chicken would be lower owing to their smaller environmental impact, at €0.36 (31p)/100g and €0.17 (14p)/100g respectively. The report suggests such charges could reduce consumption of beef in the EU by 67%, pork by 57% and chicken by 30% by 2030. As well as reducing emissions by 120m tonnes a year, the charges would raise €32bn a year for EU member states, according to the report. The Tapp Coalition said about half of this should be given to help farmers move their production away from meat, which could increase individual farm incomes by thousands of euros per year. The rest should be used to reduce the cost of fruit and vegetables, support poorer families and help developing countries deal with the climate crisis. Jeroom Remmers, a Tapp Coalition director, said: “Europeans eat roughly 50% more meat than is recommended in dietary health guidelines. [So] we could also save billions of euros every year in lower healthcare costs.” In November, three European health associations wrote to Frans Timmermans, the senior European commissioner leading the green new deal initiative. They said: “Numerous studies in recent years have shown that a shift to healthy, more plant-rich diets can deliver important health, environmental and economic benefits.” A carbon tax on high-impact food is also backed by a second report, from the Behavioural Insights Team (Bit), a social purpose company part-owned by the UK government. It further suggests making plant-based food the default choice at catered events or on flights. Recent research has shown that a huge reduction in meat-eating in rich nations is essential to tackle the climate emergency. Other work indicates that avoiding meat and dairy products is the single biggest way to reduce your environmental impact on the planet. “Including the environmental cost of animal protein in the price is a crucial element of meeting EU targets for climate, biodiversity, public health, and animal welfare,” said Prof Pier Vellinga at Wageningen University in the Netherlands and chair of the Tapp Coalition. The report from Bit, also known as the “nudge unit” set up by David Cameron in 2010, examines how governments, the food industry and campaign groups can help shift diets away from meat. As well as supporting a carbon tax on high-impact food, it says governments could lead by example, by “removing or reducing unsustainable foods from public canteens in hospitals, schools and government offices”. It also says practical cooking skills could be taught in schools and colleges. Food companies could make plant-based products the default choice, for example at catered events or on flights, the Bit report said. It also suggested marketing plant-based food as “delicious, normal, and satisfying, not as light, abstemious, or overtly healthy or vegetarian”. Another proposal is placing veggie burgers alongside their meat counterparts instead of separating them on menus or in supermarket aisles. The report said campaign groups could reduce the perceived complexity of sustainable eating by promoting clear rules of thumb, such as “red meat’s a treat”. Toby Park, the head of energy and sustainability at Bit, said: “Governments, industry and consumers around the world are more aware than ever of the need to live within our planet’s means. “While some of the solutions will come from technical advancements, there is huge potential and need to reduce our environmental impacts with some simple behaviour changes.” In the UK, the National Farmers’ Union says agriculture can become climate neutral by 2040 without cutting beef production. Instead, it says three-quarters of farming emissions can be offset by growing fuel for power stations and then capturing and burying the carbon dioxide."
"

 _Global Science Report_ _is a feature from the_ _Center for the Study of Science_ _, where we highlight one or two important new items in the scientific literature or the popular media. For broader and more technical perspectives, consult our monthly “Current Wisdom.”_   




The figure below is a portion of a screen capture from the “Heat-Related Deaths” section of the EPA’s new “Climate Change Indicators” website. It is labeled “Deaths Classified as ‘Heat-Related’ in the United States, 1979–2010.”   
  
We don’t know anyone who could look at this chart and not be left with the strong impression that heat-related deaths in the United States are on the rise—apparently confirming the president’s concern about climate change and underscoring his desire to do something about it.   






  
  
But notice the asterisk at the bottom of the box. Here's the text associated with it:   




Between 1998 and 1999, the World Health Organization revised the international codes used to classify causes of death. As a result, data from earlier than 1999 cannot easily be compared with data from 1999 and later.



In other words, you shouldn’t plot pre- and post-1999 data on the same chart because the data are not comparable, lest you mislead the uninitiated reader. The EPA ignores its own warning and instead plots the two sets of not-easily-compared data side by side on the same chart, ensuring that they are compared!   
  
Such an analysis would probably grade out as an F in an undergraduate paper, but perhaps the EPA is suffering from a bit of “Noble Cause Corruption.” After all, they are trying to save us from certain death.   
  
The proper way to view the EPA chart is to put your hand over the data points on the right-hand side of the chart (1999 and onwards) and then over the data points on the left-hand side of the chart (pre-1999 data). In doing so, you’ll see that during both periods the rate of heat-related mortality does not rise.   
  
For those who want a clearer image of the truth when it comes to the effect of global warming on trends in heat-related mortality across the United States, see the figure below, taken from a brand new study by Jennifer Bobb from the Harvard School for Public Health and colleagues. The graph shows the number of heat-related deaths (for every thousand overall deaths) that result from the daily temperature being 10°F above normal, from 1987 to 2005. The trend is strongly downward—in other words, fewer deaths are associated with heat.   






_Temporal trends, from 1987 to 2005, in the excess number of deaths (per 1,000 deaths) attributable to each 10°F increase in the same day’s summer temperature, nationally in the United States (excerpted from Bobb et al., 2014)._   
  
Or as Bobb and colleagues put it:   




This study provides strong evidence that acute (e.g., same-day) heat-related mortality risk has declined over time in the US, even in more recent years. This evidence complements findings from US studies using earlier data from the 1960s through mid-1990s on community-specific mortality rates, as well as European studies that found temporal declines in heat-related mortality risk, and supports the hypothesis that the population is continually adapting to heat. [citations removed]



Not only is the risk from extreme heat declining, but so too are the actual numbers of people dying from extreme heat both in the United States and abroad (when properly standardized for demographic changes and population growth).   
  
This is opposite from what the EPA chart leads you to believe.   
  
The only way for the EPA to be so out of touch with the prevailing science is to be so on purpose.   
  
We can’t help but to think that purpose will be revealed today.   
  
**Reference:**   
  
Bobb, J.F., R.D. Peng, M.L. Bell, and F. Dominici, 2014. Heat-related mortality and adaptation in the United States, _Environmental Health Perspectives_ , http://dx.doi.org/10.1289/ehp.1307392


"
"Americans elected Donald Trump, who insisted climate change was a hoax – so it’s no surprise that since taking office he’s been all-in for the fossil fuel industry. There’s no sense despairing; the energy is better spent fighting to remove him from office. Canada, on the other hand, elected a government that believes the climate crisis is real and dangerous – and with good reason, since the nation’s Arctic territories give it a front-row seat to the fastest warming on Earth. Yet the country’s leaders seem likely in the next few weeks to approve a vast new tar sands mine which will pour carbon into the atmosphere through the 2060s. They know – yet they can’t bring themselves to act on the knowledge. Now that is cause for despair.  The Teck mine would be the biggest tar sands mine yet: 113 square miles of petroleum mining, located just 16 miles from the border of Wood Buffalo national park. A federal panel approved the mine despite conceding that it would likely be harmful to the environment and to the land culture of Indigenous people. These giant tar sands mines (easily visible on Google Earth) are already among the biggest scars humans have ever carved on the planet’s surface. But Canadian authorities ruled that the mine was nonetheless in the “public interest”. Here’s how Justin Trudeau, recently re-elected as Canada’s prime minister, put it in a speech to cheering Texas oilmen a couple of years ago: “No country would find 173 billion barrels of oil in the ground and leave them there.” That is to say, Canada, which is 0.5% of the planet’s population, plans to use up nearly a third of the planet’s remaining carbon budget. Ottawa hides all this behind a series of pledges about “net-zero emissions by 2050” and so on, but they are empty promises. In the here-and-now they can’t rein themselves in. There’s oil in the ground and it must come out. This is painfully hard to watch because it comes as the planet has supposedly reached a turning point. A series of remarkable young people (including Canadians such as Autumn Peltier) have captured the imagination of people around the world; scientists have issued ever sterner warnings; and the images of climate destruction show up in every newspaper. Canadians can see the Australian blazes on television; they should bring back memories of the devastating forest fires that forced the evacuation of Fort McMurray, in the heart of the tar sands complex, less than four years ago. The only rational response would be to immediately stop the expansion of new fossil fuel projects. It’s true that we can’t get off oil and gas immediately; for the moment, oil wells continue to pump. But the Teck Frontier proposal is predicated on the idea that we’ll still need vast quantities of oil in 2066, when Greta Thunberg is about to hit retirement age. If an alcoholic assured you he was taking his condition very seriously, but also laying in a 40-year store of bourbon, you’d be entitled to doubt his sincerity, or at least to note his confusion. Oil has addled the Canadian ability to do basic math: more does not equal less, and 2066 is not any time soon. An emergency means you act now. In fairness, Canada has company here. For every territory making a sincere effort to kick fossil fuels (California, Scotland) there are other capitals just as paralyzed as Ottawa. Australia’s fires creep ever closer to the seat of government in Canberra, yet the prime minister, Scott Morrison, can’t seem to imagine any future for his nation other than mining more coal. Australia and Canada are both rich nations, their people highly educated, but they seem unable to control the zombie momentum of fossil fuels. There’s obviously something hideous about watching the Trumps and the Putins of the world gleefully shred our future. But it’s disturbing in a different way to watch leaders pretend to care – a kind of gaslighting that can reduce you to numb nihilism. Trudeau, for all his charms, doesn’t get to have it both ways: if you can’t bring yourself to stop a brand-new tar sands mine then you’re not a climate leader. Bill McKibben is an author and Schumann distinguished scholar in environmental studies at Middlebury College, Vermont. His most recent book is Falter: Has the Human Game Begun to Play Itself Out?"
"

No doubt about it, it’s been a good month for tornadoes even by the “spinny” standards of May, when most twisters occur. Even more predictable than the development of severe storms in spring, however, is the phenomenon of people trying to tie such bad weather to global warming. Witness Tom Toles’s cartoon in the May 7 Washington Post, which intoned, “These superpowerful tornadoes are the kind of storm we’re likely to see more of with global climate change.” Who’d he get that from, Al Gore?



It has become Standard Operating Procedure in climate change hype to never bother with inconvenient facts. Tons of tornado data are only a few mouse‐​clicks away. And they show that Toles was dead wrong in his implication that the recent storms show any link to the slight warming of the atmosphere that has occurred in recent decades. In fact, just the opposite may be occurring despite a perception of increased storminess.



Two interesting facts: The number of reported tornadoes has increased for decades while the number of deaths has dropped.



What’s going on is called “radar.” Thanks to an awful 1953 tornado in Worcester, Massachusetts (far from the Oklahoma and Texas “tornado alley”), the Weather Bureau (today’s National Weather Service) went on a crash program to develop a national network of weather radar. Spearheaded by David Atlas and Ted Fujita (whose “F‐​scale” rates tornado severity on a 1–5 basis, as is done for hurricanes), meteorologists soon learned that when the radar paints a thunderstorm that looks more like a comma than a blob, there’s often a tornado buried in the curliest point.



It took several years for the original radars, known as WSR-57’s, to cover the country. But by 1970 the job was nearly complete. As more radars came online, more and more tornadoes were reported. It’s interesting that as this network stabilized, from 1970 through 1990, so did the number or tornadoes.



Beginning in 1988, a new network began to take shape that was even better at detecting potential twisters. Instead of painting a picture of a thunderstorm, the new machines, called Doppler radars and designated as WSD-88’s, actually measure the change in a storm’s velocity by tracking the movement of raindrops. When those drops start to rotate, it’s not long before there’s a tornado warning. The rotation fields often develop before the comma shape, which means more tornado warnings. This gets people’s attention, and saves more and more lives. Not surprisingly, the number of tornadoes increased again, in the 1990’s this time proportional to the number of WSD-88’s, which now blanket the nation. By the beginning of this century, with the new network now in place, the number has stabilized again.



Any reporter (or cartoonist) doing his homework might have asked if indeed the number of big storms (categories 3–5 on the Fujita scale) is increasing. The fact is that the vast majority of tornadoes are in the “weenier” classes. Only about 5 percent reach category 3 or higher. (The severity data is at  http://​www​.spc​.noaa​.gov/​a​r​c​h​i​v​e​/​t​o​r​n​a​does/. Click on, graph it up, and you’ll see that the number of severe tornadoes is dropping.)



Where does the notion that tornadoes must increase because of global warming come from? Another panel in the Post’s cartoon reads: “With energy added to the atmosphere, more frequent and intense storms are a probable outcome.”



Perhaps a refresher course in high school earth science might be in order here. Tornadoes occur because a portion of a normally quiescent thunderstorm begins to spin. That spinning is done in large part by a dip in the strong westerly winds (“jet stream” in common parlance) that sometimes penetrates the U.S. when thunderstorms are common. The jet stream is the result of the temperature contrast between the poles and the tropics. Global warming reduces this contrast (warming the poles much more than the tropics) and reduces the spin. That means fewer tornadoes, not more.



Obviously, it’s a lot hotter in June, July, and August than it is in the peak of the tornado season in May. So much for the hot‐​air‐​tornado link. And why are there so many tornadoes in Mississippi in February? 



Rather, the key ingredient that spins garden‐​variety thunderstorms into killer tornadoes, the jet stream, is missing during the hottest part of the year, having migrated north to Canada for the summer. Warm it up and the migration will start earlier, it will move further north.



That may explain why the number of severe tornadoes is declining. They may be running out of spin, unlike stories attempting to relate these destructive storms to global climate change. 
"
"Some 12m hectares of the UK is currently covered by agricultural grasslands which support a national lamb and beef industry worth approximately £3.7 billion. However, proposals have been made that this landscape should undergo radical changes to aid the country’s climate change commitments. A controversial government advisory report recently produced by the independent Committee on Climate Change calls for UK lamb and beef production to be reduced by up to 50%. It claims that by replacing grazing land with forestry the UK will be able to substantially decrease its greenhouse gas (GHG) emissions. The National Farmers Union has responded to the report stating that it has no plans to reduce livestock numbers. Lamb and beef production is an important part of the UK’s cultural heritage, and is vital for supporting rural communities. The lamb and beef industry also provides the country with a supply of high-welfare locally sourced meat. In fact, the UK is the top lamb producer and the third largest beef producer in the EU. And in 2016, the UK was 76% self-sufficient in terms of its own food production. But lamb and beef production is also the greatest contributor to agricultural GHG emissions – the CCC report states that, in 2016, lamb, beef and dairy production combined contributed to around 58% of UK agricultural emissions.  Sheep and cattle grazing is also an integral part of how upland landscapes are currently managed. This is particularly true for Scotland, where managing the upland landscape is important for supporting other industries, such as game bird production. These upland systems have great potential for afforestation – the planting of trees in previously unforested areas – though this doesn’t necessarily have to result in a decrease in livestock numbers.  Planting trees is a crucial step in the fight against climate change. Trees act as a carbon sink for CO2 and also provide a source of different biofuels products. Previous planting schemes have seen success, for example, between 1990 and 2010 the area of the UK covered by woodland increased from 2.6 to 2.8 million hectares. But grazing land need not be taken away for the sake of this environmental initiative. Afforestation plans can be sensitive to the aforementioned socioeconomic and cultural factors if a balanced approach is taken. So what can be done? Agroforestry might be a way to meet the Committee on Climate Change’s recommendation to release between three to seven million hectares of grassland for afforestation without affecting the UK’s food supply.  Under agroforestry schemes, new woodlands are grown and existing trees are cultivated on farmlands. The aim is to optimise farming systems by incorporating woodland into them rather than replacing grazing land with trees. Planting trees and hedgerows improves grass growth, protects against flooding and topsoil erosion, increases farmland biodiversity and provides a source of natural shelter for livestock. And if the trees are used for biofuel or timber they can provide additional farm income.  Agroforestry schemes can improve animal welfare too. The 2018 lambing season resulted in an unprecedented lamb mortality rate. But it has been shown that, by providing a source of natural shelter, lamb mortality rates can be reduced by up to 50% during inclement weather. Projects like this are already in place, for example the Welsh government’s Glastir scheme. Launched in 2012, this pan-Wales sustainable land management scheme rewards farmers financially for adhering to environmental guidelines. Though it must be noted that while Glastir has proven more effective than previous agri-environmental schemes, it has been criticised for its lack of measureable outcomes and its limited uptake by Welsh farmers. With Brexit looming, now is the perfect time for agricultural reform as the country revisits current land use policies. As an industry that is currently so reliant on EU subsidies, there is a strong incentive to optimise production methods. Government discussions are already well under way over how to bring together the agriculture and forestry sectors in order to better manage pastoral landscapes. If agroforestry is incorporated in to these new agricultural policies and subsidy schemes there will be huge benefits for farmers, conservationists, the general public and the livestock they rely on."
nan
"
Share this...FacebookTwitterFrom about 80,000 to 20,000 years ago, Greenland temperatures abruptly warmed by about 10°C in just a few decades on at least 20 occasions. And then, about 870 to 1,500 years later, CO2 rose. 
Li and Born (2019) document 8-16°C climate warmings (Dansgaard-Oeschger events) in Greenland that extended to both hemispheres between about 80 and 20 thousand years ago. (Though global in scope, temperature changes were less pronounced outside Greenland.)
These abrupt warmings occurred within decades (or less). It has been suggested the warm-ups may have required no external forcing, as they’re considered an “unforced oscillation”.

Image Source: Li and Born (2019)
A new study (Shin et al., 2020) suggests the about 1,000 years after these warming events occurred, CO2 concentrations rose.
Despite the millennial-scale duration of this lag relative to the decadal-scale temperature changes, there are many who believe CO2 changes are a driver of warming.
“However, the CO2 decrease did not always start at exactly the same time as the onset of the DO warming, and the lag itself varied. For example, during Marine Isotope Stage (MIS) 3, atmospheric CO2 maxima lagged behind abrupt temperature change in Greenland by 870±90 yrs. During MIS 5, the lag of atmospheric CO2 maxima with respect to abrupt temperature warming in the NH was only about 250±190 yrs (Bereiter et al., 2012). … During MIS 6d which corresponds to CDM 6d.1 and 6d.2, CO2 concentrations show a much slower increase over a duration of ~3.3 kyr. Here, CO2 lags behind the onset of the NH abrupt warming by 1,500±280 yrs and 1,300±450 yrs, respectively (1,400± 375 yrs on average).”

Image Source: Shin et al., 2020
Share this...FacebookTwitter "
"

There is a lot not to like about the Quadrennial Defense Review, which comes out today (the _National Journal_ posted a leaked copy Friday). Like past QDRs, this one uses vague, trendy ideas about international relations to inflate threats and justify our massive defense budget. As usual, we hear the evidence‐​free claims that non‐​state actors are getting more powerful and that the world is getting more complex and unpredictable (“change continues to accelerate”). I believe that states are hanging onto or even gaining power relative to other sorts of social organizations and that the world is no less predictable than it was in 1900 or 1950. The QDR also says that climate change is a national security problem. That’s a popular line, which as near as I can tell is a marketing gimmick. Then there the usual tripe about how great our alliances are, how strategic every country with a Marine in it is, how terrific interagency cooperation is, and so forth.   
  
  
The good news is that it doesn’t really matter. Newspapers confuse the QDR with law, but it is closer to PR. It’s like a particularly important speech. It sells what Secretary of Defense is selling and justifies what the Department of Defense does. Because it comes in part from agencies it is supposed to guide, it rationalizes rather than leads. Because it is largely a consensus document, it says only what half of the Pentagon can agree on—various strains of mush. Can anyone explain what past QDR’s have accomplished? I think nothing. Sure, there are interesting tidbits about forces structure plans, but these are in the budget documents too. At best it causes DoD to justify itself, giving us analysts something to argue about.   
  
  
The administration’s proposed defense budget, also being released today, matters much more to policy. It reveals more about the nation’s defense strategy than the vacuous documents that purport to do so.   
  
  
Policy types love strategy documents because they are mostly technocratic idealists. They want government polices to be made by rational processes that reveal national interests, which are then laid out in plans like the QDR. They want policy to be like science. But democratic government is the push and pull of competing ideologies and interests. Public plans or strategies are part of that process. Congress should thank DoD for these mind‐​numbing 120 pages, throw them away, and focus on the budget.
"
"

_Global Science Report_ _is a feature from the_ _Center for the Study of Science_ _, where we highlight one or two important new items in the scientific literature or the popular media. For broader and more technical perspectives, consult our monthly “Current Wisdom.”_   
  
Global warming buffs have been fond of claiming that the roaring winds of Typhoon Haiyan were the highest ever measured in a landfalling tropical cyclone, and that therefore (?) this is a result of climate change. In reality, it’s unclear whether or not it holds the modern record for the strongest surface wind at landfall.   
  
This won’t be known until there is a thorough examination of its debris field.   
  
The storm of record is 1969 Hurricane Camille, which I rode out in an oceanfront laboratory about 25 miles east of the eye. There’s a variety of evidence arguing that Camille is going to be able to retain her crown.   
  
The lowest pressure in Haiyan was 895 millibars, or 26.42 inches of mercury. To give an idea, the needle on your grandmonther’s dial barometer would have to turn two complete counterclockwise circles to get there. While there have been four storms in the Atlantic in the modern era that have been as strong or a bit stronger, the western Pacific sees one of these approximately every two years or so.   
  
Camille’s lowest pressure was a bit higher, at 905 mb (26.72 inches). At first blush it would therefore seem Haiyan would win the blowhard award hands down, but Hayian had a very large eye around which its winds swirled, while Camille’s was one of the smallest ever measured. At times in its brief life, Camille’s was so small that the hurricane hunter aircraft could not safely complete a 360 degree turn without brushing through the devastating innermost cloud band, something you just don’t want to be near in a turning aircraft. In fact, the last aircraft to get into Camille, which measured 190mph sustained winds, lost an engine in the severe turbulence and fortunately was able to limp home.   
  
Haiyan’s estimated 195mph winds were derived from satellite data, rather than being directly sensed by an aircraft. But winds over the open ocean are always greater than those at landfall because of friction, and the five mph difference between the two storms is physically meaningless. 



The chance that an onshore anemometer (wind-speed and direction sensor) will survive such a storm isn’t very high, so the winds are inferred by scientists and engineers from the texture and distribution of what’s left behind.   
  
Every year, our National Hurricane Center summarizes the Atlantic hurricane season in painstaking detail in article published in the prestigious journal _Monthly Weather Review_. Describing Camille’s destruction, it said:   




Maximum winds near the coastline could not be measured, but from an appraisal of splintering of structures within a few hundred yards of the coast, velocities probably approached 175 k[nots]. 



That’s 201 mph.(Higher winds have been measured on small islands. With Haiyan and Camille, we are talking about storms running into large landmasses, where friction takes place.)   
  
Camille killed 143 along the Gulf Coast, while Haiyan’s toll is currently estimated to be more than 2,500.   
  
The difference, which is more than an order of magnitude, is largely (but not completely) due to poverty. Despite experiencing roughly five landfalling tropical cyclones per year, Philippine infrastructure simply isn’t as sound as it is in wealthier countries. As a grim example, a number of Haiyan’s casualties actually occurred in government-designated shelters that collapsed in the roaring eyewall.   
  
In addition, the transportation infrastructure simply couldn’t handle a mass evacuation. If a similar situation applied to the U.S. Gulf Coast, Camille would have killed thousands at landfall, a fact noted in the Hurricane Center’s report on the 1969 season. Where Haiyan hit in the Philippines, there simply weren’t any roads capable of evacuating the citizens of Tacloban City safely inland, forcing them to ride it out dangerously close to the invading ocean and exposed to winds that pulverized most structures.   
  
So, while we really don’t know which storm had higher winds, we do know that more affluent societies are much less affected by even the strongest storms. As Indur Goklany, (who writes frequently for Cato) has pointed out, if left to develop, the entire world will be much more resilient to climate change than it would be if the ineffective policies to “stop” it slowed economic growth.


"
nan
"
Share this...FacebookTwitterAs recently as 2000 to 1000 years ago, spanning the Roman to Medieval Warm Periods, East Antarctica was 5-6°C warmer than it is today. The consequent ice melt resulted in >60 meters higher water levels in East Antarctica’s lakes.
East Antarctica has been rapidly cooling in recent decades, with magnitudes reaching -0.7°C to -2.0°C per decade since the mid-1980s (Obryk et al., 2020).

Image Source: Obryk et al., 2020
A new study (Myers et al., 2020) reports that until about 15,000 years ago and throughout the Last Glacial Maximum, East Antarctica was 4-9°C colder than it is today.
Antarctica then abruptly warmed 15°C within centuries. From 12,000 to 6,000 years before present, East Antarctica was about 5°C warmer than it is today.

Image Source: Myers et al., 2020
And then as recently as 2,000 to 1,000 years ago, East Antarctica was so warm (~6°C warmer than present) that its lakes were filled with 60 to 80 meters more meltwater than exists in lake basins today.
“Resistivity data suggests that active permafrost formation has been ongoing since the onset of lake drainage, and that as recently as 1,000 – 1,500 yr BP, lake levels were over 60 m higher than present. This coincides with a warmer than modern paleoclimate throughout the Holocene inferred by the nearby Taylor Dome ice core record. …  Stable isotope records from Taylor Dome (located roughly 100 km west of the MDVs) indicate mean annual air temperatures ca. 4-9 °C lower than modern during the LGM (Steig et al., 2000).”
“Between 12,000–6,000 yr BP, Taylor Dome ice core record indicates that regional temperatures were up to 5 °C warmer than modern conditions (Fig. 2) (Steig et al., 2000).”
“Permafrost age calculations indicate late Holocene lake level high-stands (up to ~81 masl, 63 m higher than modern Lake Fryxell) roughly 1.5 to 1 ka BP that would have filled both Lake Fryxell and Lake Hoare basins (Fig. 3b). …  Taylor Dome ice core records show a highly variable Holocene, with short lived peaks up to + 6 °C above modern temperatures between 1-2 ka BP (Steig et al., 2000).”
“Lake levels were higher potentially during and after the LGM when an ice dam blocked the mouth of TV, allowing for lake levels to increase by over 280 m compared to modern level. Taylor Dome ice core records indicate an abrupt warming of >15 °C from 15 – 12 ka BP, (Steig et al., 2000), which may have coincided with the maximum lake level of GLW.”
“Short lived changes in temperature such as a 6 °C increase in the late Holocene could have resulted in anywhere between 60 to 80 m of lake level rise and subsequent drawdown.”
This substantial regional warmth can also be verified by the 1,000-year-old elephant seal remains that document a time when Antarctica was sea ice free 2,400 kilometers south of where sea ice free conditions occur today (Koch et al., 2019). Elephant seals require sea ice free conditions to breed, and the same locations where they used to breed during the Medieval Warm Period are today buried in sea ice.

Image Source: Koch et al., 2019


		jQuery(document).ready(function(){
			jQuery('#dd_9e221820cc7def01ad3e9985c5250b19').on('change', function() {
			  jQuery('#amount_9e221820cc7def01ad3e9985c5250b19').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"Christmas songs are in the air and supermarket aisles are fit to burst – the festive season is upon us. But many may view the shiny, plastic-wrapped goods on the shelves through a different lens this year thanks to growing concern over plastic pollution.  Each year, the UK produces over 2.3m tonnes of plastic packaging and over 4.7m tonnes of paper and cardboard, with only 45% of plastic being recovered and recycled. Waste production peaks over the Christmas holidays, with a 30% increase in plastic use, such as packaging and plastic products, and Britons bin the equivalent of 108m rolls of wrapping paper. A survey last year found that 84% of consumers were worried about the amount of plastic packaging used on gifts at Christmas, with 22% of those surveyed stating there was too much waste generated by their households to recycle all of it and 37% confused about what can be recycled. It’s easy to forget the implications of plastic once our waste has been binned, but significant volumes of the plastic waste we generate this Christmas will remain in the environment for hundreds of years. However, the Plastics Collaboratory, a joint research effort by academics in different fields at the University of Hull, have come up with 12 ways you can reduce your plastic use this Christmas. Over one billion Christmas cards are sold every year in the UK, but many are not recycled. Cards are often embellished with plastic and glitter, which makes them non-recyclable. You can tear off parts that can’t be recycled, but making your own cards is much more cost effective, personal and fully recyclable. All you need is recycled plain card, ink stamps, crayons and your imagination. Although most plastic-based decorations are used over several years, many (such as tinsel) degrade over time, releasing plastic fragments. An alternative is to use string and natural materials, such as pine cones and fruit, which look good and reduce plastic at the same time. Plastic-based floral foam is often used as a backing to hold christmas wreaths together, which crumbles into small microplastics over time. Make sure you buy wreaths that include natural moss. Or, you can make your own wreath, which can be used for years, using natural materials. You’d have to use an artificial plastic tree for over ten years to reduce the carbon footprint to that of a real tree. But the best option of all is to buy a potted tree which you can plant out and re-pot every year. In the UK, consumers buy an estimated 370m mince pies over the holidays yet consume only 80% of them – 74m go uneaten! Around 62m plastic trays are needed to hold all the pies that are sold. The best solution is to make your own. Secret Santa is a great tradition, but often results in people trying to buy silly gifts that are cheap and tacky and often made of plastic that is quickly thrown away. A nice alternative could be a refillable gift stored in a glass jar, such as hot chocolate or pancake mix. Enough wrapping paper to wrap around the equator nine times is sold each year in the UK. Unfortunately, much of this paper contains glitter and plastic films which make them non-recyclable. You can test this using the scrunch test – if the paper has no glitter on it and scrunches up you can recycle it. But an easier alternative is making and decorating your own, with recycled brown paper and string, which is fully recyclable. “Reindeer food” has become a popular craft activity for families at Christmas, often made from porridge oats and glitter that is spread in the garden for Santa’s reindeers. Glitter is technically a microplastic and cannot be recycled, but there are natural alternatives such as the mineral mica which has the same effect without the environmental impact. Gone are the days of the small fabric stockings that dangle at the end of the bed. Now it’s all about huge synthetic stockings that brim with presents and flashing lights. By using felt, old pillow cases or even old socks you can recreate your own plastic-free personal stockings which children will cherish for years to come. The majority of Christmas crackers are laden with teeny, tiny plastic gifts. With over 150m crackers  pulled each year, that’s a lot of plastic waste with a few hours of lifespan before the rubbish bin. Make your own crackers and fill them with homemade hats, dad jokes and tiny games such as bingo or origami frog racing for a fun and unique alternative. Christmas dinner comes with a huge amount of plastic packaging. Even when you attempt to be good and buy loose vegetables at the supermarket, most retailers still only have single use plastic bags to hand. Worry not – all you need is a lightweight material, such as an old pillow case and you can make your own veggie bags that you can use again and again. You have 12 months to get ready for next year. Instead of buying an advent calendar wrapped in plastic and with chocolate in plastic moulding, why not make your own? One design features 24 matchboxes filled with chocolate and wrapped in card."
"

In a recent speech to the Washington‐​based think tank Resources for the Future, EPA Administrator Gina McCarthy promoted the White House’s new Clean Power Plan by: (a) appealing to science and disallowing any debate about it; (b) making statements unsupported by the science; (c) praising the economic analysis behind the plan; and (d) announcing rules that economic analysis says won’t work and will cost too much.



In other words, it was business as usual in the world of climate policy.



She started her speech by saying that scientists are as sure that humans cause climate change as they are that smoking causes cancer, and “we are way past any further discussion or debate.…don’t debate about climate change any longer because it is our moral responsibility to act.”



From there she focused on the harms from extreme weather events, attributing the California drought to carbon dioxide emissions, as well as increased storms, wildfires and floods. She said anthropogenic climate change (i.e. global warming) leads to more extreme heat and, amazingly enough, more extreme cold. And she linked weather‐​related economic threats facing families and small businesses to anthropogenic climate change.



Now whatever you do, don’t question the science. For many years we have been told to rely exclusively on the UN Intergovernmental Panel on Climate Change (IPCC) for official truth on all climate topics. There are, of course, lots of reasons to mistrust the IPCC, including its past blunders, the conduct of its disgraced and discredited chair Rajendra Pachauri, and its clique‐​like report‐​writing process. But for now, let’s play the game and turn to the IPCC.





A growing body of economic analysis over the years has indicated that the models overstate the potential savings from energy efficiency programs.



In 2012 the IPCC published a Special Report on Extreme Weather (SREX), gathering up the available knowledge on storms, droughts, etc, and their possible connection to climate change generally and carbon dioxide emissions specifically.



Contrary to McCarthy’s claim, the SREX singled out the U.S. as a region where “droughts have become less frequent, less intense or shorter.” Worldwide there is only “limited to medium” regional evidence regarding changes in floods because the records are sparse and the effects are confounded with changes in land use and engineering. “Furthermore,” they said, “there is low agreement in this evidence, and thus overall low confidence at the global scale regarding even the sign of these changes.”



Does this sound like the level of confidence associated with the link between smoking and cancer?



Overall the IPCC’s attribution of a causal link between extreme weather and carbon dioxide emissions was the limpest possible: “There is evidence that some extremes have changed as a result of anthropogenic influences, including increases in atmospheric concentrations of greenhouse gases.” But, they went on, there is only low confidence in attribution of tropical cyclone activity to anthropogenic influences, and “Attribution of single extreme events to anthropogenic climate change is challenging” — UN speak for “we’d go further if we could but even we can’t torque the evidence that far.”



They also made it clear that economic vulnerability to weather is a function of a nation’s wealth, adding “Increasing exposure of people and economic assets has been the major cause of long‐​term increases in economic losses from weather‐ and climate‐​related disasters (high confidence). Long‐​term trends in economic disaster losses adjusted for wealth and population increases have not been attributed to climate change, but a role for climate change has not been excluded.”



Do doctors say “trends in lung cancer have not been attributed to cigarette smoking, but a role for tobacco has not been excluded”? Of course not. McCarthy’s invocation of scientific certainty and prohibition on further debate was mere demagoguery.



After boasting about the extensive research and consultation that went into the rule, McCarthy then said that it will reduce household utility costs, a prediction based on engineering studies behind the energy efficiency rules in the Clean Power Plan. But do these programs really save households money?



A growing body of economic analysis over the years has indicated that the models overstate the potential savings from energy efficiency programs. New evidence from a large‐​scale randomized field experiment has confirmed this. Conducted by a team of economists from Berkeley and MIT, the study tracked more than 30,000 households in the federal Weatherization Assistance Program. Participants in the program went through household energy audits using a government‐​approved engineering model to estimate the savings from undertaking a fully subsidized efficiency upgrade.



By comparing before‐ and after‐​data, and comparing against households that did not undergo weatherization, the authors showed that the engineering models were way off, exaggerating the energy savings 2.5-fold, with the result that the renovations cost twice the value of the subsequent energy savings. Even taking account of social and environmental benefits the rate of return on the program was about -9.5 percent annually, in other words the costs greatly exceeded the benefits.



The authors also found that the implicit cost of carbon dioxide emission reductions in the program were about $330 per tonne, roughly ten times the administration’s own estimate of the Social Cost of Carbon. In other words, taking the administration’s science and economics at face value, a major component of their climate plan costs $330 per tonne for emission cuts they themselves value at $38 per tonne.



McCarthy told her audience not to question her science and to respect the research behind their climate policy. If you doubt her analysis, you will definitely find the policy plan misguided. The problem is that, even if you accept her science and economics, it’s still misguided.
"
"

A plurality of likely voters now say they disagree with Vice President Gore on what is clearly his innermost, core belief. As a result, Washington insiders have advised Bush to capitulate to Gore. 



Last Earth Day, Gore re‐​released his book “Earth in the Balance,” which declares that fighting global warming should be the “central organizing principal for civilization,” and that the price of energy should be increased. Gore says he “wouldn’t change a thing” about the original (1993) edition. 



In order to create the legal framework for his program of global salvation, he told ABC’s This Week that he would “build support” for the Kyoto Protocol on global warming, which coerces dramatic reductions in energy use through higher prices, before submitting it to the Senate for ratification.



According to a recent Zogby/​Reuters poll, so far he has failed. By a margin of 46 percent to 42 percent, people support Bush’s position over Gore’s. Specifically, in the second debate, Bush said, “I’ll tell you one thing I am not going to do. I’m not going to let the United States carry the burden for cleaning up the world’s air, like the Kyoto treaty would have done.” 



Not only did Bush carry the day, it looks as if Kyoto causes heartburn for a lot of Democrats. Of people identifying themselves as Democrats, 68 percent agreed with Gore. That means one‐​third of the party faithful either agreed with Bush or had no opinion, while only 15 percent of Republicans favored Gore’s position. 



Sensing defeat, Gore recently retreated from his “Earth in the Balance” position on energy taxes, which are the fastest (and most economically disruptive) way to discourage fuel use. In the second debate, he said “I’m not in favor of energy taxes.”



So, why hasn’t Bush belled Gore’s cat? Not only does Bush enjoy popular support, he has caught Gore in another clear misstatement. The answer is that the Bush campaign itself is conflicted about climate change. Tucked away in his energy policy white paper released last month is a statement about limiting carbon dioxide emissions, the main greenhouse warming gas. That position potentially puts him to the left of Gore on global warming. 



In many ways, Bush is handling environmental policy a lot like his father did. In 1992, President Bush went to Rio de Janeiro to sign the original U.N. global warming treaty, against the advice of many but riding a crest of popularity. Five months later he was beaten by Clinton and Gore, the latter of whom heckled him in Rio. 



Why do Bushes do this? While Gore governs, campaigns, lives and breaths confrontation, Bushes make compromises and “bring people together.” They’re “kindler and gentler” and “compassionate.” 



In Washington, the people you “bring together” are involved in Washington’s primary industry: government. And so when either Bush sought Washington advice on climate change, he ran into people who can always be depended on to recommend federal programs to “do something.” For global warming, this means placing some type of restriction on greenhouse gas emissions. “Nothing” is not an acceptable answer in governmentville.



There are neither term limits nor elections for lobbyists, and they will do anything to stay here. The food is good (they’re not paying), the wine is cheap (D.C. has the lowest liquor taxes around), and the power is even more intoxicating. Keeping those perks means defining anything as a problem, requiring a solution from the federal government. 



Thus it was the electric utility lobby that encouraged Bush to include emissions restrictions in his environmental proposals. But the electric utility lobby will pursue its regulatory interests regardless of who is elected. With the prospect of a Bush victory, the lobby just made up a set of proposals, in order to have a reason for existence come inauguration time. 



Do they care what voter opinion is? Look at the Zogby poll and decide for yourself. Have they rewarded Bush for his reluctance to go along with Kyoto? No, because they’d be out of a job. Instead, they advise Bush to capitulate on his opponent’s most heartfelt opinion, in spite of evidence that Bush articulates the most popular position. They fear that Bush might actually win and make them irrelevant.
"
"
Share this...FacebookTwitterBy Jouwatch
(Translated/edited by P. Gosselin)
Since everyone is preoccupied with Corona, hardly anyone notices what is being decided to continue destroying Germany:
The German government now wants to make the use of renewable energies a question of national security. “The use of renewable energies for electricity generation is in the public interest and serves public security,” says the draft of the new German Renewable Energy Sources Act, on which the newspaper “Welt am Sonntag” reported.
From the point of view of experts, the decision is of enormous significance.
It concerns a energy-political turning point, say legal experts of energy law at the law firm of Luther, Gernot, Engel, reports Die Welt am Sonntag.
In the controversy over the building  of wind parks, for example, the reference to “public security” may fundamentally impact court rulings. In court proceedings in connection with the expansion of bioenergy, wind and solar power, the reference to “public safety” could restrict the impact rulings by judges, business representatives fear, according to the “Welt am Sonntag”.
The new norm threatens to become a basis for far-reaching state intervention.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The federal government confirmed to Die Welt am Sonntag that the new state consecrations for eco-energy should make it easier to enforce building applications. “The regulation stipulates an overriding public interest in electricity generation from renewable energies as well as a public security interest,” the Federal Ministry of Economics announced in response to an inquiry by the newspaper.
The specification is important for discretionary and public interest rulings by authorities and institutions.
Latest government power-grab
If this law passes, and it will pass because there is no real opposition apart from the AfD party, the path is cleared for Germany. Then wind turbines will be forced to be built directly next to residential areas, and ownership rights will be undermined.
That is the revolution from above. That is energy fascism. Resistance must be stirred up here – and it fatally reminds us of the power grabbing in these times of Corona!
The massively green electricity damaged Wattenrat East Friesian comments on this new underhanded approach as follows:
The renewable energy industry is insatiable, ideologically consolidated and closely linked to politics – and above all very inventive,
if it concerns the preservation of its ecclesiastical  income, which is paid by all current customers through the EEG green energy feed in act to the tune of double-digit billions annually.
Now the use of renewable energies is even supposed to “serve public safety”, says the draft of the new Renewable Energy Sources Act. This would make wind farm sites easier to implement. This is incredibly brazen and wrong because the renewable energies (wind and sun) only work depending on the weather. Especially wind power plants endanger the security of supply due to the erratic feed-in through grid instability unstable power grids, are therefore a public safety risk.”


		jQuery(document).ready(function(){
			jQuery('#dd_cd206d699e3eb9d49f563e7d100375a7').on('change', function() {
			  jQuery('#amount_cd206d699e3eb9d49f563e7d100375a7').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"
NOTE: This post is the second in the series from Dr. Roy Spencer of the National Space Science and Technology Center at University of Alabama, Huntsville. The first, made last Friday, was called Atmospheric CO2 Increases: Could the Ocean, Rather Than Mankind, Be the Reason?
Due to the high interest and debate his first post has generated, Dr. Spencer asked me to make this second one, and I’m happy to oblige. 
Here is part2 of Dr. Spencer’s essay on CO2 without any editing or commentary on my part.
(Side note: Previously, I erroneously reported that Dr. Spencer was out of the country. Not so. That was my mistake and a confusion with an email autoresponse from another person named “Roy”. Hence this new update.)

More CO2 Peculiarities: The C13/C12 Isotope Ratio

Roy W. Spencer
January 28, 2008

In my previous post, I showed evidence for the possibility that there is a natural component to the rise in concentration of CO2 in the atmosphere.  Briefly, the inter-annual co-variability in Southern Hemisphere SST and Mauna Loa CO2 was more than large enough to explain the long-term trend in CO2.  Of course, some portion of the Mauna Loa increase must be anthropogenic, but it is not clear that it is entirely so.
Well, now I’m going to provide what appears to be further evidence that there could be a substantial natural source of the long-term increase in CO2.
One of the purported signatures of anthropogenic CO2 is the carbon isotope ratio, C13/C12.   The “natural” C13 content of CO2 is just over 1.1%.  In contrast, the C13 content of the CO2 produced by burning of fossil fuels is claimed to be slightly smaller – just under 1.1%.
The concentration of C13 isn’t reported directly, it is given as “dC13”, which is computed as:
“dC13 = 1000* {([C13/C12]sample / [C13/C12]std ) – 1
The plot of the monthly averages of this index from Mauna Loa is shown in Fig. 1.

Now, as we burn fossil fuels, the ratio of C13 to C12 is going down.  From what I can find digging around on the Internet, some people think this is the signature of anthropogenic emissions.  But if you examine the above equation, you will see that the C13 index that is reported can go down not only from decreasing C13 content, but also from an increasing C12 content (the other 98.9% of the CO2).
If we convert the data in Fig. 1 into C13 content, we find that the C13 content of the atmosphere is increasing (Fig. 2).

So, as the CO2 content of the atmosphere has increased, so has the C13 content…which, of course, makes sense when one realizes that fossil-fuel CO2 has only very slightly less C13 than “natural” CO2 (about 2.6% less in relative terms).  If you add more CO2, whether from a natural or anthropogenic source, you are going to add more C13.
The question is: how does the rate of increase in C13 compare to the CO2 increase from natural versus anthropogenic sources?
First, lets look at the C13 versus C12 for the linear trend portion of these data (Fig. 3).

The slope of this line (1.0952%) represents the ratio of C13 variability to C12 variability associated with the trend signals.  When we compare this to what is to be expected from pure fossil CO2 (1.0945%), it is very close indeed: 97.5% of the way from “natural” C13 content (1.12372%) to the fossil content.
At this point, one might say, “There it is!  The anthropogenic signal!”.  But, alas, the story doesn’t end there.
If we remove the trend from the data to look at the inter-annual signals in CO2 and C13, we get the curves shown in Figures 4 and 5.


Note the strong similarity – the C13 variations very closely follow the C12 variations, which again (as in my previous post) are related to SST variations (e.g. the strong signal during the 1997-98 El Nino event).
Now, when we look at the ratio of these inter-annual signals like we did from the trends in Fig. 3, we get the relationship seen in Fig. 6.

Significantly, note that the ratio of C13 variability to CO2 variability is EXACTLY THE SAME as that seen in the trends!
BOTTOM LINE: If the C13/C12 relationship during NATURAL inter-annual variability is the same as that found for the trends, how can people claim that the trend signal is MANMADE??


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea1489aab',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterCoastal history analyses increasingly suggest sea levels are lower today than at any time in the last 7000 years – even lower than the 1600s to 1800s.
Recently we compared cartology from the 17th to 19th centuries to direct aerial images of coastal positions today. Rather surprisingly, there seemed to be more land area below sea level a few hundred years ago.
For example, an 1802 nautical map of New York City and Long Island shows there may have been more open waters in this region during the Little Ice Age than in 2019.

Image Source: Amazon.com
Shoreline analysis from India also suggests the coasts were further inland during the 1600s than they are today (Mörner, 2017).

Image Source: Mörner, 2017
In another new study, the borehole sea level history for the Italian port city of Salerno reveals the coast was hundreds of meters further inland compared to today’s 7000 years ago. Even 300 years ago the coast was still much further inland (Amato et al., 2020).

Image Source: Amato et al., 2020
Citing previous studies, another new paper has today’s sea levels about 2 to 3 meters lower than they were 4000 to 5000 years ago along the coasts of Brazil (Martins et al., 2020). And, again, today’s relative sea levels seem to be the lowest of the record – lower than the Little Ice Age.

Image Source: Martins et al., 2020
Share this...FacebookTwitter "
"

A new USC study shows that Deep-sea temperatures rose 1,300 years before atmospheric CO2 rose, ruling out the greenhouse gas as driver of meltdown, says a study in Science.
Carbon dioxide did not cause the end of the last ice age, a new study in Science suggests, contrary to past inferences from ice core records. “There has been this continual reference to the correspondence between CO2 and climate change as reflected in ice core records as justification for the role of CO2 in climate change,” said USC geologist Lowell Stott, lead author of the study, slated for advance online publication Sept. 27 in Science Express. “You can no longer argue that CO2 alone caused the end of the ice ages.” Deep-sea temperatures warmed about 1,300 years before the tropical surface ocean and well before the rise in atmospheric CO2, the study found.
The finding suggests the rise in greenhouse gas was likely a result of warming and may have accelerated the meltdown – but was not its main cause. The study does not question the fact that CO2 plays a key role in climate. I don’t want anyone to leave thinking that this is evidence that CO2 doesn’t affect climate,” Stott cautioned. “It does, but the important point is that CO2 is not the beginning and end of climate change.” While an increase in atmospheric CO2 and the end of the ice ages occurred at roughly the same time, scientists have debated whether CO2 caused the warming or was released later by an already warming sea.
The best estimate from other studies of when CO2 began to rise is no earlier than 18,000 years ago. Yet this study shows that the deep sea, which reflects oceanic temperature trends, started warming about 19,000 years ago. “What this means is that a lot of energy went into the ocean long before the rise in atmospheric CO2,” Stott said. But where did this energy come from” Evidence pointed southward. Water’s salinity and temperature are properties that can be used to trace its origin – and the warming deep water appeared to come from the Antarctic Ocean, the scientists wrote. This water then was transported northward over 1,000 years via well-known deep-sea currents, a conclusion supported by carbon-dating evidence. In addition, the researchers noted that deep-sea temperature increases coincided with the retreat of Antarctic sea ice, both occurring 19,000 years ago, before the northern hemisphere’s ice retreat began.
Finally, Stott and colleagues found a correlation between melting Antarctic sea ice and increased springtime solar radiation over Antarctica, suggesting this might be the energy source. As the sun pumped in heat, the warming accelerated because of sea-ice albedo feedbacks, in which retreating ice exposes ocean water that reflects less light and absorbs more heat, much like a dark T-shirt on a hot day.  “The climate dynamic is much more complex than simply saying that CO2 rises and the temperature warms,” Stott said. The complexities “have to be understood in order to appreciate how the climate system has changed in the past and how it will change in the future.”


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea37da97f',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

Just released: new DOE figures showing that the US has reduced CO2 production 1.5% last year in 2006, even without the US signing on to Kyoto.  You can read the full report here (Adobe PDF file).
 Here are some of the numbers for 2006:

• Total U.S. greenhouse gas emissions in 2006 were 1.5 percent below the 2005 total—the first annual drop since 2001 and only the third since 1990.
• The total emissions reduction, from 7,181.4 million metric tons carbon dioxide equivalent (MMTCO2e) in 2005 to 7,075.6 MMTCO2e in 2006, was largely a result of reductions in carbon dioxide (CO2) emissions. There were smaller reductions in emissions of methane (CH4) and man-made gases with high global warming potentials (high-GWP gases)
• U.S. carbon dioxide emissions in 2006 were 110.6 million metric tons (MMT) below their 2005 level of 6,045.0 MMT, due to favorable weather conditions; higher energy prices; a decline in the carbon intensity of electric power generation that resulted from increased use of natural gas, the least carbon intensive fossil fuel; and greater reliance on non-fossil energy sources.
Despite my stance on the measurement and interpretation errors associated with the surface temperature record, I’ve always felt that reducing pollution is a good thing. At the same time I’ve always felt that our environmental movement is too often focused on panic driven ideas.
Coupled with the news about the 2007 hurricane season being very low in my post below, I believe we’ve seen evidence that things aren’t all they are claimed to be, particularly by Gore. I think the best approach overall is to not panic, and to work on alternate energy solutions and better efficiency as a way to wean ourselves from foreign oil. The key here is slow change. It took us 100 years to get to this point, it will probably take us at least half that to reverse the trends in a sensible way with new technology.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea2506bff',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Biodiversity hotspots that have given species a safe haven from changing climates for millions of years will come under threat from human-driven global heating, a new study has found. Species that have evolved in tropical regions such Australia’s wet tropics, the Guinean forests of Western Africa and the Andes Mountains will come under increasing stress as the planet warms, the study finds.  Experts reacted to the study with shock, saying it was depressing that some of the Earth’s “most critical real-estate for saving nature” could be under threat. Published in the journal Nature Climate Change, the study modelled global land and ocean temperatures and rainfall for the past 21,000 years. The study then examined the impact of adding greenhouse gases to the atmosphere under two scenarios – one considered to represent very high emissions and another with much lower levels of emissions. Places that are rich in biodiversity tend to overlap with places in the tropics that have experienced relatively stable climates in the past, providing a refuge for species when other regions have warmed, the paper explains. Assoc Prof Damien Fordham, a global change ecologist at the University of Adelaide and a co-author of the research, told Guardian Australia this had allowed ancient species to survive, causing a “stacking” of biodiversity. He said: “We had hoped that what we would find was that these places would continue to have stable climates. But what’s extremely worrying is that we see a shift from stable to unstable.” He said while the study looked closely at the past 21,000 years, the areas impacted were known to have supported stable climates for millions of years. Fordham said species in these areas tended to be adapted to survive within very narrow temperature and climate boundaries. But human-caused climate change would happen too fast for species to evolve or move, so even small shifts would have large impacts. “Here we see really strong direct evidence of how climate change could have really adverse affects in the tropics that harbour the highest places for biodiversity on the planet.” He said the higher and lower emissions scenarios used to project changes to the end of this century showed similar impacts. He added: “We see this as a further reason for action on climate change, and also in considering these hotspots in our plans for climate change mitigation and adaptation.” Global expert on conservation management Prof Hugh Possingham, of the University of Queensland and chief scientist at the Nature Conservancy, said the study was “depressing”. He said there had been a common assumption that places that had acted as “climate refugia” of the past would carry out the same function in the future. He told Guardian Australia: “If this is true, and they do provide compelling arguments, it is more bad news for nature. “What I would like to see is some work on picking landscape scale actions that could ameliorate these predicted effects. “What actions could we conceivably take that would facilitate climate adaptation at these critical locations? Habitat restoration? Reducing human pressures like hunting?” Prof Bill Laurance, director of James Cook University’s centre for tropical environmental and sustainability science, who was not involved in the study, said it was “the scariest paper that I’ve read in the last couple of years”. He said: “The idea that our global biodiversity hotspots – Earth’s most critical real-estate for saving nature – will be intensely vulnerable to future climate change is enough to scare the bejesus out of anyone with a lick of common sense. “These tiny vestiges of native vegetation – essentially living arks of unique species – are going to be repeatedly body-slammed by highly fluctuating temperatures as this century progresses, according to this study. Wildfires, killer droughts, intense storms, flooding rains, the list of calamities goes on.” But he said it was important that people did not fall into the trap of feeling helpless, adding: “This work is alarming but it’s akin to being warned that there’s a massive sinkhole in the highway ahead. “We have a chance to dodge it if we start changing direction now.”"
nan
"Sometime in the next year or two, Nigeria will become the seventh country to reach a population of 200m or more. It is still growing considerably faster than all other nations towards the top of the list and, by 2050, the UN expects Nigeria to have the world’s third-largest population. Keeping all those mouths fed will be a huge challenge, not least because millions of Nigerians depend on fish from the Atlantic coastline, mostly caught by small-scale artisanal fishermen. And those livelihoods are now threatened by climate change, pollution and illegal fishing. Firstly, climate change: as oceans warm, habitats will be degraded and biodiversity will be lost. Many fish will migrate towards the poles to follow the cooler seas, making fishing at high latitudes more productive while tropical fisheries suffer. Nigeria, just above the equator, will be hit particularly hard. According to the World Bank, under a high CO₂ emissions scenario there will be a 53% reduction in the country’s fish resources by 2050.  Nigeria did adopt a climate change strategy as part of the UN policy process which culminated in the Paris Agreement, but it does not seem to have been widely implemented. Neither is there any evidence of an adaptation policy that would enable vulnerable coastal communities to become more resilient in the face of climate change.   Second, pollution by oil companies also threatens the livelihood of more than 6.5m people in the Niger Delta area. The 2011 Bonga oilfield spillage, a facility owned by Shell Nigeria, is just one recent example of the inadequacies of existing environmental regulations. The spill discharged an estimated 40,000 barrels of crude oil that then spread along the Atlantic coast for 185 km. Nearly 30,000 fishermen were forced to abandon their trade.  According to the Niger Delta Artisanal Fisher Association, not only have communities not been compensated, they have also been hit by reduced populations of bonga fish, a common species in the area.  As a relatively poor country with relatively rich seas, Nigeria is also vulnerable to illegal fishing by foreign vessels, predominantly from China. No wonder: the government’s fisheries department does not have any patrol boats to monitor licensed vessels and, when I interviewed a representative from the department, they claimed there has been no budgetary allocation for “monitoring, control and surveillance” in more than 15 years. In March 2018, the Nigerian navy noted that the country loses an estimated US$70 million each year due to illegal fishing.  These three threats add up to looming disaster: according to an ODI report, half of the fish species in waters off West Africa are already overexploited.  With fewer fish to catch, people who depend on the oceans for their livelihoods are seeking more creative ways to make ends meet. This has included fishing across borders, which has the potential to provoke conflict between Nigeria and its neighbours – in one 2017 incident, Cameroonian forces are alleged to have killed 97 Nigerians who they claimed had not paid a fishing levy.   With no clear climate change mitigation and adaptation strategy, weak fisheries and environmental management policies, there is growing potential for unrest. Coastal communities are attempting to build their resilience without institutional support, yet may undermine the stability of Nigeria and neighbouring countries. To see that depleting fisheries have the potential to undermine the limited stability currently enjoyed in the country, one only has to look as far as north-central Nigeria. There, a conflict between nomadic pastoralists and resident farmers due to lack of land for grazing has resulted in more than 1,000 deaths, and the displacement of millions of people.  To avoid a similar resource conflict along its coasts, Nigeria needs a national plan of action for how to help people who are left vulnerable by its depleting fisheries. This would first require robust monitoring and control mechanisms to cut out illegal fishing and ensure the country’s remaining resources are exploited sustainably. Environmental agencies also need to be better equipped to enforce existing regulations, including ensuring that oil companies clean up their spillages to the level that is seen in developed countries.  Finally, having a nicely written climate change mitigation policy is great, but its time for Nigeria to walk the walk. It must invest in climate adaptation strategies that would empower coastal communities and better prepare them to cope with the impact of depleting fisheries."
"It was not long ago that, if you wanted to reduce the impact of your consumer choices on the environment, your only option was to use your own shopping bag. These days, the eco-minded shopper is overwhelmed with “green” choices. With the rise of reusable pads and menstrual cups, your period can now be plastic-free. Cosmetics increasingly come in glass and aluminium containers. Even hosiery brands are swapping nylon for more eco-friendly material. Given the devastating toll of consumer waste on the health of the planet, you may find this visible drive towards sustainability on supermarket shelves cheering. But if you are a man, you may not have even noticed it: most eco-friendly products are marketed to women.  There is an obvious (and depressing) reason for this: women are not only more powerful consumers, but also disproportionately responsible, still, for the domestic sphere. The result of this is what the market research firm Mintel has termed an “eco gender gap”, where green branding might as well be pink. In a 2018 report by Mintel on the subject, Jack Duckett, a senior consumer lifestyles analyst, said women “still tend to take charge of the running of the household”, with laundry, cleaning and recycling falling under that banner. But “with eco-friendly campaigns and product claims largely aimed at female audiences”, advertisers run the risk of communicating the message that sustainability is women’s work. The idea is already insidious due to the persistent portrayal of women as caregivers – even of the planet. Janet K Swim, a professor of psychology at Pennsylvania State University who has done extensive research into the social consequences of environmentally friendly behaviour, points to a political cartoon showing Theodore Roosevelt, the US president from 1901 to 1909, wearing an apron, “trying to mock him as feminine” for his conservation policies. While it is true that women are more likely than men to be green, in the past that gender gap has been attributed to personality differences. Research from the mid-90s to early 00s pointed to women’s greater tendency to be prosocial, altruistic and empathetic; to display a stronger ethic of care; and to assume a future-focused perspective. “Research suggests that women have higher levels of socialisation to care about others and be socially responsible, which then leads them to care about environmental problems and be willing to adopt environmental behaviours,” says Rachel Howell, a lecturer in sustainable development (a subject that is, she notes, studied overwhelmingly by women at undergraduate level) at the University of Edinburgh. Whether women are born caring about the planet or learn to do so, there is evidence to suggest that femininity and “greenness” have come to be cognitively linked (by men and women) – and that this, as absurd as it may sound, is partly what puts off men from doing their bit. In a study published last year in the journal Sex Roles, Swim and her fellow researchers at Penn State found that men could be disinclined to carry a reusable shopping bag – or recycle, or any environmentally friendly activity that had been gendered as feminine – for fear of being perceived as gay or effeminate. (The same concern has been well established as a factor in men’s reluctance to adopt vegetarian or vegan diets.) Similarly, a 2016 paper in the Journal of Consumer Research found that “men may be motivated to avoid or even oppose green behaviours in order to safeguard their gender identity” and that their participation could be encouraged by weakening the association between femininity and sustainability, such as “by using masculine rather than conventional green branding”. Plastic Freedom and Package Free Shop, two popular zero-waste online retailers, say they are careful to use gender-neutral marketing – but both say about 90% of their customers are women. Lauren Singer, the founder of Package Free Shop, which sells items such as bamboo cutlery and eco cleaning products, suggests that the imbalance presents women with an opportunity to lead. “Let’s be the ones that absorb the responsibility of being the stewards and educators of sustainability,” she says. But with analysis in 2016 from the Office for National Statistics showing that women carry out an average of 60% more unpaid work than men, Howell’s suggestion may hold more appeal: to close the eco gender gap, close the associated gap “in terms of who does the laundry, who does the grocery shopping, who does the cleaning at home”. Also, get rid of “false ideas of what a sustainable product must look like”, she says, pointing out that men may carry a rucksack or reusable sports bottle without it being sold or perceived as green. The British men’s skincare company Bulldog stands out for making sustainability a cornerstone of its brand. Its plastic tubes are derived from sugar cane, not fossil fuel; it sells bamboo-handled razors and shower gel in cardboard packs; and its Original Moisturiser is certified carbon-neutral. “We’ve never thought that there’s really a gender perspective on the idea of sustainability,” says Simon Duffy, the brand’s founder. “It’s a crazy idea to me, that that is considered more feminine than masculine. Everybody should be focused on this.” For female beauty brands, sustainability may well be a way of standing out in a crowded market, says Duffy (for male beauty, “the challenge is getting men to use these types of products at all”) – but commitment should not be only skin deep. “We’re trying to make it inherent to everything we do,” he says, “because it’s the right thing to do. It doesn’t have to be a marketing story. Companies that try to use that as a tactic to sell more products are missing the point.” It is a reminder that, for a company to be truly green, its attention to sustainability should extend to every level of its business – not just the one that draws consumers. Areeba Hamid, a senior campaigner at Greenpeace, says the impact of individual choices – even giving up meat or air travel on a large scale – is negligible: “If the corporations keep drilling for oil and gas, that is not going to amount to anything.” Howell says: “While individual action is important, the individualisation of responsibility can go too far. We have got to look at the whole and try to do something at a societal level.” Even arguments about meaningful action on the climate crisis are are split down gender lines. Another study by Swim, published in the journal Global Environmental Change last year, showed that men preferred arguments that centred on science and business and tended to “attribute negative feminine traits” to men who argued on the basis of ethics and environmental justice – as women typically did. Women tend to have less trust in institutions, Howell says, which may mean they have less faith in the ability of science, technology and the government to address the issues that face us. Men, however, having been historically well served by the status quo, “are much more inclined to believe that, if they accept there is a problem, then somebody or some technology will sort it all out – that we don’t need to change our lifestyle”. Misogyny has been shown to be a factor in climate denial. A 2014 paper in the International Journal for Masculinity Studies found that: “For climate sceptics, it was not the environment that was threatened; it was a certain kind of modern industrial society built and dominated by their form of masculinity.” As Martin Gelin wrote last year in the New Republic, the highest-profile climate campaigners in the world today are two young women: Greta Thunberg and Alexandria Ocasio-Cortez. Those shouting them down are primarily older conservative men. “Occasionally, I feel quite angry,” says Howell, “because a lot of the problems have historically been created more by men, because they have more power, but it sometimes seems that women are getting more desperate about trying to solve them – and maybe have less power to do it.” But the world is changing. Millennials and Generation Z (those born between the early 80s and the mid-00s) have been shown to align broadly on the climate crisis, according to recent data compiled in the US by the Pew Research Center; even young Republicans are more likely to say that governments need to do more. “If you look at the youth climate movement, and Greta, there are a lot of young men as well as women,” says Hamid. “I think this is generational.” Duffy says that brands are changing, too. More than two-thirds (68%) of Europeans rate being environmentally friendly as more important to them than it was five years ago, according to a European Consumer Packaging Perceptions survey from 2018. For 19- to 29-year-olds, it was 80%. While some companies will change their ways only when forced, Duffy looks to Adidas’s range of trainers made from upcycled ocean plastic, and the footwear company Allbirds, as examples of those with “sustainable stories”, irrespective of the gender of their target market. “It’s certainly seeping in,” he says. “If you’re a man and you’re not picking up that this is important, something is wrong.” Additional reporting by Ruby Abbiss"
nan
"

Florida State University’s COAPS (Center for Ocean-Atmospheric Prediction Studies) says that hurricane season 2007, which ends November 30th, is looking well below normal, in fact they are calling it “historic inactivity”.
According to COAPS: “Unless a dramatic and perhaps historical flurry of activity occurs in the next 11 weeks (ACE is based on calendar year, not traditional June-November hurricane season) , 2007 will rank as a historically inactive Tropical Cyclone year for the entire Northern Hemisphere. During the past 30 years, only 1977, 1981, and 1983 have had less activity to date (Jan-December). For the period of June 1 – October 19, 2007, only 1977 experienced LESS tropical cyclone activity.”
ACE Departure from Climatology thru October 24th, 2007 
Northern Hemisphere  -31% **** 316 (458) (Historic inactivity, 16% of season to go)
North Atlantic  -28% **** 63 (87) (Bill Gray wants 4 more (huh?, Season 91% over)
Eastern Pacific  -59% **** 52.2 (128) (Kiko helping out a little, Season 95% over)
Western Pacific  -25% **** 179 (237) (Still 21% of yearly activity to go)
PDI Departure from Climatology thru October 24th 2007
(PDI = Power Dissipation Index)
Northern Hemisphere  -24% **** 29687 (39101)
North Atlantic  -8% **** 6533 (7095) Effects of the Category 5’s
Eastern Pacific  -63% **** 3875 (10510) Includes Kiko
Western Pacific  -18.3% **** 17189 (21037) Includes Kajiki
Here are the named storms so far and their PDI:
Andrea 2.3 (Subtropical)
Barry 3.4
Chantal 2.5
Dean 386
Erin 1.3 (weak weak weak)
Felix 215
Gabrielle 4.0
Humberto 8.2
Ingrid 2.8
Jerry 2.4
Karen 17.2
Lorenzo 6.7
Melissa 1.9
There are some caveats:
Climatology based upon ACE (Bell et al. 2000) from 1970-2006 for each basin. ACE is not a perfect metric and does not account for storm size. Northern Hemisphere includes Northern Indian Ocean after 1976, which accounts for less than 3% of the yearly total. Data quality is a tremendous issue. The NHC declared extratropical observations were not included, which can account for up to 20% a year in additional ACE. The JTWC only started keeping track of EX phases in 2004, so there are literally 1,000 observations since the 1950s that are likely extratropical in the database (as phished out from the JMA database).


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea324212a',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"In February 2018, the Bolivian authorities captured two Chinese citizens in a poultry store in the city of Santa Cruz de la Sierra. They were apprehended in possession of 185 jaguar fangs, three feline skins, a 22-caliber pistol, a large sum of money, and body parts of many other animal species, including rattlesnakes, marsh deer, giant armadillos and jaguars. All were to be shipped to Chinese medical markets, where, according to experts in the animal illegal trade, the jaguar – a wild feline native to the Americas – is in more and more demand as a replacement for Chinese medicines derived from their “original” source – the Asian tiger. This story highlights something not often discussed when it comes to the illegal wildlife trade for traditional medicines – that traditions are a human product, a result of entangled exchanges, often driven by commerce. Thanks to these processes, new species that are strangers to Chinese lands can become staples of the black medical market as substitutes to the (dwindling) traditional ones.  The jaguar is the largest native feline species of the New World, the third largest in the world and the only extant member of the genus Panthera native to the Americas. Jaguars have already been long exploited for the fur industry, both at home and abroad. Alexander von Humboldt recorded that late in the 18th century, 4,000 jaguars were killed in the Spanish colonies annually and 2,000 were exported every year from Buenos Aires for use in the fur industry. But the historical sources do not mention any medical use of jaguar body parts. Today, the species is considered “near threatened” and the trade in jaguars and their body parts is prohibited. Numbers are, however, declining: due to the emergence of a new black market for jaguar parts located on the other side of the world. 


      Read more:
      Captive breeding has a dark side – as disturbing Czech discovery of trafficked tiger body parts highlights


 This story of substitution and surrogates in the wildlife trade has a long history, especially when it comes to medicines derived from animal parts. As the Spanish military engineer Félix de Azara put it early in the 19th century: “Humans make remote beasts bind together.” One such story that I’m currently researching revolves around the hooves of a species of large mammals. Early in the 1580s, the Milanese physician Apollonius Menabenus, former doctor of John III Vasa of Sweden, published a treatise discussing the  virtues of the elk. This “great beast”, he wrote, was a creature that suffered from epilepsy and cured itself by putting the hoof of the left hind foot into its ear.  This peculiar pairing of affliction and cure had been seen before. A similar habit had long ago been noted in the ass by Roman scholars Dioscorides and Pliny. So the fact that Swedish naturalist Olaus Magnus, one of the most important early modern authorities on this animal, described the elk as a wild ass or onager in his History of the Northern Peoples (1555) can probably explain this new belief about the elk.  This could have stimulated Menabenus to write about the elk, an animal that in Sweden had been placed under the king`s protection. Aware of the potential commercial interest in Swedish exotic and curious objects, Menabenus promoted the medical use of the so-called “nail of the great beast”. The currency of this strange tale by no means ended in Northern Europe. Late in the 18th century, the Welsh traveller, naturalist and antiquarian, Thomas Pennant, devoted a long description in his Arctic Zoology to the elk and the moose, the largest extant species in the deer family. According to Pennant, North American natives used the elk hoof in the same way it was used in Old World pharmacopeias:  The opinion of this animal’s being subject to the epilepsy seems to have been universal, as well as the cure it finds by scratching its ear with the hind hoof till it draws blood. That hoof has been used on Indian medicine for the falling-sickness; they apply it to the heart of the afflicted, make him hold it in his left hand, and rub his ear with it. On the other side of the Americas and almost at the same time, Félix de Azara attributed the same property to the hooves of the Paraguayan tapir, a large herbivorous mammal, with a short, prehensile snout, that inhabits forest regions of South America. The animal was called “gran bestia” by the Spaniards and “anta” by the Portuguese. Since then, every time the tapir was described, in no matter which region of South America, the medical virtues of the its hoof reappeared over and over again as a local, native tradition. Referring either to the moose, elks or tapirs, all the way across the Americas and Europe, the sources exhibit a recurring belief that the hooves of large mammals, often simply called “the great beast”, were valuable in treatment of human epilepsy. Pennant, the Welsh naturalist, considered this association to be a kind of universal belief or a remarkable parallel to the Old World. He saw the pattern as evidence of an underlying ancestral unity of humans that causes them to react similarly to new and evolving situations. 


      Read more:
      Pangolin: illegal medicine trade threatens these scaly mammals with extinction


 But the contemporary trade in jaguar’s fangs shows us that these reactions could have more mundane causes. The nail of the “great beast” and the jaguar´s fang have something in common. Both illustrate how the commerce in animal products transfers names and virtues across species, contributing to a human association between species that come from alien worlds. It was commerce, not universal truth, that lead to the search for surrogates that could act as the “great beast” on both sides of the Atlantic, sealing the destiny of the local animal species selected to be the source of the curing hoof.  Jaguar fangs, for now, are not used in Bolivia as medicine; their sale appears strongly linked to the community of Chinese workers who have arrived in the country in the last decade. But the story of the nail of the great beast makes it plausible that in the near future it will be considered part of the country’s traditions. We’ll have to stay tuned."
"It’s amazing what you can get away with in a hi-vis vest. On Thursday 30 January, pedestrians in some suburbs of Melbourne, Sydney and Brisbane would have walked straight past activist artists (vandals, some critics might call them) removing advertising from bus shelters and inserting artwork protesting the Morrison government and its handling of Australia’s bushfire crisis.  “Bushfire Brandalism”, the action is being called. Sydney-based artist Scott Marsh chuckles about the hi-vis vests: “It’s the cloak of invisibility.” Marsh, known internationally for his political murals, contributed a portrait of Scott Morrison with the words “climate denial” emblazoned across his forehead. A QR code on each poster links people to a bushfire-related charity of the artist’s choice. It also gives the collective an idea of how and where people are connecting with the campaign. Unfortunately, many of the works get taken down as fast as they go up. The collective said on Monday they installed 78 posters last week, describing it as “the nation’s largest unsanctioned outdoor art exhibition”. But only a few posters remain. The practice of “brandalism” – also known as “subvertising” or “anti-advertising” – isn’t new. In 1979, Billboard Utilising Graffitists Against Unhealthy Promotions (colloquially known as “Bugger Up”) was formed in Sydney and spread to other Australian cities, targeting cigarette and alcohol advertising. British artists the KLF have been associated with the practice since the 90s, and in 2015, more than 80 artists took over 600 Parisian bus shelters during the COP21 UN climate change conference. Forty-one artists are involved in this latest Australian iteration, including Georgia Hill, Tom Gerrard, Sarah McCloskey, Ghostpatrol, Callum Preston and E.L.K, as well as anonymous artists. In one poster, a Caramello Koala has burst and is melting above the words “Save an Aussie icon”. In another, Blinky Bill runs from an encroaching wall of flames. The collective launched three weeks prior to the posters going up, via a group chat of artists on Instagram. They were dismayed at what they saw as biased bushfire coverage and at the misinformation being shared by some media – particularly the Murdoch-owned press. “It felt like taking over public space was an appropriate angle to tackle it,” says one organiser who doesn’t want to be named. “There was a lot of discussion about the divided attitudes and experiences of people living in the city versus the regional areas – but we were limited in time and resources, and also those type of ‘adshell’ spaces only really exist in the city centre.” Many of the artists involved aren’t known for being political in their work. The same can’t be said for Marsh, who has for years responded to policies he takes issue with – starting with Sydney’s lockout laws, when he was an art student living behind the Coke sign in Kings Cross. “People were losing their jobs and it didn’t make any sense at all – [there was] dodgy stuff when you started looking into it,” he says. “I went to the Keep Sydney Open march, and then had the idea of doing a mural of Casino Mike [Baird, the then-NSW premier].” Then there was his mural of Alan Jones with a ball gag in his mouth; and one lampooning Israel Folau for the crowdfunding campaign he launched after Rugby Australia stripped him of his contract following homophobic social media posts (Folau is depicted begging next to a Lamborghini). Marsh’s murals are frequently defaced or painted over, such as his short-lived “Merry Crisis” Scott Morrison mural that lasted three days (he turned it into a merchandise line and raised $131,424.50 for Australian fire brigades) and a saintly George Michael portrait, which got painted over in black ink before locals reclaimed it with pro-marriage equality messages. Marsh’s depiction of Cardinal George Pell and Tony Abbott – A Happy Ending – was painted over within 24 hours by three men who labelled it “pornography”. On one occasion, Marsh even obliterated his own mural – Kanye Loves Kanye – after he reportedly sold a one-off print of it for $100,000. “The interactive stuff’s more fun than murals,” Marsh says. “I did a Fraser Anning Easter egg hunt last year.” (Those who found the eggs were encouraged to throw them at the Fraser bunny.) Before last year’s federal election, he made posters of  Clive Palmer  falling asleep during question time “and invited people to draw dicks on him”. Sometimes Marsh really goes the extra mile. Not content with the mural of Cardinal Pell in his prison greens that he put up in Sydney 50 metres away from St Mary’s Cathedral, Marsh flew to Rome on his own coin and did the same near the Vatican. When he has to act fast, he has a printed paper version of the mural, pastes it up and finishes the job with paint, but in any case, passersby were surprisingly supportive. The last of the 78 Bushfire Brandalism posters have now gone up, but for Marsh, tackling the issue of climate change is far from over. He continues to create works relating to the Adani coalmine, not least because of all the family holidays he spent at the Great Barrier Reef. “It’s really hit home for me,” he says. “I’m frustrated with the lack of action. I got distracted for a while, but you can smell it in the air that now is the time to really push on climate change. If nothing happens now, it’s never going to fucking happen.” "
"
Share this...FacebookTwitterThe COVID 19-pandemic has led the German public to grow weary and distrustful of the “follow the science” mantra and to realize that it means losing liberty and fundamental rights.
Political shifts and public opinion changes are afoot in Germany as libertarians and conservatives become every more disenchanted with the restrictions.

Tens of thousands gathered in Berlin in August 1st to protest government restrictions. Image cropped here, Michael Ballweg.
Tide change in Berlin 
Last weekend tens of thousands (estimates range from 10,000 to over 1,000,000) demonstrated in Berlin to protest government restrictions aimed at limiting the spread of the COVID-19 virus. The protest was also about the limitation of free speech and the right to assemble.
Desperate, ruling politicians and their allied mainstream media responded by defaming the protesters as nutcases rather than treating them as respectable working citizens and taking their grievances seriously. The gross mistreatment by politicians and media only confirmed to many demonstrators that they’ve gone too far.
Citizens demonstrating in Stuttgart
This weekend German citizens have turned out by the thousands in Stuttgart and other cities to continue their protests and demand their freedom and rights back. A large part of the public refuses to “just believe” the government experts. In their view the science is not settled at all, and there’s no reason to continue refraining from their liberties.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




German Research Institute reverses
Another sign of changing opinion tides and distrust was the recent reversal by the German Research Foundation (DFG) which earlier had taken down a climate science critical comment by high profile satirist Dieter Nuhr from its website. In his comment Nuhr warned its reckless to “follow the science” because the science behind climate and COVID-19 is far from settled.
Under mass public pressure, the DLG reinstated Nuhr’s comment.
State now considered “a threat to civil liberty”
Moreover, the German Tagespost here warns German leaders to be wary of the current trend, and sees the political right in Germany to be transitioning away from statist traditions.
“At the latest since Hegel and in accordance with Prussian and Protestant traditions, the state had a promising, even metaphysical sound. That is currently changing,” the Tagespost comments.
US right-wing liberal thinking gaining influence
“While Chancellor Merkel was accused of state failure in the migration crisis, and thus still demanded a strong state that is able to protect its borders, the state itself is now increasingly becoming a problem. As in the USA, right-wing liberal thinking is gaining influence. The state is considered a threat to civil liberty.” adds the Tagespost. “Corona is currently whirling the relationship of the Germans to the state in a colorful confusion.”
The next major demonstration is planned for August 29 in Berlin.


		jQuery(document).ready(function(){
			jQuery('#dd_8e919b1a54fb1ca36f88be78165d8b92').on('change', function() {
			  jQuery('#amount_8e919b1a54fb1ca36f88be78165d8b92').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"Picture this, a cute baby penguin, blown down a gully during a fierce storm, with no escape. You’ve been filming the natural world for weeks, following this individual. You’ve invested in it, become interested in it, attached to it – would you be able to let it die, or would you want to save it? Well, while filming an episode of Dynasties, a BBC crew decided to intervene, causing controversy in the process. As noted by presenter David Attenborough at the end of the episode, intervention by film crews is “rare”. Indeed, the goal for any nature documentary crew is to capture the living world without succumbing to emotional distress, and thus the urge to alter the things they film. So, was saving the penguin the right thing to do?  There are many arguments against what the BBC crew did: first, death is a natural process in the animal kingdom. Without dead animals many species would starve to death. In fact, many animals have evolved to feed off other dead animals – these are the scavengers, the ones that clean up the mess – and carcasses can attract thousands of animals. For instance, carcasses of whales may support fauna such as crabs, lobsters, sharks and fish, for up to 80 years. Death is also needed in order for species to evolve and become adapted to their environment: evolution via natural selection, otherwise known as “survival of the fittest”. This is where individuals that are more suited to take advantage of the resources in the environment – be they food, shelter or mates – are more likely to survive. They are also more likely to survive long enough to reproduce, hence they will pass their advantageous genes on to their offspring and, over time, we end up with a population that is perfectly adapted to their environment. Once we start intervening with this natural process we are potentially augmenting a “survival of the not-so-fit”, and often “survival of the weakest”.  However, intervention doesn’t always take the form of a benevolent documentary crew. Often, animals are saved by well-meaning people – those who want to nurture animals and provide them with the best life possible. Every spring the Royal Society for the Protection of Birds (RSPB) are inundated with calls from members of the public who have found “abandoned” birds and tried to save them. However, most of the birds haven’t been abandoned, as they are typically only a short distance from their parents. Unfortunately, well-meaning people often “rescue” animals which, in reality, means that they will either be destined to a life in captivity or will be returned to the wild without the necessary skills to survive, so will probably perish.  Born free, the true story of Elsa the lioness who was rescued by George and Joy Adamson, documents how Elsa was raised by the Adamsons until she became too big and caused chaos. By this time, Elsa had been in captivity for so long that she didn’t display the normal behaviour needed to survive in the wild – she couldn’t hunt and didn’t know how to behave around other lions – she had to learn how to be a wild lion again. The film portrays the emotional attachment and inner turmoil that Joy has towards Elsa. For example, “I know what is good for her but I don’t want to let her go”, is seen in many humans, putting their own compassion over what might be best for animals. However, to denounce the direct action of humans in this way would seem to ignore the alterations humans have already made to our environment. By destroying habitats, exploiting species, polluting the planet and introducing non-native species, humans have already caused destruction to the planet, and are the cause of the current extinction crisis. This could see much-loved species such as lions go extinct in the wild through human-induced threats including persecution and trophy hunting. Given our profound impact on wild populations, it is fitting that we help as many animals as possible. One way to do this responsibly would be to undertake more effective habitat management or educate people on aspects of conservation.  For example, Attenborough released a three-part documentary, State of the Planet, in 2000, but it didn’t attract the usual number of viewers. The danger is that repetition may make people numb to the issues, or simply stop watching. Although, more recent attempts have been far more successful. The final episode of the Blue Planet II highlighted the current plastic problem and people took notice. Indeed, the emotional response that such documentaries elicit, and that is inherent in most of us, can be beneficial. However, its benefits are often limited as the biggest conservation draws are the “flagship species”, those that are cute, cuddly, charismatic and pull on our heartstrings. So, what about the penguins? If these were animals being killed by a natural predator, it is hard to justify why you would intervene and prioritise one species of animal over another. But, if these were animals dying from a human-induced threat, surely we have a responsibility to help. Regardless of whether the storm that stranded the penguins was natural or not, I would have found it hard to watch the penguins perish."
"Boris Johnson has promised “urgent action” on the climate crisis, taking personal leadership of this year’s UN climate talks after a blistering attack by the sacked former minister who was to lead them. “Unless we take urgent action, we will get 3C hotter,” the prime minister told a gathering of climate experts, business leaders and civil society groups at the Science Museum in London on Tuesday morning. “As a country, as a society, as a planet and as a species, we must now act.” He called on all governments to follow the lead of the UK in setting a target of net zero emissions by 2050, promised support for “our Chinese friends” in their efforts to tackle species loss and environmental degradation, and announced he would bring forward the phaseout of diesel and petrol cars in the UK from 2040 to 2035. In a boost to Johnson as social media buzzed with criticism of his handling of the climate talks so far, Sir David Attenborough signalled his strong public support at the launch. “Unless we do something, [the climate crisis] becomes insoluble. That’s why Glasgow is extremely important,” said Attenborough. “It is up to us to organise the nations of the world to do something about it. That it is why it is so encouraging to know that the present government has devoted this year to it. It’s a huge encouragement to those of us who have been worrying about this problem for a very long time to know that now this government is going to do something about it.” The UK will host this year’s crunch UN talks on the climate crisis, known as COP 26, scheduled for Glasgow this November. But the launch of the government’s strategy got off to a troubled start, as the intended president of the talks, the former energy minister Claire O’Neill, was abruptly sacked late on Friday. For almost three decades, world governments have met every year to forge a global response to the climate emergency. Under the 1992 United Nations Framework Convention on Climate Change, every country on earth is treaty-bound to “avoid dangerous climate change”, and find ways to reduce greenhouse gas emissions globally in an equitable way. Cop stands for conference of the parties under the UNFCCC. The UK will host Cop26 this November in Glasgow. In the Paris agreement of 2015, all governments agreed for the first time to limit global heating to no more than 2C above pre-industrial levels, and set out non-binding national targets on greenhouse gases to achieve that. However, these targets are insufficient, and if allowed to stand would lead to an estimated 3C of heating, which scientists say would spell disaster. For that reason, the Cop26 talks in Glasgow are viewed as the last chance for global cooperation on the emergency, with countries expected to come with tough new targets on emissions. The negotiations will be led by environment ministers and civil servants, aided by UN officials. Nearly every country is expected to send a voting representative at the level of environment secretary or equivalent, and the big economies will have extensive delegations. Each of the 196 nations on earth, bar a few failed states, is a signatory to the UNFCCC foundation treaty. The Cops, for all their flaws, are the only forum on the climate crisis in which the opinions and concerns of the poorest country carry equal weight to that of the biggest economies, such as the US and China. Agreement can only come by consensus, which gives Cop decisions global authority. Fiona Harvey Environment correspondent That leaves a vacuum that will not be filled, perhaps for as long as a fortnight, as the appointment depends on a wider cabinet reshuffle. Former prime minister David Cameron was approached but declined the role. Possible other candidates are understood to include Michael Gove, a serving cabinet minister, and the former Tory party leaders William Hague and Michael Howard, both now in the Lords. O’Neill made a damaging intervention with a swingeing attack on the prime minister on BBC Radio 4’s Today programme on Tuesday morning, just before the launch. She accused Johnson of not understanding the climate emergency, of a lack of commitment and of being untrustworthy. Whitehall sources have been briefing that O’Neill had rows with her staff and gave contradictory opinions on the COP 26 talks when meeting other governments. O’Neill rebuffed these accusations in a letter to Johnson, saying: “No 10 is rumoured to be behind the media briefings put out to support your decision, which variously contained awful, false and distorted defamatory allegations. To take two examples: ‘bullying allegations’ were referred to, when you are aware that there was a single historical complaint, which was fully investigated by the Cabinet Office and found to be entirely without merit. Equally, reports of ‘problems on international engagements’ stemmed from a single blogpost which I believe can be completely rebutted by the emails.” High-ranking officials and people familiar with O’Neill’s work as COP 26 president in the few months since her appointment have said her performance has been mixed, with some criticising her for falling out with senior officials. Others have said she made a good impression on other governments at key meetings. Time is now running out, several people familiar with the talks warned. “We are certainly far behind where we should be now” in getting key countries on board, said one longtime observer of the climate negotiations. The mission for COP26 is to forge a new global consensus on the climate crisis. At Paris in 2015, all governments agreed for the first time to limit global heating to no more than 2C above pre-industrial levels, and set out non-binding national targets on greenhouse gases to achieve that. However, those national commitments are insufficient to meet the Paris goal, and if allowed to stand they would lead to an estimated 3C of heating, which scientists say would spell disaster. The world’s leading scientists, the Intergovernmental Panel on Climate Change, have warned that the world must drastically change direction in the next decade to have a hope of meeting the Paris goals. For that reason, this year’s talks are viewed as the last chance for global cooperation on the emergency. Countries are expected to come to Glasgow with stringent new targets on emissions. Johnson’s launch of the UK’s COP 26 strategy was intended to draw a line under the O’Neill row and move forward to an all-out diplomatic strategy to forge agreement among 196 nations, some of which are reluctant to come up with new targets and some of which are avowed opponents of the Paris accord. However, without a replacement for O’Neill, it looks hard to persuade people that the UK has really started on what is seen as one of the biggest international challenges this year. As one prominent attendee at the launch said: “We are getting no direction. That’s what’s missing here.”"
nan
"
Share this...FacebookTwitterSnowFan here reports on the latest winter forecasts for the 2020/21 Europe winter. History and statistics show Europe could be in for a frosty winter. 
Currently a significant La Nina is shaping up, and history shows that these events in the Pacific have an impact on Europe’s winters:

The NOAA reanalysis above shows the temperature deviations (left) and for precipitation (right) from the WMO average 1981-2010 during the six La Niña years of winter in Europe. Large parts of Europe have average temperatures and precipitation is distributed differently, with Germany being slightly drier overall than the WMO average. Is a 2020/21 winter in Germany under La Niña conditions shaping up to have average temperatures and slightly less humidity?
Strong winter-solar correlation
A more important factor determining winter in Europe may be solar activity. Data from the German DWD national weather service since 1954 show a remarkable higher frequency of cold winters in times of low solar activity, such as we are now in the midst of.
The following chart shows the December-January-February cold temperature anomalies occurring in the times of low solar activity (circled):

After the current minimum of solar activity in December 2019, statistically it leads us to expect a crisp winter 2020/21 – not only in Germany. Source: DWD time series with supplements.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




It could look like the chart below because the NOAA reanalysis shows the high statistical probability of cold winters in Europe during the weakest solar cycles after 1948. What follows is a chart showing the temperature anomalies for the winters occurring at times of low solar activity:

The winters in Europe since 1948 with the weakest solar activity so far have all been significantly colder than the 1981-2010 WMO climate average. The solar activity cycle ending in December 2019 was one of the weakest cycles ever since observations began. Source: NOAA reanalysis and long-term weather. 
But with the different statistical approaches, one thing already seems to be clear: The winter 2020/21 will probably not be particularly mild in Europe…
Also IRI expects cool 2020/21 winter
Last message: IRI continues to expect a rather supercooled winter 2020/21 in Central Europe with slightly more precipitation than average.

Like in September 2020, the IRI October forecast of Columbia University in New York also predicts a slightly cooler winter 2020/21 with slightly increased precipitation over Central Europe. Source: IRI Seasonal Forecast

Thanks to SnowFan for this report.


		jQuery(document).ready(function(){
			jQuery('#dd_61345aa3ea6c80009ddf1466cb136d50').on('change', function() {
			  jQuery('#amount_61345aa3ea6c80009ddf1466cb136d50').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"

While doom and gloom predictions continue about CO2 induced global warming, saying that it now is the largest driver of climate, overwhelming any influences of the suns variation, there appear to be other things happening. There are forecasts emerging for a wet and cold winter.
Lets review. We have a longer than normal solar minimum occurring, and we have a strong La Niña developing too. We have colder water in the Pacific.
Here is a animated view of the growing La Niña. Watch the animation, note the exapnding La Niña off the west coast of South America, note also the expanding pool of cooler water developing the Gulf of Alaska. This will be a key formation point for cold wet storms.
And there are other signs too. Acorns. Have you noticed this year we have an overabundance of acorns? I was walking in Bidwell Park a couple of weeks ago and the ground was covered with them, and they were still raining down like hailstones. I’ve never seen anything like it. This has been what biologists call a “mast year” for valley oaks.
While this may sound a bit like an “Old Farmers Almanac” moment, but I have a theory for it.
Trees are directly in touch with the sun, more so than other living things in the biosphere. Our “valiant” dendroclimatologists, like Michael Mann, point to tree rings as a proxy for earths climate. That may be true, but I think in addition to “treemometers” they also act as helioproxies too.
In a nutshell (ahem); I think it’s highly likely that trees have evolved survival strategies that are based on detecting changes in the sun’s output. It stands to reason that over the billion plus of years that plant life has been on earth and the millions of solar cycles they’ve been through, that they can detect changes in their primary energy source, the sun, and adapt accordingly. Producing abundant acorns could well be such a survival strategy.
We have strong signs of a solar cycle that is late and well below average, a near record low hurricane season, and a strong La Niña emerging.  Now we have valley oaks producing acorns like there is no tomorrow. Maybe we should heed the trees.
h/t Russ Steele at NCwatch for the animation for forecast links


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea315f833',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea35292fa',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

According to Sir David Attenborough, the famous British broadcaster and naturalist, “humans are threatening their own existence and that of other species by using up the world’s resources.” In a recent interview, Attenborough said that “the only way to save the planet from famine and species extinction is to limit human population growth.”   




We are a plague on the Earth,” he continued. “It’s coming home to roost over the next 50 years or so. It’s not just climate change; it’s sheer space, places to grow food for this enormous horde. Either we limit our population growth or the natural world will do it for us, and the natural world is doing it for us right now… We keep putting on programmes about famine in Ethiopia; that’s what’s happening. Too many people there.



In 2006, Sir David Attenborough was voted Britain’s greatest living icon. Popularity, however, is no substitute for wisdom. As I have explained in a previous blog post, “[The] rate of global population growth has slowed. And it’s expected to keep slowing. Indeed, according to experts’ best estimates, the total population of Earth will stop growing within the lifespan of people alive today. And then it will fall… the long‐​dreaded resource shortage may turn out not to be a problem at all.”   
  
  
Some of the reasons why Attenborough is as mistaken about the “over‐​population problem” today as Paul Ehrlich was when he published his infamous The Population Bomb in 1968, include:   




What is to be said about Attenborough’s take on the famine in Ethiopia? In a word: embarrassing.   
  
  
To start with, population density in Monaco is 17,676 people per square kilometer. It is 79 people per square kilometer in Ethiopia. Monaco is one of the richest countries in the world and Ethiopia one of the poorest. If anything, there is an inverse relationship between population density and poverty. Some of the world’s most populated places (Hong Kong, Singapore, The Netherlands, etc.) are very rich, while some of the least heavily populated countries (Central African Republic, Chad, the two Congos, etc.) are very poor.   
  
  
The real reasons for Ethiopian famines are altogether different. First, Ethiopia was a Marxist dictatorship and like many Marxist dictatorships (USSR, PRC and Cambodia), it experienced both economic collapse and civil war. Second, Ethiopia has almost no economic freedom. All land, to give one example, is owned by the state – and the state can take it away. As a consequence, farmers have little incentive to make long term plans and undertake necessary investment, and agricultural production suffers.   
  
  
Attenborough is, in many ways, a great man and I love watching his programs. But, he thinks he knows more than he does. A little intellectual humility would not be amiss.   
  
  

"
"
U.S. Senate Report: Over 400 Prominent Scientists Disputed Man-Made Global Warming Claims in 2007 
from this link:
http://epw.senate.gov/public/index.cfm?FuseAction=Minority.SenateReport
The variety and reach of this is quite large. This is a report gathered from many independent publications, it is not one of those “Internet Petitions” which can be easily loaded up with fake names by those that seek to minimize it.
I think the gist of this is that the pronouncements of “the science is settled”, the “debate is over” and “scientific consensus” may be a bit premature.
Of course I’m sure we’ll have those that will denounce this for a variety of the usual reasons, such as the favorite “they are all employed or supported by the fossil fuel industry”.  But given the diversity on this list that will be pretty hard to prove.
For those interested in my work on the www.surfacestations.org project, this set of preliminary data posted here on 460 out of 1221 USHCN climate stations in the continental USA pretty well sums it up:

 


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea203e59c',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterFormer Tropical Storm Edouard brings bitter temperature drop to Germany
By Kalte Sonne
(Translated/edited and image added  by P. Gosselin)
Stupidity clicks well in Germany. Alarmist messages about tropical storm Edouard now running through the Internet on numerous websites have been no better in quality than the earlier reports of an impending summer of heat shocks (The opposite has been true so far this summer).
On the other hand, reports like those by Fabian Ruhnau of Kachelmannwetter are beneficial, which assess former tropical strom Edouard somewhat differently, without neglecting the powerful thunderstorms:
“On Friday, a small, but rather weather-intensive low-pressure system will sweep over Northern Germany. It is ‘formerly EDOUARD’, the low was once a tropical storm, but is now just a normal low. In the run-up to the cold front, hot air reaches the south and southeast, where powerful thunderstorms can form. During the weekend the weather will calm down and get colder again.”

Image cropped from kachelmannwetter.com 
The kneejeck digital excitement and constant alarms are clearly a sign of our times. But a very dangerous one, because permanent alarm dulls the senses.
 
Share this...FacebookTwitter "
nan
"

Seven years ago, Rand Simberg, an adjunct scholar at the Competitive Enterprise Institute (CEI), wrote a blog post criticizing the work of Dr. Michael E. Mann, a climatologist at Penn State University and a noted global warming doomsayer. Mann helped create the famous “hockey stick graph,” which shows temperatures spiking in the 20th century, and he was implicated in the famous “Climategate” scandal, when hackers obtained emails from the Climate Research Unit at the University of East Anglia. One of those emails described “Mike’s nature trick,” referring to the splicing together of different temperature data to “hide the decline” in global temperatures. The emails created enough controversy that investigations into Mann’s work were launched by Penn State and the National Science Foundation, both of which cleared him of any wrongdoing.



Simberg wrote that many in the skeptic community regarded the Penn State investigation as a “whitewash” because “university circled the wagons and narrowed the focus of its own investigation to declare him ethical.” He then used unfortunate language to compare the investigation to the then‐​ongoing Jerry Sandusky scandal, writing that Mann could be said to be “Jerry Sandusky of climate science, except for instead of molesting children, he has molested and tortured data in the service of politicized science.” He raised the Sandusky comparison because Penn State’s investigation had concluded that “in order to avoid the consequences of bad publicity” the university’s top officials had “repeatedly concealed critical facts relating to Sandusky’s child abuse from authorities.” Simberg asked if the university could be expected to “do any less to hide academic and scientific misconduct, with so much at stake” in terms of reputation and funding.



Michael Mann sued CEI, Simberg, National Review, and Mark Steyn for defamation (Mark Steyn had linked and quoted Simberg’s post in a National Review post), claiming that the accusations of scientific misconduct and data manipulation and molestation were false statements of fact (rather than opinion) that defamed his reputation as a scientist. Surprisingly, the DC Court of Appeals, which is like the state supreme court for DC, allowed the case to go forward despite the clear and disturbing First Amendment implications. Now the case is on petition to the Supreme Court. Cato has filed for the fourth time in this case, now joined by the Individual Rights Foundation and the Reason Foundation, and we’ve asked the Court to stop this dangerous case from going forward.



Defamation is one of the categories of speech unprotected by the First Amendment, and it is very important that courts keep those categories narrow or a lot of protected speech could be censored or chilled. When speech is about an ongoing debate of significant public concern, as is the case here, courts should be wary of those who want to use defamation law to shut down public debate. Mann, who has described climate change “deniers” as “shills for the fossil fuel industry,” was exonerated by the investigations into his conduct, but Simberg disagreed. The DC Court of Appeals, however, put undue weight on the investigations into Mann and other climate researchers. In the court’s view, the investigations showed not only that the allegation of “scientific misconduct” was “capable of being proved true or false, but the evidence of record is that it actually has been proved to be false by four separate investigations.”



Questioning an investigation that purports to exonerate a controversial figure should not give rise to an actionable defamation claim. Calling O.J. Simpson a murderer is not defamation because he was acquitted by a jury. Saying that someone who was exonerated by the Warren Commission did in fact have role in the Kennedy assassination is not defamation either. If this case is allowed to stand if will be the law in the District of Columbia, the pulsing heart of our political discourse. Those who arrive at conclusions contrary to official reports or investigations will be too easily subject to possible defamation suits. The Supreme Court should take the case to ensure that people can’t use courts to shut down public debate.  

"
"

The Cato Institute will sponsor a week‐​long seminar near San Diego from August 1 to 7, 1999, as part of its Cato University program. Cato Sponsors will be invited to participate in the program featuring lectures and discussions on American history, law, economics, and philosophy.



Cato University allows busy adults to explore the fundamental ideas of liberty and limited government. In addition to the seminars, there is a separate 12‐​month home‐​study course that uses audiotapes, books, and an integrated study guide.



Faculty at the week‐​long program will include Alan Charles Kors, professor of history at the University of Pennsylvania and coauthor of The Shadow University; Randy Barnett, professor of law at Boston University and author of The Structure of Liberty; Don Boudreaux, president of the Foundation for Economic Education; and Tom G. Palmer, director of Cato University.



Guest lecturers will include historian Paula Baker of the University of Pittsburgh; psychologist Nathan‐​iel Branden, author of Taking Responsibility; and philosopher Christina Hoff Sommers, author of _Who Stole Feminism?_ Cato’s Edward H. Crane, David Boaz, Ted Galen Carpenter, and Robert Levy will also speak. 



In announcing the August seminar, Palmer said, “This program gives you the chance to recapture the intense intellectual atmosphere of your college days, in a climate where the lecturers and other participants share your fundamental ideas about freedom and justice. The schedule of lectures and discussions is designed to impart a great deal of information and analysis and encourage spirited discussion about the implications of the basic ideas.”



Cato University will be held at the beautiful Rancho Bernardo Inn, about 20 minutes from downtown San Diego. It will begin with dinner on Sunday, August 1, and conclude with lunch on Saturday, August 7. The cost, which includes all lectures and discussions, all meals, six nights in the inn, and a set of readings, is $1,500. Some scholarships are available for full‐​time students.



All Sponsors will receive a seminar brochure soon. Check the Web site at www​.cato​-uni​ver​si​ty​.org for more information or to register online, or call 202–789-5296. 



_This article originally appeared in the March/​April 1999 edition of_ Cato Policy Report.   
Full Issue in PDF  (16 pp., 317 Kb)
"
"

My coffee buddy, Butte County Sheriff Perry Reniff helps Alexis Dominguez exit the helicopter (Photo: Bill Husa, Chico Enterprise Record)
 Today was a good day. No, strike that, today was a GREAT day!
The saga of the Dominguez family lost in the snow looking for a Christmas tree hit home with me in a big way, because I had people from all over asking me what the weather was going to do to the search and rescue effort. I was the bearer of bad news, which I hated, because the winter storm bearing down made survival even less likely.
(Note: for national/international readers of this blog, this story unfolded in my home city and county)
Mountain weather is unforgiving. Fortunately, they knew what to do. They improvised a snow cave, wrote “HELP” in the snow, and stayed put until rescuers could find them. When they did, the relief was nation-wide.
Yes, its the best Christmas present anybody could ever have.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea213c461',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterWind energy investment plummeted in the third quarter of this year in Germany, reports the online IWR here.
“The nine-month figures now available make it clearer that this trend will continue in 2020,” writes the IWR.
Issued construction licenses drop 70 percent in 3 years
Installation of wind energy in Germany peaked in 2017 (see bar chart here), but has since fallen sharply after the German federal government enacted new rules and regulations against their construction.
According to Clean Energy Wire here,
An analysis by energy industry lobby group BDEW found that the falling number of permits issued for onshore wind turbines was the main factor behind the decline, with issued licenses dropping by 70 percent over three years. About 11 GW, roughly 2,000 turbines, were stuck in bureaucratic procedures as of mid-2019.”
In the third quarter of 2020, only 85 turbines with a total capacity of 293 MW were installed. Germany has approximately 30,000 turbines operating.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In the first nine months of 2020, only a total of 306 new wind turbines  (1,104 MW) were added.
The IWR forecasts 1200 MW of new onshore wind energy capacity to be added for the full year 2020. In 2019 the figure was slightly lower at 1,078 MW. The slight increase, the IWR reports “is not sufficient to compensate for the decline in offshore wind energy.”
“Overall, it is thereforeexpected that the total increase in new wind power capacity in the current year will again be significantly weaker than in the already weak previous year 2019.”
Green energy expansion “being totaled”, a “farce” 
Green energy lobbyist Volker Quaschning at Twitter sees Germany’s green energy expansion as being “totaled” and the country’s promises of climate protection as “a farce”

Totalschaden mit Ansage: Ausbau der #Windkraft bricht noch weiter ein. So werden alle deutschen #Klimaschutz-Versprechen zur Farce. Lieber @peteraltmaier, @BMWi_Bund: Wann sorgen Sie endlich dafür, dass wenigstens Ihre Ausbauziele eingehalten werden? https://t.co/5JhhFYoUml
— Volker Quaschning (@VQuaschning) October 6, 2020



		jQuery(document).ready(function(){
			jQuery('#dd_a568152ecfe8f688295399cd73262f09').on('change', function() {
			  jQuery('#amount_a568152ecfe8f688295399cd73262f09').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"

After the Second World War, the entrepreneur virtually disappeared from economic analysis (Baumol 1968). This neglect followed from the emerging models of general equilibrium that formed one aspect of the core of economic theory.1 By assumption, the Walrasian auctioneer knew the appropriate prices necessary to equate quantity supplied with quantity demanded in each market. In addition, the auctioneer knew when and by how much to adjust prices when an exogenous factor changed such as income or production technology. Trade only occurred at equilibrium prices so that markets cleared. No market participant chose or changed prices; it occurred exogenously.



Kenneth Arrow recognized the lack of real world mechanisms to determine and adjust prices in competitive markets. He identified a logical gap in the perfectly competitive model. He wrote that “there is no place for a rational decision with respect to prices as there is with respect to quantities” (Arrow 1959: 42). Prices exist independent of consumer and firm behavior. A complete model would have to provide a solution to the conundrum.2



Israel Kirzner (1967, 1971, 1973) responded to Arrow’s challenge. He argued for the reintroduction of the entrepreneur into economic analysis in order to explain how markets work. He offered a novel interpretation of the role of the entrepreneur in explaining how markets adjust to changes in conditions. Entrepreneurs recognized profit opportunities that no one else had. What appeared as an equilibrium price was not; it was a disequilibrium price that once recognized would yield profits. The fundamental aspect of entrepreneurship is alertness. Entrepreneurs, wrote Kirzner (1997: 72), notice “hitherto unnoticed profit opportunities” that arise from disequilibrium prices.



Kirzner did not devote many pages in his writings to discussing economic development. He focused on microeconomic processes, especially those pertaining to the mechanisms necessary to attain or approach equilibrium states. He devoted less time to understanding the role of entrepreneurship in explaining the differences in income per capita around the world. However, early in the development of his theory of entrepreneurship, he did critically examine the role of the entrepreneur in explaining comparative economic development.



In “Entrepreneurship and the Market Approach to Development,” Kirzner (1971) offered a definition of the entrepreneur that predated his more well‐​known 1997 definition. He argued that development economics in the 1960s, outside of the Schumpeterian variety, did not include the entrepreneur and, as a result, explanations regarding the differences in income around the world were not adequate. Like general equilibrium models, models of economic development lacked an endogenous source of innovation, invention, and resource reallocation.



Kirzner’s critique of development economics included a citation to P.T. Bauer and Basil Yamey’s 1957 book, _The Economics of Under‐​Developed Countries_. He argued that their contribution missed the central feature of entrepreneurship—namely, alertness to new opportunities to make a profit. I disagree. Indeed, Bauer and Yamey (1957: 106) identified the same aspect of entrepreneurship that Kirzner would later stress—”hitherto unsuspected opportunities for profitable economic activity.” Even though Kirzner (2005: 465) referred to the Bauer‐​Yamey book as a “classic” in development economics, he failed to fully recognize the pioneering contributions they made to understanding the true nature of entrepreneurship.



Neoclassical economics, as characterized by Arrow‐​Debreu general equilibrium, does not explain how prices emerged from the trading process. Prices existed prior to exchanges. The Walrasian auctioneer knew the necessary information regarding consumers’ preferences and information as well as the cost curves facing the firms. After collecting all the information, the auctioneer identified the vector of prices necessary to clear markets. Trade only occurred after prices were announced. Arrow identified this puzzling aspect of neoclassical theory; it lacked a theory of how prices change in a competitive market: “Each individual participant in the economy is supposed to take prices as given and determine his choices as to purchases and sales accordingly; there is no one left over whose job its is to make a decision on the price” (Arrow 1959: 43). Prices existed independent of the decisions of individuals. No one within the model set or changed prices.



Interest in the entrepreneur increased in development eco­nomics in the early 1960s as alternatives to general equilibrium theorizing appeared. Irma Adelman (2001) argued that entrepreneurship became the central variable in development policy from 1958 to 1965, while McClelland (1961), Hagen (1963), Baumol (1968), and Leibenstein (1968) each offered their own attempt to include the entrepreneur. Peter Kilby (1971) identified no less than 13 aspects of entrepreneurship related to economic development. Entrepreneurship appeared on the intellectual agenda but its essential component—alertness—did not.



Kirzner (1971) developed the arguments that would later appear in _Competition and Entrepreneurship_ (1973). He criticized development and growth economics for misunderstanding the role of the entrepreneur:



In a footnote following the above quote, Kirzner cites Bauer and Yamey (1957). He includes them in the group of economists who have discussed entrepreneurship but failed to address its central feature of alertness—perceiving hitherto unnoticed profit opportunities. He should not have, because Bauer and Yamey identified the central aspect of entrepreneurship that Kirzner stressed. They, too, recognized and discussed entrepreneurial alertness.



Kirzner goes on to argue that:



Kirzner recognized the importance of the entrepreneur in explaining economic growth and development as did many others in the 1960s. Unlike the others, Kirzner identified an aspect of entrepreneurship they did not. In order for economies to grow, someone had to grasp “the knowledge which might otherwise remain unexploited” (Kirzner 1971: 197). But Kirzner was not the first to recognize the importance of alertness.



Although much of development economics in the 1950s and 1960s neglected the entrepreneur, the contributions of P. T. Bauer and Basil Yamey did not. Rather, they emphasized the importance of the entrepreneur in their earliest writings. Bauer clearly identified entrepreneurship as a vital but neglected aspect of orthodox development economics. His early studies on trade in West Africa (Bauer 1954) provided ample evidence that entrepreneurship was omnipresent and was vital in understanding how economies evolve from low to high levels of income per capita. For example, Bauer (1954: 30) wrote that the trader‐​entrepreneur (as he referred to entrepreneurs) in Nigeria and the Gold Coast exhibited the following characteristics: “exceptional effort, foresight, resourcefulness, thrift and the ability to perceive economic opportunity.” Trader‐​entrepreneurs, at least those in Nigeria and the Gold Coast, perceived profit opportunities. They were alert. Entrepreneurs recognized the gains that emerged from changes in relative scarcities, new information, new ideas, or serendipity.



In other writings, Bauer continued to argue that the trader‐​­entrepreneurs existed throughout the developing world. His fieldwork in sub‐​Saharan Africa provided plenty of evidence. According to Bauer ([1963] 1972: 347), “The prominence of foreigners in African commerce reflects technical and administrative skills, thrift, [and] the ability to perceive and take advantage of economic opportunity.” Once again, entrepreneurs perceive economic opportunity when it arises. They do not simply respond to a given set of prices, production techniques, or information. Entrepreneurs engage in more than arbitrage. They recognize profit opportunities no one else had and develop new means to attain their goals.



Bauer and Yamey (1957) offered a comprehensive discussion of the source of economic development that extended beyond conventional models at the time that stressed capital formation or the rate of savings. They stressed a number of factors including the quality of public institutions and policies, the importance of international and intranational trade, values, and attitudes. More importantly, central to their argument, they stressed entrepreneurial alertness and its perception of “hitherto unsuspected opportunities.”



Bauer and Yamey began their discussion of the entrepreneur by noting that entrepreneurship occurs quietly through small changes that raise productivity. Better knowledge of prices and costs allow the entrepreneur to make profits. Knowledge of productivity increasing techniques also represents an aspect of entrepreneurship. But they extended entrepreneurship beyond greater knowledge of existing conditions. In some cases, it leads to significant changes. In particular, “Innovation and the exercise of entrepreneurship in the sense of creating or taking advantage of _hitherto unsuspected opportunities for profitable economic activity_ are often dramatic in their impact,” wrote Bauer and Yamey (1957: 102, emphasis added). They went on to argue that “the ability of individuals to perceive new opportunities for profit and the ability and willingness to exploit them are indeed crucial in economic development” (ibid.). From these passages, it is clear that Bauer and Yamey held views similar to those of Kirzner regarding the central features of entrepreneurship.



Bauer and Yamey (1957: 102) pointed to how entrepreneurs help generate new ideas and new techniques that foster economic development:



Kirzner’s contribution to the theory of entrepreneurship clearly has its antecedents in the works of Bauer and Yamey. Yet, their contribution appears to have been forgotten. There is no mention of their pioneering work on entrepreneurship in Kirzner’s seminal book, _Competition and Entrepreneurship_ (1973); nor in Kirzner’s 1997 _Journal of Economic Literature_ article, which is a survey of his theory of entrepreneurship. Neverthelss, in Kirzner’s (2005) contribution to a conference volume in honor of Bauer after his death, he called Bauer and Yamey’s 1957 book a “classic.”



Bauer and Yamey’s (1957) identification of entrepreneurship with “hitherto unsuspected opportunities for profitable economic activity” prior to Kirzner does not imply that he did not make a scientific contribution to the theory of entrepreneurship. Originality is only one aspect of scientific progress. As George Stigler (1955: 294) noted, “Scientific originality in its important role should be measured against the knowledge of a man’s contemporaries. If he opens their eyes to new ideas or to new perspectives on old ideas, he is important in the scientifically important sense.”



Even though Bauer and Yamey identified an aspect of entrepreneurship that had eluded development economists and the profession more broadly, Kirzner’s discussion opened the eyes of others. For example, Schultz (1975, 1990) developed an alternative theory of entrepreneurship that emphasized the role of human capital partially in response to Kirzner in order to better understand the process of economic development. Moreover, Baumol (1990) differentiated between productive and unproductive entrepreneurship, and differentiated his approach from Kirzner’s. Although, Bauer and Yamey emphasized the role of entrepreneurship in explaining the process of economic development, Kirzner brought a new perspective to an old idea.



Adelman, I. (2001) “Fallacies in Development Theory and Their Implications for Policy.” In G. Meier and J. Stiglitz (eds.), _Frontiers of Development Economics: The Future in Perspective_ , 103–34. New York: Oxford University Press.



Arrow, K. J. (1959) “Toward a Theory of Price Adjustment.” In M. Abramovitz et al. (eds.), _The Allocation of Economic Resources: Essays in Honor of Bernard Francis Haley_ , 41–51. Stanford, Calif.: Stanford University Press.



Bauer, P. T. (1954) _West African Trade: A Study of Competition, Oligopoly and Monopoly in a Changing Economy_. Cambridge, UK: Cambridge University Press.



__________ ([1963] 1972) “The Study of Underdeveloped Economies.” In _Dissent on Development_ , chap. 8. Cambridge, Mass.: Harvard University Press.



Bauer, P. T., and Yamey, B. (1957) _The Economics of Under‐​Developed Countries._ Chicago: University of Chicago Press.



Baumol, W. (1968) “Entrepreneurship in Economic Theory.” _American Economic Review_ 58: 64–71.



__________ (1990) “Entrepreneurship: Productive, Unproductive, and Destructive.” _Journal of Political Economy_ 98: 893–921.



Fisher, F. M. (1983) _Disequilibrium Foundations of Equilibrium Economics_. New York: Cambridge University Press.



Gintis, H. (2007) “The Dynamics of General Equilibrium.” _The Economic Journal_ 117 (October): 1280–1309.



Hagen, E. (1963) “How Economic Growth Begins: A Theory of Social Change.” _Journal of Social Issues_ 19 (1): 20–34.



Kilby, P. (1971) “Hunting the Huffalump.” In P. Kilby (ed.), _Entrepreneurship and Economic Development_ , 1–40. New York: Free Press.



Kirzner, I. M. (1967) “Methodological Individualism, Market Equilibrium, and Market Process.” _Il Politico_ 32: 787–99.



__________ (1971) “Entrepreneurship and the Market Approach to Development.” In F. A. Hayek et al. (eds.) _Toward Liberty: Essays in Honor of Ludwig von Mises_ , Vol. 2, 194–208. Menlo Park, Calif.: Institute for Humane Studies.



__________ (1973) _Competition and Entrepreneurship_. Chicago: University of Chicago Press.



__________ (1997) “Entrepreneurial Discovery and the Competitive Market Process: An Austrian Approach.” _Journal of Economic Literature_ 35 (1): 60–85.



__________ (2005) “Human Attitudes and Economic Growth.” _Cato Journal 25_ (3): 465–69.



Leibenstein, H. (1968) “Entrepreneurship and Development.” _American Economic Review_ 58: 72–83.



McClelland, D. (1961) _The Achieving Society_. Princeton, N.J.: Van Nostrand.



Schultz, T. (1975) “The Value of the Ability to Deal with Disequilibria.” _Journal of Economic Literature_ 13: 827–46.



__________ (1990) _Restoring Economic Equilibrium: Human Capital in the Modernizing Economy._ Williston, Vt.: Basil Blackwell.



Stigler, G. (1955). “The Nature and Role of Originality in Scientific Progress.” _Economica_ 22: 293–302.



Yates, A. (2000) “The Knowledge Problem, Entrepreneurial Discovery, and Austrian Market Process Theory.” _Journal of Economic Theory_ 91: 59–85.



J. Robert Subrick is Associate Professor of Economics at James Madison University.



ShowHide

Endnotes



1 Keynesian macroeconomics formed another prominent aspect of economic theory. It too lacked any use for an entrepreneur as it focused on the movement of statistical aggregates with little concern about the underlying microeconomic processes.



2 Few have followed up on Arrow’s concerns. See Fisher (1983), Yates (2000), and Gintis (2007) for exceptions.
"
nan
"
According to my stat counter, the Projects Page tab above has been getting a regular stream of interest, so it has been updated with relevant content as of today 10/22/07


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea3457f2b',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"It is the middle of the 2040s. After years of warning, scientists have just confirmed that the tipping point for the West Antarctic Ice Sheet has been triggered. Governments around the world are horrified as the news filters through. The days when they could reverse climate change by cutting carbon emissions to reduce global temperatures have just come to an end. There is now no way of stopping global sea levels from rising by over four metres. Nations and islands around the world are about to be lost forever.  It’s not real life – not yet anyway – but a computer game being played by a group of delegates and other attendees at the UN COP24 Climate Change conference in Katowice, Poland. Earth Remembers plays a bit like a 30-person version of Football Manager. Closely mirroring the real-life world climate change negotiations that take place every six months, each affected player represents a different country and has to negotiate with everyone else about how they’ll spend their national budget.  The game is the brainchild of a collaboration between undergraduates and academics from Glasgow Caledonian University, Utrecht University and the Purdue Climate Change Research Centre in Indiana. It uses an IPCC climate model to simulate the effects of each decision on carbon emissions, national GDP and the global temperature. Each turn skips forward five years, enabling players to “live” through the plausible future scenarios of 2033, 2038, 2043 and onwards out to 2118 to see how their decisions affect the world. The idea of using computer games, known as applied games, to help educate people goes back decades. Some might remember the “edutainment wave” of the 1990s, typified by games like Math Blaster (1994), where players had to do sums to release a tractor beam to pick up space rubbish.  Not only were such titles usually mediocre, the whole approach saw games as a kind of spoonful of sugar to make the nasty medicine of learning go down. It was bad teaching hiding inside bad games, and players were not usually fooled for long.  Fortunately, modern applied games are designed with a much better understanding of what makes games special. One of the best is the space exploration simulator Kerbal Space Program (2011). The object is to create a space programme for a race of little green humanoids called Kerbals. Players are encouraged to experiment and be creative. Once they have built the necessary equipment, they fly it with a simulator based on a realistic physics model.  The game wasn’t originally designed for educational purposes. But after NASA decided to back it, the developers created a version aimed at classrooms. Only by grappling with real-world trade offs between rocket components, life-support systems, fuel and weight, can players get the Kerbals to their nearest moon, the “Mun”, and then back in one piece.  Earth Remembers was designed with the same sense of jeopardy in mind. Should a country’s budget be spent on researching new green technologies that could, for example, extract carbon from the atmosphere and sink it in the ground? Should it be spent reducing greenhouse-gas emissions with investments in green energy sources or on adapting to the impacts of climate change? When events trigger in the game, each player/nation is given an event card that describes what has happened to their country. In one game, for example, the US was told that Miami’s coastline had seen significant flooding as a result of the ice sheet melt and that millions of residents were going to have to be moved further inland at great cost to the country. Meanwhile, other nations were coming to terms with news that certain industries had been dealt a massive blow.  The whole point is to use narrative storytelling and imagination to make the human and economic cost of these events more concrete. As the Dutch psychologist Nico Frijda convincingly argued, people have emotional reactions to what is apparently real – not to what actually is real. Games give us a platform to create just such an apparent reality.  The final part of our game shifts 100 years into the future, and players are presented with scenarios derived from the decisions they have made. The Fijian people no longer reside in Fiji, for instance, but in a part of Australia renamed by one participant “Fijiland”. This prompted discussions about the challenges of identity loss, whether this community should be a separate nation, and who was responsible for this situation.  Our trip to Katowice was the second time we’d simulated the game, having previously demonstrated it to negotiators at the climate change talks in Bonn, Germany in the spring. When the West Antarctic Ice Sheet collapsed in one of the games in Katowice, the sense of alarm in the room was palpable. We got great feedback from players about the way the game made tipping points like this one much more real. Negotiators will hopefully have kept this in mind when it came to the real-life discussions.  Next for us is to demonstrate Earth Remembers for scientists and policy specialists in Washington, DC in a few days’ time. We are also hoping to develop further enhancements to the game. This is where the potential of applied games lies: in mixing together the scientific and the artistic; the rational and the emotional. Do this well and you have the potential to create meaningful change – and maybe even help avert disaster in the process."
nan
"
Share this...FacebookTwitterA new assumption about carbon budgets reveals climate scientists have been vastly underestimating (by a factor of 2) the amount of carbon absorbed by the ocean for decades. Every past carbon budget estimate has been twice as wrong as the current estimate.
When it comes to the ocean heat fluxes and source vs. sink carbon budget estimates, climate scientists have been providing little more than educated guesses for decades.
For example, climate models have long suggested the ocean heat fluxes may only vary around 1 W/m². But “objective” analyses of oceanic latent heat flux (LHF) using different assumptions (equations) reveals fluxes were likely closer to 10 W/m² during 1981-2005 (Yu and Weller, 2007). So our modeled guesses were off by a factor of 10 compared to newer analyses.

Image Source: Yu and Weller, 2007
Ocean carbon sink processes not understood and driven by natural variability
McKinley et al. (2017) analyzed ocean carbon sink estimates and was willing to admit that due to a lack of observation, we lack a “detailed, quantitative, and mechanistic understanding of how the ocean carbon sink works…”
In addition, because internal variability in oceanic carbon uptake is so massive and largely unobserved, we cannot yet detect an anthropogenic influence.
McKinley and co-authors go so far as to acknowledge the “change in CO2 flux over 10 years (1995-2005)…is due almost entirely to the internal variability” because in most ocean regions “the forced [human-induced] trends in CO2 flux are too small to be statistically significant” and the “variability in CO2 flux is large and sufficient to prevent detection of anthropogenic trends in ocean carbon uptake on decadal timescales.”

Image Source: McKinley et al. (2017)
The Southern Ocean absorbs more than 10 times less carbon than previously thought


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Southern Ocean is where the largest portion of anthropogenic carbon (from our emissions) is said to be absorbed, or Earth’s largest oceanic CO2 sink.
Just 2 years ago, a carbon uptake analysis (Gray et al, 2018 with a Physics Today press release) that utilized estimates from biochemical floats instead of estimates from ships suggested the exact opposite of what had been previously thought. Instead of absorbing close to 1 petagram of carbon (PgC) per year, the Southern Ocean is barely even a carbon sink at all – just 0.08 PgC of yearly absorption. In fact, large regions of the Southern Ocean near Antarctica are a net source of CO2 to the atmosphere.
In other words, when estimates are float-based rather than ship-based, one estimate is more than 10 times different than the other.

Image Source: Physics Today
The global ocean absorbs 2 times more CO2 than previously thought
And now a new study (Buesseler et al., 2020) has scientists insisting that all of our previous estimates of global ocean carbon uptake are substantially wrong because we’ve been measuring from a fixed depth rather than varying depths.
Previously scientists had been using flux estimates from the “canonical fixed 150-m depth.” The new-and-improved way to assess carbon uptake is from varying but often much shallower depths: the euphotic zone (Ez). This is the section of the upper ocean layer that sunlight is able to penetrate, and it can “vary from less than 20 m to almost 200 m” in depth.
When we use the Ez to estimate carbon absorption versus export, the absorption changes from 2.8 petagrams of carbon (PgC) per year to 5.7. So the global ocean sink can be more than doubled just by varying the depth of measurement rather than using a fixed depth.
So, up to this point, scientists’ past guesses about ocean carbon uptake have been emphatically wrong. We can be assured, though, that our current guesses are anywhere from 2 to 10 times less wrong than the last ones.

Image Source: Buesseler et al., 2020 and press release
Share this...FacebookTwitter "
"Where the Iron Curtain once divided Europe with barbed wire, a network of wilderness with bears, wolves and lynx now thrives. Commemorating 100 years since the end of World War I, people wear poppies to evoke the vast fields of red flowers which grew over the carnage of Europe’s battlefields. Once human conflict has ended, the return of nature to barren landscapes becomes a potent symbol of peace. These tragedies, which force people away from a place, can help ecosystems replenish in their absence. Though rewilding is typically considered an active decision, like the reintroduction of wolves to Yellowstone National Park, abandoned rural land often returns to wilderness of its own accord. Today, as people vacate rural settlements for life in cities, accidental rewilding has meant large predators returning to areas of Europe, long after they were almost made extinct.  Sudden changes, such as the the Chernobyl nuclear power plant disaster in 1986, result in wildlife recolonising exclusion zones in previously developed areas. Warfare can also result in human exclusion, which might benefit wildlife under specific conditions. Isolation and abandonment can generate wild population increases and recoveries, which has been observed in both terrestrial and aquatic ecosystems. Fish populations in the North Atlantic benefited from World War II as fishing fleets were drastically reduced. Fishing vessels were requisitioned by the navy, seamen were drafted and the risks of fishing due to enemy strikes or subsurface mining deterred fishermen from venturing out to sea. As a result, the war essentially created vast “marine protected areas” for several years in the Atlantic Ocean. After the war, armed with faster and bigger trawlers with new technology, fishermen reported bonanza catches. A more gruesome result of World War II allowed opportunistic species such as the oceanic whitetip shark to flourish, as human casualties at sea proved a rich and plentiful food source. Warship wrecks also became artificial reefs on the seabed which still contribute to the abundance of marine life today. The 52 captured German warships that were sunk during World War I between the Orkney mainland and the South Isles, off the north coast of Scotland, are now thriving marine habitats. Exclusion areas, or “no mans lands”, which remain after fighting has ended may also help terrestrial ecosystems recuperate by creating de facto wildlife reserves. Formerly endangered species, such as the Persian leopard, have re-established their populations in the rugged northern Iran-Iraq frontier. An uneasy post-war settlement can create hard borders with vast areas forbidden to human entry. The Korean Demilitarised Zone is a 4km by 250km strip of land that has separated the two Koreas since 1953. For humans it is one of the most dangerous places on Earth, with hundreds of thousands of soldiers patrolling its edges. For wildlife however, it’s one of the safest areas in the region.  Today, the zone is home to thousands of species that are extinct or endangered elsewhere on the Korean peninsula, such as the long-tailed goral. Miraculously, even habitats scarred by the most horrific weaponry can thrive as places where human access is excluded or heavily regulated. Areas previously used for nuclear testing, such as the Marshall Islands in the Pacific Ocean have been recolonised by coral and fish, which seem to be thriving in the crater of Bikini Atoll, declared a nuclear wasteland after nuclear bomb tests in the 1940s and 50s. For all the quirks caused by abandonment, warfare overwhelmingly harms human communities and ecosystems with equal fervour. A review of the impact of human conflict on ecosystems in Africa showed an overall decrease in wildlife between 1946 and 2010.
In war’s aftermath, natural populations were slow to recover or stopped altogether as economic hardship meant conservation fell by the wayside. Humans often continue to avoid a “no mans land” because of the presence of land mines. But these don’t differentiate between soldiers and wildlife, particularly large mammals. It’s believed that residual explosives in conflict zones have helped push some endangered species closer to extinction.  However, where possible, accidental rewilding caused by war can help reconcile people after the fighting ends by installing nature where war had brought isolation. There is hope that should Korea reunify, a permanently protected area could be established within the current demilitarised zone boundaries, allowing ecotourism and education to replace enmity. Such an initiative has already succeeded elsewhere in the world. The European Green Belt is the name for the corridor of wilderness which runs along the former Iron Curtain, which once divided the continent. Started in the 1970s, this project has sprawled along the border of 24 states and today is the longest and largest ecological network of its kind in the world. Here, ponds have replaced exploded land mine craters and forests and insect populations have grown in the absence of farming and pesticide use. Where war isolates and restricts human movement, nature does seem to thrive. If, as a human species, we aim for a peaceful world without war, we must strive to limit our own intrusions on the natural paradises that ironically human warfare creates and nurture a positive legacy from a tragic history."
"New leaders have emerged over the past few years who have changed the highest levels of political and diplomatic discourse. After divisive elections, both the US and Brazil are among the countries to have succumbed to the “strongman”. The modern strongman is a leader who rules by force and bluster, and who shuns cooperation in favour of an isolationist and protectionist foreign policy. This attitude is usually reflected in a very dim view of climate action. The US president, Donald Trump, and Brazil’s president-elect, Jair Bolsonaro, are both doubtful about climate science and have both suggested they would eventually like to withdraw from the Paris Agreement on climate change. At the latest COP24 climate talks in Poland, the US hosted a pro-coal side event, while Brazil has pulled out of hosting next year’s talks, COP25. Yet the two countries are a vital part of any fight against global warming. The US remains the world’s largest economy, and is the largest consumer and one of the largest producers of fossil fuels. Brazil also has a huge population and its wealth of natural resources – including the world’s largest rainforest, the Amazon –  are under threat.  In this context, with these leaders, what hope is there for the future of climate treaties and conferences?  Yet despite Trump, Bolsonaro and a few other awkward parties, delegates at COP24 have reached agreement on most of the “rulebook” for implementing the Paris Agreement on climate change. It is important to remember that Paris had 197 signatories with 184 countries ratifying it. This agreement is about more than just a couple of nations. Countries, it seems, are still working together. A significant reason for this is money – and, as the old adage goes: “money makes the world go round”. Many nations are still feeling the effects of the 2007-2009 financial crisis, and money remains in short supply. Any chance to create jobs and new investment will be welcomed by governments across the world, and investing in clean energy is one solution. Political leaders everywhere, including strongmen, are still motivated by money. For example, in many countries, public health has became a key climate change issue. Just look at China, where leader Xi Jinping shares some characteristics with classic strongmen yet his government has realised that fossil fuel use comes at a growing cost to public health, tourism and labour productivity. The Lancet estimates the welfare costs from pollution to be equivalent to 6.2% of global GDP – and these costs are rising. One way of negating the effects is to adopt a more climate change-friendly economic policy as China has been developing – for example, improving regulation, introducing environmental taxes and developing sustainable development zones. One key issue to emerge from the Paris Agreement was the idea of a “just transition”, which seeks to ensure that moving from a society based around fossil fuels to a new low-carbon economy is done fairly and with adequate support for workers. The Paris Agreement refers to: Taking into account the imperatives of a Just Transition of the workforce and the creation of decent work and quality jobs in accordance with nationally defined development priorities. This issue of a just transition remained relatively dormant but has risen to prominence over the past year. It was highlighted in the communiqué produced from the recent G7 talks in June this year. And notably, at the start of COP24, in a country dominated by coal, the Polish prime minister even announced a declaration on support for workers in rapidly-changing industries. There is no doubt that strongmen can distract from the global movement on climate change. But ultimately the movement has already gathered sufficient pace for continued cooperation by other countries, as evidenced by the numbers signed up to Paris. It is unfortunate that certain leaders will slow progress on climate action, perhaps particularly in their own countries, but nevertheless investment data shows that more and more low-carbon energy projects are receiving financial support globally. In following data trends, it is also clear that the cost to public health systems, the loss of worker productivity and the loss of tourism all from pollution is becoming more costly to societies than to reorient themselves to a low-carbon economy. In particular countries are acting on energy infrastructure issues and are developing strategies to deliver new low-carbon infrastructure.  Finally, there is recognition through the just transition movement that the labour force of our current fossil fuel-dominated economies needs to be transitioned to a labour force that builds a low-carbon economy – currently Scotland, Ireland, Germany and several states in the US and Australia are establishing commissions to deliver this policy. Money talks and, with finance now being geared towards low-carbon investments, it will supersede even the interests of media-savvy strongmen."
"
Share this...FacebookTwitterIn an interview with flagship daily Frankfurter Allgemeine Zeitung (FAZ here), Max-Planck Institute for Meteorology (MPIM) Director Dr. Jochen Marotzke said predicting how many degrees of warming we need to prepare for was like reading tea leaves and that he is not worried about “climate tipping points”. 
He also spoke of the wide disagreement among climate models.

Max-Planck Institute for Meteorology (MPIM) Director Dr. Jochen Marotzke told the FAZ he doesn’t worry about climate “tipping points”, but worries about panic. Image: MPIM. 
He told the FAZ that the worst case scenarios put out by some models were useful for the purpose of risk assessment, i.e. scenarios that are unlikely but cannot be ruled out. “In the latest generation of models, there are some models that are much more sensitive to greenhouse gases than previous models in terms of their temperature increase,” he said.
Five degrees “very very unlikely”
When asked about the results of the French model released earlier this year, which assumes five degrees of warming for a doubling of atmospheric CO2, Marotzke expressed his amazement, telling the FAZ what he thought of the French scientists: “My God, what are you doing? Because it is very, very unlikely that the true climate is as sensitive as these new models show.”
“The issue of climate sensitivity is extremely complex. Therefore, the results of a model should first be treated with caution,” Marotzke said.
When asked why the French model produced such a high warming for a doubling of CO”, Marotzke said he didn’t know why: “No one understands why they published it without first reflecting. The British did it differently, they said the new value is a mystery to us. They first want to investigate what the reason is and whether the warming rate is realistic.”
No worries about climate tipping points
Later in the interview, the FAZ touched on the so-called “tipping points in the climate system”, which are “threshold values that set irreversible processes in motion that, once started, can no longer be stopped.” Possible tipping points named by some scientists include the Greenland Ice Sheet, Gulf Stream, West Antarctica:, coral reefs, Amazon dying etc.
On whether they could happen, Marotzke views it as “conceivable” and that it “cannot be ruled out” and with “almost all of them we don’t know where we stand.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




When asked which one is most worrying, he replied: “None”.
“I don’t see any risk with Greenland”
And not even the melting of the Greenland ice sheet worries the MPIM Director. He told the FAZ:  “It’s gonna take so long – a couple thousand years. I don’t see any risk with Greenland.”
Arctic not a tipping element
On the subject of the Arctic, Marotzke says he is “quite sure that it is not a tipping point” – and that the ice albedo feedback “is not the dominant effect”.
“The ice comes back every year – in winter, said Marotzke, who has been Director at the MPIM in Hamburg since 2003. “When the temperature goes down again, the sea ice will come back.”
No worries about thawing permafrost
He is also not worried about the permafrost thawing, saying the contribution to warming “is relatively small.”
“Besides, even if the permafrost thaws, it is uncertain how much of the methane actually reaches the atmosphere,” said Marotzke. “Methane can be converted by bacteria to CO₂. I am not worried about methane.”
Worries “panic will backfire”
When asked about what he is worried about, he replies: “That the panic will backfire.” Marotzke warns against spreading panic: ” It can become incendiary. The question is, at what point do the risks of climate protection measures exceed the risks of climate change? Panic does not help here, only relatively sober analysis and weighing up – and a democratic discussion will help.”
Hat-tip: Die kalte Sonne. 


		jQuery(document).ready(function(){
			jQuery('#dd_1ad68e0372d18ffba913ecc7236487c6').on('change', function() {
			  jQuery('#amount_1ad68e0372d18ffba913ecc7236487c6').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"
As you may or may not know, this blog has taken off with big traffic increases as of late.
While the traffic has been an indicator of success, unfortunately, keeping that success gets to be more and more time consuming. This blog platform is hosted on Moveable Type version 3.2, which is about as close to being crippled as blog software can get. For example. it doesn’t even have a spell checker. The spam comment filter doesn’t work much anymore, and email notifications are also broken. The host has promised for months now to upgrade the platform, but so far has been unable to do so.
Working with MT in it’s current state requires a lot of extra effort compared to other software, and I find myself spending an inordinate amount of time just dealing with the limits of Moveable Type and trying to work around them. It has become quite frustrating as I want to offer better quality content and find myself unable to easily do so. I can’t even put in fully rich HTML into MT because of the way it deals with formatting. I’ve tried several add on programs to aid in blog generation, all of which have been thwarted by the MT platforms non standards compliance. Of course, some of my more snarky readers would likely suggest that standards “don’t matter” and that any problems with the content can be “adjusted” 😉
So the question is this, should I:
1) Close this blog and give up blogging altogether on this platform
2) Move someplace else and link back to this location
3) both
I welcome any input.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea3b81b69',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

 _The_ Current Wisdom _is a series of monthly articles in which Patrick J. Michaels and Paul C. “Chip” Knappenberger, from Cato’s Center for the Study of Science, review interesting items on global warming in the scientific literature that may not have received the media attention that they deserved, or have been misinterpreted in the popular press._   
  
  
  
With all the stern talk about global warming and widespread concern over climate change, you would think that we humans would have a propensity for cooler temperatures. Everywhere you look, the misery that rising temperatures (and the associated evils) will supposedly heap upon us seems to dominate reports about the coming climate. But do patterns of population movement really support the idea that we prefer cooler locations?   
  
**Increased Mobility**   
  
Since 1900, the population of the United States increased from about 76 million people to about 309 million people in 2010. Accompanying that population growth were major advances in technology and industry, including vast improvements in our nation’s system of transportation. As planes, trains, and automobiles replaced the horse and buggy, Americans became more mobile, and where we live was no longer connected primarily with proximity to where we were born. Instead, we became much freer to choose our place of residence based on considerations other than ease of getting there.   
  
Where has our new-found freedom of mobility led us? Figure 1 shows the rate of population change from 1900 to 2010 for each of the contiguous 48 states. Notice the increases in states with warm climates such as Florida, Texas, and California, and also in states with big industry (that is, jobs), such as New York, Michigan, and Ohio for example.   
  
  






  




_Figure 1. The state-by-state population trend (people/year) from 1900 to 2010 (data fromU.S. Census Bureau)._



Which states are people less likely to choose to live in? States such as North Dakota, South Dakota, Montana, Maine, Vermont—all of which have harsh climates and low temperatures.   
  
Comparing a map of the change in population (Figure 1) with a map depicting the average temperature of each state (Figure 2) reveals a pretty strong indication that people seem to be seeking out warmer states.   
  
  






**  
**_Figure 2. The state-by-state average annual temperature for the period 1900-2010 (statewide temperture data available from the U.S.National Climatic Data Center)._   
  
**Experiential Temperature**   
  
Another way of looking at human temperature preferences is to calculate what we’ll call the “average experiential temperature”—that is, the annual temperature that the average person living in the lower 48 states experiences each year. We can calculate this value by first multiplying the average temperature in each state during a particular year by the state’s population in the same year. Then we sum this product across the 48 contiguous states, and finally divide this sum by the total population of the country. In other words, the temperature in states with larger populations weigh more heavily on the national composite experiential temperature than does the temperature in those states with sparser populations. As the population of the country redistributes itself over time, we can track how the average person’s climate changes.   
  
When we do that for each year from 1900 to 2013, we get the result shown in Figure 3—a steadily rising temperature. In fact, the average experiential temperature has risen by a total of about 3.85ºF over the course of the last 114 years (a rate of 0.34ºF per decade).   








_Figure 3. The average experiential temperature of the population of the United States, 1900 to 2013._



But the history of experiential temperatures alone can’t tell us whether the increase has been unwillingly forced upon us by a large-scale warming of the climate from, say, an enhanced greenhouse effect, or whether the change results from Americans seeking out warmer locales on their own accord.   
  
**U.S.** **Average Temperature**   
  
To answer this question, we must calculate the area-weighted average temperature of the United States—that is, the combination of the yearly average temperature within each state weighted by that state’s total area. In this case, it is the size of the state, rather than the size of its population, that matters—the bigger the state, the bigger its contribution to the nationwide average.   
  
The result of this calculation is a quite different looking temperature history. In Figure 4, we included the annual U.S. average temperature history along with the annual U.S. “experiential” temperature from Figure 3. We see that, while the United States actual temperature has fluctuated a bit, experiencing warm decades such as the 1930s and 1990s and cold ones such as the 1910s and 1970s, it has increased only slightly during the 20th century—about 0.90ºF (a rate of 0.08ºF/decade).   






_Figure 4. Average temperature of the United States, 1900 to 2013._



For what it’s worth, when you calculate the national temperature this way (using the state-by-state temperature data from the National Climatic Data Center, NCDC), you get a heckuva lot less warming than is in the “official” NCDC record put out by the U.S. Department of Commerce. The difference lies in the “adjustments” plastered on to the original data. Both records are adjusted for a bias known as “time of day” when the previous 24-hour highs and lows recorded. It’s complicated, but it also does slightly alter the data.   
  
But the official version is additionally massaged more than—well, we can’t say in polite company. A laundry list can be found here. The sum of all of those adjustments is to put about twice as much warming in the record as is in our state-averaged plot.   
  
**Seeking the Heat**   
  
Although there has been a slight warm-up of the actual temperature, that rise is nowhere near the increase in the _experiential_ temperature. In fact, the average experiential temperature has climbed at a rate more than four times that of the U. S. average temperature—which is the experiential temperature had the population distribution not changed at all. That means that Americans have actively been moving to warmer climates. And there is every indication that they are continuing to do so, as evidenced by the strong rise in experiential temperatures during the past 20 or 30 years.   
  
While climatologists have not generally appreciated this fact, it has been long recognized and appreciated by sociologists. As both people's mobility and their ability to select the climate they prefer have increased throughout this past century, the core of the U.S. population has moved southward—into warmer climates. The overall migration of people into the southern ""Sunbelt"" states has created a temperature change over time for the ""average American"" that far outstrips the most pessimistic measurements of global warming for the past century, and rivals the projections for the next!   
  
Apparently, people--or Americans at least--seem to prefer a warmer climate to a cooler one. Next time climate prognosticators warn of the perils of rising temperatures, remember this: when given the means and a choice, some (or rather, most) like it hot!   
  
_(Special thanks to Robert C. Balling Jr. and Randy Cerveny, who assisted with early versions of this research.)_


"
nan
"

In my recent op-ed for _The Hill_ examining the Obama administration’s estimation of the social cost of carbon (SCC)—a measure of how much future damage is purportedly going to be caused by each ton of carbon dioxide that is emitted through human activities—I identified two major problems with their measure.   
  
First, the administration’s SCC was based on an estimate of _global_ rather than domestic damages from anthropogenic climate change—an odd scope for a measure designed to be incorporated in the cost/benefit analysis of U.S. rules and regulations governing domestic activities (such as the energy efficiency of microwave ovens sold in the United States). In fact, Office and Management and Budget (OMB) guidelines state that   




Your analysis should focus on benefits and costs that accrue to citizens and residents of the United States. Where you choose to evaluate a regulation that is likely to have effects beyond the borders of the United States, these effects should be reported separately.



Instead of “reporting separately,” the administration’s SCC embodies “effects beyond the borders of the United States.”   
  
Second, the administration recently revised (upwards) its initial calculation of the SCC. In doing so, it included updates to its underlying economic/climate-change/damage models, but it did not include any updates to the characteristics of the equilibrium climate sensitivity used by the models. Since the equilibrium climate sensitivity is the _key factor_ in how much climate change will result from a given amount of anthropogenic carbon dioxide emissions, and since there is mounting scientific evidence that the equilibrium climate sensitivity is better constrained and lower than that used in the initial analysis, there is no defensible reason why the new science was not included in the administration’s revised SCC calculation.   
  
So that’s two strikes against it.   




What I didn’t go into in my op-ed, because it is a rather complicated topic, is the choice of discount rate used in the administration’s SCC analysis. The discount rate, generally put, reflects how much you are willing to pay now to avert future damages. The lower the discount rate, the more costly (in today’s dollars) future damages become. The same OMB guidelines mentioned above also cover the selection of the discount rate to use in cost/benefit analysis. The OMB guidance is that as a default an analysis should use a 7 percent discount rate as the base case, and to show the sensitivity of the results to the discount rate assumption, the analysis also should include the results of using a 3 percent discount rate.   
  
The administration ignored that guideline as well. Instead it opted to determine the SCC using discount rates of 2.5, 3, and 5 percent, and didn't include results for a 7 percent rate—results that would have indicated a _substantially_ reduced cost of future damages.   
  
With now three strikes against it, the administration’s determination of the social cost of carbon should be tossed out.   
  
The door to doing so has just been opened slightly with the announcement that the Department of Energy is opening for public comment a Petition for Reconsideration of its use of the administration’s newly figured and newly increased SCC in its above-mentioned microwave oven energy efficiency rule. We’ll see what becomes of that.   
  
In the meantime, here's an example of how the SCC is currently being used and abused in the justification of new regulations. Economist Robert Murphy (who recently testified to Congress as to the problems with the administration’s SCC methodology) posted this gem from the Environmental Protection Agency discussions of a proposed new rule regulating discharges from steam electric power plants (and how the rule may impact carbon dioxide emissions from the plants):   






Murphy comments:   




As the above table shows, EPA is being a dutiful federal agency, following Executive Branch guidelines on how to calculate costs and benefits—it reports its findings using both a 3 percent and a 7 percent discount rate. Yet as the footnote explains, when reporting the benefits of reducing CO2 emissions, the EPA actually _can’t_ use a 7 percent discount rate, because an estimate of the SCC (social cost of carbon) for a 7 percent rate is “not available.” _Why_ is it not available? Because the [administration’s] Working Group explicitly ignored the OMB guidelines, and only reported the figures for 3 percent and 5 percent.   
  
We thus have an absurd situation, in which EPA and other regulatory agencies will be following the rules and calculating benefits and costs at both the 3 percent and 7 percent discount rates. Yet, when they express the “social benefits” of reducing greenhouse gas emissions at the 7 percent rate, they are actually going to plug in the wrong number, and explain in a footnote why they are doing so. To repeat, this is important, because the “right” number would show that there are virtually _no_ “social benefits” from reducing greenhouse gas emissions.   
  
As I have explained elsewhere, there are far more problems to the Obama Administration’s computer-model-case against carbon, than just the choice of discount rate. Yet the knots into which the federal government has tied itself, in order to avoid revealing the truth about the actual economic literature, is quite revealing—not to mention hilarious.



The administration’s SCC is a devious tool designed to justify more and more expensive rules and regulations impacting virtually every aspects of our lives, and it is developed by violating federal guidelines and ignoring the best science.   
  
All around bad news.


"
"Curious Kids is a series for children of all ages, where The Conversation asks experts to answer questions from kids. All questions are welcome: find out how to enter at the bottom of this article.  What is a species? – Finlay, age four, London, UK Thanks for the question, Finlay. In the past, it seemed like a sensible and simple idea to put living creatures – including animals, plants, fungi, bacteria and so on – into different categories called “species”.  Scientists mostly told different species apart from the way they looked, or where they could be found. But sometimes that proved very tricky indeed.  For example, it’s clear that giraffes and mice are very different groups of creatures, and that you can easily tell them apart; in other words, they are two different species. But what about those two little brown birds, which look so similar?  It was also easy to say that emus and ostriches were probably different species, even though they look a bit similar, because they live on different continents, so they must be different groups of birds. As time passed and scientists got to study more and more creatures, they realised that some creatures could be quite different, but still be part of the same group.  Have you seen a peacock and a peahen next to each other? In the animal kingdom, mums and dads can look quite different, but they should definitely be part of the same species.  So, by the end of the 1800s, the scientists realised that you can’t always decide if creatures belong to the same species, just by how they look.  Around this time, a man called Charles Darwin started to convince other scientists with his idea of evolution: he showed how creatures change over time, to become better at living in their environment.  One example is how the peppered moths in the UK changed from light to dark colour, after pollution from factories darkened the tree trunks where the moths like to hide. Light coloured moths became easy to spot and got eaten by birds, while the dark coloured moths survived and had more dark coloured babies.  By the beginning of the 1900s, scientists also started to understand that a baby looks like their mum and dad because some kind of information is passed between parents and their children, inside their bodies. Nowadays, we know that this information is called DNA.  With this knowledge, scientists decided that it’s better to define a species as a group of living things that can exchange DNA, by creating “viable offspring”. “Viable offspring” means a baby that can survive, and make babies of its own later on.  This is important, because some species can make babies together, like a zebra and a horse. But this baby – called a zorse – is sterile; it cannot have babies of its own.  This “viable offspring” definition of species is useful, and it’s the one that scientists rely on most often today.  But if you want to have some fun and see a scientist get very hot under the collar, you could mention that sometimes it’s possible to bring together, which would never meet without the help of humans, and that they can produce a viable offspring. This is the case with tigers and lions. They do not exist in the same location, but humans have bred them together to produce the “liger”. Now what? Are they the same or different species?  As you can see, defining species can get tricky… But I think most scientists will agree that if these two groups wouldn’t meet and have babies without humans getting involved, they are probably two different species.  So how can we define a species? Well, in most cases the “viable offspring” test will work just fine.  You just need to remember that groups of creatures are constantly evolving, so sometimes the differences between species might become a bit blurry.  Hello, curious kids! Have you got a question you’d like an expert to answer? Ask an adult to send your question to us. You can: * Email your question to curiouskids@theconversation.com 

* Tell us on Twitter by tagging @ConversationUK with the hashtag #curiouskids, or

* Message us on Facebook. Please tell us your name, age and which town or city you live in. You can send an audio recording of your question too, if you want. Send as many questions as you like! We won’t be able to answer every question, but we will do our best. More Curious Kids articles, written by academic experts: How do moths eat our clothes? – Albie, age five, Australia Why do leaves change colour? – Isaac, age eight, Guildford, UK Why do we need food? – Milo, age five, Cowes, Australia"
"The gilets jaunes movement, by its own description, is motivated by broad discontent over shrinking incomes and rising living costs in France. However, the demonstrators in yellow jackets have rallied around one particular government policy: a looming hike in fuel taxes.  Since 2014, domestic excise taxes on energy products have been linked to carbon content, with more carbon-intensive fuels taxed at a higher rate. Tax rates have also been scheduled to increase on an annual basis. For consumers, this has translated into gradually rising prices for fossil fuels such as petrol, diesel, natural gas, and heating oil. The objective of these rate hikes, according to the French government, is to reduce reliance on imported energy, reduce greenhouse gas emissions and yield tax revenue to cut payroll taxes and stimulate employment. The problem, however, is that such taxes tend to be unpopular. While the recent protests in France stand out for their intensity, they join a growing record of political turmoil spurred by carbon and energy taxes in different parts of the world.  In 2017, Mexicans took to the streets to express outrage at fuel tax increases. During the recent US midterm elections, residents of Washington state again rejected a ballot measure aimed at introducing a carbon fee. North of the border, several Canadian provinces have started legal proceedings against a federal carbon pricing framework. Germany and Ireland recently backed away from carbon tax expansions.  Research has long shown how difficult it is to win popular support for carbon and energy taxes. One reason is that these impose an explicit and immediate cost on emitters, disproportionately affecting politically influential industries such as fossil fuel companies, which tend to use their influence to resist or weaken pricing policies. At the same time, they only promise diffuse future benefits for the broader population.  Renewable energy subsidies are a costlier way of achieving emission reductions overall but they spread that cost across the broader public. The financial benefit, meanwhile, is highly concentrated for subsidy recipients, creating strong supportive constituencies. Surveys confirm that voters prefer financial aid policies over taxes, suggesting that public support for climate action is broad but shallow. Addressing climate change enjoys widespread approval – until climate action comes with a tangible price tag, that is. Unlike other climate policies such as subsidies, carbon taxes make that price tag visible, and that is a big reason for their low popularity. Some commentators have therefore suggested a sequenced approach in which less contentious policies pave the way for gradual introduction of a robust carbon price. Still, the fact that other policies don’t carry an explicit price tag doesn’t mean they don’t also impose a burden on the economy and on consumers. In the long run, the cost of doing nothing will almost certainly outweigh the cost of climate action – but the latter is real and will be allocated unevenly, creating winners and losers. That explains a growing preoccupation with the distribution of climate policy impacts. The idea of a “just transition” is an overriding theme at this year’s climate summit in Poland. It asks us to consider how we can move society to a low-carbon world without leaving anyone behind. The idea was enshrined in a declaration signed by ministers attending COP24, calling for greater consideration of the social consequences of a low-carbon transition. The French could well have used this as a guide in its response to public backlash against its energy tax plans. The demand for a just transition includes gaining social approval for climate policy by compensating, training and supporting people likely to be impacted by it. The French government assigned revenues from its energy tax increase to the general budget and earmarked parts of it for a business tax credit meant to stimulate employment and competitiveness. For taxpayers, the benefits remained obscure, and credibility of the carbon tax suffered. Instead, the government could have returned the revenue directly to taxpayers in the form of uniform or targeted cash transfers. Not only would that have made the use of revenue more transparent, it would have counteracted the general tendency of carbon and energy taxes to be regressive, that is, to affect low-income households disproportionately. Dedicating a share of revenue to helping disadvantaged communities could further reduce the perceived inequities that sparked unrest in the first place. Other places have shown that it can be done. A carbon tax introduced in British Columbia in 2008 faced initial opposition, but smart investment of tax revenue – including an annual Climate Action Tax Credit for every citizen – and a robust communications strategy have since won it broad support. People need access to affordable low-carbon options if a carbon price is to be effective, which underscores the need for adequate investment in innovation and infrastructure, such as public transit or electric vehicle charging stations.  The gilets jaunes movement reminds us that we still have much to learn about how to craft climate policies that are both environmentally ambitious and politically durable. We would do well to heed this insight: time is not on our side, and we cannot afford more setbacks."
"
I mentioned this a couple of posts back, exploding Comet 17P/Holmes is one of the strangest things in the sky ever but it gets stranger…Last night, astrophotographer Alan Friedman of Buffalo, NY, took a close-up picture of the comet’s core. “A strong deconvolution filter followed by multiple passes of unsharp mask and gaussian blur reveals startling new structure in comet 17P/Holmes.” i.e. after processing the image with Photoshop Here’ what popped out:

Linus would be impressed. The structure is due to outgassing from fissures and crevices in the comet’s core, but it is just a little too coincidentally spooky. Of course we’ve always seen things in the sky that mirror our minds, from constellations to UFO’s,  so why not Halloweeen?
Would you like to see the comet masquerading as the great pumpkin?? Look north after sunset for an expanding fuzzball in the constellation Perseus: sky map. Comet Holmes is about as bright as the stars of the Big Dipper, easy to see with the unaided eye and for backyard telescopes. The Chico Observatory in upper Bidwell Park will also be looking at this object.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea2d50172',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
After a near brush with death, GOES 12 is back up and running, our full disk image  is now 100% The loop may take some time to get synced but images are being produced from GOES 12 correctly now.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea231e8fe',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"Lehman Brothers filed for bankruptcy on September 15, 2008. The investment bank’s collapse was the drop that made the bucket of global finance overflow, starting a decade of foreclosures, bailouts and austerity. The resulting tsunami hit the global economy and public sector, discrediting finance and its attempts to extract large rents from every aspect of the economy, including housing and food. An alternative was urgently needed. Ten years later, private finance and large investors will play a central role at the COP24 in Katowice, Poland, and in the full implementation of the 2015 Paris Agreement. Representatives from pension funds, insurance funds, asset managers and large banks will attend the meeting and lobby governments, cities and other banks to favour investments in infrastructure, energy production, agriculture and the transition towards a low-carbon economy.  There is a US$2.5 trillion gap in development aid which needs to be filled if poor countries can adequately mitigate the effects of climate change. With little enthusiasm among rich countries to stump up, the role of private finance is inevitable. Policy makers trust financial capital as our best hope of securing investment to avoid the catastrophic warming beyond 1.5°C. This has been the case for a while – the first announcement came at the UN Climate Summit in 2014, when a press release on the UN website said the investment community and financial institutions would “mobilise hundreds of billions of dollars for financing low-carbon and climate resilient pathways”. Since then, networks that stress the role of private finance in rescuing the planet have multiplied, including the Climate Finance session at the Sustainable Innovation Forum, which will also take place in Katowice, on December 9-10 2018. It is difficult to ignore that a strong reliance on private finance means putting the future of Earth in the hands of individuals and institutions that brought the global economy to the verge of collapse. It may be partially true that some are divesting from fossil fuels and funnelling their money into better projects. But before we pin our hopes on finance to solve climate change, there are some things we need to ask ourselves. How did we get to a point in history where it is taken for granted that public money alone can never be sufficient to finance our transition from fossil fuels? Is it an objective condition with no clear causation and responsibility, or something else?  What about the fact that global military spending in 2017 reached US$1.7 trillion while poor countries promised funding for climate change adaptation and mitigation in 2015 are still waiting? 


      Read more:
      COP24: climate protesters must get radical and challenge economic growth


 What about the cost of bailouts to the financial sector, which in the UK alone has been estimated at US$850 billion? As Michael Lewis noted in his boomerang theory, states that have propped up financiers with public money are now asking those same financiers to step in and do the job that states should do. And this leads to the second consideration. Climate change is historically, politically and socially complex. Although sustainable finance is not presented as the sole solution, analysing its role produces a series of strategic short circuits.  


      Read more:
      Climate change and migration in Bangladesh – one woman's perspective


 It oversimplifies and depoliticises the response to climate change. It legitimises the idea that sustainability can be achieved within continuous growth and expansion, which are essential to the survival of the financial sector.  It rewrites the way we think about our planet in the vocabulary of finance and its obsession for a return on investment. It marginalises any claim to address climate change based on present and historical injustices, redistribution and bottom-up projects organised by ordinary people. It accepts that the financial way of defining sustainability and its achievements are inherently aligned with the rights, interests and needs of people and the planet. Finance may be a partner in the fight against climate change, but it is certainly not a partner motivated by altruism. It’s motivated by generating profit from the transition. It is therefore unsurprising that energy generation, railways, water management and other forms of climate mitigation have been identified as priorities for sustainable finance. Wall Street can find large returns by investing in the transition to “greener” infrastructure, including the not-so-green Chinese green belt and road and dams like the Belo Monte, a project that originally applied for carbon credits and was labelled as a sustainable investment. Green bonds can help cities finance projects to reduce their environmental impact or adapt to climate change.  However, if money is the driver, we should not expect private investors to have any interest in projects that won’t generate a sufficient return, but would benefit people or cities that cannot pay for the service or for the debt, or that would protect vulnerable people from climate change. If climate change is fought according to the rules of Wall Street, people and projects will be supported only on the basis of whether they will make money. Ten years ago, the world saw that finance had permeated every aspect of the global economy. Back then, it was clear that financial interests could not build a better and different world. Ten years later, COP24 should not legitimise large financial investors as the architects of a transition where sustainability rhymes with profitability."
nan
"
There is a lot of intense interest out there in watching TS Noel to see if this disorganized system turns into a Hurricane when it hits the warmer waters of the Gulf Stream. Click on the image for an animated version.

Then, place your bets.
The image is from my company, IntelliWeather, and updates every half hour.
UPDATE: Noel did in fact become a hurricane, and now has 80 mph sustained winds, but it appears to be headed out to sea, and into cooler waters where it will likely dissipate.
from NHC advisory 22: …HURRICANE NOEL EXPECTED TO BECOME A LARGE AND POWERFUL EXTRATROPICAL STORM OVER THE OPEN ATLANTIC ON FRIDAY… NOEL IS MOVING TOWARD THE NORTH-NORTHEAST NEAR 20 MPH…32 KM/HR…AND THIS MOTION IS EXPECTED TO CONTINUE DURING THE NEXT 24 HOURS. ON THIS TRACK…NOEL WILL CONTINUE TO MOVE AWAY FROM THE BAHAMAS.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea2e89e8d',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

On January 10, CBS News began a series of six, count ‘em, separate global warming scare stories. On January 27, President Clinton called global warming “the greatest environmental challenge of the new century.” On February 1, Roger Ballentine, Clinton’s deputy assistant for environmental initiatives, sent a “Dear Interested Party” letter elaborating on the president’s position. On February 9, Bill Stevens, the New York Times global warming reporter (and advocate of Clinton/​Gore policies; see his new book The Change in the Weather) called, saying he’s writing a new, comprehensive feature article on the subject. On April 22, Earth Day, presidential candidate Al Gore will release a new edition of his 1992 bestseller, Earth in the Balance. 



Is there a pattern here? 



After avoiding the issue like the political plague that it is, the Gore campaign has decided to go into high dudgeon over climate change. 



The Gore team is banking on some type of national weather disaster this summer. They hope to call attention to global climate change and their belief that uncaring Republicans refuse to pass the Kyoto Protocol on global warming. This U.N. document will cost the country a fortune and has the potential to relegate an amazing percentage of our land — the United Nations calls it “Kyoto lands” — to their watchful eyes. They are about to release a report that puts just about all U.S. forested land in this category, as well as much of our farmland. That’s easily half the country. 



This makes it a good idea to examine what is coming out of the White House as it ramps up the weather horror machine. On February 1, Deputy Assistant Ballentine wrote, “You may have noticed the steady stream of new scientific studies suggesting that global warming is . . . occurring more rapidly than previously thought.” 



What “steady stream?” Fact: Of hundreds of global warming papers that appeared last year, only one, published in Geophysical Research Letters, says this, and it does so by using 16 months of data to forecast the next 100 years. The only “steady stream” it has created is a torrent of scientific criticism. 



Rather, the balance of scientific evidence, according to the U.N. Intergovernmental Panel on Climate Change is to the contrary. In its last comprehensive report, the United Nations stated, “When increases in greenhouse gases only are taken into account, most [climate prediction models] produce a greater mean warming than has been observed.” In other words, the computer models that gave rise to the initial concern predicted too much warming. 



From Mr. Ballentine: “Reports by … the National Climatic Data Center … found that since 1976 the planet has been warming at a rate of 0.35 degrees Fahrenheit per decade.” 



Fact: Integrated over the troposphere–the earth’s active weather zone — the planetary warming since 1976 has been a mere 0.07ºF/decade, or far beneath normal background fluctuations in this region. According to NASA scientist John Christy, writing in Nature magazine, the originally forecast tropospheric warming rate was around 0.70ºF/decade. This is 10 times what has been observed. Because those models, in the United Nation’s words “produce[d] a greater mean warming than has been observed,” the integrated tropospheric warming forecast was lowered, by 1997, to 0.4ºF/decade. This is still an egregious error, and a new report by the National Research Council has finally admitted that it casts serious doubt on current computer forecasts of global warming. 



More Facts: It is seriously misleading to report the temperature of “the planet” in disregard of the distribution of observed surface warming. Had Mr. Ballentine consulted the latest issue of Climate Research, he would have seen that by far the greatest warming is occurring in the coldest winter air masses of Siberia and northwestern North America. Northern Hemisphere cold‐​season warming outside those regions averages one‐​tenth of what is being observed within them, which is below normal variability. 



Still More Facts: The very air masses that are warming are those under which winter mortality is four times greater than summer mortality. Furthermore, in almost every year that surface temperatures have warmed, global food production has risen. This results from improved technology, benign weather and the same carbon dioxide that makes the coldest air of winter less deadly. Finally, as surface temperatures have warmed, we have witnessed the greatest democratization of wealth and expansion of longevity in human history. 



None of this matters when the hype is on, and Gore knows a lot about American weather. He has been told, for sure, that conditions in the industrial Midwest, Texas and Southern California are fairly dry, predisposing the region to a very mediagenic drought, just in time for the nominating conventions. 



And Gore surely has been told that the way the federal government measures moisture status — please sit down — puts an average of 20 percent of the Electoral College in drought each summer. This year, thanks to where the dry conditions are, it’s closer to one‐​third, or a mere New York+Florida from putting Gore in the White House.
"
"
From the days of Wine and Gore department: The Second annual Climate Change and Wine Conference is scheduled for Feburary 15th and 16th in Madrid, Spain. Al Gore will be the featured speaker.
http://www.climatechangeandwine.com/eng/index.php
SALUD!
Wine snobbery and climate change together.  What’s not to like?
No word yet on whether California wineries will be attending.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea1a1dcff',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterYou would think that with all the added wind and solar energy in Germany, along with all the conventional power plants on standby, all totaling up to huge unneeded capacity, there would be no need to import any power at all. Well, think again.

Photo: P. Gosselin
The German epochtimes.de here reports that German imports of electricity in fact: “rose by 43.3 percent to 25.7 billion kilowatt hours in the first half of 2020 compared with the first half of 2019.”
The epochtimes.de explains further:
One reason for this was the declining share of domestic feed-in from base-load-capable, mostly conventionally operated power plants, which mainly use coal, nuclear energy and natural gas. As a result, electricity was imported to cover the demand for electricity, especially when there was no wind or darkness. The main import country for electricity was France with 8.7 billion kilowatt hours.
Overall, however, more electricity was still exported from Germany.”
What the article does not mention, however, is the reason for the rise in export from Germany. On windy and sunshine-plenty days, Germany produces more electricity than needed, and so is forced to dump the excess power into neighboring foreign markets – often at negative prices. The negative prices, in combination with the mandatory feed-in tariffs and excess production capacity, all means higher costs for consumers.
Little wonder that at close to 35 US cents per kwh, Germany’s electricity prices are among the highest in the world.


		jQuery(document).ready(function(){
			jQuery('#dd_f32389d0d82421273a7d3eb7eaea0392').on('change', function() {
			  jQuery('#amount_f32389d0d82421273a7d3eb7eaea0392').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"

The President on Tuesday signed the continuing resolution that funds the government through September and (gasp) keeps the sequester cuts intact. Now that it appears sequestration isn’t going away (and yet the earth continues to spin merrily on its axis), the focus should be on how this small step might be extended.



Unfortunately, the reaction to Paul Ryan’s relatively modest budget indicates the fight for smaller government will continue to be an uphill battle in the current political climate. The Ryan budget has brought predictable condemnation from the political left. Sen. Harry Reid called it “extreme,” and the New York Times called it “the worst of the Ryan budgets.” The plan’s sin: restraining the growth of federal spending to 3.4 percent instead of 5 percent.





Serious policymakers need to start explaining to the American people how the federal government doing less will do more to enhance their personal and economic well‐​being.



While there are some of us that don’t feel the Ryan budget goes nearly far enough, it was never going to become law as is with a Democratic White House and Senate. But here’s the important question: does sequestration and Ryan’s follow‐​up give proponents of limited government a reason to be optimistic?



Currently, the answer is no.



Sequestration has yet to cause a public revolt and the markets have treated it with indifference throughout. Although the cuts that happened under sequestration are hardly an occasion for a victory lap, they are a small and welcome bit of evidence that government can spend less without society as we know it coming to an end.



Sequestration reduces federal spending by $44 billion this year, which is a relatively small sum considering that total spending will be around $3.5 trillion. The budget deficit alone is projected to be around $850 billion. That means to balance the budget this year, the spending cuts would have to be almost 20 times larger. However, sequestration barely scratches entitlement programs, which dominate the federal budget and are the source of our long‐​term fiscal problems. And because it doesn’t actually terminate any agencies or programs, spending can be restored in the future.



So in the big picture, sequestration hasn’t changed all that much. Federal spending is still on a dangerous upward trajectory. Unfortunately, while there is much talk about the need to reform the welfare state in order to make it more affordable, the underlying desirability of our centralized system of cradle‐​to‐​grave entitlement programs remains virtually unchallenged on Capitol Hill. And while the Pentagon’s bloated budget is being challenged, only a handful of policymakers are questioning the underlying desirability of the United State’s global military footprint.



The size and scope of the federal government needs to be dramatically reduced. Republicans are commonly understood to be in favor of limited government, but their track record suggests otherwise. Federal spending went through the roof under Republican rule in the previous decade. After reclaiming the House in 2010, Republicans positioned themselves as the frugal alternative to the debt‐​happy Obama administration. Unfortunately, the manner in which Republicans handled sequestration indicates that they are still unwilling or incapable of making a principled argument for smaller government.



Ever the defenders of the warfare state, Republicans bemoaned the sequestration cuts made to the Pentagon’s budget. Mirroring the administration’s orchestrated hysteria over cuts to domestic programs, some Republicans even claimed that the cuts would “gut” the military — a specious assertion considering that military spending under sequestration would be higher in real dollars than peak Cold War spending.



So if sequestration doesn’t do a whole lot to shrink the size and scope of government, what about Mr. Ryan’s proposal? In his budget, Ryan calls for ending Obamacare, but that wouldn’t end the federal government’s involvement in health care. Ryan says that higher education subsidies should be capped, but that wouldn’t end the federal government’s involvement in education. How the federal government delivers the goods might change, but a more efficient government isn’t the same as limited government. And if the goal is limited government, as Republicans often claim, then there has to be actual limits on what the government is involved in.



The tough reality is that the average voter is content to spend other people’s money on programs that they benefit from. And every government program is backed by a special interest that will fight tooth‐​and‐​nail to protect their share of Uncle Sam’s loot.



That’s an obviously difficult dynamic to overcome. But if progress is to be made, serious policymakers need to start explaining to the American people how the federal government doing less will do more to enhance their personal and economic well‐​being. That means making the case for limited government. Until that happens, the question of whether or not proponents of limited government should be optimistic will remain no.
"
"

A friend from my coffee group sent this about recognizing the signs of a stroke and encouraged me to post it and spread the word. I checked it out to make sure it was not another Internet hoax and I’m happy to report it is valid.
If everyone can remember this simple STR procedure, lives could be saved.
Some background –
During a BBQ, a friend stumbled and took a little fall – she assured everyone that she was fine (they offered to call paramedics) …..she said she had just tripped over a brick because of her new shoes.
They got her cleaned up and got her a new plate of food. While she appeared a bit shaken up, Ingrid went about enjoying herself the rest of the evening.
Ingrid’s husband called later telling everyone that his wife had been  taken to the hospital – (at 6:00 pm Ingrid passed away.) She had suffered a  stroke at the BBQ. Had they known how to identify the signs of a stroke, perhaps Ingrid would be with us today. Some don’t die…. they end up in a  helpless, hopeless condition instead.
A neurologist says that if he can get to a stroke victim within 3 hours he can totally reverse the effects of a stroke… totally . He said the trick was getting a stroke recognized, diagnosed, and then getting the patient medically cared for within 3 hours, which is tough.
RECOGNIZING A STROKE
Remember these ‘3’ steps:  STR. It’s the first three letters of the word STRoke.
Sometimes symptoms of a stroke are difficult to identify. Unfortunately, the lack of situational awareness spells disaster. The stroke victim may suffer severe  brain damage when people nearby fail to recognize the symptoms of a stroke .
Now doctors say a bystander can recognize a stroke by asking three simple
questions:
S * Ask the individual to SMILE.
T * Ask the person to TALK and SPEAK A SIMPLE SENTENCE (Coherently)
       (i.e. It is sunny out today)
R * Ask him or her to RAISE BOTH ARMS.
If he or she has trouble with ANY ONE of these tasks, call 999/911 immediately and describe the symptoms to the dispatcher.
See References: American Stroke Foundation, Stroke Awareness.org
New Sign of a Stroke ——– Stick out Your Tongue
Ask the person to ‘stick’ out his tongue.. If the tongue is ‘crooked’, if it goes to one side or the other , that is also an indication of a stroke.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea1962e56',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"
Share this...FacebookTwitterExpect this new study to be greeted by an angry mob with pitch forks and torches. Results Big Pharma, Bill Gates and social engineering technocrats don’t want to see. 
So picture this: tens of thousands of scientists, doctors and health authorities worldwide spending billions and billions in a frenzied search for new medicines and vaccines – while imposing economy-crippling lock downs – all to combat the COVID 19 virus. Meanwhile, a large part of the solution is likely just sitting right there on the supermarket shelf – to be had for just a few bucks!
Use a mouthwash, stupid!
That may be just the case, believe it or not, according a a recently published study appearing in the British journal FUNCTION titled: “Potential Role of Oral Rinses Targeting the Viral Lipid Envelope in SARS-CoV-2 Infection“.
It may be that simply gargling regularly in fact goes a long way in combating the spread of COVID-19, and letting us do away with the face mask circus we’ve been going through lately.
Promising results

A team of scientists led by Valerie B O’Donnell reviewed known mechanisms of viral lipid membrane disruption by widely available dental mouthwash components that include ethanol, chlorhexidine, cetylpyridinium chloride, hydrogen peroxide, and povidone-iodine and assessed their potential ability to disrupt the SARS-CoV-2 lipid envelope, based on their concentrations.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




 

Figure 1: Breaching the viral envelope. Source: O’Donnell et al 2020. 
Direct evidence: “Potential way to reduce transmission”
The preliminary results are promising enough to warrant serious further investigation, the authors say. Moreover, citing already published research on other enveloped viruses, they conclude that several deserve clinical evaluation.
These studies “directly support the idea that oral rinsing should be considered as a potential way to reduce transmission of SARS-CoV-2,” the authors say.
Mixing science and politics
If this turns out to be so, there are going to be lots of “experts” out there looking awfully silly. But so it is so often when social engineering politics get mixed with science.

Share this...FacebookTwitter "
"

9/29/07 UPDATE: We are still waiting on Mr. Steve Bloom to answer this question: “Why is positive bias imparted in USHCN adjustments?”
He incorrectly asserts that he has been “banned” from this blog. Not true. Once he answers this question, that answer along with whatever else he has to say after that will be posted here. Otherwise we’ll continue to wait.
What say you, Mr. Bloom?
——————————————-
Given what NASA GISS has recently done with posting a change to the data methodology on the heels of an error which was embarrasing to them, (see Raising Walhalla)  I think this review of a relevant paper might bear some examination:
An Introduced Warming Bias in the USHCN Temperature Database Reference
Balling Jr., R.C. and Idso, C.D. 2002. Analysis of adjustments to the United States Historical Climatology Network (USHCN) temperature database. Geophysical Research Letters 10.1029/2002GL014825.
Abstract http://www.agu.org/pubs/crossref/2002/2002GL014825.shtml and the full paper Download file
What was done:
The authors examined and compared trends among six different temperature databases for the coterminous United States over the period 1930-2000 and/or 1979-2000.
What was learned:
For the period 1930-2000, the RAW or unadjusted USHCN time series revealed a linear cooling of 0.05°C per decade that is statistically significant at the 0.05 level of confidence. The FILNET USHCN time series, on the other hand – which contains adjustments to the RAW dataset designed to deal with biases believed to be introduced by variations in time of observation, the changeover to the new Maximum/Minimum Temperature System (MMTS), station history (including other types of instrument adjustments) and an interpolation scheme for estimating missing data from nearby highly-correlated station records – exhibited an insignificant warming of 0.01°C per decade.
Most interestingly, the difference between the two trends (FILNET-RAW) shows “a nearly monotonic, and highly statistically significant, increase of over 0.05°C per decade.” With respect to the 1979-2000 period, the authors say that “even at this relatively short time scale, the difference between the RAW and FILNET trends is highly significant (0.0001 level of confidence).” Over both time periods, they also find that “the trends in the unadjusted temperature records [RAW] are not different from the trends of the independent satellite-based lower-tropospheric temperature record or from the trend of the balloon-based near-surface measurements.”
What it means:
In the words of the authors, the adjustments that are being made to the raw USHCN temperature data “are producing a statistically significant, but spurious, warming trend in the USHCN temperature database.” In fact, they note that “the adjustments to the RAW record result in a significant warming signal in the record that approximates the widely-publicized 0.50°C increase in global temperatures over the past century.” It would thus appear that in this particular case of “data-doctoring,” the cure is worse than the disease. In fact, it would appear that the cure IS the disease.
From the paper: Our analyses of this difference are in complete agreement with Hansen et al. [2001]
and reveal that virtually all of this difference can be traced to the adjustment for the time of observation bias. Hansen et al. [2001] and Karl et al. [1986]
The reviewer notes: “Our prescription for wellness? Withhold the host of medications being given and the patient’s fever will subside.”
Originally from CO2Science


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea3ed9891',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

**March 1:** Mexico’s peso crisis is only the latest example of how misguided monetary policy can wreak havoc on economiclife and disrupt society. At a Book Forum, editors James A. Dorn and Roberto Salinas‐​León discussed their new book, _Money and Markets in the Americas_. The book provides a framework for thinking about how to end the monetary chaosthat has plagued Latin America and how to energize the market‐​liberal order that is now emerging in the Americas. SteveHanke, professor of applied economics at Johns Hopkins University; Sir Alan Walters, former economic adviser to MargaretThatcher; and Ed Hudgins, Cato’s director of regulatory studies, provided comments. 



**March 7:** At a Capitol Hill Policy Forum, “It’s Time to Tear Up the Tax Code: The National Retail Sales Tax,“cosponsored with the National Taxpayers Union and Citizens for an Alternative Tax System, Cato’s director of fiscal policystudies Stephen Moore led a discussion on completely replacing the tax code with a retail sales tax. The panel included Rep.Dan Schaefer (R‐​Colo.), Rep. Billy Tauzin (R‐​La.), David Keating of the National Taxpayers Union, David Burton of theArgus Group, and Vic Krohn of Citizens for an Alternative Tax System. 



**March 8:** A debate over whether regulations, like legislation, should have to be signed by the president before they becomelaw was the centerpiece of a Cato Policy Forum on “Ending Regulation As We Know It: Legislative Deregulation inthe Dock.” Professor Marci Hamilton of Cardozo Law School discussed the highly controversial constitutional questionssurrounding legislative delegation, and Professor David Schoenbrod of New York Law School, author of Power withoutResponsibility: How Congress Abuses the People through Delegation, addressed the policy ramifications of executive‐​branchlawmaking. Nadine Strossen, president of the American Civil Liberties Union, explained how civil liberties are curtailed by theabrogation of legislative responsibility. David Hawkins, senior attorney at the National Resources Defense Council, spokeabout how ending the delegation of lawmaking power to the executive branch will affect regulatory practice; and Rep. J. D.Hayworth (R‐​Ariz.) described legislation he has sponsored to require all lawmaking regulations to be affirmatively adopted byCongress and signed into law by the president before they take legal effect. 



**March 18:** Cato hosted a Capitol Hill Policy Briefing on the question, “Is the Immigration Bill in the NationalInterest?” A panel featuring Ben Wattenberg of the American Enterprise Institute, Scott Hoffman of Americans for TaxReform, and Stuart Anderson and Stephen Moore of the Cato Institute addressed the economic, demographic, and politicalimplications of the pending legislation. 



**April 3:** A Cato Book Forum celebrated publication of _Oil, Gas, and Government: The U.S. Experience_. Author RobertL. Bradley Jr., president of the Institute for Energy Research, debunked the “market failure” arguments for oil and gasregulation, including those based on a theory of natural monopoly, predatory pricing, and national security. 



**April 9:** A Policy Forum, “The New Prohibition? Freedom and Tobacco under Siege by the FDA,” asked whether theFood and Drug Administration is acting outside its statutory authority and threatening free speech. Sam Kazman of theCompetitive Enterprise Institute, Larry Pilot of McKenna & Cuneo, L.L.P., Jack Calfee of the American Enterprise Institute,and Matthew Myers of the Coalition on Smoking or Health debated the issue. 



**April 9:** The conflict over Taiwan is the latest in a series of rough spots in the U.S.-Chinese relationship. At a Policy Forumentitled “Tensions in the China Sea,” Ted Galen Carpenter, Cato’s vice president for defense and foreign policy studies;James Przystup, director of the Asian Studies Center at the Heritage Foundation; and Selig Harrison, senior associate at theCarnegie Endowment for International Peace, discussed the steps that Washington could take to avoid a showdown overTaiwan. 



**April 10:** The Honorable Vojt_​ch Cepl, a justice on the Czech Constitutional Court and currently E. L. WiegandDistinguished Visiting Professor of Democratization at Georgetown University, discussed the legal foundations of civil societyat a Roundtable Luncheon with Cato policy staff. Justice Cepl attributed the Czech Republic’s successful transition fromcommunism to capitalism to the combination of a tradition of civil society in Bohemia and Moravia and a carefully implementedpolicy of legal “lustration”: a clean legal break with the collectivist past. 



**April 11:** The inclusion of medical savings accounts (MSAs) in Medicare reform proposals has sparked an intense debateover “adverse selection”–the notion that MSAs will appeal only to the young and healthy, leaving traditional Medicare to servethe elderly and sick. Proponents of MSAs maintain that they will appeal to everybody because they minimize theout‐​of‐​pocket costs of both the healthy and the sick. At a Policy Forum entitled “Medical Savings Accounts and AdverseSelection,” Leonard Burman, tax analyst at the Congressional Budget Office; Edwin Hustead, chair of the MSA WorkGroup of the American Academy of Actuaries; and Peter Ferrara, general counsel and chief economist at Americans for TaxReform, debated the issue. 



**April 17:** Many Americans anticipate that the Federal Communications Commission will be doing less under theTelecommunications Act of 1996. The Clinton administration, however, has proposed increasing the FCC’s budget by almost$47 million. In light of those opposing expectations, Cato organized “The Future of the FCC,” a Policy Forum that askedwhat the administration’s policy bodes for proposals to phase out the FCC altogether. Discussants included Gregory Simon,chief domestic policy adviser to Vice President Al Gore; James Gattuso, vice president of policy research at Citizens for aSound Economy; and Kenneth Robinson, attorney at law. 



**April 17:** While the political tide of regulatory and statutory reform appears to have been stemmed for the time being by theenvironmental lobby, many people still criticize the centralized command‐​and‐​control regulatory structure of mostenvironmental laws. At a Policy Forum entitled “The Politics and Policy of Environmental Protection: Beyond the 104thCongress,” Kenneth Chilton, executive director of the Center for the Study of American Business, and Debra Knopman,director of the Center for Innovation and the Environment at the Progressive Foundation, discussed both what should be doneto reform the status quo and how to do it in the current political climate. 



**April 18:** As the Senate prepares to consider congressional term limits, Sen. John Ashcroft (R‐​Mo.) has launched anunprecedented online petition drive to highlight popular support for that constitutional change. At a Policy Forum entitled“Emerging Technologies and the Fight for Congressional Term Limits,” Senator Ashcroft discussed the role that termlimitation and emerging technologies can play in promoting participation in the democratic process. Introductory remarks wereby Paul Jacob, executive director of U.S. Term Limits. 



**April 23:** Recent Supreme Court opinions and the California Civil Rights Initiative have catapulted affirmative action to centerstage as we enter the political season. Not to be outdone, Congress itself will revisit its 30‐​year‐​old policy of groupentitlements this year as it debates H.R. 2128, the Equal Opportunity Act of 1995, a bill to end preferences in federalprograms, contracting, and employment. At a Capitol Hill Policy Forum entitled “An End to Preferential Treatment?“Cato’s director of constitutional studies Roger Pilon moderated a critical discussion of affirmative action. Panelists includedClint Bolick of the Institute for Justice, Faye Anderson Douglass of the Policy Institute, Linda Chavez of the Center for EqualOpportunity, Rep. Charles Canady (R‐​Fla.), and Rep. Tom Campbell (R‐​Calif.). 



**April 25:** Cato hosted a Roundtable Luncheon with Hisahiko Okazaki, former Japanese ambassador to Saudi Arabia andThailand. Okazaki spoke about U.S.-Japanese relations and East Asian security issues. 



**April 26:** The Institute hosted a City Seminar in New York City that featured a keynote address by John Stossel,investigative reporter for ABC’s 20/20. Other speakers included José Piñera, president of the Center for Pension Reform andcochairman of Cato’s Project on Social Security Privatization, and Cato’s president Edward H. Crane, director of fiscal policystudies Stephen Moore, and director of telecommunications and technologies studies Lawrence Gasman. 
"
"

Did Al Gore really deserve that Oscar for “An Inconvenient Truth”? The Left says yes — only the ideologically disabled or intellectually dishonest deny that the four horsemen of the environmental apocalypse (drought, disease, sea rise, and hurricanes) will soon devastate our fair planet. Reporter William Broad in the _New York Times_ today, however, says not so fast — a backlash is brewing among REAL scientists who are getting sick and tired of bed‐​wetting hysteria surrounding climate change.



The gist of their concern is this: while most (but not all) scientists are willing to accept that industrial emissions are an important driver in the planetary warming we’ve experienced since the late 1970s, they aren’t anywhere near so eager to embrace politically inspired warnings from non‐​scientists about how “the end is near.” Al Gore, according to many of the scientists interviewed by William Broad, is too shrill and too apocalyptic given the scientific evidence. 



Case in point: Al Gore warns in his documentary that sea levels will rise over 20 feet if warming continues. Yeah, well maybe in a thousand years or so if trends continue indefinitely, but the former Vice President leaves that little bit of perspective out of the movie. What might happen during our lives and the lives of our children and grandchildren? A sea rise of 23 inches, max, according to the new report just out from the Intergovernmental Panel on Climate Change. That’s hardly going to flood Manhattan, but acknowledging that would spoil the wonderful special effects visuals offered in the slideshow, now wouldn’t it? 



Gore’s scientific advisors, friends, and admirers defend the documentary and the book that followed by conceding that he may be a bit dodgy here and there, but that he gets the big picture right. That’s ridiculous. The fact that the planet is warming and that industrial emissions might well have something to do with it is not what this debate is ultimately about. This debate is whether we should or should not care. And if the former, how much should we be willing to sacrifice to do something about it? 



To say that Al Gore is to some extent out to lunch on the “should we care” argument but relatively sound on the question about whether we’re warming the planet (at least, if we measure these things by that most holy of metrics, the “scientific consensus” as defined by the IPCC) is akin to saying that the fellow proclaiming that a wrathful God is about to incinerate the planet is contributing to social welfare by usefully pointing out to the unbelievers that there is a God. That bit about God being particularly angry or plotting to destroy the world — Well, that’s a bunch of nonsense, but hey, he got the big picture right.



One of the scientists interviewed in the article — Roger Pielke, Jr. — wrote an essay recently for our own _Regulation_ magazine pointing out that science is inevitably corrupted when politicians decide to effectively delegate policymaking power to those who wear white frocks. So if you want to know why scientists aid and abet this kind of thing, go there. 
"
"Wind turbines are a leading source of green energy which could supply 12% of the world’s energy by 2020. But their use is often criticised for its impact on wildlife, particularly birds. Larger birds can collide with turbines and some have even learned to avoid flying near them. Impacts on smaller birds are less well documented as they tend to manoeuvre around turbines and can avoid impacting with them much more easily than larger species. My own research showed that birds associated with farmland, including a range of songbirds, were generally unfazed – their winter distribution didn’t change in the presence of turbines.  But there were also some intriguing patterns in the behaviour of skylarks in early spring. We noticed their numbers were generally lower close to turbines. I wondered then whether the noise emitted by the turbines might be responsible. Much of the evidence for how wind turbines affect birds concerns their distribution patterns around turbines, but we know little about why birds choose to avoid them. The robin, a widespread small bird which lives in rural areas where turbines are common, seemed a perfect candidate to investigate. Robins are an aggressive but popular species in the UK, having recently been voted the nation’s favourite bird. Males are territorial beyond proportion to their diminutive size. Nevertheless, we subjected territorial male robins to one of three treatments – another robin’s song, a robin’s song with wind turbine noise, and wind turbine noise alone – via a sound recording device inside their territory. Robins defending their territory typically respond to an intruder by increasing the proportion of low frequency sounds in their songs. We found that the robins subjected to robin song and wind turbine noise simultaneously had significantly fewer low frequency elements in their songs and so their songs sounded higher pitched. We interpreted this as interference from the wind turbine noise which occurs at low frequencies. It’s suspected that lower frequency noises make the robin singer “sound” bigger and thus reduce the need for more direct physical encounters to defend their territory. But with the low frequency sound emitted by wind turbines drowning them out, there was a suggestion that robins were having to rely more on puffing out their red chest to deter aggressors. That may be why breeding songbirds, such as the skylark, avoid turbines. Recent work has found breeding bird populations such as the Dupont’s lark, a near-threatened species of songbird found in North Africa and Spain, declined in areas with wind turbines. The underlying reason may be, at least partially, that birds avoid noisy habitat that makes communication more difficult. Another study looked at the long-term impact of noise from generators in a forest, and showed how it reduced territory quality for ovenbirds, a common warbler with a complex and beautiful song from the Americas.  


      Read more:
      Wind turbines aren't quite 'apex predators', but the truth is far more interesting


 The impact of wind turbines on birds goes beyond the risk of direct collision or avoidance. Noise emitted from turbines could disrupt their communication and leave them vulnerable. This is particularly troubling when we consider that wind turbines are often located in remote areas, some with high densities of songbirds, such as meadow pipits and skylarks in upland areas of the UK.  Of course, it is important to remember the bigger picture. While wind turbines may harm birds nearby, renewable energy is a vital solution to climate change – perhaps the most pressing threat to biodiversity globally.  Nevertheless, noise pollution from wind turbines should be measured during environmental impact assessments of wind energy projects, to ensure effects on the surrounding wildlife are minimised. That way, the robin and other songbirds might hope for more peaceful Christmases in future."
nan
"With the UK leaving the European Union and eyeing new trade opportunities beyond the EU, it should also be looking for ways to take forward its policies for reducing greenhouse gas emissions. One of the few advantages of Brexit might lie in being able to design policies that haven’t gone down the long and winding road of Brussels’ consensus building. Since the beginning of industrialisation, humanity has released 1.5 trillion tonnes of carbon dioxide into the atmosphere and, as a consequence, global temperatures have risen by 1°C. As the recent IPCC special report reminds us, we must pump out less than another 770 Gigatons to keep the total rise below 1.5°C.  This is not going to be easy. The currently stated ambitions of the world’s nations would actually increase outputs from their current total of just over 40 Gigaton a year to around 55 Gigaton by 2030. At 50 Gigaton a year we blow the 770 Gt budget in just 15 years. So, more must be done, and it must be done immediately. A carbon tax is arguably the most effective way of addressing the emissions problem as it provide a simple framework that everyone understands as well as the regulatory stability that allows businesses to plan ahead. Carbon taxes send a clear price signal and incentivise households and industry to change their behaviour.  Taxes are also superior to top-down regulation such as sector-specific reduction targets or even emissions trading. A carbon tax factors in the cost of CO₂ emissions to production, thereby forcing industry to account for it and reduce emissions. It is “technology-blind”, meaning a carbon tax does not pick a winner in the market and instead leaves it to industry to develop more sustainable production.  In practice, however, carbon taxes haven’t been very popular. Political leaders worry about support for anything called a tax and shy away from it. The recent fuel protests in France are a testimony to that fear. By increasing the cost of energy, taxes also risk increasing fuel poverty. In short, squaring the circle between climate goals and distributional equity is a matter of energy justice. The EU instead opted for an emissions trading system, the ETS, and other countries, including China, have adopted similar schemes. The ETS puts a cap on emissions, forcing polluters to buy carbon permits if they emit more than they can under their allocated quota. Permits are tradeable, thus creating a price signal for carbon. The problem with the EU’s ETS is that, until very recently, it has delivered prices around €5 per ton or less – a far cry from the €45 or more that would be needed for it to be compliant with targets set in the 2015 Paris agreement. The ETS also only covers a few industries, such as electricity generation, that, together, produce only 45% of the EU’s total emissions. So how can the UK enhance its climate leadership and keep citizens and businesses on board? A place for inspiration is Canada, the first nation to implement a carbon-fee and dividend scheme.  Their main idea was to tax carbon emissions and ensure money taken in taxes is given to the public in the form of a dividend paid to households. There is much to celebrate in such a scheme. The initial tax level might be something like £25 per tonne of carbon dioxide and, in the UK, we each produce about six tonnes per year. A rough back-of-the-envelope calculation suggests the tax could generate £150 per person per year.  A recent study estimates that the majority of households will come out rather well on a net basis, getting more back in carbon dividends than they would pay in carbon taxes, should the government roll out the scheme nationwide as planned. As research has shown, redistributing carbon revenues not only helps social equality, it also improves the acceptance of such taxes among taxpayers. It therefore makes it very hard for a future government to reverse the policy if people become attached to payments from the state. Just think how hard it would be for any government to repeal the UK’s winter fuel allowance for over 65s. 


      Read more:
      Electricity bills could rise if Brexit threatens Northern Ireland's unique energy agreement with Ireland


 An effective and socially acceptable carbon fee, in turn, fosters economic competitiveness. The Nordic countries, which pioneered carbon taxes, have become leaders in clean technology. Denmark has some of the world’s lowest unit energy costs thanks to drastically reduced energy use in their economic output. This, among other reasons, effectively shields the country’s industry from energy price shocks. The UK, in many respects already a climate frontrunner thanks to its carbon floor price, stands to learn from the Canadian experience as its post-Brexit low carbon policies take shape. In Europe, the UK is the second-largest polluter, behind only Germany in overall greenhouse gas emissions.  The UK can exert true leadership by designing progressive policies that benefit both people and the climate. If they work, this might set a model across the continent – whether from within or outside the EU."
"

Above: Earth in comparison, size wise to common sunspots
The Christion Science Monitor had a detailed article recently that brought in a surprisng source – NASA GISS – an entity that seems firmly entrenched in the AGW- CO2 theory of climate change. Here are some excerpts from the article:
Researchers say they’ve found puzzling correlations between changes in the sun’s output and weather and climate patterns on Earth. These links appear to rise above the level of misinterpreted data or faulty equipment.
“There are some empirical bits of evidence that show interesting relationships we don’t fully understand,” says Drew Shindell, a researcher at NASA’s Goddard Institute for Space Studies in New York.
For example, he cites a 2001 study in which scientists looked at cloud cover over the United States from 1900 to 1987 and found that average cloud cover increased and decreased in step with the sun’s 11-year sunspot cycle. The most plausible cause, they said: changes in the ultraviolet (UV) light the sun delivers to the stratosphere.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea38acdc3',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"
Share this...FacebookTwitterA new paper reveals that climate models have failed to take important natural factors, such as the North Atlantic Oscillation, into account in their climate models on which leaders have been basing their policies. 

 A new paper in Nature says NAO not taken adequately into account by climate models. Image: see video (German) here.
Paper in Nature Criticizes NAO Hole: Medium-Term Climate Far More  Predictable Than Climate Models Suggest
By Die kalte Sonne
(German text translated/edited by P. Gosselin)
Can the ups and downs of the climate of the coming years and decades be predicted? A large group of researchers (Smith et al. 2020) affirms this and describes in a Nature article that much more is possible here than current climate models suggest.

Image Source: Smith et al., 2020
North Atlantic climate far more predictable than models imply
Quantifying signals and uncertainties in climate models is essential for the detection, attribution, prediction and projection of climate change1,2,3. Although inter-model agreement is high for large-scale temperature signals, dynamical changes in atmospheric circulation are very uncertain4. This leads to low confidence in regional projections, especially for precipitation, over the coming decades5,6. The chaotic nature of the climate system7,8,9 may also mean that signal uncertainties are largely irreducible. However, climate projections are difficult to verify until further observations become available. Here we assess retrospective climate model predictions of the past six decades and show that decadal variations in North Atlantic winter climate are highly predictable, despite a lack of agreement between individual model simulations and the poor predictive ability of raw model outputs. Crucially, current models underestimate the predictable signal (the predictable fraction of the total variability) of the North Atlantic Oscillation (the leading mode of variability in North Atlantic atmospheric circulation) by an order of magnitude. Consequently, compared to perfect models, 100 times as many ensemble members are needed in current models to extract this signal, and its effects on the climate are underestimated relative to other factors. To address these limitations, we implement a two-stage post-processing technique. We first adjust the variance of the ensemble-mean North Atlantic Oscillation forecast to match the observed variance of the predictable signal. We then select and use only the ensemble members with a North Atlantic Oscillation sufficiently close to the variance-adjusted ensemble-mean forecast North Atlantic Oscillation. This approach greatly improves decadal predictions of winter climate for Europe and eastern North America. Predictions of Atlantic multidecadal variability are also improved, suggesting that the North Atlantic Oscillation is not driven solely by Atlantic multidecadal variability. Our results highlight the need to understand why the signal-to-noise ratio is too small in current climate models10, and the extent to which correcting this model error would reduce uncertainties in regional climate change projections on timescales beyond a decade.
The authors looked at the behavior of the North Atlantic winter climate over the last six decades and found that there is basically good predictability. Yet, current climate models do not make use of this as they underestimate the influence of the North Atlantic Oscillation (NAO) by an entire order of magnitude. The noise is still too high in the climate models, and the real signal is lost.
The paper is so important that even Science commented on it at the end of July 2020
Missed wind patterns are throwing off climate forecasts of rain and storms
Climate scientists can confidently tie global warming to impacts such as sea-level rise and extreme heat. But ask how rising temperatures will affect rainfall and storms, and the answers get a lot shakier. For a long time, researchers chalked the problem up to natural variability in wind patterns—the inherently unpredictable fluctuations of a chaotic atmosphere.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Now, however, a new analysis has found that the problem is not with the climate, it’s with the massive computer models designed to forecast its behavior. “The climate is much more predictable than we previously thought,” says Doug Smith, a climate scientist at the United Kingdom’s Met Office who led the 39-person effort published this week in Nature.
[…]
The study, which includes authors from several leading modeling centers, casts doubt on many forecasts of regional climate change, which are crucial for policymaking. It also means efforts to attribute specific weather events to global warming, now much in vogue, are rife with errors. “The whole thing is concerning,” says Isla Simpson, an atmospheric dynamicist and modeler at the National Center for Atmospheric Research, who was not involved in the study. “It could mean we’re not getting future climate projections right.”
You can read the entire commentary at Science.
Forecasts based on weak models
Now medium-term forecasts based on the weak computer models are being put to the test. Unfortunately, these are exactly the same forecasts that have already been used for political planning purposes. Now it is probably dawning on the latter: “the Science is NOT settled”.
Climate snake oil
Even the “attribution game” of extreme weather events, which is so popular in the media, is now being put on the back burner. Not good news for Friederike Otto, who has already been treated as an attribution superstar in the media, as she claimed to be able to calculate with percentage accuracy how much man was involved in a storm, flood or drought.
But wait, the German-language media did not even report on this important new paper…perhaps it did not fit into the climate narrative given from above. Fortunately, there is the Die kalte Sonne climate blog: That’s the first place you’ll hear it.
NAO ignored too long… stirring resistance
By the way, the systematic influence of the NAO on European temperatures has also been described by Lüdecke et al. 2020 a few months earlier. So it was a logical further step by Smith et al. 2020 to actively demand improvements in climate models.
The effect of the NAO has been known for decades. Surprisingly, it is only now that resistance is stirring in the scientific community, since it was actually clear that the models did not reflect these empirically well-documented relationships.


		jQuery(document).ready(function(){
			jQuery('#dd_b898986594013ea7fb3b1091acdc7faf').on('change', function() {
			  jQuery('#amount_b898986594013ea7fb3b1091acdc7faf').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"There is a touch of the Dickensian about the urban pigeon, often seen hobbling about on gnarled stumps, pecking at trash. The mongrel mix of grey and brown plumage on feral pigeons adds to the dowdy look, the occasional iridescent flash on neck feathers too obvious, too cheap. Dickens himself wrote of the pigeons of Spitalfields in London, associated with the poorest hovels: The pigeon hutches and pigeon traps on the tops of poor dwelling.  Our local shopping mall entrance regularly echoes to the wheeling scream of a recorded peregrine falcon, played purposefully to scare away the pigeons. Urban animal life, whether domestic or feral, has often been lumped in with the socially excluded – beggars, drunks and revellers and the like. Meanwhile other pigeons provoke intense concern. The pink pigeon of Mauritius is a heartwarming example of what we can do to protect endangered species. In 1975 only ten birds lingered at just one site. It was listed by the IUCN as Critically Endangered in 1994 – “possibly the most threatened bird in the world”. Today there are around 400 in the wild of Mauritius.  This pigeon has some distinct advantages. It is pink, it lives on an exotic island famous for the Dodo and it has had some big-name backers – notably author Gerald Durrell, who brought some into captivity in 1976 to breed and started a programme of releasing them back into the wild – along with intensive habitat management. As a result, the pink pigeon’s numbers and range have markedly increased, with wild-bred young now turning up. Pink pigeons in Mauritius have turned the corner. Meanwhile their urban grey brethren remain every bit the unloved city mob. The urban pigeon is a great example of the inheritors of the Earth described by ecologist Chris Thomas – species that do well because of us, thriving in the world we have created. Theirs is a biodiversity of cityscapes, a zoopolis deserving of our respect. Not least because the rats, racoons and pigeons of our cities are so like us – at home in concrete landscapes and on diets of processed food. I am not against the effort expended on the pink pigeon at all. They are cute and exotic, two prime criteria for conservation – but the urban pigeon deserves our respect too. The great shame is that other members of the pigeon family are also at risk, species that were once commonplace, which can hardly be said of the pink pigeon.  


      Read more:
      Where are all the dead pigeons?


 Take the turtle dove, for example, which belongs to the same family as pigeons. In the UK, the turtle dove population has declined by more than 95% in barely two decades. This once common farmland dove is a bird of high summer – its call is a sleepy drone on the hottest days. It is the dove of poetry and ballads, the Phoenix’s lover in a Shakespeare sonnet. We understandably focus so much effort on rare species while we don’t notice that the commonplace is in sharp decline. Thankfully, the turtle dove is now the focus of its own conservation projects. The urban pigeon needs no such help, although they have fallen from grace since the days when pigeon fancying was a widespread hobby, which even had Charles Darwin hooked. Pigeons in all their domestic variety feature large in Darwin’s book, The Variation of Animals and Plants Under Domestication. Darwin installed a pigeon breeding loft in his home and gathered invaluable insights into how traits are inherited through reproduction by studying their breeding. Pigeons are likely to be more qualified muses for Darwin’s theories on evolution by natural selection than the commonly cited Galapagos Island finches. 


      Read more:
      Humans not entirely at fault for passenger pigeon extinction


 The story lends a distinct air of erudite science and respectability to the gentlemen pigeon fanciers of Victorian times. Not so any more – pigeon fancying is now a peripheral pastime of a lost world of old men tending their pigeon crees in tucked away allotments and backyards. Turtle doves and pink pigeons will always arouse our sympathy, while the dodo and passenger pigeon – once the most numerous bird in North America before dying out in 1914 – stand as accusing witnesses. Meanwhile the feral pigeon battles on, hobbling, chased by kids, tormented by mall managers, swallowed whole by pelicans. You can’t help but admire them."
"
Rounding out a review of California weather stations this week we visit Gilroy, CA, the garlic capital. This COOP station has an MMTS temperature sensor on a pole just a few feet from a concrete slab. We’ve seen a lot of that lately. But look closely – roasted garlic anyone?

Photo from NWS, San Franciso/Monterey CA
While it’s likely the BBQ grill is not used daily, one has to wonder just how much bias it’s proximity imparts into the temperature record. This station  COOP number is 04-3417 as is part of NOAA’s “A” network which reports climate to NCDC. It is located at the Fire station in Gilroy, seen below. Notice that is is also near a large parking lot and major intersection downtown. So much for NOAA’s 100 foot rule for station siting.


Click on the picture for a larger interactive view
The recently released paper from LaDochy et al. showed that “urban” stations warmed at a rate of 0.20°C per decade while the “non-urban” stations warmed only 0.08°C per decade, with the lack of attention to the measuring environment such as we see here, is it any wonder?


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea26beeda',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Earlier I wrote up an essay on the NOAA climate station at Cordova, AK.
Click thumbnail at left for a larger image. 
  
This station was directly next to the village diesel power plant. That station also happens to be part of the NASA GISS surface temperature record used for climate research. The problem is the proximity to nearby human caused heat sources, which may not be accurately adjusted for in the record. Of course the real issue is that if the stations were properly setup and maintained by NOAA, paying attention to their own 100 foot rule, such potential bias would not be an issue. Today I’d like to show you a few other NOAA climate stations in Alaska.
Click thumbnails below for larger images.
Thanks to John Papineau for these photographs






English Bay – note the MMTS temperature sensor within about 1 foot of the building.No cold winter nights for this sensor!


 



Moose Pass – note the concrete structure which is a fish hatchery
NCDC record says: HATCHERY, OUTSIDE & 3 MI NW OF PO AT MOOSE PASS, AK


 




Susitna Landing – note proximity to building this was installed on May 21st, 2003

NCDC record says: FLAT GRAVEL AREA NEAR CONFLUENCE OF KASHWITNA AND SUSITNA RIVERS. How would a researcher know about the building proximity from this?




 


  
  
Seward 19N – note proximity to building
NCDC Record says: OBSERVERS HOME, OUTSIDE & 19.5 MI N OF PO AT SEWARD, AK Again, how would a researcher know about the building proximity?





 





Seward #2 – note proximity to street and shading issues. You can see the station location in Google Earth.




 



Tutka Bay – note proximity to building and weathering of old Stevenson Screen shelter.


 


As I’ve been saying, the MMTS temperature sensor and it’s cable is systematically forcing measurements closer to human influences. They problem clearly is not unique to the continental United States as these photos from Alaska demonstrate.
In all of Alaska’s open wilderness, are these truly representative of the climate? It seems that every station is close to the small packets of towns and villages that dot Alaska, and necessarily so, since a human observer is required to read and record the thermometer.
Surely though, a better job at station siting could have been done.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea15855be',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

This was forwarded to me by Russ Steele over at NCWatch. Titled: Climate Change – Is CO2 the cause? 
It’s a compelling presentation by Bob Carter of the facts of climate change to a recent public forum in Australia.  He is a research professor in the Marine Geophysical Laboratory at James Cook University, Australia. He’s featuring a “Count the torpedos” element.
My www.surfacestations.org project is highlighted in Part 4. It is gratifying to see my work used by others,
Part1
Part2
Part3
Part4


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea3616c34',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

I had just finished reading a speech by George W. Bush in which he calls for creating a Compassion Capital Fund whereby the federal government would finance a wide variety of local social initiatives that “worked” when I received a letter from Milton and Rose Friedman asking me to give a speech at the upcoming Vancouver Mont Pelerin Society meeting making the optimistic case for the future of liberty. I didn’t know whether to laugh or to cry. After all, when the leading candidate of the so‐​called market‐​oriented party in the U.S. thinks that federal bureaucrats could or should engage in such activities, one despairs for the future of liberty. But one also doesn’t turn down Milton and Rose Friedman, so here I am.



Which is fine, because the truth be known, I genuinely am optimistic about the future for liberty in the world and, specifically in the United States of America. I apologize in advance, by the way, to our non-U.S. members and guests for the mostly provincial nature of my comments, but I think there is generally a universal applicability to the points I’ll be making. To begin with, what do we mean by liberty? To this audience the definition won’t be as contentious as it is for most of society, because as Hayek points out in the beginning of _The Constitution of Liberty_ , Abraham Lincoln said, “The world has never had a good definition of the word liberty … We all declare for liberty: but in using the same word, we do not mean the same thing.” Which is true, of course, but Hayek typically cuts quickly to the chase, saying we should seek “that condition of men in which coercion of some by others is reduced as much as possible in society.” He contrasts liberty to slavery by saying that liberty involves “the possibility of a person’s acting according to his own decisions and plans, in contrast to the position of one who was irrevocably subject to the will of another.”



By that standard the march of freedom that Milton described on Monday has indeed been impressive. And Milton said something else in his talk that is equally important in terms of assessing the prospects for liberty. He talked about the overwhelming support for socialism and the “tiny pockets of people who believed in freedom” back in 1947 when our Society’s founders met on Mont Pelerin. Everything must be put in perspective. My friend and one of the great champions of liberty in the Twentieth Century, the late Julian Simon, was keenly aware of this fact. Whenever a left‐​wing environmentalist would point to some trend starting in, say, 1985, the first thing Julian would ask was, Why 1985? Why not 1975 or 1875?



In a debate with environmentalist Hazel Henderson in 1996 Julian was confronted with a with a chart purporting to show the decline in pollution levels in London since the passage of London’s Clean Air Act of 1956. In his rebuttal, Julian produced his own chart showing the smoke levels in London dating back to the 1800s and, as reported in a great _Wired_ magazine profile of Simon, “the line from the 1920s on showed a constant and uniform downward slope. ‘If you look at all the data,’ Julian said, ‘you can’t tell that there was a clean‐​air act at any point.’ ”



And so in projecting the prospects for liberty, it’s probably useful to stand back a bit from the Compassion Capital Funds of 1999 and put things a bit more in perspective. In 1772 when there were 775,000,000 people inhabiting the world, it is estimated that only about 33,000,000 of them lived under relatively free governments. Some 95 percent of humanity lived lives described by historian Arthur Young as “miserable slaves of despotic tyrants.” As late as 1848, according to Julian Simon, the share of serfs among the population of Austria was about 72 percent, and in Hungary about 50 percent.



By another measure, worldwide per capita income in 1800 was $100; by 1900 is was about $500; next year it will be about $5000 and by the end of the next century some estimates put it to be in excess of $40,000, or higher than the average Western income of today. It could, of course, turn out to be much greater than even that.



In addition, any long term assessment of human liberty has to take into account the collapse of communism. Hundreds of millions of people today are free from the yoke of communist totalitarianism under which they labored just a decade or so ago. The change has been dramatic, even in Russia, despite all its difficulties. In those nations that have really moved toward capitalism, the past decade has been nothing short of exhilarating. As _Business Week_ noted a couple of months ago, for instance, “Poland has enjoyed brisk economic growth for most of the decade because it chose radical reform, and despite the pain, stuck with it.”



The only remaining communist country of any consequence is China which, as Milton has pointed out, for all it’s human rights failings is nevertheless clearly headed in a capitalist direction. The Associated Press distributed a photo recently of a protester in Tiananmen Square sporting an umbrella painted with the slogan “Privatize. Give all state property to the people.” He was arrested, to be sure, but when such subversive ideas are alive in the land, the end is near for the thugs in Beijing. 



And not all of the Chinese leaders in Beijing are thugs. A couple of years ago in Shanghai Jose Pinera and I met with an individual from Beijing who has been charged with responsibility for creating a public pension system in China. His name is Sun Jianyong and as he approached us in the lobby of the Peace Hotel, Jose remarked, “But you are much younger than I had anticipated.” To which Sun, who appeared to be in his late thirties, replied, “But you were only thirty when you privatized Social Security in Chile.” At the meeting Sun convinced us that he was a great admirer of the Chilean system because of the higher income at retirement, the economic boost from increased savings, and, he said, because it gave people the dignity of not depending on the state for their retirement income. Some communist.



Speaking of the collapse of communism, I think one of the clear indicators of the fact that liberty has the long‐​term momentum today is what Vaclav Klaus and John O’Sullivan talked about on Monday. The so‐​called Third Way. Because, believe me, Bill Clinton, Tony Blair and those other European politicians wouldn’t be adopting that phrase — the Third Way — if socialism wasn’t as thoroughly discredited as it is. They are leftists who are trying desperately to hide that fact from the voters. To a large degree they’ve succeeded. But such deceit won’t be successful over the long haul as it becomes increasingly evident that whatever they call themselves, they always end up promoting more state intrusion into civil society. Bill “The era of big government is over” Clinton, for instance, offered no fewer than 95 new or expanded federal interventions in his January State of the Union Address. The Third Way politicians are trying to sugar‐​coat statism in the rhetoric of free markets and reinventing government, but in the Information Age they will sooner or later — sooner, probably — be exposed for the frauds that they are.



I mentioned the interest in China in setting up a private, individually capitalized pension system. There is, of course, tremendous interest in doing so in the United States also, in large part, because of the work of the Cato Institute, the Heritage Foundation and the National Center for Policy Analysis, each of which, in turn, is indebted to the incredible work of the international Pied Piper of pension reform, our good friend Jose Pinera. Even if we live in an era of Bill Clinton and George W. Bush in the U.S., the fact is that by any objective standard, classical liberal ideas are making remarkable progress in the national policy debate there. Privatizing Social Security is supported by two‐​thirds of the population in the United States, and if you talk to people under 50, it’s nearly unanimous. Men and women, Republicans, Democrats and Independents, union workers, blacks, whites, Asians, and Hispanics all overwhelming favor junking Social Security, the centerpiece of the New Deal. When asked if when a system is set up to allow the purchase of stocks and bonds government or individual workers should be allowed to invest the funds, by a margin of nearly five to one, Americans say individuals should be allowed to invest on their own. They also say the present government‐​run pay‐​as‐​you‐​go system is riskier than the market. This is all from a Zogby International poll we commissioned recently that will be released in a week or so. In looking over those poll results, by the way, I was reminded of a poll from the Pew Research Center last year that asked government officials this question: “Do Americans know enough about issues to form wise opinions about what should be done?” Here are the results. Among members of Congress 31 percent said yes, 47 percent said no. Among Presidential appointees, 13 percent said yes, and 77 percent said no. Civil servants also are disdainful of the American people, with 14 percent saying the public can form wise decisions and a whopping 81 percent saying no, they can’t. This huge gulf between the political class and the people in the U.S., it seems to me, is another cause for optimism.



Getting back to Social Security, it’s true that neither political party has had the courage to call for complete privatization today, but that’s what the people want and it may well turn out to be a decisive issue in next year’s presidential campaign. Dr. Pinera, who’s working with Cato in our efforts in that regard, has already succeeded in bringing some form of privatization to pension systems in no less than eight Latin American countries and, most recently, Poland. To achieve such a thing in the U.S. would not only dramatically change our political dynamics in a very favorable direction from a classical liberal perspective, I believe it would also put tremendous pressure on the European Union and Japan to follow suit. They cannot compete with the U.S. or survive forever with public pension systems that feature unfunded liabilities of two or three hundred percent of GDP.



There are other significant policy gains evident in the U.S. today — which is not to say that we’ve won them — but that progress is clearly being made. Today the education monopoly is under attack as never before. The teachers unions are in rapid retreat, throwing Charter Schools at the snarling masses in the hopes of placating them before they tear down the walls of their monopoly. Ten years ago, not to mention when Milton Friedman first wrote about school vouchers, the unions were impervious to criticism. 



In the area health care, there is a growing understanding that it’s the third party payer system, whether government or first dollar insurance coverage, that’s to blame for bureaucratized and expensive health care in America. Hillary Clinton’s effort to sell essentially the Canadian system as the model for the U.S. broke down when it became common knowledge that people in this country travel south when they have serious health problems, despite the deficiencies of the U.S. system. There is a serious effort underway now to expand Medical Savings Accounts and, indeed, to separate health insurance from employment through equal tax treatment, something a growing number of major corporations in the U.S. now favor. All of this undermines efforts to socialize medicine in the United States.



In other policy fronts, the welfare establishment has never really recovered from the assault on its hegemony by Charles Murray’s _Losing Ground_ and today lives with the reality that welfare is no longer a federal entitlement. Most people clearly understand the counterproductive nature of the dole and are determined to hold their fellow citizens responsible for their own actions, as they did prior to the advent of the paternalistic Great Society programs of the Sixties.



There is also a growing consensus that scrapping the 9000‐​plus page IRS code in the U.S. would be a good thing to do. Tax simplification is something all politicians now must at least pay lip service to. At Cato we frequently have forums on the flat tax or replacing the income tax altogether, not with a VAT, but with a retail sales tax. It is virtually impossible to get a politician or even someone from the IRS to defend the current system at these events. Radical simplification of the tax code not only would be good economically, but it would end the patronizing policies of politicians who now use the tax code to socially engineer citizen behavior. It would also create some taxpayer solidarity in the movement to sharply lower taxation in America. We are making progress in this area, including creating a consensus to abolish both the capital gains tax and the death tax.



Further, trade policy has clearly been on a positive trend in the U.S. for decades. Free traders have won the intellectual battle. The United States today has lower tariffs, as measured by the ratio of tariff income to the value of imports, than at any time in our history. In 1929 with the Smoot‐​Hawley tariff, that number stood at nearly 60 percent. Today it is less than 4 percent. Furthermore, trade and foreign investment income as a percentage of GDP in the U.S. is at an all‐​time high of 30 percent, when as recently as three decades ago it was only 15 percent of GDP. Internationally, a large number of countries ranging from Chile, to Mexico, Argentina, Australia, New Zealand, the transition countries of Central and Eastern Europe and even, to a certain degree, India, are following suit. As, indeed, they must if they’re to survive in the new global economy.



One other positive development in the United States has been a series of court decisions that may portend the end of a very sorry history of jurisprudence in the U.S. dating back to 1937 when Franklin Roosevelt threaten to pack the Supreme Court unless it agreed to ignore its clear constitutional responsibilities and capitulate to FDR’s grand social schemes. Thomas Jefferson once said that “The natural progress of things is for government to gain ground and for liberty to yield.” Kind of an early Public Choice analysis. What Jefferson and most of the American Founders understood so well was that there is an inherent built‐​in bias for the state to expand. The statist imperative, if you will. Without some kind of institutional constraints — in the case of the United States, the Constitution — the majoritarian instinct in a democracy would naturally lead to the tendrils of the state reaching into every corner of civil society.



As they pretty much have since 1937. But, as I say, that all may be changing. The father of the Constitution, James Madison, said that the courts were to be the “bulwark of our liberties” against the inevitable majoritarian onslaught from the two political branches of the national government. In recent years the federal courts have once again started defending property rights, have been firm in support of free speech rights, have challenged Congress not to delegate its power to unelected bureaucrats, and even have resurrected the essence of the Constitution, the Doctrine of Enumerated Powers, whereby if the power is not specifically delegated to the national government it is reserved to the states or to the people. A renaissance of respect for the Constitution, which seems to be taking place in the States, is imperative if the prospects for liberty are to be as positive as they should be.



So, in conventional terms, the prospects for liberty are, if you stand back far enough, pretty bright. But as the people in this room are well aware, there are other forces at work which augur even more brightly for a global future with far less political society and far more civil society. I speak, of course, of the Information Age and the two most dramatic things it brings to society: widespread, diversified and instantaneous access to knowledge, and on the financial side of the ledger, what economist Richard McKenzie accurately calls “quicksilver capital” — the ability of capital to move anywhere in the world with the click of a mouse. An ancillary benefit of the financial revolution that is occurring, and to which Milton briefly referred, is what our colleague Richard Rahn refers to as “the end of money.” There are brochures on his book of the same name at the Cato table outside and I highly recommend that you order a copy of the book, which must be giving central bankers around the world severe cases of heartburn.



At the Cato Institute we prefer to discuss the political battle, that is, man’s relationship to the state, in terms of civil society versus political society, rather than liberal versus conservative or even libertarian. In a civil society you make the choices about your life — how to spend your money, where to send your children to school and so forth — in a political society, based as it is on coercion, somebody else — a politician or a bureaucrat — makes those decisions. The goal, it seems to us, should be to minimize the role of political society consistent with the protection of our individual liberties.



Political society, of course, has historically derived its power from three main sources: Geographical territory, which is to say land; control of the flow and nature of information because knowledge is power; and control over capital flows and the value of a nation’s currency. The Information Age is eating away at those three sources of power just as surely as the sun rises in the East.



Geographical territory and natural resources, as Hong Kong let anyone who was paying attention know decades ago, become increasingly irrelevant with the advent of the new Global Economy made possible by the information revolution in knowledge and finance. Indeed, the computer‐​challenged Soviet Union ended up finding geographical territory a liability in its contest with the information‐​rich West. Let me read to you from a book that’s been on the _New York Times_ bestseller list for four months now. It’s called _The Lexus and the Olive Tree_ and it’s written by the _Times_ ’ chief foreign correspondent, Thomas Friedman. Friedman, I should say, unlike our Friedmans, is a liberal in the bad sense of the word — an Al Gore Democrat. But the first half of the book is really terrific. He refers in the following quote to the “Golden Straitjacket,” by which he means that in order to benefit from the new global economy, nations must play by certain rules. Here’s what he writes:



“To fit into the Golden Straightjacket a country must either adopt, or be seen as moving toward, the following golden rules: making the private sector the primary engine of its economic growth, maintaining a low rate of inflation and price stability, shrinking the size of its state bureaucracy, maintaining as close to a balanced budget as possible, if not a surplus, eliminating or lowering tariffs on imported goods, removing restrictions on foreign investment, getting rid of quotas and domestic monopolies, increasing exports, privatizing state‐​owned industries and utilities, deregulating capital markets, making its currency convertible, opening its industries, stock, and bond markets to direct foreign ownership and investment, deregulating its economy to promote as much domestic competition as possible, eliminating government corruption, subsidies and kickbacks as much as possible, opening its banking and telecommunications systems to private ownership and competition, and allowing its citizens to choose from an array of competing pension options and foreign‐​run pension and mutual funds.…As your country puts on the Golden Straightjacket,” he writes, “two things tend to happen: your economy grows and your politics shrinks.”



Not bad for a liberal Democrat, is it? Before you Americans decide to vote for Al Gore, however, I should point out that the second half of _The Lexus and the Olive Tree_ is truly awful — full of mush‐​minded environmentalism, bleeding‐​heart calls for more funding for the IMF and World Bank, and more taxing of the rich. So, he doesn’t really get it, but Friedman’s analysis of the nature of the new global economy is brilliant. So brilliant, in fact, that I think much of the analysis came directly from Walter Wriston’s wonderful 1991 book, _The Twilight of Sovereignty_. That book, written in anticipation of the Internet, has to be one of the most thoughtful, prescient books of all time. Walt Wriston simply sees things the rest of us can’t.



In it he writes, “Intellectual capital is becoming relatively more important than physical capital. Indeed, the new source of wealth is not material, it is information, knowledge applied to work to create value. The pursuit of wealth is now largely the pursuit of information.” And in competition with the private sector today, government can’t possibly keep up in the pursuit of information. Individuals are being empowered irrespective of borders; irrespective of what politicians have done throughout the sorry history of government domination of society, which is happily coming to an end: The twilight of sovereignty, as Walter puts it.



And as Walter knows so well, one of the great sources of power for the state has been its ability to control capital flows by regulating major financial institutions, among other means. But one of the great aspects of the information revolution has been disintermediation — the decreasing need for the middleman, for major institutions — and the increasing ability of people to deal with one another directly, anywhere in the globe. Consider, for instance, the fact that in 1997 the singer David Bowie raised $55 million in capital based on his projected royalties. The ability of capital markets to securitize virtually any future income flow, combined with the ability of companies to set up operations virtually anywhere on the globe, means that developing nations can expect explosive growth in the next century and that IMF and World Bank bureaucrats can start looking for honest work.



Richard Rahn writes in his book, “The world’s people will be neither truly prosperous nor free unless governments retreat from their seemingly never‐​ending desire to control the production and use of money.” He then goes on to persuasively demonstrate that they have no choice but to give up that control. Private, digital, encrypted money is already a reality and it will become the norm early in the next century. It is likely that those nations that wish to preserve their sovereignty in the future will do so only in a superficial sense, and then only by pursuing policies of very low taxation and free and open trade.



We live in interesting times. When the Agricultural Age turned into the Industrial Age virtually no one was aware of what was happening. But as the Industrial Age turns into the Information Age, by virtue of the age it’s turning into, virtually everyone is aware of it. It’s estimated that by the end of the year 2000 some 100 million Americans will be plugged into the Internet. Some even suggest that the Internet may come to Canada. _Wired_ magazine has dubbed those individuals who participate on the Net, Netizens. In a classic article from 1997 in _Wired_ , Jon Katz wrote, “The Digital Nation constitutes a new social class. Its citizens are young, educated, affluent. They inhabit wired institutions and industries — universities, computer and telecom companies, Wall Street and financial outfits, the media.…and some of their common values are clear: they tend to be libertarian, materialistic, tolerant, rational, technologically adept, disconnected from conventional political organizations — like the Republican or Democratic parties — and from narrow labels like liberal or conservative.…The digital young, from Silicon Valley entrepreneurs to college students, have a nearly universal contempt for government’s ability to work; they think it’s wasteful and clueless. On the Net, government is rarely seen as an instrument of positive change or social good. Politicians are assumed to be manipulative or ill‐​informed, unable to affect reform or find solutions, forced to lie to survive.”



Katz went on to suggest that this Netizen community will fuse technology with politics in such a manner as to advance civil society. I think he’s right. The twilight of sovereignty means the dawning of a new age of liberty and the empowerment of individual choice. The world is moving toward pluralism, capitalism, and civil society. It will take time, but it likely will happen. But it will happen because as the world community grows, as we get to know one another and work with one another around the globe, independent of the political process, civil society will flourish. Increasingly, it will be groups like the Mont Pelerin Society, and not political parties, that lead the way. I’m reminded of that famous quote from the French politician Alexandre Ledru‐​Rollin, who was quoted while among the mob during the Paris revolt of 1848 as saying, “There go the people. I must follow them, for I am their leader.”



Politicians and political society are not the answer. The Mont Pelerin Society, uncountable other voluntary organizations and civil society are the answer. Thus, let me conclude with the same plea my colleague Bill Niskanen made at last year’s meeting in Washington, D.C. We do live in the information age today. There clearly was a time in 1947 and through the Fifties when the idea of secret, off‐​the‐​record talks at MPS made sense, given the intellectual climate of the time. But my goodness, our members win Nobel Prizes now. We should be celebrating the fact that classical liberals from dozens of nations attend these events. We should invite the media in and drop the conceit that we have something to hide, or something for which the outside world is somehow not worthy. The future of liberty does indeed look bright, but it won’t happen automatically. It will require leadership and openness. I trust we can all work together toward that goal. Thank you very much.


"
"
There’s a story at the Telegraph UK from Christopher Booker where he states “…the latest US satellite figures showing temperatures having fallen since 1998, declining in 2007 to a 1983 level…”
Wanting to make sure that there was some data to reference this claim for my readers, I’ve presented some graphs of satellite microwave sounder data below.
MSU data are produced by Remote Sensing Systems and sponsored by the NOAA Climate and Global Change Program. Data are available at www.remss.com 
Below are the trend graphs for the data since 1979. Note that these graphs are multi channel, which represent different microwave sounder wavelength channels from the spacecraft. These channels represent different measured levels of the atmosphere.
Channel. TLT – Lower Troposphere
 
Channel TMT – Middle Troposphere

Channel TTS – Troposphere and Stratosphere combined

Channel TLS – Lower Stratosphere

Above: Global, monthly time series of brightness temperature anomaly for channels TLT, TMT, TTS, and TLS.
All matter emits microwave radiation that varies with its temperature, among other factors. Microwave sensors on weather satellites can take more than 60,000 temperature measurements of oxygen in the atmosphere, from the surface to about 10 km (6 mi) altitude.
NOAA and it’s affiliated researchers have compiled almost three decades of data showing how atmospheric temperature has behaved over the entire globe.  At UAH (University of Alabama, Huntsville) where Dr. John Christy and Dr. Roy Spencer have been keeping watch on this trend for some time as well, they have tabular data online should you care to plot it. Here is an ongoing history of the data. You can see some of their other work here.
For Channel TLT (Lower Troposphere) and Channel TMT (Middle Troposphere), the anomaly time series is dominated by ENSO events and slow tropospheric warming. The three primary El Niños during the past 20 years are clearly evident as peaks in the time series occurring during 1982-83, 1987-88, and 1997-98, with the most recent one being the largest. Channel TLS (Lower Stratosphere) is dominated by stratospheric cooling, punctuated by dramatic warming events caused by the eruptions of El Chichón (1982) and Mt Pinatubo (1991). Channel TTS (Troposphere + Stratosphere combined) shows a mixture of both effects.
Temperatures in the lower troposphere (for non weather geeks, that is the portion of the atmosphere where we live) have shown a series of ups and downs since 1979, mostly in a ±0.4oC band, with negligible trends over that period. This contrasts with the near surface temperature record that shows a warming during the same period of time. The graph below is from Wikipedia.

Note in the TLT graph above, the strong 1997-98 El Niño event caused significant lower tropospheric warming in late 1997, and record warmth in February 1998 as evidenced by the spikes shown in the TLT, TMT, and TTS graphs above.
Satellite measurements of the lower stratosphere (TLS) reveal two marked warm periods (as much as 1.5oC warmer), caused by sulfuric acid aerosols deposited in this layer by the eruptions of El Chichón in 1982 and Pinatubo in 1991.
These two warm periods are concurrent with a strong cooling trend over the 19-year period that has been attributed to ozone depletion in the lower stratosphere. In 1997, record low stratospheric temperatures were recorded.
On the TLT graph, for the years 1998 to present, there appears to be a slight downward trend in lower stratospheric temperature, and this is what I believe Christopher Booker is referencing in his article in the Telegraph.  Note that there have been other downward trends in the nearly 30 year measurement history, but the overall trend in the TLT, TMT, and TTS channels has been positive, so a short downward trend doesn’t necessarily prove anything. The TLS channel shows a negative trend, and along with the ozone depletion factor, indicates that we aren’t getting much heat transport from the troposphere into the stratosphere.
The real question is whether this small downturn in the tropospheric temperature trend is a short term anomaly, or something indicative of a longer term event. Only time will tell.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea2a961b0',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Preparations for this year’s climate summit in Glasgow are being overshadowed by a bitter row between the UK and Scottish governments over a key building near the venue. UK government sources have accused Scottish ministers of refusing to hand over a building the Scottish government wants to use as its base for the COP 26 climate talks in November.  Scottish ministers say they booked the Glasgow science centre, a publicly funded venue on the opposite bank of the Clyde from the main conference site, only after the UK government said it would be outside the summit security zone last November. The dispute deepened after Claire O’Neill, the former minister who was sacked as the summit’s chair by Boris Johnson last week, alleged the two governments “were in an extraordinary state of standoff” over the event. O’Neill told BBC Radio 4’s Today programme that she had been told the Scottish government had “behaved disgracefully” by booking buildings on the summit site – a claim rejected by Scottish government officials and independent sources. In a letter to the prime minister published by the FT, O’Neill said that Johnson was even considering moving the event to an English city because of “ballooning costs”. That claim was rejected by a Whitehall source who said there was “zero chance” of it being relocated. O’Neill told Today that the “playground politics, the yah boo of this, has to stop”. She suggested to Johnson that Nicola Sturgeon, the first minister of Scotland, be given a key role at the summit which “the prime minister heartily and saltily rebutted.” Spurred on by O’Neill’s disclosure, Sturgeon wrote to Johnson on Tuesday afternoon asking him to allow Scotland’s environment and climate secretary, Roseanna Cunningham, to take part in climate change ministerial meetings that he has promised to chair in London. Johnson is very likely to reject that request. At the Conservative’s conference in October, he told a raucous Scottish Tory fringe event that he did not want Sturgeon “anywhere near” the climate summit. The spat deepened after a Whitehall source said that the Scottish government had failed to reply to a formal request from Michael Gove in mid-January to relinquish use of the centre and hand it to the climate summit secretariat. A spokesman for Sturgeon insisted her government was willing to discuss how the centre could be used. Ministers in Edinburgh were open to the idea of sharing it, he said, but refused to confirm that they would vacate the building entirely. “It’s a mischaracterisation of our position to suggest we’ve been behaving in anything other than a responsible or cooperative way over the organisation of COP 26. That’s the entire basis on which we are taking things forward. It really shouldn’t be a party-political spat,” he said. Other sources said that the Foreign Office had considered using the science centre last year but failed to book it in time. The event is expected to be the largest gathering of foreign leaders, diplomats and dignitaries ever hosted by the UK, dwarfing previous global summits. Up to 30,000 people are expected to attend, including 200 world leaders. Police Scotland’s chief constable said last month that the force estimated policing the event could cost more than £200m, increasing tensions between the two administrations. The Scottish government said on Tuesday the UK government should foot the entire bill – a position rejected by the UK government. The Whitehall source said there were well-understood processes for setting and sharing costs in situations like this. The UK government believed last year the main Scottish Events Campus (SEC), which includes the SEC Hydro venue, the Scottish exhibition centre, the Armadillo theatre and the Crown Plaza hotel, would be enough. They now argue the summit should expand across the Clyde to include the science centre, which sits opposite BBC Scotland’s headquarters at Pacific Quay. Environment and climate justice campaigners also approached the science centre to use it as a base for their alternative summit but were told the Scottish government, which is the centre’s largest funder, had already taken it."
"Barclays is facing a fresh revolt from the UK’s most powerful investor group amid mounting concerns over its role as the biggest European financier of fossil fuel companies. The Investor Forum, which holds £18.5tn in assets and represents Britain’s largest investors, is understood to be pressing Barclays to adopt stricter policies on climate change before the bank’s annual shareholder meeting in May.  The bank is already facing criticism from a separate group of 11 pension and investment funds managing more than £130bn of assets. Spearheaded by the campaign group ShareAction, they have filed a resolution calling for Barclays to set clear targets to phase out services to energy companies that fail to align with Paris climate goals. But the reported intervention of the Investor Forum, whose members include all the big names in the UK fund management industry, will intensify the pressure on the bank. The Investor Forum declined to comment. Barclays is being targeted because of its leading role in funding fossil fuel projects. A recent study found that its lending and underwriting to carbon-intensive companies and projects between 2015 and 2018 totalled $85bn (£64bn). The sum is more than any other British or European bank, and prompted campaign group ShareAction to coordinate the resolution tabled for May’s AGM. Barclays said: “We continue to engage with ShareAction and other stakeholders on this issue and will make a further statement at the appropriate time.” Privately, the bank believes the campaign against it is unfair, pointing to figures that show that while it remains a significant banker to the fossil fuel industry, its business with the companies most aggressively expanding in the sector fell sharply, from $13.1bn in 2016 to $5.2bn in 2018. It has also facilitated £27.3bn in “green” bonds and renewable financing. Unlike some European banks, Barclays has not ruled out funding projects or companies involved in coal or tar sands, regarded as particularly polluting as they require large amounts of energy to extract. Barclays has faced protests in its branches from Greenpeace campaigners over its involvement in tar sands, focusing on the pipelines being built across Canada and the US to bring oil to market from Alberta’s tar sands. If the AGM resolution is approved by shareholders, the bank will have to publish a plan to phase out the provision of financial services to energy companies that are not meeting Paris climate goals.  It is understood that since the pension and investment funds filed their resolution, the Barclays chairman, Nigel Higgins, has engaged with institutional investors. The Financial Times suggests the bank is considering putting forward its own climate change plan to stave off the investor revolt. Barclays has a way to go before it meets the standards set by some other European financial giants. The insurer Axa said in 2017 that it was divesting from 25 tar sands companies as well as the three large pipelines needed to deliver their oil to market. BNP Paribas, one of the biggest banks in France, has also pledged to stop financing companies whose main activity is extracting oil and gas from shale deposits or tar sands. 1. JP Morgan Chase $195.6bn 2. Wells Fargo $151.6bn 3. Citi $129.5bn 4. Bank of America $106.7bn 5. RBC (Canada) $100.5bn 6. Barclays $85.2bn 7. MUFG (Japan) $80.1bn 8. TD (Toronto Dominion) $74.1bn 9. ScotiaBank $69.6bn 10. Mizuho (Japan) $67.7bn Source: Fossil Fuel Finance Report Card 2019"
"
Share this...FacebookTwitterEchoing the determination of NASA scientists, a new study suggests the natural variability in cloud cover allowing more solar radiation to be absorbed by the Earth’s oceans drove the 2014-2020 global warming.
NASA scientists (Loeb et al., 2018) used satellite data to assess the 2014-2017 warming was driven by a +0.83 W/m² shortwave forcing due to the downward trend in cloud cover.

Image Source: Loeb et al., 2018
A new study (Ollila, 2020) affirms this analysis and suggests the 2018-2020 temperature changes can also be explained by shortwave cloud forcing.
“…the pause was over at the end of 2014, and the major cause was not the anthropogenic forcing, but it was the SW [shortwave] radiation forcing”
“Decreases in low cloud cover were the primary driver of the decrease in reflected SW…”

Image Source: Ollila, 2020
Share this...FacebookTwitter "
"

Alengthy new papal encyclical is being rolled out today. A version of _Laudato Sii_ , or “Be Praised”—thought by most observers to be final, though the Vatican said otherwise—was leaked on Monday. It is a highly political discussion of the theology of the environment.



In fact, Pope Francis addresses not just fellow Catholics but “every person who inhabits this planet,” with whom he proposes “to enter into discussion… regarding our common home.” Climate change is high on his list. With the UN pushing a new agreement for December, Christiana Figueres, head of the UN Climate Change Secretariat, exulted that the encyclical “is going to have a major impact.”



It’s a difficult document to critique, especially since the release was in Italian, so the English versions circulating are poor online translations. Nevertheless, _Laudato Sii_ mixes heartfelt concern for the status of the environment and man’s connection with the world around him with an often limited or confused understanding of the problem of pollution and meaning of markets. The document also wanders widely, connecting most every human endeavor, from drug consumption in affluent societies, architecture, overcoming the “barriers of selfishness,” and cultural homogenization to the environment. Indeed, contended the Pontiff, “The disappearance of a culture can be as serious as or more than the disappearance of an animal or plant species.”





The new papal encyclical understands man and religion, but not economics and politics.



Moreover, the document mixes the indubitable and the dubious. Pope Francis rightly worries about the quality of life, “extreme consumerism,” and meaning in people’s lives. He also highlights God’s concern “for the poor and abandoned,” evident throughout Christian Scripture. As for the environment, he noted, “to insist in saying that the human being is the image of God should not make us forget that every creature has a function and nothing is superfluous.”



Despite his commitment to ecological values, the Holy Father acknowledges that “a return to nature cannot be at the expense of freedom and the responsibility of the human being, that is the part of the world tasked with cultivating its ability to protect and develop their potential.” He also rejects “deification of the earth, which would deprive us of the call to collaborate with it and protect its fragility.”



Nevertheless, humanity’s responsibility for the environment is complex and the Pope discusses ecological values in the context of economic development and care for the poor. How to creatively transform but at the same time gently preserve the natural world is not easy. Unfortunately, in its policy prescriptions _Laudato Sii_ sounds like it was written by an advocate, largely ignoring countervailing arguments. The resulting factual and philosophical shortcomings undercut the larger and more profound theological discussion.



For instance, the encyclical begins by referring to “the deteriorating global environment.” In fact, “the environment” is not a single thing. There are a host of environmental issues which vary dramatically across continent, country, region, and locality. The Pope warns about “the depletion of natural resources,” yet most resources, such as oil, have been growing relatively more abundant. This reality doesn’t negate the Pope’s insistence that “destruction of the human environment is something very serious,” but affects the application of his injunction.



Worse, the document complains much of capitalism, one of the “correct models of growth that seem incapable of guaranteeing respect for the environment,” as well as property rights, which, in the Pope’s view, allow selfish individuals to act in their individual rather than the public’s interest. In fact, no system guarantees respect for ecological values. Communism was the worst: the state controlled everything and the party demanded industrialization. Analysts referred to “ecocide” in the Soviet Union and Eastern Bloc. China looks little better.



In contrast, capitalism provides the resources and technology to improve environmental protection. Indeed, the Holy Father acknowledges that “science and technology are a wonderful product of human creativity that is a gift from God.” Of course, such advances offer no panacea, he warns. Nevertheless, wealthier societies produce more efficiently. They deploy better tools to cope with ecological ills. They are freer and allow people to demand political change.



Indeed, prices in a marketplace operate as signals. _Laudato Sii_ complains that disproportionate consumption steals “from poor nations and future generations,” and that “the rate of consumption waste and degradation of the environment has passed the possibilities of the planet, in such a way that the current lifestyle, being unsustainable, may only result in disaster.” No evidence of this claim is provided. In fact, rising resource prices encourage people to use less, producers to find more, manufacturers to operate more efficiently, and entrepreneurs to create substitutes. Claims that humanity was running out of resources and destroying the ecology go back centuries and so far have been proved wrong.



Markets also do a good job of comparing the costs and benefits of different means to achieve a common end. Costs matter, and not just to big corporations, as the encyclical suggests. For the poor environmental protection can be an unaffordable luxury. _Laudato Sii_ well describes the importance of work, but jobs are not created, like the earth, _ex nihilo_. The more regulatory dictates, higher energy prices, greater supply costs, and more, the fewer the jobs and the lower the salaries.



When it comes to solving specific problems, markets can be quite helpful. For instance, the document complains about water shortages and then criticizes the “tendency to privatize this scarce resource.” Yet monopoly public utilities are renowned for providing poor service at high cost. The poor’s lack of “access to drinking water” has much more to do with Third World poverty and government incompetence than privatization.



Most curious is _Laudato Sii_ ’s almost angry attack on emissions credits, which “can give rise to a new form of speculation and would not help to reduce the global emission of polluting gases.” Yet well‐​designed tradeable permits, like emission taxes, encourage those who can control emissions at the least cost to do so the most. This is not an assault “on the solidarity of all peoples,” as the document proclaims, but a means to most help those who have the least to give.



Moreover, markets and property rights are the most important means to provide people with what the Pontiff calls “a dignified life through work.” Even Marx acknowledged that capitalism raised the mass of humanity out of immiserating poverty. Commercial society destroyed the foundations of aristocratic oppression.



Alas, the document offers a confused, misguided criticism of mechanization and economies of scale. It was the new “machines” replacing jobs, decried by the encyclical, which created vast new economic and social opportunities. The Gutenberg Press put scribes out of business, while computers transformed whole industries.



 _Laudato Sii_ asserts the “principle of subordination of private property to the destination” and the “social function of any form of private property.” Property rights may not be absolute, but the legal right to land is most important for those who lack wealth and influence. The lack of such rights in the kleptocratic systems in Latin America with which the Holy Father is so familiar hampered the entrepreneurial poor, a phenomenon highlighted by Hernando de Soto.



Property rights also create incentives for environmental stewardship. Garrett Hardin famously wrote about the “tragedy of the commons,” how public ownership naturally leads to environmental degradation. Ownership vests both costs and benefits with a sole decision‐​maker who can be held responsible. Where the public “owns” land no one effectively does so.



That’s why many countries have created quota systems, creating a form of defined development right, to govern ocean fishing. In the case of the Amazon rain forest, mentioned by the Pontiff, indigenous peoples lacked formal legal rights to the land they used. The problem is _lack of_ property rights.



Most environmental problems occur because of what economists call externalities—costs and benefits that fall on others. For instance, Pope Francis speaks of “the obligation of polluters to take responsibility economically” and “assess the environmental impact of each work or project.” Without an appropriate legal regime, industry could spew emissions far and wide, the antithesis of property rights. The real environmental issue is over where to draw the line, which requires balancing complex interests: prosperity, liberty, ecology. _Laudato Sii_ seems to assume the correct outcome in every case is more of the latter.



Indeed, the encyclical lacks any sense of the flawed nature of government. The Pope is disappointed that environmental efforts “are often frustrated not only by the refusal of the powerful, but also by the lack of interest of the other.” However, public choice economists diagnosed this problem decades ago: concentrated benefits, diffuse costs. In this case environmental organizations are as prone as corporations to push their narrow preferences on everyone else.



This reality raises doubts about the Pope’s endorsement of the “precautionary principle,” which in practice would hold virtually every beneficial human innovation hostage to interest groups dedicated to the status quo. Equally dubious is the encyclical’s endorsement of the “essential development of international institutions stronger and effectively organized… with the power to sanction.” There is no reason to believe that ever more distant, unaccountable bureaucracies will operate for the common good rather than at the behest of whatever interests, corporate, labor, activist or other, wielding the greatest influence. In fact, the encyclical complains of the failure of global conferences due to “too many special interests.”



Politics also is far more open to the Holy Father’s complaint about “the earth’s resources” being “plundered due to ways … too tied to the immediate result.” The price of property incorporates perceived future value. Ruin it and you lose that value. Politicians’ decision‐​making time frame usually is years, often months. If opening up sensitive land for development will win a few votes in the next election, why worry about future generations, which don’t vote? Those in politics may talk the talk, but in practice they are no less selfish and neglectful than those in business, and respond to far more destructive incentives.



The encyclical includes a confusing discussion of trade and globalization. External debt “has become an instrument of control.” True, yet local political leaders borrowed much and wasted the proceeds. The document also claims that trade relations forbid “access to ownership of property and resources to meet [people’s] vital needs.” However, trade mandates and forbids nothing. Rather, it provides opportunities which, like industrialization, might not offer an easy path for the poor, but which usually are better than the alternatives. That is why polls consistently show the greatest support for globalization in the poorest nations.



 _Laudato Sii_ also argues for redefining progress, contending that “diversification of a production more innovative and with less environmental impact, can be very profitable.” If true, it will happen without legal mandate.



Yet the Pope argues that it is not sufficient to care for nature while enjoying financial profits, or practicing “environmental conservation with progress.” Without evidence the encyclical contends that this will only mean “a small delay in the disaster.” However, past doomsayers consistently have been proved wrong. The Pontiff certainly is right to question “technological and economic development that does not leave a better world and quality of life.” However, compare the lives of the average person, and especially poor person, today with a century ago and a century before that. The world and quality of life are dramatically better. The Holy Father should encourage people to ask, “How much is enough?” But it is important that those living in comfort in the industrialized West do not try to answer for those living in the impoverished Third World.



Although the Vatican often is treated as an independent state, its comparative advantage is not legislation. Yet at one point the encyclical discusses “household waste and commercial, demolition debris, clinical waste, electronic or industrial waste.” Also noted is the “special challenge” presented by “marine debris and the protection of marine areas.” Later the document asserts the importance of education on “how to avoid the use of plastic material or paper,” “cooking only what you can eat reasonably,” and turning off “unnecessary lights.” Indeed, there is a lengthy but not entirely fruitful discussion of urban planning, highlighted by the professed need to improve urban transportation.



The discussion of climate change is similarly specific but partisan. For instance, the encyclical takes an almost panicked view of the problem, even though it closes out the chapter noting the Church’s obligation to “listen and promote debate honest among scientists, respecting the diversity of opinion.” _Laudato Sii_ also blames extreme weather events on climate change while admitting in the same sentence “that we cannot attribute a cause scientifically determined for each particular phenomenon.”



The fact that there likely will be more warming does not mean it will be catastrophic. In fact, models failed to accurately predict past behavior, peer‐​reviewed research increasingly suggests warming toward the lower range, and it is impossible to accurately predict events a few years, let alone a century hence (virtually no one saw the Shale gas/​oil revolution coming, for instance). This argues against making draconian, expensive changes that may make little sense soon after they are implemented. Rather, it would be better to adapt to particular problems as they arise rather than to attempt to hold down temperatures by radically rolling back energy use. The resources saved are needed to meet many other human needs.



In contrast, the Pontiff truly is acting in his unrivaled role as spiritual leader when he advocates a personal, social, and spiritual transformation in how people relate to the environment. He promotes an “ecological spirituality that arises from convictions of our faith” and advocates human freedom being “put at the service of another kind of progress, healthier, more human, more social and more integral.” The Pope’s proposed “ecological conversion” should spark much discussion, since his application of basic Christian principles is plausible, if not necessarily convincing. Is it really true that the same principle of “brotherly love” requires “us to love and accept the wind, the sun or the clouds”? Nevertheless, throughout history too many Christians probably have practiced dominion and slighted stewardship. Even this untutored Protestant can appreciate the claim that “the Eucharist is even light source and motivation for our environmental concerns and directs us to be guardians of all creation.”



Moreover, Pope Francis warns that “we cannot think that the political agendas or the force of law is enough to avoid behaviors that affect the environment,” since the culture itself is corrupt. He contends: “if we feel intimately united with all that exists, sobriety and care will arise spontaneously.” Quite true. It is committed individuals who form the “innumerable variety of associations advocating on behalf of the environment,” cited by _Laudato Sii_ , and whose reformed buying behavior can “change the behavior of firms, forcing them to consider the environmental impact and production patterns.” Aligning desire and incentive is the best way to achieve what the Pontiff’s objective.



The Pope expresses the triumph of hope over experience in his call on politicians to act responsibly and the public to participate knowledgeably. Just as one should avoid “a magical concept of the market,” so should we beware the same for politics. Problems will not be magically resolved by investing politicians and bureaucrats with vast new powers.



Larger themes point through the encyclical, which warns that “the market alone does not ensure human development and full social inclusion.” The Gospel, unlike the market, reaches the empty hearts which the Pope sees. We must “not give up asking us questions about the purposes and on the sense of everything.”



The Vatican is not well‐​positioned to assess environmental problems and develop policy solutions. Rather, the Pontiff’s duty is much more fundamental: “the great wealth of Christian spirituality, generated by twenty centuries of personal and communal experiences, is a magnificent contribution to make the effort to renew humanity.” We desperately need such a renewal. Hopefully _Laudato Sii_ , despite its practical shortcomings, will advance the larger and more important theological mission.
"
"Gol-e-Zard Cave lies in the shadow of Mount Damavand, which at more than 5,000 metres dominates the landscape of northern Iran. In this cave, stalagmites and stalactites are growing slowly over millennia and preserve in them clues about past climate events. Changes in stalagmite chemistry from this cave have now linked the collapse of the Akkadian Empire to climate changes more than 4,000 years ago. Akkadia was the world’s first empire. It was established in Mesopotamia around 4,300 years ago after its ruler, Sargon of Akkad, united a series of independent city states. Akkadian influence spanned along the Tigris and Euphrates rivers from what is now southern Iraq, through to Syria and Turkey. The north-south extent of the empire meant that it covered regions with different climates, ranging from fertile lands in the north which were highly dependent on rainfall (one of Asia’s “bread baskets”), to the irrigation-fed alluvial plains to the south.  It appears that the empire became increasingly dependent on the productivity of the northern lands and used the grains sourced from this region to feed the army and redistribute the food supplies to key supporters. Then, about a century after its formation, the Akkadian Empire suddenly collapsed, followed by mass migration and conflicts. The anguish of the era is perfectly captured in the ancient Curse of Akkad text, which describes a period of turmoil with water and food shortages:  … the large arable tracts yielded no grain, the inundated fields yielded no fish, the irrigated orchards yielded no syrup or wine, the thick clouds did not rain. The reason for this collapse is still debated by historians, archaeologists and scientists. One of the most prominent views, championed by Yale archaeologist Harvey Weiss (who built on earlier ideas by Ellsworth Huntington), is that it was caused by an abrupt onset of drought conditions which severely affected the productive northern regions of the empire.  Weiss and his colleagues discovered evidence in northern Syria that this once prosperous region was suddenly abandoned around 4,200 years ago, as indicated by a lack of pottery and other archaeological remains. Instead, the rich soils of earlier periods were replaced by large amounts of wind-blown dust and sand, suggesting the onset of drought conditions. Subsequently, marine cores from the Gulf of Oman and the Red Sea which linked the input of dust into the sea to distant sources in Mesopotamia, provided further evidence of a regional drought at the time. Many other researchers viewed Weiss’s interpretation with scepticism, however. Some argued, for example, that the archaeological and marine evidence was not accurate enough to demonstrate a robust correlation between drought and societal change in Mesopotamia.  Now, stalagmite data from Iran sheds new light on the controversy. In a study published in the journal PNAS, led by Oxford palaeoclimatologist Stacy Carolin, colleagues and I provide a very well dated and high resolution record of dust activity between 5,200 and 3,700 years ago. And cave dust from Iran can tell us a surprising amount about climate history elsewhere. Gol-e-Zard Cave might be several hundred miles to the east of the former Akkadian Empire, but it is directly downwind. As a result, around 90% of the region’s dust originates in the deserts of Syria and Iraq.   That desert dust has a higher concentration of magnesium than the local limestone which forms most of Gol-e-Zard’s stalagmites (the ones which grow upwards from the cave floor). Therefore, the amount of magnesium in the Gol-e-Zard stalagmites can be used as an indicator of dustiness at the surface, with higher magnesium concentrations indicating dustier periods, and by extension drier conditions.  The stalagmites have the additional advantage that they can be dated very precisely using uranium-thorium chronology. Combining these methods, our new study provides a detailed history of dustiness in the area, and identifies two major drought periods which started 4,510 and 4,260 years ago, and lasted 110 and 290 years respectively. The latter event occurs precisely at the time of the Akkadian Empire’s collapse and provides a strong argument that climate change was at least in part responsible. The collapse was followed by mass migration from north to south which was met with resistance by the local populations. A 180km wall – the “Repeller of the Amorites” – was even built between the Tigris and Euphrates in an effort to control immigration, not unlike some strategies proposed today. The stories of abrupt climate change in the Middle East therefore echo over millennia to the present day."
"

The first Earth Day, in 1970, was celebrated after a wave of environmentalism swept the nation. Many give credit to Rachel Carson’s 1962 book, _Silent Spring_ , which popularized the notion of large‐​scale chemical pollution, for igniting the movement.



But she was really feeding off of a concept developed a few years earlier. The “precautionary principle” was conceptualized when the National Academy of Sciences proposed a radical change in the risk assessment of exposure to radiation and carcinogens. It recommended changing the regulatory paradigm from a “threshold dose” model to a linear one.



The threshold paradigm was what one might call common sense. It held that humans could tolerate small doses of things that, in larger doses, could be harmful.



Sunlight is a perfect example. Low doses are actually required for survival, as ultraviolet radiation — the same general type that causes sunburn — catalyzes the formation of Vitamin D. But, as is obvious to anyone who lives in a sun‐​drenched area, excessive exposure can lead to death in the near term (from dehydration) or the longer term (from skin cancer).



The “linear model” assumes that just a single molecule of a carcinogen or a single ionization from an X‐​ray can induce cancer. The enthusiasm spawned by Earth Day soon gave us brand new regulatory agencies such as the Environmental Protection Agency and the Occupational Safety and Health Administration. The EPA routinely applies the linear model to carcinogens.





Environmental regulations based on the “linear model” are having a negative impact, not only on societal costs, but on our health as well.



The linear model is a case study in the unintended consequences of the desire to do good. In this case, an ideologically driven scientist, Nobel Prize laureate Herman Muller, whose research formed the basis for EPA’s model, led the charge. A very powerful figure in health physics, he is now known to have marginalized and obstructed the publication of any research that provided evidence counter to the linear model.



If that sounds like the way senior climate scientists were found to behave in the famous 2009 “Climate‐​gate” emails, it should.



The regulatory agencies fell in line, as did a compliant scientific community and a media that was afraid to dig deeper. Every country followed the U.S.’ lead.



The linear model is rigid, absolute and wrong. We now know that there are so many flaws or holes in the linear dose response model that it looks more like Swiss cheese. The resulting environmental regulations are having a negative impact, not only on societal costs, but on our health as well.



Over the past several decades, considerable research has revealed a plethora of life‐​saving adaptive processes that can be used to enhance the quality of life and to extend life. Our cells are flexible, adaptive and can actually be strengthened via low‐​level exposure to a large number of compounds that the EPA would like to regulate down to the last molecule.



Instead of preventing harm, the precautionary principle actually causes harm. The entire therapeutic model is built around the notion that certain compounds that are highly toxic in large doses can be life‐​enhancing and life‐​extending in low ones.



How can the regulatory community accept the linear model when so many of its senior practitioners are living lives that prove the opposite? Many of these aging regulators are taking ACE (angiotensin converting enzyme) inhibitors to control blood pressure. The original ACE inhibitor, Captopril, is the active substance in the venom of the Brazilian viper. A lot will kill you very quickly. A little could extend your life for decades.



We need a new Earth Day. It should be dedicated to righting the past deceptions and correcting the ongoing errors in environmental regulation. It should be one that acknowledges our adaptive responses to what, in high doses, can cause cancer, but, in low doses, can improve our well‐​being.
"
"
Share this...FacebookTwitter
‘Die Welt’ science editor Axel Bojanowski (right) comments “This is how climate change is forged”. He had 4 leading scientists confirm the above hockey stick chart was dubious. Image: Die Welt , Source:: DeWikiMan/commons.wikimedia.org/CC BY-SA 4.0; Bojanowski/private
ZDF weather moderator Özden Terli under fire: Did he deceive viewers on historical climate with sleight of hand?
By Die kalte Sonne
(German text translated/edited by P. Gosselin)
Disinformation at ZDF German public broadcasting?
ZDF meteorologist Özden Terli has been a topic at this blog several times. Now ‘Die Welt’ science editor Axel Bojanowski  has taken a closer look at a weather report, particularly a chart that Terli presented July 24, 2020.
The article is behind a paywall, but is worth the money. The centerpiece is the chart from the Potsdam Institute for Climate Impact Research (PIK). It depicts a hockey stick temperature curve that is supposed to convey drama. Excerpt from the article in Die Welt:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The weather report of the “Heute Journal” on ZDF on July 24th presented something that was supposed to be sensational. Moderator Özden Terli presented a graph that allegedly showed the course of the global average temperature since the Ice Age. At first ‘the warming was very slow,’ Terli explained, ‘and then it was stable for a long time’. Suddenly, however, since around 1900, the temperature “jumped up”.
The graph showed an almost vertical red line, the peak of which far exceeded all temperatures since the Ice Age. “This jump is quite enormous,” Terli said.
Millions of viewers were shown that the present day would be warmer than all the rest of human civilization. The discovery could only be a scientific sensation, or a hoax.”
Bojanowski interviewed several experts on the subject and their reactions speak volumes because the graph cleverly mixed two things together, namely smoothed averages from the past with measured current values. Fluctuations in the past can thus no longer be seen. The experts’ verdict was unanimous: it is dubious. Bojanowski analyzes:
The graph was a sleight of hand: the steep red line at the end was not comparable to the data in the previous period. It showed annually measured average temperatures on Earth since the end of the 19th century. However, no such precise records exist for earlier times. Most of the time in the history of civilization can only be shown with average values.
Often there is only one temperature value for hundreds of years, or data has been “smoothed”, i.e. only its average value is shown – short-term warming or cooling is not shown. In order to make the period from industrialization to the present day (the steep red line) comparable with the data for the rest of the time, it should therefore only be shown as a dot showing the average temperature from 1900 to the present day – the red line would only be an inconspicuous dot.”
And because Bojanowski has been there before, the subject of drought can be brought up again. In a weather report Terli attributed this to changes in the climate system. But without going into other sources. Perhaps the weatherman would then have noticed that annual precipitation in Germany has increased over the past 120 years. … It’s astonishing that the head of ZDF Wetter, Katka Horneffer, allows Özden Terli to include such inserts in the weather report again and again.
Share this...FacebookTwitter "
"
The National Weather Service office in San Diego, CA operates a cooperative observer network of weather stations, as do all NWS offices. The station in Coronado, CA, is particularly interesting since it is located on the roof of the Fire Station there.
Given that the MMTS sensor shown below is only about 2 feet above the tar and pea gravel roof, which is known to be a hot environment during the day, and a source for re-radiated heat at night, you have to wonder: “What were they thinking?”

Photo from NWS San Diego, click photo for larger image
The NOAA’s credit, this station is not part of the USHCN climate station network, but still, of what possible value could an air temperature measurement just 2 feet off the rooftop be to anyone?


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea2b7ab04',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

 **Introduction**  
President Obama’s major trade initiatives, the Trans‐​Pacific Partnership, the Transatlantic Trade and Investment Partnership, and obtaining fast‐​track trade negotiating authority from Congress, have run into a buzz saw of opposition, which has derailed prospects for U.S. trade liberalization for the time being.



What began as the usual objections from the usual suspects—labor unions blaming trade for manufacturing decline and job loss; environmental groups blaming trade for climate change; anti‐​globalization activists sparing the developing world from development–has grown into a populist backlash against the TPP, which is portrayed as a secretive, corporatist plot to circumvent democratic processes and usurp national sovereignty. The nascent TTIP negotiations have been smeared with a similar taint.



Characterizations of the TPP as a scheme to boost the fortunes of tobacco, oil and gas, banking, and pharmaceutical companies at the expense of worker protections, the environment, public health, and food and product safety have gone viral. And without so much as a single public repudiation of these claims by the president those perceptions are sticking.



As is true of most populist causes, buried beneath the enabling mythology and hyperbole are some kernels of truth. One such truth, which this paper seeks to distill from the vacuous, anti‐​capitalist hyperventilation surrounding the trade agenda, is that the so‐​called Investor‐​State Dispute Settlement (ISDS) mechanism, which enables foreign investors to sue host governments in third‐​party arbitration tribunals for treatment that allegedly fails to meet certain standards and that results in a loss of asset values, is an unnecessary, unreasonable, and unwise provision to include in trade agreements. Although detractors may not know it by name, ISDS is a significant reason why trade agreements engender so much antipathy. Yet, ISDS is not even essential to the task of freeing trade. So why burden the effort by carrying needless baggage?



Purging both the TPP and the TTIP of ISDS makes sense economically and politically, would assuage legitimate concerns about those negotiations, splinter the opposition to liberalization, and pave the way for freer trade.



 **What’s Troubling the Trade Agenda?**  
President Obama has failed to make an affirmative case for his trade agenda, and his disinterest in rebutting the flood of damaging portrayals of the TPP has permitted germinating dissent to metastasize into a problem much worse. Meanwhile, the nature of trade, the nature of protectionism, and the substance of trade agreements have changed with the proliferation of cross‐​border investment and transnational supply chains. As companies establish operations in foreign markets, where they are engaged in direct and more intense competition with incumbent firms, concerns about protectionism are no longer confined to the border.



Protectionism manifests in more subtle ways today. Accordingly, ensuring nondiscrimination against imports, foreign investment, and the operations of foreign companies requires rules that sometimes burrow into areas that were once the exclusive purview of domestic legislatures and regulators. Agreements nowadays include provisions affecting domestic intellectual property laws, environmental and labor standards, data flow and storage requirements, banking regulations, and food and product safety requirements, to name some.



The interplay of domestic governance and trade agreement obligations has raised questions about jurisdiction, sovereignty, and the separation of powers. That some perceive the TPP as secretive has heightened sensitivity about its objectives and implications. So, instead of seeing negotiations on “regulatory coherence” as a commonsense way for businesses to reduce the costs of compliance without compromising public health or safety objectives, some suspect it is a path to gutting compliance obligations altogether. Others see regulatory harmonization as another step toward global governance. Efforts to include provisions extending protection of patents, copyrights, and other forms of intellectual property are perceived by some as attempts to impose through treaty what was unachievable through domestic processes. Negotiations of rules that would help ensure that financial‐​sector regulations are promulgated in manners that are nondiscriminatory are painted as attempts to weaken domestic safeguards against recurrence of a financial meltdown.



The hallmarks of tighter global economic integration—cross-border investment, transnational supply chains, and intensifying competition—have created tension between the imperative of domestic sovereignty and the growing demand for rules to guard against protectionism and discrimination. One area where this debate has gotten especially heated is tobacco regulation.



Anti‐​tobacco advocates have been demanding a “carve out” provision, which would excuse lawmakers and domestic agencies from their obligations to craft and enforce tobacco regulations in manners that do not discriminate against imports. The rationale for the safe‐​harbor provision is that tobacco poses special known risks to public health and human safety and that trade obligations should not interfere with the capacity to regulate such a dangerous product. Recently, 42 of the 50 U.S. state attorneys general signed a letter insisting that such a safe‐​harbor provision is essential to protecting public health.1



But as trade experts have explained, there is nothing about the TPP or any other trade agreement that impedes a government’s capacity to protect human life or health. Trade agreements do not prohibit regulating. They merely require that such measures be based on sound science and that discrimination against similar products on the basis of national origin be avoided. The states can ban cigarettes, for example, but not cigarettes “from Indonesia.” As Cato trade policy analyst Simon Lester puts it: “Although there may be valid concerns about some of the more recent additions to trade and investment agreements … the core of these rules constrains domestic regulation only to the extent that such regulation discriminates against imports and does not preclude legitimate domestic policymaking.“2



But if one listens closely to the arguments of anti‐​tobacco advocates (or reads the letter from the 42 attorneys general), what most oppose is the possibility of tobacco companies suing the U.S. government in third‐​party tribunals. Creating a tobacco carve out would reiterate a right that governments already possess and would do nothing to safeguard against suits by tobacco companies—or any other companies.



The real ire of anti‐​tobacco advocates is the Investor‐​State Dispute Settlement mechanism.



 **What is Investor‐​State Dispute Settlement?**  
The ostensible purpose of ISDS is to ensure that foreign investors—usually multinational corporations (MNCs)—are protected against host government actions or policies that fail to meet certain standards of treatment and that cause the investor economic harm. The ISDS confers special legal privileges on foreign‐​invested companies, including the right to sue host governments in third‐​party arbitration tribunals for failing to meet those standards.



Investor‐​State Dispute Settlement dates back to the era following World War II, when previous European colonies were achieving independence and seeking to attract Western investment. It was borne as an expedient to overcome concerns about expropriation by new governments lacking experience with property rights and the rule of law.3 But ISDS procedures were rarely used. In fact, from the inception of ISDS in 1959 through 2002, the number of known ISDS claims worldwide stood at fewer than 100.4 However, during the 10 years between 2003 and 2012, the cumulative total increased to 514 cases.5 In 2012, claimants initiated 58 ISDS cases worldwide, which was the greatest number of initiations in any year, surpassing the previous record set in 2011.6



Provisions for ISDS are included in the 41 U.S. bilateral investment treaties in effect, as well as most of the U.S bilateral trade agreements.7 American TPP and TTIP negotiators are seeking ISDS rules in those agreements. Proponents argue that ISDS provides assurances against unfair treatment from host governments, strengthens the rule of law, and helps bring otherwise reluctant investors to capital‐​hungry jurisdictions. But looking more closely, ISDS arguably weakens the rule of law, forces the public to subsidize the risk of MNC investment abroad, and effectively encourages outsourcing.



 **Eight Good Reasons to Drop ISDS from TPP and TTIP**  
There are practical, economic, legal, and political reasons to expunge ISDS from current trade negotiations.



First, _ISDS is overkill_. Governments are competing to attract productive investment to keep their citizens employed and their economies growing. Accordingly, it is imperative to maintain smart, transparent, predictable policies that are administered fairly and nondiscriminatorily. Asset expropriation or other forms of shabby treatment of foreign companies is not likely to be rewarded by new investment.



Of course, that doesn’t guarantee that policies will never go astray. Sometimes they will. But investment is a risky proposition. Foreign investment is usually more risky. But that doesn’t necessitate the creation of institutions to protect MNCs from the consequences of their business decisions. Multinational companies are among the most successful and sophisticated companies in the world. They are quite capable of evaluating risk and determining whether the expected returns cover that risk. Although MNCs may want assurances, they don’t need them.



Multinational companies can mitigate their own risk by purchasing private insurance policies. Alternatively, they can condition investment on the host government’s agreeing to other protections, contractually. Whether the host agrees would be influenced by the supply of potential investors and the strings they would attach.



Second, _ISDS socializes the risk of foreign direct investment_. When other governments oppose, but ultimately concede to, U.S. demands for ISDS provisions, they may be less willing to agree to other reforms, such as greater market access, that would benefit other U.S. interests. That is an externality or a cost borne by those who don’t benefit from that cost being incurred. In this regard, ISDS is a subsidy for MNCs and a tax on everyone else. Taking the argument one step further, ISDS not only subsidizes MNCs, but particular kinds of MNCs. What may be too risky an investment proposition without ISDS for Company A is not necessarily too risky for Company B. By reducing the risk of investing abroad, then, ISDS is a subsidy for more risk‐​averse companies. It is a subsidy for Company A and a tax on Company B.



Third, ISDS encourages “discretionary” outsourcing. In the global competition to attract investment from the world’s best companies, the United States has some enormous advantages. For many decades, the United States has been the world’s premier destination for foreign direct investment. But in recent years, the United States has been slipping in a number of important investment‐​location decision criteria and, accordingly, its share of global foreign direct investment has declined from 39 percent in 1999 to 17 percent in 2011.8



While ISDS may benefit U.S. companies looking to invest abroad, it neutralizes what was once a big U.S. advantage in the competition to attract investment. Respect for property rights and the rule of law have been relative U.S. strengths, but ISDS mitigates those U.S. advantages. Access to ISDS could be the decisive factor in a company’s decision to invest in a research center in Brazil, instead of the United States. Why should U.S. policy reflect greater concern for the operations of U.S. companies abroad than for the operations of U.S. and foreign companies in the United States? Why should ISDS effectively subsidize outsourcing, and not insourcing?



To be sure, success abroad and success at home are closely correlated. Companies must be able to invest abroad to compete there, and the success of those foreign affiliates tends to be reflected in the performance of the parent companies at home.9 But there is a crucial distinction between “discretionary” and “nondiscretionary” outsourcing.



“Discretionary” outsourcing is investment that goes abroad, but doesn’t really have to. It is investment in activities that could be performed competitively in the United States, but is chased away by policies that make U.S. investment relatively more expensive. “Nondiscretionary” outsourcing is investment in activities that requires a foreign presence.



While we should not denigrate, punish, or tax foreign outsourcing, neither should we subsidize it, and ISDS subsidizes discretionary outsourcing.



Fourth, ISDS exceeds “national treatment” obligations, extending special privileges to foreign corporations. An important pillar of trade agreements is the concept of “national treatment,” which says that imports and foreign companies will be afforded treatment no different from that afforded domestic products and companies. The principle is a commitment to nondiscrimination. But ISDS turns national treatment on its head, giving privileges to foreign companies that are not available to domestic companies. If a U.S. natural gas company believes that the value of its assets has suffered on account of a new subsidy for solar panel producers, judicial recourse is available in the U.S. court system only. But for foreign companies, ISDS provides an additional adjudicatory option.



This inequality of treatment seems to run afoul of the investment provisions in the Baucus‐​Hatch‐​Camp legislation (to extend fast‐​track trade promotion authority to the president), which state that the principal U.S. negotiating objectives regarding foreign investment are to: “[R]educe or eliminate artificial or trade distorting barriers to foreign investment, while ensuring that foreign investors in the United States are not accorded greater substantive rights with respect to investment protections than United States investors in the United States…“10



Foreign investors having recourse to the U.S. legal system and then, if that produces unsatisfactory results, to third‐​party ISDS procedures arguably constitutes greater substantive rights for them than for domestic investors, whose options are confined to the U.S. legal system.



Fifth, _U.S. laws and regulations will be exposed to ISDS challenges_ with increasing frequency. The number of cases is on the rise. Most claims have been brought against developing countries—with Argentina, Venezuela, and Ecuador leading the pack—but the United States is the eighth‐​largest target, having been the subject of 15 claims over the years.11



As the percentage of global Fortune 500 companies domiciled outside the United States continues to increase, U.S. laws and regulations are likely to come under greater scrutiny. The specter of foreign companies prevailing in challenges of U.S. laws outside the U.S. legal system would frustrate further the task of selling trade to a skeptical public and would reward trade critics who have been warning of just such an outcome for many years.



Investor‐​State Dispute Settlement raises concerns about domestic sovereignty. Among recent cases highlighting these tensions is a suit brought by Philip Morris, Inc. against the Australian government for a law requiring that cigarettes be sold in plain packaging. Philip Morris claims that the requirement deprives it of its property (trademarks, logos, and labels), which is important for brand recognition and without which its revenues will decrease. Philip Morris may have a legitimate claim, but the optics will not be favorable for trade agreements if the company prevails.



Meanwhile, growing concerns in Europe about the vulnerabilities of environmental and public‐​safety laws to challenges by foreign corporations—sparked, in part, by a case brought by a Swedish energy company against Germany for its decision to abandon nuclear power—have led the EU to suspend ISDS negotiations in the TTIP for a period of three months, as it collects and evaluates public comments and reconsiders its position. Realistically, it is difficult to conceive of any benefits to including ISDS provisions in the TTIP, given the advanced legal systems in the United States and Europe, unless the wave of the economic future is expected to arrive in a tsunami of international litigation.



Sixth, _ISDS is ripe for exploitation by creative lawyers_. There is a lot of latitude for interpretation of what constitutes “fair and equitable” treatment of foreign investment, given the vagueness of the terms and the uneven jurisprudence. Thus, ISDS lends itself to the creativity of lawyers willing to forage for evidence of discrimination in the arcana of the world’s laws and regulations. Among the complaints worldwide in 2012 were challenges related to “revocations of licenses, breaches of investment contracts, irregularities in public tenders, changes to domestic regulatory frameworks, withdrawals of previously granted subsidies, direct expropriations of investments, tax measures and others.“12



Meanwhile, some agreements are attempting to expand the definition of a breach of the obligation of host governments to provide fair and equitable treatment to include: “targeted discrimination on manifestly wrongful grounds, such as gender, race or religious belief.” This attempt to broaden the scope for complaints—included in the EU‐​Canada trade agreement—should be a cause for concern.13



Seventh, _ISDS reinforces the myth that trade primarily benefits large corporations_. A persistent myth that has proven hard to dispel permanently is that trade benefits primarily large corporations at the expense of small businesses, workers, taxpayers, public health, and the environment. The fact is that trade is the ultimate trustbuster, ensuring greater competition that prevents companies from taking advantage of consumers. Lower‐​income Americans stand to benefit the most from trade liberalization, as the preponderance of U.S. protectionism affects products and services to which lower‐​income Americans devote higher proportions of their budgets.



But by granting special legal privileges to multinational corporations, ISDS reinforces that myth and is a lightning rod for opposition to trade liberalization. It is effectively a subsidy that mitigates risk for U.S. multinational corporations and enables foreign MNCs to circumvent U.S. courts when lodging complaints about U.S. policies. Ultimately, ISDS is unimportant to the task of trade liberalization and its inclusion in trade agreements only strengthens trade’s opposition.



Eighth, _dropping ISDS would improve U.S. trade negotiating objectives_ , as well as prospects for attaining them. Recently, a group of business associations joined in a statement of opposition to the requests for a tobacco carve‐​out provision, arguing that it would be superfluous and set a dangerous precedent that would undermine the settled view that governments are already entitled to regulate in the interest of protecting human life or health.14 Given their concern for the rule of law and the traditions of the trading system, the statement’s signatory organizations should be amenable to a compromise that would include purging ISDS from the TPP and the TTIP in exchange for a denial of the carve‐​out language.



Such a deal would assuage thoughtful critics of the trade agenda, who do not oppose trade, but who believe trade agreements should be more modest and balanced. Meanwhile, what now appears to be an angry mob protesting trade generally will be thinned out, exposing the unsubstantiated arguments of the professional protectionists who benefit by impeding Americans’ freedom to trade.



 **Conclusion**  
For practical, economic, legal, and political reasons, ISDS subverts prospects for U.S. trade liberalization. Yet it is tangential, at best, to the task of freeing trade. Any benefits to availing MNCs to third‐​party adjudication are all but totally overwhelmed by the additional costs. In the proverbial airplane that is down one engine and losing altitude, throwing ISDS out of the cargo hold to reduce unnecessary weight is the best solution.



At this point, it remains unclear whether the president is genuinely committed to doing what it will take to advance his trade agenda. But should he convince himself of the efficacy and righteousness of freeing trade and become interested in putting the necessary pieces together to bridge political divides, jettisoning ISDS and explaining how doing so liberates us from legitimate concern that corporations will run roughshod over domestic laws could go a long way toward selling these agreements to the public.



 **Notes**  
1\. Inside U.S. Trade’s World Trade Online, “Attorneys General From 42 States Call For Tobacco Carveout In Trade Deals,” February 6, 2014, www​.insid​e​trade​.com.  
2\. Simon Lester, “Free Trade and Tobacco: Thank You for Not Smoking (Foreign) Cigarettes,” Cato Free Trade Bulletin no. 49, August 15, 2012.  
3\. For a good history of ISDS, see Simon Lester, “Liberalization or Litigation? Time to Rethink the International Investment Regime,” Cato Policy Analysis no. 730, July 8, 2013.  
4\. United Nations Conference on Trade and Development (UNCTAD), “Recent Developments in Investor‐​State Dispute Settlement (ISDS),” IIA Issue Notes No. 1, May 2013.  
5\. Ibid   
6\. Ibid.  
7\. Shayerah Ilias Akhtar and Martin A. Weiss, “U.S. International Investment Agreements: Issues for Congress,” Congressional Research Service, April 29, 2013.  
8\. Daniel Ikenson, “Reversing Worrisome Trends: How to Attract and Retain Investment in a Competitive Global Economy,” Cato Policy Analysis no. 735, August 22, 2013.  
9\. Ibid., Figures 4, 5, 6, 7, 8, and 9; Matthew J. Slaughter, “American Companies and Global Supply Networks: Driving U.S. Economic Growth and Jobs by Connecting with the World,” Business Roundtable, the United States Council for International Business and the United States Council Foundation, January 2013.  
10\. United States Senate, Bipartisan Congressional Trade Priorities Act of 2014.  
11\. United Nations Conference on Trade and Development. To date, investors have not prevailed in any of their complaints against the United States.  
12\. United Nations Conference on Trade and Development.  
13\. Simon Lester, “An Equal Protection Clause for Investment,” International Economic Law and Policy Blog, February 6, 2014.  
14\. U.S. Chamber of Commerce, et al., “Joint Statement on Proposal to Modify Longstanding “General Exception” Provision and Dispute‐​Settlement Provision in the Trans‐​Pacific Partnership (TPP) Negotiations,” February 2014, http://​www​.amcham​.com​.au/​D​o​w​n​l​o​a​d​s​/​9​9​a​9​e​9​a​3​-​1​e​1​7​-​4​1​8​0​-​a​6​a​6​-​7​2​d​d​3​8​0​a65ca….
"
"
Share this...FacebookTwitterGerman skeptic site Die Kalte Sonne here debunks a recent alarmist article appearing in Spiegel aimed at shocking its readers. The reality, it turns out, is not shocking at all.
Greenland ice doomed?
According to Spiegel, the Greenland ice sheet is already doomed (that is unless we skip the usual democratic process and just act immediately).
Spiegel claims Greenland “glaciers are continuously losing huge masses of ice” and that the system there is “dramatically off balance”. The leftist Hamburg-based weekly reported:
The melting of the glaciers on Greenland has apparently passed the point of no return. Even if the global rise in temperature were to stop immediately, the ice sheet would continue to retreat, report researchers led by Michalea King of Ohio State University report in the journal “Communications Earth and Environment“.
Read more at Spiegel

4°C warmer 11,000 years ago
But Die kalte Sonne wondered if this were really so, and needed only 2 mouse clicks to find a recent temperature reconstruction for Greenland’s past (Lecavalier et al. 2017, pdf here). The paper’s Figure 4a  shows the temperatures, with the temperature of 1950 at the far right which in paleo-climatology is always meant as “present”.
 

Thus, 11,000 years ago, it was up to 4°C warmer than in 1950 over long periods of thousands of years, and today the warming has been about 1°C since then. Since we can see an ice sheet of 2,850,000 km³ (that is roughly Gt) today, the “point of no return” cannot have been exceeded 10,000 years ago. How does the heading then come about? We take a look at the associated work by King et al. 2020:
Dynamic ice loss from the Greenland Ice Sheet driven by sustained glacier retreat


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Greenland Ice Sheet is losing mass at accelerated rates in the 21st century, making it the largest single contributor to rising sea levels. Faster flow of outlet glaciers has substantially contributed to this loss, with the cause of speedup, and potential for future change, uncertain. Here we combine more than three decades of remotely sensed observational products of outlet glacier velocity, elevation, and front position changes over the full ice sheet. We compare decadal variability in discharge and calving front position and find that increased glacier discharge was due almost entirely to the retreat of glacier fronts, rather than inland ice sheet processes, with a remarkably consistent speedup of 4–5% per km of retreat across the ice sheet. We show that widespread retreat between 2000 and 2005 resulted in a step-increase in discharge and a switch to a new dynamic state of sustained mass loss that would persist even under a decline in surface melt.
Is there any talk of an irreversible end of the Greenland ice sheet? From the abstract:
We show that widespread retreat between 2000 and 2005 resulted in a step-increase in discharge and a switch to a new dynamic state of sustained mass loss that would persist even under a decline in surface melt.“
The authors see an acceleration in melting towards the ocean in the period 2000-2005, with not enough snowfall to compensate for the losses. They find a loss of about 500 Gt/year.
Only 0.15% of total ice mass
Unfortunately, they do not address the highly accurate gravity measurements with satellites in their paper. These data show a linear mass loss of only 275 Gt/year between 2003 and 2019 (with a gap in 2017 and 2018 due to a satellite change), so that in 17 years about 4200 Gt were lost, which is 0.15% of the total sheet.
What exactly do they say about the future?
Ultimately, predictions of future change will require improved understanding of the ice/ocean boundary and controls on glacier calving.“
Low-fact propaganda
This is much more cautious than what is being served up to us as “doomed” with the usual “overconfidence”. A look into the past is enough to unmask the media scream for what it is: low-fact propaganda.
Also read here at Ice Age Now.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Die kalte Sonne

Atlantic region near Iceland has cooled over the past 120 years. Image: NASA (public domain)
(German text translated by P. Gosselin)
There are areas of the world that stubbornly resist “global warming”. These include an oceanic region near Iceland where sea surface temperatures have cooled by almost 1°C in the last 120 years.
Allan & Allan 2019 have examined the “cold blob” more closely and suspect that the summer ice melt will cause cold melt water to flow into the ocean, which will then lead to the winter cold of the sea area.
The researchers disagree with the model by Stefan Rahmstorf from Potsdam, who suggested a weakening of the Gulf Stream as the cause of the “cold blob”.
Here’s the abstract of Allan & Allan 2019:
Seasonal Changes in the North Atlantic Cold Anomaly: The Influence of Cold Surface Waters From Coastal Greenland and Warming Trends Associated With Variations in Subarctic Sea Ice Cover
Worldwide sea surface temperatures (SST) have increased on average by about 1 °C since 1900 with the exception of a region of the North Atlantic subpolar gyre near 50°N which has cooled by up to 0.9 °C over the same period, generating the negative feature on temperature anomaly maps which has been colloquially described by Rahmstorf et al. (2015, https://doi.org/10.1038/nclimate2554) as the “cold blob” (abbreviated here CB). This unique long‐term surface cooling trend is most evident in February, but in August net warming is observed even at CB epicenter and the CB itself is reduced to a mere “warming hole.” These seasonal changes in the intensity of the CB are the product of two separate factors: (1) a long‐term winter cooling specific for the CB region which appears to be associated with cooling of Greenland coastal waters in autumn, plausibly linked to summer meltwater from icebergs and sea ice and (2) summer warming effects which derive from (a) dramatic reduction in summer sea ice cover in the sub‐Arctic over the last 30 years that allows enhanced absorption of sunlight by the new open water in summer and (b) an unusual period of increased summer sub‐Arctic ice cover in the early twentieth century, which lowers the SST baseline measured from 1900, thus increasing the calculated linear rate of change of SST with time. Both of these effects could contribute to the observed Arctic amplification of warming.”


		jQuery(document).ready(function(){
			jQuery('#dd_432284bd7a4adeca2d29179312ac45d3').on('change', function() {
			  jQuery('#amount_432284bd7a4adeca2d29179312ac45d3').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000

Share this...FacebookTwitter "
"Antimicrobial resistance (AMR) has been framed as one of the biggest threats to humanity in the 21st century. By 2050, more humans could die because of AMR than cancer. But despite alarming concerns from the early 1960s and warnings that the issue of antimicrobial resistance could cross barriers between animal species, the problems of antimicrobial use in animal farming have for long been ignored by policy makers and the food industry. Yet when the World Health Organisation (WHO) officially declared in 2001 that antimicrobial resistance was a “global problem” for both humans and animals, the link between animal farming and human health could no longer be ignored. Since then, significant public investments and political actions have been taken around the world to limit the use of antimicrobials in animal farming and raise awareness of the risks and problems related to the medicalisation of animal production.  Unsurprisingly, though, drugs are still massively consumed in animal farming and food production systems worldwide. Drugs have been instrumental to the modernisation of agriculture and are fundamental to the production of abundant and cheap food. In animal farming, drugs not only improve the health and growth of farmed animals, but are also part of the strategies employed by the food industry in order to produce more food for more people.  Public debates on the use of antimicrobials in animal farming have emerged at a time when vast epidemics of untreatable drug-resistant infections have emerged in humans because of antimicrobial resistance. Antibiotics that were once used to save lives against sepsis and were first introduced to help Allied soldiers fight the Nazis, soon became our worst enemies. In fact, the cost of new epidemics of drug-resistant infections has cast doubt on the benefit of using antimicrobials in animal farming in the global north, where countries spend vast amounts treating drug-resistant infections in their populations – the US spends US$34 billion a year on doing this. Contrary to what most newspaper headlines seem to suggest, antimicrobials are not the only drugs excessively used in animal farming. The intensive use of anthelmintics – a group of antiparasitic drugs – to prevent or regain production losses from multiple parasitic worms, has also progressively led to an increase in parasitic worm (helminth) resistance to available drugs in animal production. However, unlike antimicrobials, the crisis of this resistance in humans has been limited to the global south and neglected tropical diseases. Given the invisibility of their implications in the global north, anthelmintics are still massively consumed in animal farming. Since the beginning of the debate on drug resistance, many groups and voices, especially urban elites, have spoken about the medicalisation of animal farming, each offering its perspective and putting forward their preferred solutions: stopping animal farming in specific countries, regulating the use of antibiotics in farming, developing new antibiotics, vaccines and diagnostic tests, promoting biomedical research, developing lab-grown meat, educating veterinarians, and educating farmers. Because of their portrayed “ignorance”, farmers became stigmatised and their practices framed as part of the problem of drug resistance in the city. Associations, decision makers, the pharmaceutical industry, the food industry, experts and health professionals all called on farmers to stop using drugs in farmed animals, pushing the rhetoric towards the idea of an end to animal farming. Talking with livestock farmers across the UK, my recent research reveals that decisions made by farmers on the use of drugs in animal farming are not governed by ignorance. Instead, they are shaped by what farmers consider as appropriate practices for maintaining the well-being of their livestock and the tradition of rural professions – besides more mundane aspects that help farmers ensuring the sustainability of their businesses.  In fact, the use of drugs by farmers is situated within a larger context of animal production systems and food demand, which themselves contribute to the emergence of animal diseases, the medicalisation of animal farming and drug resistance. Urban elites often see farmers as “technicians” and the farming community as a ground for applying what is considered the best practices for improving animal health, welfare and the sustainability of the food industry. This denial of rural agency has been happening for some time and has led to an increasingly visible social divide between urban and rural. This social dislocation has recently been demonstrated in France with the gilets jaunes (yellow vests) movement. Sadly, urban elites tend to disregard the fact that farmers are the ones closest to the land and their livestock, and have everything to lose by not taking care of it. If public authorities are serious about tackling drug resistance and supporting animal well-being, sustainable food production and local economies, when it comes to farming, farmers should be the first we listen to."
"Bumblebees are in drastic decline across Europe and North America owing to hotter and more frequent extremes in temperatures, scientists say. A study suggests the likelihood of a bumblebee population surviving in any given place has declined by 30% in the course of a single human generation. The researchers say the rates of decline appear to be “consistent with a mass extinction”.  Peter Soroye, a PhD student at the University of Ottawa and the study’s lead author, said: “We found that populations were disappearing in areas where the temperatures had gotten hotter. If declines continue at this pace, many of these species could vanish forever within a few decades.” The team used data collected over a 115-year period on 66 bumblebee species across North America and Europe to develop a model simulating “climate chaos” scenarios. They were able to see how bumblebee populations had changed over the years by comparing where the insects were now to where they used to be. Dr Tim Newbold, of University College London’s Centre for Biodiversity & Environment Research, said: “We were surprised by how much climate change has already caused bumblebee declines. Our findings suggest that much larger declines are likely if climate change accelerates in the coming years, showing that we need substantial efforts to reduce climate change if we are to preserve bumblebee diversity.” Bumblebees play a key role in pollinating crops such as tomatoes, squash and berries. The researchers say their methods could be used to predict extinction risk and identify areas where conservation actions are needed. Prof Jeremy Kerr, of the University of Ottawa and the study’s senior author, said: “This work also holds out hope by implying ways that we might take the sting out of climate change for these and other organisms by maintaining habitats that offer shelter, like trees, shrubs or slopes, that could let bumblebees get out of the heat. “Ultimately, we must address climate change itself and every action we take to reduce emissions will help.” The research is published in the journal Science."
nan
"Well-meaning celebrities and MPs recently published a letter in the Guardian, calling for a ban on trophy hunting imports into the UK. To the novice conservationist, this surely sounds like a good thing, right? After all, trophy hunting kills animals so how could it possibly be good for conservation?  Unfortunately, these arguments are, at best, ill-informed and, at worst, they divert attention from the most pressing causes of biodiversity loss. The Guardian letter states that, over the last decade, hundreds of trophies have been imported into the UK. The CITES trade database lists the number of trade-restricted wildlife products entering and leaving a country. A quick perusal of it shows that, between 2008-2017, the UK imported more than 800 CITES-listed trophy products, averaging fewer than 100 trophies imported per year. To put this into perspective, more than 100 elephants are thought to be illegally poached every two days for their ivory, meaning the elephants killed for trophies and imported into the UK are an infinitesimally small number compared to the massive threat of poaching.  Poaching for the illegal ivory trade is not the same thing as legal trophy hunting and, while every death counts towards the decline of a species, we must not forget that trophy hunting helps reduce the greatest threat to terrestrial mammals: habitat loss. Don’t get me wrong, trophy hunting is morally repugnant. I cannot understand why anyone would want to kill an animal for fun – just as I can’t understand why anyone with other dining options would eat an animal, as we don’t need meat to survive.  Ethically, it makes sense to ban trophy hunting imports if the goal is to provide the greatest good for the greatest number of animals. But there are issues with this line of reasoning. Habitat loss, where land is converted for human use, remains the biggest driver of wildlife declines. Hunting reserves retain natural land for the benefit of trophy species like zebras and impalas, as well as a whole host of other biodiversity, such as birds, plants, insects and small mammals.  


      Read more:
      Trophy hunting is not poaching and can help conserve wildlife


 In effect, trophy animals become martyrs killed so other wild animals can benefit from the ever-dwindling resource of land. By diverting attention from these more pressing causes of wildlife decline by focusing on banning trophy imports, we may be left patting ourselves on the back and thinking that we’ve done our part for conservation and can all go home. I wish conservation needed such an easy fix, but sadly that is not the case. If these animal-loving politicians and celebrities are serious about conserving wildlife, they may be more effective focusing their energy towards the much bigger issues of agricultural expansion, the illegal wildlife trade and the ever-expanding threat of climate change.  If we addressed these more drastic problems we would likely save far more animals from untimely death while ensuring we have wildlife populations for generations to come. 


      Read more:
      How we arrived at a $1 billion annual price tag to save Africa's lions


 If we really want to “bend the curve” on biodiversity loss, we may do better byreducing our meat intake, hold politicians accountable for the UK’s climate change targets and reduce our overall consumption of goods. Like the signatories of the Guardian’s letter, I too want to protect the world’s wildlife. But let’s not kid ourselves into thinking red herrings like banning UK trophy hunting imports will be the silver bullet needed for addressing the sixth mass extinction. Knee-jerk reactions, while imbued with noble intents, will not save lions, elephants and rhinos."
"
Share this...FacebookTwitterScientists continue to publish papers revealing no unusual climate trends for the last several centuries in many regions of the world.
Despite the 135 ppm increase in CO2 concentration (275 ppm to 410 ppm) since the 1700s, a new 250-year temperature (precipitation) reconstruction (Peng et al., 2020) shows there has been no net warming in Central Asia since 1766. Two other reconstructions from this region also show no warming trend in recent centuries.

Image Source: Peng et al., 2020
Earlier this year we highlighted a new study that indicated France was up to 7°C warmer than today about 7800 years ago after cooling by 3°C in the last 200 years.
Another new study (Esper et al., 2020) suggests there has been no net warming in Spain since 1350 A.D.
The years that spanned 1474-1606 A.D. scored 7 of the 10 warmest years in the record. In contrast, there has been only 1 warmest year (1961) and 4 of the 10 coldest years since 1880.
The 2 warmest 30-year (climate) periods occurred in the decades surrounding the ~1530s and ~1820s.
The authors record a “striking” and abrupt (within decades) 1°C warming trend during the late 1700s to early 1800s that exceeds any temperature change in the modern record.

Image Source: Esper et al., 2020
Share this...FacebookTwitter "
"Representatives of almost all the countries on the planet are gathering in Katowice, Poland, for the 24th Conference of the Parties (COP24) of the UN Framework Convention on Climate Change (UNFCCC). They will set the course for action on climate change by discussing the implementation plan for the 2015 Paris Agreement which aims to coordinate international effort to halt warming at 1.5°C. The COPs receive significant media attention and, sometimes, even notable public interest. They take place every year as an opportunity for countries to collectively assess progress on dealing with climate change. In 2018 the negotiations kick off barely two months after a report by the UN’s Intergovernmental Panel on Climate Change (IPCC) warned that the international community only has a 12-year window to drastically reduce greenhouse gas emissions. Clearly, 24 years after the first COP there is a deep disconnect between how urgently the world needs effective climate policy and the pace of discussing global mechanisms on how to abate greenhouse gas emissions.  The first COP meetings held in the 1990s led to the creation of the Kyoto Protocol in 1997, which set binding emissions targets for developed countries over two “commitment periods” (2008-2012 and 2013-2020). However, the Kyoto agreement failed as the US did not ratify it and because several inconclusive conferences followed its implementation. COP15 in Copenhagen in 2009 also failed to yield any agreement on binding commitments for the second commitment period. A few major countries agreed to a short accord recognising the need to limit global temperature rises to 2°C, but there were no substantial guidelines on how to do so.  Similarly, COP19 in Warsaw four years later did not finalise any binding treaty. It only recognised “a flexible ruling” on differentiated responsibilities and loss and damage. In Warsaw, the international community failed to take essential steps for the future. Some even think that the 2013 conference cast some doubt on the capacity of the Polish government to successfully lead COP24 in 2018. Against this backdrop, COP21 in Paris in 2015 appeared to generate the most optimistic outcome in two decades of international climate negotiations. In Paris, the world leaders agreed on a general action plan that legally binds countries to have their progress tracked by technical experts.  The countries who signed up also agreed on a “global stocktake” – a process for reviewing collective progress towards achieving the long-term goals of the agreement. However, lots of details about the Paris Agreement still have to be nailed down. This is precisely what the international community seeks to do this December in Poland. The major objective for COP24 is to agree upon the so-called Paris “rulebook” – the details of how nations should implement the Paris Agreement and report their progress. Three major areas of political discussion will receive most attention: finance, emission targets, and the role of “big” states. Finance In 2015, richer countries pledged US$100 billion a year by 2020 for poorer nations to mitigate the effects of climate change. However, the climate funding is still about US$20 billion short. COP24 delegates will need to discuss in more detail on when the rest of the money will be generated before committing to the rulebook.  Perhaps even more importantly, rules for where that money comes from, and particularly whether international loans are acceptable, still have to be agreed on. Because finance is closely linked to issues of justice and fairness in the international system, it is unlikely that this discussion will lead to more generous levels of climate aid – although there is space for improvement, and some past conferences have actually provided small but significant advances on this front. Emission targets COP24 also needs to set some form of flexible yet comparable rules that will govern the Paris Agreement. One groundbreaking feature of the Paris Agreement is that all parties agreed to commit to national contributions to climate action. In other words, the agreement is based on a bottom-up process in which countries largely determine their own contributions, and then act upon them. This COP may settle on some basic strategies for verifying climate actions, but it is very unlikely that the international community will agree on any mechanisms for delivering sanctions to states that do not meet their targets, because of the high sensitivity towards financial costs for non-abatement. The role of ‘big’ states Finally, while “small” countries will have an important role to play at the negotiations as usual, there are several question marks around the large countries that need to bear a lot of the efforts to curb greenhouse gas emissions.  It will not help that President Donald Trump, who intends to withdraw the US from the Paris Agreement, decided in 2017 to cancel climate funding for poor nations. The US position at COP24 will also affect China and India, which are likely to continue disagreeing with rich countries on some fundamental issues. Additionally, the domestic politics of Russia and Brazil point to more uncertainty for cooperation. The urgency to reach key milestones in the Paris Agreement and deal with climate change puts a lot of high expectations on COP24. Unfortunately, many challenges stand ahead of international climate cooperation.  Approaching the negotiations with the right level of reason and determination will be critical to manage expectations and avoid any media “hysteria”, as
media coverage can hurt the climate talks by shifting attention from the policy issues to unproductive discussions of whether climate change is influenced by humans.  For a credible and valid rulebook, we need frank conversations about energy transition and compensating the “losers” of climate policies, such as people working in high-emission sectors.  There might be the opportunity to do so in Katowice, an industrial hub and coal-mining city. We will see if this COP will highlight the necessary transition from fossil fuel industry to renewable solutions as the negotiations unravel."
"

You know, for as much as we humans think we really have control over our planet, nature tends to remind us from time to time that we are just flyspecks in the vastness of space and energy. Take for example the amount of energy we get from the sun: 174.0 PetaWatts – (10^15 watts) which is the total power received by the Earth from the Sun. Now compare that to this news item.
From Slashdot: Astronomers are still speculating as to what could have caused an abnormally strong five millisecond burst to be detected six years ago when it completely saturated their recording equipment. From the article: ‘The burst was so bright that at the time it was first recorded it was dismissed as man-made radio interference. It put out a huge amount of power (10^33 Joules), equivalent to a large (2000MW) power station running for two billion billion years.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea3705f38',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

Back in December, Senate Democrats, with President Obama’s backing, attempted to prohibit anyone on the federal government’s terrorism watchlist from purchasing a firearm.   
  
  
At the time, I criticized the proposal for its lack of process and its inevitable inefficacy at reducing gun crime or terrorism.   
  
  
Yesterday, Senate Democrats launched a filibuster in order to push for the resurrection of the failed “No‐​Guns List.”   
  
  
The substance of their plan has not changed, and my earlier criticism still stands:   




How does a person prove they are not a terrorist? It’s virtually impossible. A no‐​flyer doesn’t receive the evidence against them or a hearing before being placed on the list. They are not allowed to confront their accuser. Even getting the government to acknowledge that a person is on the list may require lengthy and expensive litigation. A person on the no‐​fly list may not even know they are on the list until they’re refused service at the airport. A person on the broader terror watch list has no means of finding out. The system is devoid of anything resembling due process, a flaw _The New York Times_ condemned as being intolerable in a free and democratic society and over which the American Civil Liberties Union is currently suing the Obama administration. The no‐​fly listing procedure has already been declared unconstitutional by at least one federal judge.   
  
  
Including too many people on the list is inevitable. Nobody wants to explain, after a terrorist attack, why the attacker wasn’t in the database. And that overly inclusive quality has manifested itself in absurd ways already. Just a few examples of no‐​fly denials: the late Democratic Massachusetts Sen. Ted Kennedy, congressman and civil rights hero John Lewis, dozens of people named Robert Johnson, members of the U.S. military and federal air marshals.   
  
  
The potential for false positives and mistaken identities is not just accepted as collateral damage by these no‐​gun list proposals; it is the entire point. Anyone who has actually been convicted or is currently charged with terrorism‐​related crimes is already prohibited from purchasing a firearm under federal law. The people adversely affected by this proposal will inevitably be people against whom the government lacks sufficient evidence to charge.   
  
  
The fact that a person hasn’t been adjudicated as dangerous doesn’t preclude them from committing violence, of course. But just how much discretion should the president have in abolishing constitutional rights without charge or trial?



What _has_ changed is the political climate in the interim.   
  
  
The No‐​Guns List appears to have picked up some powerful allies on the right. Presumptive Republican presidential nominee Donald Trump has expressed support for the idea, and is apparently lobbying the National Rifle Association to come along with him.   
  
  
The GOP and the NRA are generally regarded as the two primary bulwarks against misguided gun control proposals. Adding their weight to this particular gun control proposal would bolster its legislative prospects immensely.   
  
  
Even if, as some supporters have urged, the law requires hearings before a watchlisted person can be denied the right to bear arms, important questions remain. What exactly does the state need to prove in order to take someone’s 2nd Amendment rights away? What is the burden of proof? Will judges allow the use of secret evidence, citing state secrecy concerns for refusing to disclose it? Will the individual be entitled to legal representation? Can he call and cross‐​examine witnesses? Can he appeal the ruling? Can he publicly discuss his case?   
  
  
And those are just the legal concerns. There are also pragmatic issues. What information does the FBI convey to the gun seller when someone on the list is denied? Is the gun seller told that he’s got a terror suspect standing in his store? What if the person actually is an aspiring terrorist under government surveillance? Doesn’t this process inevitably tip him off? Would finding out that he’s on the government’s radar only encourage an aspiring terrorist to act quicker? Would it compromise legitimate surveillance operations?   
  
  
The Boston bombers didn’t need guns. Nor did Timothy McVeigh or the 9/11 hijackers. Giving terror suspects a sure‐​fire way to figure out whether they’re being surveilled seems like a large price to pay for what may be a non‐​existent benefit.   
  
  
Omar Mateen passed background checks. He passed training requirements. He had access to weapons as a security guard. He wasn’t even on the terrorism watchlist. Nothing in this proposal, and nothing in any of the other gun control proposals this tragedy has spawned, would have kept firearms out of Omar Mateen’s hands. The only way his rampage could have been prevented was for someone to kill him first. Unfortunately, laws that deny even sober people the right to carry weapons in establishments that serve alcohol meant that the law‐​abiding victims were sitting ducks.   
  
  
Knee jerk reactions to horrible tragedies have proven to be a poor basis for good public policy. We have institutions like due process precisely for times when emotions threaten to overrun safeguards that are just as important for protecting the innocent as the guilty.   
  
  
It’s hard to imagine a graver violation of the spirit of the 2nd Amendment than a law allowing the President to declare anyone an enemy of the state without so much as a charge and subsequently bar them from exercising their 2nd Amendment rights. But Republicans, lured from their stalwart support of gun rights by fears of terrorism, and Democrats, lured from their stalwart support of civil rights by their zeal for gun control, combined with an election cycle that has been defined by appeals to fear may be creating a perfect storm and a severe threat to liberty.   
  
  
P.S. Two tweets this morning from sitting Congressmen highlight the divide.   
  
  
Democratic Senator and gun control advocate Joe Manchin doesn’t inspire confidence when he says things like “due process is killing us.”   




> .@Sen_JoeManchin: Due process is what's killing us right now https://t.co/OTf9LnxHXZ
> 
> — Morning Joe (@Morning_Joe) June 16, 2016



.@Sen_JoeManchin: Due process is what's killing us right now https://t.co/OTf9LnxHXZ



Luckily, not everyone in Congress agrees.   




> Amazing that U.S. senators would filibuster in favor of using secret lists, like some authoritarian regime, to deny rights w/o due process.
> 
> — Justin Amash (@justinamash) June 16, 2016



Amazing that U.S. senators would filibuster in favor of using secret lists, like some authoritarian regime, to deny rights w/o due process.
"
"In the UK it is illegal to deliberately kill or injure red squirrels, disturb them while they are using a nest, or destroy their nests. Yet, although the 1981 Wildlife and Countryside Act provides these protections, there is a legal anomaly in England and Wales – one that can potentially undermine the conservation of the red squirrel, along with every other rare and endangered forest plant or animal species. Although rare woodland species are protected, the habitat they dwell in is generally not. Timber harvesting requires a licence – although there are some very limited exceptions where this permission is not needed, for example due to public safety, or where small volumes of wood are being cut. But under the 1967 Forestry Act, applications in England and Wales cannot be refused for “the purpose of conserving or enhancing” flora or fauna (though they can be refused for this purpose in Scotland). Nor can licence conditions be imposed for this reason. No matter how rare, how vulnerable or how much effort has gone into the regional conservation of a species, there are no exceptions to this. A timber felling licence does not sweep aside the legal protection that animals such as the red squirrel have – and a precautionary approach is advisable when felling in woodlands containing this species. Nevertheless, the possession of a felling licence opens a loophole because the wildlife legislation protecting the red squirrel provides the defence of “incidental result of an otherwise lawful operation”. So, with a licence in hand, woodlands containing this threatened species can be clearfelled because tree harvesting is a lawful operation.  The solution is clearly to amend the Forestry Act to better align timber harvesting and wildlife protection laws. Harmonising UK forestry legislation would allow for better timing, methods and patterns of tree harvesting to be guaranteed in habitats containing any rare species. Additionally, while licensing authorities currently can only assess each felling licence application in isolation, legislative change would enable the cumulative impact of granting a licence to be considered in relation to felling that had previously been approved. This stops management of rare woodland species on specific sites being at the mercy of timber prices and market economics. Commercially managed forests provide jobs and produce valuable products. As the modernised laws in Scotland show, the forest industry operates quite successfully where timber harvesting licence applications can consider wildlife impacts. Amendment in England and Wales would deliver similar integration.  Consequently, the ethical credentials of the timber harvesting industry would be strengthened. In an age where consumers want confidence that timber products they purchase have not destroyed wildlife populations, this is essential. It is already commonplace for products made of UK-sourced wood to have the Forest Stewardship Council (FSC) logo. The FSC signifies the wood is from sustainable sources managed with a high regard for wildlife conservation. So amendment of the 1967 Forestry Act would give greater consumer confidence in supply chains and also reinforce the credibility of the global FSC forest certification scheme itself.  Since the 1980s, the forestry sector has increasingly balanced commercial, societal and environmental imperatives. Consequently there will be times, should the law change, when refusal of a logging license to conserve biodiversity is an unavoidable trade off. Here it is important to stress that the forest industry receives state grants to support crop establishment and protection. The taxpayer therefore has a right to ensure that forests are managed sympathetically for wildlife. We should not forget that commercial plantations can be vitally important for wildlife and without them many species would be much rarer. On the other hand, some felling will inevitably still be licensed even though operations will adversely affect individual animals of a protected species through habitat loss or alteration. Although such decisions may be unpopular with local people, it is common for wildlife management strategies to focus on population level conservation targets rather than at the individual animal level. I believe an amendment to the Forestry Act is overdue. Regulatory change will empower authorities with the legal tools to achieve a better balance between often competing forest management objectives. It will benefit wildlife and the UK timber industry too."
"It seems new action to tackle plastic pollution is announced every week, from the 5p plastic bag charge to governments debating a tax on plastic packaging. Businesses are also showing their green credentials as major supermarkets pledge to reduce plastic packaging alongside some multinational companies. With such serious steps, it looks like our problem with plastic will soon be fixed.  Before we get too excited though, other recent news stories include billions of dollars being invested in new plastics refineries and plastics being found everywhere, including in our soil. It’s estimated that 4.8–12.7m metric tonnes of plastic enters the ocean from land-based sources annually. That’s everything from toothbrushes to microplastics worn off vehicle tyres. The plastics found in the ocean come from every country in the world and if we are to tackle it we need a worldwide solution.  Like COP24 for climate change, an international summit for plastic pollution could achieve just that. We do have some international laws that attempt to tackle plastic pollution. The UN Convention on the Law of the Sea contains a commitment to “prevent, reduce and control pollution from land-based sources” which covers plastics. More recently, the Honolulu Strategy was agreed in 2011 to help tackle marine debris coming from land-based activities. If these commitments were to be fully met then our plastic problem would be vastly reduced. One issue is that these obligations depend on plastic being recognised as harmful to humans or marine life. Plastic has long been considered a wonder material, which makes modern life possible. Like other “wonderful inventions” such as the ozone-eating CFCs, it is only as plastic has started to accumulate in the world that we have realised it is a problem. A second issue is that each country has responded to this problem in different ways. Kenya, for example, has adopted legislation banning single use plastic bags, while the UK has added a charge to their use.  Current proposals to tackle plastics focus on increasing recycling. It is worth remembering though that only around 11% of plastic is currently recycled around the world. If we are to rely on recycling as a means to tackle plastic pollution we need to rapidly increase recycling in almost every country.   An increase in recycling to the extent needed can’t happen overnight. We’d need effective and accessible recycling facilities and public education. Both would need huge investments of time and resources across the world.  A treaty may be one way of coordinating such action and sharing knowledge about how best to improve recycling. Countries already share knowledge about how they meet some treaty obligations through reports to a governing body on climate change, a similar approach could be taken in a plastics treaty. Another measure being used is taxation. The assumption is that if we make plastics more expensive then either less will be used or alternative materials will replace them. Deposit return schemes are also suggested as a way to “nudge” producer and consumer behaviour. These types of measures do not always, however, prompt the desired response.  Sometimes, for example, costs are simply passed on to consumers. It is also difficult to apply these measures in emerging economies which lack the same regulatory bodies and infrastructure to monitor these measures, so other approaches may be needed. Governments have faced the question of how to tackle a pervasive pollutant produced by all countries before and the answer was to adopt a treaty for a rapid and coordinated response. The best known example is the Ozone Convention which was adopted in 1985 to reduce chemicals used in refrigeration and aerosols which damaged the ozone layer. Like subsequent treaties addressing other harmful chemicals, such as the POPs Convention, the Ozone Convention tackled the most harmful first and was designed to enable alternatives to be introduced. Alternatives to harmful plastics do already exist – current plastics are largely derived from oil and so do not easily degrade.  Alternative plastics are being developed from prawn shells and from plants such as seaweed which will degrade more easily. World leaders have called for action on plastics. It’s time to follow through with a “plastics convention”, containing binding commitments to phase out and prevent future plastic pollution. A plastics convention could ban oil-based plastics in a similar way to the ban on ozone-eating chemicals. Single use bags and straws could be phased out almost immediately under a global treaty, with other plastics addressed over a longer time frame. Those used in medical surgery may take decades to phase out, but support could be provided to industry to develop bioplastics, or other alternatives to plastics. A treaty could also address gaps in the current law. There is, for example, no provision for cleaning up the plastics already in the ocean. A new treaty could provide for a clean up fund to address these “legacy” plastics. The fund could be supported through contributions from importers and exporters of plastics, as already happens with importers and exporters of oil who pay into a fund to address harm from oil spills, or through a tax on oil-based plastics products. The public are clearly supportive of action to tackle plastic pollution and alternative materials are being developed that could replace oil-based plastics. A treaty negotiated by the world’s governments would allow us to take coordinated action against oil-based plastics."
"
Below is an opinion from the Washington Times by Geophysicist David Denning, to which I’ve added photos and links to the events he’s written about.
 
A caveat: I caution the reader that annual weather does not equate to long term climate. Yes we have had a number of record cold events in 2007, and the winter in the Northern Hemisphere is already shaping up to be colder than normal. But fortunes of weather can turn on a dime. I’d also point out that we are in a solar minimum right now and predictions of solar cycle 24’s peak range from it being very low (colder) to very high (warmer). The next few years will be telling.

Snow in Buenos Aires, July 9th, 2007



Year of global cooling
By David Deming
December 19, 2007


South America this year experienced one of its coldest winters in decades. In Buenos Aires, snow fell for the first time since the year 1918. Dozens of homeless people died from exposure. In Peru, 200 people died from the cold and thousands more became infected with respiratory diseases. Crops failed, livestock perished, and the Peruvian government declared a state of emergency.

Unexpected bitter cold swept the entire Southern Hemisphere in 2007. Johannesburg, South Africa, had the first significant snowfall in 26 years. Australia experienced the coldest June ever. In north-eastern Australia, the city of Townsville underwent the longest period of continuously cold weather since 1941. In New Zealand, the weather turned so cold that vineyards were endangered.

Last January, $1.42 billion worth of California produce was lost to a devastating five-day freeze. Thousands of agricultural employees were thrown out of work. At the supermarket, citrus prices soared. In the wake of the freeze, California Gov. Arnold Schwarzenegger asked President Bush to issue a disaster declaration for affected counties. A few months earlier, Mr. Schwarzenegger had enthusiastically signed the California Global Warming Solutions Act of 2006, a law designed to cool the climate. California Sen. Barbara Boxer continues to push for similar legislation in the U.S. Senate.

In April, a killing freeze destroyed 95 percent of South Carolina’s peach crop, and 90 percent of North Carolina’s apple harvest. At Charlotte, N.C., a record low temperature of 21 degrees Fahrenheit on April 8 was the coldest ever recorded for April, breaking a record set in 1923. On June 8, Denver recorded a new low of 31 degrees Fahrenheit. Denver’s temperature records extend back to 1872.

Recent weeks have seen the return of unusually cold conditions to the Northern Hemisphere. On Dec. 7, St. Cloud, Minn., set a new record low of minus 15 degrees Fahrenheit. On the same date, record low temperatures were also recorded in Pennsylvania and Ohio.

Extreme cold weather is occurring worldwide. On Dec. 4, in Seoul, Korea, the temperature was a record minus 5 degrees Celsius. Nov. 24, in Meacham, Ore., the minimum temperature was 12 degrees Fahrenheit colder than the previous record low set in 1952. The Canadian government warns that this winter is likely to be the coldest in 15 years.

… If you think any of the preceding facts can falsify global warming, you’re hopelessly naive. Nothing creates cognitive dissonance in the mind of a true believer. In 2005, a Canadian Greenpeace representative explained ‘global warming can mean colder, it can mean drier, it can mean wetter.’ In other words, all weather variations are evidence for global warming. I can’t make this stuff up.’
Note from Anthony: That’s what I call CYA forecasting 😉
No; but others can, and do. However, maybe at long last the penny is dropping. The New Statesman, no less, this week publishes a piece by sensible David Whitehouse which says flatly:… The fact is that the global temperature of 2007 is statistically the same as 2006 as well as every year since 2001. Global warming has, temporarily or permanently, ceased. Temperatures across the world are not increasing as they should according to the fundamental theory behind global warming – the greenhouse effect. Something else is happening and it is vital that we find out what or else we may spend hundreds of billions of pounds needlessly.

… For the past decade the world has not warmed. Global warming has stopped. It’s not a viewpoint or a sceptic’s inaccuracy. It’s an observational fact…. So we are led to the conclusion that either the hypothesis of carbon dioxide induced global warming holds but its effects are being modified in what seems to be an improbable though not impossible way, or, and this really is heresy according to some, the working hypothesis does not stand the test of data.

It was a pity that the delegates at Bali didn’t discuss this or that the recent IPCC Synthesis report did not look in more detail at this recent warming standstill.A pity indeed, that the entire western ruling class has been taken in by this scam.But now the cavalry appears at last to have arrived. According to this story, a US Senate report documents the opinion of hundreds of prominent scientists from around the world who say global warming and cooling is a cycle of nature and cannot legitimately be connected to man’s activities.The report compiled observations from more than 400 prominent scientists from more than two dozen nations who have voiced objections to the so-called ‘consensus’ on ‘man-made global warming.’ Many of the scientists are current or former participants in the United Nation’s Intergovernmental Panel on Climate Change, whose present officials, along with former Vice President Al Gore, have asserted a definite connection.

The new report comes from the Senate Environment and Public Works Committee’s office of the GOP ranking member, and cites the hundreds of opinions issued just in 2007 that global warming and man’s activities are unrelated. [My emphasis]…‘Many scientists from around the world have dubbed 2007 as the year man-made global warming fears “bite the dust”’, the introduction said. And there probably would be many more scientists making such statements, were it not for the fear of retaliation from those aboard the global-warming-is-caused-by-SUVs bandwagon, the report said.And it details some of this intimidation.
Looks like man-made global warming theory is melting away faster than you can say Al Gore. A lot of reputations are now going to disappear along with it: all those who were part of the famous ‘consensus’ (not).Those people should never be taken seriously again.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea1f56227',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Evidence is rapidly accumulating that ocean acidification and elevated temperatures will have catastrophic consequences for marine organisms and ecosystems. In fact, it is something we are already witnessing. Coral reefs are bleaching, while snails and other calcifying marine organisms struggle to build their shells, scales and skeletons and juvenile marine animals even struggle to navigate to suitable habitats. Yet many primary producers, including seaweeds, are predicted to thrive in the acidic oceans of the future – as they use CO₂ from the seawater to produce energy by photosynthesis.  Humans have eaten seaweeds for tens of thousands of years and today the diets of billions of people, especially in Asia, are based on cultivated seaweeds. However, while future ocean conditions may improve the yield of farmed seaweeds, we do not know how the nutritional content of seaweeds will be affected by climate change. To investigate this, we recently looked into how the iodine content of seaweeds will be affected by future climate change scenarios.  Seaweeds are one of the best natural sources of iodine, and this essential mineral is used by the body to make thyroid hormones. But both too much and too little iodine can change the way the body’s thyroid gland works. If climate change were to affect the amount of iodine in seaweed, humans – and other animals – who rely on it as a staple part of their diet may suffer serious health problems. For this recently published study, we simulated current and future ocean acidification conditions in laboratory and outdoors settings. To conduct the outdoor experiments, we enclosed seawater in  cages made of very small mesh polythene nets so that environmental conditions such as CO₂ and temperature could be manipulated and responses monitored, while all other environmental conditions remained the same as the natural environment. We used three kelp species – Saccharina japonica, Undaria pinnatifida, and Macrocystis pyrifera – as well as the coastal seaweeds Ulva pertusa, Ulva intestinalis, Gracilaria lemaneiformis and Gracilaria chouae, for the research. With the exception of M. pyrifera, these seaweeds are widely consumed by humans across the world – for instance, in sushi, soups and in the Welsh delicacy laverbread. M. pyrifera was selected as it is a preferred food source of marine invertebrates, such as sea urchins and abalone, which are harvested by the fishing industry. In ocean acidification research like this, oceanographers monitor the partial pressure of CO₂ in seawater. This figure reflects the amount of dissolved CO₂, which is measured as parts per million (or µatm) and is an indicator of how acidic the oceans are. The Intergovernmental Panel on Climate Change predicts that future CO₂ in the oceans will more than double by the year 2100 – rising from current levels of 400 µatm to 1,000 µatm – if no mitigating action is taken against climate change.  We created these future ocean acidification conditions by blowing CO₂ bubbles into the seawater, and measuring the µatm. We then grew seaweeds in eight climate scenarios in the lab and two climate scenarios in the field. These ranged from current levels of CO₂ and temperature to future ocean acidification and elevated temperature scenarios.  We found that seaweeds grown in conditions which followed future ocean acidification predictions accumulated more iodine than seaweeds grown in present-day conditions. However, in the scenarios we tested, elevated temperature was not as important as ocean acidification in causing iodine accumulation in seaweeds. This means that while we expect the yield of a very important food crop to increase under future climate change, levels of iodine will also increase, affecting human nutrition. We also traced elevated iodine content from seaweeds to their consumers. Natural consumers of seaweeds such as fish and shellfish are also a rich dietary source of iodine for humans. Using an outdoor feeding experiment, we examined the effect of consuming seaweeds under future ocean acidification conditions on the edible shellfish, abalone (Haliotis discus). We found that iodine concentrations increased in shellfish tissue after eating seaweeds with elevated iodine concentration. In addition, we saw that the concentration of thyroid hormones in the shellfish tissue decreased. This provides evidence that ocean acidification impacts the quality of seafood by changing the concentrations of an essential mineral with consequences for consumers. There is a risk that as the world’s climate continues to change, people who eat seaweed as a staple part of their diet may consume too much iodine, which can lead to a wide range of health problems. Since seaweeds and shellfish underpin the nutrition of billions of humans around the world it is essential to understand how the iodine content of seafood will change under global climate change. This information can for instance be used by the World Health Organisation to provide recommendations on appropriate levels of seaweeds consumption to maintain a sufficient daily iodine intake."
"

 **Presented by Alan Reynolds at “Deregulation in the Global Market Place** : **Challenges for Japan and the United States in the 21stCentury** **”  
A Keidanren‐​Cato Institute Symposium, Tokyo, April 6, 1998 .**



American economists have been giving policy advice to Japan since the Shoup tax reform commission of 1949. Even then, the advice was not always helpful. 



U.S. government officials now tell Japan that larger budget deficits are the key to boosting economic growth and stock prices. Yet the same officials claim that the U.S. economy and stock market have benefitted from much _smaller_ budget deficits. 



When looking at tax policy as a separate policy tool, we must get beyond Keynesian “macroeconomics,” and the related bad habit of ascribing magical properties to government borrowing. A few years ago, prominent macroeconomists in the U.S. and Japan were absolutely confident that American budget deficits had pushed interest rates and the dollar up, causing trade deficits. Today, much larger budget deficits in Japan are associated with the lowest interest rates in world history, a falling yen, and rising trade surpluses. 



A theory that can predict anything can also predict nothing. Fiscal macroeconomics is an unsolvable mystery, something best relegated to a museum. Even the dogma that budget deficits “stimulate” demand (nominal GDP) is just another archaic theory with no shred of evidence.(1) Budget deficits are a consequence of slow economic growth, not a cause of rapid growth. Yet the elusive theory of “fiscal stimulus” still allows politicians to claim that endless public works schemes are a free lunch, rather than a dubious debt service burden on taxpayers.(2)



Japan’s nominal GDP growth surged in the late 1980s because the Bank of Japan was buying a lot of securities (see the Appendix: “Money Matters”). Nominal GDP growth slowed after 1991–92 because the monetary base shrank. Growth of aggregate demand depends on monetary policy, not government borrowing. Whether or not supply can keep up with demand, however, _is_ affected by the _micro_ economic structure, including tax rates. 



Any serious look at policy must be based on microeconomics — all the messy but vital structural details about disincentives and distortions. An improvement in tax policy is _not_ measured by how much revenue is lost, but by how much efficiency and prosperity is gained. 



To describe tax policy in macroeconomic terms — solely by its immediate effect on the budget — leads to paradoxical conclusions. Many people suspect that the April 1997 increase in Japan’s value‐​added tax contributed to recession.(3) If that is correct, this “tax increase” will surely result in _less_ tax revenue, not more. A macroeconomist may later observe such a loss of revenue and conclude that tax policy has become “stimulative” — the opposite of what actually happened. 



Conversely, if a reduction in the highest, most damaging tax rates results in slightly more rapid economic growth, then it may also result in _more_ tax revenue. It is the impact on the economy that matters. What happens to the budget deficit mainly depends on what happens to the economy, not the other way around. 



An _efficient_ tax system is one that _raises revenue with the least possible damage to economic progress._ With such a system, tax revenues naturally _grow_ as the economy expands. 



The _marginal_ tax burden in Japan is unusually high, yet average tax revenues are relatively low. Aside from Social Security, revenues have been _falling_ since 1990, when many new taxes were added. High tax _rates_ and weak revenues are symptoms of an _inefficient_ tax system. 



******Figure 1** shows that it is _not_ unusual for countries with high tax rates (such as Japan) to collect very little revenue, even in _static_ terms — as a percentage of GDP, rather than real revenue growth over time. These figures are for the _national_ income tax on individuals (although local taxes are very important in Sweden, Canada, Japan and others). The only countries with high tax rates that collect much revenue are those in which the _lowest_ tax rate is also high, such as the 19% rate in Germany (although even a 25% minimum tax does not work in Turkey). Tax rates above 35–40% never seem to yield much revenue, anywhere. 



As the table indicates, the ratio of tax revenues to GDP can be a misleading measure of the actual burden of taxes. Some taxes may be extremely destructive yet yield very little revenue.(4) Just as “prohibitive” tariffs yield no revenue, extremely high tax rates can also be prohibitive, or nearly so, because they (1) seriously discourage the taxed activity, (2) lead to rampant tax avoidance and evasion, and (3) foster capital flight and a “brain drain.” 



A tax system that suffocates growth of GDP may result in a rising ratio of revenues to GDP even though revenues are growing very slowly in real terms. This is the situation of many Continental European countries. Real tax revenues grow very slowly, but the economy grows even more slowly, so revenues rise as a percentage of stagnant GDP. Yet such governments have little room to increase spending in real terms because revenues have stopped growing in real terms. 



Conversely, revenues may appear quite low relative to GDP and yet be growing very rapidly in real terms, because the tax climate is conducive to rapid growth of real GDP. Hong Kong’s tax revenues ( _excluding_ land sales) grew by 17.8% a year from 1984 to 1996 — nearly three times as fast as the 7.1% pace of U.S. revenue growth. Yet the ratio of taxes to GDP remains low in Hong Kong because real GDP has increased almost as rapidly as real tax receipts. Government consumption in Hong Kong has long increased by 6% a year, in real terms. 



In short, tax policy is _not_ properly described by revenue losses alone, nor even by revenues as a percentage of GDP. We need to look at _marginal_ tax rates on the returns to additional capital, including human capital. 



**The Shoup Mission**



Rather than rely too heavily on economic theory, or on foreign advice, it is often useful for a country to reexamine its own history (and that of its neighbors) to see which policies were followed by prosperity and which were not.()



In the late 1940s, the American Occupation had imposed brutal income tax rates on Japan, as high as 86% on income above Â¥5 million. This was a central part of a severe austerity program, _not_ a plan to promote economic growth. As Edwin Reischauer pointed out at the time, “Steeply graduated income taxes and inheritance taxes have been adopted to prevent in the future the accumulation of … concentrations of wealth.” But taxes designed to punish additions to _income_ must also punish additions to _output_ — economic growth. So, Japan set out to free itself from the oppressive Occupation tax regime. 



In late 1950, following a similar policy coup in Germany, Japan’s highest individual income tax rate was slashed to 55% from 86%. From 1950 to 1974, Japan cut taxes _every year_ (except 1960) often by greatly increasing the income thresholds at which the higher tax rates applied, or by enlarging deductions and exemptions. The taxable income needed to fall into a 60% tax bracket was raised to 3 million yen by 1953, for example, compared with only 300,000 in 1949. The Shoup Commission’s net worth tax was also abolished in 1953. The sting of high tax rates was further neutralized by exemptions for interest income and capital gains, deductions from corporate and individual taxes on dividends, a deduction for earnings, and various other holes in the tax base, legitimate and otherwise.(6)



Some deductions were far from neutral, and therefore less desirable than lower tax rates would have been. Yet the continual tax reductions from 1950 to 1974 accomplished two things. First, they greatly reduced effective marginal tax rates. Second, they moved the system a long way toward what is sometimes called a “consumed income tax” or “expenditure tax” — that is, a system that taxes income only once, regardless of whether the income is saved or devoted to immediate consumption.(7)



American economists were extremely critical of both accomplishments. In 1958, a member of the Shoup Commission, Jerome Cohen, described the tax cuts as “foolhardy from an economic point of view.”(8) In 1964, Martin Bronfenbrenner complained that Japan’s reductions of the highest tax rates amounted to “a retreat from the _equitable_ policies of the American Occupation.”(9)



Tax reduction was considered “foolhardy” precisely _because_ it fostered rapid economic growth. American economists were convinced that Japan would always be plagued with what Bronfenbrenner called “endemic Japanese balance of payments problems.” Failing to distinguish between tax rates (which were falling) and tax revenues (which were soaring), the U.S. critics argued on Keynesian grounds that Japan’s taxes had to be kept high to _suppress_ economic growth. Otherwise, Japan’s trade deficit would supposedly reach “currency crisis” proportions. For the same reason, many U.S. economists were sharply critical of Japan’s deep tariff cuts in the 1960s (e.g., by 1975, the effective tariff on autos fell from 40% to 10%, and the tariff on televisions from 30% to 5%). 



Bronfenbrenner’s remark about Occupation tax rates being more “equitable” was also in the spirit of the times. From about 1938 to 1962, U.S. “public finance” economists were much more concerned about using taxes to prevent people from becoming rich than about any adverse effects on economic growth. An intellectual godfather of the Shoup Commission, Henry Simons, knew perfectly well that “every gain [in] better distribution will be accompanied by some loss in production.”(10) But Simons and his followers assigned a low priority to production, believing that income leveling was the primary goal of tax policy.(11)



In the U.S., the postwar emergence of Keynesian macroeconomics destroyed any lingering anxieties about the impact of high tax rates on economic growth. Early postwar predictions of chronic “underconsumption” and “secular stagnation” meant that _saving was considered a terrible thing_ , and therefore an excellent target for confiscatory taxation. After those dire predictions proved false, slow growth was then said to be something that could easily be fixed by printing more government bonds (called “fiscal policy”) or more money (“monetary policy”). Attention to tax incentives disappeared until the Kennedy Administration, when it was revived largely because of the embarrassing success of falling tax rates and rising income thresholds in Japan and Germany. 



The point of all this history is to emphasize that promoting economic growth in Japan was certainly _not_ the primary goal of the Shoup Commission. Yet the Shoup Commission continues to influence influential Japanese tax specialists who were trained in this early postwar American tradition. 



**1975–87: Bracket Creep and Public Works**



In 1971–73, the U.S. devalued the dollar, pursued an inflationary money policy, and tried to disguise the consequences with price controls. When the dollar goes down, commodities priced in dollars go up. By the fall of 1972, commodity futures prices had already begun to soar, with oil a relative laggard. The end result was the stagflationary swamp of 1974. Japan was an innocent victim. 



Although the event was temporary, it had a lasting impact on Japan’s economic _policies._ Japan imposed a corporate surtax in April of 1972 and stopped cutting individual tax rates after 1974, thus allowing inflation, aging and economic growth to push more and more taxpayers into higher tax brackets. There was a major shift in emphasis away from fostering _private_ investment toward “social overhead capital” and “infrastructure improvement.”(12) In the quaint language that economists used at the time, endless bracket creep would supposedly generate so much revenue that public works spending would be needed to prevent “fiscal drag.” 



**Figure 2** illustrates the main reason why seemingly high marginal tax rates of 40–70% had not done much damage before 1974. The income thresholds for the highest tax brackets were repeatedly increased by huge amounts, much more than enough to keep far ahead of inflation and rising real incomes. 



From 1975 to 1984, by contrast, there were no adjustments of tax thresholds at a time when inflation averaged more than 6% a year. The resulting bracket creep appeared to generate a lot of revenue, but this was partly money illusion. It was not until 1979 that real, inflation‐​adjusted revenue was again as high as it had been in 1974. Revenues did rise as a percentage of GDP, but that would not have happened if real GDP had not slowed. Whatever its long‐​term effect on revenues, bracket creep certainly generated more and more tax distortions and disincentives. 



In 1984, there was a modest increase in the threshold for the 60% rate, but also an increase in the corporate tax rate. In fiscal 1987, the 60% rate was reduced to 55% and the 65–70% rates to 60%. That was temporarily helpful, contributing to a brief spurt of growth in the economy and in tax receipts. 



In April 1989, national tax rates above 50% were ended. But a provision that kept total national and local taxes from exceeding 78% had been eliminated in 1987, leaving combined national and local tax rates as high as 76% even in 1992. The value‐​added tax was also introduced in 1989, raising marginal rates by three percentage points at all income levels. 



**Figure 2** shows that even as recently as 1993, the 40% national tax rate still applied to the same _nominal_ income at which a 42% rate had applied back in 1974. _If tax thresholds had merely been adjusted for consumer price inflation from 1974 to 1993, not for real wage gains, they should have more than doubled in terms of yen_! The latest threshold adjustment finally came close to making up for past inflation with respect to the 50% bracket, but is still inadequate at the 40% rate. All things considered, there has been surprisingly little relief from the highest, most destructive tax rates on individual income, despite appearances to the contrary. 



Japan has been quite unique in this respect. Between 1979 and 1986, many countries had cut their highest income tax rates in half — including the United States, United Kingdom, South Korea, and Singapore. And no country that cut tax rates in half suffered any sustained revenue loss, even as a percentage of GDP. It is not even true that lowering the highest U.S. tax rate from 50% to 28–33% in 1986 was financed by eliminating deductions. Fewer itemized deductions were replaced with a larger standard deduction, but total deductions were not any smaller. Taxable incomes reported by higher‐​income people were “surprisingly” strong after tax rates came down, and labor force participation increased sharply among their spouses. 



**Social Security**



As bracket creep was pushing middle‐​aged Japanese professionals and mid‐​level managers into tax brackets once intended for the very rich, the burden of “contributions” for Social Security pensions also doubled from 6.2% in 1970 to 12.4% in 1986, and to 14.3% more recently.(13) The entire Social Security tax burden, including public health insurance, reached 25.5% of payroll by 1996. Most of this must be added to _marginal_ tax rates on labor income because, unlike the U.S., there is no maximum contribution to eliminate the _marginal_ burden at high incomes. It is the deadly combination of income tax, payroll tax and VAT that matters, at the margin. 



The fact that employees can deduct Social Security taxes from their income tax base is modestly helpful (only employers can deduct payroll taxes in the U.S.). But neutral taxation of savings requires that if contributions are deductible when going into a pension fund, then the funds must be fully taxable when they are later withdrawn. This is the principle behind the original Individual Retirement Account in the U.S. 



If contributions to public or private pensions were _not_ deductible, then income going into a pension fund would have already been taxed before it was saved. In that case, withdrawals from the pensions should _not_ be taxed a second time, when the money is taken out. This is the principle behind the new Roth retirement accounts in the U.S. 



Either of these _neutral_ treatments of saving would be equivalent to a “consumed income” tax, if applied uniformly without restrictions (such labels are misleading, however, since _all_ taxes fall on the individual owners of factors of production). Such a policy had long been advocated by British economists (Mill, Marshall, Pigou, Kaldor), and by Irving Fisher of Yale. It is in marked contrast with the Haig‐​Simons concept of “comprehensive” income taxation that inspired Shoup Commission plans. When older economists, in the Haig‐​Simons tradition, speak of “broadening the tax base,” they often mean defining income in ways that ensure that savings will be taxed several times. Some even refer to corporate depreciation as a “tax preference,” as though the cost of plant and equipment was not a cost at all, but taxable income. Today, younger U.S. specialists in public economics have moved away from these Haig‐​Simons ideas that were so fashionable fifty years ago. Most favor neutral tax treatment of saved income, and prefer immediate expensing of plant and equipment. 



Japan’s system of fully deducting contributions to (public) pensions _but not treating_ pensions as taxable income is not consistent with neutral treatment of savings. To deduct contributions and also exempt withdrawals is _too generous_ toward this specific form of savings (Social Security). Yet Japan’s tax policy after 1989 moved back toward multiple levels of taxes on all other forms of savings — capital gains, dividends and interest income. A policy of tax neutrality for _all_ savings, or at least for all _retirement_ savings, would greatly ease the fiscal strains expected from an aging population. Neutrality requires taxing income from public pensions exactly like any other income (because contributions were deducted), even if pretax benefits have to be increased to sweeten the deal.(14) Applying that same principle to _private_ pensions (deductible going into a pension plan and taxable coming out, or vice‐​versa) would encourage greater use of private retirement plans and thus ease the excessive dependence on Social Security pensions. This would be a start toward partial or full “privatization” of pensions — something that should never be a state _monopoly._



Because incomes generally rise with seniority, tax burdens tend to be extremely heavy at ages 45–57, then fall sharply at older ages due to the dubious exemption of pension income. Since Japan is aging fast, the combination of superhigh taxes on older workers and none on pensions must push many people into early retirement, whether they like it or not. 



**Different Policies; Different Results**



Before 1975, tax policy greatly reduced effective marginal tax rates and eased the multiple taxation of saved income. Economic growth in Japan ( **Figure 3** ) averaged 9.6% a year from 1952 to 1973. 



From 1975 to 1987, “bracket creep” and higher Social Security taxes reversed much of the previous progress on marginal tax rates. Economic growth slowed to 4.3% from 1975 to 1991. 



After 1989, tax policy also _reversed_ much of the previous progress toward neutral treatment of savings. Tax rates on new capital investments increased (at the level of individual investors). Economic growth slowed to 1.2% from 1992 to 1997. To continue blaming this on the “oil shocks” of the 1970s, as many do, is no longer plausible.(15) Oil has been very cheap for more than a dozen years. 



A large increase in the marginal cost of oil can indeed make production of many goods unprofitable. Growth stalls. An increase in the marginal cost of labor or capital can have the same depressing effect. An increase in the marginal cost of government is no different. It reduces the (after‐​tax) return on investments in physical and human capital — the primary source of economic growth. 



Although the dramatic slowdown of economic growth after 1974 coincided with an equally dramatic change in tax and spending policies, that change in economic policies is rarely blamed for the change in economic results. From 1989 to 1992, Japan added more taxes on sales, land, capital gains, dividends and interest. Yet the dramatic deterioration in economic growth after 1990 is rarely blamed, even in part, on those simultaneous changes in tax policy. The sole exception was the increased VAT of April 1997. Even in that case, however, complaints that this particular tax increase hurt the economy are not often translated into the logical conclusion that rolling‐​back such a counterproductive tax increase must likewise _help_ the economy. 



**Figure 4** shows OECD estimates of _average_ effective tax rates on capital and labor in the U.S. and Japan.(16) Before 1985, Japan had much lower tax rates on capital than the U.S. did. Since then, that situation has been reversed — _Japan is now more hostile to capital_. Little wonder that Japan’s domestic investment is weak, and capital flows out. 



It is often said that because Japan’s savings exceed domestic investment, the answer is to use tax policy to reduce savings (adding and increasing the VAT on consumption was therefore an odd choice, even from this strangely contractionary point of view). A much better alternative is to roll back some of the recent tax impediments to domestic investment. 



_Average_ tax rates on labor were still relatively low in Japan over the 1985–95 period as a whole. But the opposite is true of _marginal_ tax rates on highly skilled salaried people, which are extremely high in Japan. As a practical matter, the complaint that salaried people are more heavily taxed than small business owners, farmers and politicians can only be ameliorated by reducing the _marginal_ burden on salaries. 



Rising marginal tax rates on labor and capital are certainly not Japan’s _only_ problem. Monetary policy also made an unsettling shift between extremes between 1988 and 1991. Excessive regulation of finance and commerce is another unnecessary obstacle to economic progress. But the likelihood that changes in the _microeconomic incentives_ of tax policy may account for a large part of Japan’s longer‐​term economic slowdown deserves more serious attention than it has been getting. This is _not_ about tax revenues (which are terribly weak). It is about _incentives._



**“Tax Reform” Took a Wrong Turn**



Some Japanese tax specialists really believe the Shoup Commission designed a system that was “pure” in some theological sense. It does not work in practice, but it looks beautiful in theory. Such students of Shoup missionaries must therefore regard the _annual tax cuts_ of 1950–74 as a horrible mistake — a deviation from the “comprehensive” (yet arbitrary) Haig‐​Simons definition of taxable income. Hiromitsu Ishi, for example, recently urged that _“reform should achieve a return to the Shoup proposals.”_ Indeed, that is exactly the direction that Japan has taken since 1988–89 — heading back toward Occupation austerity policies in the name of “tax reform.” 



The Shoup Commission advocated a value‐​added tax, and urged that income taxes be applied to dividends, interest and capital gains. From 1989 to 1992, “tax reform” in Japan was almost _defined_ as adding a value‐​added tax and adding income taxes on dividends, interest and capital gains. There was also a curious fascination with the _number_ of tax brackets (which is irrelevant), but too little attention among academic economists to the uncompetitive _height_ of marginal tax rates, and to the declining real income thresholds at which they were applied.(17)



 **Figure 4** showed that Japan’s taxes on capital have become much heavier since all these “tax reforms” were adopted. In one respect, this may seem paradoxical. From 1988 to 1990, the statutory tax on (retained) corporate earnings was reduced from 42% to 37.5%, at the national level. But the corporate tax on earnings paid out as dividends was simultaneously increased from 32% to 37.5%. The net effect left the effective corporate tax virtually unchanged.(18) Although the _national_ corporate tax rate of 37.5% does not appear to be much higher than the U.S. rate, local taxes on corporate profits are much higher in Japan. 



The main reason that Japan’s tax on capital increased, however, was the new taxes on interest income and realized capital gains of individual investors. After April 1988, individuals who supplied debt capital to businesses (but not to housing) were subjected to a new 20% withholding tax on interest income. A year later, individuals who supplied equity capital to corporations were also subjected to national and local taxes of 26% on capital gains. Although these taxes are collected from individuals, the increased tax wedge raises the cost of capital to businesses. 



**Punishing Efficient Uses of Land**



The 1992 land tax is another new tax on capital, but one designed to achieve a specific purpose. Ishi describes the land tax as “an attempt to seek an effective policy with respect to reducing land prices.” Unfortunately, the Bank of Japan had the same goal. If inflicting windfall losses on landowners is a legitimate policy objective, then these policies were extremely effective. 



Land had been a very important asset behind Japan’s stocks, so deflating land prices deflated stock prices too. The addition of taxes on stockholder capital gains was also bound to be capitalized in lower stock prices. Land and stock were collateral behind many loans, so the goal of “reducing land prices” continues to have unpleasant repercussions on banks and credit. 



The actual problem is that capital gains taxes on land _sales_ can be _extremely_ high, while property taxes on land _ownership_ are very low, particularly for farms. The net effect is a powerful “lock in” effect that discourages property sales, and discourages efficient use of a valuable resource. Adding another tax on large business land holdings did nothing to fix this problem, because it continued to impose the lowest tax on the least efficient uses of land (urban farmland) while adding a discriminatory tax on the most efficient uses (big business). The real problem continues to be the prohibitive capital gains tax. Henry George made an overly enthusiastic theoretical case for taxing the _appreciation_ of unimproved land. But the only practical way of doing that is to tax _realized_ capital gains land _transactions._ Since any such _transactions_ tax is easily avoided by _not selling_ , changing land ownership toward more efficient uses (a process _facilitated_ by “speculation”) is thwarted by confiscatory taxes on this particular source of capital gain. Capital gains on land _transactions_ should surely not be taxed at a higher rate than gains on financial claims to land (which is largely what many corporate stocks represent). Also, higher capital gains tax rates on assets held for short periods do not make economic sense for _any_ asset, except perhaps as a very crude way of indexing for inflation. In short, the capital gains tax on land is far too high, and the new land tax is much less efficient than raising the broader property tax. 



******High Rates, Low Revenues**



There are usually two obstacles to reducing excessive tax rates. One is the belief that marginal tax rates of 50% or more actually raise substantial revenue. We have indicated before (in **Figure 1** ) that high individual income tax rates are normally associated with relatively _low_ tax revenues, and with slow growth of revenues. We also noted that several countries which slashed their highest tax rates to 28–40% in the 1980s suffered no revenue losses.



Despite our earlier warnings about expressing tax revenues as a percentage of GDP (rather than as real growth over time), **Figure 5** shows that revenues from Japan’s Social Security tax increased from 6% of GDP in 1975 to 10.4% in 1995. In the same period, revenues from all other taxes increased more modestly, from 14.9% to 18.1% of GDP. In fact, revenues were no higher in 1995 than they had been in 1980, despite 15 years of bracket creep, a new VAT, and new taxes on interest income, capital gains, and land. 





**Figure 6** takes a closer look at the nineties. It shows that receipts from individual income taxes declined by 22% from 1990 to 1995. Corporate tax receipts fell even more, thanks to weak profits. 



In the nineties, Social Security has been the _only_ significant source of added revenue. All other sources of tax revenue dropped to 18.1% of GDP in 1994–95, down from 22.2% in 1990. That actually understates the problem, because there was also very little growth of GDP. 



The prolonged downward trend of income tax revenues after 1990 was certainly not due to any “tax cuts” during these years. On the contrary, 1989 is when the biggest effort to _increase_ taxes began. 



Receipts from the VAT have been almost flat and rather small — about 1.5% of GDP. It is a common mistake to regard revenues from a value‐​added tax as a net addition to total revenues. Any variety of sales tax must _reduce sales_ , and therefore reduce personal and corporate incomes that would otherwise have been generated in producing and selling goods and services that are no longer marketable (because the VAT has raised their prices). Whether the increased revenues from VAT exceed the lost revenues from incom ****e taxes is an empirical question.



 **Figure 7** switches to a long‐​run picture of revenues from both income taxes (corporate and individual) and the VAT in real terms, adjusted for inflation. Together, Figures 5 to 7 hammer home a simple point: _Japan’s total tax revenues have declined in real terms ever since the VAT and various investor taxes were introduced._ Without the increase in Social Security tax, which depends on it remaining attractive for employers to employ and for workers to work, the budget would be in much more serious shape than it is. All these ambitious new taxes have been killing revenues. 



If taxes were measured solely by their revenue yield, as macroeconomists tend to do, then Japan’s numerous and painful new taxes would look like a “tax cut.” Such falling revenues from rising taxes might be a run of bad luck. But Canada’s experience suggests otherwise. After Canada added a VAT in 1990, revenues from all taxes virtually stopped growing. Revenues rose by 19% from 1990 to 1995 (only 1.2% if measured in U.S. dollars), compared with a 52% rise from 1985 to 1990, and 59% from 1980 to 1985. 



Japan’s subtraction‐​method VAT (with exemptions for small firms, and for some important services) is easy to evade. Such a tax will never raise much money. Higher rates will just produce more evasion, and that evasion will result in greatly reduced _income and Social Security_ tax receipts. It would be easier and more effective to allow prefectural and municipal governments to adopt simple _retail sales taxes_ , preferably at rates of their own choosing, in exchange for lower local income tax rates. 



When a large package of new taxes is followed by eight years of economic stagnation and falling government revenues, it is time to consider the possibility that some of those tax policies were a mistake. There is nothing wrong with admitting mistakes and then fixing them. 



**Income Leveling**



Aside from revenue anxieties, the other major obstacle to any constructive policy change, in both the U.S. and Japan, is the stubborn notion that tax policy can and should “redistribute income.” 



Taxes do not redistribute income; they just _reduce_ income. If less real income is produced, there is less to distribute. 



High marginal tax rates on capital must make capital more scarce and therefore _more valuable_. Pretax returns to capital rise to adjust for the tax (in a world of mobile capital, after‐​tax returns cannot possibly remain below the global norm). With less capital per worker, however, there will be less real output per worker, and therefore less real income per worker. Labor thus ends up bearing the burden of taxes ostensibly aimed at affluent owners of capital.(19)



A steeply progressive tax on _labor_ income is mainly a tax on the returns to investments in higher education. This tax makes human capital more scarce than otherwise, and therefore more valuable. Salaries of highly skilled people will command a larger premium (or they will emigrate until that happens). Consumers end up paying this tax, because they must pay more for the artificially scarce services of highly skilled professionals and managers, directly or indirectly. 



Distribution tables, which purport to show how various income groups will fare under different tax policies, involve hopelessly static, zero‐​sum, partial equilibrium incidence assumptions.(20) The first step toward meaningful tax reform is to discard these meaningless statistical exercises. 



**Minimal First Steps**



It would be wonderful to see Japan embrace some sort of fundamental tax reform, perhaps borrowing ideas from Hong Kong or Singapore, but this might take more time than the situation can afford. In the meantime, there are many very constructive steps that could be taken immediately. 



1\. The highest individual income tax rate should not exceed 40% at the national level. The threshold for the 30% rate should be raised too. 



2\. The effective corporate tax should also be reduced to no more than 40% (including the enterprise tax) through some combination of lower rates and more rapid depreciation. 



3\. The VAT could be rolled‐​back to 3% for _at least_ two years (announcing a return to the 5% rate would shift buying plans forward in time, risking another slump after the increase took effect). 



4\. The securities transactions tax should be abolished _immediately_. Phasing it out would provide a risky incentive to delay stock transactions until 1999.(21)



There is much more to do, of course, and many possible ways by which to do it. The Japan Research Institute, among others, has offered several worthy suggestions.(22) The essential point is that marginal tax rates on capital and human capital are much too high in Japan, sapping the entrepreneurial vitality of the economy. The highest tax rates do the most damage to the economy in return for the least revenue. There is little risk in being bold, and great danger in being too timid. 



Economic growth requires more and better capital, including human capital. All taxes fall on individual suppliers of labor and capital, including taxes ostensibly levied on corporations or consumption. Even consumption taxes are really production taxes. Taxes on a company’s stockholders, workers and consumers hurt business, and taxes on business hurt stockholders, workers and consumers. Excessive tax rates on capital hurt labor by reducing investment and therefore slowing the growth or real output and income per hour of work. Demoralizing tax rates on labor likewise hurt capital by raising reservation wages, shortening lifetime work hours, and reducing the intensity and quality of work. 



If Japan continues to embrace the tax and spending policies of Continental Europe and Scandanavia, nobody should be surprised if economic performance becomes as disappointing as it has been in those areas. Without more vigorous economic growth, Japan’s future budget problems could become far more difficult. Philosophers are free to debate “equity” all they like. But the serious question to ask about the structure of tax incentives is the question that was at the top of Japan’s list in the 1950s: “ _How will this tax proposal help economic growth_?” An economy that is taxed into oblivion will not help anyone — not the poor, and not even the politicians. 



* * * * *   
**Appendix: Money Matters**  
  




Macroeconomics is concerned with the short‐​term growth of aggregate demand, or _nominal_ GDP. Microeconomics is concerned with longer‐​term incentives to expand aggregate supply, or _real_ GDP. That distinction led to the 1976 phrase “supply‐​side” economics — meaning the application of microeconomics to macroeconomic problems. The “demand side” was not neglected, however, but was properly assigned to the central bank. 



The Bank of Japan pursued a very expansionary monetary policy during the so‐​called “bubble” period, and an extremely restrictive monetary policy since 1991. From 1987 to 1989, reserve money grew by 11.5% a year, and broad money (M2+CDs) by 10.9%. **As Figure 8** shows, this expansive monetary policy financed growth of _nominal_ GDP of more than 7% a year from 1988 through 1990. 



In 1991–92, the monetary base was actually _reduced_ by 2.8% a year, which was quite remarkable. Broad money then grew at only a 1.2% rate. Growth of nominal GDP slowed to 2.8% in 1992 and to less than 1% from 1993 to 1995. Consumer prices have been _falling_ lately, aside from the one‐​time effect of the increased VAT in April 1997. 



The conventional wisdom is that monetary policy is impotent in Japan — merely “pushing on a string” — because nominal interest rates are very low. That is exactly what was said about the Federal Reserve from 1930 to 1933. It was dangerously wrong then, and still is. Interest rates are high in Turkey because the central bank prints too much money. Interest rates are low in Japan for the opposite reason. 



In a deflationary situation, shaky banks naturally want to hold more reserves, and people want to hoard more currency. The central bank has to accommodate those liquidity demands before additional bank reserves and currency can have any “reflationary” effect. If the central bank fails to convert enough securities into cash, through the discount window and open market purchases, then people have to liquidate assets and inventories to get cash. To stop such a deflation, the Bank of Japan merely has to purchases as many domestic or foreign securities as necessary, and discount freely (i.e., without rationing access to the discount window) at a penalty rate. 









**NOTES**



1\. William Niskanen writes of “the residual Keynesian perspective of many older economists, based on a theory — without evidence — that government deficits increase total demand.” — “Myths About the 1980s,” _The Wall Street Journal_ , November 5, 1996. 



2\. In his 1852 critique of Louis Napoleon’s “hot house” economics, even Karl Marx understood that “public works increase the obligations of the people in respect of taxes.” Indeed, debt service now accounts for 22% of Japan’s national budget, despite the lowest interest rates in world history. 



3\. When the United Kingdom first introduced a 10% VAT in April 1973, this was promptly followed by two full years of recession in 1974–75. The VAT was increased to 15% in June 1979, followed by another two years of recession in 1980–81. 



4\. “The problem is that analysts use tax revenue, not tax rates … When households evade a high tax, they drive down tax revenue, and so the high‐​tax experiment is less noticeable in the data.” — William Easterly’s comment in _Brookings Papers on Economic Activity_ , 1995:2, p. 421. 



5\. See Alan Reynolds, “Tax Cuts Will Restore the Tigers’ Roar,” _The Wall Street Journal_ , March 17, 1998. 



Also, Reinhard B. Koester & Roger C. Kormendi, ” Taxation, Aggregate Activity and Economic Growth: Cross‐​Country Evidence on Some Supply‐​Side Hypotheses” _Economic Inquiry_ , July 1989, pp. 367–86. 



6\. “By 1956 the total number of special [tax] measures exceeded fifty because the government was very active in the promotion of economic growth through tax devices.” Keimei Kaizuka, “The Tax System and Economic Development in Japan,” in Richard A Musgrave, Ching‐​huei Chang & John Riew, eds., _Taxation and Economic Development Among Pacific Asian Countries_ , Westview Press, 1994, p.55 



7\. “In 1950, a drastic change was enforced to make the income tax less progressive than it was under the influence of the Shoup proposals.… The treatment of savings or investment income [became] almost the same as that which would be applied to all savings under and expenditure tax.… However, this hybrid developed spontaneously, without any special attempt to avoid the double taxation of savings.” Hiromitsu Ishi, _The Japanese Tax System,_ Clarendon Press, 1993, pp. 86 & 97\. 



8\. Jerome B. Cohen, _Japan’s Postwar Economy_ , Indiana University Press, 1958, p. 107. 



9\. Martin Bronfenbrenner, “Economic Miracles and Japan’s Income‐​Doubling Plan” in William W. Lockwood, ed., _The State and Economic Enterprise in Japan_ , Princeton University Press, 1964, pp. 536n & 551–52. A more perceptive essay by Hugh Patrick of Yale University attributed Japan’s vigorous growth to continual “tax rate cuts,” but even Professor Patrick saw Japan as careening “from one balance of payments crisis to another.” 



10\. Henry C. Simons, selection from _Personal Income Taxation_ (1938) reprinted in H.C. Harlan, ed., _Readings in Economics and Politics_ , Oxford University, 1961, p. 303. Simons’ influential 1948 book, _A Positive Program for Laissez Faire,_ also advocated breaking‐​up large enterprises, which was almost adopted in extreme form by Occupation officials until a properly alarmed U.S. Congress stopped them. 



11\. Referring to Shoup, Vickrey, Pechman and others, Musgrave captured the zeal with which that former generation of tax missionaries spread their gospel: “The comprehensive income tax base thus became the banner of tax reform in the United States, designed to . . provide a global base on which progressive rates could be assessed… This movement … provided the focus of analysis and delight for a generation of tax economists in the United States.” R. A. Musgrave, “A Brief History of Fiscal Doctrine,” in A. Auerbach & M. Feldstein, eds., _Handbook of Public Economics_ , Elsevier Science, 1985, Vol. 1, p. 22. 



12\. Government investment, including “the pump‐​priming function of public finance,” was the main theme of former Prime Minister Kakuei Tanaka, _Building A New Japan_ , The Simul Press, 1972, p. 207. 



13\. Yukio Noguchi, “Tax Reform Debates in Japan,” in Michael J. Boskin & Charles E. McClure, eds., _World Tax Reform_ , International Center for Economic Growth, 1990, p. 114. 



14\. “A scheme that subjects the old to global income taxation would be superior to simply using the consumption tax.” — Maria S. Gochoco, comment on Yukio Noguchi, “Aging of Population, Social Security and Tax Reform,” in Taktoshi Ito & Anne O. Krueger, eds., _The Political Economy of Tax Reform_ , University of Chicago, 1992, p. 232, 



15\. Ishi, _op. cit_., p. 54: “What are the main causes for the sharp rise of fiscal deficits since 1973? … First, there was a conspicuous slowdown of Japanese economic growth cause by the two oil crises.” 



16\. Willi Leibfritz, John Thornton & Alexandra Bibbee, “Taxation and Economic Performance,” OECD Working Paper No. 176, 1997, p. 50. 



17\. Unlike leading groups of academic and think tank economists, who advocated leaving the top _national_ tax rate at 50–60% (while also taxing much more of investment income), Japan’s Committee for Economic Development, a business group, made a relatively bold proposal in January 1986 that the _combined_ national and local income tax rate (then 78%) should not exceed 50%. Even the major trade unions advocated reducing progression. M. Homma, T. Maeda & K. Hashimoto, “Japan,” in Joseph A. Pechman, ed., Comparative Tax Systems, Tax Analysts, 1987, pp. 429–32. 



18\. Toshiaki Tachibanaki & Tatsuya Kikutani, “Japan” in Dale W. Jorgenson & Ralph Landau, eds., _Tax Reform and the Cost of Capital_ , Brookings Institution, 1993, p. 262. 



19\. This modern “general equilibrium” analysis of tax incidence is often associated with Joseph Stiglitz, _Economics of The Public Sector_ , Norton, 1988, pp.430–32. But it was well understood by classical, pre‐​Keynesian economists. Harvard’s Sumner H. Slichter, _Modern Economic Society_ , Henry Holt, 1929, p. 743: “To the extent that a tax on capital retards the increase in the supply of capital, it enables capitalists to obtain a higher return on their funds and falls, therefore on others [consumers and wage earners].” 



20\. David F. Bradford, ed., _Distributional Analysis of Tax Policy_ , American Enterprise Institute, 1995. 



21\. There is no legitimate reason to restrict corporate share repurchases, and therefore no reason for making the easing of such restrictions temporary, as has been proposed. Share repurchases create capital gains, which will generate tax revenue and strengthen loan collateral. If the reason for the restriction on repurchases has been to foster dividend payouts, that would be better accomplished by restoring some relief from double‐​taxation of dividends. 



22\. _Japan Research Quarterly_ , Winter 1997/98. 
"
"
Share this...FacebookTwitterAlso the Danish Meteorological Institute (DMI) projects a sturdy Arctic sea ice extent for this July, meaning no falling summer ice extent trend since 2007! The climate alarms are being muffled. 
Snowfan here gives us the latest on global mean temperature and Arctic sea ice.
After the year’s low in June 2020, with an anomaly of +0.48°C from the 1981-2010 WMO climate mean, the global 2-meter temperatures (black line) depicted below shows the July 16, 2020 analysis and forecast up to July 23.

Source: here
Both the anomalies of the global 2-meter temperatures from the WMO mean (black line) and especially the temperatures on the SH (blue line) continue to fall, with the deviations on the SH repeatedly falling below the zero line. This also pulls the global temperatures (black line) down to near zero in the forecast.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




But also the temperatures in the Northern Hemisphere (red line) have had a falling trend since the end of February 2020, having since reached a new annual low. There has been no more global warming since 2016. Note: With 81% of the sea surface, the southern hemisphere has the largest energy storage on earth.
Surprise DMI projection
Arctic sea ice trend growth in July 2020?

Source: DMI
A surprising DMI forecast was issued on July 14, 2020 which projects strong growth of Arctic sea ice areas for July 2020. If this expert forecast is correct, it would mean there’s been a strongly positive summer trend since 2007 – instead of the ridiculous Al Gore complete meltdown.


		jQuery(document).ready(function(){
			jQuery('#dd_9c06936df01f592ca3b87782180bf27a').on('change', function() {
			  jQuery('#amount_9c06936df01f592ca3b87782180bf27a').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn the early 1900s, the globally-averaged distribution of calculated surface temperature estimates ranged between 14 and 15°C. For 1991-2018, HadCRUT, Berkeley, and NASA GISS also estimate today’s global temperature is about 14.5°C.
Scientists estimating Earth’s surface temperature has been an ongoing pursuit since the early 19th century.
A new study (Kramm et al., 2020) suggests the generally agreed-upon global temperature from 1877 to 1913 from dozens of calculated results was about 14.4°C.
Problematically, HadCRUT, Berkley, and NASA GISS also indicate the 1991-2018 had a global surface temperature of about 14.5°C.
This would suggest there has been “no change in the globally averaged near-surface temperature over the past 100 years”.

Image Source: Kramm et al., 2020
Share this...FacebookTwitter "
"

Representatives of some 160 nations are gathered in Kyoto, Japan, this week to negotiate an international treaty to control emissions of greenhouse gases. While the summit has all the trappings of a substantive event, the gathering in Kyoto is more an exercise in public relations than in serious statecraft. Hot air, rather than cold reason, will dominate the conference and political sleight of hand will be its product. 



That’s because, according to the International Panel on Climate Change (the United Nation’s body of experts devoted to the study of global warming and known as the IPCC), even the most aggressive and costly proposals on the table this week would shave only a fraction of a degree off temperature increases projected by computer models for the year 2100. To achieve those emissions reductions, each American would have to pay an additional $1,000-$3,000 annually in higher energy prices. Such proposals would, according to Yale economist and sometime Clinton adviser William Nordhaus, take us back to the days of semipermanent energy crises like those of the 1970s. 



Both greenhouse alarmists and skeptics agree that actually preventing the global warming projected by computer models would require the world to reduce carbon dioxide emissions by 60–80 percent. Only by virtually abandoning the use of oil, gas and coal could we achieve such reductions. President Clinton’s assurances about “free lunch” climate change policies notwithstanding, nobody is proposing any real policy to prevent climate change because no one wants to usher in a permanent global depression. The idea, then, is to get the world to commit to a slow‐​motion control policy, one that would ease us into higher energy costs, a reordered industrial world and, as National Public Radio reporter Richard Harris puts it, “a whole new society” structured around less energy use.



But if the computer models are correct about global climate change (the data thus far are inconclusive), what choice do we have? Isn’t it prudent to hedge our bets with a control strategy now in order to avoid far more costly economic crash planning later? Well, no. All indications are that the “cure” for global warming is far worse than the “disease” of rising temperatures.



First, only about 2 percent of America’s economy is sensitive to weather conditions. No matter how ruinous climate change might be, it couldn’t possibly have a serious long‐​term impact on the United States. Even the most alarmist projections of ocean rise (about 3 feet or so) are trivial. If Amsterdam could figure out a way to hold back an even larger sea rise hundreds of years ago, it’s clear that a wealthier and more technologically advanced United States could counter a 3‐​foot rise. Foreign aid to help poorer countries adopt would be far less expensive than control policies.



Second, it’s not altogether clear that a warmer world would be a less habitable world. A temperature rise of 4.5 degrees Fahrenheit (the median computer‐​predicted result of a doubling of atmospheric carbon dioxide in the next 100 years) was exactly what occurred about a thousand years ago (A.D. 850 — 1300) in a period climatologists refer to as “the little climate optimum” (note that they don’t refer to it as “the little climate hell”). The result? A longer growing season, rapid economic development, a minor cultural renaissance, an expansion of fertile crop and forestland and a decrease in mortality rates. Since the data indicate that the small amount of warming we have detected over the last 100 years has largely been confined to winter evenings in the far northern latitudes, we have every reason — both empirical and theoretical — to believe that warming would be a benign, not a deleterious, event.



There are still open questions about how much if anything man has had to do with the slight amount of warming detected over the past 100 years and how much warming might eventually occur (the IPCC estimates range from insignificant to moderately significant). The IPCC report itself states that it will be another decade or so before scientists will know for certain. So why not wait? Nature magazine reported last year that waiting 20 years for better scientific information before acting will only cost us .36 degree Fahrenheit, at worst, over the next 100 years. 



In the face of this kind of uncertainty, the best “insurance policy” we could buy is one that increases the amount of wealth at society’s disposal to handle whatever problems might occur in the decades to come. Impoverishing society today to avoid a very uncertain problem tomorrow would harm, not help, future generations.
"
"
Share this...FacebookTwitterUPDATE: Here’s an even earlier version of the NASA GISS data plot of Hokitika station before all the data altering began (hat-tip Iggie). It shows temperatures had been COOLING:

Source: NASA
By Kirye
and Pierre Gosselin
We continue to hear warming horror stories coming from the island of New Zealand, and the socialist by sales pitch how “climate change is the biggest challenge of our time“.
Yet this doesn’t seem to be the case in New Zealand. For example, we learned from Electroverse here that the Pacific island country “just recorded its coldest June temperature in 5 years”.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Moreover, when we examine NASA GISS data, we uncover where all the warming rumors come from: alterations to the recorded historical data.
The following chart shows the data from Hokitika Aerodome, going back more 130 years (It’s the only NASA station that has data going back over 100 years). Plotted are the unadjusted Version 3 data and the Version 4 unadjusted:

Data source: NASA GISS V3 and V4
The old data set showed no warming, until NASA GISS went back and rewrote it Orwellian style, and made up a warming trend and called it Version 4.
Tony Heller also reported earlier: “NASA  didn’t like the fact that New Zealand wasn’t warming, so they simply changed the data.”
In summary: There really hasn’t been that much change at many locations around the globe. In fact the real changes are taking place in the NASA GISS datasets.


		jQuery(document).ready(function(){
			jQuery('#dd_2092e503990bc1bcda4ec06e5b01627d').on('change', function() {
			  jQuery('#amount_2092e503990bc1bcda4ec06e5b01627d').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"

As this year draws to a close, I think back about what I’ve accomplished on this blog in the last year, and it occurs to me that I have a lot of people to thank. It truly has been a team effort in a lot of ways, with many people contributing from many different angles to help make the work I’m doing a possibility.
First and foremost, I’d like to thank Steve Thompson of Assemblyman Rick Keene’s office. It was his mention in an email to me “that Russ Steele and I ought to get together” that started me on the path to study climate change from the data gathering aspect. Of course Russ and I had similar ideas, but we just didn’t know about each other, and knowing that there’s somebody else nearby that thought like I did whom I could converse with, was really a boost. Of course on the political front, I should also thank the local activist group “Esplande League”, because if they hadn’t worked so hard to keep me from being re-elected to the local school board, I never would have had the time to pursue this research.
I owe Russ Steele a lot, not only for the many stations he’s surveyed, and for the encouragement and support, but also for introducing my work to many people, including Steve McIntyre of Climate Audit. It wasn’t until Steve took notice that things really began to take off. Steve has been most gracious in helping to promote my work and for offering me the ability to co-author on his blog.
And there are many others, I can think of the many volunteers on surfacestations.org that have contributed many ideas, data sorting and spreadsheet macros that saved me time and effort, and made the project’s data analysis better. Gary Boden, Chris Dunn, Joel McDade, John Goetz, Barry Wise, and Eric Gamberg have all made significant contributions to the project via surveyed stations and or improvements to the survey process and analysis.
Super surveyor Don Kostuch, has been traveling the country and surveys new stations every week. He is leader of the station surveyors not only in terms of quantity, but of quality too. His surveys are always carefully done. 15 year old Kristen Byrnes and her dad have surveyed almost all of New England single handedly.
One volunteer, Arthur Edelstein, I owe a great deal to because he did some significant data capture and collation that I wouldn’t have been able to do myself in the fraction of time that he did it in.
I owe Dr. Roger Pielke Sr. a debt of gratitude for his faith in my work and his encouragement, along with his assistant, Dallas Staley, who has pulled many an obscure request for data or publications out of nowhere, even after hours.
Then there’s all the other blogs and newspaper authors out there that have promoted what I’m doing.  Joe D’Aleo of ICECAP comes to mind, and does Barry Hearn and Steve Milloy of JS for publishing my “How not to measure temperature” series, and Kate from Small Dead Animals for being a regular traffic driver.  There’s Evan Jones, who is my most prolific and enthusiast commenter, along with regulars George M., Papertiger, Larry Sheldon, and Stan Needham. Let’s not forget Steven Mosher and Jeez, for putting up with my silly rants at dinner with Mac at AGU. Jeez also footed the dinner bill, and so deserves double thanks.
Local blogger Lon Glazner deserves a nod for blogging some early support and for some mental stimulus on thermometers that got me fired up last spring.
In the newspaper realm, Ryan Olson of the local Chico Enterprise Record, not only for the stories he’s done, but for putting up with my complaints about Moveable Type and helping me migrate to WordPress where I’ve been able to make a better product.  I thank Bill Steigerwald of the Pittsburgh Tribune whose article launched me into national attention. And finally, Evan, who did a really balanced and fair article even though I feared the worst.
Then there’s the 300 plus volunteers for www.surfacestations.org Thank you each and every one.
I owe you all a debt of gratitude. Thank you. If I’ve missed anyone, don’t be shy about speaking up.
There’s a few that deserved coal this year, but I’ll leave them nameless.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea1ae9c6f',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"At the COP24 conference in Poland, countries are aiming to finalise the implementation plan for the 2015 Paris Agreement. The task has extra gravity in the wake of the recent IPCC report declaring that we have just 12 years to take the action needed to limit global warming to that infamous 1.5ᵒC target. Although the conference itself is open to selected state representatives only, many see the week as an opportunity to influence and define the climate action agenda for the coming year, with protests planned outside the conference halls. A crucial role of environmental activists is to shift the public discourse around climate change and to put pressure on state representatives to act boldly. COP24 offers a rare platform on which to drive a step change in the position of governments on climate change. However, many environmental movements in Europe are not offering the critical analysis and radical narratives needed to achieve a halt to climate change. 


      Read more:
      Extinction Rebellion : I'm an academic embracing direct action to stop climate change


 By now most people agree that greenhouse gas emissions (including CO₂)  are the proximate driver of climate change, and that climate change is not only a future problem, but is already causing significant environmental and social problems across the world. Further, the trend in global CO₂ emissions still appears to be increasing, driven largely by consumption in advanced and emerging economies. Economic growth measures the increase in the amount of goods and services produced by an economy over time, and it has historically been tightly coupled to CO₂ emissions. Decoupling these two factors is not impossible, and indeed many leading academics argue that the power of human ingenuity will solve the climate crisis. However, this is certainly unlikely in the timescales needed to tackle climate change in a just and equitable way. Practically, what this means is that as long as economic growth continues to expand rapidly and indefinitely, so too will the quantity of CO₂ in the atmosphere and the associated environmental and social impacts. To address climate change, therefore, we must address the root cause of this planetary ailment: the ideology of growth first, growth always. By moving away from growth-oriented societies in Europe and other advanced economies, towards ones that prioritise environmental and social health, we stand the slimmest chance of solving our climate crisis, while still allowing the poorest economies globally to meet their economic needs. Recent environmental movements demanding action on climate change, like the Extinction Rebellion in the UK and the Ende Gelande Alliance in Germany, don’t seem to take a clear stance on the role of economic growth in driving climate change. They don’t identify our unwavering commitment to the dogma of infinite economic growth as the driving force behind climate change, and as the reason that our efforts thus far have been impotent to stop the growing tidal wave of CO₂ emissions. In the UK, the Extinction Rebellion has captured the public’s attention and gathered widespread support and media coverage over the past few weeks, with their outraged cries for government action.  However, their demands are broad and unspecific, asking for “net zero [carbon emissions] by 2025”. They make no mention of how the UK government might achieve this, but link to other websites which offer potential routes for reaching this target. The sites suggested by the Extinction Rebellion promote ideas such as green growth and a green new deal. These ideas are founded on the premise that we can achieve both continually high rates of economic growth and reduce our impact on the planet. Sadly, the evidence (and a dash of common sense) tells us that this is not yet happening, and is unlikely to be possible in the near future. So what should groups like Extinction Rebellion do? It would currently be considered political madness to advocate for policies that might unintentionally, or intentionally, limit economic growth. Unfortunately, however, without a wider critique of the toxic relationship between climate change and economic growth, governments will be almost powerless to achieve any net zero targets they set. At COP24 environmental movements have an opportunity to use their platform to highlight the relationship between economic growth and environmental impact, and even to discuss radical alternative futures that are not dependent on a growth-based economy. Importantly, this doesn’t have to be considered a sacrifice. The relationship between economic growth and happiness in wealthy economies is at best complicated, and at worst nonexistent. This demonstrates the possibility of finding paths to climate stability that do not diminish our quality of life. By identifying the root cause of climate change, and our inability to address it, these groups can go further than demanding action. They can change public mindsets, put pressure on national governments and point to a shared way forward. Here, we have our best shot at limiting the damage of climate change in a meaningful and timely way."
"Australia “needs action on several fronts” following a catastrophic bushfire season, including leading international efforts against climate change and cutting emissions beyond the electricity sector, Julie Bishop has said. Bishop, the incoming chancellor of the Australian National University, made the comments to Guardian Australia, offering to put the university’s disaster management experts and more than 300 climate scientists at the federal government’s disposal to provide “evidence-based” responses to the bushfires.  The former foreign minister and deputy Liberal leader started the ANU role in January but has postponed an event marking her appointment as the university responds to the outbreak of coronavirus and extreme weather including bushfires in the Australian Capital Territory and damage from a hailstorm. Bishop said that “clearly there have been some missteps” in the federal government’s handling of the bushfires, adding she is “certain the government will reflect on recent events and learn from any missteps”. “I as chancellor … have offered to assist the federal government in its bushfire recovery response,” she said. Bishop said the university was preparing to provide expertise in disaster recovery, public health, biodiversity, engineering, and climate science. “ANU has climate change expertise, we have expertise in bushfire recovery, 300 climate scientists across seven colleges and 25 schools. “We have the climate change institute, headed up by Mark Howden who’s on the intergovernmental climate change panel. “As a national university we have a responsibility to the Australian community to deliver evidence-based solutions … to the myriad consequences from these catastrophic events.” The government has come under fire for its handling of climate change because the prime minister, Scott Morrison, has argued Australia contributes just 1.3% of global emissions, while lobbying to lower global ambition by including carryover credits in 2030 Paris targets. Liberal senator Jim Molan said on Monday his stance on climate change was not based on evidence, while the new deputy Nationals leader, David Littleproud, has explained he had professed doubt – but now accepts – climate science because he is not “gifted academically” and lacks a scientific background. Bishop praised Britain for being “ambitious and a leading voice in calling for greater standards to deal with climate change” after Boris Johnson urged major economies to go carbon neutral by 2050. “I’ve always been of the view that Australia, as a leading industrialised and developed nation, with one of the best standards of living in the world, needs to be a leader in the international response to climate change,” she said. “We have a responsibility. The extreme weather events, the horrific fires, that take such a terrible toll on our communities and wildlife place us at the frontline of the impact – and so Australia has a direct interest in leading international debate on this topic. “I certainly look forward to our government taking on that role.” Asked how Morrison should balance Nationals and Liberal conservatives wanting more coal-fired power with moderate Liberals’ calls to do more to fight global heating, Bishop responded that Morrison “doesn’t need my advice”. “We need action on several fronts: disaster response, including the resourcing of emergency fire services; climate change mitigation [and] adaptation; and reducing our own emissions is obviously vital – but we have to focus on all areas, not just the electricity sector,” she said. Despite Morrison claiming the government has set out how it will reduce emissions by 26% to 28% by 2030, critics have noted it is yet to set vehicle emissions standards or a plan to reduce emissions in the transport and agriculture sectors. Bishop backed the Morrison government on its handling of the coronavirus, despite criticism from Universities Australia that Australian Border Force had overreacted by reportedly detaining Chinese students returning to Australia after the travel ban. Bishop said she assumed all measures were taken after “consultation with national and international health bodies”. ANU, like many other universities, has offered flexible arrangements to help its students affected by virus-related travel bans including online delivery of courses, intensive courses and deferral without penalty. Bishop said she was “not aware of any evidence” that Australia’s relationship with China had slowed evacuations from Wuhan or had suffered as a result of travel bans. Bishop listed among other priorities for the ANU to equip students and graduates for the fourth industrial revolution and disruption of traditional work, and to gain greater international recognition for the university. Since retiring from politics at the 2019 election Bishop has also taken a role on the board of foreign aid contractor Palladium which she insists is not a breach of ministerial standards, which ban ministers lobbying on “any matters on which they have had official dealings” in the previous 18 months."
"Climate change, deforestation, widespread pollution and the sixth mass extinction of biodiversity all define living in our world today – an era that has come to be known as “the Anthropocene”. These crises are underpinned by production and consumption which greatly exceeds global ecological limits, but blame is far from evenly shared. The world’s 42 wealthiest people own as much as the poorest 3.7 billion, and they generate far greater environmental impacts. Some have therefore proposed using the term “Capitalocene” to describe this era of ecological devastation and growing inequality, reflecting capitalism’s logic of endless growth and the accumulation of wealth in fewer pockets. As social inequality and ecological breakdown escalate, steady change may no longer be enough to avoid civilisational collapse. Environmentalists cannot rely on timid appeals to power any longer. I’ve had the pleasure of getting to know radical environmentalists from numerous groups throughout my doctoral research. I’m especially interested in uncovering their worldviews – how they diagnose the root causes of ecological decline and what motivates them to engage in often high-risk interventions on behalf of the natural world and other species. They reject human superiority and separateness from other species. They blame such views, in addition to capitalism and endless economic growth, for the dire state of modern ecosystems. Many follow a burning desire for a more viable and inclusive future for all. Notable radical green groups include Earth First!, Extinction Rebellion, the Hambacher forest occupation, and Sea Shepherd. Early Earth First! activists in the US sat in trees and dismantled tractors to prevent old-growth forests from being felled. For years, Sea Shepherd vessels successfully intervened and protected countless whales from Japanese whalers in the Southern Ocean. However, last year they ended their anti-whaling campaign due to, among other things, advancements in military grade technology by the Japanese whaling industry. Activists have occupied the ancient Hambach forest in Western Germany for a remarkable six years in an ongoing effort to keep coal giant RWE at bay. Many were violently evicted by police recently. Traditional environmental organisations like the WWF tend to focus on making industrial capitalism more sustainable rather than questioning capitalism itself. The radical green movement was born in response to the perceived inability of these mainstream environmental organisations to curb ecological decline. They advocate direct action in the form of civil disobedience, blockades, tree-sits, and even the dismantling of machinery for halting ecological destruction. Criminalising and repressing non-violent activists could fatally delay an effective response to climate change. In the UK, anti-fracking activists were arrested recently after blocking a convoy delivering equipment to the Preston New Road fracking site in Lancashire. They were initially given excessive prison sentences but were eventually released. Political theorist Steve Vanderheiden referred to such incidents in his 2005 article on the “Green Scare”. The “Green Scare” at its height in the mid-2000s saw the US government mount full-scale persecution of environmental activists. The FBI classed radical environmental groups such as the Earth Liberation Front as the nation’s lead domestic terrorist threat, even though it never targeted living beings.  Even the legal definition of “terrorism” was altered to include property destruction. This sought to target radical greens and their attacks against ecologically harmful infrastructure. Lengthy prison sentences and fines befell “eco-terrorists” caught engaging in direct action deemed threatening to economic interests. These are desperate times. We’ve lost a staggering 60% of monitored vertebrate life within just 40 years. Climate change will endanger millions through disease, extreme weather, starvation, and rising seas. Occupying trees or blockading a road to a fracking site is clearly justified resistance during times of widespread injustice. These are the ideas that environmental protectors are attempting to bring to the forefront. As George Monbiot noted, a “hopeless realism” in the form of piecemeal “tinkering around the edges” has led us to our present predicament. Similar approaches simply won’t fix the mess. Radical responses – direct action and mass political mobilising – might be our only hope for building the better world that is still within our reach."
"The UK aviation industry has pledged to cut its net carbon emissions to zero by 2050 – despite still planning for 70% more flights over the next three decades. Members of the Sustainable Aviation coalition, which includes most major airlines and airports, as well as aerospace manufacturers, will sign a commitment to reach net zero by mid-century. More than a third of the proposed net reduction will be achieved through offsetting.  A “decarbonisation road map” will be published outlining how aviation can cut its carbon footprint – replacing a previous road map that only committed the industry to halving emissions over the next three decades. The plan sets out potential reductions coming from smarter flight operations, and new aircraft and engine technology – including some yet to be invented. Modernising airspace and developing sustainable aviation fuels will also contribute to reducing pollution. About 25.8 million tonnes of CO2, out of 71.1 million tonnes set to be created annually by the UK sector, will need to be addressed through what Sustainable Aviation calls “market-based measures”, or offsetting. The coalition forecasts that sustainable jet fuels, which are yet to be employed commercially, could meet almost a third of UK’s aviation fuel demand by 2050. The transport secretary, Grant Shapps, described the commitment as a huge step forward in creating a greener future. He added: “Aviation has a crucial role to play in reducing carbon emissions, and with the help of new technologies, renewable fuels and our continued international cooperation … we’ll be able to strike that balance.” Neil Robinson, the chair of Sustainable Aviation, said: “Climate change is a clear and pressing issue for people, businesses and governments across the world. We know aviation emissions will increase if decisive action is not taken, and that’s why UK aviation today commits to achieving net zero carbon emissions by 2050, through an international approach, working with governments around the world and through the UN.” However, Greenpeace dismissed the move as “greenwash”. John Sauven, its UK executive director, said: “This whole strategy is a flight of fancy. Carbon offsetting is simply an excuse to carry on with business as usual while shifting the responsibility to cut emissions to someone else, somewhere else, and some other time. It’s greenwash pure and simple and ministers should be wary of lending it any credibility.” British Airways’ owner IAG has already committed to net zero carbon emissions by 2050, while easyJet has gone further by already offsetting all flights."
"
Surfacestations.org volunteer surveyor Russ Steele brings us this gem of a climate monitoring station from Panguitch, UT. I’ve seen stations over asphalt, such as the University of Arizona station in Tucson, but this one has a special feature; they made a concrete traffic island especially for the station so that it wouldn’t get collided with by nearby parked vehicles. How’s that for diligence? The station mount was set right into the concrete. So much for the 100 foot rule away from asphalt, concrete and buildings issued by NOAA

Click image for larger version
The station was recently closed, and the instruments and wooden portion of the shelter put into storage, which is why you don’t see any Stevenson Screen shelter in the picture above, only the mount. Since it’s permanently set into the concrete, they couldn’t easily remove it. Not well thought out, I’d say.
The GISS temperature plot has an offset just before the year 2000, care to bet when the concrete for the traffic island was poured?



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea2c58e84',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterIt didn’t receive much a attention in 2015, but a comprehensive Nature journal study of 0-2000 A.D. global sea surface temperatures shows 1) climate changes occurred more than twice as fast during the Little Ice Age (LIA) than since 1800, 2) the entire first millennium was >1 standard deviation (s.d. unit) warmer than today, and 3) 1800-2000 ocean changes amounted to just 0.08 of a s.d. unit per century.

Adapted Image Source: McGregor et al., 2015
There are several reasons to question the presentation of data in  McGregor et al., 2015. – a global-scale reconstruction of sea surface temperatures.
The myriad authors decided not to clearly depict actual temperature changes in their reconstruction, preferring instead to “reimagine” temperatures as standard deviation units.
The graphical presentation of “standardized SST [sea surface temperature] s.d. units” abruptly and curiously stops in 1900. This unexplained truncation was used despite mentioning in the body of the paper that the 1900-2000 period had a “statistically significant” warming trend of (just) 0.08 s.d. units/century – half of the century-scale changes during 1200-1400 and 1400-1600 (0.17 and 0.18 s.d. units/century, respectively). Perhaps the insignificance of the post-1900 uptick wasn’t considered helpful to the AGW (anthropogenic global warming) narrative.
The graphs depicting no remarkable modern global ocean temperature changes (shown below), such as the ones with flatline trends from the 1860s to 2000, are buried in the supplemental information for the paper, making the data and graphs less accessible. One would think that the lack of any remarkable or anomalous global temperature changes occurring during modern times would deserve some scientific attention.
Finally, this study shows the Roman Warm Period and Medieval Warm Period were globally warmer than today at the ocean surface (with some location and timing differences). It also affirms the LIA was “globally coherent.” The authors even identify the mechanism for “robust” LIA cooling: “high frequency explosive volcanism” with centennial-scale impacts.
At least the latter point made its way into the paper’s abstract…rather than hidden or buried.

Image Source: McGregor et al., 2015 and supplementary data for the paper
Share this...FacebookTwitter "
"
Share this...FacebookTwitterHat-tip: Die kalte Sonne
According to a new study, the expansion of offshore wind energy planned to date could lead to less electricity actually being produced at higher costs because, according to current planning, wind farms are taking the wind away from each other.
The researchers from the Technical University of Denmark in Roskilde and the Max Planck Institute for Biogeochemistry in Jena, Germany have investigated the topic. The study entitled “Making the Most of Offshore Wind” was commissioned by the Agora Energiewende and Agora Verkehrswende think tanks.
The report looks at that the question whether energy models used today by wind farm planners and investors can adequately capture the interaction effects between turbines stemming from very large areas covered with offshore wind farms at high installed capacity density.
Among the study’s key findings:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Offshore wind power needs sufficient space, as the full load operating time may otherwise shrink
from currently around 4,000 hours per year to between 3,000 and 3,300 hours. The more turbines
are installed in a region, the less efficient offshore wind production becomes due to a lack of wind
recovery. If Germany were to install 50 to 70 GW solely in the German Bight, the number of full-load
hours achieved by offshore wind farms would decrease considerably.”
Countries on the North and Baltic Seas should cooperate with a view to maximizing the wind yield
and full-load hours of their offshore wind farms. In order to maximize the efficiency and potential of
offshore wind, the planning and development of wind farms – as well as broader maritime spatial
planning – should be intelligently coordinated across national borders. This finding is relevant to
both the North and Baltic Seas. In addition, floating offshore wind farms could enable the creative
integration of deep waters into wind farm planning.”

Chart source: Study: “Making the Most of Offshore Wind“, Agora Energiewende and Agora Verkehrswende.
More unexpected costs, inefficiency
In a nutshell: a central pillar of the German and European transition to green energies threatens to become even more inefficient and more expensive than planned.


		jQuery(document).ready(function(){
			jQuery('#dd_75682c91c950f13c05f6eed99c42cb66').on('change', function() {
			  jQuery('#amount_75682c91c950f13c05f6eed99c42cb66').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"The Americans have a saying: “you break it, you own it”. In the world of climate diplomacy, the maxim is “you host it, you own it”. In Copenhagen in 2009, the Danes owned a disastrous climate event that broke up in rancour. In Paris in 2015, the French owned the successful agreement. The 2020 UN climate change conference, known as COP26, which will be taking place in Glasgow in November, could be Copenhagen or Paris, or somewhere in between. Ownership and responsibility will firmly rest with the government. The events of the past few days have proved beyond doubt, however, that we cannot leave it to the government alone. We all need to take ownership of this event.  In case you are not convinced, and feeling a bit inert, let me persuade you that this really matters: 2020 was the year nominated in the Paris agreement for when the world had to narrow the gap between its noble aspirations to limit global warming to 1.5C and its country-by-country commitments, which currently add up to, at best, 3C of warming. Given we only have a decade to decisively turn things around, we just cannot allow Glasgow to fail. This is a massive moment and the government has so far simply been unable to get to grips with the importance and the complexity of these negotiations, as illustrated by the fiasco over the appointment and sacking of Claire O’Neill, and the rather public – and so far fruitless – search for a president for COP26. However, it’s not just the government that needs to step up. Success or failure will in part depend on how much it is made to care about the issue. That depends on all of us. If the government thinks it can slink out of Glasgow without too much notice being taken, it may well decide other priorities are more important. We cannot let that happen. That means in practice, first, that the government must feel the pressure to act here at home. This summit is about persuading other countries to ratchet up their ambition. To succeed, we need to ratchet up ours and quickly. Britain has committed to net-zero carbon emissions by 2050 but currently our 2030 target does not reflect even that ambition. As we seek to persuade others to do more in the short term, we need a 2030 target of significantly greater ambition that puts us on track for net-zero by 2050. This more ambitious target must be accompanied by action in every sector, and a budget on 11 March that focuses on this issue, and includes a proper 10-year plan to decarbonise homes over the coming decade, while cutting bills and creating jobs. Second, crucial to the success of Glasgow is a strong alliance with the EU. Before Paris it was the US-China axis that made the crucial breakthrough. This time, with the US off the pitch under President Trump, the best hope is that the EU, which is responsible for 10% of global emissions, and China can act in concert to raise the level of ambition. Third, we have to recognise that every lever of government must be part of making this agreement happen, particularly around how public and private finance supports or thwarts the transition. That includes mobilising public and private finance for developing countries, ending international government support for fossil fuel extraction and building on the appointment of Mark Carney as the COP special envoy to ensure proper regulation of financial and corporate institutions around climate risk. Fourth, over and above actions by national governments, Glasgow must power forward coalitions of states, cities, businesses and civil society around the path to net-zero, including the phasing out of coal, and petrol and diesel vehicles, divestment from fossil fuels, and addressing deforestation. There are millions of people who care deeply about this issue in the UK and beyond. Extinction Rebellion and the pupil climate strikers have changed the terms of the debate over the past year. It’s up to all of us, including our brilliant NGOs, to ensure this moment sees the biggest mobilisation on the climate emergency in British history. You may wonder what the point of mobilisation is if the geopolitical forces are so badly aligned. The answer is there is no other option. The only way we will get change on this issue is showing government that there is a big political coalition that believes this really matters. Positive momentum from Glasgow is essential. We all need to step up. We all need to own it. Our future, and that of our children and grandchildren, is in the balance. Only by acting now can we prevent future disaster. • Ed Miliband is Labour MP for Doncaster North and a former climate change secretary"
nan
"
Share this...FacebookTwitter
German Coal Power Plants To Be Converted: To Burn Trees

Millions of trees to be shipped from around the world to Europe to be burned as “green coal”. Image cropped from “Planet of the Humans”
By Die kalte Sonne
(Translated/edited by P. Gosselin)
On May 2, 2020, we reported on the movie Burned. In the USA, the focus is on biomass.
However, they do not ferment fast-growing plants into gas as is the case in Europe, rather they cut down trees and burn them in power plants – often together with other things like car tires or soaked railway ties.
The issue is controversial because it is about pure ideology. Climate organisations such as 350.org, which in the USA is like Fridays For Future (FFF) in Europe, have given their blessing to this type of power generation.
The film Planet of the Humans by Michael Moore also denounces this.
Converting CO2 sinks instantly into atmospheric CO2
And so the USA is losing valuable carbon sinks and biotopes, destroying its environment and lying to itself about sustainability and the climate. A tree that takes 50 – 100 years to become big and stately, but then is burned up in a few minutes, can never have a favorable climate balance, no matter how you calculate it. Trees are the new coal, it seems.
But anyone who thinks that this is only done in the USA, where huge forests and thus carbon sinks are destroyed, is mistaken.
“Madness”: German coal plant to be converted to burn trees
The online daily Weserkurier reports on a coal-fired power station in Wilhelmshaven (North Germany) that is to be converted to burn wood. This made Germany’s most famous forester, Peter Wohlleben (book “The Secret Life of Trees“) flash with anger on Twitter.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Der Wahnsinn geht weiter: Obwohl hunderte Wissenschaftler vor der Holzverbrennung als Klimakiller warnen, setzen Politik und Wirtschaft in Deutschland auf Waldzerstörung und wollen Kohlekraftwerk umrüsten. https://t.co/gHJvNGi4YR @GrueneBundestag @SvenjaSchulze68 @spdbt
— Peter Wohlleben (@PeterWohlleben) June 13, 2020

 
Wohlleben’s tweet in English:
The madness continues: although hundreds of scientists are warning against burning wood as a climate killer, politics and industry in Germany are backing forest destruction and want to convert coal-fired power plants.”
What Wohlleben means by madness could be the statements of Social Democrat Party member of parliament Siemtje Möller. Her slogan on her own website: “Think about the climate too!”
“Green coal”
Siemtje Möller is already thinking ahead. After all, the Wilhelmshaven site could eventually also produce hydrogen with the green coal. The stimulus for the technology, worth billions of euros, which has just been ratified, should also come to Wilhelmshaven.
“I’d like a fair share here,” says the Siemtje Möller about the budget. In general, she sees the hydrogen initiative, the coal phase-out law and the structural transformation law as “a huge opportunity for the Northwest to enter the future”.
She calls trees “green coal” in all seriousness and then wants to use the energy from burnt trees to produce hydrogen. Does the federal hydrogen initiative mean something like that? Probably not. Destroying carbon sinks cannot possibly be a huge opportunity for the future.
Why does Ms. Möller take her own slogan so little seriously?

Share this...FacebookTwitter "
"
Share this...FacebookTwitterEvidence that temperature swings of ±17°C occurred during the end-Triassic mass extinction event imply that CO2 would have needed to increase 8- to 1,024-fold (3 to 10 doublings) to have induced that magnitude of temperature change. It didn’t.
Evidence from a new study (Petryshyn et al., 2020) suggests “repeated” temperature swings of 16-17°C occurred in Cotham Marble (CM, southwest United Kingdom) at the end of the Triassic epoch, when the worst extinction event of the last 500 million years occurred.
However, Petryshyn and colleagues acknowledge they “cannot resolve millennial-scale increases in temperatures in the region, implying that, at least locally, the initial extinction is not attributable to extreme warming.”
But even if the end-Triassic mass extinction (ETME) could be attributable to extreme warming, CO2 would be “implausible” as a mechanism.
According to models, CO2 increases up to 8 times the pre-industrial baseline (280 ppm) could only increase sea surface temperatures 5.4°C at most (Petryshyn et al., 2020). CO2 concentrations would need to increase up to 1,024-fold to elicit temperature changes reaching 16 or 17°C.
Therefore, “the initial onset of the biodiversity crisis may necessitate another mechanism.”

Image Source: Petryshyn et al., 2020
Share this...FacebookTwitter "
"

 **A Week at Cato University**



While many people took their summer vacations getting away from it all, more than 200 professionals, business people, college students, and retirees spent a week in early August exploring the ideas of liberty at the Cato University Summer Seminar. Held August 1–7 at Rancho Bernardo Inn, about 20 miles from San Diego, the program featured lectures and discussions on American history, law, economics, psychology, philosophy, and public policy.



In announcing the August seminar, Cato University director Tom G. Palmer said, “This program gives you the chance to recapture the intense intellectual atmosphere of your college days, in a climate where the lecturers and other participants share your fundamental ideas about freedom and justice. The schedule of lectures and discussions is designed to impart a great deal of information and analysis and encourage spirited discussion about the implications of the basic ideas.”



The faculty included some of the country’s most spirited and brightest defenders of liberty. Alan Charles Kors, professor of history at the University of Pennsylvania and coauthor of _The Shadow University_ , discussed the roots of liberty and the state of academia today. Randy Barnett, professor of law at Boston University and author of _The Structure of Liberty_ , gave a sneak preview of his forthcoming book during his talk “The Constitutional Presumption of Liberty.” (Excerpts of Barnett’s remarks are available on the September edition of CatoAudio.) Don Boudreaux, president of the Foundation for Economic Education, discussed the economics of law and the illogic of politics. Historian Paula Baker of the University of Pittsburgh discussed the growth of the American welfare state and American liberty in the 19th and 20th centuries. Guest lecturers included psychologist Nathaniel Branden, author of _Taking Responsibility_ , who examined liberty and responsibility from a psychological viewpoint, and philosopher Christina Hoff Sommers, author of _Who Stole Feminism?_ who discussed the way America has become “the republic of feelings.” Cato’s Edward H. Crane, David Boaz, Ted Galen Carpenter, Robert A. Levy, and Tom Palmer also spoke.



The attendees heaped glowing praise on the summer seminar. “The Cato University Summer Seminar was one of the most intellectually exciting times of my life,” said Kyle Larsen of Valrico, Florida. “All of the speakers were engaging and entertaining, and the friendships I have built with some of the fellow participants have far outlasted the week of the conference.”



“Excellent organization and production,” said Lyn Weingarten of Austin, Texas. “Talks were the right length with plenty of time for clarification and discussion.”



“Overall we enjoyed the week immensely, felt uplifted and educated, and are mulling over how much we can increase our annual Cato donation,” said David and Shirley Gilbreath of St. George, Utah.



Scholarships from the Opportunity Foundation allowed 40 students to participate in the program.



The Cato University program also includes a separate 12‐​month home‐​study course that uses audiotapes, books, and an integrated study guide. Another week long seminar and a weekend seminar will be held in 2000. More information about Cato University is available on the Cato University Web site.



 _This article originally appeared in the November/​December 1999 edition of_ Cato Policy Report.



 _This article originally appeared in the November/​December 1999 edition of_ Cato Policy Report.
"
"Community group members and public health professionals have fought back tears while calling on the New South Wales government to drop “anti-climate” legislation that would limit planning authorities’ ability to block fossil fuel developments. Several witnesses became emotional while giving evidence to a parliamentary hearing into the proposed laws, which are designed to stop planning authorities from rejecting or imposing conditions on projects based on their impacts overseas, including overseas emissions.  It is in part focused on scope 3 emissions, which are emissions that occur after coal or gas is sold into the market and burned. Because Australia exports much of these resources, many of these emissions occur overseas. The NSW Minerals Council lobbied the state government in 2019 to change laws that require the Independent Planning Commission to consider these emissions when assessing a project. It followed the NSW land and environment court’s rejection of the Rocky Hill coalmine in February, which cited the impact the mine would have on climate change, including through the burning of coal in other countries, at a time when “a rapid and deep decrease” in global emissions was urgently needed. Two other decisions by the IPC also cited the impact of climate change in their reasons for imposing conditions on a mine or rejecting it entirely. But the amendments now before the NSW parliament were drafted before the unprecedented fires that have affected much of the country. On Thursday, multiple speakers choked back tears as they spoke of the impact the bill would have at a time when Australians were living the reality of the climate crisis. “What I find so insulting, so wilfully ignorant that it leaves me white hot with anger, is that this government and some within its departments are so easily bullied by the fossil fuel lobby to even think of introducing an anti-climate bill while Australia is burning,” Julie Lyford told the hearing. Lyford is the president of Groundswell Gloucester, which argued in the Rocky Hill case that the mine would have a detrimental impact on climate change and the social fabric of the town. “The proponents of this bill are climate criminals. They will be held to account one day if this bill goes through,” she said. Dianne Montague, a member of Groundswell Gloucester, told the hearing rural communities disproportionately bore the impacts of mining and were now also “the ones bearing the burden of the impacts of climate change”. She said the community had been living with smoke from nearby fires for months. “Depression is everywhere. Everybody you talk to is depressed because of what’s happening,” she said. Doctors told the hearing that the bill was a step backward in planning for health risks from fires and other extreme events associated with climate change. Ingrid Johnston, a senior policy officer at the Public Health Association of Australia, told the hearing that the effects of global heating crossed borders. To demonstrate this, she spoke of putting a gas mask on her 11-year-old son because of severe smoke that settled over Canberra in January from fires burning in NSW. “The last couple of months have demonstrated all too clearly that bushfire smoke doesn’t respect borders. Just ask people in the west coast of New Zealand,” she said. Other speakers identified major concerns with the wording of the bill, telling the committee it could have unintended consequences. This included the NSW Minerals Council, which has been pushing for these changes. The council’s policy director, Andrew Abbey, said the proposed amendments could potentially lead to a greater risk that developments would be refused outright. “In the sense that if a project couldn’t get over the line because you can’t impose a condition on it related to scope 3 or downstream emissions the view could be formed that you subsequently don’t approve the project,” he told the hearing. Both the council and the CFMMEU said they supported the “intent” of the bill but were not sure if it achieved its stated purpose. And the Environmental Defenders Office, which acted for Groundswell Gloucester in the Rocky Hill Case, said the bill could limit planning authorities’ ability to consider all emissions associated with projects, including emissions that occur in Australia. “In terms of legal drafting, this is a mess,” the principal lawyer Elaine Johnson said after the hearing. “It’s almost impossible to determine how it would be applied.”"
"
Share this...FacebookTwitterPrior to the transition from the last ice age to the current interglacial climate, when CO2 levels still lingered below 250 ppm, the relative sea levels in southern Greenland were “at least ∼32 m above present.”
Relative sea levels have undergone a series of major changes since the last glacial maximum, when global sea levels were 120 meters below today’s.
Sea levels rose at rates of up to 60 or 70 millmeters per year (6 to 7 meters per century, Tanabe, 2020) from about 12,000 to 8,000 years ago. Most of the globe experienced sea level high stands of 2 or 3 meters above present between about 7,000 to 5,000 years ago (King et al., 2020, Lopes et al., 2020, Martins et al., 2020).
But a new study (Steffen et al., 2020) proposes relative sea levels instead peaked at 32 meters above today’s levels in Nanotalik (southern Greenland) during the latter stages of the last ice age (13,800 years ago).

Image Source: Steffen et al., 2020

Image Source: Tanabe, 2020

Image Source: King et al., 2020

Image Source: Lopes et al., 2020

Image Source: Martins et al., 2020


		jQuery(document).ready(function(){
			jQuery('#dd_0e946332d5df286d97dcf4a1c7d65536').on('change', function() {
			  jQuery('#amount_0e946332d5df286d97dcf4a1c7d65536').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"

Matt Ridley’s new book, _The Rational Optimist: How Prosperity Evolves_ , is garnering rave reviews. Ridley, science writer and popularizer of evolutionary psychology, shows how it was trade and specialization of labor–and the resulting massive growth in technological sophistication–that hauled humanity from its impoverished past to its comparatively rich present. These trends will continue, he argues, and will solve many of today’s most pressing problems, from the spread of disease to the threat of climate change.   
  
  
The Cato Institute has now presented three different looks at the book, with a review in the _Cato Journal_ , another in _Regulation_ , and an event at Cato with Matt Ridley himself.   
  
  
**Powell on Ridley**   
  
  
My colleague Aaron Powell published the first Cato review of _The Rational Optimist_ with a piece in the Fall 2010 edition of the _Cato Journal_ (pdf). 



What _The Rational Optimist_ makes clear, in perspicuous prose and enchanting storytelling, is that, just as biological evolution populated the world with the wondrous variety of life, exchange allowed one of those species to achieve a wondrous standard of living that will only improve and become more uniform as we trade and invent.



Powell doesn’t find the book flawless, however. He identifies two problems that weaken Ridley’s argument, the first dealing with the “circular and unconvincing” nature of his claim that trade caused our human ancestors to achieve humanity. The second concern is broader. Powell writes, 



It would be easy to get the impression Ridley is Pollyannaish. If nuclear annihilation, super flus, and starvation are nothing to be worried about, what possibly could be? Unfortunately, Ridley’s response to this critique is less convincing than it could be, for he fails to adequately draw a line between when an anticipated disaster is real and when it’s just pessimism writ large.



 **Henderson on Ridley**   
  
  
David R. Henderson reviews the book in the latest issue of _Regulation_ (pdf). Like Powell, Henderson enthusiastically endorses the style and substance of Ridley’s book, though without identifying the weaknesses highlighted in the former review. His only point of contention with _The Rational Optimist_ is a “jarring misstatement” regarding trade and value. Henderson writes, 



Given the important role of trade in Ridley’s theory, and given his obvious understanding of trade, it is surprising that he makes a jarring misstatement: “For barter to work,” he writes, “two individuals do not need to offer things of equal value. Trade is often unequal, but still benefits both sides.” The correct statement is: “For barter or trade to work, individuals _must_ offer things of _unequal_ value.” If I valued what I give up the same as what I get in return, there would be no point in trading. Trading is _always_ an exchange of unequal values.



Henderson goes on to defend Ridley against the negative appraisal his book received in the _New York Times_. That review, written by famous foreign‐​aid critic William Easterly, attacked _The Rational Optimist_ for its take on Africa and for failing to “confront[] honestly all the doubts about the ‘free market.’ ” “Really?” Henderson responds. “All the doubts? I do not know if such a book could be written with the requisite amount of evidence and have under 3,000 pages.”   
  
  
**Ridley on Ridley**   
  
  
And then, of course, there’s the source himself. In May, Ridley spoke at a Cato Institute book forum about _The Rational Optimist_. He discussed the core arguments of his book and concluded (optimistically) that technology and trade have now made it possible to stop trying to keep the world from getting worse, and instead focus on making it better.   
  
  
As with all Cato events, full video and audio are available for download on www​.cato​.org. Or watch it right here:   

"
"

The main political conflict in recent years is between experts or elites and non‐​experts. For lack of a better word, the non‐​experts are called populists. Their complaints have been specific: Elites and experts are arrogant, they have different values, they condescend in annoying ways, they ignore the sometimes legitimate concerns of populists, among others. Experts say that they should be listened to because they’re more knowledgeable. We see it in debates on every issue from climate change to trade, immigration, and everything in between.



The COVID-19 pandemic exposes another criticism of experts: They lie with noble intentions. And the consequences of those noble lies are quite negative.



A recent _New York Times_ __ op‐​ed by Zeynep Tufekci exposes the danger of noble lies when it comes to limiting the transmission of COVID-19. She details the claims by public officials and health experts that masks don’t limit transmission. She wrote:



Many health experts, no doubt motivated by the sensible and urgent aim of preserving the remaining masks for health care workers, started telling people that they didn’t need masks or that they wouldn’t know how to wear them.



Those claims were simply untrue. Yes, healthcare workers need masks, but masks (even those that are homemade) also reduce transmission outside of hospitals and clinics. Sick people who wear masks reduce their likelihood of transmitting the virus and healthy people who wear them reduce their likelihood of becoming infected. Tufecki pointed out the obvious contradiction: If masks don’t work, why do healthcare workers need them?



Noble lies are those knowingly propagated by elites or experts to advance a bigger agenda. I can’t think of a single noble lie that has led to better outcomes and most have done more harm than good. The arguments against mass use of face masks were noble lies intended for the good reason of attempting to reduce the mass consumption of face masks to conserve them for healthcare workers. However, they backfired quickly. Ultimately, that failure will cause even more harm down the line.



One source of harm is how social enforcers of new anti‐​COVID‐​19 norms respond. Enforcing these norms through pressure to not gather in large crowds, proper hand hygiene, to maintain social distance, and to stop shaking hands is positive. Those social enforcement mechanisms work best when everybody is basically on the same page about what works but they follow the norms to varying degrees. But if lots of people don’t trust the advice and they disagree about proper methods to limit the transmission of the disease because they’ve been misled by noble lies, social pressure will be contradictory and less effective at altering behavior.



Health experts, epidemiologists, medical researchers, scientists, and other experts have knowledge and experience that is valuable in containing COVID-19 and eventually wiping it out. They will eventually discover a vaccine and treatments that will benefit all of us. But without widespread trust in them, their jobs will be harder. Noble lies will reduce that trust and make it less likely that people will heed their advice and warnings. If some percentage of their guidance is a lie and we all know that they are sometimes lying, people will be less likely to listen or will cherry‐​pick which advice to follow. People will be more likely to consume snake oil, listen to grifters, and fall back on prejudices or other biases that will end up hurting themselves and others. And this will all happen rapidly in the current media market where information is cheap and available at a cost near zero, as it currently is.



Even worse, the noble lie does serious damage to expert culture as one noble lie can justify more lies that are increasingly less noble. Experts will justify less‐​noble lies on the precedence of previous lies that were nobler with no natural limiting principle. And they judge the nobility of the lie by the intent of the liar, which is a dangerous trap. This cycle can only destroy expert credibility.



A common justification for the noble lie is that people aren’t taking the current COVID-19 crisis seriously enough, so experts are justified in trying to “scare people straight” with a lie. The major problem, if the goal is to change other people’s behavior with additional information, is that they won’t be scared straight as soon as the lie is known. Thus, the noble lie will backfire.



Scaring people straight works better when scary truths are revealed rather than when lies are peddled. Emily Oster, economist and author of two superb books on pregnancy risks and raising young children, points out this problem in another area of medicine: alcohol consumption by pregnant mothers. She highlights a report published by the American Academy of Pediatrics with the headline finding that “no amount of alcohol should be considered safe in pregnancy.” Oster points out that the report itself contradicts that statement. She further details to another problem:



Reasonable people can differ, but when we lump together all levels of drinking—without really clearly focusing on what we should be concerned about—we risk losing sight of the groups that actually need help.



Heavy drinking during pregnancy is a big risk, but exaggerating it means that the public can lose sight of the people most negatively affected. Perhaps some pregnant mothers can’t limit themselves to a small amount of alcohol so, for them, the better advice is not to drink at all, but that does not translate into a warning that no expecting mothers should imbibe ever. Exaggeration could mute the actual message: Drinking a lot while pregnant can do serious, permanent harm to your baby.



Experts and elites are more trusted when they tell the truth and expose non‐​obvious tradeoffs. Every action has tradeoffs, even those that are obviously a net‐​benefit. For instance, arguing in favor of lockdowns, quarantines, and travel restrictions while acknowledging that those actions will severely disrupt economic activities and lead to other, different health problems and early deaths. Those extra health problems and deaths may be worth it, but being open about that tradeoff and making the case honestly is the best that experts can do.



This doesn’t mean that experts should consider every non‐​expert objection and weigh them equally when considering a response. Anti‐​vaxxers can be safely ignored during the COVID-19 crisis, for instance. But it does mean that experts need to present the facts honestly and openly. Populists may not believe them, but it’s better to make an honest case for an action that isn’t believed than it is to make a dishonest case that is later exposed as the long‐​term costs in lost credibility are high. The present value of trust in experts is too valuable to be squandered on an ephemeral change in behavior bought at the expense of a lie.



As a libertarian, my preference is for as few government rules and regulations as required to build and maintain a free, peaceful, and prosperous society. In the areas where rules and regulations are necessary, they should be well‐​considered and guided by experts who understand the issue that is being regulated. There should also be consequences for making errors and rewards for being correct. Trust in those experts is fragile in even the best of times, but crucial for widespread popular acceptance which is necessary for the enforcement of any new policy. When some experts commit noble lies, it damages their credibility and limits the extent of their wiser (compared to non‐​experts) recommendations.



Tufekci ended her piece with this prescient warning:



Research shows that during disasters, people can show strikingly altruistic behavior, but interventions by authorities can backfire if they fuel mistrust or treat the public as an adversary rather than people who will step up if treated with respect. Given that even homemade masks may work better than no masks, wearing them might be something to direct people to do while they stay at home more, as we all should.



Experts should commit themselves publicly to always telling the truth and to banish the noble lie from public debate. By limiting the transmission of noble lies, hopefully we can do something to limit the spread of COVID-19.
"
"

The nation’s 76 million stockholders have “internalized their new role as capitalists,” causing public opinion to favor investor‐​friendly policies over government programs, says Richard Nadler in “The Rise of Worker Capitalism” (Policy Analysis no. 359). Forty‐​three percent of U.S. households own stocks or stock mutual funds, a 126 percent increase in shareholding over the last 15 years. The rate of increase was particularly steep among laborers and farmers (106 percent), householders 34 years old or younger (64 percent), and families with incomes under $25,000 (80.4 percent). As wage earners become owners of capital, Nadler finds, they increasingly favor policies that reduce taxes on savings and distrust government “investments” such as Social Security. “Congress should enact policies that expand worker ownership and financial self‐​sufficiency,” Nadler concludes, pointing out the importance of spreading wealth to even larger segments of the population by expanding individual retirement accounts and 401(k) plans and instituting individually owned Social Security accounts.



 **Tennessee—Still the Volunteer State?**



In “The Case against a Tennessee Income Tax” (Cato Briefing Paper no. 53), Stephen Moore and Richard Vedder argue that insti‐​tuting an income tax in Tennessee would reduce growth and job creation and would be the most economically destructive way to close the state’s budget shortfall. The study was released the day before the state legislature was to begin debating Gov. Don Sundquist’s proposed 3.75 percent state income tax. Tennessee is currently one of only nine states without an income tax. Moore, director of fiscal policy studies at Cato, and Richard Vedder, an economics professor at Ohio University, contend that “Tennessee’s structural deficit problems are a result of a huge growth in state expendi‐​tures, not insufficient revenues.” Of the options available for closing the state budget deficit, estimated to be between $300 million and $500 million, an income tax “would likely be the single most economically harmful. Tennessee derives large economic benefits from not having an income tax, and it should not forfeit those benefits,” the authors conclude.



 **An Agenda for the WTO**



Supporters of free trade should abandon the reciprocity model of negotiations and instead pursue a course of coordinated unilateralism, in which the benefits of open markets at home and abroad are clearly recognized, write the authors of “Seattle and Beyond: A WTO Agenda for the New Millennium” (Trade Policy Analysis no. 8). Brink Lindsey, director of Cato’s Center for Trade Policy Studies; Daniel Griswold, associate director of the center; Mark Groombridge, research fellow; and Aaron Lukas, trade policy analyst, argue that the new WTO round should be seen as a “ ‘bottom‐​up’ process in which countries liberalize, not merely to gain ‘concessions’ from other countries, but primarily to reap the economic rewards of their own liberalization.” Free traders, the authors maintain, “should focus on getting the available gains as quickly as possible and fend off efforts to clog and corrupt the agenda with illiberal initiatives.”



 **Iraqi Threat Overblown**



The U.S. policy of attempting to remove Saddam Hussein from power will be difficult, could be counterproductive, and might throw Iraq into a civil war, argues defense analyst David Isenberg in “Imperial Overreach: Washington’s Dubious Strategy to Overthrow Saddam Hussein” (Policy Analysis no. 360). The author contends that the Iraq Liberation Act of 1998, which states that the United States will aid efforts to overthrow Saddam and promote democracy, is flawed because it does not offer a realistic way of dealing with the Iraqi leader. Isenberg believes that the threat of Saddam is “overblown,” pointing out that Saddam’s army has already been decimated by war and sanctions. “Saddam may be odious, but his regime does not pose a major threat to America’s security.” Isenberg argues that a more realistic policy would be to lift general economic sanctions in exchange for international weapons inspections and to continue a selective embargo on military weaponry.



 **Not‐​So‐​Smart Growth**



The campaign to eliminate urban “sprawl” and replace it with “smart growth” has been financed with federal tax dollars, note the authors of a new Cato study, “Smart Growth at the Federal Trough: EPA’s Financing of the Anti‐​Sprawl Movement” (Policy Analysis no. 361). The federal government, via grants from the Environmental Protection Agency to nonprofit organizations, has been covertly supplying funds and technical support to anti‐​automobile, anti‐​suburb groups. Peter Samuel, editor of _Toll Roads Newsletter_ and a consultant on EPA policies for the George C. Marshall Institute, and Randal O’Toole, executive director of the Thoreau Institute and an adjunct scholar at the Cato Institute, argue that “EPA’s campaign fundamentally subverts not only the Tenth Amendment but the very concept of democracy itself.”



 **Social Security Is Still a Bad Deal**



The current Social Security system would not pay higher rates of return and benefits than a privatized system of personal retire‐​ment accounts, writes Peter J. Ferrara in “Social Security Is Still a Hopelessly Bad Deal for Today’s Workers” (Social Security Paper no. 18). The analysis refutes a recent study by John Mueller for the National Committee to Preserve Social Security and Medicare. Ferrara, chief economist and general counsel with Americans for Tax Reform and senior fellow at Cato, points out that Mueller’s findings are contradicted by a broad range of analysts, institutions, and leaders, including President Clinton, Harvard economics professor Martin Feldstein, the Heritage Foundation, the World Bank, and the 1994–95 Social Security Advisory Council.



 **The Imperial Presidency**



Modern presidents have moved beyond their constitutional duty of seeing “that the Laws be faithfully executed” and have instead been usurping vast lawmaking powers reserved to Congress or the states, argue attorneys William J. Olson and Alan Woll in “Executive Orders and National Emergencies: How Presidents Have Come to ‘Run the Country’ by Usurping Legislative Power” (Policy Analysis no. 358). The authors note that, during the recent presidential scandals, many people called for the investigations to end “so that the president could get back to ‘the business of running the country.’ ” How did we get to a point, the authors ask, “where so many Americans think of government as embodied in the president and then liken him to a man running a business?” The answer rests, in part, “with the growth of presidential rule through executive order and national emergency,” according to the authors. Congress has delegated more and more power to the executive branch, aiding and abetting the expansion of presidential power, the authors note. The courts have acted in just two cases––in 1952 and 1996––to restrain the executive branch. The good news, the authors point out, is that the nation’s governors have just forced President Clinton to rewrite a federalism executive order; and now there are two proposals in Congress that seek to limit presidential lawmaking.



 **Clinton’s Pyrrhic Victory in Kosovo**



The Clinton administration’s policy in Kosovo has habitually failed to meet its objectives and will continue to entangle the United States in multi‐​billion‐​dollar, open‐​ended peacekeeping operations, writes Christopher Layne, a visiting scholar at the Center for International Studies at the University of Southern California. In “Faulty Justifications and Ominous Prospects: NATO’s ‘Victory’ in Kosovo” (Policy Analysis no. 357), Layne writes that the administration “stumbled into war and blundered its way to ‘victory.’ ” Layne says that President Clinton’s claim of victory “rings hollow”: NATO’s intervention not only killed many innocent civilians in Yugoslavia; it also caused serious economic and social disruptions throughout the Balkans and greatly strengthened the position of the extremist Kosovo Liberation Army. Layne warns that the war continues to have negative policy repercussions. “The war with Yugoslavia has had important geopolitical effects that reverberate far beyond the Balkans. Clinton’s Kosovo policy has had portentous consequences for America’s relations with its great‐​power rivals, Russia and China, and its great‐​power allies, the West European nations.”



 **Cut Global Warming Program**



Congress should eliminate funding for a $1.4 billion global warming program, argues Jerry Taylor, Cato’s director of natural resource studies, in “Energy Efficiency: No Silver Bullet for Global Warming” (Policy Analysis no. 356). The Climate Change Technology Initiative, being pushed by the Clinton administration as a way to combat global warming, is a “sham,” and a “repackaging of failed programs” that do nothing to significantly reduce global temperatures, he writes. The program—an amalgam of tax credits, research and development, product labeling and awareness programs, demonstration projects, and subsidies and regulations to increase energy efficiency and the economic attractiveness of renewable energy—is “built on economic ignorance and political symbolism,” Taylor writes.



 **Protocols on Biological Weapons Ineffective**



The protocols proposed for the Biological Toxins and Weapons Convention would do little to stop the spread of bioweapons and could compromise valued U.S. secrets and critical data used for defense against biological weapons, writes Eric R. Taylor of the University of Louisiana at Lafayette in “Strengthening the Biological Weapons Conventions: Illusory Benefits and Nasty Side Effects” (Policy Analysis no. 355). Taylor writes that proposed protocols render inspections “useless” in demonstrating either compliance with or violation of the convention. According to Taylor, U.S. pharmaceutical development, which relies heavily on the very technology that is also critical to bioweapons research and development, would be especially hurt by the new protocols. “The future of the people’s right to be secure in their possessions and personal effects is placed in peril by the Biological Toxins and Weapons Convention protocols,” he writes. “Although an attack with biological weapons on the United States would be dangerous, an assault on U.S. constitutional rights in an effort to strengthen an international convention has little hope of stopping the spread of those weapons.”



 **Repeal the Community Reinvestment Act**



The Community Reinvestment Act should be repealed, writes economist George J. Benston in “The Community Reinvestment Act: Looking for Discrimination That Isn’t There” (Policy Analysis no. 354). Originally intended to deal with “redlining”—the alleged refusal of banks to lend to residents of poorer urban areas inhabited by racial minorities—the two‐​decade‐​old CRA is an expensive way to deal with a problem that may not exist, the study finds. Benston reports that qualified applicants, regardless of their address, do not suffer unwarranted discrimination in lending. “Researchers using the best available data find very little discernible home‐​mortgage lending discrimination based on area, race, sex, or ethnic origin,” writes Benston, the John H. Harland Professor of Finance, Accounting, and Economics at Emory University.



 **Cradle‐​to‐​Grave Taxation**



The federal gift and estate tax, better known as the “death tax,” is clearly a failure from an economic standpoint, but “the biggest problem with the death tax is a moral one,” writes law professor Edward J. McCaffery in “Grave Robbers: The Moral Case against the Death Tax” (Policy Analysis no. 353). He notes that the tax’s economic shortcomings are well‐​known. It “raises barely over 1 percent of total federal tax revenues,” and “for every dollar raised from the tax, roughly another dollar is lost because of avoidance, compliance, administrative, and enforcement costs.” But it is the moral impact that is most objectionable, according to McCaffery. The tax “rewards a ‘die‐​broke’ ethic, whereby the wealthy spend down their wealth on lavish consumption, and discourages economically and socially beneficial intergenerational saving.” McCaffery, a professor in the University of Southern California Law School, finds that the death tax rewards those who don’t work, don’t save, and spend all of their wealth.



 _This article originally appeared in the January/​February 2000 edition of_ Cato Policy Report.
"
nan
"
Share this...FacebookTwitterGermany’s Bundestag moves to enact a higher CO2 tax 
The “Corona pandemic”, despite the ever falling death rate, has given governments cover to enact draconian regulation and lockdowns, thus allowing their even wildest power wet dreams to turn into reality.
Just a year ago much of what we are seeing today was considered unimaginable. Yet, here we are.
Never before have modern “democratic” governments enacted such extreme lockdown and government intrusion measures like those we have seen in the current “Corona crisis”. And like real junkies, they need more.
There are other government crackdown opportunities left out there, among them the “climate crisis” – the Big Kahuna when it comes to government regulation, takeover and control. It’s not for nothing they’ve frittered away hundreds of billions propping up this fake crisis.
Germany is already seizing the opportunity, having pledged to ban internal combustion engines soon, modify human eating habits and restricting a host of other amenities we once took for granted. Soon these amenities will be redefined as privileges, and they will be easily available only to the wealthy and elite.
The latest is energy and heat.
Higher CO2 tax decided
The German media, e.g. NTV public broadcasting, have reported that the Bundestag has just decided on a higher CO2 tax beginning already next year, January 1st.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“It is intended to make fossil fuels less attractive. This means that fuel, heating oil and gas, among other things, will cost more,” reports  German public broadcaster NTV. “The CO2 price will be 25 euro per ton from the new year on. The levy acts like a tax and is to climb gradually to 55 euros by 2025.”
That also means higher gasoline and diesel fuel prices, which will make transportation more expensive.
Already German electricity is the most expensive in Europe.

But not to worry: Industries with particularly high energy requirements that are also in global competition will be relieved of the costs. And of course, the rich and elitists will also keep their cushy red carpet lives – so that they can continue effectively doing their important work – while the rest of us are forced to move out into the cold mud.
In the end it’ll be lower income workers and households left struggling with the higher prices for everything. Even heat will become a luxury.
And so continues the cycle of political demise 
And once governments get total control and surveillance over citizens across the world, they’ll try to tell us all just how much better things have become as a result, like the old communists used to do with their state controlled media. Of course, life in reality will become much worse, but we’ll be asked to pretend that it isn’t.
We all know what follows next: Revolution.


		jQuery(document).ready(function(){
			jQuery('#dd_4223c6fa640da5fd71799ecd0745c810').on('change', function() {
			  jQuery('#amount_4223c6fa640da5fd71799ecd0745c810').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"People are too afraid to return to the village so they are sleeping in the forest or have left altogether. They have lost their stored grain and all their belongings. I don’t know how they will get by. These are the words of Riana*, a young woman from Bevoahazo, a tiny village in the eastern rainforests of Madagascar. Bevoahazo sits on the edge of Ranomafana National Park in a UNESCO world heritage site teeming with endangered and endemic species. Security in the area has been deteriorating over the last few years but things have escalated recently. On November 24, 50 men raided the village stealing stores of rice – vital food reserves for local people who are mostly subsistence farmers – and injuring anyone who tried to defend their property. A few days later the local police chief, Heritiana Emilson Rambeloson, who had come to the area with a small team to investigate, was shot dead. I spent two years living in Bevoahazo in the early 2000s while researching the sustainability of crayfish harvesting. I have spoken to friends from the village who are are currently staying in the nearby town of Ranomafana for safety, and researchers in the area to get a better understanding of what is happening.  Patricia Wright, a professor of anthropology, has spent more than 30 years working in Ranomafana. She directs the Centre Valbio, an internationally renowned conservation research centre situated on the edge of the forest. She said: The security situation is at crisis point. This is leading to real human suffering in one of the most important places for biodiversity on the planet. The [murdered policeman] was smart, dedicated to his job and was interested in wildlife and the importance of the forest. A genuine friend. We will miss him. The recent death comes just months after a member of Valbio staff was killed by bandits. Jean François Xavier Razafindraibe was killed when armed men raided his village close to the park entrance in June 2018. Ranomafana National Park was established by the Malagasy government to protect its globally important biodiversity. As part of the Forests of Atsinanana it is home to a number of critically endangered endemic lemurs such as the golden bamboo lemur and the black-and-white ruffed lemur. Ranomafana is a popular tourist spot in Madagascar with stunning scenery, rare wildlife and the friendly, sleepy town nearby. So far the insecurity hasn’t influenced tourism. As Wright says:  The bandits steer clear of tourists, but the villagers are living a life of fear. Miners panning for gold illegally in the forest interior are a source of the insecurity. This has been an ongoing issue for many years but has become much more difficult for the park authorities to control. The miners pollute rivers, clear the rare swamp forest and hunt endangered wildlife for meat. The situation is complicated. Armed cattle thieves known as dahalo are causing havoc in many areas of Madagascar. A recent estimate suggests they have caused 4,000 deaths in the last five years alone. In 2017, the mayor of the neighbouring town of Ambalakindresy, Elysé Arsène Ratsimbazafy, was shot dead in what is widely believed to have been a hit. He had run for election on a platform of ridding the town of the bandits and had cooperated with efforts to get the miners expelled from the national park interior. Mar Cabeza, a professor of biology at the University of Helsinki, returned from the area a few days ago. She said: The gold mining has escalated in recent years and differs greatly from previous subsistence-related threats. The widespread fear has negatively affected both research and conservation management. One of Cabeza’s PhD students, Marketta Vuola, was meant to conduct research in the attacked villages recently, but was warned of the danger and moved to another village. Vuola told me  News spread fast, with all villages in the region being afraid. We spent last night hiding, with our day packs ready to escape to the forest. There has been a robust response to the recent series of attacks. The district quickly sent reinforcements of 80 police. This will hopefully reassure the local population, allowing people to return to their village, and will reduce the immediate threat. 


      Read more:
      Animals are victims of human conflict, so can conservation help build peace in warzones?


 This reassurance is essential as my old friend Koto* told me over the phone:  People need to be able to get back home to tend their crops; if they can’t do this they will suffer even more. However the rise in insecurity reflects a wider problem of respect for the rule of law in Madagascar. Jonah Ratsimbazafy, a professor of paleontology at the University of Antananarivo in Madagascar, said: If you focus on what is happening, then you will lose your hope for Madagascar. We must focus on the solutions. Good governance is crucial in order to develop the economy of Madagascar and for saving the irreplaceable biodiversity. Madagascar will elect a new president on December 19. People in Bevoahazo, and throughout Madagascar, are hoping that the new government can bring the change so desperately needed. *Names changed to protect identities."
"

**May 1:** In the name of “universal service,” the Telecommunications Act of 1996 empowers the Federal CommunicationsCommission to create public entitlements to advanced telecommunications services. At a Policy Forum on “UniversalService: Socializing the Telecommunications Infrastructure,” Milton Mueller, professor of communications at RutgersUniversity; Wayne Leighton, senior economist at Citizens for a Sound Economy; and Lawrence Gasman, director oftelecommunications and technology studies at the Cato Institute, addressed the question: Can mandated and subsidizedtelecommunications serve consumers better than competition? 



**May 8:** Auctions are heralded as the most beneficial means of allocating the airwaves that have been set aside for advancedtelevision services (ATV), including high‐​definition television. But if federal regulators insist that broadcasters be subject topublic‐​interest controls, must they offer broadcasters free ATV spectrum as a quid pro quo? That question was the focus of“Beyond Budgetary Concerns: A Free‐​Market Perspective on ATV Spectrum Auctions,” a Policy Forum featuringTom Hazlett, visiting scholar at the American Enterprise Institute; James Gattuso, vice president for policy research at Citizensfor a Sound Economy; and Bob Okun, vice president of NBC. 



**May 14:** Cato hosted a delegation from the Hungarian Embassy at a Roundtable Luncheon. The discussion with Cato staffand policy analysts centered on the Hungarian perspective on European security issues, expanding NATO, and U.S. troops inHungary. 



**May 15:** During a Policy Forum titled “Red Resurgence or Revitalized Reform? Russia’s Political Future,” SusanEisenhower, chairman of the Center for Post‐​Soviet Studies; Dmitry F. Mikheyev, senior fellow at the Hudson Institute; andAriel Cohen, senior policy analyst at the Heritage Foundation, discussed the prospects and implications of a possiblecommunist victory in Russia’s June election. 



**May 16:** Although natural gas deregulation is generally considered an economic success pregnant with valuable lessons forother industries, a web of regulatory oversight still surrounds the industry. Jerry Ellig of the Center for Market Processes andJoseph Kalt of Harvard University appeared at a Cato Book Forum to discuss their new book, _New Horizons in NaturalGas Deregulation_ , a collection of papers originally presented at a 1995 Cato conference. Ellig and Kalt reviewed the pastfailure of natural gas regulation, the lessons of regulatory reform, and how further deregulation should proceed in the 1990s. 



**May 22:** As chairman of the U.S. House of Representatives’ Task Force on Privatization, Rep. Scott Klug (R‐​Wis.) is aleading proponent of privatization in the 104th Congress. At a Policy Forum titled “Privatization: New Zealand’s SuccessStory,” Klug discussed his fact‐​finding mission to New Zealand and the success of that country’s privatization program. Inmeetings with railroad executives and sheep and dairy farmers living without subsidies, Klug learned lessons that Americansshould heed. 



**May 23:** The Cato Institute held its 14th Annual Monetary Conference, “The Future of Money in the Information Age.“The full‐​day conference addressed the technological viability and economic implications of digital currency, or “E-money.“Speakers included Scott Cook, chairman of Intuit, manufacturer of the popular business software “Quicken”; Rep. MichaelCastle (R‐​Del.), chairman of the House Subcommittee on Domestic and International Monetary Policy; and Jerry L. Jordan,president and CEO of the Federal Reserve Bank of Cleveland. For the first time, a Cato event was carried live via interactivetelevideo to nine sites around the country as well as broadcast on the Internet. Over 175 people attended the event inWashington, D.C., while others participated in New York, San Francisco, Chicago, Silicon Valley, and other places. 



**May 28:** As telephone services in New Zealand were deregulated, bureaucrats took a more “hands‐​off” approach than in theUnited States. Should U.S. regulators take a similarly minimalist approach, allowing even the terms of interconnection to be setby private negotiations? That was the topic of discussion during “New Zealand Telephone Deregulation: What Lessonsfor the United States?” a Policy Forum featuring Milton Mueller of Rutgers University, Jeff Rohlfs of Strategic PolicyResearch, and Joseph Farrell of the Federal Communications Commission. 



**May 29:** This year’s decertification of Colombia and the confirmation of Gen. Barry McCaffrey as “Drug Czar” suggest astepped‐​up effort in the war on drugs. With that in mind, Cato asked, “Does the International Drug War Make Sense?“at a Policy Forum featuring Robert Gelbard, assistant secretary of state for international narcotics and law enforcement affairs,and Kevin Jack Riley, author of _Snow Job? The War against International Cocaine Trafficking._ Gelbard reviewed thelogic of Washington’s international narcotics control strategies and explained how the United States plans to significantlyreduce the flow of drugs across its borders. Riley questioned the supply‐​side campaign, examined its impact on drug‐​sourcecountries, and assessed its prospects for success. 



**June 6:** Cato held its midyear Board of Directors Meeting. Board members set the Institute’s course and were brought upto date on Cato’s policy activities, progress in fundraising, and fiscal standing. 



**June 17:** In Seattle Cato hosted a City Seminar, “Leviathan and the New Millennium: An Agenda for Real Reform,“that featured a keynote address by Lawrence Kudlow, economic counsel at Laffer Advisors, Inc., and a panelist on CNBC’s _Strictly Business._ Other speakers included José Piñera, co‐​chairman of Cato’s Project on Social Security Privatization,Edward H. Crane, president of the Cato Institute, Stephen Moore, Cato’s director of fiscal policy studies, and MichaelTanner, Cato’s director of health and welfare studies. 



**June 18:** America’s security commitments abroad remain largely unchanged despite the end of the Cold War. Nowhere is thatmore evident than on the Korean peninsula, where a commitment of nearly 40,000 U.S. troops, costing billions of dollars ayear, threatens to draw the United States into any conflict that might erupt in Northeast Asia. Cato senior fellow DougBandow appeared at a Book Forum to discuss his new Cato book, _Tripwire: Korea and U.S. Foreign Policy in aChanged World._ Bandow argued that it is time to phase out the American military commitment to South Korea, which hastwice the population of North Korea and an economy 18 times as large as that of the North. That step would free the UnitedStates of an obsolete obligation and give South Korea responsibility for its own security. 



**June 19:** Cato hosted a City Seminar in San Francisco on “Leviathan and the New Millennium: An Agenda for RealReform.” The keynote address was given by Ward Connerly, a member of the Board of Regents of the University ofCalifornia and chairman of the California Civil Rights Initiative, which would outlaw racial quotas in state policy. Otherspeakers included José Piñera, co‐​chairman of Cato’s Project on Social Security Privatization and Edward H. Crane, StephenMoore, and Michael Tanner of the Cato Institute. 



**June 21:** In the postcommunist era Russia and Eastern Europe have implemented systems of parental choice in educationsimilar to the U.S. voucher concept. At a Book Forum for _Educational Freedom in Eastern Europe,_ author Charles L.Glenn, professor of education at Boston University, discussed his survey of educational reforms in 10 East European countriesand the lessons that America might learn. Denis P. Doyle of the Heritage Foundation commented. 



**June 26:** Living standards and rates of growth differ dramatically around the world. Robert J. Barro, Robert C. WaggonerProfessor of Economics at Harvard University and author of _Getting It Right: Markets and Choices in a Free Society,_ spoke at a Book Forum on what accounts for those disparities. He discussed the relationships among material progress anddemocracy, domestic institutions, and government policies and concluded that the rule of law has enormous explanatory poweras a factor in economic growth and that governments should provide markets with a stable framework of rules and then get outof the way. 



**June 27:** Sixty years ago the New Deal Supreme Court began unraveling the Constitution of limited government byreinterpreting first the general welfare clause and then the commerce clause. Recently, scholars and the Court have begun toreexamine the commerce clause jurisprudence that gave us the modern regulatory state, but little has been done with thejurisprudence of the general welfare clause that gave us the modern redistributive state. At a Book Forum, Leonard R.Sorenson, professor of history at Assumption College, discussed _Madison on the “General Welfare” of America,_ his newbook that provides a detailed refutation of scholars on whom members of today’s Court were schooled. Comments wereprovided by Judge Douglas H. Ginsburg of the U.S. Court of Appeals for the District of Columbia Circuit. 



**June 28:** International negotiations addressing the issue of global climate change have resumed in Geneva, and a recent reportfrom the Intergovernmental Panel on Climate Change (IPCC) has introduced a sense of urgency to those negotiations. Doesthat report really justify immediate governmental action to address global warming, or is it just another example of scientificsensationalism? At a recent Policy Forum, “The New IPCC Report: Scientific Consensus of Scientific Meltdown?“William O’Keefe of the Global Climate Coalition argued that the scientific “finds” of the report have been heavily anddisingenuously edited by political activists. Patrick Michaels, climatologist at the University of Virginia, similarly maintained thatthe report is so riddled with basic scientific errors as to be a completely unreliable guide for policymaking. 
"
"

Got a person on your christmas list that is fully deserving but can’t find that lump of coal at K-Mart at the last minute? Thanks to the good folks at Free Carbon Offsets, you too can join the ranks of the carbon purified. Just visit: www.freecarbonoffsets.com  and you can print your own Carbon Offset Certificate suitable for a stocking stuffer for the most deserving person on your Christmas list.

Merry Christmas Everyone! 


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea1e71ffe',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Given the deluge of coverage, comment and analysis of the UK’s chaotic exit from the EU, it’s tempting to conclude that the exhausting subject of Brexit has been talked into the ground and analysed to death.   But that is far from true. Take the issue of the Irish border. Many keenly understand that creating a hard border between Northern Ireland and the Republic of Ireland would threaten the fragile peace that has held for two decades since 1998’s Good Friday Agreement.  Theresa May’s proposed withdrawal agreement – which goes to a parliamentary vote on December 11 – endeavours to avoid a hard border if the UK and EU cannot reach an alternative agreement, by temporarily aligning Northern Ireland with some EU single market rules, and the UK as a whole with EU customs rules. Before the Good Friday Agreement, the border was heavily fortified and crossings were tightly controlled. Its post-1998 incarnation is more than just an improvement in practical terms; it has come to symbolise progressive peace and openness in a place marked by violence and militarised division. The border’s uncertain future in light of Brexit has attracted a tremendous amount of attention – and rightly so, given its enormous importance. But Brexit’s cyclops eye struggles to look meaningfully at more than one dimension of an issue at a time, and other areas that are crucial to people’s everyday lives are being neglected. One key issue concerns the potentially damaging impact of Irish border divisions on Ireland’s all-island energy market. Northern Ireland and the Republic of Ireland operate an Integrated Single Electricity Market (ISEM), which covers most energy generation on the island. This bespoke market is regulated by a special committee composed of northern and southern regulators, and overseen by a Single Electricity Market Operator (SEMO). This groundbreaking set up was created in 2007 by the then Northern Ireland secretary, Peter Hain, during a period of direct Westminster rule, after devolution had collapsed. Working in tandem with the Irish government, Hain’s team drew the northern and southern electricity markets together into a single all-island market, with most of the island’s electricity bought and sold through one overall market. A two-party legislative framework locked the ISEM in place on either side of the border, supported by a “memorandum of understanding” between the two governments.  Energy is a devolved matter under the UK’s constitutional arrangements, and when devolution was restored in 2007 the reins were passed to the Stormont administration, which continued to operate the electricity market jointly with the Irish government. The Democratic Unionist Party’s alleged mismanagement of a renewable heat incentive scheme has since collapsed the devolved institutions once more, and so the Northern Irish elements of the ISEM are currently being overseen by Belfast civil servants until the situation can be resolved.   The ISEM improved on the conditions that preceded it, increasing competition and dampening consumer prices. It has also bolstered north-south energy security, and has had positive effects on energy efficiency and integrating renewable energies. But Brexit is currently pulling this UK-Ireland innovation in opposite directions. A target model has been issued by the EU that requires member states such as the Republic of Ireland to strive for greater energy integration, whereas the Northern Irish/UK momentum is disengaging from the EU initiative as a consequence of Brexit. Meabh Cormacain, manager of the Northern Ireland Renewables Industry Group (NIRIG),  offered insightful comment on this crucial issue, suggesting that the Irish border might function as an “electric fence”, cutting the ISEM market in two if Brexit is not carefully managed. Consumers on both sides will bear the brunt of any diplomatic failure because it will likely increase their energy costs over time. It has been pointed out that these difficulties might be solved if Northern Ireland continues to operate as a distinct zone within the UK that remains largely subject to EU law in this area post-Brexit, meaning Northern Ireland would continue to be in regulatory alignment with the republic. May’s withdrawal agreement by and large adopts this approach. While sticking with this type of collaborative approach clearly solves problems, I suggested in a recent lecture to the Irish energy industry that it seems undemocratic to subject Northern Irish citizens to significant EU energy laws while depriving them of the democratic mechanisms to influence those laws – bearing in mind Northern Ireland will have left the EU along with the rest of the UK. At any rate, the overall principle is clear: the ISEM is a novel, bespoke energy market specific to the island of Ireland, and so its preservation and maintenance will require a similarly novel, bespoke set of agreed UK-EU arrangements for the post-Brexit period. May’s proposals may achieve this in practice, but it seems unlikely that the UK parliament will vote in favour of her deal as a whole. The Irish and UK governments support the protection and continuation of the ISEM, as does the European Commission. With the Brexit clock ticking down to the make-or-break parliamentary vote in December, the sooner the parties responsible can agree on the specific policies that will underpin arrangements for the future, the better. Markets need certainty – and so do the people of Northern Ireland."
"

There’s nothing wrong with your computer monitor, do not attempt to adjust the picture.
Normal blogging will resume shortly.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea39aedd2',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

From Slashdot.org The Wall Street Journal has a sobering piece describing the research of
medical scholar John Ioannidis, who showed that in many peer-reviewed research
papers ‘most
published research findings are wrong.’ The article continues: ‘These flawed
findings, for the most part, stem not from fraud or formal misconduct, but from
more mundane misbehavior: miscalculation, poor study design or self-serving data
analysis. […] To root out mistakes, scientists rely on each other to be
vigilant. Even so, findings too rarely are checked by others or independently
replicated. Retractions, while more common, are still relatively infrequent.
Findings that have been refuted can linger in the scientific literature for
years to be cited unwittingly by other researchers, compounding the errors.’


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea3ddae1c',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

I was forwarded a slide show presentation done by Thomas Lowell et al of the University of Cincinnati titled: Organic Remains from the Istorvet Ice Cap, Liverpool Land, East Greenland: A Record of Late Holocene Climate Change
It was presented last week at AGU’s Greenland Climate Change Past and Present session. It has some very interesting data in it. In summary it has a report on occurrence of subfossil organic remains, with organics recovered in locations presently void of plant growth.

Picture of Istorvet organic remnants at edge of glacier melt.
The preliminary conclusion from the data collected in the field work is that presently the small ice caps at high latitudes in Greenland are retracting to locations where they were at 1000 years ago.  The presence of subfossil vegetation was found within 280 vertical meters of ice cap summit and where comparable modern assemblages do not exist. The implication seems to be that there were warmer periods in these areas prior to today, warm enough for plant growth.
According to the study, the organic material in Liverpool Land radiocarbon dates from 400 to 1015 AD. It is interesting to note that the Vikings settled in Greenland around 974 AD and the study indicates that ice cap expansion began around 1015 AD.

While the UC team that did the field work still has more work to do to reconstruct temperatures from this data, the study lends support to the idea that Greenland’s climate was warmer approximately 1000 years ago. One of the organic samples recovered at another location was dated to 910BC. This makes one wonder just how often shifts in Greenland’s climate occurs.
More study is needed, but this is certainly interesting. You can view the abstract here


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea222cbf0',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
This from www.Spaceweather.com
As January comes to an end, sky watchers in Scandinavia are recovering from a veritable storm of nacreous clouds. After mid-month, hardly a night went by without someone spotting the phenomenon. “It was incredible! They were all over the sky,” says Morton Ross of Oslo, Norway. This picture, taken by Ross on Jan. 25th, shows a typical apparition:

Also known as “Mother of Pearl” clouds, nacreous clouds are peppered with tiny ice crystals that blaze with iridescent color when struck by light from the setting sun. It is these crystals that make nacreous clouds so rare: they require exceptionally low temperatures of minus 85 Celsius (-120 F) to form. Icy nacreous clouds float 9 to 16 miles high, curling and uncurling hypnotically as they are modulated by atmospheric gravity waves.
For much of January, these clouds rolled across the Arctic circle with puzzling regularity. Why the sudden abundance? Is the show over? No one knows. Stay tuned for February!
For more, see the 2008 Nacreous Cloud Gallery For the science behind nacreous clouds, please see this entry in Atmospheric Optics.
As for temperatures at high latitudes, its -35°F in Saskatoon at the surface this morning, so there’s a chance we’ll see more nacreous clouds in days ahead.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea13cef97',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Congratulations for your thorough analysis of the environmental impacts of High Speed 2 (Will HS2 help the climate – or will it make things worse?, 3 February; Barn owls, bats, butterflies, birds – all now at risk, 3 February). The escalating costs of HS2 call into question the way the UK designs and evaluates big infrastructure projects. We should take much more account of the impact on development and land values, especially if the uplift were shared with investors. Spending £3bn on land acquisition to date is surely wasteful. But little can be done without reintroducing regional and strategic planning. Before we turn our backs on Europe, we should learn from how the French succeeded in growing their towns and economies while keeping down car use and pollution. The crucial difference is not going for one grand national project or another, but joining up investment in development and infrastructure at a city region level, as a comparison of Lyons or Lille with Leeds would show.  So let’s start by revisiting attempts to come up with regional or sub-regional plans and ask how much of the costs could be recovered from the uplift in land values. The late Sir Peter Hall proposed a relatively economic way of improving rail services, later named HS3. This would use a series of improvements, such as better signalling and junctions, not one big project, which is almost bound to go wrong. Such a policy would produce faster results, using public investment to secure multiple benefits, not just faster long-distance journeys.Dr Nicholas FalkExecutive director, The Urbed Trust • At last the necessity for HS2 is being steered away from the need to get from London to Birmingham a bit quicker (The case for, 4 February; The case against, 4 February). The essential issue is capacity. If the public wants fewer heavy trucks on the roads then additional rail is the only answer. There are virtually no spare paths between London and the Midlands on the west coast mainline: £8bn-£10bn was spent in 2008-10 upgrading that line, but there is now nothing spare. A new line is needed, so why would you build a slow one? The data is regularly published in Modern Railways, but it is apparent that politicians and their advisers don’t read the industry journals. In all the furore about rising costs, politicians never ask why it is four times more expensive per mile compared with the LGV Est line in France. Perhaps land prices are lower in France, and each new LGV line has been dovetailed into existing termini in Paris, which might explain some of the lower costs. But really, four times as much here? Who’s making a killing? Finally, why are the arguments presented as either we spend on HS2 or upgrade areas in other parts of the country? Why can’t it be both?Robert AshleyLondon • Hurrah! At last you have hit the nail on the head and made the clear and coherent case for HS2 (Editorial, 6 February). Taken together with enhancement and integration of local networks to ensure maximum access to HS2, there is little doubt that the new line will more than pay for itself and stimulate development across the Midlands and north. There’s already been digging aplenty in Birmingham. More please, Mr Johnson, and soon.Roy Boffy Sutton Coldfield, West Midlands • Here are some other ways to spend £106bn: 15 tram systems like Manchester Metrolink £42bn, free bus services for everyone for 10 years £30bn, free ebike for every adult £34bn. Well-funded local transport for everyone is what we require.Edward FieldingShipley, West Yorkshire  • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"When I dropped my kids off at childcare just a few weeks ago, the air was so dangerous that the warning on my phone showed someone in a gas mask. As I stood on the burned-out property of Nick Hopkins in Malua Bay last month, he summed it up perfectly, feeling two parts shattered and three parts angry.  Australians are angry and anxious because the government clearly doesn’t have the climate emergency under control and has no plan to get it under control. But people are also angry and anxious because the basics of life are no longer guaranteed. Study hard and do Tafe or university and you get underemployed in an insecure job with low pay. You get a job and then find you can’t afford a house because the government has rigged the housing market against you. We have a climate and environment emergency, an inequality crisis and a jobs crisis, and the government’s only answer is: “get used to it, because it is the new normal”. Well, I refuse to adapt to kids wearing gas masks. I refuse to accept a world where people put off having kids because they are feeling so insecure about their jobs and their future. I refuse to accept people living below the poverty line in a country as wealthy as ours. And I refuse to accept the dismal standard of this rotten government led by Scotty from marketing, a man whose love of coal has helped drive the climate crisis that has made these fires worse, and a Labor so-called opposition that celebrates coal in the middle of bushfires and votes with the Liberals to give tax cuts to millionaires. We are a smart and wealthy country and if we have the guts to take on the big corporations and the weak politicians they have in their pocket, we can solve these crises. That is why we need a Green New Deal. A Green New Deal is a government-led plan of investment and action to build a clean economy and a caring society. The two elements of a Green New Deal – government taking the lead to create new jobs and industries, and universal services to ensure no one is left behind – are the values I have been fighting for my whole adult life. I joined the Labor party at high school, but left in university because the ALP started making education so expensive and putting people in debt. As a lawyer, I fought big corporations on behalf of clothing outworkers and represented firefighters as well as coal workers dealing with privatisation. And in my seat of Melbourne we have brought people together, from public housing tenants to young families with a mortgage. That’s what a Green New Deal will do too, because it solves the big challenges our country faces and provides a hopeful vision for the future that the whole country can support. While this has been a summer of complete devastation for our country, I remain hopeful that a better, fairer, safer world is possible. By fighting for a Green New Deal, we can not only address the challenges we face today, we also have the best ever opportunity to build a more just future. Throughout history, change has come when everyday people stand up and make their voices heard. The conservatives will do everything in their power to avoid tackling the climate emergency and the jobs and inequality crisis, so it’s up to us to shape the country we want to see. To build a future for our kids and grandkids and the generations to come after us. Change is possible. In 2010, with the Greens in balance of power, we delivered climate legislation and the carbon price, bringing down pollution for the first time in Australian history. With a Green New Deal, we can deliver a manufacturing renaissance, turning Australia into a renewable energy superpower exporting our clean energy to the world. At the same time, as Ross Garnaut has proposed, we can process our resources and minerals in Australia and attract new business investment because of our abundance of solar energy. And while the Greens were able to achieve dental into Medicare for 3.4 million children, with a Green New Deal we can ensure all dental is fully included under Medicare. We can make public schools genuinely free, rather than parents being lobbed with hundreds of dollars of additional fees every year. This is the change I believe our country needs. This is the country I know is possible and this is the change I’ll be fighting for. I hope all Australians will join us in this fight. • Adam Bandt is the leader of the Australian Greens"
"
Share this...FacebookTwitterCORRECTION: The chart below is misleading. The ARD has not changed its color scheme. The chart for 2009 shows the 3-day forecast, whose color coding according to ARD in fact has not changed.  The 2019 is the forecast chart for the day, and this 1-day chart uses a different color code for temperature. It too has not changed since 2009. The third chart, as already mentioned, is from another drama source: website: wetter.de. Hat-tip: reader Taylor Martin
=======================================
WARNING: Watching too much German public television will make you hysterical, and pretty stupid (if you’re already leaning in that direction)
Sometimes you really wonder: can people be fooled really so easily?
German ARD public television network apparently thinks so, and has since gone off the deep end with the hype, drama and disinformation they add to their reports. I guess they think it’s working.
At Facebook one person illustrated this very well by showing the evolution of weather charts used by ARD German television in 2009, 2019 and this year. If you were to rate numerically the level of redness and fiery imagery and plot it,  you’d get a real hockey stick trend. Check out the forecast chart evolution below:


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Hat-tip: Axel Robert Göhring at Facebook
In 2009, a nice hot summer day way forecast using pleasant color scheme of yellow and green. Even the “Samstag” (Saturday) forecast of highs from 19-25°C used the same green color scheme as it did for showing 34-36°C.
But as the years went by, Germans refused to panic enough about warming, and so by 2019 everything charts had to look hot and unbearable – even for forecasts of 20°C, see middle chart. Even temperatures in the 70sF look warm and toasty.
Then last year came doomsday prophet Greta with her inferno-visions and messages of hell. This year, weather forecast charts of highs in the 70s! to upper 80s are exploded in size, and made to look like explosion-like inferno images taken from beyond the gates of Hell. Just a note: I’m not sure if the 2020 chart is from ARD or another station, but you get the idea of what’s going on.
Also read here.


		jQuery(document).ready(function(){
			jQuery('#dd_579b3b87884f076d22b60daba2b95d2e').on('change', function() {
			  jQuery('#amount_579b3b87884f076d22b60daba2b95d2e').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000
Share this...FacebookTwitter "
"The latest UN climate talks, known as COP24, have just concluded. The supposed story this time was one of a grinding victory by the EU and developing nations over recalcitrant petro-states – Russia, the US, Kuwait and Saudi Arabia. These four, condemned as “climate villains” over the past week, worked to block the adoption of a critical IPCC report that detailed how woefully inadequate current international action was for limiting future climate change to 1.5C. Building on a previous COP in Paris in 2015, this meeting focused on writing the “rulebook” for the Paris Agreement, setting out how emissions will be measured, reported and verified. Absent at COP24 was any real discussion of how efforts to cut emissions would be increased, or targets raised from their current low level. This will be discussed at another meeting – another COP – in 2020. You could be forgiven for thinking this COP (short for Conference Of the Parties to the UN climate agreements) was no different to any of the previous COPs. As usual, there were a set of villains who were “holding up progress”. There was another scientific report spelling out how little time we have and how bad climate change will be if nothing changes. There was rancorous debate on technicalities, a sideshow debate around carbon markets, and no action on what to actually do. So far, so normal. Throughout its history very little has actually been achieved at the COP.  As things stand, we are still heading for 3℃ or more of global warming. We do not have 12 years to “do something” about it as the IPCC insists. Increasing numbers of commentators, journalists, scientists and environmentalists are breaking ranks from the “hopeful”, to argue that not only is far too little being done too late, but that dangerous climate change is already here.  Kevin Anderson of the Tyndall Centre for Climate Change Research, has consistently criticised IPCC reports for magical thinking, for assuming that at some point in the near future technology will be both invented and rolled out on a mass scale that will suck carbon dioxide from the atmosphere (so-called negative emission technologies). At the moment, there are none that are close to being ready to be mass produced. Take these out of the most recent IPCC report and instead of 12 years to stop dangerous climate change we have just three. Given all this, it could be tempting to blame the state of things on the climate villains – who doesn’t want to blame authoritarian or outright fascist government leaders for the world’s problems? But the problem isn’t bad leaders, but the entire system itself. The reality of climate change is that we need a radically different economic and political system if we are to limit future warming and ensure adaptation is fair and just. The COP reveals the limits of using nation states as the basis for action. Wedded to geopolitical realities and economic competition, states have not changed their behaviour to match the demands of climate science. In many ways it is unrealistic and naive to demand they do so. After all, they are not, as sometimes imagined, ships under the command of a single captain, able to direct the nation one way or another, but rather, complex assemblages where a huge number of actors and interested parties compete for wealth, power, access and influence.  Let’s be clear about what must be demanded of nation states: not some kind of minor adjustment or new zero-cost policy, but the end of economic growth. It would require legislating for de-growth, something that could be considered, after a decade of economic austerity, as electoral suicide. Legislating for de-growth is the right government policy, but the wrong approach. If the nation state is the wrong climate change actor, then the national economy is also the wrong perpetrator. Yet this is what every plan to combat climate change focuses on: national emissions. But this focus hides massive inequities within national populations and, more importantly, obscures both who is responsible for carbon emissions and who has the power to arrest them. It is really important that we – that is, the vast majority of humanity who will or already are suffering the effects of dangerous climate change – move past “national action plans” and start to take action immediately against two groups largely responsible for climate change. They are the 100 or so corporations responsible for 71% of global carbon emissions and the wealthiest 10% of the global population responsible for 50% of consumption emissions. To put the latter in perspective, if this 10% reduced their consumption to the level of the average European that would produce a 30% cut in global emissions.  Focusing on the wealthy and their corporations would enable us to bring about an immediate cut in carbon emissions. But it would also form part of a just transition, ensuring that the majority of the world’s population do not have to pay for climate policy, a conflict we have already seen on the streets of Paris in recent weeks in the yellow vests movement. 


      Read more:
      Gilets jaunes: why the French working poor are demanding Emmanuel Macron's resignation


 As we hurtle into 2019, we need to immediately shift to actions against the ultra-wealthy and the uber-powerful. It is long past time for changing how we talk about climate change. At some point we will need social movements capable of changing everything, but right now we need to relentlessly focus our actions on that small group of people profiting off the destruction of the world, and not wait in vain on governments to do it for us."
"
An odd twist has developed in the past week regarding some data sets that surfacestations.org volunteers have been using to look at individual stations. The data has changed on NASA’s GISS website with no notice whatsoever.
My first indication that something changed came from surfacestations.org volunteer Chris Dunn who wrote to me complaining that one of the sites he’d recently surveyed, Walhalla, SC had been greatly adjusted at GISS for no good reason that he could ascertain, since the site is pristine by climate monitoring standards, and has not gone through any significant changes in the past, and has been operated at the same location (by the same family) since 1916. He wondered why NASA would have to adjust the data for a “good” station. The way I view it, shouldn’t good data stand on it’s own? That was September 7th. He was using data from NASA GISS published on 8/28.
So he continued to look at the data, and the site. The on Sept 11th he noticed a change when he downloaded the data again. Something had changed, the data was different. Not only the adjusted data but the “raw” data too.
Steve McIntyre of Climate Audit has a complete review at: http://www.climateaudit.org/?p=2077 where he traces data back to Detroit Lakes, MN the station that started this all. See my original post on this: http://www.norcalblogs.com/watts/2007/08/1998_no_longer_the_hottest_yea.html
This set other people into motion looking at the NASA GISS data sets. The conclusion? NASA published new raw and adjusted data on their website with no formal or informal notice. I don’t know what to make of this, by I think perhaps this could be a breach of the Data Quality Act. At the least, it flies in the face of accepted scientific courtesy, where if you publish data sets being used by researchers worldwide, scientific courtesy would dictate that you at least place notice of such a change, otherwise there can be a domino effect for hundreds of research projects that use the data. Which would cause researchers to wonder why things don’t look the same anymore and begin searching for answers. Well that is exactly what happened here. We had a citizen trying to figure out why a climate site with good data was “adjusted”, and then the data changed right in the middle of him looking at it.
Whether this was accidental or intentional I cannot say, but it certainly does not look good coming on the heels of NASA GISS’s most recent issue of a mistake causing a revision of our temperature history on August 8th. We deserve better accounting than this when so much hinges on this data.
Let’s give NASA and Hansen the benefit of the doubt and see what they have to say about it.
UPDATE: NASA has posted today, their explanation which you can read here: http://data.giss.nasa.gov/gistemp/ Note that this notice appears a full week after the data changed (about 9/10) and only after there was discussion of the issue on blogs such as Climate Audit over the weekend. Why would NASA GISS not announce the change at the same time the data did, particularly when the announcment of the change ammounted to one small paragraph?


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea3fb385b',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

On Oct.10, Tom Daschle (D-SD), Senate Majority Leader and potential presidential candidate, ordered his own Energy and Natural Resources Committee to stop working on a National Energy Policy bill. He did this because a majority of that committee now favors drilling for a modest amount of oil in a tiny area of the remote Arctic National Wildlife Refuge (ANWR). Further, he has substitute‐​legislation in mind that goes beyond ANWR, calling for drastic changes in our energy structure.



Hopefully, Daschle will reconsider his actions on the energy bill. Although ANWR can supply only a small fraction of our energy, it is a political no‐​brainer. Who’s going to vote against domestic oil when we are at war? The emerging energy bill also encouraged the development of technologies to further reduce the already small atmospheric impact of coal combustion, promoting the increased use of this domestically abundant fuel.



But do we need any energy legislation? Coal is cheap and plentiful, and it is regulated via the Clean Air Act Amendments of 1990. If there’s the political will, go ahead and re‐​open those (though expect some opposition here). Drilling in the ANWR doesn’t require 30 pages of text; a few sentences will do.



However logical it might be to “do nothing here,” that’s not the way D.C. works. Instead, Daschle would like to substitute another bill, S.556, for large portions of the current energy legislation. The substitute‐​bill is sponsored by Jim Jeffords (?-VT). Instead of drilling in ANWR and developing cleaner coal technology, the bill looks a lot like the old Kyoto Protocol on global warming, which has wisely been rejected by President Bush because it is 1) expensive, and 2) scientifically indefensible. Jeffords’ bill mandates that we reduce emissions of carbon dioxide from power plants to 1990 levels by January 2007. Our national emissions are currently about 15 percent above 1990 levels. As we continue on our merry economic way, those emissions will go 20 percent above 1990 levels by 2007. To meet this law would therefore require a major energy reduction in a nation at peace, let alone in one at war.



Now, about 55 percent of the nation’s electricity is produced by the combustion of coal. Jeffords’ target could be met if somehow every coal‐​fired turbine was converted to natural gas. But we do not have the infrastructure to move that much gas, and, further, S.556 mandates “policies that would reduce the rate of growth of natural gas consumption” Without coal or natural gas, there’s only one significant source of power production left: nuclear. Does anyone seriously think that the same radical greens that pressured Daschle into all this will allow him to push nuclear power?



It gets worse. The substitute‐​bill also requires that 90 percent of mercury emissions be removed from power generation by 2007. There is only one way to do that: Stop burning coal. If this bill is passed, it will be against the law to use coal to produce appreciable amounts of electricity. That is mandated for a nation that has hundreds of years of coal supply, and depends upon the rest of the world for 60 percent of its oil. That is mandated for a nation that is currently fighting a war using oil‐​powered technology.



So what S.556 scuttles is more than just ANWR drilling, it is our domestic energy hole card. The result of the substitute‐​bill is that the country will become bereft of power. Jeffords’ bill makes energy prohibitively expensive even as it mandates an impossible result. All of this when there’s a war on.



How could such folly evolve? It all goes back to “genus: Extreme environmentalism, species: global warming.” You’d think this critter would at least go into hibernation given the current problems in the world. But instead it is flying stealthily through Congress while the public concentrates on the more important matters at hand.



How much additional global warming “gain” do we get for the Jeffords pain? We ran the United Nations’ own computer model, assuming their dire “storylines” (their word) for global warming and development. The amount of global warming that Jeffords’ bill prevents in the next 50 years is 0.04ºF. No one will be able to measure this against the natural variability of climate.



Do we need omnibus energy legislation when a few sentences will do? Worse, do we want to substitute a bill that will increase energy prices, have no demonstrable effect on climate, and outlaw an inexhaustible domestic source of energy?



If anybody has noticed that we are at war, it must be Sen. Daschle. Maybe it’s time to be a bit more conservative about domestic energy policy. There will be plenty of time to debate things like global warming after we win a victory that is much more assured by domestic energy security at this precarious moment in time.
"
"Following the sacking of Claire O’Neill as president of the forthcoming climate change talks in Glasgow, and her subsequent criticism of Boris Johnson (COP 26: Cameron was asked by PM to take over – but he said no, 5 February), I would suggest that the only UK politician of sufficient integrity, dedication and expert knowledge on the subject of climate change to take over is Caroline Lucas MP.Rose HarvieDumbarton • I wonder what the government will do to replace the huge tax receipts lost when petrol and diesel vehicles are banned. Answers on the back of an electricity bill, please.Ian MetcalfePerth • No, Larry Elliott is not the only economist who believes the UK to be better off (in the long term) outside the EU (Letters, 3 February). One of the others is Prof Bill Mitchell, of Newcastle University, Australia. Prof Mitchell is speaking in London on 20 February, so why not come along and ask him to explain his viewpoint?Mike EllwoodAbingdon, Oxfordshire • May I, a 95-year-old, second-generation Guardian reader, join the marmalade marathon (Letters, 5 February). This year I have made 6lb of grapefruit marmalade and 20lb of Seville orange. I hope to live to enjoy it all!Joy NalpanisReading, Berkshire • I have never made marmalade. But I still do create jams/chutneys for my friends. To keep them on their toes, I also write the labels. “Rosepetal and Earwig” was a favourite!Yvonne MalikWray, Lancashire • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"
I’m working on porting over to a new blogging platform. So there may be a delay in new content here. I’m trying out some ideas and themes, and it is looking promising.
When it’s all done, the URL will be announced. Stay tuned. Thanks to all who gave me feedback.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea3aa00f2',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Today I obtained the paper: LaDochy, S., R. Medina, and W. Patzert. 2007. Recent California climate variability: spatial and temporal patterns in temperature trends. Climate Research, 33, 159-169 You can download the paper in PDF format in its entirety here: ca_climate_variability_ladochy.pdf
I’ll post more on this paper later, but I wanted to make it available for everyone to read beforehand.
This paper references my good friend and colleague, Jim Goodridge, former California State Climatologist in its bibliography. As you may recall, I posted on Jim’s work here a couple of months ago. One of the maps that Jim has prepared, seen below, closely matches the mapped results from the LaDochy et al paper.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7ea24130c6',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterGerman libertarian site Die Freie Welt reports that German Extinction Rebellion activists protested against short-haul flights at several German airports earlier this week.
Lübeck / Munich
In Lübeck, 10 people tried to glue themselves to the runway with superglue, but the police were able to prevent the action. In Munich, people chained themselves to luggage trolleys.Even political figures took part, for example Lorenz Gösta Beutin, climate policy spokesman of Die Linke (The Left)  accompanied the protests in Lübeck, reports Freie Welt. “100 to 150 additional demonstrators protested outside the airport building.”
Düsseldorf
In Dusseldorf, one person even managed to get through security and onto a plane for Hamburg. The protester claimed to be a climate saver and shouted: “Please stop this plane. I am not prepared to fly. I want to get off. I am not prepared to sit down again.”
Many annoyed passengers reacted angrily. One passenger shouted, “Hey you arse—, sit back down”.  The activist claimed to represent everyone and that the issue was not about him.
“The earth is getting hot”, he declared, “Our mother nature is going to hell.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




According to witnesses, the activist tried to continue reading his speech, which he had written down, and stammered about “the end of the dear world”. The pilot was forced to to return the aircraft to the parking position so that the passenger could get off.
Berlin
In Berlin another activist made her way onto a plane and demanded passengers “disembark and stay on the ground” in order to keep domestic German flights from heating up the planet. “We are all threatened by an ecological collapse.”

BREAKING: Flugzeug in #Berlin #Tegel durch #ExtinctionRebellion Aktivisti gestört!!!Die sich täglich verschärfenden #Klimakrise weiter durch innerdeutsche Flüge anzuheizen ist Wahnsinn – Zeit auszusteigen und am Boden zu bleiben!#LuftBlock #ActNow #RebelForLife #stayGrounded pic.twitter.com/fevcjIAlse
— Extinction Rebellion Berlin 🌍 (@XRBerlin) August 17, 2020

The Freie Welt refuted the claims made by the Düsseldorf protestor, writing:

The figures actually say something completely different: domestic flights within Germany are responsible for just 0.3 percent of Germany’s CO2 emissions. In contrast, car traffic alone accounts for 20.8 percent. But you can imagine how motorists will react if activists stick themselves to the autobahn with super glue.”


		jQuery(document).ready(function(){
			jQuery('#dd_8a0034c297c24f880c76cad0fcfcb63f').on('change', function() {
			  jQuery('#amount_8a0034c297c24f880c76cad0fcfcb63f').val(this.value);
			});
		});
		
Donate - choose an amount5101520501002505001000

Share this...FacebookTwitter "
"This is an article from Head to Head, a series in which academics from different disciplines chew over current debates. Let us know what else you’d like covered – all questions welcome. Details of how to contact us are at the end of the article. Rob Bellamy: 2018 has been a year of unprecedented weather extremes around the world. From the hottest temperatures ever recorded in Japan to the largest wildfire in the history of California, the frequency and intensity of such events have been made much more likely by human-induced climate change. They form part of a longer-term trend – observed in the past and projected into the future – that may soon make nations desperate enough to consider engineering the world’s climate deliberately in order to counteract the risks of climate change.  Indeed, the spectre of climate engineering hung heavily over the recent United Nations climate conference in Katowice, COP24, having featured in several side events as negotiators agreed on how to implement the landmark 2015 Paris Agreement, but left many worried that it does not go far enough. Matt Watson: Climate engineering – or geoengineering – is the purposeful intervention into the climate system to reduce the worst side effects of climate change. There are two broad types of engineering, greenhouse gas removal (GGR) and solar radiation management (or SRM). GGR focuses on removing anthropogenically emitted gases from the atmosphere, directly reducing the greenhouse effect. SRM, meanwhile, is the label given to a diverse mix of large-scale technology ideas for reflecting sunlight away from the Earth, thereby cooling it. RB: It’s increasingly looking like we may have to rely on a combination of such technologies in facing climate change. The authors of the recent IPCC report concluded that it is possible to limit global warming to no more than 1.5°C, but every single one of the pathways they envisaged that are consistent with this goal require the use of greenhouse gas removal, often on a vast scale. While these technologies vary in their levels of maturity, none are ready to be deployed yet – either for technical or social reasons or both. If efforts to reduce greenhouse gas emissions by transitioning away from fossil fuels fail, or greenhouse gas removal technologies are not researched and deployed quickly enough, faster-acting SRM ideas may be needed to avoid so-called “climate emergencies”. SRM ideas include installing mirrors in Earth’s orbit, growing crops that have been genetically modified to make them lighter, painting urban areas white, spraying clouds with salt to make them brighter, and paving mirrors over desert areas – all to reflect sunlight away. But by far the best known idea – and that which has, rightly or wrongly, received the most attention by natural and social scientists alike – is injecting reflective particles, such as sulphate aerosols, into the stratosphere, otherwise known as “stratospheric aerosol injection” or SAI. MW: Despite researching it, I do not feel particularly positive about SRM (very few people do). But our direction of travel is towards a world where climate change will have significant impacts, particularly on those most vulnerable. If you accept the scientific evidence, it’s hard to argue against options that might reduce those impacts, no matter how extreme they appear. Do you remember the film 127 Hours? It tells the (true) story of a young climber who, pinned under a boulder in the middle of nowhere, eventually ends up amputating his arm, without anaesthetic, with a pen knife. In the end, he had little choice. Circumstances dictate decisions. So if you believe climate change is going to be severe, you have no option but to research the options (I am not advocating deployment) as broadly as possible. Because there may well come a point in the future where it would be immoral not to intervene. SRM using stratospheric aerosols has many potential issues but does have a comparison in nature – active volcanism – which can partially inform us about the scientific challenges, such as the dynamic response of the stratosphere. Very little research is currently being conducted, due to a challenging funding landscape. What is being done is at small scale (financially), is linked to other, more benign ideas, or is privately funded. This is hardly ideal. RB: But SAI is a particularly divisive idea for a reason. For example, as well as threatening to disrupt regional weather patterns, it, and the related idea of brightening clouds at sea, would require regular “top-ups” to maintain cooling effects. Because of this, both methods would suffer from the risk of a “termination effect”: where any cessation of cooling would result in a sudden rise in global temperature in line with the level of greenhouse gases in the atmosphere. If we hadn’t been reducing our greenhouse gas emissions in the background, this could be a very sharp rise indeed. 


      Read more:
      Time is running out on climate change, but geoengineering has dangers of its own


 Such ideas also raise concerns about governance. What if one powerful actor – be it a nation or a wealthy individual – could change the global climate at a whim? And even if there were an international programme, how could meaningful consent be obtained from those who would be affected by the technology? That’s everybody on Earth. What if some nations were harmed by the aerosol injections of others? Attributing liability would be greatly contentious in a world where you can no longer disentangle natural from artificial.  And who could be trusted to deliver such a programme? Your experience with the SPICE (Stratospheric Particle Injection for Climate Engineering) project shows that people are wary of private interests. There, it was concerns about a patent application that in part led to the scientists calling off a test of delivery hardware for SAI that would have seen the injection of water 1km above the ground via a pipe and tethered balloon. MW: The technological risks, while vitally important, are not insurmountable. While non-trivial, there are existing technologies that could deliver material to the stratosphere.  Most researchers agree that the socio-political risks, such as you outline, outweigh the technological risks. One researcher remarked at a Royal Society meeting, in 2010: “We know that governments have failed to combat climate change, what are the chances of them safely implementing a less-optimal solution?”. This is a hard question to answer well. But in my experience, opponents to research never consider the risk of not researching these ideas.  The SPICE project is an example where scientists and engineers took the decision to call off part of an experiment. Despite what was reported, we did this of our own volition. It annoyed me greatly when others, including those who purported to provide oversight, claimed victory for the experiment not going ahead. This belies the amount of soul searching we undertook. I’m proud of the decisions we made, essentially unsupported, and in most people’s eyes it has added to scientists’ credibility. RB: Some people are also worried that the promise of large-scale climate engineering technologies might delay or distract us from reducing greenhouse gas emissions – a “moral hazard”. But this remains to be seen. There are good reasons to think that the promise (or threat) of SRM might even galvanise efforts to reduce greenhouse gas emissions. MW: Yes, I think it’s at least as likely that the threat of SAI would prompt “positive” behaviour, towards a sustainable, greener future, than a “negative” behaviour pattern where we assume technology, currently imaginary, will solve our problems (in fact our grandchildren’s problems, in 50 years time). RB: That said, the risks of a moral hazard may not be the same for all climate engineering ideas, or even all SRM ideas. It’s a shame that the specific idea of stratospheric aerosol injection is so frequently conflated with its parent category of SRM and climate engineering more generally. This leads people to tar all climate engineering ideas with the same brush, which is to the detriment of many other ideas that have so far raised relatively fewer societal concerns, such as more reflective settlements or grasslands on the SRM side of things, or virtually the entire category of greenhouse gas removal ideas. So we risk throwing the baby out with the bathwater. MW: I agree with this – somewhat. It’s certainly true all techniques should be given the same amount of scrutiny based on evidence. Some techniques, however, often look benign but aren’t. Modifying crops to make them more reflective, brightening clouds, even planting trees all have potentially profound impacts at scale. I disagree a little in as much as we simply don’t know enough yet to say which technologies have the potential to reduce the impacts of climate change safely. This means we do need to be thinking about all of these ideas, but objectively.  Anyone that passionately backs a particular technology concerns me. If it could be conclusively proven that SAI did more harm than good, then we should stop researching it. All serious researchers in SAI would accept that outcome, and many are actively looking for showstoppers. RB: I agree. But at present there is very little demand for research into SRM from governments and wider society. This needs to be addressed. And we need broad societal involvement in defining the tools – and terms – of such research, and indeed in tackling climate change more broadly. 


      Read more:
      Why you need to get involved in the geoengineering debate – now


 MW: Some people think that we should just be getting on with engineering the climate, whereas others feel even the idea of it should not even be discussed or researched. Most academics value governance, as a mechanism that allows freedom to explore ideas safely and there are very few serious researchers, if any, who push back against this.  A challenge, of course, is who governs the governors. There are strong feelings on both sides – scientists either must, or cannot, govern their own research, depending on your viewpoint. Personally, I’d like to see a broad, international body set up with the power to govern climate engineering research, especially when conducting outdoor experiments. And I think the hurdles to conducting these experiments should consider both the environmental and social impact, but should not be an impediment to safe, thoughtful research. RB: There are more proposed frameworks for governance than you can shake a stick at. But there are two major problems with them. The first is that most of those frameworks treat all SRM ideas as though they were stratospheric aerosol injection, and call for international regulation. That might be fine for those technologies with risks that cross national boundaries, but for ideas like reflective settlements and grasslands, such heavy handed governance might not make sense. Such governance is also at odds with the bottom-up architecture of the Paris Agreement, which states that countries will make nationally determined efforts to tackle climate change.  Which leads us to the second problem: these frameworks have almost exclusively arisen from a very narrow set of viewpoints – either those of natural or social scientists. What we really need now is broad societal participation in defining what governance itself should look like. MW: Yes. There are so many questions that need to be addressed. Who pays for delivery and development and, critically, any consequences? How is the global south enfranchised - they are least responsible, most vulnerable and, given current geopolitical frameworks, unlikely to have a strong say. What does climate engineering mean for our relationship with nature: will anything ever be “natural” again (whatever that is)?  All these questions must be considered against the situation where we continue to emit CO₂ and extant risks from climate change increase. That climate engineering is sub-optimal to a pristine, sustainably managed planet is hard to argue against. But we don’t live in such a world. And when considered against a +3°C world, I’d suggest the opposite is highly likely to be true. If there’s a specific topic or question you’d like experts from different disciplines to discuss, you can:"
"
Share this...FacebookTwitterA new temperature reconstruction indicates today’s sea surface temperatures are colder than all but a few millennia out of the last 156,000 years.
A Southern Ocean site analyzed in a new study (Ghadi et al., 2020) has averaged 1-2°C during glacials and 4°C during interglacials. Today, with a 410 ppm CO2 concentration, this location has again plummeted to glacial/ice age levels (2°C).
The site was 2°C warmer than now when CO2 concentrations were 180 ppm about 20,000 years ago, or during the peak of the last ice age. During the Early Holocene (10,000 to 8,000 years ago), summer sea surface temperatures were also 2°C warmer than today.
There is no indication that CO2 concentration changes are in any way correlated with temperature changes throughout this entire 156,000-year epoch.

Image Source: Ghadi et al., 2020
Share this...FacebookTwitter "
