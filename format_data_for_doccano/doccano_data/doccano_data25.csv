"
Share this...FacebookTwitterA new paper written by Maeng-Ki Kim, Department of Atmospheric Science, Kongju National University, and Seonae Kim of the Applied Meteorology Research Team, Environmental Prediction Research Inc. of Korea has been published by the Journal of Atmospheric Environment.The two scientists examined cities in South Korea and the urban heat island effect. Hat-tip: Dr. Ghana.
According to the abstract here (emphasis added):
The quantitative values of the urban warming effect over city stations in the Korean peninsula were estimated by using the warming mode of Empirical Orthogonal Function (EOF) analysis of 55 years of temperature data, from 1954 to 2008. The estimated amount of urban warming was verified by applying the multiple linear regression equation with two independent variables: the rate of population growth and the total population. […] The cities that show great warming due to urbanization are Daegu, Pohang, Seoul, and Incheon, which show values of about 1.35, 1.17, 1.16, and 1.10°C, respectively. The areas that showed urban warming less than 0.2°C are Chupungnyeong and Mokpo. On average, the total temperature increase over South Korea was about 1.37°C; the amount of increase caused by the greenhouse effect is approximately 0.60°C, and the amount caused by urban warming is approximately 0.77°C.”
According to their results, that means well over a half of the warming is caused by urban warming.
Why aren’t we surprised? Anyone who has read Ed Caryl’s very recent stories here at this blog and is familiar with Anthony Watts’s surface stations audit knows why.
 
Share this...FacebookTwitter "
"People like to say that we cannot witness evolution because it occurs over timescales immensely greater than our lifetime. That’s incorrect. We can witness evolution all we want, in our lifetime, by watching other things that change and morph freely – for example the evolution of sports, or the evolution of technology. Evolution in technology is the same as the evolution of a biological species. The ‘organism’ in this case is the human-and-machine species. Machines do not happen by themselves; they are created by humans, because of human needs, and it is humans that add the abilities of their creations to their own in order to improve them – to make their bodies move more easily, or more economically, more safely, or further over the earth. More technology tends towards more and better life. Evolution is about facilitating flow, the movement of one thing over or past another. Flow systems, the designs created by this evolutionary process, change freely over time. As such, evolution is a physical phenomenon, not just a biological one. The changing organisational structures that facilitate greater and better flow are physical objects, whether animate or inanimate. In an article just published in the Journal of Applied Physics, we documented the evolution of a single technology – aircraft. We predicted this evolutionary path based on the laws of physics and their application to how designs evolve in the natural world. This is the constructal law: for a flow system to persist in time (in effect, to live) its configuration must evolve to allow greater and easier access to its currents.   We showed that aircraft must have predictable (theoretical) design features that unite them with the birds and other flying animals. For example, larger aircraft must be faster, more efficient as vehicles and must cover greater distances. The engine weight must be proportional to the total body weight; this scaling is the same throughout animal design, where the size of the body parts driving the movement (muscle, heart, lung) is proportional to the body size.  Large or small, an aircraft must have a wing span that is proportional to the fuselage length. The fuel load must be proportional to the body size. The animal design counterparts of these human-designed, technological features are evident. Looking at how these evolutionary laws govern the current trend followed by aircraft until now, we can predict the same laws will govern how aircraft will change into the future. We’ve used the constructal law to predict the design features of many other seemingly unrelated natural phenomena. For example, the shape of river basins (four tributaries feeding into one larger channel), vegetation (roots, trunks, branches, forests), animal design (body insulation, respiration, blood circulation, skeleton, and ability to swim, run, or fly) and the wheel as a natural rather than human design. It has also explained human phenomena such as the evolution of sports (speed vs body size for sprint running or swimming, throwing sports such as baseball, golf and boxing), social organisation (rankings of universities and sports teams, urban design, city traffic), and the evolution of many types of technology such as electronic cooling, steam and gas turbines, power plants, refrigeration plants. The view that emerges is that the phenomenon of evolution is much broader and more visible than simply biological evolution. The constructal law unites the evolutionary designs of the realm of animate creatures with those of the inanimate, social and engineered.  What works is kept. Architectures that offer greater and improved access to flow persist over time, and are joined by even better ones. Together, the vascular tapestry of old and new designs carries the global human flow – from the microscopic to the macroscopic level – easier and farther than the old alone. To return to the example, new and old designs for mass transport by air provide a more effective mechanism to aid mixing and flow of people around the globe more effectively than in the absence of new models.  Flow leads to better flow. Flow architectures are evolving right now, throughout nature and throughout our technologies, in accord with the constructal law. Evolution is one phenomenon of nature, and it belongs under physics, the biggest tent of science."
"

Mr. Chairman and members of the committee, thank you for inviting me to testify today regarding energy efficiency and the federal tax code.



Additional tax incentives, such as tax credits, probably could reduce U.S. energy consumption modestly.1 However, narrow incentives complicate the tax code, create distortions that reduce growth, and move down the slippery slope of widespread social engineering through the tax system.



On the other hand, Congress should reform tax provisions that hinder new investments in energy production and conservation. Current business depreciation rules for energy and conservation investments are unfavorable compared to the rules in other countries. Congress should reform those rules, and it should pursue broader tax reforms to spur more rapid replacement of older structures and equipment with newer, more energy efficient infrastructure throughout the economy.



Policymakers have long considered major reforms to the federal tax system. Some favor a broad‐​based consumption tax, while others favor a broad‐​based (or Haig‐​Simons) income tax. The difference between the two is the treatment of savings and investment. Consumption taxes apply one layer of tax to savings and investment, while income taxes apply two layers. The current federal “income tax” is a hybrid between the two systems.



Reforms to move the current tax code toward a consumption‐​based system dovetail with the goals of those concerned about America’s energy future. A consumption tax would limit current consumption, including energy consumption, while removing tax barriers to investment‐​including investment in energy production, energy technologies, and energy conservation. As discussed below, more favorable depreciation rules would be an important step in a consumption tax direction.



The federal tax system has become enormously complicated in recent years. The anti‐​investment bias and high tax rates under the current system have encouraged the proliferation of narrow loopholes and special preferences. There seems to be more interest on Capitol Hill these days in creating new tax credits than in simplifying the tax code to provide fair and equal treatment of all taxpayers.



By contrast, during the 1980s there was bipartisan agreement that the tax code should be reformed to have a broad and neutral base with low rates. One congressional leader on tax reform at the time, Richard Gephardt (D-MO), noted in 1985:



The main argument for tax reform, I believe, is to achieve greater efficiency in the way the tax code works. When Congress gets into the business of figuring out $370 billion of tax breaks a year, the House Ways and Means Committee and the Senate Finance Committee really are put in the business of trying, at least partially, to plan the American economy. … I confess that I am not qualified to act as a central planner and I do not know anybody on either committee who is.2



The Reagan administration held similar views about tax reform. The Congressional Research Service noted that the administration



opposed using the tax law to promote oil and gas development, energy conservation, or the supply of alternative fuels. The idea was to have a more neutral and less distortionary energy tax policy, which economic theory predicts would make energy markets work more efficiently and generate benefits to the general economy.3



The two parties came together and agreed on the landmark Tax Reform Act of 1986, which ended many narrow tax breaks and reduced rates.4 Unfortunately, “central planning” through the tax code has come back into vogue since then. The number of pages in the federal tax code, regulations, and related rules has increased from 40,500 in 1995 to 67,204 in 2007, an increase of two‐​thirds.5



The number of narrow provisions, or loopholes, in the tax code is rising. Figures 1 and 2 show the number of “tax expenditures” in the income tax, based on data from the Office of Management and Budget.6 The number of tax expenditures for energy jumped from 11 to 23 between 1996 and 2006. The total number of tax expenditures increased from 121 in 1996 to 161 in 2006.



There are problems with these measures of tax expenditures. Some items, such as accelerated depreciation, are counted as loopholes under the income tax. But such pro‐​investment provisions would not be considered loopholes under a consumption tax. Nonetheless, the OMB’s tally of tax expenditures shows that Congress is moving away from the ideal of a neutral tax base toward micromanagement of the economy.





The rising number of narrow provisions in the tax code reduces economic efficiency. Such provisions distort market price and profit signals, which redirects capital and labor into less productive uses. That’s why a tax code with a neutral base and low rates is preferable to one with narrow carve‐​outs and high rates. The economic cost of today’s Swiss cheese tax base is large. U.S. output would be substantially higher if the tax base were reformed and effective tax rates across industries were equalized and reduced.7



Going forward, creating new tax incentives for energy and conservation would exacerbate these complexity problems. New tax incentives would add to the paperwork burden, create more errors in tax administration, further confuse economic decisionmaking, and provide further reason for the IRS to dig into personal affairs.



Current federal tax incentives for energy and conservation are not large. Total income tax expenditures for these items are valued at just $7 billion in 2007.9 That represents just 0.3 percent of total federal revenues. Thus, the discussion about tax incentives for energy and conservation is not a discussion about how high federal taxes ought to be.



Instead, the important issue for policymakers is to consider the sort of tax code that America ought to have. Should we have a tax code that treats families and businesses as equally as possible? Or should we have a tax code full of special provisions that treat people differently as Congress micromanages family and business decisions? I favor the former. After all, equality under the law is a bedrock American principle.



Proponents of tax incentives no doubt think that their favored activities deserve special attention. Many energy and environmental analysts argue that federal tax policies should be used to fix “externalities” in energy markets.10 But such an approach risks opening a Pandora’s box of widespread social engineering through the code.



Many interest groups, such as those promoting education, housing, and scientific research, argue that their favored activities are subject to externalities that need special tax code treatment. But, in theory, there are an endless number of externalities that governments could meddle in. At the risk of promoting bad ideas, tax lobbyists could champion tax credits for



I’m not advocating these tax credits, but they illustrate the slippery slope of social engineering if Congress wanted to fix every externality through the tax code. Just this year, the CRS finds that more than 150 bills on energy efficiency and renewable energy have been introduced, with many proposing narrow tax breaks. I hope Congress resists the temptation to create more tax loopholes.



The Congressional Research Service noted that the “Reagan administration believed that the responsibility for commercializing conservation and alternative energy technologies rested with the private sector and that high oil prices … would be ample encouragement for the development of alternative energy resources.“11 I think Reagan got it right.



Competitive markets have made a huge contribution toward America’s energy security and conservation. Businesses, for example, have powerful market incentives to reduce energy consumption. They are relentless in cutting costs‐​labor costs, tax costs, production costs, fuel costs, heating costs, cooling costs, and lighting costs. Lower costs mean higher profits. That’s why businesses strive continually to improve efficiency, including energy efficiency, particularly in today’s competitive global economy.



Market forces are behind huge improvements in U.S. energy efficiency in recent decades. The amount of energy consumed for each unit of gross domestic product has fallen dramatically since the 1970s. Economist Gilbert Metcalf found that if U.S. energy intensity were still at the level of 1970, the nation would be consuming 187 quadrillion BTUs annually.12 Instead, the United States consumes just 98 quadrillion BTUs annually, and thus we have cut our energy intensity almost in half since 1970.



Some of this improvement stemmed from the changing structure of the U.S. economy. But Metcalf calculates that at least two‐​thirds of the improvements since 1970 came from rising energy efficiency. And much, perhaps most, of that I think is due to the natural competitive processes in the economy, not government policy.



Consider the rising energy efficiency of household appliances. Federal efficiency standards for appliances went into effect in 1990, and appliance efficiency has improved since then. But appliance efficiency also improved markedly between the early 1970s and 1990, apparently as a market response to rising electricity prices.13 The average energy consumption of U.S. refrigerators fell from 1,800 kWh per year in 1974 to just 800 kWh by 1990.



If Congress does not change efficiency standards or enact new tax credits for energy conservation, it seems likely that U.S. energy intensity will continue to fall in coming years due to natural market forces.



Congress can make tax policy reforms to improve energy efficiency. A first step would be to end any tax provisions that encourage excess energy consumption. A good example are the tax preferences for owner‐​occupied homes, which some economists think favor the acquisition of particularly large homes.14 Larger homes need more heating, cooling, and lighting. Thus, one reform would be to combine repeal of the mortgage interest deduction with marginal tax rate cuts.



Another avenue for reform would be to reduce the tax code’s bias against capital investment. The income tax encourages current consumption and discourages long‐​term investment. To fix this bias, Congress should consider more favorable depreciation rules, optimally moving toward immediate expensing of capital purchases. That would remove barriers to all types of investments including those in energy production, alternative fuels, and conservation technologies. The Energy Policy Act of 2005 took some modest steps in this direction, but more could be done.15



Policymakers often say that America needs more job‐​creating investments in computers, automotive plants, transportation, and other activities. Those concerned with energy policy seek greater investment in electricity generation and transmission, oil refining, alternative fuels, pollution control, and conservation technologies. Thus, more favorable tax treatment of capital investment should be a common cause on Capitol Hill.



A new study by Ernst & Young and the American Council for Capital Formation shows that the current tax code stands in the way of energy and energy efficiency investments.16 The study compared U.S. cost recovery, or depreciation, rules to the rules in 11 other countries for 11 types of energy investment. Faster write‐​offs of assets over shorter periods of time reduce effective tax rates on new investment.



The study found that the United States has less favorable tax rules than most other countries for investments in petroleum refining, electricity, pollution control equipment, electricity smart meters, and other items. Here are the results for capital cost recovery after the first five years of an investment:



Consider electricity smart meters. If a U.S. utility installed these assets, it would take depreciation deductions worth 30 percent of the cost over the first five years. The comparable cost recovery values in other countries are Canada (63 percent), Germany (63 percent), Korea (58 percent), and Malaysia (90 percent).



America’s less favorable depreciation rules combined with the industrial world’s second‐​highest corporate tax rate creates a barrier to investment in new and traditional energy technologies. Because Congress is concerned with energy security, conservation, global warming, and high gasoline prices (partly caused by restricted refining capacity), it should focus on removing tax barriers to investment in energy production and energy efficiency.



Congress should consider reinstating the 50 percent capital expensing provisions that were in place in 2003 and 2004.17 That would spur economic growth while promoting the replacement of all types of older business assets with new, more efficient assets. New machines don’t just replace similar old ones, they embody new technologies that increase economic and energy efficiency.



Thank you for holding these important hearings. I look forward to working with the committee on energy tax policy issues.



1 Kevin Hassett, “The Role of Tax Incentives in Energy Policy,” American Enterprise Institute, July 10, 2001. For a history of federal tax incentives, see Chris Edwards, Ada Rousso, Peter Merrill, and Elizabeth Wagner, “Cool Code: Federal Tax Incentives to Mitigate Global Warming,” National Tax Journal 51, no. 3 (September 1998).



2 Richard Gephardt, “The Economics and Politics of Tax Reform,” Cato Journal 5, no. 2 (Fall 1985): 458.



3 Salvatore Lazzari, “Energy Tax Policy: History and Current Issues,” Congressional Research Service, July 28, 2006, p. 5.



4 However, the 1986 Act had numerous anti‐​savings and anti‐​investment provisions.



5 This page count is based on CCH data. See Chris Edwards, “Income Tax Rife with Complexity and Inefficiency,” Cato Institute Tax & Budget Bulletin no. 33, April 2006.



6 Budget of the U.S. Government: FY2008, Analytical Perspectives, p. 291.



7 The literature is summarized in Chris Edwards, “Options for Tax Reform,” Cato Institute Policy Analysis no. 536, February 24, 2005.



8 CCH, “CompleteTax Survey Suggests Taxpayers Confused by Tax Code Complexity,” March 16, 2005.



9 Budget of the U.S. Government: FY2008, Analytical Perspectives, p. 291.



10 For background on the history and purposes of federal energy policy, see Gilbert Metcalf, “Federal Tax Policy Towards Energy,” National Bureau of Economic Research, Working Paper no. 12568, October 2006.



11 Salvatore Lazzari, “Energy Tax Policy: History and Current Issues,” Congressional Research Service, July 28, 2006, p. 5.



12 Gilbert Metcalf, “Energy Conservation in the United States: Understanding Its Role in Climate Policy,” National Bureau of Economic Research, Working Paper no. 12272, May 2006, p. 2. See also International Energy Agency, “The Experience with Energy Efficiency Policies and Programs in IEA Countries,” August 2005.



13 Ronald Sutherland, “The High Costs of Federal Energy Efficiency Standards for Residential Appliances,” Cato Institute Policy Analysis no. 504, December 23, 2003, p. 5.



14 The homeowner tax preference results from the combination of the mortgage interest deduction and the exemption from taxable income of imputed rent on homes.



15 For a discussion of the 2005 law and background on the depreciation of energy assets, see Gilbert Metcalf, “Federal Tax Policy Towards Energy,” National Bureau of Economic Research, Working Paper no. 12568, October 2006.



16 Ernst & Young for the American Council for Capital Formation, “International Comparison of Depreciation Rules and Tax Rates for Selected Energy Investments,” May 2, 2007.



17 For background, see Christopher House and Matthew Shapiro, “Temporary Investment Tax Incentives: Theory With Evidence from Bonus Depreciation,” National Bureau of Economic Research, Working Paper no. 12514, September 2006.
"
"

 _Global Science Report_ _is a weekly feature from the_ _Center for the Study of Science_ _, where we highlight one or two important new items in the scientific literature or the popular media. For broader and more technical perspectives, consult our monthly “Current Wisdom.”_   
  
When it comes down to scaring people into accepting onerous reductions in carbon dioxide emissions, it’s always a good idea to trot out the specter of increased hurricanes, despite the lack of backing for this in the science literature.   
  
“Bluster” isn’t the name of an Atlantic hurricane (although it would be a good one*), but rather our description of the stories about new research out of the Massachusetts Institute of Technology projecting an increase in the frequency and magnitude of hurricanes as a result of anthropogenic climate change.   
  
Publishing in the _Proceedings of the National Academy of Science_ , M.I.T.’s Kerry Emanuel projects a rather large increase in the global frequency of tropical cyclones as well as their intensity over the course of the 21st century.   
  
Emanuel is the first to admit that the changes he found were largely of a different character to those in the generally accepted literature, which projects little change in the frequency of tropical systems (with perhaps even a slight decline) and only a slight increase in the future intensity.   
  
The difference between Emanuel’s results and those from the bulk of other studies arises primarily for two reasons; 1) the future emissions scenario used to drive the global climate models; and, 2) the method of downscaling coarse climate model output to the finer scale necessary to model tropical cyclones.   
  
When it comes to emission scenarios, Emanuel chooses to use the most extreme scenario, which more than triples the effective atmospheric carbon dioxide concentration by the end of the century, while most other studies have used a more modest scenario which leads only to about a doubling. With new technologies opening up vast abundances of lower CO2-emitting natural gas available for power generation, the extreme emissions scenario used by Emanuel seems unlikely.   




(This might also prompt the question as to why it was necessary to use the extreme scenarios in the draft “National Assessment” of climate change released in January by federal climatologists. See our voluminous comments here).   
  
With regard to the downscaling methodology, another paper, to be published later this year, uses a different procedure and arrives at nearly the opposite result. In the North Atlantic basin—the area in which the bulk of tropical cyclones which effect the United States occur—Thomas Knutson (of the Geophysical Fluid Dynamics Laboratory) and colleagues find a _decline_ of hurricane frequency of nearly 25 percent with an intensity increase of only about 6 percent.   
  
It’s worth noting that, according to research by Wang et al. (2011) and Murakami et al. (2012), future storms are actually more likely to remain at sea rather than striking the U.S.   
  
Emanuel, on the other hand, finds increases in both frequency and intensity of storms in the North Atlantic. Emanuel notes that further research into the difference produced with his model compared with Knutson’s “may prove enlightening.”   
  
We concur.   
  
The bottom line is that the significance of the results of Emanuel’s new study depends on an extreme emissions/warming scenario and a methodology which needs further evaluation. And even so, the changes reported by Emanuel in the North Atlantic, the area or primary concern for U.S. interests, do not rise above the noise of natural variability for many decades into the future.   
  
Contrary to the media bluster being generated by the new study, the true bluster of future hurricanes impacting the U.S. will likely be little different in the coming century than it was during the last—with any impact of anthropogenic climate change lost in the noise of the natural system.   
  
As with most global warming scare stories, cocksure stories about increased hurricane activity are a bit blustery.   
  
**References:**   
  
Emanuel, K., 2013. Downscaling CMIP5 climate models shows increased tropical cyclone activity over the 21st century. _Proceedings of the National Academy of Sciences_ , do:10.1073/pnas.1301293110   
  
Knutson, T., et al., 2013. Dynamical Downscaling Projections of Twenty-First-Century Atlantic Hurricane Activity: CMIP3 and CMIP5 Model-Based Scenarios. _Journal of Climate_ , doi:10.1175/JCLI-D-12-00539.1, in press.   
  
Murakami, H., et al., 2012. Future Changes in Tropical Cyclone Activity Projected by the New High-Resolution MRI-AGCM. _Journal of Climate_ , 25, 3237–3260. doi: 10.1175/JCLI-D-11-00415.1.   
  
Wang, C., L. Hailong, S-K. Lee, and R. Atlas, 2011. Impact of the Atlantic warm pool on United States landfalling hurricanes. _Geophysical Research Letters_ , 38, L19702, doi:10.1029/2011GL049265. 




"
"Government should budget to spend £10 per cyclist by 2020 in order to make bicycle travel safer, according to a committee of MPs. The report of the Transport Committee also called for a “change in culture” across departments, so that cycling is supported at all levels of government.  Leaving aside the issue of whether £10 per head (up from £2) by 2020 is sufficiently ambitious, comfortably distant in parliamentary terms as it is, the report’s most notable call is for the number of cycling casualties to decrease – 109 cyclists were killed on UK roads last year, and another 3,000 seriously injured – and for the amount of cycling to increase at the same time.   This latter point is very important. The tendency to ignore risk-exposure has long been characteristic of Department for Transport reports, which trumpet decreases in pedestrian and cyclist casualty numbers without showing whether the number of walking and cycling trips has changed. Logically, celebrating a reduction in pedestrian casualties without asking whether people are walking less is like saying dinosaurs are the safest form of travel because no dinosaur riders were hurt last year. So it’s encouraging to see this considered. The next problem is how to measure that risk of injury – incidents per cyclist, per kilometre, per journey, or per day? Each will paint a very different picture.  The report also illustrates a key debate within bicycle safety circles over recent years: are cyclists’ needs best met by making roads safer places to cycle, reducing the dangers imposed by motorists, or by providing dedicated cycle infrastructure?  The argument goes that, as the UK already has an excellent network of roads to almost anywhere a person might want to reach, if this network could just be made safe for cyclists then cycling would be a practical form of transport for most people. The committee talks about taming roads by, for example, making it easier for local authorities to introduce 20mph speed limits and holding the haulage and construction industries to account for the disproportionate number of cycling deaths their members cause. Are such approaches feasible? The idea that people operating heavy machines will inevitably make dangerous mistakes, even if they don’t want to, is the starting point for how we operate aviation, maritime and rail transport systems, to say nothing of industrial workplaces. In these industries, human error is seen as inevitable and systems are put in place to prevent accident or disaster. But governments have never really addressed this issue for those driving motor vehicles on the roads, even though traffic psychologists have long drawn attention to how errors and lapses are normal features of driving. Lower speed limits could mitigate the effects of driver error – less speed means reduced energy on impact and greater time for drivers to react. But this would only work if drivers are sufficiently convinced the new limits are a good idea, and motivated to obey them. Traffic psychology research also shows that drivers’ deliberate violations of traffic rules cause dangers, and a person already happy to drive recklessly is unlikely to be made more safe for others by the imposition of further rules for them to ignore. And this is to say nothing of the risks to rural cyclists who are never going to get their roads reduced to 20mph.  This is why many cycle safety campaigners instead look to improving infrastructure, a solution the committee also raises. However, not all cycling infrastructure is equal. Research has shown that on-road features such as bicycle lanes can lead to motorists blindly following the paint on the road rather than making proper judgements, increasing the risk to riders. So many campaigners today prefer the idea of “gold standard” segregated cycle infrastructure, as found in cycling-friendly countries such as Denmark, Belgium and the Netherlands. This protects cyclists from the danger posed by drivers by using physical separation, which is still effective even with a proportion of reckless or intentionally dangerous motorists.  The key question to arise from this report is whether there can be sufficient impetus to change to established practices across Whitehall required to ensure good-quality segregated infrastructure is provided in the future? My feeling – putting aside one misguided comment about everybody respecting everybody else, which ignores the hugely different levels of harm each road user can inflict – is that the committee’s heart is in the right place. But I am not convinced much will happen. It’s encouraging to see demands for cycling to become safer, and also feel safer. This is the critical shift required to move cycling from something unusual used by a stubborn minority, to something ordinary used by commuters, children and older people. And the committee is right to believe that achieving this kind of change will require banging a lot of heads together across Whitehall.  But I wonder if they realise just how big a task this entails – if we truly want to normalise and encourage cycling, fundamental changes are needed everywhere: planning laws that prevent out-of-town shopping centre sprawl, the health service (doctors should ask if you use sedentary travel before they ask whether you smoke, given the former is a better predictor of premature death), in education, in business. Above all, we must stop making motoring the cheapest, easiest, and most “standard” form of travel, and go further to ensure the true cost of vehicle use is paid by those that use them.  Motor vehicles are of course useful and definitely have a role. But that role should not include, for example, using a five-seat vehicle to move a single person less than 5 urban kilometres. That’s what bicycles are for. We’ll know we have a culture that truly values cycling when we see a government’s message to an able-bodied person driving alone across town is: “What’s wrong? Is your bike broken?”"
"

A few weeks ago, Senator Josh Hawley wrote a _New York Times_ op‐​ed calling for “abolishing” the World Trade Organization (WTO). I responded to Hawley’s piece here, pointing out the various ways that he had misunderstood the WTO. Hawley’s op‐​ed was apparently intended to lay the foundation for the joint resolution he introduced to withdraw the United States from the WTO. As I noted here, a Senate vote on this resolution is likely in late July.



Over in the House, two Congressmen, Peter DeFazio and Frank Pallone, introduced their own WTO withdrawal resolution. DeFazio had an op‐​ed in _The Hill_ recently, in which he also tried to make the case for the United States leaving the WTO. Due to a rule change passed last week, it now looks extremely unlikely that this resolution will come to the House floor for debate and a vote. Nevertheless, for the sake of completeness, I’m going to respond to his piece as well. I’m not sure I have it in me to address each and every one of his points, but I’ll try to deal with a lot of them. Here goes.



DeFazio says:



Since its establishment in 1995, but even more so since China joined in 2001, the WTO’s ban on Buy American and other domestic procurement preferences, its protections for foreign investors, and its lack of rules against currency misalignments and other forms of unfair trade practices have promoted the outsourcing of American production capacity and decimated well‐​paying manufacturing jobs.



In truth, the WTO doesn’t “ban” Buy American and other procurement preferences, but rather countries can negotiate to open their procurement markets to each other. Many countries have joined the WTO’s Government Procurement Agreement, and have made market‐​opening commitments. Through this process, the United States has opened some (but far from all) of its procurement to foreign bidders, in exchange for U.S. bidders being allowed access to foreign procurement markets. But we are not completely open (although I wish we were, aside from legitimate national security issues), and Buy American procurement preferences still exist. There is, in fact, a federal Buy American Act, which was recently tightened by the Trump administration, as well as state and local procurement preferences.



As for “protections for foreign investors,” this refers to a controversial aspect of many bilateral and regional trade agreements, under which foreign investors can sue governments directly in an international tribunal (I am skeptical of this myself). But the WTO doesn’t have anything like this, so DeFazio can relax. DeFazio should, however, join the debate over foreign investor protections that is going on in the context of bilateral and regional trade agreements.



With regard to “currency misalignment,” the WTO does actually have a vague provision on this (GATT Article XV:4: “Contracting parties shall not, by exchange action, frustrate the intent of the provisions of this Agreement, nor, by trade action, the intent of the provisions of the Articles of Agreement of the International Monetary Fund.”) But DeFazio is free to propose something more detailed and encourage the U.S. government to put it forward for discussion at the WTO. In addition, it is worth noting that the Department of Commerce (DOC) is currently pushing ahead with its own efforts to use countervailing duties to address what it considers to be currency manipulation that leads to a subsidy causing injury to a domestic industry. The WTO does not have specific rules on this, but if the DOC’s actions are challenged there, the general WTO obligations on subsidies/​countervailing duties will be applied.



DeFazio then offers the following:



These are the facts: a quarter of U.S. manufacturing jobs – roughly 5 million – lost. Sixty thousand U.S. factories shuttered. A U.S. goods and services trade deficit explosion of 265 percent, from $170 billion in 1994 to $617 billion in 2019.



There is plenty to dispute with these jobs and factories numbers, but let’s put that aside for now. The figures he presents are not as relevant to the WTO debate as he seems to think. Yes, manufacturing employment has gone down, as the United States has been moving away from relying on manufacturing to employ vast numbers of people, just like hundreds of years ago we moved away from large‐​scale employment in agriculture. This is partly due to increased productivity (including through automation): As we get more efficient in production, we need fewer people to work in factories. And some of it is due to general shifts in the economy over the years. But it’s surely true that some amount of U.S. manufacturing jobs were lost due to competition with foreign producers. It’s also true, however, than many jobs were gained due to increased exports. And it’s most important to point out all the gains to U.S. consumers from this increased trade and competition. You could, in theory, shield your economy from foreign competition and manufacture everything yourself. But centuries of experience with governments using this strategy shows pretty clearly that it does not make you better off.



As for the trade deficit, Cato colleagues of mine have debunked this point many times in the past, including here, here, and here.



Back to DeFazio:



The WTO has promoted corporate protectionism while banning commonsense consumer safeguards. In fact, WTO terms required the U.S. to extend for three years monopoly protections for pharmaceutical firms that they use to charge sky‐​high prices. …



I assume that he is referring here to the extension of patent terms from 17 years to 20 years as part of the Uruguay Round negotiations which created the WTO. But stronger intellectual property rules was something the U.S. government supported. If he wants to make the case for going back to 17 years, I have no objection, but it’s not like “the WTO” did this. The U.S. government was on board with it the whole time and that’s why it’s part of WTO rules.



DeFazio then tries to argue about the fairness of WTO dispute settlement as follows:



The WTO rules and dispute settlement system are so lopsided that the U.S. has lost a staggering 90% of the cases attacking U.S. policies.



This is some wonderful cherry‐​picking of data. He’s not too far wrong, it’s just that he forgot to mention that the United States has won even more of the cases it brought to “attack” foreign government policies. The explanation here is that governments tend to be pretty circumspect about bringing WTO complaints, and the result is that most of the ones that are brought are successful.



Putting aside all of these errors, omissions, and deceptions, what does DeFazio want to see happen now?



A withdrawal vote would put our trading partners on notice that after decades of trade deals and systems that have led to weakened supply chains, structural trade imbalances, and massive income inequality, there is bipartisan appetite for transformative change.



As the largest economy in the world, the U.S. has a powerful hand to play, and we should use it to advocate for new rules, including strong and enforceable labor and environmental safeguards, and a more level playing field. In doing so, we can — and we must — address the understandably immense frustration among Americans whose lives have been ruined by trade policies that put corporate profits over working people.



At a moment where authoritarian nationalism is on the rise, it is also essential that the U.S. bring the world’s democracies together to make the case for a fair and resilient form of global cooperation, encouraging multilateral responses to the pandemic crisis, shared security, marginalization, and climate change.



I can get on board with “bringing the world’s democracies together” and “advocating for new rules” (perhaps not the same ones DeFazio wants, of course). I have suggested some improvements to the WTO myself. But if he thinks U.S. withdrawal from the WTO would lead to any of his desired changes, he has badly misread the situation. Our trading partners, including those that are democracies, want to keep the WTO intact. They would support reform, and they would love to hear reform proposals from the United States. But they don’t want the United States to leave.



In fact, the Trump administration, despite its own skepticism of the WTO, has made some reform proposals. The administration has raised questions about the transparency of some governments’ reporting on their trade practices, as well as the special status that allows some poorer countries to take on fewer responsibilities. These are valid concerns, but a withdrawal from the WTO won’t address them. It will simply cede U.S. leadership of the trading system, leaving us more isolated than we already are.
"
"

Today, Senator John McCain will formally announce that he is a candidate for president of the United States. Which reminds me that on Monday, Senator McCain gave a speech at the Center for Strategic and International Studies on what federal energy policy would look like under a McCain administration. So is the omnipresent captain of the “Straight Talk Express” prepared to tell Americans things they might not want to hear about energy? Apparently not. An examination of the speech suggests that we may need to rename McCain's campaign bus the ""Hot Air Express."" Let’s look at this speech and deconstruct it line by line.   




Thank you. I appreciate the invitation to talk with you about a great and urgent challenge - breaking our nation's critical dependence on foreign sources of oil, and making America safer, stronger and more prosperous by modernizing the way we generate and employ energy.   
  
Oil is often called the lifeblood of our economy--the indispensable commodity that keeps commerce humming and America on the move. But, in today's world, our dependency on foreign oil and the way we use hydrocarbons is a major strategic vulnerability, a serious threat to our security, our economy and the well being of our planet.



While this is standard-issue political cant, it pays to dwell on the implication of what is being said. In essence, John McCain would have us believe that free trade is good for everything save energy. But why – what’s so special about energy? As best as I can tell, the grand “energy exception” exists because energy is so important that we dare not rely upon foreign sellers. But couldn’t the same thing be said about food, technology, etc? I must have missed that part of _The Wealth of Nations_ where Adam Smith argued for the virtues of free trade for unimportant things but championed the case for protectionism when truly valuable commodities were in play. 



Fortunately, there are times in a nation's history when great challenges coalesce with great moments of opportunity. We are at such a moment today. We have the urgent need and the opportunity to build a safer and thriving future with more diverse, reliable, and cleaner energy. But it will take another indispensable commodity to make it happen -American leadership. I'm running for President to help provide that leadership. And I want to talk a little today about the direction I want to lead us and why.



Every single presidential candidate that I’m aware of is saying exactly the same thing when it comes to what America’s national energy policy ought to be. It’s as if they are all going to the same speech writer. There’s a reason for that. Politicians are in the business of ratifying public sentiments, and it there’s one thing the public believes these days, it’s that it would be great if we could find a cheap replacement for gasoline. Yes, that would be great. But government isn’t God. 



Oil is a vital resource and we will always need it. But we account for 25% of global demand and possess less than 3% of proven reserves. Most of the world's known reserves are in the Persian Gulf, in the hands of dictators or nationalized oil companies. Its availability and price are manipulated by a cartel of countries where our values aren't typically shared and our interests aren't their first priority.



Actually, we don’t know that. It turns out that academics have been trying to quantify OPEC’s impact on world crude oil markets for decades and have found no compelling evidence to support the contention that prices are higher because of OPEC than they would be absent OPEC. 



By mid-century there will be three-and-a-half billion cars worldwide-over four times the number today. Most of the growth will take place in the developing world, in India and China, but the increase in fuel prices, pollution, and climate impacts will be felt worldwide. As world demand for oil soars, higher prices, severe economic volatility, and heightened international tensions follow.



Really? If we were to draw a line on a graph showing world oil consumption from 1900 to the present, and then we were to draw similar lines for crude oil prices, world GDP, and the number of cross-border conflicts, I guarantee you that oil consumption would correlate with economic growth but would not correlate with higher world crude oil prices or international conflict. A regression analysis would be required to settle the matter, but I’m pretty sure that, if I had the time to undertake one, we’d find that John McCain’s prediction about the future has no basis in past experience.   
  
Regardless, increases in world oil consumption are manifestations of progress and improved human well-being. The fact that people in China, India, and elsewhere in the third world are now wealthy enough to buy cars and gasoline is good news, not bad. 



These unpredictable forces could seriously circumscribe our future if we let them. Great nations don't leave the ""lifeblood"" of their economy in the hands of foreign cartels or bet their future on a commodity located in countries where authoritarians repress their people and terrorists find their main support.



What is a “great nation"" exactly? There must be many qualities that could earn a nation the adjective “great”; leadership in the arts, leadership in the sciences, leadership in wealth creation (GDP), or personal well-being (per capita GDP), leadership in military power, or, for the more ideologically minded, leadership in civic virtue (income equality for some, personal liberty for others). Now, I’m going to hazard a guess here that when John McCain refers to a country as a “great nation,” he’s either defining it as “a nation that would elect John McCain” or “a nation that can blast apart any other nation on earth.” By that criterion, is there a correlation between “great nations” and those that get all of their economically important commodities from within their own borders? No there isn’t. If we broaden our definition of “great nation” to those that meet other criteria of “greatness,” I ask again: Is there any correlation between economic independence and fine art and literature, per capita GDP, aggregate GDP, equality, or personal liberty? Again, no.   
  
In reality, John McCain is making a tautological argument; “A great nation is one that does not rely on trade with others.” By this metric, Albania prior to the collapse of the Soviet block and North Korea today are the world’s greatest nations. Neither the United States – nor ancient Rome for that matter – would ever qualify under those terms. 



Terrorists understand the seriousness of our vulnerability. Al Qaeda plans for attacks on oil facilities in the Middle East to destroy the American economy. A little over a year ago, a suicide attack at a major Saudi Arabian oil refinery came close to disabling its target. Had it succeeded, it would have driven the world price of oil above $150 dollars a barrel -and kept it there for a year.



Yeah, well, “If ‘ifs and buts’ were chickens and nuts, we’d all have enough for winter.” It turns out that it’s a lot harder for terrorists to disrupt the oil trade via targeted attacks than John McCain imagines. They’ve been at it for nearly a decade now and have nothing to show for their efforts. 



We're one successful attack away from an economic crisis. The flow of oil has many chokepoints - pipelines, refineries, transit routes, and terminals; most of them outside our jurisdiction and control. Our enemies understand the effects on America of a significant disruption in supply, a crippled transportation system, gasoline too expensive for many Americans to purchase, businesses closed.



Economists are increasingly of the opinion that oil price spikes have very little impact on the economy as a whole. Think about it – oil prices have almost tripled since 2002 (when oil prices averaged $22 per barrel) but the economy continues to hum along nicely. 



Al Qaeda must revel in the irony that America is effectively helping to fund both sides of the war they caused. As we sacrifice blood and treasure, some of our gas dollars flow to the fanatics who build the bombs, hatch the plots, and carry out attacks on our soldiers and citizens.



Unless John McCain knows something we don’t, he’s just making this up as he goes along. We don’t know who’s running al Qaeda or where their high command happens to be, much less what their financial books look like. 



Iran made over $45 billion from oil sales in 2005, and it is the number one state sponsor of terrorism.



Yeah, and Pakistan earned virtually nothing from international oil sales in 2005, but its military is probably the most dangerous sponsor of Islamic terrorism on the planet. But let’s go back to Iran. Even when sales revenue was less than half that of today (namely, during the entirety of the 1990s), Iran was busy setting up Hezbollah and Allah knows what else. There is no correlation between oil revenues and Islamic terrorism. 



The transfer of American wealth to the Middle East helps sustain the conditions on which terrorists prey.



Actually, hatred of America in the Islamic world sustains the conditions on which the terrorists prey. And in that regard, John McCain – because of his support for the war in Iraq if nothing else – is almost certainly more responsible for Islamic terrorism than ExxonMobil.   
  
But let’s go back to McCain’s contention that drying up the flow of petrodollars going into the Middle East would reverse “the conditions on which terrorists prey.” I don’t think that’s true. What terrorists need most is a recruiting pool from which to draw. If the United States were to reduce oil consumption to such an extent that profits for oil producers declined, oil states would have smaller economies and less to distribute to their underemployed youth. To the extent that deteriorating economic conditions breed social discontent and political resentment, it’s not so obvious to me that reducing oil profits reduces Islamic terrorism. And that’s particularly the case when oil profits are being reduced as a consequence of a policy with a stated intention of bankrupting the economies of the Middle East. Has it not occurred to John McCain that this would almost certainly increase the recruitment pool for Islamic terrorists and make matters worse if we accept that manpower, not money, is the chief limiting factor for terrorist activities? Has our stated policy of strangling the revenues available to the Cuban government increased or decreased the pool of anti-American citizens of Cuba? 



Some of the most oil-rich nations are the most stagnant societies on earth. As long as petro-dollars flow freely to them those regimes have little incentive to open their politics and economies so that all their people may benefit from their countries' natural wealth.



Does anyone seriously think that if the oil revenues dried up that Saudi Arabia, Kuwait, Bahrain, the UAE, and Iran would go happily into that market liberal night? Gee, what do Islamic countries without oil revenue – like Egypt, Syria, Pakistan, and Afghanistan – look like? 



The Middle East's example is spreading to our own hemisphere. Venezuela's Hugo Chavez is using his country's oil revenues to establish a dictatorship, bully his neighbors and succeed Castro as Latin America's leading antagonist of the United States.



Sad but true. Score one valid point for John McCain. But there’s little the United States can do to deny significant oil revenues to producing states. Our ability to radically reduce world crude oil prices via public policy is routinely overstated. The U.S. is just one actor of many in a global crude oil market in which prices are determined by global supply and demand. Sure, we could ban the internal combustion engine and thus cut world crude oil demand by something like 20 percent, but is it worth throwing our economy into a depression just to bring Venezuela’s oil revenues back to 1990 levels? 



The politics of oil impede the global progress of our values, and restrains governments from acting on the most basic impulses of human decency.



Not necessarily. “The politics of oil” didn’t impede the development of the United States throughout the first six decades of the 20th century. Few today remember that the United States once dominated the world crude oil market to the same extent Saudi Arabia does today. There’s no iron link between crude oil extraction and human rights violations. 



There is only one reason China has opposed sanctions to pressure Sudan to stop the killing in Darfur: China needs Sudan's oil.



That and the fact that China has no interest in promoting a global bias against human rights violations for reasons that should be obvious to John McCain. Regardless, China doesn’t need Sudan’s oil – it needs oil. Sudanese oil is no better than anyone else’s. If Sudan is willing to cut China a better deal in return for foreign policy favors, what are we supposed to do about it? 



The burning of oil and other fossil fuels is contributing to the dangerous accumulation of greenhouse gases in the earth's atmosphere, altering our climate with the potential for major social, economic and political upheaval. The world is already feeling the powerful effects of global warming, and far more dire consequences are predicted if we let the growing deluge of greenhouse gas emissions continue, and wreak havoc with God's creation.



Oil consumption has less to do with global warming than does coal consumption, but alas, politicians find it more convenient to lay global warming at “Big Oil’s” feet than at the feet of “Big Coal.” That’s probably because it’s politically safer to attack the oil industry than the coal industry. Declare war on coal and you declare war on coal miners and coal towns. That might very well cost you battleground states such as Pennsylvania, West Virginia, Tennessee, and Ohio … and thus, the presidency. Declare war on oil, on the other hand, and you’ll probably get a bump in your fundraising efforts in California with no obvious downside to speak of. 



A group of senior retired military officers recently warned about the potential upheaval caused by conflicts over water, arable land and other natural resources under strain from a warming planet.



Exactly what expertise do military officers bring to the global warming policy table? Military officers specialize in killing great numbers of people in an organized and efficient fashion. How does that skill set translate into specialized knowledge about atmospheric physics, climatological impacts of a warmer and wetter world, and/or the socio-political responses to the same? 



The problem isn't a Hollywood invention nor is doing something about it a vanity of Cassandra like hysterics. It is a serious and urgent economic, environmental and national security challenge.



According to the “best and the brightest” within the global academy, global warming ranks near the bottom of human worries. 



National security depends on energy security, which we cannot achieve if we remain dependent on imported oil from Middle Eastern governments who support or foment by their own inattention and inequities the rise of terrorists or on swaggering demagogues and would be dictators in our hemisphere.



What does this mean? Canada is a net exporter of oil, which suggests that McCain would deem Canada “energy secure.” America imports lots of oil, so we’re not. If national security depends on energy security, then Canada has relatively more “national security” than the United States. I can spin out even more insane comparison if you like, but I think you get the point. 



There's no doubt it's an enormous challenge. But is it too big a challenge for America to tackle; this great country that has never before confronted a problem it couldn't solve? No, it is not. No people have ever been better innovators and problem solvers than Americans. It is in our national DNA to see challenges as opportunities; to conquer problems beyond the expectation of an admiring world. America, relying as always on the industry and imagination of a free people, and the power and innovation of free markets, is capable of overcoming any challenge from within and without our borders.



We’ve been trying mightily to achieve energy independence ever since the Nixon administration, but we’re as far away from our goal as ever. John McCain can pat us on the backs all he likes, but he’s not the first do so – or the first to argue that a little “can-do” spirit can solve everything from oil dependence to drug use. 



Our enemies believe we're too weak to overcome our dependence on foreign oil.



Look, I’m not asking for Cicero, but can’t American politicians employ better rhetoric than this? 



Even some of our allies think we're no longer the world's most visionary, most capable country or committed to the advancement of mankind.



They think that because politicians like Sen. McCain are so popular in the United States. Need I remind John McCain that our allies’ loss of faith has to do largely with our embrace of a foreign policy straight out of the John McCain playbook? 



I think we know better than that. I think we know who we are and what we can do. Now, let's remind the world.



Yes, let’s impress the world regarding how well we’ve learned the lessons taught by France; give the politicians full power to dictate who makes what in our economy and let her rip! 



George Gershwin wrote that good music reflects its people and times. ""My people are Americans,"" he said. ""My time is today."" That's what made his music memorable. That's what made all America's best accomplishments memorable. We were capable and confident, we aspired to greatness and we understood our times. Our time is today, my friends, and the achievements of our storied past will shine no brighter than those we accomplish right now, in our time, if we meet our problems confidently and honestly; if we trust in the strength and ideals of free people; if we aspire to greatness.



Reagan he isn't. 



As President, I'll propose a national energy strategy that will amount to a declaration of independence from the fear bred by our reliance on oil sheiks and our vulnerability to the troubled politics of the lands they rule.



Even if we imported no Persian Gulf oil whatsoever, a supply disruption there would increase the price of crude oil everywhere in the world no matter where it is produced. 



When we reach the limits of military power and diplomacy to contain the dangers of that cauldron of burning resentments and extremism, energy security is our best defense. We won't achieve it tomorrow, but we must achieve it in our time.



If energy security is our best defense against terrorism, then how do we explain the fact that Great Britain is being menaced by Islamic terrorists? Great Britain, after all, is a net exporter of oil. If energy independence is the thin blue line between us and the terrorists, then it’s not proving to be much of a defense. 



The strategy I propose won't be another grab bag of handouts to this or that industry and a full employment act for lobbyists. It will promote the diversification and conservation of our energy sources that will in sufficient time break the dominance of oil in our transportation sector just as we diversified away from oil use in electric power generation thirty years ago; and substantially reduce the impact of our energy consumption on the planet. It will rely on the genius and technological prowess of American industry and science.



There is no way for McCain to pursue his vision without providing “another grab bag of handouts to this or that industry.” Market actors are currently rejecting alternatives to oil in the transportation sector. The only way to change that reality is to provide subsidies to oil’s competitors. 



Government must set achievable goals, but the markets should be free to produce the means. And those means are within our reach.



Whether government “must set achievable goals” or not depends upon your vision of government. In short, should decisions about what I drive be made by me or some politicians? As far as whether these “goals” that McCain is promoting are within our reach depends on what the goals are and how much we’re willing to pay to meet them. Unfortunately, he’s silent on both of those fronts. 



Energy efficiency by using improved technology and practicing sensible habits in our homes, businesses and automobiles is a big part of the answer, and is something we can achieve right now. And new advances will make conservation an ever more important part of the solution. Improved light bulbs can use much less energy; smart grid technology can help homeowners and businesses lower their energy use, and breakthroughs in high tech materials can greatly improve fuel efficiency in the transportation sector. We need to dispel the image of conservation that entails shivering in cold rooms, reading by candlelight, and lower productivity. Americans have it in their power today to contribute to our national security, prosperity and a cleaner environment. They understand the dangers we face, and are prepared to respond to appeals to patriotism that explain how we can free ourselves from them.



If energy conservation makes sense, people will conserve energy of their own accord. Amazing how that works. 



We need not wait for another age, in which science fiction becomes every day reality. Flexible-fuel vehicles aren't futuristic pie in the sky. We can easily deploy such technology today for less than $100 per vehicle; and we must develop the infrastructure necessary to take full advantage. We were able to overcome the challenges of putting seatbelts, airbags, and computer technology in practically every car. We can provide fuel options and improve the fuel efficiency of our vehicle fleet by making them out of high tech materials that improve their strength and safety. We are doing that very thing right now to beat our foreign competitors in the aerospace industry.



Who’s this “we”? Is John McCain running for President of the United States or overseer of all national business and industry? 



Alcohol fuels made from corn, sugar, switch grass and many other sources, fuel cells, biodiesel derived from waste products, natural gas, and other technologies are all promising and available alternatives to oil. I won't support subsidizing every alternative or tariffs that restrict the healthy competition that stimulates innovation and lower costs. But I'll encourage the development of infrastructure and market growth necessary for these products to compete, and let consumers choose the winners. I've never known an American entrepreneur worthy of the name who wouldn't rather compete for sales than subsidies.



The old John McCain opposed ethanol subsidies. The new John McCain will apparently embrace any idea to win the White House. 



America's electricity production is for the most part petroleum free, and the existing electric power grid has the capacity to handle the added demand imposed by plug-in hybrid vehicles. We can add more capacity and improve its reliability in the years ahead. Nuclear energy, renewable power, and other emission free forms of power production can expand capacity, improve local air quality and address climate change. I'll work to promote real partnerships between utilities and automakers to accelerate the deployment of plug-in hybrids.



Why don’t we just nationalize the car companies and get it over with? 



With some of the savings from cutting subsidies for industries that can stand on their own, we can establish a national challenge to improve the cost, range, size, and weight of electric batteries for automobiles. Fifty percent of cars on the road are driven 25 miles a day or less. Affordable battery-powered vehicles that can meet average commuter needs could help us cut oil imports in half. The reward will be earned through merit by whomever accomplishes the task, whether a laboratory in the Department of Energy, a university, a corporation or an enterprising young inventor who works out of his family's garage.



See, we’re just not trying hard enough. We can all drive to work in hot-rod golf carts if we just put our mind to it.   
  
Seriously though, don’t you think there is sufficient profit incentive to produce such technology now? This strike me as akin to doubling the bounty on bin Laden’s head. Nothing wrong with that, but it’s not likely to lead to his capture any sooner. 



There is much we can do to increase our own oil production in ways that protect the environment using advanced technologies, including those that use and bury carbon dioxide, to recover the oil below the wells we have already drilled, and tap oil, natural gas, and shale economically with minimal environmental impact.   
  
The United States has coal reserves more abundant than Saudi Arabia's oil reserves. We found a way to cut down acid rain pollutants from burning coal, and we can find a way to use our coal resources without emitting excessive greenhouse gases.



We know how to do that. We just don’t know how to do that cheaply. 



We have in use today a zero emission energy that could provide electricity for millions more homes and businesses than it currently does. Yet it has been over twenty-five years since a nuclear power plant has been constructed. The barriers to nuclear energy are political not technological.



Politicians don’t stand in the way of new nuclear power plants. Investment bankers do. That’s because the total cost of nuclear power is substantially greater than the total cost of other sources of electricity. 



We've let the fears of thirty years ago, and an endless political squabble over the storage of nuclear spent fuel make it virtually impossible to build a single new plant that produces a form of energy that is safe and non-polluting.



Even the Nuclear Energy Institute disagrees with this. At a Manhattan Institute conference on March 28 of this year, Richard Myers, vice president of NEI, argued that America’s inability to site a high level radioactive waste disposal facility has nothing to do with the reluctance to build new sites. I know that because I was there on the panel with Mr. Myers. 



If France can produce 80% of its electricity with nuclear power, why can't we? Is France a more secure, advanced and innovative country than we are? Are France's scientists and entrepreneurs more capable than we are? I need no answer to that rhetorical question. I know my country well enough to know otherwise.



If France can have a 35 hour work week, why can't we? If France can guarantee that no person is fired with a damned good reason, why can't we? If France can guarantee all of its citizens a robust income for life whether they work or not, why can't we? The reason France has a lot of nuclear power is because French politicians make the decisions about what kind of power plants are built in France, not French investors or businessmen. In America, we leave more decisions to the market than does Europe.   
  
Seriously, I don’t think that Republicans will take well to an argument that France should be the metric by which all American domestic policy is judged. But maybe I’m wrong about that. 



Let's provide for safe storage of spent nuclear fuel, and give host states or localities a proprietary interest so when advanced recycling technologies turn used fuel into a valuable commodity, the public will share in its economic benefits.   
  
I want to improve and make permanent the research and development tax credit. I want to spend less money on government bureaucracies, and, where the private sector isn't moving out of regulatory fear, to form the partnerships necessary to build demonstration models of promising new technologies such as advanced nuclear power plants, coal gasification, carbon capture and storage, and renewable power so we can take maximum advantage of our most abundant resources.



Maybe the private sector “isn’t moving” towards John McCain’s preferred sources of energy because it makes zero economic sense. Energy demonstration projects, by the way, have a long record of failure in the United States. All that has been demonstrated is that the technology in question isn’t ready for prime time – something market actors managed to figure out without a dime of taxpayer money. 



And I'll make it a national mission to develop a catalyst capable of breaking down carbon dioxide into useful chemical building blocks, and rendering it a new source of revenue and opportunity.



So many national missions, so little time. Where do you think this will be – or should be – on President McCain’s “to-do” list were he to find himself in the Oval Office? 



America competes in a global economy where innovation and entrepreneurship are the pillars of prosperity. The competition is stiff and the stakes are high. We have the opportunity to apply America's technological supremacy to capture the export markets for advanced energy technologies, reaping the capital investment and good jobs it will provide. Our innovators, scientists, entrepreneurs and workers have the knowledge, resources, and drive to lead the way on energy security, as we have in so many other world-changing advancements. The race has always been to the swift, and America must be first to market with innovations that meet mankind's growing energy and environmental needs. Again, government should set the standards, and leave it to the marketplace to win the race.



It’s difficult to read that paragraph without concluding that John McCain sees no real boundary line between government and industry. They are both one – or need to be made one – to work in concert. 



I have proposed a bipartisan plan to address the problem of climate change and stimulate the development and use of advanced technologies. It is a market-based approach that would set reasonable caps on carbon and other greenhouse gas emissions, and provide industries with tradable credits. By reducing its emissions, a utility or industrial plant can generate credits it may trade on the open market for a profit, offering a powerful incentive to drive the deployment of new and better energy sources and technologies; for automakers to develop new ways to lower pollution and increase mileage; for utilities to generate cleaner electricity and capture carbon; for appliance manufacturers to make more efficient products, and for the nation to use energy with maximum efficiency-building conservation into the economy in a manner that produces financial and environmental benefits. Dupont Corporation has reaped $2 billion dollars in energy savings and reduced its carbon emissions by 72% since 1990.   
  
As it always does, the profit motive will attract the transformational power of venture capital, and unleash the market to move clean alternative fuels and advanced energy technologies from the margins into the mainstream.



FYI, economists at Resources for the Future – a rather non-ideological bunch who likewise endorse greenhouse gas emission reductions – report that John McCain’s plan would likely increase electricity prices by at least 35 percent, and probably more. 



Some urge we do nothing because we can't be certain how bad the problem might become ...



That is, they stubbornly point out that we don’t know enough about the costs associated with warming to ensure that any policy we adopt actually passes a cost-benefit test. 



... or they presume the worst effects are most likely to occur in our grandchildren's lifetime.



Actually, that’s true and there’s not a scientist alive who thinks industrial emissions are the primary drivers of warming who would argue to the contrary. 



I'm a proud conservative ...



""Conservative"" apparently means something quite different than it did when I was a boy. 



... and I reject that kind of live-for-today, ""me generation,"" attitude. It is unworthy of us and incompatible with our reputation as visionaries and problem solvers.



But it speaks well for our ability to undertake simple math. Even if global warming were to cut GDP by 10% a year (that is, about 10 times the best estimates at present), that would mean per capita incomes 100 years hence will likely be $289,515 rather than $321,684 assuming a 2 percent annual increase in per capita income, which is a relatively safe bet given past trends. In short, our grandchildren are going to be much, much wealthier than we are – just as we are much wealthier than our grandparents were in 1907.   
  
Would John McCain ever propose a $440 a year tax on those making $44,000 (that’s what per capita incomes were last year) to generate benefits for those making $289,000 (per capita incomes in 2106 under worse case scenarios related to global warming) if this sort of policy were advanced in any other context? 



Americans have never feared change. We make change work for us.



That’s so vacuous let’s turn it around. So what if the planet gets a few degrees warmer over the next couple of centuries? Americans have never feared change. We make change work for us. That's actually a pretty defensible argument given that climate change is unlikely to effect the American economy very much at all. It will have a much more negative effect on our global competitors. 



In the coming months, other proposals will be offered to establish a national climate policy. I welcome this. But let's not let urgency breed rashness and irresponsibility. I claim no monopoly on the best answers. Let the marketplace of ideas flourish. But as there is great reward in the responsible policy, there's also enormous risk in the wrong way forward. The policy must include mechanisms to control costs and protect the economy. Just as there is danger in doing too little, there is peril in going too far, too fast, in a way that imposes unsustainable costs on the economy. I believe ""cap and trade"" is the best way to manage cost and maximize benefits, but we must look at other market-based means to give added assurance that our policies are an instrument of job creation, economic progress, and environmental problem solving.



Economists are almost in complete agreement that “cap & trade” is poor way to go about this exercise if we want to reduce industrial greenhouse gas emissions. Carbon taxes would be far preferable. The reason politicians embrace the former but eschew the latter is because voters will not support climate control policies that impose significant costs on them. Hence, politicians need to endorse policies that impose few visible costs on voters. 



Climate change is a global problem that requires a global solution. But we know America has both an obligation and a compelling national interest in fulfilling our historic leadership role. China's carbon emissions will soon exceed ours. As President, I will invite a collaborative relationship with China to make coal use cleaner and climate friendly. But, we should address the problem on our terms, and bring others into the fold of a common sense effort to solve it, while we sell to the world the technologies needed to do it.



If John McCain has some secret plan to convince China to stop building cheap coal-fired power plants (that is, to stop growing), then I will be quite impressed. If current trends continue, within the next 25 years, China will emit twice as much greenhouse gases as the United States, Europe, Japan, and all other industrial nations combined. 



Answering great challenges is nothing new to America. It's what we do. We built the rockets that took us to the moon not because it was easy but because it was hard. We've sent space probes into the distant reaches of the universe. We harnessed nuclear energy, mapped the human genome, created the Internet and pioneered integrated circuits that possess the computing power of Apollo spacecraft on a single silicon chip you can barely see. In twenty years we've gone from using this cell phone (SHOW), a $4000 toy for the wealthy, to this cell phone (SHOW), an inexpensive and virtually universal means of communication. We can solve our oil dependence. You can't sell me on hopelessness. You can't convince me the problem is insurmountable. I know my country. I know what we're capable of. We're capable of unimaginable progress, unmatched prosperity, and vision that sees around the corner of history. We've always understood our times, accepted our challenges and made from our opportunities, another better world. My people are Americans. Our time is today. That is the country I ask to lead.



Yes, if we wish something into existence, government can make it so. God bless that straight-talkin' John McCain! Now, to be fair, this same intellectual horse-whipping could be administered to every single energy speech being given by every single candidate running for the presidency. So in that spirit, consider these comments as the standard-issue rebuttal to everything you’re about to hear on the campaign trail re our “addiction to oil.”


"
nan
"Despite all the treaties, pledges, export bans and labelling schemes, the world’s forests are still disappearing at an alarming rate. In poorer countries a forest may simply be worth less as a living, thriving ecosystem than it is as timber and farmland. So if money is a key factor, why not get rich countries to pay poor countries to stop chopping trees? The UN Climate Summit in New York saw major new agreements along these lines. Norway in particular has pledged to pay Peru and Liberia hundreds of millions of dollars if they protect their forests more effectively. Such so-called REDD+ schemes hope to save millions of tons of carbon emissions while at the same time protecting indigenous people’s rights.  Although these bilateral deals sound good in principle, many NGOs, indigenous people and community groups have expressed significant concerns. The deal with Peru, which also involves Germany, is designed to cut the rate of deforestation in that country, home to large expanses of the Amazon rainforest, by paying its government up to US$300m if certain targets are achieved. A similar deal with Liberia is worth up to US$150m. Norway, Germany and the UK have promised further REDD+ funds if developing countries come forward with credible proposals.  Such bilateral agreements are not new, and Norway in particular has signed similar deals with Indonesia, Brazil, Guyana and other countries in recent years. These latest announcements are part of a wider New York Declaration on Forests, which involves more than 150 governments, companies, indigenous peoples organisations and NGOs, committing to halve deforestation by 2020 and end it by 2030. But the destruction of the world’s forests continues apace, and we are still far away from a truly global agreement. Every single country on earth would benefit from global forest protection, given forests’ importance for biodiversity and their ability to store carbon. But despite efforts ever since the Rio Earth Summit in 1992, it has been impossible to reach a global deal. Given this deadlock, bilateral agreements may be the best alternative. As early as 2006, the Stern Review argued that curbing deforestation was one of the most cost-effective ways to reduce emissions. Indeed, the review recommended precisely the Norwegian approach of compensating countries for the opportunity cost of other forest uses and the cost of managing the resource. Money talks in cash-strapped developing countries. By putting a price on trees that remain standing, such deals potentially introduce a viable alternative to logging or burning. Yet, a range of NGOs, pressure groups, indigenous people organisations and other civil society groups have expressed deep concerns over such schemes.  First, are US$300m and US$150m, as in the Peru and Liberia deals respectively, enough to change decisions and development paths for the long term? The underlying problems generating deforestation are complex and require multiple approaches to correct, including changes in buying behaviours of companies and consumers in the industrialised world.  Indeed, deals have been struck with Liberia and other countries before, but deforestation has continued and hence their results have been mixed. Some have claimed that changes to deforestation rates have generally followed trends begun before the Norwegian interventions and have been driven by other indigenous changes in attitudes, laws, and enforcement. So, deals with Norway alone will not be enough. Political will and leadership in developing countries, and being able to confront economic elites, are essential to address the drivers of the problem.  A second concern is that not all forests are alike, and some are more worth saving than others. A forest plantation should be seen more like an industrial, monocultural crop, with much reduced biodiversity and even increased carbon emission rates, given the uses of fertilisers and pesticides. Such plantations are quite different from untouched Amazon rainforests, for instance, and raise the question of which forests are actually protected by these agreements or should be. Third, how the agreements are implemented and who receives the payments has important equity implications. Experiences so far suggest that it is often elites in the receiving countries that benefit the most, further exacerbating social and economic inequalities. If the environmental problem of deforestation is more clearly understood as social and economic problem, so that wide disbursement of the benefits is necessary to achieving a solution, then the promised US$300m and US$150m deals suddenly seem very modest in comparison to the scale of the problem.  Fourth, and perhaps most importantly, it is often forgotten that forests are the homes of millions of indigenous people around the world. The new deals with Peru and Liberia explicitly acknowledge this, which is a step in the right direction. Yet, serious concerns have been raised by AIDESEP, the main organisation for the indigenous peoples of the Peruvian Amazon, and Rainforest Foundation Norway. These groups point to conflicts of interests and double standards at the centre of the Peruvian government, which has presided over a decline in the protection of forests and indigenous rights in recent years. Hence, the general principle of protection in the letter of intent may not contain enough teeth to be effective. That being said, such deals could be a step in the right direction if the money encourages some of the underlying conditions for better future forest management to take hold, including better mapping and associated enforcement mechanisms, better training and staffing of those in forest management and increasing awareness of standing forests as assets as well as cultural home to indigenous people.  The latest agreements specify some reasonable steps toward the ultimate goal of stopping deforestation by 2030, and to “cut emissions and reduce poverty at the same time,” in the words of one Norwegian government adviser. But actually reaching that goal might be a big ask from such bilateral agreements alone, given the complexity of the problems involved."
"**There have been more than 1.6 million confirmed cases of coronavirus in the UK and about 60,000 people have died, government figures show.**
However, these figures include only people who have died within 28 days of testing positive for coronavirus and other measures suggest the number of deaths is higher.
**Find out how the pandemic has affected your area and how it compares with the national average:**
If you can't see the look-up click here.
After the first peak in April, cases started rising again in July, with the rate of growth increasing sharply in September and October, before falling again in the past two weeks.
On Wednesday, the government announced a further 16,170 confirmed cases.
It is thought the infection rate was much higher during the first peak in spring, but testing capacity at the time was too limited to detect the true number of daily cases.
The data for cases can also be broken down by region and comparing the change in those figures by week gives a sense of where there has been a recent increase in newly-reported infections.
Coronavirus infections in England have fallen by about a third during lockdown, according to a major study carried out by Imperial College London.
While some of the worst-hit areas saw the biggest improvements, cases have remained relatively high across England, according to the React-1 study, which is based on tests of more than 100,000 people between 13-24 November.
The latest figures from the Office for National Statistics (ONS), suggest about one in 185 (16,400 people) in Wales had the virus in the week ending 21 November.
In Northern Ireland rates are thought to be decreasing at around one in 145 people (about 12,700 people), while in Scotland, the figure was one in 115 (about 45,700 people).
The average number of daily deaths began to rise again in September, following the first peak in April.
On Wednesday, the government announced a further 648 deaths.
Of these, 555 deaths were in England, 51 in Wales, 38 in Scotland, and four in Northern Ireland.
Rules were amended over the summer to include deaths in the coronavirus total only if they occurred within 28 days of a positive test. Previously in England, all deaths after a positive test were included.
England has seen the majority of UK deaths from Covid-19. Using the 28-day cut-off, there have been more than 52,000.
Although hospital admissions for Covid-19 remain below the levels seen in the spring, there are big regional disparities.
The North West, North East and Yorkshire, and Midlands have seen the highest number of admissions but the situation in all three now appears to be improving.
Cases have risen across large parts of England, with other spikes in areas of Scotland, Wales and Northern Ireland.
The red areas on the map below are those currently seeing the highest number of cases per 100,000 people.
Restrictions have been tightened across the UK in an effort to tackle the number of rising cases.
In England, each local authority has been placed in one of the new three tiers following the end of the recent national lockdown.
Wales has announced a range of further measures, including a ban on pubs, restaurants and cafes serving alcohol, from Friday 4 December.
In Northern Ireland, a further two-week ""circuit-break"" lockdown began on 27 November.
Scotland has a five-tier system of alert levels with different measures in place in different parts of the country.
UK leaders have agreed to allow up to three households to meet indoors during a five-day Christmas period of 23-27 December.
When looking at the overall death toll from coronavirus, official figures count deaths in three different ways.
Government figures count people who died within 28 days of testing positive for coronavirus.
But there are two other measures.
The first includes all deaths where coronavirus was mentioned on the death certificate, even if the person had not been tested for the virus. The most recent figures suggest there had been almost 70,000 deaths by 20 November.
The second measure counts all deaths over and above the usual number at the time of year - that figure was more than 75,000 by 20 November.
The most recent figures available from the ONS are for the third week of November, which show there were 14,276 deaths registered in the UK.
Some 3,038 of these deaths involved Covid-19 - 199 more than the week before.
Deaths normally do rise at this time of the year, but the data from the ONS and its counterparts in Scotland and Northern Ireland show the second wave of the virus has pushed the death rate above the average seen over the past five years by about 21%.
Overall, the figures are still well below the peak of 9,495 deaths recorded in a week, reached on 17 April.
The ""R number"" is the average number of people an infected person will pass the disease on to.
If R is below one, then the number of people contracting the disease will fall; if it is above one, the number will grow.
The government's current estimate for the R number across the whole of the UK is 0.9 to 1.
The estimate for England is 0.9 to 1, while for Scotland it is 0.8 to 1. The estimate for Wales is 0.8 to 1 and in Northern Ireland it is 0.9 to 1.1.
The government has said in the past that the R number is one of the most important factors in making policy decisions."
"
Share this...FacebookTwitterGerman daily Die Welt here reported last month how the transition to renewable energy development in Europe, particularly Germany, has not been progressing well lately.
Offshore parks are being delayed, the expansion of the power grid is practically DOA and people are realizing that the energy the sun sends for free is actually awfully expensive and inefficient.
The regulatory system designed to steer society through an energy efficiency revolution isn’t working. As a result bureaucrats are getting frustrated as their targets look less attainable than ever. Failure of their grand project is something they refuse to allow. Rather than admitting that the whole idea is unworkable, they instead think that the measures haven’t been drastic enough. Die Welt writes:
It’s no wonder that environmental politicians are considering forcing people rather than waiting for them to volunteer. That’s why the EU Commission has proposed a directive that threatens power utilities with fines in order to get them to finance the energy saving measures of their customers. Also homeowners are once again in the cross-hairs of politicians. After all, homes are the biggest consumers of energy . Too few homeowners are thinking about replacing their heating systems or insulating their walls and attics.”
Hat tip: http://oekowatch.org.
So what do the EU politicians have in mind? They want to force homeowners to renovate their homes to make them more energy efficient. Never mind if it’s economical or not. The idea is to save energy, no matter the cost. Besides, European politicians believe homeowners are too stupid to come up with the right answer when it comes to making investment decisions.
The German government is now considering such a measure. For example, the law would force people to insulate their homes and replace their furnace if they decide to carry out larger scale renovation works.
But as Die Welt writes, such drastic measures that try to force certain behavior are already being tried in the State of Baden-Württemberg, which is attempting to force homeowners there to carry out comprehensive renovation works for energy efficiency. The result: homeowners are renovating less than before. Die Welt:
Even small works are being avoided now because otherwise the law of the state threatens to force a costly full renovation. The laws of the state have only led to strategies of dodging and avoiding and have proven to be counter-productive.”
Little wonder. Whenever the state intrudes this deep into private property and lives, things are sure to go awry. That the state now is contemplating laws that tell people how to run their own private property is a scary measure indeed. They only need to look back at what happened under previous dictatorial regimes, never mind Baden-Württemberg.
Share this...FacebookTwitter "
"Tree planting is one of the government’s key strategies for fighting the climate crisis, but ministers have got off to a slow start that shows little sign of speeding up, according to the latest figures: just £5.2m will be spent on new trees in England under the countryside stewardship scheme for the current financial year. That is enough for only 1,260 hectares, according to Friends of the Earth, which is calling for a greater effort on tree-planting to absorb more carbon dioxide from the atmosphere.  Under current plans – revealed in the answer to a parliamentary question by the Labour MP Kerry McCarthy – about £27m will be spent by the end of this parliament, enough for about 6,500ha of forest. These sums fall far short of the 30,000ha of new trees the government has pledged. Friends of the Earth revealed last year that ministers were failing to meet targets on trees, despite assurances from the government that forestry would form a central plank of the push to reach net zero emissions by 2050. Less than £2 per person was being spent on forestry, research found. Each of the major parties included substantial tree-planting pledges in their manifestos at last autumn’s general election. However, details from the government on how this will be achieved have been scant. The agriculture bill currently progressing through parliament will put in place a broad legal framework to reward farmers for providing public goods, such as tree planting, but there have been no concrete plans yet from ministers on how much farmers can expect to be paid, when and how such schemes will be managed. There are also increasing questions over the strategy, which has the backing in principle of many environmental groups, but must be worked out in careful detail if new forests are to be sited in the right places so as to preserve existing habitats and not lead to further unintended emissions. Experts told the Guardian this week that commercial forests would provide little gain in the UK’s ability to store carbon. They also said trees planted in the wrong places could increase emissions, for instance, planting trees in some peatland dries out the peat and causes it to release carbon into the air. Other plantations can threaten local birds and wildlife if not carefully managed. Guy Shrubsole, a campaigner at Friends of the Earth, called on the government to increase funding for forestry and double tree cover in the UK, which, at 13%, is currently sparsely wooded compared with similar European countries. He said: “Ministers love to talk about planting more trees to fight the climate emergency, but seem unprepared to put their money where their mouth is. We have enough land but not yet the political will.” He called on the chancellor to act in Wednesday’s budget. “This budget is an opportunity to free up funding to create and maintain woodlands. Nature benefits from more trees, people feel better, and of course trees help combat climate change so there is absolutely no excuse to skimp on this funding.” The Department for Environment, Food and Rural Affairs said the final figures on funding for trees were likely to be much higher, as cash would flow from other sources within government beyond the countryside stewardship scheme. For instance, the government made a commitment in its manifesto to spend £640m on a Nature for Climate Fund, which would increase tree planting among other efforts to restore the UK’s natural environment. However, no details of any of these new potential sources of funding have yet been laid out. A spokesperson for Defra said: “Forests and woodlands are vital for capturing carbon, protecting wildlife and improving the environment for the next generation. That’s why our commitment to increase woodland cover as we work towards net zero sits at the heart of our ambitious environmental programme.”"
"
Share this...FacebookTwitterThe European Institute for Climate and Energy (EIKE) issued a press release on a 28-page report that German energy expert Dr. Guenter Keil wrote concerning Germany’s transition to renewable energy, and away from nuclear and fossil fuel energy.
KEIL’S FULL 28-PAGE REPORT IN ENGLISH
As the report shows, Germany’s transition to green energy is turning into a real horror story. The 28-page full report will keep you up at night!
What follows is EIKE’s PRESS RELEASE describing the contents of the report.
======================================================
Germany’s Green Energy Supply Transformation Has Already Failed
EIKE Press Release, 24 January, 2012
Energy expert Dr. Guenter Keil has closely examined Germany’s energy policy of shifting away from nuclear and fossil fuels and over to renewables. What he finds is a bleak picture. Years ago Germany ambitiously embarked on transforming its energy supply system, and hopes to supply at least 80% of its energy needs through renewable energies by 2050, and thus become a moral leader on environmental responsibility for the rest of the world.
To do this, the former Socialist-Green coalition government, led by Gerhard Schröder, enacted the so-called Renewable
Energy Feed-In Act (EEG) in 2000. This Feed-In Act requires electric utilities to buy all renewable energies, such as solar and wind power, from all producers at fixed, exorbitant rates and to feed it into the power grid for a period of 20 years. This has led to a boon as thousands of homeowners, businesses, and investors have installed thousands of megawatts of solar and wind power capacity over the years. The current Conservative-Liberal government, not to be outdone by its predecessor, is also gleefully pushing the Feed-In Act to the limit.
Weather-dependent supply wreaking havoc on the power grid
The problem is that these energy sources are weather-dependent and thus their sporadic supply is starting to wreak havoc on Germany’s power grid and is even now threatening to destabilize power grids all across Europe. The other problem: the power grid needed to distribute the decentrally produced green power is simply not there yet. They forgot to build it! So far, after tens of billions of euros spent on renewable energy systems and higher prices for consumers, not a single coal or gas-fired power plant has been taken offline. To the contrary, old inefficient German plants have been brought back into service in an effort to stabilize the grid.
In a panic reaction, Germany shut down 8 nuclear power plants
To make matters worse, in a fit of panic and hysteria, the German government shut down 8 of its older 18 nuclear reactors in the wake of the Fukushima disaster, thus removing a very cheap and stable supply of power and further pushing the grid to the limits. Before the shutdown of the nuclear reactors, Germany had been a net power exporter; today it is a net power importer and is at times severely straining neighboring power grids. To compensate for the missing nuclear power, the government is now heavily promoting even more weather-dependent wind power, which is further destabilizing the German and European power grids. A solution to the problem of storing electricity is still at least a generation away.
The question of course is how could such absurd decisions have been made to begin with? Were there no experts involved in the planning of the new power generation infrastructure? The answer obviously is no. Power executives are viewed as evil, dirty and greedy polluters, and thus were never really consulted. They could not be counted on to give the politically correct solutions. Therefore the decision to shut down the German nuclear power plants and to massively support renewables was done unilaterally by the government, without consulting the power executives or even neighboring countries.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Offshore wind parks, but no transmission lines to industrial regions!
Now that the damage is spreading, Germany’s utilities are now struggling to keep the grid stable and to fill in the power gap left by the shut-down of nuclear reactors. To do this the German government has ordered the installation of large-scale wind parks in the North and Baltic seas, in addition to the re-commissioning of mothballed, inefficient coal-fired plants. This overall energy production transition from nuclear and fossils over to “renewables” is dubbed by German officials as the Energy Supply Transformation. Construction of the offshore wind parks is now progressing rapidly. But there’s just one problem: the huge high voltage power transmission lines needed to bring their power to Germany’s industrial heartland to the south are missing! More than 3000 km of these lines are needed, but are nowhere near in sight. The government forgot about those too.
Activists groups blocking grid expansion
Building the power transmission lines quickly across the landscape will be a virtually impossible task. Activist groups have long since organized and are effectively blocking their approval and construction. So far only a measly 214 km have been built. As a result, surplus wind power cannot be delivered to the markets, and thus either has to be destroyed, dumped on the market at “negative prices”, or wind park owners are simply ordered to stop generating. No problem though – paragraph 12 of Germany’s Energy Feed-In Act requires electric utilities to pay for the electricity that they ask not to have produced! Technically, there is an incentive for wind parks to destabilize the grid.
Eventually all these costs add up and in the end they get passed along to the consumer. Under the bottom line, consumers have to pay more and more, and for a lower and lower quality supply. German industry is getting nervous and surveys show that many are leaving Germany, or are planning to do so. They no longer view Germany’s power supply as reliable.
In a death spiral…”will fail spectacularly”
Dr. Guenter Keil’s report focusses in detail on the amazing absurdities of Germany’s Renewable Energy Feed-In Act and the country’s utopian Energy Transformation. The government, through intrusive meddling and ballooning bureaucracy, has maneuvered Germany’s energy supply system into a vicious death spiral: the more the government intervenes, the greater the mess becomes. And the greater the mess becomes, the more the government intervenes! Dr. Keil concludes:
Germany’s energy transformation has already failed. For Germans, the outlook is bleak. …the planned mismanagement is heavily damaging the economy and will fail spectacularly some years later because its economic and social costs will have become unbearable. The question remaining open is how many billions of euros will have to be destroyed before a new energy policy (a new energy transformation?) picks up the shattered pieces.”
So it’s no wonder that according to a survey of experts from 21 national committees by the World Energy Council, 0% said they could imagine their own country completely taking over the German political approach. An equal number believe Germany will reach its stated targets. Germany’s model will serve as a classic lesson on how not to handle energy production and management.
Dr. Guenter Keil was a scientific employee at the Technical University of Munich / Fraunhofer Society, as well as Project Support at the Federal Research Ministry.
 Contact EIKE at: limburg@grafik-system.de
============================================
KEIL’S FULL 28-PAGE REPORT IN ENGLISH
I’ve read the entire report, and I can say that it sounds worse than Soviet-style central planning.
Share this...FacebookTwitter "
"The concept of the circular economy has left the realm of academic theory and entered the world of business. The price of natural resources and materials is soaring, and in response to volatile markets and increasing competition, developed nations are examining this sort of alternative economic model.  A circular economy is one that exchanges the typical cycle of make, use, dispose in favour of as much re-use and recycling as possible. The longer materials and resources are in use, the more value is extracted from them. This could contribute toward reducing Europe’s dependence on critical materials such as cobalt, fluorspar or gallium, but also reduce overall demand by recovering the resources, nutrients or energy contained in products at the end of their useful life.  Extending the life of products and materials prevents the over-generation of waste and recovers the full value of products. This would create new business opportunities and revenue streams, while minimising the environmental impact of mining, resource extraction, refining and manufacture.  Moving towards a more circular economic model is one of the pillars of the EU 2020 strategy – and within a few weeks of each other the European Commission and a committee of British MPs have released reports on how to bring it about.  The EU proposes to define a headline target of material productivity, a measure of the amount of value generated per unit of raw materials or products. Based on GDP relative to raw material consumption, this would be set at 30% by 2030. The package also includes a legislative proposal to review waste targets which includes targets for 70% recycling of municipal waste, 80% recycling of packaging waste and bans on any landfilling of recyclable goods. Other measures would boost innovation in resource efficiency, and tackle material intensive sectors, such as construction, with measures to improve the material efficiency of buildings through a harmonised framework for life-cycle assessment of buildings and promotion of secondary markets for construction materials. From the UK, the Environmental Audit Committee’s report on “ending the throwaway society” calls for an ambitious strategy to lay down the right conditions to transition to a more circular economy.  The committee’s proposals are more radical, suggesting lower VAT for recycled products and repair services to encourage new markets, innovation and better eco-design of products. The report also calls for a recycling regime that would improve on the limitations of the current system of many different, local schemes. Although all these measures have potential it’s unlikely they are enough to provoke the sort of radical changes in patterns of consumption and production required. From Europe the strategy relies on hefty recycling targets, but the measures to make it easier and more worthwhile to re-use waste to create new products are still missing.  Taxes have proven extremely successful in reducing material waste and in driving demand for secondary, recycled or re-used materials markets. For example, the UK aggregates levy for the construction industry has increased recycling rates of aggregates (sand, gravel, etc) to 25% and boosted the market for recycled aggregates. It has, in other words, made it worthwhile to re-use and not to waste. Run across the entire EU, a similar tax could lead to revenues in the order of €800 billion and hugely reduce material requirements for the building sector. While talk of implementing a circular economy emphasises the opportunities, there’s little reflection on the costs and challenges of the changes required. It’s true that waste is valuable, but recovering that value is complex and costly. For example, construction waste, the single most important waste stream in the EU, contains metals, minerals, glass and wood, but nonetheless in most cases has negative value – companies have to pay others to take it away. The re-manufacturing sector in the UK has a potential to generate £5.6 billion with the right support, but none of the suggested policies do anything to overcome the barriers it faces.  The entire European package lacks any systemic approach. The emphasis on waste and recycling distracts from the need to address the consumption aspect. Although there is some mention of the need to design products to be more recyclable and re-usable from the start, more work is needed to redesign the whole production and consumption system itself. We need not just products that are more easily and economically recycled but also products that last longer and are better for the environment. We also need the production and consumption infrastructure in which resources are optimised to maintain their value and usefulness over the lifespans of a number of products, at the end of each being recycled into another.  This is no mean feat, and will require measures such as industrial symbiosis, which is aimed at closing the loop by promoting co-operation across different industries where waste streams from one become inputs to another. Or an extended producer responsibility schemes where producers have a duty of custody of the resources contained in a product even after its sale.  Another shortcoming of the package is the lack of reference to commerce and industry that accounts for about a quarter of the EU’s waste. Some organisations are taking the lead, for example the ambitious Marks & Spencer’s Plan A, Unilever’s sustainable living plan, or Sainbury’s recent announcement that one of its stores would “close the loop” by using its own food waste to power the store. But until these outliers become the norm there is much more the EU and national governments could do to encourage them."
"**An expansion of coronavirus testing for hospital patients and health and social care staff has been announced by the Scottish government.**
Health Secretary Jeane Freeman said frontline health professionals would receive twice-weekly tests.
Emergency hospital admissions will also be tested from next week, and will be extended to all admissions next month.
Testing will also be expanded in the coming months for care home visitors and staff.
However, the GMB union said it would not be until March that all at-home care workers received regular tests, which it described as ""shameful"".
And opposition politicians accused the Scottish government of making similar promises in the past without delivering, and said the measures should have been introduced months ago.
Ms Freeman said the roll-out to health professionals would include frontline staff in hospitals, the Scottish Ambulance Service, Covid assessment centres in the community and healthcare professionals who visit care homes.
It will be phased in from next week, with the aim of being completed by the end of December.
Visitor testing will be initially introduced in up to 12 care homes across four local authority areas from 7 December, with full roll-out planned for January.
To facilitate Christmas visiting in all care homes, PCR testing will be provided for those that do not have access to lateral flow testing by that time.
Ms Freeman said guidance on visiting arrangements over Christmas is to be published shortly.
Testing for home carers will start to roll-out from mid-January.
December will also see the start of a testing programme for students before they return home for Christmas.
And targeted geographic testing will be trialled in communities covered by NHS Ayrshire and Arran, Forth Valley, and Greater Glasgow and Clyde, which are currently under level four restrictions.
This trial will utilise a mixture of existing and new testing technology, and will include an asymptomatic test site with capacity to test up to 12,000 people over the course of a week in Johnstone, Renfrewshire.
The results of these pilots will inform plans for a wider programme of targeted community testing in early 2021.
Ms Freeman said the plans would ""provide further protection for our communities, our extraordinary health and social care staff and the people they serve"".
She added: ""This expansion is possible because of increases in our testing capacity, delivered through our new regional hub laboratories and supply of new testing technologies, which will help us suppress Covid to the lowest levels possible as we face a challenging winter ahead.""
Scottish Labour MSP Monica Lennon said the Scottish government had made similar promises about testing ""time and time again"", and said there was a ""worrying lack of detail"" on how it would work.
She added: ""SNP ministers were warned months ago to test all hospital workers routinely to help slow virus transmission, but today the SNP government announced that it will be December before this happens.
""For at-home care workers, they will have to wait until March - a full year on from the start of the pandemic.""
And Rhea Wolfson of GMB Scotland added: ""In all probability it will be March 2021 before every home care worker has testing at work and staff could very well be receiving their vaccinations before they ever receive a test.
""Last March the first minister told us that Scotland was prepared for this pandemic and that Scotland had among the best testing capacity in the world. This was a tissue of lies.
""Covid has exposed how poorly Scotland's carers are valued and today's statement is the equivalent of kicking an exhausted workforce when they are already down."""
"**A Christmas shop that was ordered to close due to lockdown restrictions has been allowed to reopen.**
Ipswich Borough Council (IBC) served a prohibition order on Christmas Wonderland in Tavern Street, arguing it did not sell enough ""essential"" items.
But it has since been found ""compliant"" because it sells real Christmas trees.
Owner Zoe Scarrott said: ""We're obviously very pleased that they've allowed us to open and they feel that we're now abiding by the legislation.""
A council spokesman said: ""The Christmas Wonderland shop has been assessed for compliance with the regulations since reopening and found to be compliant.
""This is because the government's rules on what's allowed to be sold as 'essential' changed on 21 November to include real Christmas trees.""
IBC said it was ""satisfied that this retailer is complying with the amended regulations"".
It said it continued to monitor compliance of businesses across the town during lockdown and ""will take appropriate action where required"".
When the prohibition order was issued, Ms Scarrott said she felt ""discriminated against"" as a small business.
She said the shop's tenancy agreement had always allowed it to stock essential items in case of a second lockdown.
However, because the prohibition order had already been issued, it was only the change in legislation that allowed it to reopen.
""We never intended to get into a fight with the council but we just wanted people to consider the bigger picture,"" she said.
""We won't claw back what we've lost but it gives us extra time to try to make it up.""
England is due to come out of the current lockdown on 2 December.
_Find BBC News: East of England on_Facebook _,_Instagram _and_Twitter _. If you have a story suggestion email_eastofenglandnews@bbc.co.uk"
nan
"Commercial tree plantations in Britain do not store carbon to help the climate crisis because more than half of the harvested timber is used for less than 15 years and a quarter is burned, according to a new report. While fast-growing non-native conifers can sequester carbon more quickly than slow-growing broadleaved trees, that carbon is released again if the trees are harvested and the wood is burned or used in products with short lifespans, such as packaging, pallets and fencing.  Of the UK’s 2018 timber harvest, 23% was used for wood fuel, while 56% was taken to sawmills. Only 33% of the wood used by sawmills was for construction, where wood used in permanent buildings can lock in carbon for decades. Much of sawmill wood was used for fencing (36%) with a service life of 15 years, or packaging and pallets (24%) or paper (4%). “There is no point growing a lot of fast-growing conifers with the logic that they sequester carbon quickly if they then go into a paper mill because all that carbon will be lost to the atmosphere within a few years,” said Thomas Lancaster, head of UK land policy at the Royal Society for the Protection of Birds (RSPB), which commissioned the report. “We should not be justifying non-native forestry on carbon grounds if it’s not being used as a long-term carbon store.” The Committee on Climate Change has called for 1.5 billion new trees by 2050 – requiring planting on 30,000 hectares (74,000 acres) of land a year, increasing Britain’s forest cover from 13% to 19%. Many of these new forests will also provide a commercial timber crop. But the scientific review by the ecologist Ellie Crane of how forestry can best address the climate and biodiversity crisis finds that there is no simple solution in Britain. The best place for non-native conifers to quickly sequester carbon is on intensively farmed lowland but this high-quality agricultural land is too expensive for forestry to make financial sense for landowners. Planting conifers on the cheapest land such as the blanket bogs of Scotland’s Flow Country is “disastrous” for biodiversity, according to Lancaster, but also leads to carbon emissions because the bogs are drained for forestry and the peat degrades, releasing carbon into the atmosphere. This leaves “shallow peat” moorlands of western Scotland, south and mid-Wales and parts of the Lake District and the Pennines as the most likely locations for new carbon-sequestering forests. Here, the RSPB has concerns about the impact on wildlife. Rare and declining species such as the curlew that breed on open moorland cannot survive close to plantations, which become home to predators of their chicks such as crows. While the best option for wildlife and slower but long-term carbon sequestration is to plant broadleaved woodlands in the right locations and leave them intact, if Britain does not produce its own timber it will import more – in effect exporting its carbon footprint overseas. “It’s clearly not just a question of more trees equals a safer climate. Trees in the wrong place could exacerbate climate change and biodiversity decline,” said Lancaster. “There’s also a big question around the capacity of Natural England and regulatory bodies in Scotland and Wales and the forestry commissions to properly assess what impact any planting schemes will have on nature, both good and bad, and on the climate. “If we’re serious about tackling the climate and ecological emergency there needs to be a huge government investment in capacity to get that right, otherwise we’re going to have lots of inappropriate planting which could be negative for the climate as well as biodiversity.”"
"
Many of you watch sea ice as closely as some people follow the NFL, soccer, or NASCAR. So when something of interest happens, I’m not without an inbox full of notices.
Today it is encouraging to see the NANSEN is reporting that both Arctic Sea Ice area and extent are above the normal line. Usually we don’t see both in this mode. Here’s area:

And here is extent:

Source: http://arctic-roos.org/observations/satellite-data/sea-ice/ice-area-and-extent-in-arctic
By itself, this is just a small thing, but it is just one more indication that there’s some improvement in the Arctic Ice situation again, and the indications are that we’ll have another summer extent that is higher than the previous year, for the third year in a row.
Of course our friends will argue that extent and area don’t matter now, that only volume and ice quality (the rotten ice meme) matters.
Interestingly, if you go back to  the press releases on the record minimum extent in 2007 at NSIDC here:
http://nsidc.org/arcticseaicenews/2007.html
And search the entire set of release for the word “volume”, you won’t find it used anywhere that year. The volume worry is a more recent talking point that first appeared in October 2008 when it became apparent that extent wasn’t continuing to decline. They couldn’t tout another record low extent, so volume became the next big thing:
http://nsidc.org/arcticseaicenews/2008/

Arctic  sea ice minimum press release
Please see the NSIDC press release, “Arctic  Sea Ice Down to Second-Lowest Extent; Likely Record-Low Volume” for  a detailed analysis of this year’s Arctic sea ice minimum and a  synopsis of the 2008 melt season.
With nature still not cooperating with “death spiral predictions”, what will be the press release ice meme this year? Color? Texture? Cracks per square kilometer? It will be interesting to watch.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8c3f0dc3',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterGerman veteran meteorologist Klaus Eckhart Puls writes a piece at the European Institute for Climate and Energy (EIKE) on what he calls the “glaring contradiction between IPCC prognoses and reality”. Rather than increasing 0.2°C per decade, global temperatures over the past decade have actually declined.
Global mean temperature hasn’t risen in over 10 years. (Chart K.E. Puls)
Warmist Max Planck Institute now in a state of panic
Since Fritz Vahrenholt’s and Sebastian Lüning’s skeptic book “Die kalte Sonne” has become a German bestseller, major German climate institutes have gone in a state of panic to salvage global warming scenarios. They refuse to acknowledge that observed data deviate completely from their model projections. Instead they have undertaken a massive campaign to feed the media panic machine by unveiling their “latest model projections” which shows the planet is warming rapidly. However, the observed trends tell the opposite story.
The Max Plank Institute (MPI) for Climate Research in Hamburg and the Alfred Wegener Institute in Bremen last week went on a professional media blitz, claiming that temperatures are going to climb faster than ever and that the Arctic ice cap will melt – all based on their latest computer models, which will become part of the IPCC 5th Assessment Report. Why do they ignore reality and real observed data and focus on crystal ball projections?
Puls writes:
The most beautiful catastrophe from the computer crystal ball – the so called climate model – is always juicier than the arduous look at reality, which looks entirely different.”
Puls makes his point using charts from observed data and trends. Here I will present only the global data charts. Here’s what the Daily Mail said a month ago (see blue text in chart):

Here’s the global trend over the last 10 years:
Falling global temperatures (Chart: K.E. Puls)


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The above chart is from data from the Climate Research Unit of the University of East Anglia – a leading provider of climate data to the IPCC. Where’s the warming catastrophe? Answer: in the climate crystal balls of the Max Planck Institute and others only, and nowhere else!
Modellers ignore natural factors sun and oceans, massively inflate CO2
So why do their models continue to produce only warming? It is because the modellers are deliberately ignoring major climate driving factors such as ocean cycles, solar cycles and their amplification mechanisms, and wrongfully transfering their respective warming effects over to human-emitted CO2. Volumes of data and the trends of the last 15 years show this is wrong to do – but they continue to intentionally do it anyway.
From wrong science to fraud science
Deliberately ignoring the major natural factors while wildly exaggerating another, despite the volumes of data out there, has been going on in the IPCC models for years now. We’ve seen the culture of deception in the Hockey Stick, Al Gore’s exaggerated AIT, Climategate, Hansen’s adjustments and just recently with the behavior of Peter Gleick. With every passing year, scientists have noticed the widening deviation between their models and reality, yet they continue to ignore the major factors of sun, oceans and soot, and they manipulate the models even more to make CO2 appear as the culprit.
This systematic fudging and manipulation of models is increasingly fitting the definitions of criminal fraud. Unless the IPCC changes its course and starts acknowledging the sun, oceans and soot in its models in its next report, then the public will have grounds to sue them for fraud in a class action suit. The sheer weight of the data showing that the sun, oceans, etc. have considerable impacts is overwelming and can no longer be ignored in good faith.
A society the feels defrauded needs to start taking the legal steps to begin moving the case forward. It can be argued that the line between wrong science and fraud science was crossed long ago and that the hand of justice needs to intervene.
German readers can read more about Klaus-Eckhart Puls’s piece at EIKE here and “Die kalte Sonne, here“.
 
Share this...FacebookTwitter "
"

A recent _Science_ paper by J-F. Busteri and 30 named coauthors assisted by 239 volunteers found, looking at global drylands (about 40% of land areas fall into this category), that we had undercounted global forest cover by a whopping “at least 9%.” 239 people were required to examine over 210,000 0.5 hectare (1.2 acre) sample plots in GoogleEarth, and classify the cover as open or forested. Here’s the resultant cool map:   






This has been the subject of a flood of recent stories, blog posts, tweets, and whatever concerning Bastin et al. But here at the Center for the Study of Science, we’re _value added_ , so here’s some added value.   
  
  
Last year, Zaichin Zhu and 31 coauthors published a remarkable analysis of global vegetation change since satellite sensors became operational in the late 1970s. The vast majority of the globe’s vegetated area shows greening, with 25–50% of that area showing a statistically significant change, while only 4% of the vegetated area is significantly browning. Here’s the mind‐​boggling map:   






_Trends in Leaf Area Index, 1978–2009. Positive tones are greening, negative are browning, and the dots delineate where the changes are statistically significant. There is approximately 9 times more area significantly greening up than browning down._



Hope you’re sitting down for the money quote:   




We show a persistent and widespread increase of growing season integrated LAI (greening) over 25% to 50% of the global vegetated area, whereas less than 4% of the globe shows decreasing LAI (browning). Factorial simulations with multiple global ecosystem models show that CO2 fertilization effects explain 70% of the observed greening trend…



And the other greening driver that stood out from the statistical noise was—you guessed it— _climate change_.   
  
  
Now, just for fun, toggle back and forth between the two maps. As you can see, virtually every place where there’s newly detected forest is greening, and a large number of these are doing it in a statistically significant fashion. This may lead to a remarkable hypothesis—that one of the reasons the forested regions were undercounted in previous surveys (among other reasons) is that there wasn’t enough vegetation present to meet Bastin’s criterion for “forest,” which is greater than 10% tree cover, _and carbon dioxide and global warming changed that._   
  
  
**References:**   
  
  
Bastin, F-L., et al., 2017. The extent of forest in dryland biomes. _Science_ 356, 635–638.   
  
  
Zhu, Z., et al., 2016. Greening of the earth and its drivers. _Nature Climate Change,_ DOI: 10.1038/   
  
  
NCLIMATE30004. 
"
"With each monsoon season India waits with bated breath for forecasts from the India Meteorological Department and other international forecasting agencies. This year’s forecast suggested a weakened monsoon, and sure enough for five weeks the monsoon has failed to provide the deluge that is expected.  For India, the monsoon rains typically last from June to September and contribute a whopping 80% of the annual rainfall total.  Indian society is therefore finely tuned to the monsoon for its agriculture, industry and water supply for drinking and sanitation.  If spread evenly over the whole country, the total rainfall during summer amounts to around 850mm. This year has seen a substantial deficit so far, currently standing at about 37% below normal and close to the large deficit in experienced in 2009, which was, like 2002 before it, a year of substantial drought, bringing reduced crop yields and hitting the country’s whole economy. Now in mid-July, the forecast looks set to improve. The monsoons’ advance northwards across the country has been particularly slow, leading to lack of water for agriculture and prolonged heatwave conditions – in Delhi a week or so ago I experienced temperatures near 40°C due to the absence of rain. In some regions, farmers have had to plant alternative crops that require less water due to the lack of rain, and authorities have diverted irrigation to drinking water, exacerbating their problems. The monsoons are the biggest manifestation of the effects of the annual seasonal cycle on the planet’s weather. During spring and summer, the difference between the rapid warming of the Earth’s surface and the slower warming of the nearby ocean generates a tropospheric temperature gradient – a strong gradient in air temperature from north to south of the equator, seen in South Asia most strongly over northern India and the Tibetan Plateau. This temperature gradient stretches far up into the atmosphere forming a difference in pressure, stretching from high pressure over the southern Indian Ocean to low pressure over India. The result of this pressure gradient is the seasonal winds we know as the monsoon, which carry moisture to supply the monsoon rains across Asia. The onset of the monsoon rains typically comes at the beginning of June, with the weather front stretching from the southwest Indian state of Kerala across the ocean to cover the states in the far northeast of India. For Indian society, and especially farmers, knowing about any variation in the intensity and duration of the monsoon and when it will start is vital. The progression of the monsoon across the country normally takes around six weeks, reaching the border of India and Pakistan by around mid-July. In September, the monsoon withdraws in the opposite direction, and as a result northwest regions experience a much shorter monsoon season and consequently greater pressure on water resources. So why has it been happening? While a full study won’t be carried out until after the season, it is likely that it relates to El Niño – a warming of the central-to-east Pacific Ocean along the equator that happens every few years, changing seasonal weather patterns in many parts of the world but particularly around Indian and Pacific Ocean regions.  For India, El Niño is generally associated with monsoon drought. The remote interaction with the monsoon (known as teleconnection) is caused by a disruption to the normal trade winds in the Pacific and Indian Oceans, known as the Walker Circulation after Sir Gilbert Walker, a British meteorologist in India who sought to predict when the monsoon would fail. Rising air and enhanced rainfall meet over the warm ocean surface during El Niño, much further east than Indonesia as is usual. But what goes up must come down, and these shifts in the circulation lead to descending air over India, which reduces the strength of the monsoon. Research has also established that El Niño can delay the monsoon’s onset, shortening the duration of rains over India.   A major concern is that the monsoon will be changed by global warming.  However, all the indications from our climate models are that the Indian monsoon will continue to supply the region with strong seasonal rainfall. In fact most suggest that greater concentrations of atmospheric carbon dioxide will bring more, rather than less, rain.  So far, so good – but the monsoon’s rains are not a statistical average spread equally on each day and in each location. Model simulations also suggest that tropical rainfall will tend to be heavier when it occurs, with potentially longer dry periods between rain events. Both of these factors have important implications for water resources, including crop damage as well as increased flooding. With El Niño conditions forecast to grow in the Pacific throughout the rest of 2014, the full impact on this summer’s monsoon will depend on if the forecast comes true and the location of where El Niño occurs. What we can’t yet say with any certainty is how El Niño’s link to and effect on the monsoon will change under warmer future climate conditions – we only know that greater extremes of variability are likely, and a more variable monsoon may be a problem."
"The hot and dry conditions that helped drive Australia’s bushfire crisis would be eight times more likely to happen if global heating reached 2C, according to new analysis. An international team of scientists also found the risk of Australia being hit by intense fire weather had already risen since 1900 “by more than a factor of four”.  And the scientists said it was “scary” a country as well prepared for tackling bushfires as Australia had seen its systems “severely strained” by what the called the Black Summer Bushfires. Australia’s bushfire crisis began in spring 2019 and burned at least 7.7m hectares in the south of the country, claiming 34 lives and causing an environmental disaster. More than a billion animals were killed and threatened species were pushed towards extinction. Thousands of homes were destroyed. The 17 scientists from across Europe and the US, used computer climate models to examine the impact of increased levels of greenhouse gases in the atmosphere on the risk of intense fires. The bushfire study used the computer models to look at a metric called the Fire Weather Index, which is one way to predict the severity of fires by combining wind speed, relative humidity, temperature, drought and the flammability of the fuel. The index is widely used across the world to forecast dangerous wildfire conditions. The models found the probability of the index reaching levels seen during Australia’s bushfires had increased due to human-caused climate change by 30%. But the scientists said the influence of extra greenhouse gases was likely much higher because when they compared the climate models to the actual temperatures, they found the models underestimated the extreme heat seen during the bushfires. Prof Geert Jan van Oldenborgh, lead author of the study, of the Royal Netherlands Meteorological Institute, said: “We found that climate models struggle to reproduce these extreme events and their trends realistically. “However, they always underestimate the increase in chances for extreme fire risks such as Australia saw in the last few months. This means we know the effect is likely larger than 30% increase lower bound, which is already a significant influence of global warming.” The analysis also looked at conditions under a climate that warms by 2C above the pre-industrial levels. Two climate models found that fire weather conditions like those seen in 2019 “become about eight times more likely” in a 2C world, with a “lower bound of four times more likely.” The study released on Thursday has not been peer reviewed, but is being submitted to a journal with all data being made available. The methods and climate models had been used in previous studies that had been peer reviewed, they said. Dr Sophie Lewis, a co-author of the study from the University of New South Wales, told a briefing the fires had broken out during Australia’s hottest and driest year on record. She said new records had been set for high Forest Fire Danger Index in all states and territories throughout the 2019 spring. Lewis, who is based in Canberra, recalled being stuck in her own home with a young family for weeks to avoid the heavy smoke from the bushfires. She said: “In January, the national park that forms a large part of our home in Canberra exploded in flames. It was just last week the fire was declared out. “Clearly this was an event with an enormous ecological and human cost. It’s because of this that it’s so important to understand the contributing factors to this.” Looking only at observations, the scientists found the chances of Australia experiencing Fire Weather Index ratings as high as 2019 had already risen by “more than a factor of four” since 1900. The scientists that analysed the bushfire conditions are part of a project called World Weather Attribution that has examined the human influence on previous extreme events, including the 2016 bleaching of the Great Barrier Reef. That analysis found human-caused climate change had made the heat during the bleaching event 175 times more likely to happen. Co-author Maarten van Aalst, director of the Red Cross Red Crescent Climate Centre in the Netherlands, said it was “really scary that we are seeing such extreme conditions in countries that are as well prepared [for bushfires] as Australia.” He said: “What’s really obvious in light of these findings of rising risk is that it will become even more important to build resilience and prepare for these rising risks. “But there are also limits to what we can do through that adaptation and preparedness. So it’s critical that we find ways of reducing the underlying drivers of these rising risks to avoid problems getting even further out of hand in the future.” Dr Sarah Perkins-Kirkpatrick, a UNSW climate scientist who examines extreme events who was not an author on the study, said: “Fire weather is a very complex thing to simulate. “Combined with everything about this event being unprecedented, its extremely challenging for climate models to simulate everything about fire weather perfectly. “Australia just just experienced its worst bushfire season on record, overlapping our warmest and driest year on record. We know climate change has a role in increasing temperatures, which is a component in bushfire weather.”"
"Lurking beneath the authorities’ radar is a vast, international underground movement that stretches from Africa and Europe to the Americas: guerrilla gardening, the un-permitted colonisation of land, is still a mysterious activity about which little research is undertaken.  The movement brings together students, academics, businessmen, planners, architects, chefs, community workers and many more professions making up the ranks. Would-be guerrillas can enlist in a troop online through sites such as guerrillagardening.org; a forum established by Richard Reynolds (“Britain’s 24th most influential gardener”), deemed the father of the modern guerrilla gardening movement. The movement has grown in recent years, fuelled partially by the rise of Twitter and other forms of social media which make it much easier to organise digs. Generally speaking, guerrilla gardeners either aim to beautify a neglected patch of land or, increasingly, pursue the cultivation of space via urban agriculture by growing fruit and vegetables in a city context. A somewhat famous example of this is Incredible Edible Todmorden, a guerrilla gardening project started in 2008 where residents “adopt” areas of the town and plant without permission. Impressed by the displays and ideas, the local authority started to work with the guerrillas and the Incredible Edible Network was soon born – now an international movement promoting the idea of urban agriculture.  Between 2010 and 2013, I carried out an extensive ethnographic exploration of those guerrilla gardeners practising their form of urban agriculture in the Midlands, UK. After some searching (and lots of luck) I tracked down three groups eager to be involved in the study.  The first was a group of local authority employees who named their collective, F Troop – a reference to the 1970s American Western TV show featuring cowboys gallivanting around without much of a plan. In this case, the troop realised this name reflected their practices, with members turning up to the dig site and planting randomly. The group occupied land next to an inner-city dual carriageway, planting nasturtiums, peas, spinach and other produce alongside the road’s barrier. Their core reason for pursuing such an activity was the thrill of transgression from messing with council land (their employer, no less).  The second was an elderly lady who, angry with her local authority’s lack of effort to clean up nearby alleyways, took it upon herself to rid the space of junk. In its place she laid out raised beds in which to cultivate vegetables. Finally, the third was group of women who occupied a large green space in a deprived area and convert it into a large community garden. Their motivation was to bring fresh produce closer to those who needed it, since the majority of those surrounding the site had poor diets. The women opted for the guerrilla route due to the perception that gaining official permission was too arduous and would only delay their activities. These three examples show the spectrum of those involved in guerrilla gardening: from the radical yet middle-class professionals of F Troop, to the group of more working-class women who adopted a large area for those around it, guerrillas come from different backgrounds and all have different reasons for pursuing their action.    As a researcher, the ethics and practicalities of interacting with an activity that exists in a legally grey area were tricky, for instance, the cities in which the above guerrillas practised cannot be named in order to protect the identities of those involved. An extra dilemma was added by the fact that I was a member of the police Special Constabulary at the time. There has been rising interest in guerrilla gardening, but the majority of this portrays it in purely positive terms. There is very little in the way of criticism, despite the fact that guerrilla gardeners often colonise space not only without the permission of the local authority, but also without permission of those who reside nearby. Guerrilla gardening could even be occurring on your street corner or grass verge, perhaps even without you knowing. Interviews with those living close to the sites colonised by the gardeners revealed that not everyone was happy. Some were angry about not being involved, or perplexed as to the appeal of produce grown in such harsh roadside environments. Furthermore, the guerrilla gardeners, especially F Troop, would provide little maintenance of the site, which would soon fell into disrepair between digs.  Guerrilla gardening can make significant changes to our landscapes: the case of Incredible Edible Todmorden demonstrates the potential of this activity. Many large urban agricultural initiatives have stemmed from underground gardening, such as New York’s community gardens or Havana’s allotments; Carrot City, an exhibition on urban agriculture, which I brought to the UK in 2012, features even more examples of projects which started through guerrilla gardening. Yet while guerrilla gardeners often improve spaces, there is a need to delve deeper and provide a more objective account of their actions; reflecting not only on what the gardeners do, but their impact on the area and the community as a whole."
"Fish are acutely aware of sea temperature; it’s one of the key reasons particular species of fish live where they do. As the oceans warm however, many tropical species are moving towards cooler climes. So might the traditional cod and chips one day be replaced by Nemo and chips?  It’s a big question, as the distribution of species across the Earth is one of the most fundamental patterns in ecology. All plants and animals are of course adapted to a limited set of climatic and environmental conditions; if the climate changes, we expect distributions to change. This matters not only because we like to eat many of the species in question, but also because entire ecosystems appear to depend on the number of interacting species present.  In general the tropics have more different species than the poles. This pattern, known as the latitudinal diversity gradient, holds true for plants and animals across the world both on land and in the sea. Compare a rainforest or a coral reef with icy tundra or the Arctic ocean.  As ever in the natural sciences, it’s much easier to describe a pattern than to explain its cause but we do know that temperature seems to have a important role, as solar radiation increases levels of primary production. Temperature impacts the food that species can eat and also their metabolic rates and activity levels.  In aquatic systems, temperature also strongly affects the amount of oxygen that can be dissolved in the water. Changes in temperature, therefore, are very likely to lead to changes in the distributions of marine species, and the current trend of warming temperatures is driving fish away from the tropics and towards the poles. We need to know what’s lurking round the ecological corner. Miranda Jones and William Cheung of the University of British Columbia have modelled the changes in marine species’ ranges – and by summing up, changes in overall biodiversity – expected under the IPCC’s different climate change scenarios. The research, published in the Journal of Marine Science, looks at the known distribution of around 800 marine fish and invertebrate species, matches their distributions with environmental conditions and then projects where these species are likely to be found under future environmental scenarios. Abandoning the tropics: The authors find that tropical seas, particularly the shallow highly diverse seas of South-East Asia are likely to suffer the most local extinctions, while polar – and particularly Arctic – seas are likely to see the greatest number of invasions. Consequently cold regions will generally see biodiversity increases, while tropical regions will suffer. In total, marine fish and invertebrates are expected to shift 26km per decade towards the poles under the IPCC’s worst case scenario (3°C warming by 2100). Even under the best-case scenario, fish will move 16km per decade. Similar predictions have been made before and the fishing industry has certainly seen this coming, with infrastructure already being put in place to exploit expected higher catches in Arctic regions. But what is new in this study is an approach combining several different models of species distributions. By looking at agreements between models, the authors identify likely regional hotspots of both extinction and invasion, marked with black diagonal lines in the maps above and below. Going polar However, while the idea of tropical fish invading chillier waters might sound fun, we’re unlikely to eat Nemo and chips in London any time soon. Temperature (or climate) is not the only limit to a species’ distribution; suitable habitat must also exist. Clown fish such as Nemo need to live in a coral reef and such reefs are complex ecological communities themselves with all sorts of environmental requirements.  At the moment ecological and climate models do not allow us to include interactions between species as additional factors that limit movements. This may significantly alter individual species’ ranges. Competition from well-established resident fish may discourage new arrivals, for instance, or some fish may rely on a different species specifically to feed their young – if the food for the juveniles does not move in the same way as for the adults, then the species range will not change. While it might be tough to predict exactly how fast things will change, or what it will lead to, the general message from this study is clear: change is coming to marine ecosystems. We can’t take the current distribution of marine life for granted."
"**Dozens of cases of Covid linked to an Aberdeenshire food plant are being investigated.**
NHS Grampian said that 78 detected cases had been associated with the Kepak McIntosh Donald plant in Portlethen.
An incident management team has now been set up to monitor the situation involving the premises.
The news came as 122 new Covid cases were reported in Grampian, up from 49 on Tuesday.
NHS Grampian said: ""Following a small number of confirmed cases associated with the plant - and after discussions with management there - we offered asymptomatic testing to all employees on Monday. More than 200 staff took up the offer.
""These results are now being processed and account for much of the increase in our case numbers in Grampian.
""They are not the only reason behind today's increase in case numbers - we continue to see other clusters of cases and the virus continues to circulate in the community.""
The statement added: ""There is no evidence at this time to suggest this cluster has spread beyond those working at the plant. Given the large number of people who were tested it is likely further cases could be confirmed."""
"

Does global warming threaten to permanently cripple the global economy? According to a new report from the British Treasury prepared by economist Nicholas Stern, that’s exactly what will happen unless we cut greenhouse gas emissions to 25 percent below current levels by 2050. Should we do it? A close reading of the report reveals that the answer is “not necessarily.” 



Not to be flip about it, but why should the relatively poor (us) sacrifice for the relatively rich (our children and grandchildren)? The Stern Report argues that the emissions cuts necessary to stave off disaster will likely cost about 1 percent of global GDP every single year, or about $1,154 in current dollars per household in the United States. A small price to pay, we’re told, when GDP losses will likely total 5–10 percent of global GDP every year if we do absolutely nothing. 



But even with a 10% reduction in GDP relative to what it would have been, 100 years from now, people will still be extraordinarily well off by current standards. For example, since 1950 real U.S. GDP per capita has increased by about 2% a year. Given that growth rate, real GDP per capita one hundred years hence would be $321,684, or more than 7 times higher than it is at present ($44,403). If global warming cuts GDP by 10% a year beginning about 50 years from now, then GDP per capita will be $289,515 in 2106 rather than $321,684. 



Would anyone, let alone liberals, ever propose a 1% tax on those who make $44,000 to create benefits for those who make $289,000? In short, paying now to head off warming is a regressive intergenerational tax that takes from the poor and gives to the rich. 



The direct costs associated with greenhouse gas emission controls include avoidable deaths in the developing world. The United Nations, for example, reports that about 2 million people on this planet die every year because they don’t have electricity and must burn biomass for heating and cooking. This results in greatly elevated levels of indoor air pollutants and premature deaths. Increasing the cost of electricity – an unavoidable consequence of ridding the global economy of the fossil fuels that generate greenhouse gases – will slow our ability to conquer this problem. 



Higher fossil fuel costs will also slow the general march out of poverty. Not only is poverty the number one killer on the planet, it is also the number one cause of environmental ruin. Deforestation, habitat loss, and air and water pollution are all strongly correlated with per capita income. 



Nor are citizens in the industrialized West immune from the health effects associated with reduced income. Academics have established that every $15 million reduction of aggregate income causes one statistical death. That stands to reason; the poorer we are, the less likely we are (on average) to eat well, exercise, procure necessary health care services, and avoid unhealthy lifestyles. This effect alone suggests that in the U.S., greenhouse gas abatement, on the scale suggested by the Stern report, would cost more than 8,800 lives per year. 



Of course, the Stern Report argues that the GDP losses associated with doing nothing dwarf the GDP losses associated with effective emissions controls. In a world with no doubts, spending 1% of U.S. GDP to eliminate a loss of 10% of U.S. GDP every year beginning 50 years from now passes a cost‐​benefit test if we assume that GDP grows 2% per year, we discount future costs and benefits by 5% a year, and run our analysis out for 1,000 years. That calculation reveals that the present value of the costs would total $15,541 while the present value of the benefits would total $36,477. If the future stream of benefits were only 5% of future GDP, however, then it’s about a wash; $15,541 would get us only $18,239 in benefits. 



But climate predictions are not certain. The Stern report argues that there’s at least a 50–50 chance that temperatures will rise 5 degrees Celsius over pre‐​industrial levels if we do nothing. You won’t find that argument in the latest report of the International Panel on Climate Change (IPCC), however, which offers a wide band of possible warming scenarios. The Stern Report’s estimate is within the upper boundary of what’s possible, but median warming projections are around 2–3 degrees Celsius. 



It’s worth noting that when economists have crunched those median warming projections in the academic literature, they have found that the costs associated with climate change are 0 – 2% of GDP rather than the 5 – 10% asserted in the Stern report. If the benefits are only 2% of future U.S. GDP, then $15,541 in costs in present value terms produces only $7,295 in benefits. 



Finally, none of the above calculations consider the possibility that the costs will buy no benefits at all. The latest IPCC report, for instance, notes that the warming we’ve detected thus far is “unlikely (bordering on very unlikely) to be entirely the result of internal variability,” and that “natural forcing alone [i.e., solar and/​or volcanic activity] is unlikely to explain the increased rate of global warming since the middle of the 20th century.” 



No matter how you read that, it’s clear that there is greater than zero chance that greenhouse gas emission cuts will produce no economic gains at all. Accordingly, all the benefit estimates above must be discounted to some degree (how much is in dispute) to reflect that possibility. 



Think of the Stern Report as an elaborate economic pitch for an expensive insurance policy. Well, we’re not buying … yet.
"
"
There’s been a lot of worry and speculation over what will happen if a hurricane and the gulf oil spill collide. In response, the National Hurricane Center (NHC) has prepared a document answering some of the questions. There’s of course, a lot of uncertainty too.
Hurricane Katrina Aug28, 2005


What will happen to a hurricane that runs through this oil slick?
• Most hurricanes span an enormous area of the ocean (200-300 miles) — far wider than the current size of the spill.
• If the slick remains small in comparison to a typical hurricane’s general environment and size, the anticipated impact on the hurricane would be minimal.
• The oil is not expected to appreciably affect either the intensity or the track of a fully developed tropical storm or hurricane.
• The oil slick would have little effect on the storm surge or near-shore wave heights.
What will the hurricane do to the oil slick in the Gulf?
• The high winds and seas will mix and “weather” the oil which can help accelerate the biodegradation process.
• The high winds may distribute oil over a wider area, but it is difficult to model exactly where the oil may be transported.
• Movement of oil would depend greatly on the track of the hurricane.
• Storms’ surges may carry oil into the coastline and inland as far as the surge reaches. Debris resulting from the hurricane may be contaminated by oil from the Deepwater Horizon incident, but also from other oil releases that may occur during the storm.
• A hurricane’s winds rotate counter-clockwise.
Thus, in VERY GENERAL TERMS:

A hurricane passing to the west of the oil slick could drive oil to the coast.
A hurricane passing to the east of the slick could drive the oil away from the coast.
However, the details of the evolution of the storm, the track, the wind speed, the size, the forward motion and the intensity are all unknowns at this point and may alter this general statement.

Will the oil slick help or hurt a storm from developing in the Gulf?
• Evaporation from the sea surface fuels tropical storms and hurricanes. Over relatively calm water (such as for a developing tropical depression or disturbance), in theory, an oil slick could suppress evaporation if the layer is thick enough, by not allowing contact of the water to the air.
• With less evaporation one might assume there would be less moisture available to fuel the hurricane and thus reduce its strength.
• However, except for immediately near the source, the slick is very patchy. At moderate wind speeds, such as those found in approaching tropical storms and hurricanes, a thin layer of oil such as is the case with the current slick (except in very limited areas near the well) would likely break into pools on the surface or mix as drops in the upper layers of the ocean. (The heaviest surface slicks, however, could re-coalesce at the surface after\ the storm passes.)
• This would allow much of the water to remain in touch with the overlying air and greatly reduce any effect the oil may have on evaporation.
• Therefore, the oil slick is not likely to have a significant impact on the hurricane.
Will the hurricane pull up the oil that is below the surface of the Gulf?
• All of the sampling to date shows that except near the leaking well, the subsurface dispersed oil is in parts per million levels or less. The hurricane will mix the waters of the Gulf and disperse the oil even further. Have we had experience in the past with hurricanes and oil spills?
• Yes, but our experience has been primarily with oil spills that occurred because of the storm, not from an existing oil slick and an ongoing release of oil from the seafloor.
• The experience from hurricanes Katrina and Rita (2005) was that oil released during the storms became very widely dispersed.
• Dozens of significant spills and hundreds of smaller spills occurred from offshore facilities, shoreside facilities, vessel sinkings, etc.
Will there be oil in the rain related to a hurricane?
• No. Hurricanes draw water vapor from a large area, much larger than the area covered by oil, and rain is produced in clouds circulating the hurricane.
Learn more about NOAA’s response to the BP oil spill at http://response.restoration.noaa.gov/
deepwaterhorizon.
Document available in PDF form here.
Will the oil slick help or hurt a storm from
developing in the Gulf?
• Evaporation from the sea surface fuels tropical
storms and hurricanes. Over relatively calm water
(such as for a developing tropical depression or
disturbance), in theory, an oil slick could suppress
evaporation if the layer is thick enough, by not
allowing contact of the water to the air.
• With less evaporation one might assume there
would be less moisture available to fuel the
hurricane and thus reduce its strength.
• However, except for immediately near the source,
the slick is very patchy. At moderate wind speeds,
such as those found in approaching tropical
storms and hurricanes, a thin layer of oil such as
is the case with the current slick (except in very
limited areas near the well) would likely break into
pools on the surface or mix as drops in the upper
layers of the ocean. (The heaviest surface slicks,
however, could re-coalesce at the surface after the
storm passes.)
• This would allow much of the water to remain in
touch with the overlying air and greatly reduce
any effect the oil may have on evaporation.
• Therefore, the oil slick is not likely to have a
significant impact on the hurricane.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b5bf2a5',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterWhat is it going to take? They deny their own data and insist fantasy is correct.
The MAIL Online writes today has an excellent report, and starts with:
The supposed ‘consensus’ on man-made global  warming is facing an inconvenient challenge after the release of new temperature data showing the planet has not warmed for the past 15 years…based on readings from more than 30,000 measuring stations.”
Yet the MetOffice, the supplier of that data, says (the MAIL writes):
“…because the impact of the sun on climate is far less than man-made carbon dioxide. Although the sun’s output is likely to decrease until 2100, ‘This would only cause a reduction in global temperatures of 0.08C.’ Peter Stott, one of the authors, said: ‘Our findings suggest  a reduction of solar activity to levels not seen in hundreds of years would be insufficient to offset the dominant  influence of greenhouse gases.”
Is Stott sane, or what! What little reduction we’ve had in solar activity in just the last 4 years has already offset the GHG effect – no warming in 15 years! The MAIL writes:
In 2007, the Met Office claimed that global warming was about  to ‘come roaring back’. It said that between 2004 and 2014 there would be an  overall increase of 0.3C. In 2009, it predicted that at least three of the years 2009 to 2014 would break the previous temperature record set in 1998.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Wrong on every count. And so what is their reaction? Here’s what the MAIL tells us:
But yesterday a Met Office spokesman insisted its models were still valid.
This is more than stupid – it’s hopelessly stupid. Even though the models don’t work, they insist they’re still valid. This is like saying the well is poisoned, but the water is still safe to drink!
The MAIL interviewed Nicola Scarfetta, who says that eventually they are going to have to admit they are wrong. Judith Curry was more direct, saying: “…the models may have severe shortcomings…’ and that “many scientists’not surprised'”.
Readers, if you like this Mail article, then you are going to like Sebastian Lüning’s and Fritz Vahrenholt’s book: Die kalte Sonne (The Cold Sun). The lay it all out. Only morons and blind ideologues will go on continuing to believe the CO2 bullshit.
Read more: http://www.dailymail.co.uk/sciencetech/article-2093264/Forget-global-warming–Cycle-25-need-worry-NASA-scientists-right-Thames-freezing-again.html#ixzz1ks3bcDhU
 
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhat if scientists one day concluded that climate was influenced mostly by natural factors and that man had little impact? What would be the result? For one, lots of people would find themselves in the unemployment line. And for many, their companies and operations would have to close shop. Hat-tip: Reader DirkH.
One person who likely would be negatively impacted is Katherine Hayhoe, who is not only an atmospheric scientist with expertise in climate modelling, regional climate impacts and science-policy interface at Texas Tech, but also happens to be CEO of ATMOS Research and Consulting, a Lubbock-based company “providing detailed reports, maps, and other graphics that vividly illustrate changes that have already been observed, as well as highlighting the possible future impacts of climate change over the coming century“.
The bold print in layman terms: climate fortune-telling services.
Climate consulting is surely a business that derives much benefit from the notion that climate change is now happening rapidly and that a catastrophe is imminent. A lot folks want to know what to do in order to prepare, and Katherine takes big money for telling them.  I really don’t see how it is possible for people like Ms Hayhoe to avoid conflicts of interest here. Is it possible to remain objective in a science when you run a business whose very success depends on the output of that science? God knows that consulting fees are exorbitant. Tempting to say the least.
Should we be surprised that Hayhoe, as the CEO and top beneficiary of the climate consulting company, is a big proponent of climate catastrophe scenarios? Seems it would certainly help the ATMOS bottom line.
And how much of the services rendered by ATMOS are actually sourced from the tax-payer funded university where Hayhoe is a professor? As a professor at a state university, is she using research money and all the number-crunching facilities there to supply reports that ATMOS Consulting in turn sells at a high price to clients (after a little cut and paste editing)?  I’d like to know what part of them high-priced consulting reports were actually generated by ATMOS resources alone, and what part was actually generated by her employer Texas Tech (taxpayer). Would Hayhoe confirm it’s 100%/0%?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




ATMOS is an ideal set-up as a real money-making machine: scare the bejesus out of clients on one side, and sell them lucrative consulting services on the other. Though legal, there seems to be some ethical issues here.
And who are her clients? What proportion are private and what proportion are taxpayer funded government agencies, who just happen to love scary reports that sway public opinion? It all seems dubious to me and the potential for conflicts of interest is simply too high.
Crystal ball services: possible 100-year scenarios
The ATMOS website does not provide any information about the quality of its products, especially its climate forecast-related scenarios. Do they come with a guarantee? We get the sense that they don’t and that it’s mostly speculation dressed up to look scientific. Indeed if there is no guarantee, then it would be safe to say that ATMOS is actually selling high-priced crystal ball fortune-telling services. The ATMOS website writes that they “provide possible impacts of climate change over the coming century.”
Read the fine print – no money back!
 
 
Share this...FacebookTwitter "
"If money seems scarce, Clydesdale Bank notes are about to become much more so. The brand's owner, Virgin Money, is retreating from its contracts to supply cash machines run by rival lenders.
No longer will you get a crisp Clydesdale polymer note when drawing cash out of Santander, TSB, Co-op or Asda machines. The contract to supply them is being taken over by the other issuers of notes, Royal Bank of Scotland and Bank of Scotland.
You might think this reflects the fast-declining use of cash. And that may be part of the story.
We're learning today of new Bristol University research for the Financial Conduct Authority showing a 19% reduction, or more than 10,000, in free-to-use cash machines in the two years to last March, while there was a 15% decline in the number of withdrawals.
The move to infection-free contactless card payments during the Covid crisis has accelerated the reduced use of readies.
But this has more to do with the even faster-declining use of the Clydesdale Bank brand, 182 years after its founding in Glasgow.
By the end of February, it will have disappeared from the fascia of all its branches, replaced by Virgin Money.
That bank, based in Edinburgh, was taken over by Clydesdale, or to be more accurate, its parent company listed on the stock market as CYBG. The 'Y' stands for its other legacy brand, Yorkshire Bank.
In a reverse brand takeover, licensed from Sir Richard Branson's Virgin Group, CYBG last year renamed itself Virgin Money. Its plan is to use that to expand beyond Scotland and its Yorkshire turf as the leading challenger to the UK's dominant big five retail and business lenders.
This leaves a banknote anomaly - entirely appropriate, given that Scottish banknotes are themselves anomalous.
Clydesdale Bank, no longer a trading brand, will continue to appear on the notes you get out of Virgin Money cash machines, but not any others.
The idea of issuing a Virgin Money banknote must have appealed to Sir Richard Branson, particularly if his cheerful physog appeared on it with an airliner or balloon. But that's not happening.
Virgin Money is not saying how much cash it's retiring as notes are returned, but it will be a big reduction from the Â£2.3bn which I'm told is now in circulation - around 47% of the Scottish banknote total.
You wouldn't bet on it continuing indefinitely, because it's an odd and expensive advertising and marketing tool to support a brand being consigned to history.
That, after all, is what Scottish banknotes are - something with which to irritate London cabbies, and advertising for their issuers.
It wasn't always thus. Banknotes were an innovation in the early days of Scottish banking, when late 17th Century famine meant gold currency had to be spent on importing food. With gold therefore in very short supply, the banknote represented a promise to refund the holder who presented it with precious metal coinage.
As notes were issued in greater number than the gold and silver that backed them in the vaults, banks innovated in expanding credit. But they had to do so carefully. In the 18th Century, they were at risk of rival banks presenting them with a lot of notes at once, an unscrupulous tactic which sank some issuers.
The modern-day equivalent would be a run on a bank, when savers panic and demand to get their money out, far in excess of the funds available on the day. Remember the queues outside Northern Rock in 2007 - one of the first indications in Britain of the underlying pressures that led to the financial crash the following year?
The Scottish history of this is detailed in the recent magnificent history of Edinburgh (and Scottish) finance, City of Money, penned by Ray Perman.
He relates the dirty tricks visited by the Bank of Scotland, the 'Old Bank' on the Royal Bank of Scotland, 'the New Bank'.
But when two Glasgow rivals were founded, known as the Ship and the Arms banks reflecting the heraldry they used, the established Edinburgh rivals joined forces to see off the Weegie threat. It's a story worth repeating.
Their threats and dirty tricks included successfully blocking the use of Glasgow notes to pay Customs and Excise. But Glasgow's tobacco merchants were loyal to their own.
In 1757, the Edinburgh banks were approached by one Archibald Trotter, a former trade financier, with a plan to undermine the Glasgow challengers.
On a salary of Â£150 and supplied with Â£5,000 in credit, Mr Trotter set up on Clydeside as a dealer in bills of exchange, intending to put the Glasgow banks under pressure with his demands for collateral coinage. The Glasgow bankers, writes Perman, quickly realised what he was up to, and the Arms Bank decided to have fun at his expense.
""They limited the hours when they were prepared to redeem notes, and paid him only in sixpences. There were 40 sixpences to the pound and Trotter was presenting Â£100 or more at a time, giving ample scope for error and delay.
""The bank teller would laboriously count out the tiny silver coins, occasionally losing count and having to begin again, or dropping one on the ground, providing another excuse for restarting the process anew, or finding one which might have been tampered with and having to go off to get a second opinion as to whether it was valid or not. If they ran out of time, the process had to be restarted the following day.""
Banking hours were short, notes Perman, because counting coins by candlelight in winter was a risky business.
Mr Trotter's venture didn't last long. But from my experience, anyone who has spent any time more recently in an Indian bank branch probably knows how he felt."
"**People have been urged to be cautious of the risk of spreading coronavirus when rules are relaxed over Christmas.**
Up to three households will be allowed to stay together and form a ""Christmas bubble"" from 23 to 27 December, as agreed by all four UK nations.
A scientific adviser to the government said the relaxation of rules amounted to ""throwing fuel on the Covid fire"".
Meanwhile, it is expected most areas of England will be placed in the middle tier of a toughened three-tier system.
Details on what will happen when the current lockdown ends on 2 December will be announced on Thursday. The decision will be based on a number of factors including case numbers, the reproduction rate - or R number - and pressure on local NHS services.
BBC political editor Laura Kuenssberg says a ""handful"" of areas will be in the lightest regime of limits - tier one - but most of the country is likely to be in either tier two or three.
She said London is expected to be placed in tier two.
The measures for Christmas will see travel restrictions across the four nations, and between tiers and levels, lifted to allow people to visit families in other parts of the UK.
Anyone travelling to or from Northern Ireland may travel on the 22 and 28 December, but otherwise travel to and from bubbles should be done between the 23 and 27.
People will not be able to get together with others from more than two other households, and once a bubble is formed, it must not be changed or be extended further.
The guidance says a bubble of three households would be able to stay overnight at each other's home but would not be able to visit hospitality, theatres or retail settings.
Prime Minister Boris Johnson has told people to use ""personal judgement"" on whether to visit elderly relatives.
In a video message from Downing Street, the prime minister described the agreement as a ""special, time-limited dispensation"", saying: ""This year means Christmas will be different.""
Mr Johnson said people must consider the risks of who to form a bubble with and whether or not to visit elderly or vulnerable relatives, adding: ""Many of us are longing to spend time with family and friends... And yet we can't afford to throw caution to the wind.""
He added: ""'Tis the season to be jolly but 'tis also the season to be jolly careful.""
The prime minister has also reassured children that Father Christmas ""will be packing his sleigh and delivering presents this Christmas"".
In response to a letter from eight-year-old Monti, Mr Johnson said Father Christmas would not be a risk to children's health but that ""leaving hand sanitiser by the cookies is an excellent idea"".
It comes as the government recorded another 18,213 Covid cases in the UK. Figures also showed a further 696 people had died within 28 days of a positive test.
The number of deaths is the highest since the start of May and compares to 608 recorded on Wednesday.
BBC health editor Hugh Pym says many of those who have died are likely to have picked up an infection before the current lockdown measures were put in place. He said a rise in the death toll would not be expected to continue into December because the average number of daily cases is now falling and hospital admissions are levelling off.
A mid-week rise can also be down to delays in deaths being reported over the weekend.
First Minister of Wales Mark Drakeford said the ministers agreed they had to ease the rules because people would have flouted restrictions - creating further risk - if they were told Christmas had been ""cancelled"".
Ministers were shown behavioural science evidence that ""too many people simply would not have been prepared to have gone along with such an instruction"", he told BBC Breakfast on Wednesday.
Mr Drakeford also said a UK-wide approach to coronavirus rules after Christmas was needed.
Nicola Sturgeon has said guidance for people in Scotland is still being finalised and will be issued on Thursday, but that her government will not be ""encouraging"" people to meet up.
""The expectation should be that the guidance will probably look to tighten around the edges rather than further expand and that will be true with the travel window of opportunity as well - we want to limit that window, not expand it,"" the first minister said.
Published guidance for England gives further details of the rules for 23 to 27 December:
Prof Andrew Hayward, director of the UCL Institute of Epidemiology and Health Care, and a member of the government's Sage committee, told BBC Newsnight allowing families to meet up over Christmas amounted to ""throwing fuel on the Covid fire"".
He said it would ""definitely lead to increase[d] transmission and likely lead to third wave of infections with hospitals being overrun, and more unnecessary deaths.""
Prof Hayward said while you cannot ban Christmas, he called for clearer messaging to families about the ""dangers"" of socialising and inter-generational mixing.
Gavin Terry, head of policy at the Alzheimer's Society, said thousands of relatives would be in ""complete despair"" at government guidance which says only care home residents of working age should be allowed to leave their care homes to visit family, due to the increased risk of exposure to the virus.
""After eight harrowing months filled with devastation and tragic loss of life, the announcement that many care home residents will be facing Christmas alone is just heartbreaking,"" he said, calling for further testing to allow for more visits.
Meanwhile, Emma McClarkin, chief executive of the British Beer and Pub Association, called on ministers to publish evidence for its Christmas bubble rules, which would ""inflict unnecessary pain and irreversible damage on our sector"".
Local rules mean many pubs and restaurants - such as those in England's tier three or Scotland's level four - will remain closed during the festive period, irrespective of the Christmas change.
**How will your Christmas plans be affected?**haveyoursay@bbc.co.uk **.**
Please include a contact number if you are willing to speak to a BBC journalist. You can also get in touch in the following ways:
If you are reading this page and can't see the form you will need to visit the mobile version of the BBC website to submit your question or comment or you can email us at HaveYourSay@bbc.co.uk. Please include your name, age and location with any submission."
"
Josh of Cartoons by Josh writes: Another in the Surreal Climate series – in response the WUWT story about the EPA rejecting CO2 petitions
I think we all know what the decent thing to do would be…


A couple of weeks ago I started a new series called ‘Fantasy Climate’ where anything goes really – even the title apparently!
So the next week I called it ‘Surreal Climate’ – H/t Tallbloke – rather a nice allusion to another blog.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a1ceebe',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"
By Steve Goddard

Guardian  photo : Ann Daniels Enjoying The Warming Arctic
Yesterday, WUWT  reported on a University of Melbourne study claiming that melting  ice is behind the warming of the Arctic.
“Findings  published in Nature today reveal the rapid melting of sea ice has  dramatically increased the levels of warming in the region in the last  two decades. The sea ice acts like a shiny lid on the Arctic Ocean. When  it is heated, it reflects most of the incoming sunlight back into  space. When the sea ice melts, more heat is absorbed by the water. The  warmer water then heats the atmosphere above it.”
If this were true, we would expect to see that months with the most  ice loss would also show the most warming.  In fact, we see the exact  opposite.  As you can see in the graph below, most Arctic  warming from 1979-present has occurred in the winter and spring,  with very little warming during the summer.

By contrast, ice extent  trends over that same time interval show that ice loss has  occurred mainly during the summer.  It appears that the relationship  between warming and ice loss is inconsistent with the claims in the  University of Melbourne study. Temperatures have increased the least  during times of year when ice loss was the greatest.

April is the month which has warmed the most, a full seven months  after September – the month of peak ice loss.  There is very little  variation in ice extent year over year during April – except for this  year which is running well above any other recent years.

http://ocean.dmi.dk/arctic/icecover.uk.php
A couple of other familiar graphs showing the same issues can be seen  below.  Note in the DMI  graph below that Arctic temperatures have not warmed at all during  the summer in the central Arctic.

In the Cryosphere  Today graph below, you can see that most ice loss has been during  the summer, when there has been little or no temperature gain.

The scatter plot below shows Arctic temperature trends vs. the  absolute value of ice extent trends, for all 12 months.  Note that there  is no meaningful correlation between temperature trends and ice loss.   In fact, the months with the most increase in temperature seem to be  the ones with little ice loss.

The article claims
” Strong winter warming is consistent with the atmospheric  response to reduced sea ice cover.”
But  this is inconsistent with the fact that there has been very little  reduction in winter ice cover.  The temperature of water under the  winter sea ice is fixed by thermodynamics at -2C down to a depth of tens  of metres, and does not vary from one year to the next. Furthermore,  the rate of heat transfer through 2-5 meter thick 99+% concentration  ice, is very low. NSIDC is currently showing ice  extent right at the 1979-2000 mean, and above the 1979-2009 mean –  yet temperatures in the Arctic have been well above the mean all through  the spring.  How is the heat escaping through all the thick, high  concentration ice?

http://ocean.dmi.dk/arctic/meant80n.uk.php
The article also claims :
“reduced summer sea ice cover allows  for greater warming of the upper ocean….The excess heat stored in the  upper ocean is subsequently released to the atmosphere during winter.”
There is a major problem with that  theory.  The summer minimum occurs at the autumnal equinox when the  Arctic is receiving almost no SW radiation, and that which is being  received is well below the critical angle of water.  By September, the  shortage of insulating ice cover is actually causing a net loss of heat  from the ocean.  NSIDC  explains it like this:

“In the past five years,  the Arctic has shown a pattern of strong low-level atmospheric warming  over the Arctic Ocean in autumn because of heat loss from the ocean back  to the atmosphere. ….  As larger expanses of open water are left at  the end of each melt season, the ocean will continue to hand off heat to  the atmosphere.”


In other words, loss of summer ice  should produce atmospheric warming in the autumn, but not in the winter  and spring when ice is cover is normal or near normal.
Two years ago, WUWT published this article after review by Walt Meier at NSIDC, Roger Pielke Sr. at CU,  and Ben Herman at the University of Arizona.  It explains why changes in  ice cover probably are causing a net cooling effect.  None of the  reviewers had any substantive disagreements with the conclusions.
Conclusion: The University of Melbourne study claims are not  supported by the available data.  The authors seem to have jumped right  into statistical analysis without proposing a physical mechanism that  works.  Heat flows across differences in temperatures, yet the winter  water temperature under the ice is fixed at -2C.  Thus elevated winter  air temperatures should actually cause a reduction in heat flow out of  the ocean.  Whatever is driving increases in winter Arctic temperatures  is not heat coming out of the Arctic Ocean, which is covered with  insulating ice.
A more logical conclusion would be that the decline in ice thickness  is associated with warmer winter temperatures.
If scientific reasoning  were limited to the logical processes of arithmetic, we should not get  very far in our understanding of the physical world. One might as well  attempt to grasp the game of poker entirely by the use of the  mathematics of probability.
– Vannevar Bush


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8bebf274',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**The Blackpool Illuminations are to be switched back on when the national lockdown ends.**
The resort's famous light display was suspended on 4 November, although Blackpool Tower has continued to shine.
The illuminations will light up the resort from Wednesday until 3 January to give people ""a lift"", said Blackpool Council.
Neil Jack, council chief executive, said he hoped it would bring ""a little bit of cheer"" to people living locally.
""We're putting them back because retail will be open so we would have Christmas lights on anyway,"" he said.
""But also I think everybody could do with a bit of a lift.""
He added bringing ""a little bit of cheer in the winter months won't do any harm"" to people living in the area.
The illuminations had been due to shine for an extra two months this season, until 3 January, to aid the town's tourism trade hit by Covid-19 restrictions.
_Why not follow BBC North West on_Facebook _,_Twitter _and_Instagram _? You can also send story ideas to_northwest.newsonline@bbc.co.uk"
"
While Americans continue to put global warming aka climate change at the bottom of the list of worries, it seems the electronic media outlets that most often push alarming climate stories are losing favor. This interesting juxtaposition was from my Shoptalk TVSpy business newsletter today:
CNN Fails to Stop Fall in Ratings – from The New York Times

CNN continued what has become a precipitous decline  in ratings for its prime-time programs in the first quarter of 2010, with its  main hosts losing almost half their viewers in a year.
The trend in news ratings for the first three months of this year is all up  for one network, the Fox News Channel, which enjoyed its best quarter ever in  ratings, and down for both MSNBC and CNN.
CNN had a slightly worse quarter in the fourth quarter of 2009, but the last  three months have included compelling news events, like the earthquake in Haiti  and the battle over health care, and CNN, which emphasizes its hard news  coverage, was apparently unable to benefit. More… 

Fox News Has Best Quarter In  Network History – from Mediaite

Fox News had their best year of all time  in 2009. Now that we’ve finished the first quarter of 2010, it’s clear FNC is  showing no signs of letting up –they just finished their best quarter ever, in  total day total viewers.
It was also the second highest rated quarter ever in prime time total  viewers.
While Fox News continues to see record ratings, their cable news competitors  are dropping off even more year-to-year. In the A25-54 demographic during prime  time, FNC was up 16%, while CNN dropped 42%, MSNBC was down 22% and HLN was down  40%. More… 


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8d315c1f',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**Now is the ""time to unite"" across Northern Ireland in order to push down the spread of Covid-19, Health Minister Robin Swann has said.**
He was speaking two days before tougher lockdown restrictions come into force for two weeks.
On Wednesday, seven more Covid-19 related deaths were recorded by the Department of Health.
That brings the total number of coronavirus-related deaths in Northern Ireland to 954.
Speaking at a press conference at Stormont, Mr Swann said if everyone in Northern Ireland follows the lockdown rules, it will make a difference leading up to Christmas.
""Our actions now will have a bearing on the kind of Christmas we can all have,"" he said.
""The greatest gift we can give loved ones this year is to look after them.
""Some restrictions may be relaxed coming up to Christmas but maximum vigilance will still be required - a festive free-for-all would mean a New Year crisis.""
The minister acknowledged the importance of Christmas to many people but said there was ""still work to do"", before people could enjoy a break.
He warned that people should also follow the ""stay at home"" guidance as much as possible.
Northern Ireland's Chief Medical Officer, Dr Michael McBride, said undoubtedly allowing people to bubble with three households over Christmas ""carried some risk"" and would lead to an increase in cases.
But he said he recognised that relaxing household restrictions temporarily would benefit many people and their mental health, given the isolation experienced this year due to the pandemic.
A total of 533 new positive cases of Covid-19 were recorded by the Department of Health on Wednesday.
It said this was higher than normal due to an issue with the ""flow of data"" from Pillar 2 testing on Tuesday when it recorded just 79 new positive cases.
There have been 50,676 positive cases in Northern Ireland since the pandemic began, with 2,421 people testing positive in the last seven days.
There are currently 443 people with Covid-19 being treated in Northern Ireland, 36 of those are in intensive care units (ICU).
Overall bed capacity within the health service is currently at 98%, with two hospitals - the Ulster and the Causeway - operating beyond their capacity.
Dr McBride said the R-number, the rate of coronavirus transmission, remains around one, and that Northern Ireland's hospitals remain under ""significant pressure"".
""We now have a lower incidence than England and Wales, but the incidence here in Northern Ireland remains higher than the Republic of Ireland,"" he added.
These two weeks are absolutely critical in trying to get the R number down.
It has moved slightly below one, but health authorities want it down a lot further, and that will depend on what we all do over the next couple of weeks.
If we get R down over the next fortnight, there's a better chance of the hospitality sector opening up.
The chief medical officer has said hospitality can't stay closed indefinitely, but clearly it won't reopen until the R number comes down.
Northern Ireland's Covid statistics are starting to come down a little bit.
The number of deaths has come down; the number of people in intensive care units has come down and - quite dramatically - outbreaks care homes have come down a lot, reducing by about 20 care homes over the last week or so.
So that's all very good, but what is different this time around is the very high number of people who remain in hospital.
That's because we know more about how to treat people - more people are surviving which is a good thing.
That means our hospitals are still very, very busy
The department also reported there are 140 active care home outbreaks of the virus in Northern Ireland.
Mr Swann said he did not believe that the doors of care homes in Northern Ireland should be closed to visits, in order to manage Covid-19 infections.
It follows reports that some care homes are not facilitating access for families to visit loved ones.
Guidance on visiting care homes and hospitals changed in October, with visits limited to one family member once a week.
Mr Swann said ""contact is so important"", and said he wanted more care homes to facilitate visits or arrange ""care partners"" for families wanting to spend time with their relatives.
Speaking about the potential upcoming vaccination programme, Mr Swann said ""intensive preparation"" is under way for a mass vaccination programme in Northern Ireland.
He said he would bring a presentation to the executive on Thursday about what that programme could look like.
The minister added that all authorisation and checks would need to be carried out before vaccines could be administered.
Mr Swann added that 600 people, including retired health care workers, have come forward to volunteer as vaccinators.
This compares to 880 vaccinators currently working in the health trusts.
There is a light at the end of this long tunnel,"" said the health minister, stressing that nothing should be taken for granted."
"In January, after she posed for a photo in Davos alongside Greta Thunberg and several other white climate campaigners, the Ugandan activist Vanessa Nakate was dismayed to see that the Associated Press news agency had cropped her out of the image. It started a global conversation about how the voices of black, Asian and minority ethnic people are erased from the climate crisis movement. Climate activism has historically been perceived as a white, middle-class pursuit, but nothing could be further from the truth. Across the UK, BAME people are at the forefront of the fight against the climate crisis. Now, their efforts are being recognised by the Climate Reframe Project, an initiative spotlighting BAME voices in climate activism, funded by the Joseph Rowntree Charitable Trust and the Solberga Foundation, and put together by the team behind former Irish president Mary Robinson’s Mothers of Invention podcast. Today, it features a list of the leading figures in the UK, some of whom shared their stories with me.  Why have BAME activists so often been ignored? “Historically, the environmental movement comes from a white, privileged background,” says Suzanne Dhaliwal, 37, who is researching BAME representation in the climate justice movement at the University of Brighton. “But climate change mostly affects people in the global south, so it’s fair to elevate those voices.” Many of the people I speak to have at times felt excluded. Nish Doshi is a 32-year-old climate justice organiser from Edinburgh. When Doshi – who is non-binary, and uses they/them pronouns – goes to Cop26 organising meetings for civil society alongside NGO leaders, they often find they are one of the few BAME people in the room. “There will be 50 or 60 people there, and hardly any people of colour,” they say. “They don’t even think about that at all.” Criticism has also been levelled at Extinction Rebellion (XR), with BAME people pointing out that its tactic of encouraging protesters to get arrested ignores the reality that people of colour are disproportionately likely to be targeted in their interactions with police. Yet BAME people have been central to climate activism for decades. Farhana Yamin, 55, is the international climate lawyer responsible for getting the target of net zero emissions by 2050 included in the Paris accord. She came up with the goal after growing tired of the incremental advances promised by the carbon emission trading system. “I wanted to think bolder and bigger – no more mucking around with carbon budgets,” Yamin says. “These gases are toxic. We shouldn’t create trading systems for toxic pollutants.” Recent years have seen the movement work to address its diversity problem. “When Vanessa was cropped out of that photo, that brought about a lot of healthy debate,” says Tyrone Scott, 28, an activist from London. He has been working tirelessly to get younger people into the movement, going into pupil referral units to teach students about the climate emergency. “They are so engaged,” Scott says. “It gives you so much hope for the future.” The 16-year-old Londoner Jessica Ahmed says she used to think: “Climate change doesn’t affect me. It’s not an African-person problem.” But she became an activist after attending the May 2019 school climate strikes. “I’ve never fallen behind with school,” she says. “I think I’m more on track than most people who don’t go on the strikes.” She now organises for the UK Student Climate Network, mobilising her classmates. “It sucks that we have to miss school,” she says. “But we need to make our voices heard because it’s us that are going to be the most affected by climate change.” Like Ahmed, the Manchester-based pupil Lillia Adetero, aged 10, has been striking from school, attending the Fridays for Future protests since January 2019. She often gives speeches at these strikes. “I talk about how climate change is going to affect our future and how the government isn’t doing enough,” she says. Adetero was delighted by the court of appeal ruling against the third Heathrow runway. “I’m very happy that Heathrow has been cancelled,” she says. “I’d like them to stop the Manchester airport expansion, too.” Others are trying to change the system from within. Scott stood as a Green MP candidate in Hackney South in 2019, doubling the party’s share of the vote. “It was a good experience,” he says. “But I was relieved the day after the election, I’m not going to lie. I was out every day, delivering thousands of leaflets for 10 hours at a time.” Fatima Ibrahim, 27, from London, is a codirector of the Green New Deal UK, which lobbies for the British government to put the climate crisis at the heart of the economic system, rather than seeing it as a stand-alone issue. “We have an economic system that isn’t working for the climate,” she says. “We need a system-wide change.” Her activism is cutting through: the Green New Deal was included in the 2019 Labour and Green manifestos. Many BAME activists feel a connection to the cause because they have family members in the vulnerable global south. Ibrahim is of Somalian heritage; her parents moved to the UK from Canada when she was nine. Climate activism has been her life’s work. “I was that crazy nine-year-old who watched Newsnight,” she says. “Coming from a refugee family made me aware of everything that was going on in the world. And it became clear to me that climate change was the biggest threat to people everywhere. If you care about injustice or refugees, all of those things will be 100 times worse if we don’t deal with the climate crisis.” She sees her Muslim faith as integral to her activism. “I have a responsibility for the people around me and a commitment to my community and other people,” she says. Other activists have turned to nonviolent direct action to force the government to pay attention. Yamin joined XR after becoming depressed by Donald Trump’s decision to pull out of the Paris accord, and the release of an Intergovernmental Panel on Climate Change report in 2018 that warned we had only 12 years to avert climate catastrophe. “I fell into a state of real depression – actual depression – which I’d never had before,” says Yamin. “I felt that we had failed. We hadn’t saved the world at all. It felt really bleak.” Direct action felt like a necessary corrective. “Our laws were being flouted,” says Yamin. “Laws that I helped put in place were being totally ignored.” She attended a number of XR direct actions. “I tried being arrested a few times and failed,” she jokes. “I thought: ‘I have to work harder at this being-arrested thing.’” Eventually, her wish was granted: Yamin was arrested after gluing herself to the Shell headquarters as part of the April 2019 XR protests. But it’s possible to make a difference in less dramatic ways. “It was amazing,” says 38-year-old Dave Fuller, from London, of his experience cooking for the anti-fracking protesters at the Preston New Road site near Blackpool. “When people are doing frontline work, all they want at the end of the day is a hot meal. I went up worrying that people would feel like I wasn’t fulfilling my part, but everyone was thankful someone was willing to turn up with hot food on a cold day.” He now works for Repowering, an initiative bringing affordable renewable energy to local communities. The law can also be a powerful tool. When Tessa Khan, a 37-year-old lawyer from London, heard about a landmark case brought by 900 Dutch citizens against their government for failing to uphold its climate commitments, she phoned the lawyers working on it. “I thought they were amazing,” says Khan. She went on to cofound the Climate Litigation Network, which helps citizens around the world to sue their governments on climate-crisis-related issues. “The gap between what the governments are supposed to be doing to stop global warming and what they are actually doing is growing by the day,” says Khan. Her team of four lawyers is supporting activists in Ireland who are bringing a case against the government to demand more aggressive action on the climate crisis. “We need to hold governments accountable for the promises they are making,” says Khan. “In our view, it’s unlawful for them to be as deeply negligent as they are.” All the activists I speak to are passionate about amplifying the voices of BAME people. “A big part of what I do is pushing for voices from the global south to be included in the climate change discussion,” says Doshi. They run workshops on climate colonialism and speak at events for youth leadership. “We need more black, brown and working-class voices to be heard,” agrees Adetero. “They don’t really get the opportunity to have their voices heard that white people do.” These are challenging times. “I am depressed about things,” says Doshi. “I see Trump pulling out of the Paris accord, the Trans Mountain pipeline in Canada, Bolsonaro taking away indigenous lands in Brazil.” But in spite of everything, there is also hope. “I feel like we have no choice but to be optimistic,” says Ibrahim. “The climate movement is massively growing. We’re reaching new people. The narrative is changing. We have to keep fighting against all odds.”"
"
When you think of NASA and crashes, you think of things like this:

But, you usually don’t think about government balloon crashes being “dramatic”, unless of course it’s a balloon crash in Roswell, NM in 1947.
Watch this video from Australia’s ABC:
A huge NASA balloon loaded with a telescope painstakingly built to scan the sky at  wavelengths invisible to the human eye crashed in the Australian outback Thursday,  destroying the astronomy experiment and just missing nearby onlookers, according to  Australian media reports.
In dramatic video released by the Australian  Broadcasting Corporation (ABC),  the giant 400-foot (121-meter) balloon is seen just beginning to lift its payload,  then the telescope gondola appears to unexpectedly come loose from its  carriage. The telescope crashes through a fence and overturn a nearby parked sport  utility vehicle before finally stopping.
Video via Space.com/Yahoo News:

Fortunately, nobody was hurt, but as you can see in the video, it was a close call.
h/t to Steve Goddard


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8c3254af',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterGerman site CO2 Handel here writes about a survey on the sentiment of Germans with regards to climate change and their will to do something about it.
It’s no surprise that a vast majority of Germans believe that man is profoundly changing the climate. The major media outlets feed Germans with a constant stream of climate doom & gloom, and rarely mention science that shows otherwise.
But what is surprising is the number of Germans who say they do not plan to change their lifestyles at all “to save the climate”. They agree that something has to be done to protect the climate, but they are not willing to make any sacrifices. CO2 Handel writes:
Two thirds (66 perecent) in a survey for Hamburg-based news magazine Stern declared that they would not do more for climate protection today than before.”
The survey also shows, despite the media bombardment of dire climate prognoses, that Germans are not afraid of a climate catastrophe.
Only 31 percent fear dramatic consequences for nature and environment (women 36 percent).”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




A huge number are skeptical that governments will be able to stop climate change.
According to the Stern survey, 84 percent do not believe the goverments will be able to stop climate change.
And these 84% should continue to believe this, because climate change cannot be stopped. Anyone who claims it can is nothing less than a huge charlatan. That means 16% are completely duped and actually believe that the UN and IPCC can control the climate. Talk about utter ignorance.
If the survey says anything, it is that even if you do manage to convince the population, it doesn’t mean they are going to agree to make sacrifices. So, good luck in implementing climate protection policies in countries with high levels of skepticism. First you have to stop the growing trend of skepticism, then you have to convert their beliefs, and then you’ll have to convince them to make sacrifices, which is the hardest thing to do.
The survey was based on 1001 representatively chosen German citizens on December 1 – 2, 2011 . The margin of error is : ± 3%. The survey was conducted by Forsa, for Stern.
Not surprisingly, the major media outlets buried the survey results.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWhile reps from European countries are in Durban demanding we go green, CO2 Handel here reports that the very same governments are cutting back on “climate protection” investments. That makes Durban a farce.
According to a report called Durban Dynamics: Navigating for progress on climate change“, by consultancy Ernst & Young, governments around the world are drastically cutting back their investments in climate protection. In the worst case up to $45 billion are planned to be cut from environmental protection measures. The reason they say is the global financial mess.
Now if these investments were truly as lucrative as many like to claim they are, why on Earth would they cut back on them? The answer is obvious: That green energy is lucrative is a lie. It’s been a scam from the first day.

CO2 Handel writes:
If one sums up the already decided savings measures, then a you get a cut of $22.5 billion. ‘If the debt crisis continues to escalate and countries should then become forced to pass additional comprehensive savings measures, then in the worst case that number may double.’ said Peter Nolden, Partner at Ernst & Young.
Strangely, the lion’s share of these cuts is taking place in Europe, the very continent that constantly preaches the global warming doctrine and insists the rest of the world do as it says.  Germany already plans $2 billion less investment in “climate change fighting” projects by 2015. Bankrupt Spain, once a champion in solar energy, is cutting back a whopping $5.1 billion and Great Britain will cut back $4.2.
If push comes to shove (and with the financial situation progressing as it is, that’s very likely) then “the German government in the worst case will cut $8.3 billion in climate costs,” writes CO2 Handel. Other countries to make cuts: USA $6.4 billion and Japan $6.1 billion.
I financial crisis means that fiscal discipline needs to be exercised. Of course you cut out what is wasteful. Do you think the greens have ever wondered why Europe and the US find themselves flat broke? Refusing to heed reality has something to do with that.
 

Share this...FacebookTwitter "
"Christiana Figueres, the Costa Rican diplomat who was an architect of the worldwide Paris climate agreement, is enraged. She thinks you should be too. She was traveling in 2017 when Donald Trump made plans to announce the US withdrawal from the pact. Perched at the end of her hotel bed with pen and paper, she decided to write down each correct statement she heard.  “The speech finished and my piece of paper was completely blank,” Figueres told the Guardian in an interview. “There was not a sentence uttered in that whole speech that was correct, true or even informed.” With tiny silver frogs dangling from her ears and strung around her neck, the small-framed Figueres is animated as she recalls the story, alternately pushing back in her chair and lowering her head toward her crossed arms. Trump gave his remarks in the White House Rose Garden, a venue typically reserved for major events. “My first thought was the poor roses, they had to listen to all this,” Figueres said. Figueres, who was executive secretary of the UN Framework Convention on Climate Change, could easily be swallowed up by her anger at the intensifying climate crisis. But instead she has become an advocate for positivity about climate action. Despite Trump’s planned withdrawal, not a single nation has followed suit. Countries that agreed to the Paris deal, however, are not on track to fulfill their obligations. And, even if they were, their actions wouldn’t be enough to stall significant global warming. Figueres and her former senior advisor Tom Rivett-Carnac, who was once a Buddhist monk, have written a book they pitch as “surprisingly optimistic”. It’s titled The Future We Choose: Surviving the Climate Crisis, and it offers two contrasting visions for how the world might look in 30 years. They also have a podcast, called Outrage and Optimism. Rivett-Carnac said people can be upset and positive at the same time. “We see this form of stubborn optimism as a way of changing the world,” he said. It’s not like we wake up every morning thinking, ‘everything’s ok, don’t worry.’” Figueres argues that society is “paralyzed and obsessed about the consequences of climate change,” and hasn’t been able to separate that fear from the upsides of cutting the fossil fuel and other emissions heating the planet. She lists the possible benefits: stronger economies, energy independence, a livable environment, breathable air, less time wasted commuting, improved health, an increased connection to nature, and “on and on,” she says. Trump believes the Paris deal would sink the US economy. In Figueres’ mind, if there was any country aware of the growth opportunities from addressing the climate crisis, it was the US. “There was hardly any country that had actually gone into such an analysis of the text,” she said. “Frankly, there was barely a country that contributed as much to the text … It’s very sad when you basically cut your nose off to spite your face.” She said “the sad thing is that the US has become irrelevant in the most consequential challenge that humanity has faced,” clarifying that she meant the federal government, and not the states, localities and businesses that have stepped up to make their own pledges in its place. The book and podcast come as eco-anxiety is growing, particularly among younger people. Nearly half of US adults under the age of 35 say stress about climate change affects their lives, according to a poll by the American Psychological Association. Among all adults, seven in 10 say they wish they could do more to combat climate change, but 51% say they don’t know where to start. Figueres wants those people to take their power back. “We would say what makes you feel better quickly is actually to engage in a positive contribution so that you bust through this myth that individual actions don’t count And you begin to realize the world is only made out of individual actions,” she said. “It does count. It does add up.”"
"
Steve Goddard writes:
Below are  animations for the entire year (150 days) so far, based on NOAA SST maps. The  videos are presented with minimal commentary. As they say, “150  pictures are worth 150,000 words.”

El Niño has faded and may be switching genders.

The Northern Pacific has been generally below average.

The tropical Atlantic has warmed significantly over the year, heading in  to the hurricane season.

The ocean just south of Greenland has been persistently above average  temperatures.

Antarctic waters have been getting colder, which is reflected in the  growth of ice.

Arctic waters have been warm on the Atlantic side, and cold on the  Pacific side. This is reflected in excess ice near Alaska and  deficiencies near Greenland and Svalbard.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b287ff1',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"
Share this...FacebookTwitterNo surprise here. Just more inconvenient results for CO2 broken-record dogmatists.
New paper: GISS temps and solar activity
A recent paper published by the Journal of Atmospheric and Solar Terrestial Physics (74) 2012 87-93 and authored by Souza Echer et al. suggests that solar cycles, to a substantial extent, drive global temperatures, and that likely through amplification mechanisms.
Solar particles interact with Earth’s magnetosphere. (Source: NASA)
 
The paper is titled: On the relationship between global, hemispheric and latitudinal averaged air surface temperature (GISS time series) and solar activity.
The authors decomposed average air surface temperature series obtained from GISS and sunspot number (Rz) from 1880 – 2005 to see if a correlation could be found. They performed a cross correlation analysis between band-passed filtered data around 11-year and 22 years.
Although the authors did not find a strong correlation with the 11-year solar cycle, they found a “very significant correlation” in the 22-year Hale cycle band. The abstract states:
A very significant correlation (Rz 0.57 to 0.80) is found in the 22 yr solar Hale cycle band (16–32 years ) with lags from zero to four years between latitudinal averages air surface temperature and Rz. Therefore it seems that the 22 yr magnetic field solar cycle might have a higher effect on Earth’s climate than solar variations related to the 11-yr sunspot cycle.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Well then, can we not assume that if the 22-year cycles have an impact, also the 78-year, 210-year, and 1000-year solar activity cycles must have a “significant correlation” with the earth’s climate too? Already there are dozens of proxy records showing that this is precisely the case.
Recall that the CO2 warmists in their half-baked models stubbornly keep focusing only on total solar irradiance (TSI), which itself varies only about 0.1% over an 11-year cycle (and thus by itself is no real climate driver) and ignore all the other amplification mechanisms. Well, the results of this study, as do dozens of others studies, show you can’t do that. Like it or not – the sun is a real player. Eventually the CO2 warmists will have to admit this, as anyone with even just an inkling of intuition would do.
New paper: investigating the cosmic ray link
Obviously there are others who feel the same way when it comes to the role of the sun on the earth’s climate. Another paper just published at the same journal shows that other scientists are hot on the sun’s trail. Here Magee and Kavic in their paper titled: Probing the climatological impact of a cosmic ray–cloud connection through low-frequency radio observations suspect a solar mechanism and so propose a method of observation. In the abstract they write:
…in order to establish whether or not such a relationship exists, measurements of short-timescale solar events, individual cosmic ray events, and spatially correlated cloud parameters could be of great significance. Here we propose such a comparison using observations from a pair of radio telescopes arrays,the Long Wavelength Array (LWA) and the Eight-meter-wavelength Transient Array (ETA). These low-frequency radio arrays have a unique ability to simultaneously conduct solar, ionospheric and cosmic rays observations and are thus ideal for such a comparison.”
The direction of climate science and investigation is clear. The real discoveries will involve unraveling the solar mechanisms, and not baking simplistic, straight-line CO2-temperature models. With each new study, the CO2 warmists look more and more like broken records that keep repeating: CO2…CO2…CO2…CO2…
Obviously some scientists just aren’t clever enough to snap out of it.
Additional resources:
http://climaterealists.com/attachments
 
Share this...FacebookTwitter "
"

The British government released the Stern Review on global warming by Nicholas Stern, a former chief economist for the World Bank. As an economist, I tend to leave this topic to my Cato Institute colleague Pat Michaels, a professor of Environmental Sciences at the University of Virginia. Since Mr. Stern is also an economist, however, the rules of logic and evidence that economists use should also apply to this report. 



“Economic forecasting over just a few years is a difficult and imprecise task,” the review cautions, so forecasting technology a hundred years from now “requires caution and humility.” Unfortunately, there is little caution or humility in this report. 



The 27‐​page summary begins by saying, “The current level of greenhouse gases in the atmosphere is equivalent to around 430 parts per million (ppm) CO2, compared with only 280 ppm before the Industrial Revolution. These concentrations have already caused the world to warm by more than half a degree Celsius.” 



More specifically, that 54 percent increase of greenhouse gases was apparently associated with a warming of only 0.6 degrees Celsius, give or take two‐​tenths. Citing a 2001 survey of “high projections” for global warming, however, the report claims that a much smaller, 28 percent increase in greenhouse gases by the year 2050 could result in a “global average temperature rise” exceeding 2 degrees. 



Yet if we use the same rule‐​of‐​thumb now used to predict 2 to 3 degrees more global warming by 2050, the much larger increase in greenhouse gases ever since 1750–1850 should already have increased the average global temperature by at least 2 degrees. But it didn’t. 



Suppose this theory works this time, and the Earth actually warms by 2 to 3 degrees Celsius, putting aside what it means to average Chicago’s winters with Key West’s summers. The Stern report reluctantly concedes that places like Canada, Russia and Scandinavia would likely experience “higher agricultural yields, lower winter mortality, lower heating requirements and a possible boost to tourism.” 



Plants thrive in greenhouses, particularly fruits and vegetables. The report claims biodiversity would be at risk, as though no threatened species could possibly benefit from milder winters. 



And the report thinks malaria would increase, as though mosquitoes are picky about the climate. My great‐​grandfather J. Mason Reynolds died of malaria in Grand Rapids, Mich., in 1891. 



Naturally, The Washington Post seized this opportunity to complain that “Bush has declined to sign the 1997 Kyoto Protocol.” Yet the United Nations just reported that from 2000 to 2004 greenhouse gas emissions increased 4.6 percent in Canada, 2.4 percent in Europe and 1.3 percent in the United States. Besides, as the Stern report notes, “most future emissions growth will come from today’s developing countries, because of their more rapid population and GDP growth and their increasing share of energy‐​intensive industries.” 



As I have often noted, passenger cars are not nearly as large a share of greenhouse emissions as people think. In fact, this report’s first graph shows transportation accounting for less than 14 percent of greenhouse gas emissions — the same share as agriculture or industry. Trucks, buses and cars account for less than 10 percent of global greenhouse gas emissions. Electricity is a much bigger offender, which must be why Hollywood lefties are infatuated with electric cars. 



Two contradictory dogmas of the anti‐​auto cult are that consumption of fossil fuels will continue to increase just as rapidly as it has in the past and that fossil fuels will become increasingly expensive because we have passed the peak of oil. 



If the second prediction were correct, people would find ways to use less oil. Because some of Mr. Stern’s conclusions are “based on simple extrapolations,” however, he must and does argue that the world has “an abundant supply of fossil fuels.” Otherwise, we wouldn’t need thousands of international bureaucrats being bribed to decide which uses of fossil fuels are more meritorious than others, and which “alternative” fuels merit the biggest subsidies. 



Mr. Stern’s view of “sensible policies” involves a truly global system of high carbon taxes, tough regulations and generous subsidies “across both developed and developing nations.” Because “low‐​carbon technologies are currently more expensive than fossil‐​fuel alternatives,” he would heavily tax cheaper fuels and subsidize expensive ones. A high and “broadly similar price of carbon” throughout the world is apparently to be enforced in some way by the notoriously ineffectual United Nations and World Bank. 



The Washington Post described the Stern Review as proof that “failing to curb the impact of climate change could damage the global economy on the scale of the Great Depression or the world wars by spawning environmental devastation.” But such sensational comments about “worst‐​case scenarios” use strong words to conceal weak logic and nonexistent facts. 



For one thing, the disaster scenarios largely depend on unconvincing assertions pretending to link “extreme weather events” — such as “heat waves like that experienced in 2003 in Europe” — to extremely gradual and highly variable changes in the average temperature of many nations. The report says, “The risk of outcomes much worse than expected are very real and they could be catastrophic.” But any outcomes that are “very real” must to some extent be expected in a report claiming to deal in probabilities. And why is there no comparable assessment of outcomes much better than expected (such as the past 200 years)? 



There is repeated abuse of the old trick of switching from talking about things that could conceivably happen to things that would happen. Mr. Stern writes that “the temperatures that may result from unabated climate change would take the world outside the range of human experience.” 



The most widely reported conclusion of the Stern Review is that keeping a lid on greenhouse gases would cost “only” about 1 percent of world GDP (about $607 billion last year). Yet the fine print says the actual estimates “are clustered in the range of 2 percent to 5 percent of GDP,” with some estimating costs as high as 15 percent of GDP. 



There may be something truly informative and original concealed within the 700 pages of the Stern Review, but it does not appear as easy to find as the rough edges.
"
"
Share this...FacebookTwitterJoachim Gauck (Photo by J. Patrick Fischer)
Now that Christian Wulff has resigned in disgrace from the office of President of Germany in the wake of a scandal, a new nominee has been found: former pastor and anti-communist  Joachim Gauck. He is expected to be appointed easily.
If you’re like me, the question that comes to mind is: How skeptical is he when it comes to climate science? Surprisingly, there are signs for optimism.
First a bit of background from Wikipedia, my short version:
Endured brutal Soviet occupation
Joachim Gauck was born in Rostock in 1940, is a German politician, Protestant pastor, and former anti-communist human-rights activist in East Germany. His family was a victim of Soviet persecution. When Joachim Gauck was eleven years old, his father disappeared after being arrested by Soviet occupation forces. He was accused of espionage and deported to a Gulag in Siberia, where he was severely mistreated. For nearly three years, the family knew nothing about what had happened to him and whether he was still alive. Only in 1955, he was freed.
An “incorrigible anti-communist”
Gauck’s political activities were inspired by the ordeal of his father, and stated that he grew up with a well-founded anti-communism. In school in East Germany he made no secret of his anti-communist position, and he steadfastly refused to join the Free German Youth. He became a pastor in the Protestant church in Mecklenburg. His work as a pastor in East Germany was very difficult due to the hostility of the communist regime towards the church, and for many years, he was under constant observation and was harassed by the Stasi secret police.The Stasi described Gauck in their file on him as an “incorrigible anti-communist”.
“Tireless pro-democracy advocate”
During the Revolutions of 1989, he was a co-founder of the New Forum opposition movement in East Germany, which contributed to the downfall of the Soviet-backed dictatorship of the Socialist Unity Party of Germany (SED). Following the Reunification of Germany, he was elected by the Bundestag as the first Federal Commissioner for the Stasi Archives, serving from 1990 to 2000. As Federal Commissioner, he earned recognition as a “Stasi hunter” and “tireless pro-democracy advocate,” exposing the crimes of the former communist political police.
Gauck’s views today
Gauck today does not belong to any particular party. His views on an array issues are unknown. But perhaps some of his earlier comments can provide valuable clues.
According to the FAZ, Gauck is quoted as saying:
I’m unbelievably allergic to any politics that reacts to fear. This also applies to other issues, for example the use of nuclear power. We should refrain from forms of actions that are based on the fear of people and derive a dynamic from it.”
Surely he must be absolutely aware of the crude fear driving the global warming movement.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Sueddeutsche Zeitung here provides more interesting quotes and insights on controversial issues.
Occupy-Wall-Street movement
While the media found general praise for the protesters, Gauck had another opinion. He found it “inexpressibly absurd” that people were demonstrating against the unbridled power of the financial markets, and called the dream of a world that simply does away with markets a “romantic idea” and that it is mistake to think that it would be nice to conquer capital.
On the Stuttgart-21-mega rail station project
Here warned of a growing culture of protest. He characterized the German tendency to fall into hysteria and fear as “abhorrent”.
On Thilo Sarrazin
The politically incorrect Sarrazin dared to question multi-culturalism in Germany, Gauck said Sarrazin “showed courage” writing his controversial best-seller Deutschland schafft sich ab (Germany is going down the tubes). “He spoke about a problem that exists in our society more openly than the politicians.”
Climate change?
That’s the mystery – one that even has the warmists a bit worried and wondering. We do know he is no fan of fear and intimidation. A few hours with a good skeptic would probably suffice. The warmists such as Klimaretter have already researched Gauck and found little. That’s encouraging. If he felt half-strong about climate change, then he would have said something to support combating it. But if he disagrees with all the hysteria, and wished to avoid poking a hornets’ nest, then he would have remained silent. That is precisely what he has done on the issue.
Here’s what the warmist Klimaretter (Climate Rescuer) writes about Gauck:
The word “climate change” up to now has only appeared when he criticized the German’s so-called addiction to fear that he himself diagnosed and placed it, from his perspective, on a level with swine flu and e-coli.  Otherwise: a total blank. Gauck’s ecological plea: total silence.”
and,
Gauck, the President to be, is a contemplative man who is certainly ready to reconsider his own positions. Perhaps this will be true for his so far neglected “green” issues. One thing is clear: With this guy, the country will experience some surprises.”
Gauck appears to be a man of principle, integrity – someone who thinks policies have to be based on foundations of truth. The climate movement and its promises, like communism, are not; they are based on a plain lies and distortions. The movement is driven by fear and hysteria over scenarios 100 years in the future. This is not the sort of thing a man like Gauck readily embraces.
 
Share this...FacebookTwitter "
"**There have been more than 1.6 million confirmed cases of coronavirus in the UK and about 60,000 people have died, government figures show.**
However, these figures include only people who have died within 28 days of testing positive for coronavirus and other measures suggest the number of deaths is higher.
**Find out how the pandemic has affected your area and how it compares with the national average:**
If you can't see the look-up click here.
After the first peak in April, cases started rising again in July, with the rate of growth increasing sharply in September and October, before falling again in the past two weeks.
On Wednesday, the government announced a further 16,170 confirmed cases.
It is thought the infection rate was much higher during the first peak in spring, but testing capacity at the time was too limited to detect the true number of daily cases.
The data for cases can also be broken down by region and comparing the change in those figures by week gives a sense of where there has been a recent increase in newly-reported infections.
Coronavirus infections in England have fallen by about a third during lockdown, according to a major study carried out by Imperial College London.
While some of the worst-hit areas saw the biggest improvements, cases have remained relatively high across England, according to the React-1 study, which is based on tests of more than 100,000 people between 13-24 November.
The latest figures from the Office for National Statistics (ONS), suggest about one in 185 (16,400 people) in Wales had the virus in the week ending 21 November.
In Northern Ireland rates are thought to be decreasing at around one in 145 people (about 12,700 people), while in Scotland, the figure was one in 115 (about 45,700 people).
The average number of daily deaths began to rise again in September, following the first peak in April.
On Wednesday, the government announced a further 648 deaths.
Of these, 555 deaths were in England, 51 in Wales, 38 in Scotland, and four in Northern Ireland.
Rules were amended over the summer to include deaths in the coronavirus total only if they occurred within 28 days of a positive test. Previously in England, all deaths after a positive test were included.
England has seen the majority of UK deaths from Covid-19. Using the 28-day cut-off, there have been more than 52,000.
Although hospital admissions for Covid-19 remain below the levels seen in the spring, there are big regional disparities.
The North West, North East and Yorkshire, and Midlands have seen the highest number of admissions but the situation in all three now appears to be improving.
Cases have risen across large parts of England, with other spikes in areas of Scotland, Wales and Northern Ireland.
The red areas on the map below are those currently seeing the highest number of cases per 100,000 people.
Restrictions have been tightened across the UK in an effort to tackle the number of rising cases.
In England, each local authority has been placed in one of the new three tiers following the end of the recent national lockdown.
Wales has announced a range of further measures, including a ban on pubs, restaurants and cafes serving alcohol, from Friday 4 December.
In Northern Ireland, a further two-week ""circuit-break"" lockdown began on 27 November.
Scotland has a five-tier system of alert levels with different measures in place in different parts of the country.
UK leaders have agreed to allow up to three households to meet indoors during a five-day Christmas period of 23-27 December.
When looking at the overall death toll from coronavirus, official figures count deaths in three different ways.
Government figures count people who died within 28 days of testing positive for coronavirus.
But there are two other measures.
The first includes all deaths where coronavirus was mentioned on the death certificate, even if the person had not been tested for the virus. The most recent figures suggest there had been almost 70,000 deaths by 20 November.
The second measure counts all deaths over and above the usual number at the time of year - that figure was more than 75,000 by 20 November.
The most recent figures available from the ONS are for the third week of November, which show there were 14,276 deaths registered in the UK.
Some 3,038 of these deaths involved Covid-19 - 199 more than the week before.
Deaths normally do rise at this time of the year, but the data from the ONS and its counterparts in Scotland and Northern Ireland show the second wave of the virus has pushed the death rate above the average seen over the past five years by about 21%.
Overall, the figures are still well below the peak of 9,495 deaths recorded in a week, reached on 17 April.
The ""R number"" is the average number of people an infected person will pass the disease on to.
If R is below one, then the number of people contracting the disease will fall; if it is above one, the number will grow.
The government's current estimate for the R number across the whole of the UK is 0.9 to 1.
The estimate for England is 0.9 to 1, while for Scotland it is 0.8 to 1. The estimate for Wales is 0.8 to 1 and in Northern Ireland it is 0.9 to 1.1.
The government has said in the past that the R number is one of the most important factors in making policy decisions."
"**A bar where fans were filmed celebrating Scotland's Euro 2020 win in apparent breach of Covid rules has had its temporary licence extended.**
Jubilant fans cheered, danced and hugged at the Draft Project in Aberdeen as Scotland beat Serbia on penalties on 12 November.
Dozens of complaints were lodged.
Aberdeen's licensing board has now approved the occasional licence, subject to additional conditions including no televised sport.
There were three votes to approve the application but also three votes to refuse.
Board convener Marie Boulton's casting vote at Wednesday afternoon's meeting extended the temporary licence, which will be in operation until 4 December.
She described the scenes as a ""moment of madness"" and hoped people would have ""learned a lesson"".
A representative for PB Devco, the owner of the pop-up bar, said they appreciated the concern at the footage.
PB Devco also runs the nearby Soul Bar, where eight Aberdeen FC players visited in breach of the coronavirus rules earlier this year.
Scotland's 23-year absence from major men's tournaments ended with the victory over Serbia.
They will face England, Croatia and the Czech Republic in Group D at next summer's finals."
"
I’ve been proverbially “sick as a dog” this weekend either from stomach flu, or some food poisoning, not sure which. Spending so much time in bed, I almost forgot to put up my flag today. My neighbors must have wondered why this disheveled man with messed up hair and a three day beard was in a bathrobe out in front of my house this morning.

I put up my flag to remind myself, my family, and my neighbors how much we have to be grateful for, and how much we owe the people that have fought to keep our freedoms. Though lately, the war has changed from one of guns and bombs to one of bureaucracy and paper.
On the plus side, we could live here:

Nighttime satellite  photo of North and South Korea. Note the one light in North Korea.
There’s a great list on Listverse about the psychotic leader of North Korea: Top  10 Crazy Facts About Kim Jong Il
This one was a hoot:
The “Fact”: He is the best natural golfer in history
In 1994, it was reported by Pyongyang media outlets that Kim Jong Il  shot 38 under par on a regulation 18-hole golf course – including 5  holes in one!  That score is 25 shots better than the best round in  history, and is made even more amazing by the fact that it was his first  time playing the sport.  It’s said Kim Jong Il would routinely sink 3  or 4 holes in one per round of golf, and – lucky for the PGA – he has  since given it up.
He lies better than Tiger Woods, and that’s saying something.
I’m thankful we live in America, where if you hear a whopper like that, you can at least laugh about it without being executed.
I wonder if “Tamino” or Eli Rabbet bothers to fly a flag on memorial day? Here’s to hoping that they do.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b384083',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"

A little story popped up in the press today that offers what my wife and I, in the context of our responsibilities toward our 4 year-old son, often refer to as ""a teaching moment."" That opportunity is afforded by an accusation out of Greenpeace this morning that Cato, along with 40 other policy organizations, are wholly-owned subsidiaries of Exxon-Mobil and thus should not be trusted.   
  
The contention that Exxon-Mobil funding colors Cato’s analysis (with contributions, by the way, that accounted for less than 1/10th of 1% of our budget in 2006) is compelling only if Greenpeace has some sort of “motive detection device” that can be produced for public inspection. For instance, I say I'm motivated by genuine skepticism that industrial greenhouse gas emissions will usher in the _Book of Revelations_. They say I'm motivated by greed. We can settle this argument to the satisfaction of some third-party observer ... how exactly? Even administering me with liberal doses of sodium pentathol is unlikely to settle this little spat about the nature of my character.   
  
The truth is that my colleagues at Cato and I are skeptical about the end-of-the-world scenarios bandied about by zealots like Greenpeace, we anchor that skepticism in the peer-reviewed scientific literature, and that skepticism naturally attracts funding from those parties who like what they hear. Arguing that causality actually works the other way is not only an unproved and unprovable assertion (let's call it ""faith-based argumentation""), it is impossible to square with all the work we’ve published arguing against many of the things the oil industry is known to support.   
  
For instance, we have vigorously argued against President Bush’s national energy strategy and the resulting Energy Policy Act of 2005, called for the dismantlement of the Strategic Petroleum Reserve, railed against federal oil and gas subsidies, argued for the elimination of the Clean Air Act rules that allow older refineries to escape tough anti-pollution standards, suggested giving the Arctic National Wildlife Refuge to the Greens to do with as they wish, argued against allowing cost-benefit analysis to dictate environmental standards, and defended the government’s right to renegotiate drilling leases in the Gulf of Mexico that provided highly favorable contractual terms to some oil companies.   
  
Regardless, Greenpeace’s assertions — even if true — are founded upon a classic logical fallacy. For those who never took a course in logic, it's called ad hominem. Despite what the body politic might otherwise believe, the merit of an argument has nothing to do with the motives of the person making that argument.   




For instance, if the Institute for Policy Studies argues that minimum wage laws have little net effect on unemployment and produce citations in the literature to back that up, the reply that “IPS is staffed by a bunch of socialists who simply want to bring down capitalism and should thus not be listened too” persuades only those people who are too intellectually lazy or mentally impaired to think straight. Similarly, if Cato argues that it’s very hard to justify tight greenhouse gas emissions controls using strict cost-benefit analysis — and provides academic citations to back that up — the charge that “Cato is paid by Exxon-Mobil to take that position and thus shouldn’t be listened too” is likewise a variation of the argument made famous by Joe McCarthy. ""He's evil — and thus a liar.""   
  
And in that vein, notice the thinly veiled smear entailed in Greenpeace's constant use of the phrase “climate denial” and its related cousins. In this context, it's obviously meant to echo the ugly ""climate denial is like Holocaust denial"" charge rampant at some high-decibel quarters on the Left. Greenpeace's strategy here is to leave no insult or character smear off the table in its drive to censor the policy debate.   
  
That Greenpeace resorts to such a tactics does not surprise. Those with good arguments pound the arguments; those with poor arguments pound the table. God forbid Greenpeace grant that people of good will might actually disagree with them. And God forbid that we ask people to judge an argument by the facts rather than some schoolyard game of ""you stink.""


"
"In the wake of the devastating Australian bushfires, Jeff Bezos announced last month that he will donate $10bn to fight the climate crisis. As a resident of California and the former president of the Sierra Club Foundation, I welcome any contribution toward the struggle against our changing climate. That said, my home state, like all communities with Amazon facilities, would be far better off if Bezos simply paid his taxes. If Amazon’s properties in California were taxed at their current value, the added tax could help bolster our underfunded firefighters and fix our crumbling fire access roads. Contributing vast sums to the global effort is wonderful, but climate change is a local issue too. Our communities need to be well-funded if we’re going to face this threat head-on.  How California fights climate disruption will be a model for states and local governments nationwide, and if this effort fails in California, I worry what others will be able to accomplish. With a rapidly changing climate and underfunded emergency response systems, California residents could soon face another situation like the devastating 2018 wildfires. California’s formerly annual fire season has become a year-round phenomenon; the fires are now larger, hotter and burn longer than ever before. To combat the growing destructive power of these fires, we need a robust and well-equipped emergency response system. That requires raising more revenue. The commercial loophole in Proposition 13, which allows many corporations in California to avoid paying significant amounts of property taxes, unintentionally depleted the funding our communities now desperately need. As a result, our emergency response systems have suffered. According to the California Professional Firefighters, the number of unfulfilled requests for resources and equipment has grown over the past few years despite those resources being needed more urgently than ever. Worse, the Trump administration has promised to cut millions of dollars from the US Forest Service’s firefighting services, with additional cuts to funding for local volunteer firefighting departments. As a result of these shortfalls, firefighters across the state have been forced to appeal to voters to raise taxes to secure consistent funding. That’s a shame. Our public emergency services shouldn’t have to beg for the funding that they need to operate in the largest and most prosperous state in the country. However, there is a simple solution to this issue. Schools and Communities First is a ballot measure for the upcoming 2020 election that seeks to level the playing field by taxing commercial and industrial properties at a fair market value, rather than the decreased value they now use as a result of longstanding loopholes in the state tax code. It is estimated to reclaim $12bn every year, with 60% of that total going toward local governments, including local fire districts. Since the initiative has a clause to exclude small businesses, we can be sure that funding for our neglected public services will come only from wealthy businesses who are currently avoiding paying their fair share. Under the current tax loophole, large industries that have held their land for a long period receive an unfair advantage because their property is undertaxed compared to its current day value. For example, according to an analysis by the Proposition 13 campaign, Chevron underpays up to $100m every year on their Kern county holdings. In Chevron’s case, that same property leaked over 82m gallons of crude oil intermittently since 2003; the company recently sealed up a disastrous 800,000-gallon leak. It makes no sense for us to continue to supply reckless corporations like Chevron with financial incentives for their dirty practices while our firefighters receive pennies. That $100m could be going toward struggling local fire departments, not to mention fixing dilapidated roads and cracked sidewalks and reducing overcrowded classrooms. This tax loophole robs Californians of well-funded community services by taking money from our localities and giving it to wealthy corporations in the form of a tax break. This coming election I urge all Californians to support the Schools and Communities First Act. For that matter, I urge all voters in all states to consider measures that will aid the fight against climate change. All Americans deserve the comfort of knowing that our emergency services are adequately funded to deal with every possible climate disaster. This future is possible when wealthy corporations like Amazon pay their fair share by reinvesting in the communities that support them, not receiving tax incentives to continue their avaricious practices at the expense of local services. Guy T Saperstein is a retired attorney who founded the largest private plaintiff civil rights law firm in America, the former President of the Sierra Club, and a member of the Patriotic Millionaires"
"

Another day, another negative impact from pernicious global warming caused by humanity’s relentless quest for self-betterment.   
  
Today, it is our coffee supply that is in jeopardy. Earlier this week, global warming was melting mummies in Chile. Last week, it was blamed for war in Syria. Turns out that global warming is a highly selective beast—it only harms the things we love, while enhancing the things we don’t.   
  
Penguins? Polar bears? Songbirds? Coffee?   
  
Harms. Harms. Harms. Harms.   
  
Jellyfish? Poison ivy? Ragweed? War?   
  
Helps. Helps. Helps. Helps.   
  
Mummies are sort of a special case. If they were roaming around attacking people, we’d imagine that global warming would empower them. But in this case, the mummies are harmlessly laying around in the (apparently poorly climate-controlled) vaults in a museum in Chile. There, they are a natural treasure. So, predictably, global warming is causing harm.   




[Gotta wonder what warming could do to poor old Lenin lying entombed in Red Square. Our greener friends might want him reincarnated, while others would hope he would begin to leak like the Chilean mummies].   
  
And the list goes on and on—something that we’ve pointed out previously (see here and here, for example).   
  
Consequently, the news of the past week should hardly come as a great surprise. We’re pretty used to it by now.   
  
But what may come as a surprise is that according to U.K. economist Richard Tol, recent studies into the economic impacts of climate change find the positives to be increasing and the negatives to be decreasing.   
  
Tol writes:   




Since 2009, however, more estimates of the economic impact of climate change have been published…The new trend shows positive impacts for warming up to about two degrees global warming, just like the old trend did. The new trend, however, shows markedly less negative impacts for more profound warming than did the old trend. In other words, in the last five years, we have become less pessimistic about the impacts of climate change.



Couple this result with the bevy of new scientific findings indicating the future climate change is likely to be on the low side of climate model projections and we have some good news about climate change’s impact on something that we all like—money!   
  
Got to wonder why it is that you only find this result highlighted in these pages and not headlining the front page of the _Washington Post_ or _New York Times_.


"
"

The House is expected to vote as early as Wednesday on a resolution that decries the dangerous threat posed by rising industrial greenhouse gas emissions. The resolution calls for an emissions cap on greenhouse gases as long as (i) the cap doesn’t harm the U.S. economy, and (ii) U.S. trading partners agree to live under a similar cap.   
  
  
While the Greens are quite exited that the GOP seems prepared to go along with this, these things are called “resolutions” for a reason — they echo promises made on New Year’s Eve. In short, it’s nothing but a statement that the Congress thinks that this would be a good idea, but that they are unprepared (at the moment) to do anything about it.   
  
  
Does this represent progress for the enviros? Not really. Show me an emissions cap that won’t have a negative effect on the economy and I’ll show you an alterantive reality where up is down, black is white, and rivers are made of liquid chocolate. Now, depending upon the nature of the cap and the regulations attached thereto, the negative economic impact might be very modest or rather signficant. But ruling out caps that have _any_ negative economic impact is to essentially rule out a cap.   
  
  
Frank O’Donnell, head of the Left’s Clean Air Watch, was not too far off the mark when he was quoted in the subscription trade journal _Energy & Environment Daily_ this morning as noting that “The way [the resolution] is worded, you’d have to be a kook to be opposed to it.” Indeed, who would object to what is in effect an insurance policy with no premium?   
  
  
If the Greens really think that global warming is serious, they are demonstrating both political and intellectual cowardice by backing pablum like this. All this resolution would accomplish is to allow politicians to claim environmental virtue from empty political gestures.   
  
  
So why would the enviros provide an easy out for politicians who want to appear Green but not do anything real to advance the Green agenda? Because it’s the best the enviros can do right now. That speaks volumes. This is a resolution that advertises Green political weakness, not Green political strength.   
  
  
The resolution, then, is pretty meaningless. That having been said, you don’t have to be a “kook” to be skeptical about all the “doom, doom I say” hand‐​wringing that litters the resolution. That is, unless you think a Vice President of the U.N.‘s oft cited International Panel on Climate Change is a kook. And if you do, what does that say about the merit of that much‐​worshiped body of scientific experts?
"
nan
"Company bosses need to speak out about environmental and social issues if they want to keep their staff and stay in business for the long term, Mike Cannon-Brookes, co-chief executive of Atlassian, said. Research done for Atlassian by the accounting firm PricewaterhouseCoopers showed almost a third of Australian and US workers were willing to quit their jobs if their employer acted in a way that did not align with their values.  “The responsibility of business leaders to provide leadership in areas of the community and participate in leadership alongside government and other groups is something they should be aware of,” Cannon-Brookes said. The number of people willing to leave a company over its stance on social issues was “a lot higher than we expected across the generations”. “There’s a cost of inaction as much as there’s a cost of action here,” he said. Top issues for Australian workers were the cost of living, the long-running drought and access to healthcare. Mental health, the cost of healthcare, pollution and the climate crisis also featured heavily among workers surveyed in December, before the bushfire season hit its peak. “Anecdotally, and obviously in the media and other areas, climate change, long-term planning, listening to experts – there’s a lot of things that I think the horrific summer that we’ve had have highlighted in the minds of society in general,” Cannon-Brookes said. “People in society [whose] house was confronted by a bushfire emergency, they’re people that work in businesses. Businesses are collections of people; business leaders are people.” In the US, workers were most concerned with the cost of healthcare, the highest in the developed world at almost 17% of gross domestic product. Access to healthcare, mental health and poverty were among US workers’ top concerns, pushing environmental issues – including pollution and global heating – down the table. Cannon-Brookes has been outspoken calling for companies to take positions on economic and social issues. Grok Ventures, his and wife Annie’s private investment vehicle, has supported shareholder resolutions put forward by the activist group the Australasian Centre for Corporate Responsibility, designed to put pressure on BHP to quit the Minerals Council. Cannon-Brookes said other business leaders often told him they agreed with his positions on social and environmental issues but felt they could never go public. “If we could remove some of the hesitation, the fear, some of the sense that this is going to be a negative thing for one’s business or one’s personal position, I think we’ll have better conversations as a whole,” he said. He slammed commentators who have called for business leaders to abandon social activism in favour of a narrower focus on generating returns for shareholders. “I’m not sure that the people who are theoretically commenting on returns to shareholders understand how returns to shareholders work,” he said. “Those returns are generated by the employees at some level in whatever business you are. “Attracting and retaining fantastic people is a non-trivial exercise in business nowadays. “There’s a huge correlation if you look at corporate social responsibility between profitable, sustainable businesses and those who care about their corporate social responsibility. “One of businesses’ goals is to stay in business, and to be a sustainable business you need to have fantastic people and take longer-term sustainable positions on a lot of issues.” He said the survey showed employees wanted their business leaders “not to hide in the corner when it comes to important issues for society at large”. PwC surveyed 1,300 Australian and 2,500 US workers across age groups and industries. A partner at PwC, Diane Rutter, said the research showed the risk of inaction for employers was high. “There is a vocal younger cohort or generation coming through the workplace that are personally engaged and quite vocal around societal issues, and their expectations of workplaces are equally high,” she said. Employers who thought they could ignore the data should also be aware there was a reward for taking action. “There’s a large portion of employees that agree that businesses known for speaking out on issues important to them are much more attractive as future employers,” she said. “We see that is significantly higher for Generation Z – so again, that generation coming through.”"
"

From NASA news:


See inset view below.

 On April 29, the MODIS image on the Terra satellite captured a wide-view  natural-color image of the oil slick (outlined in white) just off the  Louisiana coast.  The oil slick appears as dull gray interlocking comma  shapes, one opaque and the other nearly transparent.  Sunglint — the  mirror-like reflection of the sun off the water — enhances the oil  slick’s visibility.  The northwestern tip of the oil slick almost  touches the Mississippi Delta. Credit: NASA/Earth Observatory/Jesse  Allen, using data provided courtesy of the University of Wisconsin’s  Space Science and Engineering Center MODIS Direct Broadcast system.
› Larger image
NASA’s Terra and Aqua satellites are helping the National Oceanic and  Atmospheric Administration (NOAA) keep tabs on the extent of the recent  Gulf oil spill with satellite images from time to time. NOAA is the lead  agency on oil spills and uses airplane fly-overs to assess oil spill  extent.
A semisubmersible drilling platform called the Deepwater Horizon located  about 50 miles southeast of the Mississippi Delta experienced a fire  and explosion at approximately 11 p.m. CDT on April 20. Subsequently,  oil began spilling out into the Gulf of Mexico and efforts to contain  the spill continue today. NASA’s Terra and Aqua satellite imagery has  captured the spill in between cloudy days.
NOAA used data from the Moderate Imaging Spectroradiometer or MODIS  instrument from the Terra satellite on April 26, 27 and 29 to capture  the extent of the oil spill, which measured 600-square-miles. The MODIS  instrument flies aboard both the Terra and Aqua satellites.
 This satellite image from NASA’s Terra satellite on April 27 at 12:05  CDT shows the outline and extent of the oil slick from the Deepwater  Horizon drilling platform. The red dot represents the platform.  The  coasts of Mississippi and Alabama appear at the top of the image. Credit: NOAA/NASA
› Larger image In the satellite image from April 27 at 12:05 p.m. CDT the MODIS image  showed that the oil slick was continuing to emanate from the spill  location. Individual slicks lay just north of 29 degrees and zero  minutes north, where they have been noted in the days before. Oil had  spread further east and the edge of the slick passed 87 degrees and 30  minutes west compared to the MODIS image taken on April 26. The April 26  satellite image came from NASA’s Aqua satellite.
On April 29, the MODIS image on the Terra satellite captured a  natural-color image of the oil slick just off the Louisiana coast. The  oil slick appeared as dull gray interlocking comma shapes, one opaque  and the other nearly transparent. The northwestern tip of the oil slick  almost touches the Mississippi Delta.
Deepwater Horizon had more than120 crew aboard and contained an  estimated to 17,000 barrels of oil (700,000 gallons) of number two fuel  oil or marine diesel fuel.
Today, April 30, NOAA declared the Deepwater Horizon incident “a Spill  of National Significance (SONS).”  A SONS is defined as, “a spill that,  due to its severity, size, location, actual or potential impact on the  public health and welfare or the environment, or the necessary response  effort, is so complex that it requires extraordinary coordination of  federal, state, local, and responsible party resources to contain and  clean up the discharge” and allows greater federal involvement. NOAA’s  estimated release rate of oil spilling into the Gulf is estimated at  5,000 barrels (210,000 gallons) per day based on surface observations  and reports of a newly discovered leak in the damaged piping on the sea  floor.
NOAA reported on April 29 that dispersants are still being aggressively  applied to the oil spill and over 100,000 gallons have been applied.   NOAA’s test burn late yesterday was successful and approximately 100  barrels of oil were burned in about 45 minutes.    NOAA is flying planes over the area and using NASA satellite imagery  from the Terra and Aqua satellites to monitor the spill.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8bc8ea96',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"British-owned car manufacturing has been in decline in UK for decades but the shift to electric cars might be just what is needed for a revival. The recent announcement by US-based Detroit Electric that it will move its production to the UK highlights some of the engineering strengths Britain possesses – but will local entrepreneurs see it too?  Britain might be a minor player in the emerging hybrid and pure electric vehicle (EV) market, but it was not always so. Indeed, the UK has a credible claim to have invented both the electric locomotive carriage in the 1830s, and the electric car in the 1880s. By the late 1880 and 1890s, the UK and France were leading the world in the deployment of the vehicles, with an electric taxi firm operating on London streets by the turn of the 20th century. Sadly its time was not to be and during most of the 20th century, the internal combustion engine made greater advances in price, range and performance; electric vehicles were pushed into niche markets such as indoor moving equipment or milk deliveries. The decline in British industry throughout the 1960s, 1970s and 1980s meant EV firms lacked access to both the most recent technology and domestic car-makers who might operate as partners and clients. One of the reasons why Japan played such a prominent early role is that advances made in industries such as consumer electronics could be transferred across to automotive mass-production – sometimes within the same group of companies. Yet, to say Britain can’t compete because it lacks a “domestic champion” car-maker would be letting its would-be innovators off too lightly. Tesla Motors succeeded precisely because it wasn’t a large car maker, but a small company with a big idea that was willing to take the risks it’s bigger rivals wouldn’t.  In 2008, many automotive multi-nationals were sceptical of EV technology and the electric cars they developed were typically less reliable and lower powered than their petrol and diesel equivalents. Tesla upturned expectations by aiming squarely at cash-rich early adopters. It was an audacious pitch and Elon Musk, internet tycoon turned Tesla founder, was not an experienced car-maker. He therefore turned towards the British firm Lotus Cars to provide the “glider” or body of the car. In this move Californian money and technology was married with British design and production to provide an eye-catching, prestige vehicle that was also sufficiently lightweight to suit the lower weigh-to-power ratio of EVs.  Given Tesla’s success it is not surprising that others such as Albert Lam, a former Lotus executive, emulated its strategy. Lam first moved into the EV market by reviving the Detroit Electric brand – a firm that had been one of the pioneers of electric vehicles in the early 1900s, before ceasing production in 1939. Today its flagship SP.01, marketed as “the fastest EV on the market” also makes use of a Lotus designed body but goes a step further than Tesla by basing its European factory in Royal Leamington Spa, West Midlands. Lam himself is no stranger to the area: he has a degree from Coventry University and has held positions in local car-makers Jaguar and Land Rover. No doubt he is aware of the region’s association with low-volume prestige brands, its excellent supply base, world-leading motorsports expertise and strong R&D facilities focused on low-carbon vehicles.  Indeed, the British car industry looks attractive for overseas investors in general. Nissan’s decision to assemble the market-leading Leaf in its Sunderland plant makes sense: the UK has high-levels of productivity in the sector (second only to Germany in Europe), favourable corporate tax levels, a package of government incentives for electric vehicle consumers and a buoyant car market. In short, the country has a lot to offer EV manufacturers. This being the case it’s worth asking why it has taken an American company to recognise the value of these assets. Mostly it comes to down to technology, money and perhaps some entrepreneurial caution. The UK has its strengths but there are notable gaps to make the transition to EV. Industry analyst Peter Harrop of IDTechEx notes that the UK is “world-class in terms of innovative component suppliers” but “nowhere” in terms of electric car batteries. Another big problem is the availability of cash (or even credit) to fund a jump into electric. Britain’s small band of domestic car makers tend to operate on a relatively small scale and often struggle to finance their existing lines. Coventry University Entreprise’s research into suppliers found that without big clients emergent EV technology firms lack partners to take prototypes into production and often shift into engineering consultancy rather than manufacturing. Detroit Electric’s move into the UK could certainly catalyse the industry. It would provide a client for component suppliers looking to move into a new field; a partner for training academies to develop a new generation of engineers – and, most importantly, it represents a model for other entrepreneurs to follow.  Albert Lam is not a tycoon in the style of Elon Musk, but a businessman who has spotted an opportunity and brought together a classic brand, US technology, British production and access to the North American and European markets in an endeavour that is likely to capture people’s attention, at the very least. Succeed or fail, the lesson for British entrepreneurs is clear: make use of the assets you’ve got, but think global. The window for innovations in the electric vehicle market is still open but it may not be for too long."
"
Me ~ ctm
By charles the moderator
Here’s the link.
I have no other comment.
From congress.org

Global Warming could make Humans EXTINCT within 50 years
Kill mechanisms list
Global Warming could make the human race EXTINCT.   The #1 kill  mechanism is famine.   See “The Long Summer” by Brian Fagan and  “Collapse” by Jared Diamond.   Shifting winds and warmer oceans have  already created a weird moving checkerboard of drought and flood that  has interfered with agriculture here and elsewhere.
The extra heat has caused heat related deaths already.
The book “Six Degrees” by Mark Lynas says:  “If the global warming is 6  degrees centigrade, we humans go extinct.”  The book lists several kill  mechanisms, the most important being famine and methane fuel-air  explosions.   Other mechanisms include fire storms.
“Under a Green Sky” by Peter D. Ward, Ph.D., 2007 says H2S bubbling out  of hot oceans is the final blow at 6 degrees C warming.
===========================
read the rest at congress.org



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b01272b',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterI was going to post this tomorrow, but what the hell…

ATTENTION GERMAN READERS: 21:05 mark has a rather damning observation about Germans in general. So why is it Germans are so damn pessimistic?

Does it have to do with all the alarmist scientists out here at places like the PIK, AWI and MPI, to name a few? Why is pessimism viewed as intellectually superior to optimism? The best thing Germany could do would be to start deporting all the top pessimism spreaders. Just imagine how quickly and how much better the country would get.
And if you haven’t already, also read Ridley’s view on why wind energy is going to flop.
http://www.rationaloptimist.com/blog/the-beginning-of-the-end-of-wind.aspx
 
Share this...FacebookTwitter "
"


From the “weather is not climate” department.
By Steven Goddard
I noticed something interesting in the  NCEP forecast for the  coming week. Temperatures are predicted to be below normal across a  7,000 mile swath of the Americas. That is more than one fourth of the  way around the earth. Below is a composite image of generated from three  of the NCEP maps.
Looks like another cold soccer Saturday, across the entire US. Of course there are other places on the Earth that will have above normal temperatures, but this seemed noteworthy for the dual hemispheric scope, even it is just “weather”.
Here’s the USA forecast to May 6th. Note that much of the West will be well below normal with neutral to slightly above normal in the East:

And South America:

Source: NCEP forecast page.
=====================
Please no grousing about the USA being in °F and South America being in °C. That’s the way NCEP provides the maps. – Anthony




			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8c7c681d',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**Here are five things you need to know about the coronavirus pandemic this Thursday morning. We'll have another update for you this evening.**
People in England will find out later which of three tiers of restrictions they will face when the national lockdown ends next week. And our political editor Laura Kuenssberg understands only a handful will be in the lowest tier, with most areas - including London - in tier two and ""significant numbers"" facing the toughest restrictions.
A government scientific adviser says the UK-wide relaxation of rules over Christmas - allowing three households to form a bubble between 23 and 27 December - amounts to ""throwing fuel on the Covid fire"". However, as health correspondent Nick Triggle reports, others argue there are huge benefits, and that the pivot from ""paternalism to partnership"" could help build public trust ahead of mass vaccination.
Average pay packets could be Â£1,200 a year smaller by 2025 as a result of the pandemic, according to analysis from a think tank focused on improving living standards for people on low-to-middle incomes. ""Weaker pay growth and higher unemployment will serve to prolong Britain's living standards squeeze"", warns the Resolution Foundation. Meanwhile, with union leaders furious over a pay freeze on at least 1.3 million public sector workers, Chancellor Rishi Sunak tells the BBC he ""couldn't justify"" a rise when the disparity with private sector pay had widened.
Our knowledge of the long-term illness ME - or chronic fatigue syndrome - has helped specialists treat long Covid, the lingering effects suffered by some people who catch coronavirus. Evan was diagnosed with ME in 2017, and she believes her experience can help her support those living with long Covid.
It's been a terrible year for many industries and cinema has been among the worst hit, with most of the year's planned blockbusters put on hold in light of the various global lockdown restrictions. Movie theatres have paid the price, with Cineworld temporarily shutting up shop in the UK. But is the era of the Hollywood blockbuster over, or do busy cinemas in Asia offer a glimmer of hope?
Get a longer daily news briefing from the BBC in your inbox, each weekday morning, by signing up here.
You can find more information, advice and guides on our coronavirus page.
Here's a rundown of the rules around Christmas across the UK, restrictions for the various tiers in England and Scotland, and details of what's allowed in Wales and Northern Ireland.
**What questions do you have about coronavirus?**
_ **In some cases, your question will be published, displaying your name, age and location as you provide it, unless you state otherwise. Your contact details will never be published. Please ensure you have read our**_terms & conditions _ **and**_privacy policy.
Use this form to ask your question:
If you are reading this page and can't see the form you will need to visit the mobile version of the BBC website to submit your question or send them via email to YourQuestions@bbc.co.uk. Please include your name, age and location with any question you send in."
nan
"
From the ARC Centre of Excellence for Coral Reef Studies James Cook University
“Evil twin” threatens world’s oceans, scientists warn
'Twins"" 1988 - Schwarzenegger and DaVito
The rise in human emissions of carbon dioxide is driving   fundamental and dangerous changes in the chemistry and ecosystems of the  world’s  oceans, international marine scientists warned today.
“Ocean conditions are already more extreme than  those experienced  by marine organisms and ecosystems for millions of years,”  the  researchers say in the latest issue of the journal Trends in Ecology and  Evolution (TREE).
“This emphasises the urgent need to adopt policies  that  drastically reduce CO2 emissions.”
Ocean acidification, which the researchers call the  ‘evil twin of  global warming’, is caused when the CO2 emitted by human  activity,  mainly burning fossil fuels, dissolves into the oceans. It is  happening  independently of, but in combination with, global warming.
“Evidence gathered by scientists around the world over  the last  few years suggests that ocean acidification could represent an equal –   or perhaps even greater threat – to the biology of our planet than  global  warming,” co-author Professor Ove Hoegh-Guldberg of the ARC  Centre of Excellence  for Coral Reef Studies and The University of  Queensland says.
More than 30% of the CO2 released from burning  fossil fuels,  cement production, deforestation and other human activities goes   straight into the oceans, turning them gradually more acidic.
“The resulting acidification will impact many forms  of sea life,  especially organisms whose shells or skeletons are made from  calcium  carbonate, like corals and shellfish. It may interfere with the   reproduction of plankton species which are a vital part of the food web  on  which fish and all other sea life depend,” he adds.
The scientists say there is now persuasive evidence that mass  extinctions  in past Earth history, like the “Great Dying” of 251  million years ago and  another wipeout 55 million years ago, were  accompanied by ocean acidification,  which may have delivered the  deathblow to many species that were unable to cope  with it.
“These past periods can serve as great lessons of what we can  expect in  the future, if we continue to push the acidity the ocean even  further” said  lead author, Dr. Carles Pelejero, from ICREA and the  Marine Science Institute  of CSIC in Barcelona, Spain.
“Given the impacts we see in the fossil record, there is no  question  about the need to immediately reduce the rate at which we are  emitting carbon  dioxide in the atmosphere,” he said further.
“Today, the surface waters of the oceans have  already acidified by  an average of 0.1 pH units from pre-industrial levels, and  we are  seeing signs of its impact even in the deep oceans”, said co-author Dr.   Eva Calvo, from the  Marine Science Institute of CSIC in Barcelona,    Spain.
“Future acidification depends on how much CO2  humans emit from  here on – but by the year 2100 various projections indicate  that the  oceans will have acidified by a further 0.3 to 0.4 pH units, which is   more than many organisms like corals can stand”, Prof. Hoegh-Guldberg  says.
“This will create conditions not seen on Earth  for at least 40  million years”.
“These changes are taking place at rates as much as  100 times  faster than they ever have over the last tens of millions of years”   Prof. Hoegh-Guldberg says.
Under such circumstances “Conditions are likely to  become very  hostile for calcifying species in the north Atlantic  and Pacific over  the next decade and in the Southern Ocean over the next few  decades,”  the researchers warn.
Besides directly impacting on the fishing  industry and its  contribution to the human food supply at a time when global  food demand  is doubling, a major die-off in the oceans would affect birds and  many  land species and change the biology of Earth as a whole profoundly,  Prof.  Hoegh-Guldberg adds.
Palaeo-perspectives on ocean acidification by Carles  Pelejero, Eva Calvo and Ove Hoegh-Guldberg is published in the latest  issue of the journal  Trends in Ecology and Evolution (TREE), number  1232.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8d484b3a',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

On the eve of Newt Gingrich’s landslide victory in the South Carolina primary, CNN’s Erin Burnett let the former speaker expound on the success of his “kick the moderator” debate strategy.



“I think there’s something going on here that’s very deep,” Gingrich said. “People want a leader who’s forceful… Part of it is, you know, if I’d said ‘The color is blue!’ — it’s the forcefulness… That delivery, that clearness is as important as the specific topic,” he explained.



Watching the interview, I had a disturbing thought: Has Newt Gingrich become self‐​aware?



I’ve never heard a better explanation for the former speaker’s ability to cloud conservatives’ minds. How, after all, did a man who’s the very model of a Beltway‐​consensus influence‐​peddler convince Tea Party voters he represents “real change”? It’s the “forcefulness,” stupid!



Unfortunately, what’s going on here is not “very deep.” Gingrich’s rise represents the triumph of rhetorical style over substance. In a way, it’s the ultimate tribute to Barack Obama.



The _Washington Post’s_ Ezra Klein asked a good question on Sunday: “What are Newt Gingrich’s big ideas?” “I’m at a loss to name even one,” he admitted.



Gingrich has an enviable rep as a one‐​man think tank, but in his wilderness years, he made a sweet living as a “forceful” pitchman for utterly conventional center‐​left policies: Medicaid expansion, the individual mandate, cap and trade, “clean energy” subsidies, and the like. Newt does a great impression of a red‐​state firebrand, but when it comes to policy, “the color is blue.”



That’s not to say that Gingrich has never had an unconventional idea. This is a guy who bragged in a 2005 GQ interview that “I first talked about [saving civilization] in August of 1958” — when he was a rising sophomore in high school.



Some of Gingrich’s big ideas are charmingly batty. Given his worries about global warming, Newt has probably abandoned his 1984 plan for “a mirror system in space” that “could affect the earth’s climate by increasing the amount of sunlight.”



But the Trekkie zeal remains, judging by one of my favorite recent headlines: “Gingrich Said Freddie Mac Could Be Good Model for Mars Travel” (Bloomberg, Dec. 2, 2011).





Gingrich’s rise represents the triumph of rhetorical style over substance.



Some of Gingrich’s other fancies are less charming. The candidate who’s warned of a “gay and secular fascism” sweeping the country has an impressive authoritarian streak of his own.



As Klein notes, in 1996, Gingrich had the “big idea” of instituting the death penalty for anyone who brought more than 2 ounces of marijuana into the United States.



Today, Gingrich condemns the Stop Online Piracy Act as censorship, but in 2006 he supported empowering “federal judges who’ve served in combat” to shut down “jihadist” websites.



This December, he advocated sending U.S. marshals to arrest activist judges who rule against religious displays in public schools (maybe combat‐​hardened jurists will get a pass).



Say what you will about Gingrichian authoritarianism — at least it won’t be “gay and secular”!



At this writing, Gallup has Gingrich neck and neck with Romney for the Republican nomination. If he gets the nod, no doubt he’ll send a thrill up many a leg in the debates. But his odds of actually winning the presidency are slim indeed.



Recall that in 2004, after Obama’s GOP opponent for the U.S. Senate, Jack Ryan, imploded in a sex scandal, the party nominated Alan Keyes: another “forceful” debater with a weakness for loopy ideas. How’d that work out?



Keyes went on to run a short‐​lived cable talk show (the somewhat defensively titled “Alan Keyes Is Making Sense”) and a role as lead plaintiff in a birther lawsuit. Obama went on to the U.S. Senate and, in short order, the presidency.
"
"
This is the final report, which has been embargoed until 5:01 PM PDT / 00:01 GMT March 31st.
Click for PDF of report
Below is the emailed notice to MP’s sent with the PDF of the report.
Date: 30 March 2010 10:30
Subject: EMBARGOED REPORT: CLIMATE SCIENCE MUST  BECOME MORE TRANSPARENT SAY MPs
To: [undisclosed recipients]
Phil Willis MP, Committee  Chair, is available for embargoed interviews today. Please let me know if you  wish to bid (I will be at the embargoed briefing until approx 1pm but will  respond once I return).
Embargoed press briefing for science, environment  and news corrs at Science Media Centre (21 Albemarle Street London, W1S 4BS),  11.30 am today.
SCIENCE & TECHNOLOGY COMMITTEE
Select Committee  Announcement
[X]
31 March 2010
***EMBARGOED UNTIL 00.01 WEDNESDAY  31 MARCH 2010***
CLIMATE SCIENCE MUST BECOME MORE TRANSPARENT, SAY  MPs
The Science and Technology Committee today publishes its report on  the disclosure of climate data from the Climatic Research Unit (CRU) at  the University of East Anglia. The Committee calls for the climate  science
community to become more transparent by publishing raw data and  detailed methodologies.
Phil Willis MP, Committee Chair,  said:
“Climate science is a matter of global importance. On the basis of  the science, governments across the world will be spending trillions of  pounds on climate change mitigation. The quality of the science therefore has  to be irreproachable. What this inquiry revealed was that climate scientists  need to take steps to make available all the data that support their work  and full methodological workings, including their computer codes. Had both  been available, many of the problems at CRU could have been  avoided.”
The focus on Professor Jones and CRU has been largely  misplaced. On the accusations relating to Professor Jones’s refusal to share  raw data and computer codes, the Committee considers that his actions were in  line with common practice in the climate science community but that those  practices need to change.
On the much cited phrases in the leaked  e-mails-“trick” and “hiding the decline”-the Committee considers that they  were colloquial terms used in private e-mails and the balance of evidence is  that they were not part of a
systematic attempt to mislead.
Insofar as  the Committee was able to consider accusations of dishonesty against CRU, the  Committee considers that there is no case to answer.
The Committee found  no reason in this inquiry to challenge the scientific consensus as expressed  by Professor Beddington, the Government Chief Scientific Adviser, that  “global warming is happening [and] that it is induced by human activity”. But  this was not an inquiry into the science produced by CRU and it will be for  the Scientific Appraisal Panel, announced by the University on 22 March, to  determine whether the work of CRU has been soundly built.
On the  mishandling of Freedom of Information (FoI) requests, the Committee considers  that much of the responsibility should lie with the University, not CRU. The  leaked e-mails appear to show a culture of non-disclosure at CRU and  instances where information may have been deleted to avoid disclosure,  particularly to climate change sceptics. The failure of the University to  grasp fully the potential damage this could do and did was regrettable. The  University needs to re-assess how it can
support academics whose expertise in  FoI requests is limited.
Ends.
NOTES TO EDITORS:
Further  details about this inquiry can be found at:
http://www.parliament.uk/parliamentary_committees/science_technology/s_t_cru_inquiry.cfm

Media  Enquiries: Becky Jones: 020 7219 5693 Committee Website:
http://www.parliament.uk/science Publications / Reports / Reference
Material: Copies of all select committee  reports are available from the
Parliamentary Bookshop (12 Bridge St,  Westminster, 020 7219 3890) or the
Stationery Office (0845 7023474).  Committee reports, press releases,
evidence transcripts, Bills; research  papers, a directory of MPs, plus
Hansard (from 8am daily) and much more,  can be found on
www.parliament.uk<http://www.parliament.uk/>.
Rebecca  Jones
House of Commons Select Committee Media Officer Children, Schools  &
Families; Health; Science & Technology; Northern Ireland; Scotland;  Wales
===================================================
UPDATE: 
Steve McIntyre has a few points to make, which I encourage reading here at Climate Audit


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8d096ce1',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**Exeter's Nightingale hospital will open to coronavirus patients for the first time on Thursday.**
The emergency field hospital will get patients from the Royal Devon and Exeter Hospital ""which is very busy"", said an NHS spokesperson.
It is one of seven Nightingale Hospitals built in England, set up in the spring as an insurance policy in case the NHS became overwhelmed.
The 116-bed hospital has also been used for vaccine trials.
On Twitter, Exeter MP Ben Bradshaw said the opening was ""very good news"".
He added it will ""take pressure off the RD&E hospitals and other local NHS services"".
The Labour MP noted he recently raised the issue with Health Secretary Matt Hancock.
A total of 540 people have died with coronavirus in South West hospitals, with four dying in Devon on Wednesday.
A Nightingale hospital spokesperson said: ""We would ask that the public continue to observe the government's advice on observing the lockdown and social distancing so that we can keep patients safe.""
**How will your Christmas plans be affected?**haveyoursay@bbc.co.uk **.**
Please include a contact number if you are willing to speak to a BBC journalist. You can also get in touch in the following ways:
If you are reading this page and can't see the form you will need to visit the mobile version of the BBC website to submit your question or comment or you can email us at HaveYourSay@bbc.co.uk. Please include your name, age and location with any submission."
"
Share this...FacebookTwitterHere we go again. Global warming causes cold European winters! So no matter what happens – it proves man-made global warming is for real.
Just a few years ago, these off-the-wall scientists claimed that global warming would lead to warm, snowless winters, with palm trees eventually reaching Scandinavia.
But now that cold winters have caught the hapless scientists with their pants down and signs pointing to even colder winters ahead are piling up, scientists have now concocted a model that they say shows that warming lack of summertime Arctic sea ice cover leads to cold winters. At least that’s what some adventurous scientists are saying at Germany’s state-funded Alfred Wegener Institute in a new paper.
The Alfred Wegener Institute press release here claims that because of the near surface warming, the air goes into upward motion and the atmosphere becomes unstable. According to the paper’s lead author Ralf Jaiser:
We have analysed the complex non-linear proceses that are behnind this destabilization, and have shown how the changed conditions in the Arctic have an impact on the typical circulation and air pressure patterns.”
The AWI tells us about the air pressure difference between the Arctic and the middle latitudes the so-called Arctic Oscillation, with the Azores high and the Iceland lows that we know from weather reports. If the index is high, then westerly winds prevail and transport warm, moist oceanic air deep into Europe. But if these westerly winds cease, then Arctic air penetrates into Europe, like the last 2 winters. The models calculation now show that in times of low Arctic ice cover, this air pressure index is weakened during the subsequent winter and thus allows Arctic air to penetrate down to the middle latitudes. It’s that simple – period. So let’s all just keep moving on.
So their knowledge of nature is complete now, and their models are tuned like no others and can recreate all the mysteries of nature. This may sound hard to believe, but it’ll do for the hordes of stupid gullible journalists out there. Overall the AWI press release takes on a sort of silly paternal attitude and treats the reader like a parent treats a 4-year old when explaining how Santa Claus brings presents at Christmas. Of course, when the child reaches the age of 8, he or she realises that he/she had been duped the whole time. Right now the media is at about age two and half, and stuck there.
 
 
Share this...FacebookTwitter "
"
By Steven Goddard,

The headline reads “NASA Satellites Detect Unexpected Ice Loss in East Antarctica”
ScienceDaily (Nov. 26, 2009) — Using gravity measurement data from the NASA/German Aerospace Center’s Gravity Recovery and Climate Experiment (GRACE) mission, a team of scientists from the University of Texas at Austin has found that the East Antarctic ice sheet-home to about 90 percent of Earth’s solid fresh water and previously considered stable-may have begun to lose ice.
Better move to higher ground! NASA also reported :
“Antarctica has been losing more than a hundred cubic kilometers (24 cubic miles) of ice each year since 2002” and that “if all of this ice melted, it would raise global sea level by about 60 meter (197 feet).“
In 2007, NASA generated this map (below) of Antarctica showing just how hot it is getting down there in the land of Penguins.

Now I am really worried! But wait……. There are a few minor problems.
Assume for a minute that we accept the GRACE numbers.  The first problem is Antarctica contains a lot of ice :  30 × 10^6 km³.  At 100 km³ per year, it will take 300,000 years to melt.
The next problem is with the NASA temperature map. From the NASA article “The scientists estimate the level of uncertainty in the measurements is between 2-3 degrees Celsius.” They are claiming precision of better than 0.05°C, with an error more than an order of magnitude larger than their 25 year trend. The error bar is large enough that the same data could just as easily indicate rapid cooling and blue colors. That will get you an F in any high school science class.
And that is exactly what happened. The hot red map above was preceded by a cold blue map which showed Antarctica getting cooler. What motivation could NASA have had to change colors without mathematical justification?

NASA justified their heating up Antarctica with this comment :
This image was first published on April 27, 2006, and it was based on data from 1981-2004. A more recent version was published on November 21, 2007. The new version extended the data range through 2007, and was based on a revised analysis that included better inter-calibration among all the satellite records that are part of the time series.
As I have already pointed out, this is absurd. Their error bar is so large that they could have painted the map any color they wanted. Apparently someone at NASA wanted red.
But why are we looking at temperature trends anyway? The real issue is absolute temperatures. Some of the regions in which GRACE claims ice loss in East Antarctica average colder than -30°C during the summer, and never, ever get above freezing. How can you melt ice at those temperatures?

http://en.wikipedia.org/wiki/File:Antarctic_surface_temperature.png
I overlaid the Antarctica summer temperature map on the GRACE “melt” map, below. As you can see, GRACE is showing ice loss in places that stay incredibly cold, all year round.

The problem with GRACE is that it measures gravity, not ice. Changes in gravity can be due to a lot of different things beneath the surface of the ice. Antarctica has active magma chambers. Plate tectonics and isostasy also cause gravity changes.
We should be clever enough not to be blinded by technology. The claims that ice is melting in East Antarctica don’t have a lot of justification.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8ac16b27',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"**Britain's major pub groups and brewers have pleaded with Prime Minister Boris Johnson to save an industry facing the ""darkest of moments"".**
Executives at Fuller's, Carlsberg UK, Greene King, and Heineken UK are among more than 50 signatories of a letter warning of huge job losses.
They call on him to publish the evidence justifying the coronavirus restrictions on the industry.
A Downing Street spokesperson said they would respond in due course.
The letter says: ""The pub is clearly being singled out for exceptionally harsh and unjustified treatment and unless your government changes course, and soon, huge portions of this most British of institutions will simply not be there come the spring.
""We believe it is in the interests of openness and transparency that any evidence showing pubs to be the source of outbreaks of the virus, and thereby justifying these extra restrictions, must be published immediately.""
The letter comes ahead of a planned announcement on Thursday that could see two-thirds of the country placed into tiers two or three when the current lockdown lifts next month.
Pubs in tier two areas will be able to serve drinks only to customers having a substantial meal, and those in tier three will not be able to open.
Pubs, and the hospitality industry generally, have been among the hardest-hit sectors during lockdown.
More than a third of hospitality firms say they have little or no confidence of surviving the next three months, according to data collected by the Office for National Statistics (ONS) earlier this month.
Other signatories to the letter include executives at Adnams, Marston's, Budweiser UK, Punch Pubs, Shepherd Neame and Young's.
They tell the PM they employ ""hundreds of thousands of people and contribute billions of pounds of economic value to the UK economy - all of this is at risk today"".
""Your Winter Plan, compounded by the Christmas announcement, have been greeted with utter dismay and incredulity by publicans up and down the country, and made the situation facing us exponentially worse,"" they say.
""How can it be that people mixing in unregulated private homes is deemed safer than gathering in limited numbers in larger, regulated and ultimately Covid-secure venues like pubs? There is no logic to this decision.
""It is clear that pubs are being scapegoated despite a lack of available evidence that they are any more responsible for outbreaks than other types of venue. We cannot stand idly by and allow these measures to destroy our businesses.""
If restrictions cannot be relaxed, the pubs are demanding, among other things, financial support in line with the first lockdown, immediate changes to business rates, and a cut in the ""punitively high"" beer duty rate."
"
Guest Post by Willis Eschenbach
This is an extension of the ideas I laid out as the Thunderstorm Thermostat Hypothesis on WUWT. For those who have not read it, I’ll wait here while you go there and read it … (dum de dum de dum) … (makes himself a cup of coffee) … OK, welcome back. Onwards.
The hypothesis in that paper is that clouds and thunderstorms, particularly in the tropics, control the earth’s temperature. In that paper, I showed that a falsifiable prediction of greater increase in clouds in the Eastern Pacific was supported by the satellite data. I got to thinking a couple of days ago about what other kinds of falsifiable predictions would flow from that hypothesis. I realized that one thing that should be true if my hypothesis were correct is that the climate sensitivity should be very low in the tropics.
I also figured out how I could calculate that sensitivity, by using the change in incoming solar energy (insolation) between summer and winter. The daily average top of atmosphere (TOA) insolation is shown in Figure 1.

Figure 1. Daily TOA insolation by latitude and day of the year. Phi (Φ) is the Latitude, and theta (Θ) is the day of the year expressed as an angle from zero to 360. Insolation is expressed in watts per square metre. SOURCE.
(As a side note, one thing that is not generally recognized is that the poles during summer get the highest daily average insolation of anywhere on earth. This is because, although they don’t get a lot of insolation even during the summer, they are getting it for 24 hours a day. This makes their daily average insolation much higher than other areas. But I digress …)
Now, the “climate sensitivity” is the relationship between an increase in what is called the “forcing” (the energy that heats the earth, in watts per square metre of earth surface) and the temperature of the earth in degrees Celsius. This is generally expressed as the amount of heating that would result from the forcing increase due to a doubling of CO2. A doubling of CO2 is estimated by the IPCC to increase the TOA forcing by 3.7 watts per metre squared (W/m2). The IPCC claims that the climate sensitivity is on the order of 3°C per doubling of CO2, with an error band from 2°C to 4.5°C.
My insight was that I could compare the winter insolation with the summer insolation. From that I could calculate how much the solar forcing increased from winter to summer. Then I could compare that with the change in temperature from winter to summer, and that would give me the climate sensitivity for each latitude band.
My new falsifiable predictions from my Thunderstorm Thermostat Hypothesis were as follows:
1 The climate sensitivity would be less near the equator than near the poles. This is because the almost-daily afternoon emergence of cumulus and thunderstorms is primarily a tropical phenomenon (although it also occurs in some temperate regions).
2 The sensitivity would be less in latitude bands which are mostly ocean. This is for three reasons. The first is because the ocean warms more slowly than the land, so a change in forcing will heat the land more. The second reason is that the presence of water reduces the effect of increasing forcing, due to energy going into evaporation rather than temperature change. Finally, where there is surface water more clouds and thunderstorms can form more easily.
3 Due to the temperature damping effect of the thunderstorms as explained in my Thunderstorm Thermostat Hypothesis, as well as the increase in cloud albedo from increasing temperatures, the climate sensitivity would be much, much lower than the canonical IPCC climate sensitivity of 3°C from a doubling of CO2.
4 Given the stability of the earth’s climate, the sensitivity would be quite small, with a global average not far from zero.
So those were my predictions. Figure 2 shows my results:


Figure 2. Climate sensitivity by latitude, in 20° bands. Blue bars show the sensitivity in each band. Yellow lines show the standard error in the measurement.
Note that all of my predictions based on my hypothesis have been confirmed. The sensitivity is greatest at the poles. The areas with the most ocean have lower sensitivity than the areas with lots of land. The sensitivity is much smaller than the IPCC value. And finally, the global average is not far from zero.
DISCUSSION
While my results are far below the canonical IPCC values, they are not without precedent in the scientific literature. In CO2-induced global warming: a skeptic’s view of potential climate change,  Sherwood Idso gives the results of eight “natural experiments”. These are measurements of changes in temperature and corresponding forcing in various areas of the earth’s surface. The results of his experiments was a sensitivity of 0.3°C per doubling. This is still larger than my result of 0.05°C per doubling, but is much smaller than the IPCC results.
Kerr et al.  argued that Idso’s results were incorrect because they failed to allow for the time that it takes the ocean to warm, viz:
A major failing, they say, is the omission of the ocean from Idso’s natural experiments, as he calls them. Those experiments extend over only a few months, while the surface layer of the ocean requires 6 to 8 years to respond significantly to a change in radiation.
I have always found this argument to be specious, for several reasons:
1 The only part of the ocean that is interacting with the atmosphere is the surface skin layer. The temperature of the lower layers is immaterial, as the evaporation, conduction and radiation from the ocean to the atmosphere are solely dependent on the skin layer.
2 The skin layer of the ocean, as well as the top ten metres or so of the ocean, responds quite quickly to increased forcing. It is much warmer in the summer than in the winter. More significantly, it is much warmer in the day than in the night, and in the afternoon than in the morning. It can heat and cool quite rapidly.
3 Heat does not mix downwards in the ocean very well. Warmer water rises to the surface, and cooler water sinks into the depths until it reaches a layer of equal temperature. As a result, waiting a while will not increase the warmth in the lower levels by much.
As a result, I would say that the difference between a year-long experiment such as the one I have done, and a six-year experiment, would be small. Perhaps it might as much as double my climate sensitivity values for the areas that are mostly ocean, or even triple them … but that makes no difference. Even tripled, the average global climate sensitivity would still be only on the order of 0.15°C per CO2 doubling, which is very, very small.
So, those are my results. I hold that they are derivable from my hypothesis that clouds and thunderstorms keep the earth’s temperature within a very narrow level. And I say that these results strongly support my hypothesis. Clouds, thunderstorms, and likely other as-yet unrecognized mechanisms hold the climate sensitivity to a value very near zero. And a corollary of that is that a doubling of CO2 would make a change in global temperature that is so small as to be unmeasurable.
In the Northern Hemisphere, for example, the hemispheric average temperature change winter to summer is about 5°C. This five degree change in temperature results from a winter to summer forcing change of no less than 155 watts/metre squared … and we’re supposed to worry about a forcing change of 3.7 W/m2 from a doubling of CO2???
The Southern Hemisphere shows the IPCC claim to be even more ridiculous. There, a winter to summer change in forcing of 182 W/m2 leads to a 2°C change in temperature … and we’re supposed to believe that a 3.7 W/m2 change in forcing will cause a 3° change in temperature? Even if my results were off by a factor of three, that’s still a cruel joke.




			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8d5f3754',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"

In the past year, concern for the environment has risen to the top of the public’s agenda. Now the environmental movement must face a monster of its own making. The very success of environmentalism threatens to undo two of mankind’s most significant environmental victories. The first is the near stabilization of humanity’s agricultural footprint, expansion of which is the single largest threat to biodiversity worldwide. The second is the spectacular reduction in chronic hunger and malnutrition without which the pressure to convert land for agricultural use would have been stronger.



Around the globe between 1990 and 2003, the amount of land given over to agricultural uses increased less than 2 percent, even though population growth increased 20 percent. Chronic hunger in developing countries declined to 17 percent from 37 percent between 1970 and 2001, despite an 83 percent increase in population. These improvements, largely due to greater agricultural productivity, increased food production per capita, helping to drive down global food prices by about 75 percent since 1950. As a result, access to food increased worldwide, despite increasing demand from a wealthier and more populated world.



The resulting reductions in hunger further reduced pressures for converting more land for agricultural uses.



Global warming hysteria — a boon for the ethanol and other biofuel enterprises — has boosted demand for crop‐​based fuels worldwide. This now threatens to reverse a half century of gains not only against world hunger, but also in holding the line against conversion of undeveloped land.



The cost of food has jumped over 10 percent in India over the past year, and 6 percent in China, according to The Wall Street Journal. This is partly due to the diversion of corn to biofuels.



In the United States, driven by subsidized ethanol, farmers were planning to plant a record 90.5 million acres in corn in 2007, the highest since 1944, while at the same time reducing acreage in soybeans, rice and cotton.



Meanwhile, European demand for biofuels to replace gasoline is fueling plans for massive clearing of rainforests for palm‐​oil plantations in Indonesia and Malaysia.



These rainforests, among other things, provide refuge for the Sumatran tiger, Borneo’s orangutan and the Malaysian elephant. 



Ironically, much of the hysteria over global warming is itself fueled by concerns that it may drive numerous species to extinction and increase hunger worldwide, especially in developing countries. Yet the biofuel solution would only make bad matters worse on both counts. 



As long as global warming is hyped as the world’s most important environmental problem — as many politicians and environmental pressure groups claim — it will be virtually impossible to rationally evaluate other options in dealing with climate change, or confront the unintended consequences unleashed by global warming hysteria. 
"
"The UK government is prepared to accept funding for studies on the risks of pesticides to bees and other pollinators from the manufacturers of the chemicals in question. Not surprisingly, this raises uncomfortable questions about trust and transparency, as a report from the Environmental Audit Committee points out. I share their concerns that the Department for the Environment, Food and Rural Affairs (Defra) has insufficient capacity to monitor environmental safety and to carry out the sort of urgent testing needed for these neonicotinoid pesticides. The testing demanded is limited to industry-funded field trials. Will the fields chosen for outdoor trials reflect all fields where neonicotinoids may be used? Unlikely as most environments are complex and unique. Therefore, conclusions are hard to interpret – there are so many influencing factors including weather, disease, habitat structure and the use of other pesticides. And despite all farmers being required by EU regulations to record their use of pesticides, this information is not collected in the UK. Without knowledge on how farmers have used pesticides, singly and combined together, a huge unknown risk exists – not just to insects, but all life. Lab studies simplify a problem by breaking it down into testable hypotheses, in carefully controlled experiments, with other potential varying factors removed. Field studies can control some factors, but this is at the expense of being realistic – their claimed advantage. Alternatively, as Defra proposes, one can include other variables into the analysis. An excellent idea, but the experiments would need to be impossibly large, and one critical variable is missing – the presence of other pesticides – as Defra does not currently consider this important. The fact is we need both laboratory and field trials, and a more rigorous understanding of what insect pollinators are important and affected, the impact of different habitats and threats, what pesticides are there and how these all interact. Without adequate funding, we cannot hope to acquire this full scientific knowledge, and so we should adopt a precautionary principle wherever evidence of risk exists. This shouldn’t consider economic interests. It should be use-dependent, and consider what alternatives exist. Regardless of your opinion on the risks of neonicotinoid pesticides, nobody would recommend replacing them with even more toxic compounds; yet alternative pesticide options are not compared side by side in order to make a strategic choice. It has become clear that a simple lethal dose at which 50% (LD50) of bees or pollinators die is too crude a test to gauge a pesticide’s environmental risk. Which insects should be studied? In the laboratory, choices are limited due to issues of which insects can be easily bred and adapted for tests. In the field, we need a baseline to know what existed beforehand. What test? We need more assessment carried out on individual insects and how this impacts a colony’s performance. We also need to know about how long and in what concentrations pesticides persist in the environment.  Finally, we must investigate the effects of chemical cocktails. We can only achieve this through laboratory studies, and a mechanistic approach to screening. If we accept Defra’s view that only field studies are required, then we can never understand the full risk potential of chemical cocktails. But by combining the careful monitoring of insect pollinator populations (both managed and wild) and the information farmers record of which pesticides they use and how, we could actually learn from past mistakes using real field data. If the results are to be trusted by the public, the industry cannot be given control. Yet it is the pesticide chemical industry that needs the data in order to get approval for their products, for which they stand to financially benefit. So it’s obvious the industry should pay – but they must not control the research. Funds for such research should be collected by Defra and passed to research council funding agencies such as BBSRC and NERC to distribute anonymously to expert independent academic laboratories for blind testing. The researchers should know only what is essential to conduct safety tests in the field and laboratory. Industry should also be blinded to the identity of the researchers throughout, but receive the full dataset for comment.  This conflict of interest between safety and profit isn’t impossible to break. There is an urgent need for evidence of neonicotinoids’ safety, and perhaps anonymity can’t be achieved this time. Nevertheless the industry must not be involved at any stage of the research until after the findings have been peer-reviewed and published. Because if the public can’t trust the results, then the money has been wasted."
"

Advocates of health care reform and other big government programs, this is the business you have chosen: 



Main Street has had a tough year, losing jobs and seeing little evidence of the economic revival that experts say has already begun.   
  
  
But K Street is raking it in.   
  
  
Washington’s influence industry is on track to shatter last year’s record $3.3 billion spent to lobby Congress and the rest of the federal government — and that’s with a down economy and about 1,500 fewer registered lobbyists in town, according to data collected by the Center for Responsive Politics.…   
  
  
Plenty of sectors have scaled back their K Street spending, including traditional big spenders like real estate and telecommunications. But Obama’s push for legislation on health reform, financial reform and climate change has compensated for the grim economic times.   
  
  
And that’s after Obama kicked off the year with a massive economic stimulus package — and every major business sector tried to get a piece of the action. …   
  
  
“If lobbying the federal government did not work, people wouldn’t spend money doing it,” [Dave Levinthal, a spokesman for CRP] said.



Lay out a picnic, you get ants. Hand out more wealth through government, you get lobbyists. As Craig Holman of the Ralph Nader‐​founded Public Citizen says: _“the amount spent on lobbying … is related entirely to how much the federal government intervenes in the private economy.”_   
  
  
More on the lobbying bonanza in President Obama’s Washington here. Back in 2001 David Laband and George McClintock tried to estimate the total costs to society of efforts to effect forced transfers of wealth in their book _The Transfer Society_.
"
"The European Green Deal aims to transform the 27-country bloc from a high- to a low-carbon economy, without reducing prosperity and while improving people’s quality of life, through cleaner air and water, better health and a thriving natural world. If that sounds ambitious, it is. The European commission president, Ursula von der Leyen, called it “Europe’s man on the moon moment”. Nothing similar has been attempted before, as the pattern of human progress since the industrial revolution has been one of relentless exploitation and despoilment of the natural world, filling the atmosphere with carbon and the seas with plastic. Nearly every major aspect of the European economy will have to be overhauled, from energy generation to food consumption, from transport to manufacturing and construction. In part, this will build on two decades of work in a few of these sectors, such as directives mandating renewable energy and cutting air pollution. Previous attempts were piecemeal, limited in scope and sometimes flaccid in execution. Energy-intensive industries, for instance, have been covered by an emissions trading scheme since 2005, but political pressure kept the price of carbon low, rendering it largely ineffectual. The green deal will work through a framework of regulation and legislation setting clear overarching targets – a bloc-wide goal of net zero carbon emissions by 2050, and a 50%-55% cut in emissions by 2030 (compared with 1990 levels) are supposed to be at the core – alongside incentives to encourage private sector investment, with action plans for key sectors and goals such as halting species loss, cutting waste and better use of natural resources. All of the EU’s budget will be subject to checks to ensure it is spent in ways that benefit the environment. That includes the common agricultural policy, scorned by green campaigners for promoting intensive farming, which will retain farm subsidies but direct more to green measures. Science, research and development budgets will take on more of a low-carbon slant, and there will be a detailed roadmap of “50 actions for 2050” for other sectors. Jobs will be created, the commission believes, in new high-tech industries from renewable energy to electric vehicle manufacturing and sustainable building, and efficiencies in resource use will repay the cost of the changes. “The European green deal is our new growth strategy – a strategy for growth that gives back more than it takes away,” von der Leyen said. All of this will require myriad changes and detailed measures, which will have to pass through tortuous EU processes, requiring the approval of all member states and parliament, so the details will inevitably be subject to horse-trading and backroom deals. East European states have been promised financial incentives, as their economies are more fossil fuel dependent. The backing of the UK – which despite covertly watering down some measures in the past has broadly pushed for the low-carbon agenda – will be missed, predicts Jean Lambert, the former Green party MEP. The new European parliament also has more rightwing MEPs, so it may be harder to pass some measures, she says. The hole that Brexit has created in the EU budget will also be hard to fill. But what is clear is that the incoming presidency under von der Leyen and her vice-president, Frans Timmermans – charged with delivering the green deal – will throw all of its might behind the effort. “It’s not going to be straightforward to get all this through,” says Tom Burke, co-founder of the environmental group E3G. “It will be a typical EU process. But it has become the touchstone issue for this commission.” It needs to. Europe has cut emissions by roughly one quarter since 1990 – good but nowhere near enough to put the bloc on track to net zero by mid-century. Current measures will not suffice for that – disruptive change is required, which is why the green deal targets are key. On other environmental scores, the EU’s record is mixed. There have been vast improvements in areas such as air and water quality across EU states, western and eastern, in the past five decades, spurred by EU regulations since the 1980s. Dozens of harmful chemicals have been phased out, farm animal welfare standards raised and recycling rates beat most of the world. But alongside those successes, the natural world has suffered a calamity across the continent: birds, insects, mammals, fish … few creatures (other than humans) have had a good time of it since the EU was created in 1992.  At least €1 tn (£852bn) needs to be found over the next decade, according to the European commission. The biggest share, €503bn, should come from the EU budget, unleashing a further €114bn from national governments (because EU programmes often require a contribution from member states). The next €279bn would come mostly from the private sector: the idea is that companies would be encouraged to make risky green investments by loan guarantees from the European Investment Bank, the EU lender, which recently pledged to phase out loans to fossil fuel projects. On top of this Brussels has promised a €100bn “just transition” mechanism to help retrain workers who lose jobs in shuttered coal mines or steel factories. Even friendly experts detect wishful accounting in Brussels’ figures. Economists at the Bruegel thinktank say it is a stretch to consider the €503bn from the EU budget as “green investment”, as much of the money would be spent on traditional EU policies such as farm subsidies. Previous attempts to “green” the common agricultural policy have failed dismally. In a damning report in 2017, the EU’s auditors highlighted how farmers were being paid to undertake environmentally friendly measures they would have done anyway, such as crop rotation, while governments handed out “green” cash with little oversight. Others fear that carbon financiers will game the system, meaning EU cash fails to trigger truly green investment from the private sector. And don’t forget, EU governments last month failed to agree a new seven-year budget, with four “frugal” net payers leading the charge to cut EU spending. The €503bn is not even in the bank. Even if the EU realised its €1tn plan, it wouldn’t be enough. Bruegel argues the €1tn is only one third of what is needed, if the EU follows through with the commission’s plan to reduce European greenhouse gas emissions by up to 55% by 2030. Meanwhile, critics in eastern countries complain there is not enough money to help coal regions. In 2015 there were 128 coal mines alone in the EU employing more than 238,000 people from Aragón to Silesia. This year – coronavirus permitting – will see the most important international climate meeting since the landmark Paris agreement was signed in 2015. Then, all of the world’s functioning states signed up to hold global temperature rises to no more than 2C, and preferably to below 1.5C, beyond which the ravages of climate breakdown become catastrophic and irreversible. But the national pledges made at Paris on curbing greenhouse gases fell short of what is required to stay below 2C, and since 2015 the world’s carbon output has risen by 4%. At the Cop26 climate talks, to be held in Glasgow this November, nations are supposed to come up with tougher targets for 2030, and preferably also with goals for reaching net zero emissions by mid-century, or soon after. But enthusiasm has ebbed since Paris, from Donald Trump’s US, to Brazil, India and big oil producers such as Russia and Saudi Arabia. The key player will be China, the world’s biggest emitter of greenhouse gases and second biggest economy. At Paris, a pact between the US and China was the core of the deal. This time, the EU must bring China to the table alone. “EU climate leadership [in the form of] the green deal is crucial to putting pressure on China and other major emitters to make more ambitious climate commitments,” says Paul Bledsoe, a climate adviser in Bill Clinton’s White House, who has attended more than a dozen climate negotiations since the 1990s. “In the face of Trump’s climate nihilism, only the EU can show that the world’s largest economy can decarbonise while continuing to provide a high standard of living for its 500 million people.” The EU will face a backlash from its citizens, fuelled by populist politicians, for persisting with green policies, predicts Charles Grant, director of the Centre for European Reform thinktank. He points to the gilets jaunes protests in France, which took off after rises in fuel taxes intended to reduce carbon dioxide emissions, and the rise of the AFD in Germany. “The AFD is fuelled partly by climate scepticism. Populists are keen to promote anti-greenery, as they listen to voters,” he says. “The green agenda will meet more and more opposition as voters start to realise it will make them poorer and affect their lifestyles, and they will worry about Europe becoming less competitive than, say, India and China, which won’t be going carbon-neutral,” says Grant. “This will increase the electoral strength of populists.” Some leftwing campaigners have also attacked the plans. Taking issue with the “just transition” mechanism, Yanis Varoufakis and David Adler of the Democracy in Europe Movement 2025, wrote in the Guardian: “Will there be justice for the communities across Germany and France that have been asked to shoulder the costs of the climate transition? Does it speak to the swathes of Greek or Portuguese people who cannot afford to care about carbon emissions in 2050, preoccupied as they are with making ends meet this week? The stark answer is no.” Boris Johnson’s government has made it clear that the UK wants to depart from EU environmental standards after Brexit. The post-Brexit environment bill, agriculture bill and fisheries bill now going through the British parliament contain various loopholes that green campaigners say would reduce in the UK the environmental protections that current EU law guarantees. The UK does officially have a 25-year environment plan, with the government pledging to leave the UK’s natural realm in a better state than this generation inherited, but how that will hold up after Brexit is moot. On the climate crisis, the UK is aligned with the EU. Last summer, a target of reaching net zero by 2050 was enshrined in law, and all major parties are pledged to uphold it. What’s missing, though, is a clear plan of action to meet the net zero aim. That is what Europe’s green deal is meant to provide, and unless the UK forms its own parallel plans soon, its 2050 target will look increasingly adrift. The idea of a Green New Deal has been kicking around US politics since at least 2006. The European Green Deal (minus the word “new’ with its radical overtones) is not yet one year old. The EU plan resulted when an unexpected political leader collided with newly-elected MEPs, energised by the global climate movement. Von der Leyen, a German defence minister, was a surprise choice to become European commission president, leapfrogging candidates who had run in the European elections in May. Those elections resulted in a record number of seats for European Greens, as climate change topped the agenda in Germany and the Nordic countries. Von der Leyen’s last-minute elevation angered the European parliament, pressuring her to lean to the left, liberals and Greens to gain support. To win MEPs over, she promised a European Green Deal within 100 days of taking office. Beyond the Brussels power play, politicians were responding to the streets, as school children walked out of their classrooms, demanding action. The school strike was personal. Chief executives, heads of government and senior UN officials told EU officials their children were asking what they were doing to save the planet. As one official recounts: “You can imagine a conversation with your own children is much more confrontational than a conversation with a shareholder, or a bad headline in a newspaper.” It’s a bit like world peace: everyone backs the European Green Deal, in theory. But there is a big hole in the ambition to be net-zero by 2050: Poland, which says it will reach climate neutrality at “its own pace”. And beneath the surface, tensions over Europe’s green ambitions are not hard to find. At least eight countries, including Spain, Sweden and Latvia, want the EU to increase its 2030 emissions reduction target. Poland and Hungary think that is too much. Divisions will also come when hard choices have to be made: from closing coal mines, demanding more from farmers, to tougher emissions standards for the car industry. EU governments agree environmental laws with the European parliament. That gives MEPs a weighty role across a swathe of new laws expected to flow from the European Green Deal: a revision of the EU’s heavily criticised carbon trading scheme, new performance standards for cars and vans, an overhaul of farm policy, changes to EU rules on state subsidies that will phase out support for fossil fuels. Typically, the parliament tends to raise the bar on green action – it last year declared a climate emergency. But MEPs often lose the battle against EU ministers, who usually get the upper hand in EU negotiations. Reading list The European Green Deal, the European commission A trillion reasons to scrutinise the Green Deal Investment Plan, Bruegel How good is the European commission’s Just Transition Fund proposal?, Bruegel Europe’s Green Deal, Jeffrey Sachs, Project Syndicate"
"**Scotland's finance secretary has said the chancellor's plan to freeze some public pay ""absolutely misjudges the value of frontline services"".**
Kate Forbes said she disagreed with the decision, announced by Rishi Sunak during the UK government's Spending Review on Wednesday.
The chancellor said the pay freeze will affect 1.3 million workers.
He said the freeze was part of the ""tough choices"" arising from the Â£280bn cost of the pandemic so far.
The Scottish government will publish details of the public sector pay awards it controls in January.
Ms Forbes stopped short of promising a public sector pay rise but said January's Scottish budget would include ""a recognition of the work that our key workers have done"".
Staff on less than Â£24,000 and some NHS workers will still get a pay rise under the UK government's plans.
Speaking to Good Morning Scotland, Ms Forbes: ""I think the pay freeze absolutely misjudges the value of frontline services, I absolutely disagree with the chancellor's approach to freezing pay of public sector workers.
""Just a few short months ago we were applauding the key workers who were working on the frontline and responding to Covid, and now they are seeing their pay frozen.
""What you can assume is we will build on our approach of the last few years which is to recognise the work of key workers.""
In Scotland, many public sector pay awards are made or negotiated separately from the UK, including local government workers, GPs and teachers.
January's budget comes ahead of the Holyrood election on 6 May.
Mr Sunak has said the economic emergency the UK faces means ""tough choices"" had to be made over which public sector workers would get a pay rise.
Speaking to BBC Breakfast, he said: ""I've had to make some tough choices and what I couldn't do is justify an across-the-board rise in public sector pay.""
Alister Jack, the Scottish Secretary, added that the chancellor's Spending Review was aimed a trying to ""re-inflate the economy by keeping money in it and see tax receipts go up from business activity."""
"**With England's lockdown coming to an end, it's all change.**
A new system of regional tiers will come into force next week. That will be followed by a relaxation of rules at Christmas across the UK which will allow up to three households to meet over the festive period.
But scientists are warning the move risks a third wave of Covid. Is the government making a mistake?
Scientists have been pretty vocal about their concerns. Prof Andrew Hayward, an expert in infectious diseases at University College London and member of the government's Scientific Advisory Group on Emergencies (Sage), believes the relaxation of restrictions at Christmas is tantamount to ""throwing fuel on the Covid fire"".
He warns it is likely to lead to a third wave of infection with ""hospitals being overrun and more unnecessary deaths"".
Edinburgh University global public health chair Prof Devi Sridhar, who advises the Scottish government, agrees. She says she cannot understand the move given that the rollout of vaccines is so close.
""Why risk getting infected and infecting others over the holidays? Delaying by a few months is perfectly rational given solutions within sight in the spring."" She now fears we will ""pay for"" Christmas with lockdowns in the new year.
What is certainly true is that more mixing will lead to more infections. That is a given since the virus thrives on human contact. But there is an argument that what the government is doing will actually help curb infections in both the short and long-term.
Modelling done for the government has suggested that for every day of restrictions being relaxed, five days of tougher ones are needed.
But others advising ministers think this way of looking at things is too one-dimensional. ""The problem with the modellers,"" says a member of SPI-B, the government committee that advises on human behaviour, ""is that they see a nut and reach for the sledgehammer.
""Banning Christmas was never going to work. People were not going to follow the rules. Providing guidance to help them celebrate safely is perhaps a much better way of managing the situation.""
The UK is also not unique in taking this approach. France has announced it will be relaxing the rules at Christmas and other parts of Europe look likely to follow suit in the coming weeks.
Prof Stephen Reicher, an expert in social psychology at the University of St Andrews who also sits on SPI-B, says it is impossible to know to what extent the public would have followed the restrictions at Christmas had they remained in place.
But he says there was certainly a danger that people would have ""asserted their will"", arguing: ""People don't like being lectured to.""
He says that by providing people with the autonomy to make their own decisions, you encourage people to take more responsibility and become actively engaged in working out the best choice to make.
And he thinks the pivot from ""paternalism to partnership"" could actually help build trust in the longer term, which will stand the UK in good stead for the rest of the winter in terms of adherence to restrictions and take-up of the vaccine.
More trust is certainly needed. Polling by YouGov shows public trust in the government has halved since the spring, with just a third of people happy with its handling of the pandemic.
Prof Reicher says what the government has to do now is provide good, clear advice on how to reduce the risks, from ensuring rooms are ventilated to the benefits of isolating before getting together.
But he would also like to see some more practical support. As an example, he says the government could provide ""Covid fuel allowances"" to allow people to leave windows open and the heating on during Christmas.
Another idea, he says, would be to introduce an extra bank holiday at Easter to provide an incentive to delay family get-togethers to a time when those at most risk are likely to have been vaccinated, and the change in the seasons means there is likely to be less virus around.
There are some signs the government is moving in this direction. Ministers have being speaking about the need to use the opportunity to meet up responsibly - with the key message being just because you can, it does not mean you have to.
A crucial consideration will, of course, be assessing who is the most vulnerable in each Christmas bubble.
Age is the overriding factor when it comes to risk from Covid.
But as well as minimising risk, there is also a need to assess the benefits. For some, this could be the last chance they have of a family Christmas.
And, even where that is not the case, a year spent not seeing family and being isolated from people has clearly taken its toll.
Prof Paul Hunter, from the University of East Anglia's school of medicine, says the benefits on people's mental health of being able to meet up with family over this time ""should not be underestimated"".
Indeed, he believes for some it will provide the boost that people need to ""make it through the rest of winter"".
But the other factor that is just as important - and this was a point made earlier this week by England's chief medical officer Prof Chris Whitty - is adherence to the regional tier restrictions in the lead up to Christmas and afterwards.
Doing this, he says, will minimise the risks.
The move into lockdown was widely interpreted as a sign the regional tiers introduced in mid October were not working. But infection rates were actually stabilising by the time lockdown came in as the chart below shows.
And now an analysis by the University of East Anglia has shed more light on how they could be more effective.
It looked at infection rates across 315 local authority areas across England during the period where tiers were used. It found the tier with the least restrictions - tier one - was largely inadequate in that it was unable to control the virus because rates of infection were too high.
Tier two was effective in about half of local authority areas placed in it, while tier three was good enough to drive the R number measuring the rate of infection below one.
One of the key problems, the research said, was the fact that areas were often not moved into a higher tier quickly enough.
The government says it will learn the lessons from that. It has already moved to beef up the tiers - the top two will see tighter restrictions on hospitality in particular.
The hope is that a more intelligent use of the system coupled with the Christmas boost to the public's resolve could suppress virus enough to avoid another lockdown and get us through winter.
_Follow Nick_on Twitter
Read more from Nick"
"Globally, we still catch enough fish to eat – just about. But numbers of fish caught from the sea haven’t kept up with human population growth and unsustainable fish farms have filled the gap. So why are we still being encouraged to eat more fish? The health benefits are clear: fish protein is typically low in saturated fats and high in nutrients and essential fatty acids. UK and US food standards agencies recommend eating two portions of fish per week, while Australia, New Zealand and Estonia advocate two or three servings per week and Greece five or six. Yet as our recent research has shown these health recommendations must be set against a backdrop of declining global fish stocks and food security concerns. While in the UK fish constitutes just one choice of animal protein among many, one billion people throughout the world rely upon it as their primary source of animal protein and our global fisheries are in crisis.  Some fisheries do exist that successfully balance production and sustainability, but many more are under increasing pressure from over-exploitation, destructive fishing practises like trawling and dredging, pollution or other factors. As the world’s population continues to expand these pressures are likely to intensify, not decrease. Over the past 50 years fisheries have rapidly expanded and today fish is one of the world’s most globalised commodities. The UK is typical: the fish you buy in supermarkets comes from all over the world. Cod and haddock are sourced from Iceland and Norway, while much of our tuna comes from the Indian Ocean, South-East Asia and West Africa. Shrimp and prawns are sourced from Asia, Iceland and Canada. The UK also exports fish – mainly mackerel, herring and farmed salmon – to the EU, the US and Russia, although far less than it imports. For a nation surrounded by the sea, the British have never been especially ardent lovers of fish. Before the advent of freezers and swift transport networks you could understand why; fish spoils rapidly unless salted or smoked. However, railways built in the mid-19th century provided reliable transport to inland markets for the first time and helped drive the expansion of industrial fisheries around the UK. Subsequently, the British developed a taste for fish, although mainly when covered in batter and deep-fried.  National recording of landings and fishing effort began in the 1880s and help us chart the development of the UK’s fisheries. Fuelled by steam power and ice, accessible fishing grounds expanded to the Arctic, North America and Africa during the early 20th century and the total catch grew rapidly. However the formation of exclusive economic zones in the late 1970s forced a return to home grounds and it became ever more apparent that fish had been over exploited and stocks were seriously depleted. Government records show that landings of fish by UK vessels peaked in 1913 at 1.27m tonnes and declined throughout the remainder of the 20th century. Today, a significant proportion of UK vessels land their fish abroad, but even accounting for these ships domestic production is still half what it was a century ago. This can be partly attributed to a loss of European markets during and after the war, and restriction of traditional fishing grounds from the 1970s, but many fish stocks are also at historically low levels. During this period, the UK population has also increased and to keep up with demand as well as diversify our fish supply, greater and greater quantities of fish are sourced from other nations’ waters. Clearly, fish supply is not merely a domestic issue and policies that support increased consumption at the national level must also strive to adopt a more global outlook. For example, the quantity of domestic fish available (through landings and aquaculture) per person in the UK plummeted throughout the 20th century, with overall supplies only kept stable by imports. But even despite this declining supply UK consumers still eat less fish than the recommended two portions (280 g) per week, which is fortunate really, since only twice in the past 120 years have supplies been sufficient to meet this aspiration. If demand should rise further, either through population growth or changes in consumer preference, it is likely that even more extra fish will have to be sourced from other nations.  Increased imports are not necessarily an indication of unsustainability, but they do demonstrate the potential for developed nations to mask domestic shortfalls in wild fish. This experience is not just restricted to the UK: Europe imports around 55% of the fish it consumes; last year the US imported 91% of its fish. While developed countries are able to mask domestic declines, this is not the case in societies that rely upon fish as their major source of protein. Global wild fish landings plateaued at 85-95m tonnes during the 1990s. However, when human population growth is taken into account, wild fish availability per person has been in decline since 1970.  Global fish supplies have only been stabilised by increasing aquaculture production, which is currently exceeding the pace of human population growth. Yet fish farms come with associated environmental costs of habitat loss, pollution, introduced species, pests and diseases, which will need to be addressed if aquaculture production is to keep up with future population growth. Though aquaculture has so far prevented a downturn in global fish supplies, many developed nations continue to aspire to consume more fish than they produce. Until demand is balanced with sustainable methods of production governments should consider carefully the global social and environmental implications of national policies that promote greater fish consumption."
"
Share this...FacebookTwitterOne of the IPCC’s most dubious achievements is ignoring so many papers showing that the sun plays a huge role in our climate. The sun play a role? Yeah, right!
A reader brings our attention to some recent papers showing that the sun plays a major role on climate, not that the IPCC will be the least bit interested. Here are a few in case you may have missed any.
1. Variations in tree ring stable isotope records from northern Finland and their possible connection to solar activity; Ogurtsov et al, 2010, see abstract here.
Statistical analysis of the carbon and oxygen stable isotope recordsr eveals variations in the periods around 100, 11 and 3 years.A century scale connection between the 13C/12C record and solar activity is most evident.”
2. A possible solar pacemaker for Holocene fluctuations of a salt-marsh in southern Italy; Di Rita, 2011 abstract here.
The chronological correspondence between the ages of saltmarsh vegetation reductions and the minimum concentration values of 10Be in the GISP2 ice core supports the hypothesis that important fluctuations in the extent of the salt-marsh in the coastal Tavoliere plain are related to variations of solar activity.”
3. Solar and volcanic fingerprints in tree-ring chronologies over the past 2000 years; Breitenmoser et al, 2012
Results from wavelet analysis and SEA reveal significant periodicities near the solar DeVries frequency in the volcanic and residual ‘volcano free’ contributions during the LIA, making a clear separation of the solar and volcanic forcing signals difficult. Nevertheless, the ‘volcano free’ temperatures show significant periodicities near the DeVries frequency during the entire past 1500 years, pointing to a solar imprint on global climate.
4. Holocene hydrological changes in south-western Mediterranean as recorded by lake-level fluctuations at Lago Preola, a coastal lake in southern Sicily, Italy; Magny et al, 2011, see abstract here.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




This major oscillation may be related to a non-linear response of the climatic system to the gradual decrease in insolation, in addition to seasonal and inter-hemispherical changes in insolation. Another major climate oscillation around 7500 – 7000 cal BP may have resulted from combined effects of a strong rate of change in insolation and of variations in solar activity.”
5. Variations in climate parameters at time intervals from hundreds to tens of millions of years in the past and its relation to solar activity; Raspopov et al, 2010, see abstract here.
Our analysis of 200-year climatic oscillations in modern times and also data of other researchers referred to above suggest that these climatic oscillations can be attributed to solar forcing. The results obtained in our study for climatic variations millions of years ago indicate, in our opinion, that the 200- year solar cycle exerted a strong influence on climate parameters at those time intervals as well.”
6. Climate patterns in north central China during the last 1800 yr and their possible driving force; Tan et al, 2011, see abstract here.
Solar activity may be the dominant force that drove the same-phase variations of the temperature and precipitation in north central China.
7. Multifractal Detrended Cross-Correlation Analysis of sunspot numbers and river flow fluctuations; Hajian, 2010, see abstract here.
Our results show that there exists a long-range cross-correlation between the sunspot numbers and the underlying streamflow records.”
Doesn’t Hajian work for the Iranian gas and oil industry?
 
Share this...FacebookTwitter "
"
Forecasting The NSIDC News
By Steven Goddard and Anthony Watts
Barring an about face by nature or adjustments, it appears that for the first time since 2001, Arctic Sea ice will hit the “normal” line as defined by the National Snow and Ice Data Center (NSIDC) for this time of year.
NSIDC puts out an article about once a month called the Sea Ice News.  It generally highlights any bad news they can find about the disappearance of Arctic ice.  Last month’s news led with this sentence.
In February, Arctic sea ice extent continued to track below the average, and near the levels observed for February 2007.
But March brought good news for the Polar Bears, and bad news for the Catlin Expedition and any others looking for bad news.  Instead of ice extent declining through March like it usually does, it continued to increase through the month and is now at the high (so far) for the year.
If it keeps this trend unabated, in a day or two it will likely cross the “normal” line.

Source: NSIDC North Series

The Danish Meteorological Institute shows Arctic ice extent at the highest level in their six year record.

Source: DMI Ice Extent
The Norwegians (NORSEX) show Arctic ice area above the 30 year mean.

Source: NORSEX Ice Area
And the NORSEX Ice Extent is not far behind, within 1 standard deviation, and similar to NSIDC’s presentation. Note that is hit normal last year, but later.

Source: NORSEX Ice Extent
And JAXA, using the more advanced AMSR-E sensor platform on the AQUA satellite, shows a similar uptick now intersecting the 2003 data line.

Source: IARC-JAXA
WUWT asked NSIDC scientist Dr. Walt Meir about this event to which he responded via email:
It’s a good question about the last time we’ve been above average. It was May 2001. April-May is the  period when you’re starting to get into the peak of the melt season for the  regions outside of the Arctic Ocean (Bering Sea, Hudson Bay) and the extent  tends to have lower  variability compared to other parts of the year as that  thinner ice  tends to go about the same time of year due to the solar  heating. Even  last year, we came fairly close to the average in early  May.
He also mused about a cause:
Basically, it is due primarily to a lot more ice in the Bering Sea, as is evident in the images. The Bering ice is controlled largely by local winds, temperatures are not as important (though of course it still need to be at or at least near freezing to have ice an area for any length of time). We’ve seen a lot of northerly winds this winter in the Bering, particularly the last couple of weeks.
As we’ve been saying on WUWT for quite some time, wind seems to be a more powerful factor in recent sea ice declines than temperature. Recent studies agree.
See: Winds  are Dominant Cause of Greenland  and West Antarctic Ice Sheet Losses and also NASA  Sees Arctic Ocean Circulation Do an About-Face
You can  watch wind patterns in this time lapse animation, note how the ice has been pushed by winds and flowing down the east coast of Greenland:
Animation of Arctic sea-ice being pushed by wind patterns - CLICK IMAGE TO VIEW ANIMATION- Above image is not part of original story, but included to demonstrate the issue. Note that the animation is large, about 7 MB and may take awhile to load on your computer. It is worth the wait Source: National Snow and Ice Data Center

Dr. Meier also wrote:
This has very little implication for what will happen this summer, or  for the long-term trends, since the Bering Sea ice is thin and will melt completely well before the peak summer season.
There’s certainly no reason to disagree with the idea that much of the Bering Sea ice will melt this summer, it happens every year and has for millenia. But with a strong negative Arctic Oscillation this year, and a change in the wind, it is yet to be determined if Arctic Sea ice minimum for 2010 is anomalously low, and/or delayed from the usual time.
In 2009, WUWT noted it on September 15th: Arctic sea ice melt appears to have turned the  corner for 2009
Dr. Mark Serreze of NSIDC offered some hopeful commentary in a press release back on October 6th 2009, but still  pushes that “ice free summer” meme:
“It’s nice to see a little recovery over the past couple of  years, but  there’s no reason to think that we’re headed back to conditions seen in  the 1970s,” said NSIDC Director Mark Serreze, also a professor in  CU-Boulder’s geography department. “We still expect to see ice-free  summers sometime in the next few decades.”
Remember this 2007 prediction from The Naval Postgraduate School?
http://news.bbc.co.uk/2/hi/7139797.stm
==============================


Arctic summers ice-free ‘by 2013’






By Jonathan Amos
Science reporter, BBC News, San  Francisco












Arctic summer melting in 2007 set new records

More details




Scientists in the US have presented one of the most dramatic forecasts yet  for the disappearance of Arctic sea ice.
Their latest modelling studies indicate northern polar waters could be  ice-free in summers within just 5-6 years.
Professor Wieslaw Maslowski told an American Geophysical Union meeting that  previous projections had underestimated the processes now driving ice loss.
Summer melting this year reduced the ice cover to 4.13 million sq km, the  smallest ever extent in modern times.
Remarkably, this stunning low point was not even incorporated into the model  runs of Professor Maslowski and his team, which used data sets from 1979 to 2004  to constrain their future projections.






 In the end, it will just melt away quite suddenly 


Professor Peter Wadhams





“Our  projection of 2013 for the removal of ice in summer is not accounting for the  last two minima, in 2005 and 2007,” the researcher from the Naval Postgraduate  School, Monterey, California, explained to the BBC.”So given that fact, you can argue that may be our projection of 2013 is  already too conservative.”


========================================
Joe Romm wrote up a clever piece last year on this subject:
Exclusive: New NSIDC director Serreze explains the “death spiral” of Arctic ice, brushes off the “breathtaking ignorance” of blogs like WattsUpWithThat
June 5, 2009
I interviewed by email Dr. Mark Serreze, recently named director of The National Snow and Ice Data Center.  Partly I wanted him to explain his “death spiral” metaphor for Arctic ice
So now that Arctic ice has returned to normal extent and area, we eagerly await the explanation from the experts about how that fits into the “death spiral” theory.  Richard Feynman famously said “Science is the belief in the ignorance of the experts.”
Time will tell. 2010 is looking promising for sea ice recovery again. After all, who wouldn’t want the Arctic Sea ice to recover? WUWT is predicting a recovery again this year, which we started mentioning as a prediction last fall.
So given what we know today, what will NSIDC highlight in their April Sea Ice News?
Take Our Poll
And even more importantly, will the MSM cover it like they do the ‘terrible’ minimums?
NOTE: The poll code got messed up, duplicating an entry, press REFRESH if you see a double entry. -A



Forecasting The NSIDC News
 NSIDC puts out an article about once a month called the Sea Ice News.  It generally highlights any bad news they can find about the disappearance of Arctic ice.  Last month’s news led with this sentence.
In February, Arctic sea ice extent continued to track below the average, and near the levels observed for February 2007.
But March brought good news for the Polar Bears, and bad news for the Catlin Expedition and any others looking for bad news.  Instead of ice extent declining through March like it usually does, it continued to increase through the month and is now at the high (so far) for the year.
 
http://nsidc.org/data/seaice_index/images/daily_images/N_stddev_timeseries.png
The Danish Meteorological Institute shows Arctic ice extent at the highest level in their six year record.


DMI Ice Extent
The Norwegians (NORSEX) show Arctic ice area above the 30 year mean.
 
NORSEX Ice Area
Joe Romm wrote up a clever piece last year on this subject:
Exclusive: New NSIDC director Serreze explains the “death spiral” of Arctic ice, brushes off the “breathtaking ignorance” of blogs like WattsUpWithThat
June 5, 2009
I interviewed by email Dr. Mark Serreze, recently named director of The National Snow and Ice Data Center.  Partly I wanted him to explain his “death spiral” metaphor for Arctic ice
So now that Arctic ice has returned to normal extent and area, I eagerly await the explanation from the experts about how that fits into the “death spiral” theory.  Richard Feynman famously said “Science is the belief in the ignorance of the experts.”
So what will NSIDC highlight in their April Sea Ice News?


The 	increase in both ice extent and quantity of multi-year ice


The 	long-term downwards linear trend line


The 	lack of 4+ year old ice





Sponsored IT training links:
Get free resources including 642-972 tutorial and 1z0-048 dumps questions for guaranteed success in JN0-532 exam.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8cb7c1de',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

The Nordic countries are widely regarded as world leaders in gender equality. In the Global Gender Gap Index, the Nordic nations are top performers. Iceland leads the list, followed by Norway, Finland, and Sweden in second, third, and fifth places, respectively. Denmark ranks lowest in 14th place, but still considerably higher than the United States, which is in 49th place.



A common view is that Nordic gender equality reflects the social welfare policies of these nations. Indeed, Nordic governments advertise their welfare systems as a recipe for gender equality and even promote these policies in the United States for that reason. Several other European countries have followed in Norway’s tracks by legislating gender quotas for board of director positions in publicly traded firms. Although the political climate in the United States is not ripe for quotas, that policy does lie on the horizon.



This analysis argues that gender quotas have been ineffective and that several aspects of Nordic social policies have negatively affected women’s career progress and even contributed to a glass ceiling. The glass ceiling is a metaphor for the barriers women face in reaching leadership positions.



While Nordic societies are indeed role models when it comes to gender equality, this equality stretches back centuries before the modern welfare state and reflects traditional Nordic culture.



The rise of the Nordic welfare state has been a double-edged sword: creating some benefits for women’s careers, but also creating barriers to women’s professional progress. For example, benefits include various public systems that encourage a combination of family and work, such as public daycare and parental leave benefits.



But barriers abound. Public monopolies in health care, child care, and elderly care reduce development of these women-intensive parts of the labor market. High taxes and welfare policies encourage women to work fewer hours, and generous parental leave systems influence women to stay home, all of which reduce their ability to climb the career ladder.



I begin my paper by outlining significant cultural and historical elements that underpin equality in the region. These historical features fall outside of touted modern social democratic policies. Next, I describe how Nordic public-sector monopolies, tax policy, and welfare policies have affected women’s careers. Finally, I compare women’s professional outcomes in the Nordic countries and find them lacking. Nordic countries seemingly have the best possibilities for women to reach the top, but Nordic women are not world leaders when it comes to the rate of women advancing to top positions in the private sector. In spite of their intentions, gender quotas are unable to meaningfully improve Nordic women’s professional outcomes in terms of leadership, pay, or career goals. And although Norwegian gender quotas are inspiring similar policies throughout the world, few admirers seem aware of the Norwegian research literature that shows they have had little or no positive meaningful effect on women’s careers.



In an age of women’s progress, the Nordic societies are worth admiring for a culture that supports gender equality. But when it comes to supporting women’s professional development, the Nordic model has disadvantages.



A common assumption is that Nordic gender equality is a product of prevalent welfare-state policies.1 But a broader perspective shows egalitarian gender values predate modern welfare states by centuries in Sweden and other Nordic countries. The Viking ancestors of today’s Nordic societies had a culture that emphasized women’s rights.



Norse societies are often portrayed in books and media as having a relatively even distribution of power between the sexes. Although these cultures were patriarchal, women had considerably more influence in Norse societies than women in other contemporary cultures. For example, Scandinavian folklore includes _shieldmaidens_ , women who fought as warriors. Byzantine historian John Skylitzes records that women were participating in Nordic armies during the 10th century.2 This suggests that gender segmentation in early Norse societies was considerably more flexible than in other parts of contemporary Europe.



There is also evidence that women in early Nordic societies could inherit land and property, control their dowry, and own a third of the property they shared with their spouses. They could sometimes participate in the public sphere with men. Additionally, women could opt for divorce.3 Medieval laws show that Nordic women had greater rights than women in other parts of the contemporary world: inheritance laws in Norway followed family relations through female lines as well as male lines.



These rights might not seem impressive today, but they were historically unusual. In many contemporary European and Asian societies, the legal system was based on women belonging to their fathers or husbands and the women held minimal property, contractual, and public participation rights.



Nordic gender egalitarianism continued following the Viking age. In much of the world, women were excluded from participating in the rise of capitalism during the 18th and 19th centuries; free markets and property rights were treated as institutions for men. Although Nordic countries were far from perfectly egalitarian, they challenged contemporary gender norms by inviting female participation in early capitalism.4



For example, Swedish women began managing businesses during the second half of the 18th century. In 1798 a reform was passed that stipulated that married women had legal majority and juridical responsibility within the affairs of their businesses, and in 1864 Swedish business freedom was granted to virtually all unmarried adult women and all adult men.5



Although married women were initially excluded, it is noteworthy that business freedom was granted to both sexes at the same time. Swedish women were given the right to stipulate in premarital contracts that their husbands could not impose on the business 10 years later.6



Alongside American states, the Nordic nations were pushing for women’s economic rights. Married women in Maine gained the right to a separate economy in 1844, and four years later the Married Woman’s Property Act was passed in New York, allowing women to enter contracts on their own.7 In other regards, the Nordic countries were ahead of the American states. For example, in 1850 Iceland became the first country to institute unconditional equal inheritance rights.8 Nordic and American advances in women’s economic rights were, at their time, groundbreaking, and inspired similar reforms in other parts of the world.



Nordic policies continued developing during the beginning of the 20th century. The question of labor legislation to “protect” women from factory work was suggested in the beginning of the century, inspired by international developments. These proposals caused heated debate. Sweden did introduce a night-work prohibition in 1909, after considerable criticism from the women’s movement. Unlike other European countries, Australia, and the United States, a prohibition on women’s night work was never included in Danish and Norwegian factory laws. Women were allowed to participate in the industrial development of these two countries.9



Nordic countries recognized married women as individuals in their own right in the early 20th century, before the rise of the modern welfare state.10 Nordic tax law and marriage law provide an example of this treatment. They are based on a dual-breadwinner model, so men and women are taxed independently. In societies where spouses are taxed jointly, both spouses will face high marginal tax rates if one has a high income. In Nordic tax systems, the spouse with a lower income (often the wife) will not experience a higher marginal tax rate if the other spouse has a higher income. This model encourages both spouses to invest in their careers.



In addition, marriage legislation in the Nordic countries has been built around the idea that men and women are jointly responsible for family provision. In the rest of Europe, marriage legislation has traditionally given the husband the responsibility to provide for his family, declaring the husband’s guardianship over his wife and children.



The Nordic tradition of gender equality is evident today in the values of these societies. The World Values Survey shows that Sweden has the smallest proportion of respondents who believe men should have more of a right to a job than women if jobs are scarce. As shown in Figure 1, Sweden stands out as unusually gender egalitarian in this regard. While similar attitudes can be found in other modern societies such as the United States and Australia, the Nordic countries stand out as having the most gender-equal values. Previous surveys that included other Nordic countries show egalitarian gender beliefs are held throughout the region.11





Similarly, a 2015 YouGov survey found that a minority of Nordic respondents agree with the statement “It is likely to cause problems if a woman earns more money than her husband.” Just 26 percent in Finland, 20 percent in Sweden, and 18 percent in Norway and Denmark rated this statement as true, contrasted with 32 percent of Americans.12



The long tradition of gender-equal laws and values should theoretically create optimal conditions for Nordic women to reach the top of the career ladder. But Nordic countries are not world leaders in the share of women who climb to the top. The modern welfare state seems to create a glass ceiling.



It has long been evident that Nordic countries have a lower representation of women in business than many modern economies. A Eurostat study from 1995 found that only 6 percent of top earners in Sweden were women, considerably lower than France’s 15 percent.13 A study from the University of California–Los Angeles (UCLA) concluded that merely 11 percent of managers and professionals in Sweden were women, lower than in other developed economies.14



As early as 1998 the International Labor Office published a report that noted an unusually gender-segregated labor market in Scandinavian countries, with many women working in the public rather than the private sector.15



Economists Magnus Henrekson and Mikael Stenkula note in an academic literature review that women are underrepresented in executive positions in Sweden—behind the United States, United Kingdom, West Germany, and France. They conclude that “broad-based welfare-state policies impede women’s representation in elite competitive positions.”16



A key explanation lies in the expansion of the welfare state into the service sector. The Nordic countries adopted large welfare sectors that expanded into education, health, and elderly care.17 In Sweden and other Nordic countries, female-dominated sectors such as health care and education are almost entirely financed by the public sector. The Nordic Innovation Centre notes that the high percentage of women working in public monopolies explains some of the difference in entrepreneurship rates between genders.18



The emergence of a large public sector has been both positive and negative for women. It played an important historical role in women’s entry into the labor market because many women entered through the expanding public sector. Public-sector services also facilitated the combination of work and the fulfilment of family responsibilities. The expansion of the public sector partly explains why Nordic nations reached a high employment rate among women earlier than other Western countries and stayed that way. The provision of public daycare was particularly important in this regard.



But labor-force participation is only one measure of female professional success. Another measure is female business ownership. Anita Lignell Du Rietz studied women’s business ownership in Sweden and found that many businesses, including taverns, tailor shops, breweries, and stores were run by women entrepreneurs during the 19th century. Over time, women dominated businesses such as schools and pharmacies.



However, government monopolies crowded out private enterprise as the Swedish welfare state grew during the 20th century. Meanwhile, male-dominated sectors, including manufacturing, mining, and forestry, remained under private control. The transition toward welfare-state monopolies meant that women’s business ownership suffered.19



Government monopolies have combined with a strong influence of union wage-setting to undermine incentives for work: wages in the female-dominated public sectors in Nordic countries are flat, and rise based on seniority rather than achievement. Although there are public-sector managerial positions, the opportunities for individualized careers and business ownership are comparatively limited.



Recent labor liberalizations highlight the effects of government monopolies. Since the early 1990s, Swedish public monopolies have gradually opened up to private enterprise. New systems have been created in which tax-funded welfare services such as education, elderly care, and health care are partially provided by the public sector and partially through private for-profit businesses. These systems are mainly based on vouchers, but also on public procurements.



The Swedish Agency for Economic and Regional Growth noted that market reforms have gradually opened up the public sector for private businesses, paving the way for more women business owners.20 In their paper, researchers Elisabeth Sundin and Malin Tillmar suggest that restructuring the public sector reduced business ownership obstacles for women.21



The benefits of industry privatization are not limited to female business ownership. For example, the Confederation of Swedish Enterprise found that privatization drove wages up 5 percentage points compared with similar employees whose workplaces remained public.22 Individuals whose workplaces were privatized also benefited from a stronger foothold in the labor market and reduced risk of employment.23



A survey of international literature supports the theory that wages rise following privatizations, partially because of productivity gains.24 Lars Calmfors, one of Sweden’s leading economists, and Katarina Richardson, an expert on women’s career opportunities, argue that wage decentralization in the public sector led to equality gains because of individualized, higher wages for women. They conclude this is a more efficient method of reducing the gender pay gap than legislation.25



It is likely unintentional that public-sector monopolies limit women’s career opportunities, but the effect remains. Although some steps toward privatization and competition have been taken in Nordic countries, public-sector monopolies still reduce economic opportunities for women.



High tax rates are another obstacle for Nordic women’s professional advancement because women are more responsive to taxes than men. Women take more responsibility for housework and childcare, on average. When high taxes reduce incentives for paid work by reducing take-home pay, women’s “opportunity cost” is higher because they would otherwise use the time on other productive domestic activities. Women are inclined to reduce their paid work and spend more time on unpaid work as taxes increase.



Alexander Gelber and Joshua Mitchell conducted a detailed analysis of time usage for single men and women in the United States between 1975 and 2004. The authors look at how tax changes have affected the decision to spend time on housework. They find that for single women, when income taxes are reduced, productive domestic activities decline substantially as women presumably increase their paid work. Expenditure on goods and services that can substitute for housework increases with greater labor-market incentives. However, for single men the authors find limited change in response to tax policy.26 Single men continue to invest time in the labor market when taxes are high, while single women shift to household work. Single women increase their participation in the labor market and purchase goods and services such as housecleaning and prepared dinners that substitute for household work when taxes are low.



A number of studies have shown the ability to purchase services that alleviate household work is crucial for women’s career prospects.27 Henrekson and Stenkula find that the development of substitutable services is especially important for producing female executives.28 Rachel Ngai and Barbara Petrongolo find that increasing substitutable services raises women’s wages and market hours. In their abstract they write: “The rise of services, driven by structural transformation and marketization of home production, raises women’s relative wages and market hours. Quantitatively, the model accounts for an important share of the observed trends in women’s hours and relative wages.”29



Although Nordic countries have high female employment rates, many women are part-time workers and part-time housewives. This is partly because high taxes reduce incentives to work and purchase “substitutable services.” For example, highly skilled individuals such as professors often paint their own houses during the summer holidays. But a professor who sets aside an hour a day to paint her or his own house could spend the same time teaching a class. Teaching provides greater economic value because the professor is specialized in the task. It is therefore economically rational to spend the time teaching and pay for a professional painter, but high taxes change this decision.30 So Nordic professors and other workers are more inclined than their lower-taxed American counterparts to devote unpaid time to domestic work rather than work longer hours in their paid work.



High taxes significantly affect women’s careers by reducing their ability to purchase service substitutes for household work. Instead, husbands trade services with wives. Husbands spend time at work, while their wives spend time on domestic activities. High-earning women’s opportunities are limited because of gender roles and the fact that husbands are, on average, somewhat older than their wives and have higher wages.



 _The Economist_ suggests Nordic career women “find it harder to afford domestic help than their American equivalents” because public welfare services are paid for by high taxes. When time-sensitive domestic work can’t be outsourced, women do it.31 Even in the lesser-taxed United States, the combined tax effect significantly reduces incentives for individuals to buy substitutable services (Table 1).





Provision of public services encourages women to work, but high taxes discourage them from working more. International evidence supports this theory. Evridiki Tsounta concludes that women’s work was stimulated in Canada through policies that have created greater access to childcare and lower tax wedges for secondary earners.32 Michelle Rendell finds evidence that high taxes are associated with smaller service sectors and reduced female labor-force participation.33



Governments in Sweden, Finland, and Denmark realize high taxes create problems and have introduced tax deductions for personal services to counteract the problems. In 2012, 150 female executives advised the Swedish government to expand tax deductions related to the purchase of personal services and increase opportunities for flexible working time.34 These reforms have helped to improve women’s business ownership and have made it easier to combine careers with family responsibilities.



But although tax deductions for personal services have made it easier to buy some services, these targeted deductions are limited in size. Thus, high taxes still reduce the incentive for market work compared with untaxed housework, and this affects women’s professional progress.



Nordic welfare institutions influence work incentives for women in a number of ways. The Nordic welfare system has been designed to encourage parents to engage in market work while benefiting from various forms of public funding.35 But research suggests that national paid and unpaid leave policies, work entitlements, and other family benefits encourage women to work part-time rather than full-time. This hinders their ability to develop top careers.36



The European Commission’s research suggests that part-time work often accompanies public parental benefits in Sweden.37 Eva Meyersson Milgrom and Trond Petersen similarly conclude in a study that the glass ceiling “appears to be more severe in the Scandinavian countries with their generous family policies, than in the U.K., U.S., and other comparable countries.” Childcare and maternity leave policies make reducing work hours attractive, but can later disqualify women for top jobs. As a result, the policies “may not overcome the effects of domestic division of labor (and indeed may possibly exacerbate them).”38



Publicly funded programs, including childcare and parental-leave payments, reward families where both parents work at least part-time. The outcome is often that the wife works some hours, but too few to realize her marketplace potential. Her spouse often commits fully to his career. _The Economist_ , citing Danish researcher Nina Smith, suggests generous Nordic social policies are backfiring for this very reason.39



The generous family policies also affect women who decide not to take lengthy leave(s). Nordic employers have minimal or no input in this negotiation. In fact, it might be seen as discrimination if an employer asks during a job interview whether a potential employee is planning to have children in the near future. Consequently, employers may assume it is risky to hire a women of child-bearing age to a key position if the position is difficult to find a substitute for.



In some cases, parental leaves are not a major concern for employers, at least when employees are easily substitutable. But for smaller firms and vvkey roles, lengthy parental leaves ignore employers’ needs. For example, imagine a small or medium firm recruiting a person to be in charge of sales. The firm depends on the competence of this person in day-to-day operations. In practice, it may not be easy to find a substitute for this position if the employee takes leave. If a young woman applies for the job, she might be discriminated against on the grounds that she is likely to take long parental leave. This affects young women who are not planning to do so because the employer doesn’t know in advance who will or won’t take leave. If parental leave were based on agreements made between employers and employees, this would happen less often.



The parental leave system particularly  
affects those in managerial or expert positions. An employee who is easily replaced on short notice will not be affected as strongly as someone in a specialized position. It is no coincidence that women who have successful careers tend to either take short parental leaves or time their childbearing to minimize career disruption.



Because welfare programs hinder women’s professional trajectories and women take greater responsibility for family caretaking on average, Nordic countries (similar to other nations) have looked for policies that would resolve this problem.



For centuries, women in Nordic societies have progressed without relying on state-  
mandated policies. It was a break with tradition when Norway passed a gender-quota law at the end of 2003, requiring 40 percent of board members of public companies to be women.



The law became mandatory at the beginning of 2006, and the letter of the law was followed in Norway’s law-abiding society. Most companies used affirmative action to change the gender composition of their boards. Some chose another difficult but legal strategy: around 100 of approximately 500 companies targeted by the legislation changed their corporate ownership structure to free them from the legislation.40



It is telling that so many firms invested time and energy to circumvent the legislation. Once firms were forced to follow the law, another challenge became apparent: a shortage of experienced individuals to fill the positions. New female directors were eight years younger than their existing male counterparts on average, which suggests they also had less professional experience.41



The literature on corporate governance suggests that board diversity is positively related to firm performance. The explanation given is that more diversity can increase the talent pool, and diversity of origin can sometimes be linked to diversity in knowledge. Kenneth Ahern and Amy Dittmar examined the Norwegian evidence by looking at firm stock prices and Tobin’s Q, a measure of the market value of firms.42 They find that firm value fell by more than 12 percent with every 10 percent increase of female board members. The gender quota led to less experienced board members, greater company leverage, higher company acquisition rates, and declining operating performance.



Before the quotas were introduced in Norway, the rise of women among board members was achieved without declines in experience.43 Ahern and Dittmar note that once board-member characteristics—such as age and CEO experience—are accounted for, the proportion of female board members is no longer significantly related to firm market value. This suggests that it was the change in board member experience and not the gender of board members that reduced firm performance.44



Additional studies have shown that firm performance improves as gender equality grows. For example, Nina Smith, Valdemar Smith, and Mette Verner study 2,500 Danish firms from 1993 to 2001. The authors find that having a greater proportion of women in top management roles is associated with improved firm performance, even when controlling for firm characteristics.45 This effect is not because individuals are better or worse at their jobs because of their gender. Instead, some of the women who reach the top among the studied companies are particularly good at their jobs. The paper concludes that the effect of women in top management roles is related to women’s individual qualifications.46 When firm performance suffers as a result of gender quotas, gender quotas give diversity a bad name.



In spite of this, gender quotas have gained considerable international attention, and politicians around the world are pointing to the quotas as a success story.47 The rationale is that quotas were intended to increase the proportion of women on corporate boards, and have achieved that goal. But this criterion has limited usefulness.



A more holistic view suggests gender quotas have had negative effects and didn’t accomplish their goal. The purpose of quotas was to catalyze a wider change in society. Legislators hoped to break the glass ceiling so women would generally gain a professional boost. Instead, the benefit is confined to a few individuals who already had top careers. Cathrine Seierstad and Tore Opsahl write that the law has had the effect of creating “a small elite of women directors who rank among the top on a number of proxies of influence.”48 In a more recent paper, Marianne Bertrand and coauthors find that the policy has had no trickle-down effect to the broader group of female employees, no obvious effect on highly qualified women who were not appointed to boards, no significant effect on the gender pay gap, and no impact on women’s career plans.49



Norwegian researchers Sigtona Halrynjo, Mari Teigen, and Marjan Nadim analyze how women’s careers were affected by the quotas and note they had no apparent effect on the gender division of managers.50 Kjersti Misje Østbakken, Harald Dale-Olsen, and Pål Schøne investigate whether quotas have led to higher earnings for women, in accordance with the theory that quotas would break patriarchal wage-setting. The researchers do not find a visible effect.51 In mid-2015 the _Nordic Labour Journal_ published an article explaining that Norway had no female CEOs in its 60 largest firms, even though eight years had passed since the quotas were introduced.52



These studies give us insight into the quota’s effects. Women’s progress is often discussed in simplistic terms, where the share of women on company boards is seen as a goal in itself. But this is a narrow view of women’s professional success, and a more holistic view paints a different picture.



Reforms that enable women to climb the professional ladder organically or create successful firms provide a superior approach. Eliminating public-sector monopolies in service industries and reducing the tax wedge to improve incentives for work and purchasing household service substitutes would be a good start. These reforms produce new professional choices for women, and would gradually increase their representation on company boards. This is a different mechanism from legislation, which leads to a more rapid, but largely symbolic, change.



Nordic public-sector monopolies, tax policies, and welfare and family policies, along with ineffective gender quotas, combine to create the Nordic glass ceiling. The glass ceiling is a metaphor for the barriers women face in reaching leadership positions.



Nordic women might be expected to fare well in the private labor market. After all, Nordic countries have an unusually high rate of women’s labor-force participation, and generous public parental leave and daycare are intended to encourage women’s economic participation. However, when it comes to the actual share of women managers, the Nordic countries are not on top.



Some 28 percent of managers are female in Denmark, 32 percent in Finland, 32 percent in Norway, and 36 percent in Sweden (Table 2).





Iceland in particular stands out among the Nordic states, since it has a smaller welfare state than its larger Nordic cousins and also ranks among the highest share of female managers in the world. On the other hand, Denmark has the highest tax rate among all the nations in the Organisation for Economic Co-operation and Development and ranks at the bottom in terms of its proportion of female managers.



In the dataset for developed economies, there are three countries with equal or higher rates of female managers than Iceland: New Zealand, the United States, and Latvia.55 These countries have relatively low tax rates: 26.4 percent in the United States, 29.0 percent in Latvia, and 32.8 percent in New Zealand.56



Of course, government size is just one factor influencing women’s careers. Nevertheless, the relationship between government size and the proportion of female managers is interesting to note.



Another metric that can be used to measure female professional attainment is _The Economist_ ’s glass-ceiling index. The index compares opportunities for women in various countries. Table 3 compares the Nordic countries with the United States along several metrics.





The Nordic countries do well on some of the index’s metrics. They consistently outperform the United States on issues such as the gender gap in higher education and women’s labor-force participation. Direct childcare expenditure is relatively low in the Nordics because much of it is tax-funded. The Nordics also have generous public paid-leave programs.



The United States has a larger gender gap in labor-force participation, a smaller advantage for women in tertiary education attainment, higher private childcare costs, and no public paid leave. As a result, it might seem the United States has woman-unfriendly policies and the Nordics have woman-friendly policies. However, the United States has the highest rate of female managers among all countries in the Index. The Nordic countries have a lower share.57 _The Economist_ has written about this pattern and suggests professional gender segregation by role is high in the Nordics.58



One place that Nordic women break the glass ceiling is in the political arena. The feminist movement was successful in pushing for women’s political representation. Women have played a key role in Nordic politics historically, both on the political left and the right.59 The proportion of women in parliament ranges from 37 percent in Denmark to 44 percent in Sweden. This is higher than the United States, where 19 percent of those elected to the U.S. House of Representatives and 20 percent of those elected to the U.S. Senate are women.60 This success may be admired in isolation.



However, when compared with trends in the broader private economy, it only calls further attention to the Nordic Gender Equality Paradox: if Nordic policies are the best at supporting women’s climb to the top, then women should be successful in roles throughout the economy. Unfortunately, Nordic societies with large welfare states have surprisingly few women in managerial positions in the private sector.



The Nordic countries are in many ways the most gender-equal in the world, owing to their history, culture, and some beneficial policies. Therefore, foreign observers assume replicating Nordic policies is the key to women’s progress, even when facts and research tell us the opposite.



Welfare policies, high taxes that make it costly to purchase substitutable services, generous benefit systems that reduce economic incentives for full-time work, public-sector monopolies/oligopolies in female-dominated sectors, and paid-leave policies that incentivize long breaks from working life prevent women from reaching the top. Taken together, these policies create a Nordic glass ceiling. Gender quotas are unable to make up the difference, even though politicians routinely point to gender quotas as a policy success story. In reality they fall short of their objectives.



It is true that Nordic countries have high female employment rates and an unusually gender-equal history and gender-equal values, and these achievements merit admiration. Still, the proportion of women managers, executives, and business owners is disappointingly low. Several other countries that lack the advantages of the Nordics, but have more small-government and market-oriented policies, have a larger proportion of women who reach the top. This is true of the United States. The Nordic Gender Equality Paradox is important to keep in mind in countries such as the United States, where Nordic-style welfare policies are routinely touted as a way of promoting gender equality without tradeoffs.61



The pattern within the Nordics is also worth keeping in mind. More women reach executive positions in Iceland, the Nordic country with a smaller welfare state, than in Denmark, the Nordic country with an unusually large welfare state. This pattern, together with various studies cited in this report, suggest that key aspects of social welfare policy hold professional women back.62



1. Saadia Zahidi, senior director and head of gender parity and human capital at the World Economic Forum, has stated that the Nordic countries “have made it possible for parents to combine work and family,” which results in better female labor-force participation, more egalitarian sharing of domestic work, and improved work-life balance. Saadia Zahidi, “What Makes the Nordic Countries Gender Equality Winners?” _Huffington Post_ , October 24, 2013, https://www.huffingtonpost.com/saadia-zahidi/what-makes-the-nordic-cou_b_4159555.html.



Katrin Bennhold at the _New York Times_ argues that Sweden’s feminist model is beneficial both to men and women in tearing down traditional gender roles. Like other international proponents of Nordic gender equality, Bennhold admires the “social engineering” that has made “a new definition of masculinity” possible. Likewise, Bennhold writes enthusiastically about laws that have “set off profound social change.” Katrin Bennhold, “In Sweden, Men Can Have It All,” _New York Times_ , June 9, 2010, http://www.nytimes.com/2010/06/10/world/europe/10iht-sweden.html.



In the left-wing American journal _The Nation_ , Ann Jones states that equality between genders is “the heart of Scandinavian democracy.” Jones argues that the United States should follow in the footsteps of Norway, where “feminists and sociologists pushed hard against . . . the nuclear family.” In particular, Jones admires the policy in which an expanded role for the state has undermined the family institution. Ann Jones, “After I Lived in Norway, America Felt Backward. Here’s Why,” _The Nation_ , January 28, 2016, https://www.thenation.com/article/after-i-lived-in-norway-america-felt-backward-heres-why/.



Norwegian political scientist Helga Maria Hernes introduced this narrative in 1987, and the narrative has significantly influenced policy research. Anette Borchorst and Birte Siim, “The Women-Friendly Welfare States Revisited,” _NORA—Nordic Journal of Feminist and Gender Research_ 10, no. 2 (2002): 90–98.



Eva-Maria Svensson and Åsa Gunnarsson write in an article published in a feminist law journal that “a prominent characteristic of the Swedish model is . . . that gender equality policy is closely intertwined with the Swedish welfare state ideology.” Eva-Maria Svensson and Asa Gunnarsson, “Gender Equality in the Swedish Welfare State,” _Feminists@law_ 2, no. 12 (July 23, 2012): 1–27.



2. During the 10th century Battle of Dorostolon, the Kievian Rus forces—who were essentially Swedish Vikings with a strong presence in today’s Russia—invaded present-day Bulgaria. A counteroffensive by the Byzantine Empire dealt a devastating defeat to the Vikings. The Byzantine were stunned at discovering armed women among their fallen enemies. Dick Harrison and Kristina Svensson, _Vikingaliv_ (Värnamo: Fälth & Hässler, 2007).



3. Marianne Moen, “The Gendered Landscape—A Discussion on Gender, Status and Power Expressed in the Viking Age Mortuary Landscape,” Department of Archaeology, Conservation and History (IAKH) Faculty of Humanities, University of Oslo, 2010.



4. Anders Johnson, “Kvinnliga handlare trots förbud,” _Handelns Historia_ , October 5, 2011, www.handelnshistoria.se/historien/handelns-lagstiftning/kvinnliga-handlare-trots-forbud/.



5. Sweden included Finland from the 13th to the beginning of the 19th century, and was in union with Norway between the beginning of the 19th and the end of the 20th century. Thus, during this period, Sweden’s history is key to understanding the development in the region as a whole. The country also has the largest population in the Nordics.



6. Christine Bladh, “Kvinna med eget företag—från 1700-talets mitt till 1800-talets slut,” p. 127-142 in “Mot halva makten – elva historiska essäer om kvinnors strategier och mäns motstånd”, ed. Ingrid Hagman (Stockholm: Arbetsmarknadsdepartementet, 1997). This report was, in turn, part of a government inquiry regarding the economic resources and influence of men and women in Sweden, entitled “Utredningen om fördelningen av ekonomisk makt och ekonomiska resurser mellan kvinnor och män Stockholm 1997.”



7. Suzanne McGee and Heidi Moore, “Women’s Rights and Their Money: a Timeline from Cleopatra to Lilly Ledbetter,” _Guardian_ , August 11, 2014, https://www.theguardian.com/money/us-money-blog/2014/aug/11/women-rights-money-timeline-history.



8. Ibid.



9. Kari Melby, Anna-Birte Ravn, and Christina Carlsson Wetterberg, _Gender Equality and Welfare Politics in Scandinavia_ (Bristol, UK: The Policy Press, University of Bristol, 2009).



10. Ibid.



11. Source: “World Values Survey, Wave 3 (1995–1999),” World Value Survey Association, http://www.worldvaluessurvey.org/WVSDocumentationWV3.jsp; and “World Values Survey, Wave 6 (2010–2014),” World Value Survey Association, http://www.worldvaluessurvey.org/WVSDocumentationWV6.jsp. Data files are aggregated by Asep/JDS, Madrid, Spain.



12. “Global Report: Attitudes to Gender,” _YouGov_ , November 12, 2015, https://yougov.co.uk/news/2015/11/12/global-gender-equality-report/.



13. “The European Structure of Earnings Survey,” _Eurostat_ , 1995, http://ec.europa.eu/eurostat/web/microdata/structure-of-earnings-survey.



14. Torben Iversen, Frances Rosenbluth, and David Soskice, “Women and the Service Sector,” University of California–Los Angeles (UCLA) Postindustrial Working Group, April 18, 2004.



15. The report concluded that “studies comment on how Nordic countries, and in particular Sweden, have among the greatest inequalities.” See Richard Anker, “Gender and Jobs: Sex Segregation of Occupations in the World,” International Labour Office, 1998.



16. Magnus Henrekson and Mikael Stenkula, “Why Are There So Few Female Top Executives in Egalitarian Welfare States?,” IFN Working Paper no. 786, February 9, 2009, http://www.ifn.se/wfiles/wp/wp786.pdf.



17. Matti Alestalo, Sven E. O. Hort, and Stein Kuhnle, “The Nordic Model: Conditions, Origins, Outcomes, Lessons,” Hertie School of Governance Working Papers no. 41, June 2009, http://edoc.vifapol.de/opus/volltexte/2013/4255/pdf/41.pdf.



18. “Women Entrepreneurship—A Nordic Perspective,” Nordic Innovation Centre, August 2007, http://nordicinnovation.org/Global/_Publications/Reports/2007/women_entrepreneurship_final_report_web.pdf.



19. Anita Lignell Du Rietz, Svenskornas företagsamma historia (Stockholm: Timbro, 2009).



20. “Många miljarer blir det. . . Fakta och nyckeltal om kvinnors företag,” Swedish Agency for Economic and Regional Growth, 2010. Translated into English by Nima Sanandaji.



21. Elisabeth Sundin and Malin Tillmar, “Kvinnors företagande i spåren av offentlig sektors omvandling,” in Forskning om kvinnors företagande, presentation av projekten (Stockholm: Vinnova, 2008). Translated into English by Nima Sanandaji.



22. Increased competition from private firms also pushes up the wages in the public sector, as previous public-sector monopolies had to begin competing for talent retention. Since the study does not take this into account, it likely underestimates how important privatization can be for wage increases.



23. Johan Kreicbergs and Carl Oreland, _Nyföretagande inom den offentliga sektorn—ett lyft för kvinnor_ (Stockholm: Svenskt Näringsliv, 2009).



24. Andrew Pendleton, “What Impact Has Privatization Had on Pay and Employment? A Review of the UK Experience,” _Industrial Relations_ 52, no. 3 (1997): 554–82.



25. Lars Calmfors and Katarina Richardson, “Marknadskrafterna och lönebildningen i landsting och regioner,” Institute for Evaluation of Labour Market and Education Policy, Uppsala, Sweden, 2004, http://www.ifau.se/globalassets/pdf/se/2004/r04-09.pdf.



26. Alexander Gelber and Joshua Mitchell, “Taxes and Time Allocation: Evidence from Single Women and Men,” _Review of Economic Studies_ 79, no. 3 (November 2011): 863–97.



27. See, for example, Patricia Cortes and Jessica Pan, “Outsourcing Household Production: Foreign Domestic Workers and Native Labor Supply in Hong Kong,” _Journal of Labor Economics 31, no. 2 (April 2013): 327–71; and Jan Kabatek, Arthur Van Soest, and Elena Stancanelli, “Income Taxation, Labour Supply and Housework: a Discrete Choice Model for French Couples,” _Labour Economics_ 27 (April 2014): 30–43._



28. Henrekson and Stenkula, “Why Are There So Few Female Top Executives in Egalitarian Welfare States?”



29. L. Rachel Ngai and Barbara Petrongolo “Gender Gaps and the Rise of the Service Economy,” _American Economic Journal: Macroeconomics_ 9, no. 4 (2017): 1–44.



30. The professor pays taxes on income, including indirect employer’s fees and direct taxes on work. Afterwards, consumption taxes are paid on the service purchased. Finally, the painter pays direct and indirect taxes on the income received. This adds up to a high total tax burden. The tax wedge ranges from 34.0 percent in Iceland to 43.8 in Finland (Table 1). This captures both indirect and direct taxes on labor for an average worker. Thus, if the first individual works an additional hour in Finland to create an economic value of 100 euros, 56.2 euros will be rewarded to the individual while 43.8 euros will go to the government. When the same individual purchases a service from a second individual, a VAT of 24 percent is charged on top of that, leaving 42.7 euros. The second individual is also affected by indirect and direct taxes on labor, leaving 24.0 euros in her or his pocket at the end of the transaction. In Iceland, the Nordic country with the lowest tax rate, a third of the original value created is left after taxes. This is equivalent to a situation where the individual simply performs the service him or herself, paying no taxes at all. It is rational for Nordic professors to paint their own houses under this system, even if their time would create three times more value if they worked in their specialty.



31. Schumpeter, “A Nordic Mystery,” _The Economist_., November 15, 2014, https://www.economist.com/news/business/21632512-worlds-most-female-friendly-workplaces-executive-suites-are-still-male-dominated.



32. Evridiki Tsounta, “Why Are Women Working So Much More in Canada? An International Perspective,” International Monetary Fund Working Paper 06/92, April 2006, https://www.imf.org/external/pubs/ft/wp/2006/wp0692.pdf.



33. According to Rendell, Nordic countries balance the effects by providing public-sector benefits including subsidized full-day childcare. Michelle Rendell, “Rise of the Service Sector and Female Market Work: Europe vs US,” University of Zurich Working Paper Series no. 23, February 2014, http://www.econ.uzh.ch/ipcdp/Papers/ipcdp_wp312.pdf.



34. “Rut och flex vägen för kvinnors framgång,” _Ny Teknik_ (Stockholm), February 10, 2012.



35. Child support is provided to all families, regardless of income.



36. Catherine Hakim, _Work-Lifestyle Choices in the 21st Century_ (New York: Oxford University Press, 2000).



37. “The current situation of gender equality in Sweden—Country Profile,” European Commission, 2013.



38. E. M. Milgrom and T. Petersen, “The Glass Ceiling in the US and Sweden: Lessons from the Family-Friendly Corner of the World, 1970–1990,” in _The Declining Significance of Gender?_ , ed. F. D. Blau, M. C. Brinton, and D. Grusky (New York: Russell Sage Foundation, 2008), pp. 2, 39.



39. Schumpeter, “A Nordic Mystery.”



40. Kimberly Weisul, “Women on Boards: Are Quotas Really the Answer?” _Fortune_ , December 5, 2014, http://fortune.com/2014/12/05/women-on-boards-quotas/.



41. “The CS Gender 3000: Women in Senior Management,” Credit Suisse Research Institute, 2014, https://glg.it/assets/docs/csri-gender-3000.pdf.



42. To be more precise, the Tobin’s Q, which was introduced in 1968 by James Tobin and William Brainard, is the ratio between a physical asset’s market value and its replacement value.



43. Johanne Grosvold, Stephen Brammer, and Bruce Rayton, “Board Diversity in the United Kingdom and Norway: An Exploratory Analysis,” _Business Ethics: A European Review_ 16, no. 4 (2007): 344–57.



44. Kenneth Ahern and Amy Dittmar, “The Changing of the Boards: The Impact on Firm Valuation of Mandated Female Board Representation,” _Quarterly Journal of Economics_ 127, no. 1 (February 1, 2012): 137–97.



45. Nina Smith, “Gender Quotas on Boards of Directors,” _IZA World of Labor_ , 2014. https://wol.iza.org/articles/gender-quotas-on-boards-of-directors/.



46. Nina Smith, Valdemar Smith, and Mette Verner, “Do Women in Top Management Affect Firm Performance? A Panel Study of 2,500 Danish Firms,” _International Journal of Productivity and Performance Management_ 55, no. 7 (August 2006): 569–93.



47. Norway’s gender-quota policy has received attention in the United States, as well. Aaron Dhir, professor of law at Yale Law School, argues that “while quotas might not be palatable in the United States, it is clear that a more forceful regulatory shove is needed to disrupt the status quo.” He suggests that law is a “powerful tool” and we shouldn’t be afraid to use it to shape culture or address biases. Aaron A. Dhir, “What Norway Can Teach the U.S. about Getting More Women into Boardrooms,” _The Atlantic_ , May 4, 2015, https://www.theatlantic.com/business/archive/2015/05/what-norway-can-teach-the-us-about-getting-more-women-into-boardrooms/392195/.



48. Cathrine Seierstad and Tore Opsahl, “For the Few Not the Many? The Effects of Affirmative Action on Presence, Prominence, and Social Capital of Women Directors in Norway,” _Scandinavian Journal of Management_ 27, no. 1 (2011): 44–54.



49. Marianne Bertrand, Sandra E. Black, Sissel Jensen, and Adriana Lleras-Muney, “Breaking the Glass Ceiling? The Effect of Board Quotas on Female Labor Market Outcomes in Norway,” National Bureau of Economic Research, Working Paper no. w20256, July 2017, http://www.nber.org/papers/w20256.



50. Sigtona Halrynjo, Mari Teigen, and Marjan Nadim, “Kvinner og menn i toppledelsen: Ringvirkningar av lovkrav om kjønnsbalanse i bedriftsstyrer?” in _Virkninger av kjønnskvotering i norsk næringsliv_ (Oslo, Gyldendal Akademisk, 2015), pp. 18–22. Translated into English by Nima Sanandaji.



51. Kjersti Misje Østbakken, Harald Dale-Olsen, and Pal Schøne, “Kjønnsbalanse i styrer og kvinners karriere,” in _Virkninger av kjønnskvotering i norsk næringsliv_ (Oslo: Gyldendal Akademisk, 2015), pp. 31–33. Translated into English by Nima Sanandaji.



52. Björn Lindahl, “Norway’s Female Boardroom Quotas: What Has Been the Effect?” _Nordic Labour Journal_ , May 21, 2015, http://www.nordiclabourjournal.org/artikler/forskning/research-2015/article.2015-05-20.3011019632.



53. “Women in Business and Management Gaining Momentum,” International Labour Organization, 2015.



54. As measured by taxes as share of GDP. Ranking of Nordic countries by government size is as follows: Denmark has the highest tax rate as a share of GDP among the Nordic countries and the industrial world. According to OECD data, the tax rate of Denmark was 46.6 percent of GDP in 2015. Finland is second, at 44.0 percent of GDP, and Sweden follows at 43.3 percent. In Norway, public expenditure is partly funded through oil revenues, and the tax rate is lower, at 38.1 percent. Iceland has the lowest tax rate, at 37.1 percent.



55. “Women in Business and Management Gaining Momentum,” International Labour Organization, 2015.



56. “Revenue Statistics—OECD Countries: Comparative Tables,” _OECD Stat Extract_. https://stats.oecd.org/Index.aspx?DataSetCode=REV. Latest available data for 2015.



57. “Glass Ceiling Index,” _The Economist_ , http://infographics.economist.com/2017/glass-ceiling/.



58. Ibid.



59. A. Johnson, _De gjorde skillnad: liberala kvinnor från Anna Maria Lenngren till Marit Paulsen_ (Stockholm: Folkpartiet Liberalerna, 2009).



60. “Women in National Parliaments,” Inter-Parliamentary Union, 2016, http://archive.ipu.org/wmn-e/arc/classif011216.htm.



61. The social democratic Swedish government that took office in 2014 describes itself as “the first feminist government in the world.” The BBC published a story entitled “Is Sweden’s Feminist Agenda Working?,” and reported that “things are getting better for women” but did not state any factual support for this conclusion. “Is Sweden’s Feminist Agenda Working?,” BBC, February 17, 2017, http://www.bbc.com/news/world-europe-39004991.



An opinion column by Gabrielle Jackson argues that the Swedish welfare-state model of providing generous paternity leave is a model that should be adopted in other parts of the world. Gabrielle Jackson, “Force Men to Take Paternity Leave. It Will Make the World a Better Place,” _Guardian_ , April 9, 2015, https://www.theguardian.com/commentisfree/2015/apr/10/want-better-dads-happier-mums-and-healthier-kids-make-men-take-paternity-leave.



In March 2017, the Nordic Council of Ministers and New America think tank cohosted a public event in New York on how the United States could be inspired from Nordic countries in expanding the public parental leave system. Anne-Marie Slaughter, the president of New America, explained before the event that the Nordic countries have outpaced the United States “in terms of valuing families and shifting gender roles” and said that “Americans should learn from them.” “US Think Tank to Showcase Nordic Gender Equality,” _Norden_ , March 9, 2017, http://www.norden.org/en/news-and-events/news/us-think-tank-to-showcase-nordic-gender-equality.



62. For more information, see Nima Sanandaji, _Jämställdhet inom räckhåll_ (Stockholm: Captus, 2009); Nima Sanandaji, _Att Spräcka Glastaken_ (Stockholm: Captus, 2013); and Nima Sanandaji, _The Nordic Gender Equality Paradox_ (Stockholm: Timbro, 2016).
"
"

 _Global Science Report is a weekly feature from the Center for the Study of Science, where we highlight one or two important new items in the scientific literature or the popular media. For broader and more technical perspectives, consult our monthly “Current Wisdom.”_   
  
  
There seems to be a noticeable murmur around town about a carbon tax—a tax on the amount of carbon dioxide that is released upon generating a unit of energy. Since fossil fuels—coal, oil, natural gas—are both the source of over 75% of our energy production and emitters of carbon dioxide when producing that energy, a carbon tax insures that the price of everything goes up.   
  
  
There is one and only one justification for a carbon tax—an attempt to influence the future course of the earth’s climate (or, as some people prefer, to mitigate anthropogenic climate change) by trying to force down the emissions of the most abundant human‐​generated greenhouse gas.   
  
  
But of all the things that a carbon tax will do (raise prices, increase bureaucracy, elect Tea Partiers, etc), mitigating anthropogenic climate change in any meaningful manner is not one of them.   
  
  
The annual carbon dioxide emissions from the U.S., currently about 5,500 million metric tons per year, only contributes roughly 0.003°C/per year of warming pressure on global temperatures (see here for a handy way of making that calculation). So the best that a carbon tax could ever hope to achieve, climatically, would be to prevent this amount of warming each year by completely eliminating all carbon dioxide emissions from the U.S.   
  
  
If we went to zero emissions tomorrow, the carbon tax would prevent about 0.26°C of global temperature rise by the year 2100. According to the latest projections from the Intergovernmental Panel on Climate Change (IPCC), the projected temperature rise by the end of the century ranges from about 1.1 to 6.4°C, with a business‐​as‐​usual rise of around 3°C (put me down for 1.6° until then, unless nature is being a blatant liar). The “mitigated” rise is proportional to the expected temperature rise. A carbon tax enacted today that is immediately and completely successful at eliminating all U.S. CO2 emission would lower rise in temperature expected by the end of the century around 10%. This amount is small, of little consequence, and in fact will be difficult to detect.   
  
  
It is also not going to happen. We only have the capacity to produce about 30% of our electricity from non‐​carbon emitting fuel sources (primarily nuclear and hydroelectric). So it will take time, and probably a lot of time (many decades) before our energy needs could possibly be met without emitting CO2 into the atmosphere. And of course, as time ticks by before eliminating or at least appreciably reducing our emissions, the amount of global warming saved by such action declines (and become less and less consequential), as does the justification for the carbon tax.   
  
  
I am just in the early stage of this analysis, so the numbers above are a bit rough (but conservative). In the future I hope to produce a menu of emissions reductions/​climate savings options—but one without prices. That way the policymakers will see what they are going to be getting for whatever price they decide to assign. So too will the general public. And what they will all see is that whatever level of carbon tax they decide upon, they will get a lot of climate nothing for a lot of financial something.   
  
  
The best thing would be for policymakers to just leave well enough alone, for on their own, carbon dioxide emissions in the U.S. have been declining for more than a decade (and in fact are pushing levels of the early 1990s, http://​www​.eia​.gov/​e​n​v​i​r​o​n​m​e​n​t​/​e​m​i​s​s​i​o​n​s​/​c​a​rbon/). And even if such a reduction doesn’t result in any scientifically detectable climate impacts, at least it hasn’t cost us anything.
"
"
Share this...FacebookTwitterThe millions of Germans who read my blog 🙂 may wish to pick up FOCUS magazine tomorrow at the newsstands.Tomorrow’s edition features Professor Dr Fritz Vahrenholt, author, along with Sebastian Lüning, of the upcoming climate catastrophe skeptic book, Die kalte Sonne. It’s the book that warmists fear, and that open minds will surely absorb. Focus report on page 66.
Skepticism of the alarmist junk climate science is spreading in Germany.
The FOCUS report will also feature Freeman Dyson.
Michael Miersch writes of the FOCUS article:
A Bishop Leaves the Church
Fritz Vahrenholt wrote one of the standard books for the environmental protection movement, was the most well-known green-type social democrat, and today leads a company that is investing billions in renewable energy. But now not even he believes any longer in the forecasts of the IPCC and the Potsdam Institute concerning climate warming. More on that in tomorrow’s FOCUS (only in the print edition, not online). Also there is an interview with physicist and mathematician Freeman Dyson, who feels global cooling is far more problematic than a warming.”
German readers, please pick up a copy and tell us what you think.
Photo source: Die kalte Sonne website.
Share this...FacebookTwitter "
"In every part of our daily routines technology makes its presence felt. Now, forward-thinking Finland plans to change the way Europe goes about urban travel using a novel system, based on a smartphone app, to help people get the most out of public transport. It might even herald the end of the dominance of the private car. The driving force behind this move is that the younger generation want practical travel options. With incomes falling and motoring costs soaring, cars are increasingly seen as an unwelcome burden rather than the liberating symbol of personal freedom they once were. A recent report shows Generation Y (18 to 29-year-olds) hold different attitudes to cars than their predecessors. For Generation Y, being debt-free is suddenly sexy, while less than one in five consider car ownership a reflection of personal success. This is reflected by the lower car ownership levels among Generation Y (68%), compared to the previous Generation X (81%). While cars have been elevated to status symbols representing something aspirational, public transport, walking, and cycling only account for a small amount of total travel, and are often perceived as the fallback option for those with no other choice. The social, economic and cultural power attributed to private automobiles has meant that modern cities prioritise the car. The automobile industry sets new records each year, selling 69m cars in 2013 as emerging markets follow in the footsteps of Western Europe and North America.  In social and environmental terms, this is incredibly destructive. Car culture has contributed to a rise in individualism that cuts off social interactions and damages community relations. Neighbours simply pass by one another in their separate metal boxes.  Astoundingly, a quarter of all energy-related carbon dioxide emissions originate from road transportation, with passenger vehicles the main culprit. It is no small matter that this equates to a fifth of global oil usage. The Finnish capital has announced plans to transform its existing public transport network into a comprehensive, point-to-point mobility on-demand system within the next ten years. City-wide, this would link together taxis, shared cars, ferries, trains, shared bikes, driverless cars, buses, trams and, also, the Kutsuplus – the minibus rolled out last year that lets riders specify where they want to be picked up and put down via smartphone. In theory the Finnish set up would render car ownership essentially pointless in the city.  The Planning Department-approved plans come from an engineering student, Sonja Heikkilä, who believes young Helsinki residents view transportation differently from their parents. They want simple, flexible and inexpensive transportation so she has suggested a mobility model based on how services are provided in the telecommunications industry (in which Finland was also a trailblazer). Like internet service providers or mobile phone companies, residents might get around by paying by the kilometre, or by purchasing a monthly package with kilometres included. This integrated approach goes beyond traditional public transport systems, with transport procured in real time through a single app, providing residents with a range of options available at the touch of a screen. Users simply specify an start and a destination, and the software then acts as a journey planner to both identify and book the most efficient means of completing the journey.  This approach allows users to tailor their journeys from point to point, offering all the convenience of owning a car without much of the cost. As other economies still suffer fallout from the global economic crisis, the Nordic model of capitalism is gaining increasing attention. The Scandinavian approach entails a pragmatic judgement on public services: as long as they work, it does not matter who provides them. The city’s transportation will continue to be run as a public utility but will include competition to ensure the services that most benefit residents win out as commuters vote with their feet. This is Nordic capitalism in action: public authorities facilitating capitalist innovation to improve the overall standard of living, state-private partnerships that promote the comfortable life in Helsinki. But the impact of this plan could be felt beyond Northern Europe. It’s clear that, in the name of sustainable mobility, radical measures in urban planning need be undertaken. The electric car is currently the most popular alternative to petrol and diesel engines. However, by replacing cars with more cars we are not solving the problem. The electric car competes with public transport, walking and cycling. It displaces sustainable transport options in urban areas and requires precious raw materials to build. Add to this the fact that they are generally powered by electricity from fossil fuel-burning power stations and we are faced with the truth that realistically, the problem can only be remedied through changing our relationship with cars, not just changing the car with which we have a relationship."
"**The four UK governments have announced their plans to enable families to celebrate Christmas together.**
So how is the festive period likely to be different this year?
The governments of England, Scotland, Wales and Northern Ireland have agreed a common approach allowing up to three households to form a Christmas bubble and meet up from 23 to 27 December (22 to 28 December in Northern Ireland).
People can mix in homes, places of worship and outdoor spaces, and travel restrictions will also be eased.
However, a Christmas bubble must be exclusive, so people cannot swap between them. Bubble members also will not be able to visit pubs or restaurants together.
There will be no limit to the number of people in a household joining a bubble in England, Wales and Northern Ireland.
But the Scottish government has said that Christmas bubbles should contain no more than eight people. Children under 12 will not count in the total.
Fears that a lack of skilled overseas workers on poultry farms could hit the supply of turkeys have been overcome after travel rules were relaxed so they could travel to the UK.
But many people are buying smaller turkeys than usual because they are likely to have fewer guests.
An Aberdeenshire farmer has warned many birds could go to waste, while a farm in Wales cut its turkey numbers by 20% in September.
Any turkey shortage may make some people consider a vegetarian or vegan meal instead.
This year's work celebrations seem certain to take place on Zoom and other online platforms.
Rules on big groups meeting up in pubs or anywhere outdoors are very unlikely to be eased in December, so seeing friends for a pre-Christmas drink or meal will probably not be allowed.
Current rules for socialising outside your household/support bubble/extended household are:
At the moment, it is not known what will happen about traditional Christmas religious services like midnight Mass.
From 2 December in **England,** places of worship will reopen for communal prayer.
Up to 50 people can attend indoor services in **Scotland** in levels zero to three areas, but only up to 20 in level four places.
Places of worship have reopened in **Wales,** but with social distancing in place and communal singing banned.
They are also open in **Northern Ireland with**no limit on numbers if safety measures are in place. Weddings, civil ceremonies and funerals can happen, but only 25 people. can attend
While in-person shopping in non-food shops can currently happen in all of the UK except England, online retailers are expecting a big surge in demand this year.
In September, shoppers were warned by an industry boss to buy as early as possible.
Andy Mulcahy, from the online businesses' industry body, told the BBC: ""At this point, I think we can expect an increase of at least 30% for the peak festive trading season, but if stores have to close this might push to 50%.""
In **England,**non-essential shops will reopen on 2 December. They are currently open in all of **Scotland**except level four areas, across Wales, and in Northern Ireland.
Last posting dates inside the UK range from 18 to 23 December, while we have already passed some international dates.
Theatres in **England** can reopen on 2 December, and plans have been made for some Christmas pantomimes.
While many venues and production companies have cancelled their shows, others are going ahead thanks to National Lottery backing.
One is at the London Palladium, where the Lottery will buy seats that cannot be used because of social distancing. It will also donate 20,000 free tickets to Lottery players.
Meanwhile a drive-in show - the Car Park Panto - will tour Great Britain with audience members watching from inside their cars.
Theatres in **Scotland** are closed in level two, three and four areas, throughout Wales, and to audiences in **Northern Ireland,** where they can open for rehearsals or a live recording.
The Christmas relaxation of meeting up rules does not extend to New Year's Eve, so that is likely to be a quiet affair this year, with house parties banned in most places.
Fireworks have been cancelled in London and Edinburgh's Hogmanay street party is off."
"
Guest post by Bob Tisdale
There are numerous blog posts and discussions about how the GISS global  temperature anomaly product GISTEMP differs from the Hadley Centre and  NCDC datasets.
The repeated reasons presented for this are, GISS uses  1200km radius smoothing to fill in the areas of the globe with sparse  surface temperature readings, and the area this has the greatest impact  is the Arctic. Typically, a map or comparison of global temperature  anomaly maps is included, similar to Figure 1. The top two maps were  cropped from Figure 3 in the Real  Climate post “2009  temperatures by Jim Hansen”. I added the third.
The bottom map was  created at the GISS Global  Maps webpage. It’s a map of the GISTEMP Global Temperature Anomaly  product with 250km radius smoothing for the calendar year 2005, the same  year as the top two maps. I did not include a temperature scale because  the bottom map was provided to allow a visual comparison of the spatial  coverage of the HadCRUT product and the GISTEMP product with 250km  radius smoothing. Examine the Arctic and the ocean surrounding  Antarctica, the Southern Ocean. Notice a difference? In 2005, the  HadCRUT data had better coverage of the Arctic and Southern Oceans than  the GISTEMP dataset with 250km radius smoothing. What’s missing in the  GISTEMP product? There’s no sea surface temperature data.
 http://i45.tinypic.com/htsgeq.jpg
Figure  1
GISS DELETES POLAR SEA SURFACE TEMPERATURE DATA
The  general regions where GISS deletes Sea Surface Temperature data are  shown in Figure 2. Three areas are highlighted: two cover the Arctic  Ocean, and a third surrounds Antarctica. The specific locations are  clarified in the following. GISS then uses their 1200km radius smoothing  to replace the sea surface data with land data.
 http://i48.tinypic.com/33adj86.jpg
Figure  2
Tilo Reber in his recent “Diverging  views” post at Watts Up With That? noted that  the GISS Current  Analysis webpage includes the following statement:
“Areas  covered occasionally by sea ice are masked using a time-independent  mask.”
This means that vast regions of Sea Surface  Temperature (SST) anomaly data in the Arctic Ocean and Southern Ocean  are deleted from the GISTEMP record. GISS does not delete all of the  Arctic and Southern Ocean SST anomaly data, just the data from the areas  where the annual sea ice melt occurs, and those are good portions of  them.
I have looked for but have not found an explanation for  this exclusion of Sea Surface Temperature data in the papers provided on  the GISTEMP  references page.
THE AREA OF THE ARCTIC OCEAN WHERE  GISS DELETES SST DATA

Figure 3 shows four Arctic (North  Pole Stereographic, 65N-90N) maps prepared using the map-making feature  of the KNMI Climate Explorer. The maps illustrate temperature anomalies  and sea ice cover for the month of September, 2005. The calendar year  2005 was chosen because it was used in the RealClimate post by Jim  Hansen, and September is shown because the minimum Arctic sea ice  coverage occurs then. The contour levels on the temperature maps were  established to reveal the Sea Surface Temperature anomalies. Cell (a)  shows the Sea Ice Cover using the Reynolds (OI.v2) Sea Ice Concentration  data.
The data for the Sea Ice Cover map has been scaled so that zero  sea ice is represented by grey. In the other cells, areas with no data  are represented by white. Cell (b) illustrates the SST anomalies  presented by the Reynolds (OI.v2) Sea Surface Temperature anomaly data.  GISS has used the Reynolds (OI.v2) SST data since December 1981. It’s  easy to see that SST anomaly data covers the vast majority of Arctic  Ocean basin, wherever the drop in sea ice permits. Most of the data in  these areas, however, are excluded by GISS in its GISTEMP product. This  can be seen in Cell (c), which shows the GISTEMP surface temperature  anomalies with 250km radius smoothing. The only SST anomaly data used by  GISS exists north of the North Atlantic and north of Scandinavia.
The  rest of the SST data has been deleted.
The colored cells that appear  over oceans (for example, north of Siberia and west of northwestern  Greenland) in Cell (c) are land surface data extending over the Arctic  Ocean by the GISS 250km radius smoothing. And provided as a reference,  Cell (d) presents the GISTEMP “combined” land plus sea surface  temperature anomalies with 1200km radius smoothing, which is the  standard global temperature anomaly product from GISS. Much of the  Arctic Ocean in Cell (d) is colored red, indicating temperature  anomalies greater than 1 deg C, while Cell (b) show considerably less  area with elevated Sea Surface Temperature anomalies.
 http://i46.tinypic.com/dpygcj.jpg
Figure  3
Basically, GISS excludes Arctic Ocean SST data from 65N to 90N  and, for round numbers, from 40E to 40W. This is a good portion of the  Arctic Ocean. Of course, the impact would be seasonal and would depend  on the seasonal drop in sea ice extent or cover. The sea ice extent or  cover has to decrease annually in order for sea surface temperature to  be measured.
I’ll use the above-listed coordinates for the examples that  follow, but keep in mind that they do not include areas of sea ice in  the Northern Hemisphere south of 65N where sea surface temperature data  are also deleted by GISS. These additional areas are highlighted in  Figure 4. They include the Bering Sea, Hudson Bay, Baffin Bay and the  Davis Strait between Greenland and Canada, and the Sea of Okhotsk to the  southwest of the Kamchatka Peninsula.
http://i50.tinypic.com/28j9u6u.jpg
Figure  4
Note: GISS uses Hadley Centre HADISST data as its source of  Sea Surface Temperature (SST) data from January 1880 to November 1981  and NCDC Reynolds (OI.v2) data from December 1981 to present. To  eliminate the need to switch between or merge SST datasets, this post  only examines the period from 1982 to present. And to assure the  graphics presented in Figures 3 and 6 are not biased by differences in  base years of the GISTEMP data and the Reynolds (OI.v2) SST data, the  latter of which has only been available since November 1981, I’ve used  the period of 1982 to 2009 as base years for all anomaly data.
WHY  WOULD DELETING SEA SURFACE TEMPEATURE DATA AND REPLACING IT WITH LAND  SURFACE DATA BE IMPORTANT?

Land Surface Temperature  variations are much greater than Sea Surface Temperature variations.  Refer to Figure 5. Since January 1982, the trend in GISTEMP Arctic Land  Surface Temperature Anomalies (65N-90N, 40E-40W) with 250km radius  smoothing is approximately 8 times higher than the Sea Surface  Temperature anomaly trend for the same area.
The Arctic Ocean SST  anomaly linear trend is 0.082 deg C/ decade, while the linear trend for  the land surface temperature anomalies is 0.68 deg C/decade. And as a  reference, the “combined” GISTEMP Arctic temperature anomaly trend for  that area is 9 times the SST anomaly trend.
 http://i46.tinypic.com/1zpheme.jpg
Figure  5
By deleting the Sea Surface Temperature anomaly data, GISS  relies on the dataset with the greater month-to-month variation and the  much higher temperature anomaly trend for its depictions of Arctic  temperature anomalies. This obviously biases the Arctic “combined”  temperature anomalies in this area.
GISS DELETES SEA  SURFACE TEMPERATURE DATA IN THE SOUTHERN HEMISPHERE, TOO
Figure  6 shows four maps of Antarctica and the Southern Ocean (South Pole  Stereographic, 90S-60S). It is similar to Figure 8. Cell (b) illustrates  the SST anomalies presented by the Reynolds (OI.v2) Sea Surface  Temperature anomaly data. SST anomaly data covers most of the Southern  Ocean, but GISS deletes a substantial portion of it, as shown in Cell  (c). The only SST anomaly data exists toward some northern portions of  the Southern Ocean. These are areas not “covered occasionally by sea  ice”.
 http://i50.tinypic.com/aensly.jpg
Figure  6
Figure 7 illustrates the following temperature anomalies for  the latitude band from 75S-60S:
-Sea Surface Temperature, and
-Land  Surface temperature of the GISTEMP product with 250km radius smoothing,  and
-Combined Land and Sea Surface of the GISTEMP product with  1200km radius smoothing, the GISTEMP standard product.
The  variability of the Antarctic land surface temperature anomaly data is  much greater than the Southern Ocean sea surface temperature data. The  linear trend of the sea surface temperature anomalies are negative while  the land surface temperature data has a significant positive trend, so  deleting the major portions of the Southern Ocean sea surface  temperature data as shown in Cell (c) of Figure 6 and replacing it with  land surface temperature data raises temperature anomalies for the  region during periods of sea ice melt.
Note that the combined GISTEMP  product has a lower trend than the land only data. Part of this decrease  in trend results because the latitude band used in this comparison  still includes portions of sea surface temperature data that is not  excluded by GISS (because it doesn’t change to sea ice in those areas).
 http://i45.tinypic.com/im6q29.jpg
Figure  7
ZONAL MEAN GRAPHS REINFORCE THE REASON FOR THE GISS  DIVERGENCE
When you create a map at the GISS Global Maps webpage,  two graphics appear. The top one is the map, examples of which are  illustrated in Figure 1, and the bottom is a Zonal Mean graph. The Zonal  Mean graph presents the average temperature anomalies for latitudes,  starting near the South Pole at 89S and ending near the North Pole at  89N. Figure 8 is a sample. It illustrates the changes (rises and falls)  in Zonal Mean temperature anomalies from 1982 to 2009 of the GISTEMP  combined land and sea surface temperature product with 1200km radius  smoothing. The greatest change in the zonal mean temperature anomalies  occurs at the North Pole, the Arctic. This is caused by a phenomenon  called Polar Amplification.
 
http://i48.tinypic.com/spd4li.jpg
Figure  8
To produce a graph similar to the GISS plot of the changes in  Zonal Mean Temperature Anomalies, I determined the linear trends of the  GISTEMP combined product (1200km radius smoothing) in 5 degree latitude  increments from 90S-90N, for the years 1982 to 2009, then multiplied the  decadal trends by 2.8 decades. I repeated the process for HADCRUT data.  Refer to Figure 9.
The two datasets are similar between the latitudes  of 50S-50N, but then diverge toward the poles. As noted numerous times  in this post, GISS deletes sea surface temperature data at higher  latitudes (poleward of approximately 50S and 50N), and replaces it with  land surface data.
 http://i47.tinypic.com/2uzfc6r.jpg
Figure  9
Figure 10 shows the differences between the changes in GISTEMP  and HADCRUT Zonal Mean Temperature Anomalies. This better illustrates  the divergence at latitudes where GISS deletes Sea Surface Temperature  data and replaces it with land surface temperature anomaly data, that  latter of which naturally has higher linear trends during this period.
 http://i45.tinypic.com/xnsp40.jpg
Figure  10
SOURCE

Maps and data of sea ice cover  and temperature anomalies are available through the KNMI Climate  Explorer:
http://climexp.knmi.nl/selectfield_obs.cgi?someone@somewhere


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b14f7c9',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterThe recent long-term forecasts for Europe show we most likely aren’t going to be escaping winter this year. Over the last week or so, the forecasts couldn’t seem to make up their minds, would it be cold or not cold?

Source: http://wxmaps.org/pix/temp4.html
One day the forecast showed cold on the way, and the next day the charts would be revised and showed mild weather in the pipeline.
But over the last few days, the signs have all been converging and showing that cold is on the way from Russia. Europe this year may get a hard winter after all – it may be just arriving late. The bottom chart for Europe shows the anomaly for the coming week. The middle chart shows the forecast for the week after. It’s going to get even colder. We’ll see how it pans out.
Asia is already freezing to death!
Below if you click on the charts for Asia, you see that cold is the story of the day. In fact it’s rare to see that much cold over such a vast continent.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Source: http://wxmaps.org/pix/temp11.html
The lower chart of central Asia shows below normal temps are forecast for almost every region for the coming week, and the middle chart shows even deeper cold for the week after, as we saw is the case for Europe.
Hansen ought to put his red crayons away and grab for blue or purple ones.
Charts for…
Central Asia: http://wxmaps.org/pix/temp11.html
East Asia: http://wxmaps.org/pix/temp5.html
South Asia: http://wxmaps.org/pix/temp6.html
North America: http://wxmaps.org/pix/temp2.html
Australia: http://wxmaps.org/pix/temp7.html
Africa: http://wxmaps.org/pix/temp10.html
Middle East: http://wxmaps.org/pix/temp9.html
South America: http://wxmaps.org/pix/temp8.html
Look at Asia and South America! See all the global warming?
Yet the kooks say it’s still too warm!
Remember that for the climate dummies, like Hansen, NOAA, and a host of others, this is still dangerously too warm. Temperatures are supposed to be a lot lower in order for the Earth to be normal and for life on it to be safe.
Yeah right! Go tell that to the billions of folks In Europe, Asia, Middle East and South America who are now struggling to stay warm.
Share this...FacebookTwitter "
"**The Democratic mayor of the US city of Denver has apologised after breaking his own Thanksgiving travel advice.**
In a message posted to Twitter early on Wednesday, Michael Hancock urged residents to ""host virtual gatherings"" and ""avoid travel, if you can"".
Just hours later, however, it emerged he had travelled to Mississippi to join his wife and daughter for the holiday.
""I apologize to the residents of Denver who see my decision as conflicting with the guidance,"" he responded.
Millions of Americans are travelling home to celebrate Thanksgiving this Thursday, despite warnings from health officials amid a significant wave of coronavirus cases and deaths.
The US has recorded more than 12.7 million infections and 262,000 deaths since the pandemic began.
Acknowledging his decision on Twitter, Mr Hancock said that his wife and daughter were in Mississippi and he ""decided it would be safer for me to travel to see them than to have two family members travel back to Denver"" for the holiday.
""I recognize that my decision has disappointed many who believe it would have been better to spend Thanksgiving alone,"" the mayor wrote on Twitter.
""I made my decision as a husband and father, and for those who are angry and disappointed, I humbly ask you to forgive decisions that are borne of my heart and not my head.""
Mr Hancock is not the only US official to be caught breaking coronavirus guidance.
Andrew Cuomo, the governor of New York, has been forced to cancel his own Thanksgiving plans after saying in an interview that he planned to host his 89-year-old mother and his two adult daughters for dinner.
Californian Governor Gavin Newsom, meanwhile, recently faced controversy after he was pictured dining indoors at a restaurant with people from other households."
nan
"
I’m remiss in getting this up until now, as Leif sent it back on May 12th. Prep, travel and recovery for ICCC4 took up quite a bit of my time, but I’m pleased to be able to offer this from Dr. Svalgaard now.

Cartoon from community.acs.org
Dr. Svalgaard writes:
Back in October WUWT had an article about my paper ‘Heliomagnetic Magnetic  Field 1835-2009‘.
The paper has now gone through extensive peer review. I  promised to let people in on the review process and can now do that. They contain a mixture of arcane  technical points and general whining. The review history may be of  general interest, at least as far the ‘flavor’ and tone of the reviews  are concerned.
The entire review is condensed into a PDF file, which can be viewed below:
Leif_IDV09-Review-History


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8ba7f40a',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**Nearly 40 people were handed fines after police raided a party at a student accommodation block in Nottingham.**
Officers said they were called to the gathering in Union Road by security staff at about 22:50 GMT on Tuesday.
Several revellers had tried to hide in a kitchen to avoid being found by officers, Nottinghamshire Police said.
The party's organiser, a 19-year-old woman, is now facing a possible fine of up to Â£10,000.
Penalties were handed out to 37 other guests.
Insp Paul Gummer said: ""At a time when the whole country's in a second lockdown and people are following the rules in the hope of being able to see their family at Christmas, it's really selfish that people are still having these big parties.""
A Nottingham Trent University spokesperson said: ""We are working with Nottinghamshire Police to investigate this as a matter of urgency and our internal disciplinary processes have already begun.""
Earlier this month, Nottinghamshire's chief constable called for students who broke Covid-19 rules to be expelled.
_Follow BBC East Midlands on_Facebook _,_Twitter _, or_Instagram _. Send your story ideas to_eastmidsnews@bbc.co.uk _._"
"
Share this...FacebookTwitterBy Ed Caryl
SH shows no warming!
In A Recent Temperature History, Part 1, the temperature trends for the contiguous United States were examined. In part 2, the rest of the world (as far as there is data) will be explored. Again, the selection criteria were: less than 10,000 population, and (as much as possible) a continuous record from 1940 or before to the present.
Ten stations were found in the Arctic and Siberia, six stations bordering the North Atlantic Ocean, and thirteen stations in the southern hemisphere, in South American, Australia, the south Atlantic, and south Pacific. All of these stations are well away from any population centers and are isolated or in or associated with very small towns and villages. No stations were found in continental Europe or Africa that met the above criteria. Station records at GISS either ceased in 1990, had a large gap during WWII, or both.

Figure 1. These are Arctic and Siberian temperature anomalies using 1930 to 1980 as the baseline period. The bold black trace is the average of these ten anomalies.
In the Arctic and Siberia we see the familiar pattern of warming in the first half of the 20th century, followed by cooling until 1970, then warming until recently.

Figure 2: The Arctic and Siberia average anomaly and a linear trend line from 1930 to the present. The trend is +0.33° C over the 80 years, or about 0.4° C per century.
The problem with the trend in Figure 2 is that it includes part of the earlier warming trend and only one cooling period. In Figure 3, the 66-year complete cycle is chosen, and there is no trend.

Figure 3. The Arctic and Siberian trend over the period 1943 to 2000.
The North Atlantic shows the same shape as the other Northern Hemisphere records.



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 4. There are six North Atlantic temperature anomalies. The bold black trace is the average of the six stations. Before 1900, only the Akureyi station on Iceland was active.

Figure 5. This is the North Atlantic average anomaly and the linear trend from 1930 to the present. The trend from the mid 1930’s to the present is flat.
In the northern hemisphere the temperature trend is a cycle, roughly paralleling the Atlantic Multi-decadal Oscillation (AMO), and the Pacific Decadal Oscillation (PDO). Between the cycles of that oscillation, there is no trend. There may have been a trend in the 19th century of warming from the LIA, but that is now over.
The Southern Hemisphere
There are few stations in the Southern Hemisphere that meet the criteria for admission into this exclusive club. South Africa has none. Australia has three, two at airports, but not large airports. South America has four stations, the rest are on islands in the Pacific, and there is one in the South Atlantic. There were no stations in Antarctica before 1955. Most stations in Antarctica were established during the International Geophysical Year from July 1, 1957, to December 31, 1958. Still, there are five stations in the southern hemisphere that go back to the turn of the 20th century.

Figure 6. There are 13 Southern Hemisphere stations with long records. The baseline for these anomalies is, again, 1930 to 1980. The bold trace is the average anomaly.
In Figure 6, the Argentine Base Orcada on the South Orkney Islands in the South Atlantic provides much of the noise.

Figure 7: This is the Southern Hemisphere average anomaly with the linear trend line.
The notable thing about the southern hemisphere trend is that there isn’t any trend. The eye tries to detect a pattern of cooling early and a slight warming since 1930, but it would be about 0.1° C. If real, this may be half of the 200-year cycle discussed in the Lui et al paper, and here. But it might be urban warming creeping into the data. Some of the positive peaks coincide with major El Nino years, particularly 1891, 1982-83, 1997-98, and 2010. Over the last 50 years, continental Antarctica itself seems to be cooling slightly. See A Wind in Antarctica.
In the beginning, the exercise described in this two-part article was an attempt to tease out an accurate measure of global warming in order to determine CO2 sensitivity, the amount of warming we would experience if CO2 were to double. During the 20th century, CO2 in the atmosphere has increased from about 280 parts per million (ppm) to 390 ppm. This is about 40% of doubling. If doubling the CO2 in the atmosphere were to cause appreciable warming, we should see a measurable amount now. The climate sensitivity can be calculated from that amount. That number has now been found.
It’s zero.
Share this...FacebookTwitter "
"Next up on the global development agenda: the UN’s Sustainable Development Goals (SGDs). The UN hopes the goals will form a framework of rules and ideals that can influence development plans and actions around the world. Yet the idea of “culture” in development was largely absent from the Millennium Development Goals that the SDGs will replace and, judging by the “Zero Draft”, the same mistake is about to be made again. It’s not for want of talking – a growing consensus calls for culture to be included in the SDGs. The UN secretary-general, Ban Ki-moon, stressed that “culture is at the top of this agenda”, echoing the heads of UNESCO and the UN’s development programme and various civil society organisations. The UN has even hosted a debate on culture and sustainable development. So plenty of talk about culture. But there is little room – and, it seems, little time – to build a solid evidence-based argument. Such evidence does exist, including a range of studies and reports on the subject – and academics from across the world have grouped together to investigate cultural sustainability. However the big UN discussions tend to ignore the evidence around culture. And in any case “culture” is difficult to reduce to a handful of indicators in the same way that infant mortality is a good indicator of health, or female workforce participation is a useful proxy for gender equality – not that this has stopped UNESCO from trying to develop a set of cultural development indicators.  That is why we point out here how culture can contribute to sustainable development processes in at least three ways.  First, cultural expressions can provide a way to articulate voices and ideas to reconsider the transition from unsustainable to sustainable patterns of living. NYU anthropologist Arjun Appadurai calls this the “capacity to aspire”.  In Canada, this has been made explicit. Integrated community sustainability plans outline a broad and long-term strategic vision for towns and villages – one that includes culture. Hundreds of communities have incorporated their cultural aspirations into the official vision for their future development. Furthermore, cultural expressions – from storytelling to photography – have been used to help articulate and share these visions. They also develop new narratives about local culturally resonant pathways toward greater local sustainability and resiliency. Second, cultural “ways of life” form the basis of how people interact. A community won’t be able to successfully transition to a more sustainable lifestyle without taking the particularity of these practices is taken into account. This argument builds on decades of development anthropology, where the bottom line is that ways of living matter in approaches to change.  Take the city of Auckland. New Zealand’s largest urban area is surrounded by harbours and bays and is particularly vulnerable to water pollution. A project called Fluid City brought together artists, scientists, indigenous understandings and personal storytelling. This, to encourage visitors to see water as far more than a physical resource or commodity and to see themselves as “water-dependent citizens”. Anti-pollution laws or shipping regulations on shipping are important, but this form of cultural change goes right to the roots of Auckland’s environmental issues. Thirdly, culture also forms the basis of the creative industries. This is the bottom line of the creative economy debate brought together by UN agencies. UNCTAD argues that these industries are a feasible development option. And UNESCO stresses that they help widen development pathways.  The cultural industries are, for example, a key pillar of the sustainable development plan of Burkina Faso as crafts and culture contribute to tourism. In fact, the country has developed a range of internationally respected public and private cultural events (such as FESPACO, SIAO and Rendez-vous Chez Nous). These, as well as the promotion of heritage sites (such as the Opera Village and the sculpture park at Laongo and the Ruins of Loropeni) attract tourists and domestic visitors and bring in foreign currency into the country.  The challenge with this approach is that the role of culture is often reduced to the cultural industries alone, while its potential for sustainable development depends on combining it with recognising culturally resonant aspirations and lifestyle changes. UNESCO seems to recognise this – its world forum on October 2-4 explicitly focuses on both culture and cultural industries. Culture certainly does not provide a magic solution to persistent development challenges. But precisely because sustainable development is about the future we want, we should pay far more attention to the cultural “capacity to aspire”, the transformational potential of societies – and the books, movies and programmes that articulate visions of sustainable justice. The current sustainable development goals try to incorporate a huge number of issues and perspectives into a global agenda to change how we act. This is both its strongest point and its weakest point.  It is strong because the SDGs are more inclusive, balanced and holistic than previous attempts to set such a framework. It is, however, also weak precisely because it may include too much. And, like all complex policy agendas, it risks collapsing under its own weight. This is why culture cannot simply be an addition to the goals – sustainable culture change must be a goal itself. Culture in all its facets is a reminder that as much as we need a joint global agenda, we also need to show sensibility to the different ideas, life worlds, and creative expressions addressed above that give form to the kind of transformations that are not only necessary, but also possible."
"**The number of unemployed people in the UK is expected to surge to 2.6 million by mid-2021, Rishi Sunak has warned.**
In his Spending Review, the chancellor said the ""economic emergency"" caused by Covid-19 had ""only just begun"".
The government expected to borrow Â£394bn this year - the ""highest"" level ""in our peacetime history"" - he added.
The latest figures show 1.62 million people are unemployed, a number which has risen by more than 300,000 since last year.
In the House of Commons, Mr Sunak said the government would spend Â£280bn this year ""to get our country through coronavirus"".
He also announced that most public sector workers would have their pay frozen, with only the lowest paid, as well as nurses, doctors and other NHS staff, getting a salary rise.
And the chancellor said spending on overseas aid, as a proportion of national income, would be 0.5% in 2021-2 - down from the 0.7% currently set in law.
The document accompanying Mr Sunak's statement makes no mention of extending the temporary Â£20 uplift in Universal Credit beyond next April, but this is expected to be reviewed in the new year.
The last time the UK unemployment figure was as high as 2.6 million was in May to July 2012.
The number exceeded three million from 1983 to 1987 and for a few months in early 1993.
Mr Sunak told MPs the economy was predicted to contract by 11.3% this year - ""the largest fall in output for more than 300 years"" - and grow by 5.5% next year and 6.6% in 2022.
He added: ""Even with growth returning, our economic output is not expected to return to pre-crisis levels until the fourth quarter of 2022. And the economic damage is likely to be lasting.""
The government's Covid response, including furlough, has led to huge spending rises, at a time when its income from taxation is down.
Mr Sunak said the UK was expected to borrow Â£394bn this year, which was predicted to fall to Â£164bn next year and Â£105bn in 2022-3.
Some other Spending Review announcements were trailed before his statement, including:
The chancellor had intended - as usual - to set out plans for the next three years, but this was reduced to just one year due to the economic turmoil caused by the pandemic.
For Labour, shadow chancellor Anneliese Dodds said a longer-term spending review was needed soon ""to build a future for our country as the best place in the world to grow up in and the best place to grow old in"".
She criticised Mr Sunak for not mentioning Brexit in his speech, with the UK set to leave the EU single market and customs area at the end of the year.
Ms Dodds added: ""There's still no trade deal. So does the chancellor truly believe that his government is prepared and that he's done enough to help those businesses that will be heavily affected?""
The Office for Budget Responsibility said that if no deal was reached, and the UK and EU had to trade under World Trade Organization rules - including tariffs - this could ""reduce real GDP"" by 2% in 2021, on top of the damage caused by coronavirus.
The economic shock of the ""various temporary disruptions to cross-border trade and the knock-on impacts"" would continue for years, it predicted.
But a Treasury spokesman insisted the government was confident about the future of the UK, whatever the outcome of negotiations with Brussels.
He said the chancellor was focussed on Covid, which he described as the ""core economic challenge"" and ""the one that matters today to people's jobs"".
Dave Prentis, general secretary of the union Unison, called the pay freeze for most public sector workers ""austerity, plain and simple"" and a ""bitter pill"" for those affected.
He added: ""A decade of spending cuts left public services exposed when Covid came calling. The government is making the same disastrous mistake again."""
"

In a recent and wonderful _New York Times_ essay, John Tierney documented the pervasive left‐​leaning bias of the social sciences in particular and academia in general, which he persuasively painted as the home of tired ideological groupthink. No doubt his essay was an eye‐​opener for anyone without much experience in the ivy morass, even as it came up short in its search for causation.



There is a dangerous synergy between the academy’s attitudes and what is permitted or proscribed in our scientific journals. An interesting example is in the February 4th issue of _Science_ , the nation’s most prestigious technical magazine and the flagship of scientists’ Washington lobby, the American Association for the Advancement of Science.



The mixing of politics and science, particularly with respect to climate change, has been spilling onto _Science’s_ pages for decades now, but no more blatantly than in the recent paper by Ulf Büntgen of the Swiss Federal Research Institute and 11 coauthors.





The conflation of political agendas with science is destroying the credibility of academia, with the complicity of the editors of our major scientific journals.



This paper is one of many reviving the grizzled ghost of climatic determinism, an idea that originated in the 19th century, which attempts to explain complex social phenomena with simple phenomena like average temperature. For example, proponents of this theory argued that mean annual temperature is why colder regions were industrialized democracies, while the tropics were torpid and despotic. The story went (I am not making this up) that people at low latitudes can just laze around in hammocks and don’t have to go very far to find fruit, while people closer to the poles have to develop economies that coax food from the ground. This is only slightly racist, and climatic determinism went into hibernation as people realized that crank scientific theories have a way of developing into mass murder.



In the Büntgen et al. article, climatic determinism is the cause of good times, bad times, and wars. The core of the paper is a graphic showing tree‐​ring reconstructed summer temperature and spring precipitation in central Europe for the last 2,500 years. Superimposed upon the figures are what the authors feel are salubrious times, given as the Late Iron age, the Roman Empire and the Medieval period, as well as bad ones. These include the “migration period” from 1,700 to 1,400 years ago, and the “modern migration” of the 19th century. Apparently people came to the U.S. because temperatures in Europe were a degree lower than average, rather than in search of economic and political freedom.



Looking at Figure 4 in the paper, it’s pretty clear that when it was warm in central Europe, times were peachy (literally), and when it was chilly there were wars, pestilences and other bad things.



This didn’t stop the authors from making a blatant political plea — completely unsupported by the results — nor did it prevent the editors from writing it out. Remember that this is a paper in which warm periods are good times. That notwithstanding, we read:



The historical association of precipitation and temperature variation with population migration and settlement desertion in Europe may provide a basis for questioning the recent political and fiscal reluctance to mitigate projected climate change.



Imagine if they had concluded, “Such historical data may provide a basis for the support of the recent political and financial reluctance to mitigate projected climate change,” which in fact is what it does! Tierney’s analysis predicts that would have been severely criticized as a bad example of using science for political purposes.



The process is synergistic and self‐​fulfilling. Periodicals like _Science_ are what academia uses to define the current truth. But the monolithic leftward inclination of the reviewing community clearly permits one interpretation (even if not supported by the results) and not another. This type of blatant politicized science is becoming the norm in the environmental arena, and probably has infiltrated most every other discipline, too.



The conflation of political agendas with science is destroying the credibility of academia, with the complicity of the editors of our major scientific journals.
"
"

The Republican tax reform framework envisions cutting the federal corporate tax rate from 35 to 20 percent. There may be pressure in coming weeks to scale‐​back some of the framework’s pro‐​growth provisions in order to hit revenue targets, but policymakers should stick with their corporate rate target.   
  
  
Various groups have modeled the revenue effects of proposed corporate rate cuts, but they generally do not account for the full dynamic effects of reform. We can get an idea of the full effects by looking at actual reforms abroad.   
  
  
Sharp corporate tax rate cuts in Canada and Britain do not seem to have lost those governments much, if any, revenue. That is likely because companies responded with a wide range of real and paper changes that increased their reported income. The same would happen in the United States, which is why dropping our rate to 20 percent would probably not lose revenue over the long term.   
  
  
Here is some evidence. For 19 OECD countries with good rate and revenue data back to the 1960s, I calculated the average corporate tax rates and average corporate tax revenues as a share of GDP. The chart illustrates the Laffer Curve effect of chopping high tax rates on a mobile tax base—rates go down, the tax base expands, and revenues remain strong.   
  
  
From 1985 to 2005, corporate tax revenues as a share of GDP soared even though the average tax rate across the 19 countries fell from 45 to 29 percent. Then there is a sharp drop in revenues in 2010, presumably because of the recession or slow growth in many countries at the time. But note that even in the poor economic climate of 2010, corporate tax revenues were the same or higher than in years prior to the 2000 boom year.   
  
  
By 2015, revenues were rising again even as the average tax rate continued to fall to a new low of 24 percent. The average revenue for these countries in 2015 at 2.9 percent of GDP is below 2000 and 2005, but above all prior years when rates were much higher.   






Data Notes:   
  
  
The 19 countries are Australia, Austria, Belgium, Canada, Denmark, Finland, France, Germany, Greece, Ireland, Italy, Japan, Luxembourg, Netherlands, New Zealand, Spain, Sweden, United Kingdom, and the United States.   
  
  
OECD revenue data is here and rate data is here. I used the central government rates because I have not found a source for subnational rates prior to the OECD data, which goes back to 1981. As a result, the revenues (which include subnational) and the rates (which do not) are not an exact match, but that is not a big problem for illustrating trends over time.
"
"

Today's _NYT_ features a front page, above-the-fold story about former surgeon general Richard Carmona's charge that the Bush administration interfered with his office by (in the words of the _NYT)_ ""repeatedly [trying] to weaken or suppress important public health reports because of political considerations."" He made the charge yesterday in testimony before the House Committee on Oversight and Government Reform.   
  
Carmona described Bush administration behavior that ranged from petty (urging him not to attend Special Olympics events because of the Kennedy family's connection to the program) to outright worrisome (directing him, again in the words of the _NYT_ , ""to put political considerations over scientific ones""). His claims add to the image of a Bush White House in which political considerations and ideology trump all others.   
  
However, Carmona's prepared statement suggests that the Bushies aren't the only folks caught up in ideology.   
  
Carmona considers himself a person of science, and scientists have an important role in policymaking. They try to determine the existence of various empirical relationships (e.g., certain emissions trap heat in the atmosphere; exposure to tobacco smoke increases the risk of cancer) and use those determinations to make predictions about the future (e.g., ongoing emission of greenhouse gases at certain levels will affect the climate; reduced tobacco use will decrease the incidence of cancer). In this way, science informs policymaking by predicting the outcomes of various policy choices.   
  
But though science informs policy choices, it cannot make those choices. Science is a non-normative endeavor, and cannot answer such questions as whether climate change _should_ be avoided, and whether reducing tobacco use _should_ be used as a means to reduce the incidence of cancer. Those are the subject of value judgments — and, for public decisions, of politics.   




Many ""people of science"" do not appreciate this limit on science's role in policymaking. They assume that once a relationship is established scientifically, policy choices cogently follow. In making this assumption, they enter their own value judgments as suppressed premises in their analyses. Many doctors see bad health outcomes as not just undesirable, but so undesirable that they should be avoided even at high costs; many environmental scientists have the same opinion about environmental damage. Hence, they would argue that ""objective, nonpartisan science"" calls for policies to limit greenhouse emissions and reduce smoking. In fact, science can do no such thing; value judgments call for (or against) various choices.   
  
To better understand this, consider the role of a doctor. Five separate times in his testimony, Carmona refered to the surgeon general as ""the nation's doctor"" (conjuring the image of 300 million Americans sticking out their collective tongues and saying ""ahh""). I trust my doctor to make a scientific determination of the state of my health and to lay out various courses of action concerning my health (e.g., lose weight, take medication, exercise more, quit smoking). But I am the one who sets policies concerning my health — I decide whether the costs of some course of action (e.g., the side effects of some drug, or the pleasure forgone by dieting) is worth the health benefits. Likewise, public health policy should be set by elected representatives who are directly accountable to the citizenry, not by ""the nation's doctor.""   
  
But Carmona apparently wants the surgeon general to become a policymaker. He told the House committee: 



[T]he Surgeon General [should] speak and act openly and as often as necessary on contemporary health and scientific issues so as to improve the health, safety, and security of the nation.



Indeed, that role may be too modest for Carmona's surgeon general; he repeatedly argued that the surgeon general should ""serve the people and the world."" He offered lawmakers a five-point plan for the U.S. Public Health Service that included the following: 





So, instead of just being the nation's doctor (with policymaking power), Carmona's surgeon general would be a force projector for the world.   
  
Carmona is correct that politicians should not interfere with the scientific analysis of the surgeon general — the surgeon general should follow an empirical question wherever the science leads. And he may even state his personal opinion — couched as such — on the value judgments that ensue from the science. But the surgeon general should not supplant the politicians in making public policy decisions, nor supplant private individuals in making personal health decisions. And, of course, the surgeon general should not doctor scientific findings to conform them to his own value judgments.


"
"

In a piece last Wednesday on _The American Spectator_ website, David Hogberg argues that the notion that limited government supporters will be happier if Republicans lose in November — thereby ushering in at least two years of divided government — might be too clever by half.



Hogberg explains we “should never underestimate politicians’ ability to glean the wrong lesson from an election.” It’s reasonable to fear that post‐​loss Republicans will conclude that their electoral problem wasn’t that they ushered in a new era of Big Government but that they failed to endorse an era of Even Bigger Government instead.



But it seems to me the bigger problem is that Republicans are learning the wrong lessons from their victories. Right now, the message they’re receiving is that voters are peachy with how things are going on the Hill.



The GOP seems to learn the right lessons from their electoral losses. They certainly did after the 1992 elections. Without the loss of George H.W. Bush, the Republican Revolution of 1994 would not have been possible. Many of the candidates who ran in 1994 were motivated by Clinton’s rush to nationalize the health‐​care system. But many were also fed up with “me too” Republicans like House minority leader Bob Michel.



What about the morning after the elections? In the wake of a Republican loss of the House, “there will likely be challenges and possibly ‘coup attempts’ against House GOP leaders,” Hogberg writes. “While the long‐​term fallout of losing in 2006 may be positive, the short run losses could be very ugly.”



Also true. But when has the learning process in politics — indeed, much of anything in politics — ever been pretty? Necessary, yes, but certainly not a thing of beauty. Besides, there are probably very few conservatives who see the current crew of House and Senate leaders as strong captains. Denny Hastert isn’t someone who leaps to mind as a swashbuckling budget‐​cutter.



Finally, Hogberg takes aim at the divided government thesis: “It rests heavily on the Reagan and Clinton years,” he writes, “but a look at the year‐​to‐​year percentage change of the government portion of gross domestic product suggests that fiscal restraint is far more contingent on the political climate.”



You’d find plenty of agreement on this among supporters of the divided government thesis. The thesis itself is nothing if not an attempt to explain how the political climate affects policy.



As Hogberg rightly notes, the big net declines in government spending occurred only after substantial victories by candidates who professed an explicitly stated goal of scaling back government. And he’s right to point out that over time, fiscal discipline flagged. Divided government, however, puts an outer limit on how bad things can get. Republicans just weren’t interested in spending all that much money on the programs that Clinton wanted, nor was Clinton interested in spending on many of the programs the GOP wanted.



The divided government thesis rests on a key assumption about the political environment: The one thing you can count on in Washington is partisanship. When Republicans are fighting a big‐​spending Democratic White House — or when they are a beleaguered congressional minority — they are in their element. Big Government is the clear enemy. But once they find themselves in control of the game, they are less willing to throw punches out of fear that they’ll hit their own teammates.



Consider how the GOP Congress reacted to non‐​defense budget requests under both Clinton and George W. Bush. They managed to cut Clinton’s domestic spending requests by an average of $9 billion each year between fiscal 1996 and 2001. Contrast that with the budget outcomes under President Bush, specifically the years in which Congress was held entirely by Republicans. Between fiscal years 2004 and 2006, Congress passed, and Bush refused to veto, non‐​defense budgets that were an average of $16 billion more than the president proposed each year.



The rules of partisanship imply that a Big Government scheme proposed by a Republican president is more likely to be accepted by a Republican Congress than if it were proposed by a Democrat. That’s exactly what happened with the Medicare drug benefit. It’s unlikely the drug benefit would ever have passed if it had been proposed by, say, President Al Gore or President Hillary Clinton. And if the Medicare expansion had gotten traction in Congress, Republican leaders would probably have been more interested in slowing it down and tacking on real reforms instead of abandoning the reforms as they did in 2003.



“Would Bush and a Democrat‐​controlled House be an improvement over recent years? Doubtful,” Hogberg concludes. “Bush is, at best, a squish on fiscal restraint (and that’s being charitable).”



One thing we have seen, however, is that Bush, like all politicians, is a political animal. On domestic policy, he usually cares more about scoring one for his own team than upholding a coherent position on the role of government in a free society. I suspect the president would go hunting for his veto pen more often if he were faced with a Democratic House. And imagine how congressional Republicans would fight the sorts of big government schemes they currently push if those proposals came instead from the mouths of Democratic majority leaders.



Divided government isn’t a cure‐​all. But I’m willing to entertain the notion that those who value limited government would be at least no worse off under it than they are now.
"
"This week’s budget will be the first passed by parliament since MPs declared a climate emergency, but it could be the last before the UK hosts the Cop26 climate talks later this year. Many people have drawn legitimate comparisons between the respective responses to coronavirus and the climate crisis – both big shocks to the economy. But it’s important not to lose sight of why the response to Covid-19 has been so rushed and dramatic – we were caught by surprise. We have not, however, been taken by surprise by the climate crisis.  If we let things get to that point with our climate – whether through increased water scarcity, coastal flooding or wildfires – the consequences will not only be severe and tragic, but unlike an epidemic they will also be long-lasting. And so this week’s budget can’t afford to miss the bigger picture; it must be a climate budget. Measures to contain or delay the spread of disease will be a necessity. But that won’t be an excuse to detract from efforts to mitigate and adapt to the climate emergency in a way that serves society. The problems facing the chancellor, Rishi Sunak, are clear. To reach net zero, annual household emissions of carbon will need to fall from about 8,000kg of C02 today to not much more than 1,000kg by 2050. The largest reductions will need to be in heating, transport and electricity. But while good progress has been made to reduce emissions from the UK’s power sector, we are far behind in almost every other part of the economy. According to the Committee on Climate Change, the UK remains behind schedule in all but seven of its 24 indicators to reach even our previous legally binding emissions targets, before these were increased to “net zero by 2050”. More importantly, we know private investment alone won’t cut it. This is partly because many of the risks in developing new technology are too high without significant government support. But we also know creating greener jobs in the right places is unlikely to succeed if we rely on markets alone. The UK remains one of the most regionally unequal countries in Europe, with GDP per head about three times higher in Milton Keynes compared with the Wirral. Transitioning to zero-carbon industry must be used to address the geographical imbalance of our economy at the same time. So, what are the things that a chancellor serious about the climate emergency needs to do at this budget? Top of the list is significantly increasing investment in low-carbon infrastructure, prioritising electrification of transport, reforestation, and home insulation and heating. We currently spend a little under 1% of GDP per year on such investments (equivalent to around £15-20bn in 2019/20 terms), but the evidence suggests this will need to rise to more like 2-3%. Current plans see public investment sitting between 2-2.5% of GDP over the coming four years. So to avoid false trade-offs with other social infrastructure priorities such as schools and hospitals, the Conservative party’s arbitrary 3% limit on public investment will also need to be discarded. Then, of course, there’s “levelling up”. The government’s new favourite mantra must quickly find meaning and ways of genuinely improving the lives of those living in places that first powered our industrial revolution and now power our high-carbon industries. Zero-carbon transformation and levelling up are mutually dependent: outside of major airports, each of the 40 local authorities where 30% or more jobs are reliant on carbon-intensive industries are situated in the Midlands and the north. Unless these areas are supported in transitioning to low-carbon industries through government intervention, they risk high levels of unemployment and inequality. A genuine industrial strategy for regions outside London – one that centres on transport and energy efficiency – would provide this support, and in ways that go beyond making the rest of the country a glorified, one-way commuter belt. For the chancellor then, this is a no-brainer; yes, invest in the regions you want to level up, but make that investment green and you’ll be putting those places – and the country – on track for a more resilient and fairer economy as well. Alongside investment, we also need to raise money to pay for higher day-to-day spending, such as for new skills training and a stronger social safety net for the most affected regions. At the same time, an ageing population and reduced inward migration are likely to shrink tax – and increase the costs of older age care – over exactly the same period. So the chancellor will likely be considering some higher taxes, and wherever possible these will need to be green too. Things like replacing air passenger duty with a frequent flyer levy will help, as will replacing fuel duty with a more progressive alternative. Cuts to national insurance – costing billions, disproportionately benefiting higher income households and doing nothing to reshape consumption – will not. Get this right now, and the chancellor will not only help address existential threat, but he could give us the chance of becoming a healthier and fairer society for a generation. Get this wrong, and history will judge cruelly. Being resigned to last-minute damage limitation is an inevitability with an epidemic, but with the climate crisis it is ours to choose. • Alfie Stirling is head of economics at the New Economics Foundation"
"

 _Valleywag_ has an excellent rant on the problems with environmentalists’ blackmailing the technology industry: 



To ignore the wider benefits of the digital revolution is obtuse. Here’s the fundamental truth: the more human activity is pursued online, the less the environmental footprint. Apple’s pioneering of desktop publishing did away with much of the filthy print industry; its easy video‐​conferencing will make some business trips unnecessary; Ebay’s person‐​to‐​person marketplace bypasses cumbersome retail logistics; and Google is replacing inefficient physical libraries and filing systems across the world. Frankly, if a few computers end up in dumps, rather than recycled: so what.   
  
  
I can understand why it would be convenient to go after Apple. Steve Jobs’ computer maker is more easily pressured than most companies, because of its pristine brand, and because so many of its customers are environmentally conscious. Al Gore, the planet’s foremost defender, is on the board. Apple makes things, which are messy. And, given the holy war against climate change, and the political correctness that stifles critical thinking, the company can’t defend itself.   
  
  
The green lobby may choose to target high‐​tech companies rather than, say, the oil, coal or auto industries. The ex‐​hippies in charge of Silicon Valley companies are easy targets. But any victory, in converting them to the cause, will be purely symbolic, useful for fund‐​raising, maybe, but ultimately meaningless. This campaign against Apple is, at best, moral blackmail and, at worst, a cynical shakedown. Shame on them.



Thanks to Joe for the pointer. There’s a broader point here, that was best articulated by Julian Simon: in the long run, free markets and technological progress are good for the environment, because reducing costs often means reducing waste, and reducing waste often means reducing your environmental footprint. Technological progress and rapid economic growth also allows us to devote more resources to cleaning up the environment. Plus it leads to more people having the luxury to spend their time hectoring companies like Apple for their environmental records.
"
"
Share this...FacebookTwitterGerman veteran journalist and publicist Dirk Maxeiner at his website is a bit shocked by the over-the-top, misdirected investigations recently conducted against sceptic bloggers and free speech in general. In his short piece:
Climategate On The Path To A State Scandal

Maxeiner writes:
This is the kind of thing you’d expect to see against Chinese dissidents. […] The British police and the American Department of Justice are conducting a coordinated action against climate bloggers. Supposedly it is an effort to find the source of the “Cimategate” e-mails.  In Great Britain the first blogger has been interrogated and his computers have been confiscated. Canadian and American bloggers have been informed that their e-mails have been searched. It is obvious that critical thinkers are now to be criminalized.
See here:
http://wattsupwiththat.com/
http://blogs.telegraph.co.uk/news
Washington Examiner
Guardian
http://joannenova
http://climateaudit
We can only hope all this backfires. Many people we now beginning to show more interest in the contents of the Climategate e-mails. Also for those e-mails that have yet to be posted in the internet. It’s possible that some real juicy ones are on the way. Perhaps this is making a few people very nervous.”

Boy – talk about officials being desperate and looking frustrated! No wonder that the IPCC wants to be above the Freedom of Information Act (i.e. be above the law).


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




This action sounds very much like what they did with Galileo – talk about the dark, spooky ages coming back.
Welcome to the next chapter of the Climategate saga. Obviously for anyone concerned about freedom of speech and open debate, now is the time not to be intimidated. Instead it is now the time to cover every single detail of this development and make sure our friends in the Senate and Congress become aware of this threat. If they think they can just get away with this kind of behaviour, then someone is making one serious misjudgement.
Hey, but who knows? Maybe us bloggers and all the sceptics out there will all be holding the next climate conference somewhere out in Siberia at some reopened gulag or something:  6th International Climate Conference – Siberia, Russia – June 2012 to June 2037.
Whatever happens, look to read more about this in the future. Pandora’s box has been opened.
Dirk Maxeiner is the author of the climate-catastrophe sceptical book: Hurrah, wir retten die Welt (Hooray we’re rescuing the world!). Every German ought to read this book.

Share this...FacebookTwitter "
"**England enters a tougher version of its three tier system of restrictions on Wednesday, as a four-week lockdown ends.**
Northern Ireland has a two-week circuit-breaker lockdown, while Wales is banning the sale of alcohol in pubs, cafes and restaurants from Friday. Scotland has its own five-tier system.
Across the UK, some restrictions will be relaxed over Christmas, to allow three households to form a ""Christmas bubble"".
From just after midnight on Wednesday 2 December, areas will be placed in one of three tiers: medium, high and very high.
About 99% of England has been placed into the high and very high coronavirus risk category - tiers two and three.
The placing of areas in each tier will be reviewed every 14 days, with the first review on 16 December.
**Areas in tier two**
**Tier two (high) rules**
**Areas in tier three**
**Tier three (very high) rules**
Additional restrictions apply:
**Areas in tier one**
Only three areas have been placed in the lowest tier:
**Tier one (medium) rules**
Areas in the lowest tier will have some restrictions relaxed:
There are exceptions in all tiers for childcare and support bubbles. More details of the plan are here.
The new coronavirus tier restrictions will mean 55 million people will be banned from mixing with other households indoors. The decision about which tier to place an area in is based on:
Lockdown restrictions in Wales were eased on 9 November.
**The current rules say:**
People who you don't live with still cannot come into your home socially, unless you are in an extended household (bubble) with them. Tradespeople can enter your home to carry out work.
However, from **Friday 4 December:**
Read Wales' official guidance.
Northern Ireland started a two-week circuit-breaker lockdown from 00:01 GMT on Friday 27 November.
Read Northern Ireland's official guidance.
Each area of Scotland has been placed in one of five tiers.
Eleven local authority areas in west and central Scotland have recently moved from level three to level four, affecting two million people.
First Minister Nicola Sturgeon told MSPs the level four measures would be lifted at 18:00 GMT on Friday 11 December.
**Areas in level zero**
No areas have been placed in the lowest tier.
**Level zero (nearly normal) rules**
**Areas in level one**
**Level one (medium) rules**
Additional restrictions apply:
**Areas in level two**
**Level two (high) rules**
Additional restrictions apply:
**Areas in level three**
**Level three (very high) rules**
Additional restrictions apply:
**Areas in level four**
**Level four (lockdown) rules**
Additional restrictions apply:
Schools stay open in all levels, and here must also be no non-essential travel between Scotland the rest of the UK.
**Do you meet other people for exercise? Have you been out walking during the November lockdown? You can share your experiences by emailing**haveyoursay@bbc.co.uk **.**
Please include a contact number if you are willing to speak to a BBC journalist. You can also get in touch in the following ways:"
"
Richard North of the EU Referendum sends word of this new paper. I’m sure Greenpeace won’t be amused as more polar bears turn into dumpster divers with this new influx of miners and drillers in the new ice free future.
After the Ice Melts: Conflict Resolution and the International Scramble for Natural Resources in the Arctic Circle
Oklahoma Land Rush of 1889 - Image: wikimedia
Wei-en Tan, Department of Diplomacy, National Chengchi University, Yu-tai Tsai Institute of Strategic and International Affairs Studies, National Chung Cheng University No. 64, Sec. 2, Chinan Rd., Taipei 11605, Taiwan (PDF available here )

Abstract
It is a well-known fact that global warming is melting the Arctic ice cap.
As this happens, the natural resources in the Arctic will become available for exploitation. As such, the five countries with major claims to the region—the United States, Canada, Russia, Denmark, and Norway—are looking to extend their claims to the natural resources beneath the ice-covered ocean. The size of the Arctic Shelf is about 4.5 million square kilometers, and the U.S. Geological Survey posits that 25 percent of the world’s undiscovered gas and oil reserves may be there. Clearly, there are large amounts of untapped resources that these five countries could use to satisfy their increasing demand for development and economy.
This paper will try to explore the current disputes over Arctic seabed resources surrounding the five states in North Pole, evaluate the regimes for resolving the conflict in UNCLOS. Furthermore, the paper will introduce the appropriate points
of view and discuss the alternative dispute settlement mechanism (DSM) for this significant problem caused by global warming in the coming future.
…
It is very clear that the Arctic region stands at the threshold of significant changes. The increasing rate at which the Arctic ice is melting will surely have a major impact on local ecosystems and the potential exploitation of natural resources. By virtue of their sovereign rights and jurisdiction, the five countries with claims to the Arctic region are presently at a critical juncture for addressing their current and future conflicts of interest. This paper explores the current disputes over Arctic Ocean resources and evaluates the mechanisms in UNCLOS for resolving these kinds of disputes. Furthermore, this paper introduces the viewpoints and discusses the alternative dispute settlement mechanisms (DSM) which can be employed to solve this kind of significant problem.
…
Conclusion 
Global warming has not only challenged the authority of UNCLOS and its legal regime for resolving disputes relating to the continental shelf under the Arctic Ocean, but has also marked the beginning of the end for freedom of the high seas in the Arctic region. In addition to its environmental implications, global warming has caused a shift in the way the international community regards the Arctic, shifting the paradigm away from physical dominion and towards control over resources on the sea floor. The unprecedented access to untapped resources brought about by the receding permafrost in the Arctic Circle may soon cause an international gold rush as well as a variety of conflicts.
The conflicts over the Arctic region are unlikely to be resolved within the very near future. With five major states making claims to extensive parts of the Arctic seabed, there is a lot of scientific and professional work that needs to be done. Fortunately, there has been one good development since the conflict began. On May 28, 2008, Canada, Denmark, Norway, Russia, and the United States came together for the Arctic Ocean Conference in Greenland. (Note 66) The goal of the Conference, initiated by Denmark’s Foreign Minister, was to foster unity and cooperation in the Arctic area so as to prevent an environmental catastrophe. The result of the Conference was the Ilulissat Declaration. This document states that no new legal framework will be set up to govern the Arctic. Instead, the parties agreed to proceed using the guidelines set forth in UNCLOS. (Note 67) While this Declaration is not necessarily ground-breaking, it is encouraging in that it signals a willingness of the involved Arctic states to work together in settling their disputes.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8ca73846',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterAlthough Peter Gleick confessed almost 2 days ago to stealing and leaking documents designed to damage the Heartland Institute and others, one of Germany’s leading warmist climate blogs continues to ignore it and is still actively spreading rumors about them. About 12 hours after Anthony Watts’s story Breaking: Gleick confesses appeared, Klimaretter.de went ahead and published a new opinion piece to further smear Heartland and those involved.
First on February 16, Hanno Böck of Klimaretter wrote in piece titled The Financing Of Climate Change Doubt, where he gleefully broke the story about the acquired Heartland documents: He wrote:
Internal documents of the conservative Heartland-Institute of the USA show the strategies that the organization pursues in order to discredit climate sciences. The institute receives donations from industry and finances other blogs and alleged neutral organizations, who then spread doubt about climate change. Among others, donators include Bayer, Microsoft and General Motors.[…]
Canadian DeSmogBlog has revealed internal documents from conservative lobby organization Heartland Institute. […] From the documents it is clear that many seemingly independent voices in the debate are funded by donations from industry provided though Heartland Institute.”
Up to now, neither corrections nor omissions have been undertaken by Klimaretter, which is run by journalists and German Parliamentarians. To the contrary, as you will read below, they actively took steps to sustain the phony Heartland story by posting an opinion piece by Dr. Hermann Ott, who again using the fake document smears Heartland and the skeptics.
In its February 16 piece, Klimaretter listed the alleged funders of skeptic sites: Koch Industries, Microsoft, AT&T, Time Warner, Bayer – but did point out that the donations were mainly targeted for pharmaceutical lobbying.
Klimaretter then singled out blogger Anthony Watts, claiming he received donation checks from industry. Böck wrote:
One of these for example is the project of blogger Anthony Watts, who writes the widely read “Climate skeptical” blog Watts up with That, and the organization NIPCC (Nongovernmental International Panel on Climate Change) of American physicist Fred Singer, who views himself as a counter voice to the UN IPCC, but who is regarded as unscientific by climate scientists.
In the year 2012 the Institute plans to create educational material for schools.”
Klimaretter then wrote that Heartland had been funded by Big Tobacco to fight against the rights of non-smokers before it began to focus on climate change. Klimaretter claimed that much the pressure to attack scientists stemmed from the Tea Party movement.
Concerning the document “2012 Heartland Climate Strategy”, Klimaretter wrote that “the Heartland Institute claims the questionable document is a fake” and that “no further details concerning the authenticity of the other documents could be added, so says Heartland in a Press Release.”
Geick confesses, Ott quotes a faked document
Now, six days later, a full day after Gleick confessed he leaked the documents, you’d think Klimaretter would have taken down the story by now and added a correction. They haven’t. In fact, they’ve added an opinion by German Green party member Dr. Hermann Ott, who goes after Fred Singer and Heartland with renewed vigor. He posted his opinion (read it here) at Klimaretter 12 hours after Gleick’s confession.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Green Parliamentarian Dr. Hermann Ott, who is a regular contributor at Klimaretter and skeptic smearer, posted his piece yesterday (February 21, 3:01 pm CET) ) dubbed: How US Companies Undermine Climate Policy, which more or less reiterates everything Hanno Böck had written days earlier, and quotes the faked document:
And what does the Institute [Heartland] do with the money? Taking a first look at the figures, one sees that climate change denier Fred Singer alone, who unfortunately appeared in the Bundestag, is financed by the Heartland Institute with 5000 dollars per month (plus expenses). $100,000 is available for developing alternative educational curricula for schools for promoting doubt about climate change. In the description of this project for schools, there’s even the sentence that their goal includes: ‘dissuading teachers from teaching science’. Unbelievable and revealing.”
Ott later writes:
The entire ‘datacheck’ of the Heartland-Institute makes it perfectly clear what I was saying about the strategies of the climate change skeptics in my discussion in the Green Bundestag faction last year, namely that the funders stem mostly from the fossil fuel industry and that it is always about increasing doubt and nothing to do with scientific findings.”
Scientific findings? Does he mean the dubious sort that Gleick uses? Why Ott would continue to insist the Heartland story is real is baffling, and if done intentionally – it is malicious and slanderous. I can only speculate that he thinks nobody in Germany is going to notice, and so he thinks he can get away with it.
In light of the known fact that Gleick used fake documents (because the other docs simply weren’t going to produce the desired effect), Ott still has the temerity to conclude:
One can only hope that making the documents public will hamper the strategy of the fossil fuel industry and also lead to such books like the one by RWE-Manager Vahrenholt to disappear from the bestseller charts.”
And
Instead, they will be seen for what they really are: cold hearted egoists who put the future chances of humanity at stake for the sake of their profits.”
P.S.: If you wish to give Peter Gleick some kind words, you can do so at Twitter unter @PeterGleick.”
Recall that Hermann Ott posted this on February 21 at 3:01 p.m. CET, 12 hours AFTER Anthony Watts broke the story that Gleick had confessed. Obviously Ott is comfortable putting himslef in the same company as document fakers and mudrakers.
In case Heartland, WUWT, or the lawyers representaing them, would like to give Klimaretter some kind words, you can reach the editor in chief at:
nick.reimer@klimaretter.info
They undertand English very well.
Share this...FacebookTwitter "
"The amount of the earth’s ocean surface covered by sea ice has been continually observed by satellites and its extent estimated since 1978. The trend has been for shrinking sea ice in the Arctic and, more recently, expanding sea ice in the Antarctic.  This somewhat counter-intuitive finding has been explained by reference to the ozone hole, currents, and winds. But it seems in part it has a more straightforward origin, stemming from an error in how the data is recorded and processed. Several mathematical algorithms have been developed to convert raw satellite data into estimates of the area covered by at least some sea ice. While for the most part the results of different algorithms are in reasonable agreement, there are differences. A widely used method is the Bootstrap algorithm, developed at NASA Goddard, which performs particularly well at estimating Antarctic sea ice compared to others. As satellite sensors have only a limited lifespan, to calculate trends over longer time periods requires stitching together the records from several sensors. However, each sensor is a little bit different, and these differences need to be corrected to create a consistent record over several decades. Slight adjustments in the algorithms are made to ensure the estimates from the new sensor match as closely as possible to the estimates from the old sensor during the period when their records overlap. This can never be done perfectly, but with care disagreements can be minimised. All algorithms, including Bootstrap, do some form of inter-calibration to try to ensure the data is consistent. Bootstrap was used to report sea ice extent for the last two IPCC reports, AR4 in 2007 and AR5 in 2013. Between AR4 and AR5, Bootstrap changed from Version 1 to the improved Version 2. The reprocessed data set, V2, shows a magnified sea ice increase over V1. This wasn’t noticed at the time because Antarctic trends, being relatively small in magnitude and with large year-to-year variations, could change fairly substantially from year to year in any case. However, Ian Eisenman who led our investigation, published in the Cryosphere journal, found that the growth of Antarctic sea ice between the last set compiled with V1 and the first compiled with V2 was greater than could be explained just from adding more data. I helped find and provide the earlier V1 data and he and fellow co-author Joel Norris compared the two versions. We found the discrepancy can be pinned to a sensor calibration change in 1991. Our analysis doesn’t discern in which version the inter-calibration  error occurred – we simply compared the two versions and noticed the jump. The data set producer, Joey Comiso, has now looked at the issue and is confident that the error lies in V1, meaning the current version in use and used in AR5 is correct. Ian, Joel, and I are interested in looking further into this to confirm the V1 error. It’s important to emphasise that this sort of reprocessing of climate data – any scientific data, in fact – is not just common, but part of the scientific process; better data becomes available, methods are improved, errors are found and corrected. Data sets are never perfect, but as scientists we continually work to improve our data and understanding of it in order to get closer and closer to the truth. I think this paper and the reprocessing of Bootstrap are good examples of this process.  Fundamentally the paper doesn’t change our understanding of Antarctic sea ice. Today, regardless of which version of the data or sensor you use, Antarctic sea ice extent is increasing at a statistically significant rate. The paper documents that the jump in trend numbers reported between V1 and V2 was due to processing and not due to variation in sea ice extent. Our results simply correct the published literature and show that, contrary to what was previously thought, the increase in Antarctic sea ice hasn’t accelerated in the past 15 years, but has been remained consistently positive at moderate levels. Unlike Arctic sea ice, and the Antarctic continental ice sheets, which have been consistently, and substantially, falling. Next, read this: The Arctic melts, but oceans and ozone hole may cool Antarctica "
"
New study documents harmful effects of  “cap-and-trade” and “endangerment” schemes
Guest post by Paul Driessen
Environmental justice demands  that the United States address global warming, the gravest threat facing  minority Americans, insist the EPA, Congressional Black Caucus and White House.  Are they serious?
The alleged threat pales next to  unwed teen motherhood, school dropouts, murder and other crime. But even  assuming human carbon dioxide emissions will cause average global temperatures  to rise a few degrees more than they have already since the Little Ice Age  ended, it is absurd to suggest that any such warming would harm minorities more  than policies imposed in the name of preventing climate change.

Human activities have not  replaced the complex natural forces that drove climate change throughout Earth’s  history. But even if manmade greenhouse gases do contribute to planetary  warming, slashing US emissions to zero would bring no benefit, because steadily  rising emissions from China, India, Brazil and other rapidly growing economies  would almost instantly replace whatever gases we cease emitting.
Most important, fossil fuels  power the economic engine that ensures justice and opportunity in America today.  Policies that make energy less reliable and affordable reduce business revenues  and profits, shrink investment and innovation, imperil economic recovery, and  hobble job creation, civil rights, and the pursuit of happiness and the American  dream.
Whether they take the form of  cap-and-trade, carbon taxes, restrictions on drilling and coal mining, or EPA  rules under its claim that carbon dioxide “endangers” human health and welfare,  anti-energy policies frustrate the natural desire of poor and minority Americans  to improve their lives.
As to coping with higher  temperatures, restrictive energy policies send electricity prices skyrocketing,  making it harder for low-income households to afford air conditioning, and  putting lives at risk. They send poor families back to pre-AC misery of bygone  eras, like the 1896 heat wave that killed 1,300 people in New York City’s  sweltering tenements. In wintertime, they make heating less affordable, again  putting lives at risk.
I recently documented the  connection between energy policies and civil rights. My “Justice through  Affordable Energy for Wisconsin” report focuses on the Dairy State, where I grew  up. However, its lessons apply to every state, especially the 26 that get 48-98%  of their electricity from coal or have a strong manufacturing base. (The full  report can be found at www.CFACT.org)
Energy is the foundation for  America’s jobs, living standards, and everything we make, grow, eat, wear,  transport and do. Climate change bills, energy taxes and renewable energy  mandates deliberately restrict supplies of reliable, affordable hydrocarbon  energy – sending shockwaves through the economy.
Fossil fuels generate  three-fourths of Wisconsin’s electricity, keeping costs low and enabling its  $45-billion-a-year manufacturing sector to compete in a tough global  marketplace. Hydrocarbons sustain thousands of jobs in agriculture, tourism and  other sectors of the state’s economy. They ensure that hospitals and clinics can  offer high-tech diagnostic, surgical and treatment services.
They enable school districts,  families, churches, shops and government offices to operate in the black.  Soaring fuel and electricity prices would force schools to spend millions more  for buses, heating and lighting. That would mean higher taxes – or reduced  music, sports, language and special education programs. Poor and minority  neighborhoods would be impacted worst.
Small and minority businesses are  often young and undercapitalized. Increasing their operating costs, while  decreasing the disposable income of their customers, puts them on the verge of  bankruptcy.
“A single worker in our  Rhinelander fabrication plant can do the work of ten who do not have access to  cranes, welding machines, plasma burners and all other machinery that allows us  to cut, bend and fabricate steel up to six inches thick, and make all kinds of  heavy equipment,” says Oldenburg Group executive vice president Tim Nerenz. But  the machinery and facilities are energy-intensive. If energy costs rise, the  company would have to cut wages and benefits or lay off workers, as  contract prices are fixed and overseas competition is fierce.
Indoor pools and other facilities  make tourism a year-round industry, sustaining local economies during frigid  Wisconsin winters, making resorts like the Chula Vista Resort in Wisconsin Dells  popular jumping-off points for cross country skiing, snowmobiling and dining.  Rising energy costs would reduce family vacations, hammer bottom lines, force  layoffs, and cause foreclosures throughout these communities.
In every case, it is blue-collar  workers, low and moderate income families, minorities and the elderly that are  affected most severely.
Nor are these impacts likely to  be offset by “green” jobs. As Spain, Germany and other countries have  discovered, wind and solar power require constant infusions of money from  increasingly strapped taxpayers and energy consumers. When the economy sours,  the subsidies disappear, and so do the jobs.
Wind and solar electricity is  expensive, intermittent and unreliable – necessitating expensive gas-powered  backup generators, and further damaging family and business budgets. Plus, most  of the jobs will be in China and India, where low energy and labor costs, and  access to rare earths and other raw materials that America refuses to mine,  supply wind turbine and solar panel factories that easily under-price US firms.
The entire cap-tax-and-trade,  renewable energy and green-jobs edifice is a house of cards, propped up by  claims that humans are affecting the Earth’s climate. As EPA and EPA  Administrator Lisa Jackson repeatedly assert, “Climate change is already happening, and human activity is a  contributor.”
However, that is  not the issue. The issue is whether our use of fossil fuels is now the dominant  factor in global warming and cooling, and whether future manmade climate change  will be catastrophic. There is no replicable or credible evidence to support  that proposition.
Headline-grabbing disaster  scenarios forecast for 50 or 100 years in the future are the product of  speculation, assumptions, unreliable computer models, and articles by climate  activists falsely presented as peer-reviewed scientific papers in IPCC reports,  news stories and political speeches. As my Wisconsin study explains, they are  not supported by actual data and observations regarding historic and current  global temperatures, ice caps, glaciers, sea levels, rainforests or cyclical  weather patterns.
Energy taxes and  subsidies, renewable energy mandates, soaring prices for everything we need –  and severe impacts on families, businesses, jobs, opportunities, living  standards and basic civil rights – might be justified if we did indeed face a  manmade climate disaster. But even then we should carefully examine the costs  and benefits of any proposed actions.
We should determine  whether slashing fossil fuel use will stabilize our planet’s ever-turbulent  climate, and whether our limited resources might be better spent on adapting to  future changes, natural and manmade, just as our ancestors did.
If global warming science is  inaccurate, dishonest, slanted or fraudulent, there is even less justification.
We cannot have justice without  opportunity, or opportunity without energy. We cannot have justice by sharing  scarcity, poverty and skyrocketing energy prices more equally – especially on  the basis of erroneous, speculative or manipulated climate science.
We must therefore be forever  vigilant, to ensure that Congress does not slip cap-tax-and-trade proposals  through during a post-election lame-duck session – and EPA does not shackle our  economy and civil rights progress with its job-killing “endangerment” rules.
Paul  Driessen is senior policy advisor for the Committee For A Constructive Tomorrow  (CFACT) and Congress of Racial Equality (CORE), and author of  Eco-Imperialism: Green power – Black death.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e89bddb93',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

Oklahoma Attorney General Scott Pruitt’s nomination for administrator of the Environmental Protection Agency is as clear a signal as the incoming administration can send with regard to its environmental policies. 



It is also a sign that the administration is far more meticulous, internally consistent and thorough than its detractors have thought, and that it is on a clear mission not just to stop, but to reverse many of the actions of Obama’s EPA.



It is noteworthy that global warming was the second action item mentioned in President Obama’s 2009 inaugural, and that a mere 90 days later, the administration had issued a “preliminary finding of endangerment” from carbon dioxide and other greenhouse emissions.



Under their interpretation of the Supreme Court’s landmark 2007 climate change ruling, Massachusetts vs. Environmental Protection Agency, such a finding not only permitted the EPA to regulate carbon dioxide under the Clean Air Act Amendments of 1992, it compelled the agency to do so.





Fasten your seat belts, for we may be about to witness the scientific‐​cat fight of our time.



Seven years ago, on Pearl Harbor Day 2009, the administration announced its final Endangerment Finding. By March, Pruitt and 15 other state AG’s joined in a combined suit against it, which was ultimately not successful.



As long as the Endangerment Finding stands, any EPA, including one headed by Pruitt, will be in court defending against any subsidiary attempt to halt or reverse any regulation of carbon dioxide.



It may very well be held that the EPA remains responsible for regulation under the Supreme Court’s 2007 decision unless there is a specific act of Congress reversing its progeny policies, such as the Clean Power Plan. So the Endangerment Finding must be reversed.



But how to do it? For years, federal agencies have thrown massive support at scientists who, as human beings, serve their best interests (and their employer‐​universities) by generating horror‐​show results that also generate more support and professional advancement.



The Trump administration is going to have to stock up on scientists and administrators who are savvy to this game, and they are going to be very hard to find, as there’s very little incentive to not play along.



There’s going to have to be a massive effort to pick apart failing climate models and questionably‐​adjusted data. They’re going to have to find people willing to expose the current regime’s blatant abuse of logic in generating inflated “costs” of global warming, while largely ignoring the co‐​benefits of fossil fuel power, like doubled life expectancy and undreamt‐​of wealth.



The academy is going to howl, and Washington’s science lobbies, like the American Association for the Advancement of Science (headed by Democratic ex‐​congressman Rush Holt) are going to go berserk.



Fasten your seat belts, for we may be about to witness the scientific‐​cat fight of our time.



On one side will be a massive and entrenched establishment, defending models that we now know were (and this is truly shocking) often adjusted to give a predetermined result. On the other will be a dogged and far smaller clan, tearing apart the code of these models, much like the ENIGMA busters of Bletchley Park. This will get ugly.



In nominating Pruitt, the administration is signaling that it is clearly up to such a fight — and not just over climate change.



He is also on record as being against EPA’s most recent interpretation of Section 404 of the Clean Water Act, which was used to pre‐​emptively prohibit the owners of what may be the largest copper‐​gold‐​molybdenum deposit on earth, the Pebble deposit in southwestern Alaska, from even applying for a permit to mine. This, even though it is on land zoned for mining by the State of Alaska.



Our friends in the environmental movement should rightly be at Defcon Five. It appears that President‐​Elect Trump — in many ways just like his predecessor — is going to keep his environmental campaign promises, which means reversing eight years what many feel was an era of green overreach.



Remember that Obama said he would “bankrupt” anyone foolish enough to build a new coal‐​fired power plant, because he would render them unprofitable. That’s just what his Clean Power Plan does. Trump promises to nix it.



The nomination of Scott Pruitt is further evidence that the president‐​elect is serious, and circumstantial evidence that the influence of Al Gore’s recent visit was of little consequence.
"
"
by Jill Sakai, University of Wisconsin
Though still under construction, the IceCube Neutrino Observatory at the South Pole is already delivering scientific results — including an early finding about a phenomenon the telescope was not even designed to study.


This “skymap,” generated in 2009 from data collected by the IceCube Neutrino Observatory, shows the relative intensity of cosmic rays directed toward the Earth’s Southern Hemisphere. Researchers from UW-Madison and elsewhere identified an unusual pattern of cosmic rays, with an excess (warmer colors) detected in one part of the sky and a deficit (cooler colors) in another.

IceCube captures signals of notoriously elusive but scientifically fascinating subatomic particles called neutrinos. The telescope focuses on high-energy neutrinos that travel through the Earth, providing information about faraway cosmic events such as supernovas and black holes in the part of space visible from the Northern Hemisphere.
However, one of the challenges of detecting these relatively rare particles is that the telescope is constantly bombarded by other particles, including many generated by cosmic rays interacting with the Earth’s atmosphere over the southern half of the sky. For most IceCube neutrino physicists these particles are simply background noise, but University of Wisconsin-Madison researchers Rasha Abbasi and Paolo Desiati, with collaborator Juan Carlos Díaz-Vélez, recognized an opportunity in the cosmic ray data.
“IceCube was not built to look at cosmic rays. Cosmic rays are considered background,” Abbasi says. “However, we have billions of events of background downward cosmic rays that ended up being very exciting.”
Abbasi saw an unusual pattern when she looked at a “skymap” of the relative intensity of cosmic rays directed toward the Earth’s Southern Hemisphere, with an excess of cosmic rays detected in one part of the sky and a deficit in another. A similar lopsidedness, called “anisotropy,” has been seen from the Northern Hemisphere by previous experiments, she says, but its source is still a mystery.
“At the beginning, we didn’t know what to expect. To see this anisotropy extending to the Southern Hemisphere sky is an additional piece of the puzzle around this enigmatic effect — whether it’s due to the magnetic field surrounding us or to the effect of a nearby supernova remnant, we don’t know,” Abbasi says.
The new result publishes Aug. 1 in The Astrophysical Journal Letters, published by the American Astronomical Society.
You can read the rest of the article here…


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a10a901',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"The UN’s proposed sustainability targets are riddled with conflicts that could make them ineffective or outright harmful.  In theory, there is nothing wrong with such targets. After all, the Millennium Development Goals (MDGs) had mixed success on health, education and poverty but established the principle that measuring key indicators was a good way to at least begin tackling major issues. Now, with increasing concern over environmental degradation and climate change the Sustainable Development Goals (SDGs) are currently being negotiated as the successors to the MDGs.  Despite a huge effort in setting these goals, the compartmentalisation of major areas such as energy, water and the economy means that they are already in conflict – and this is before climate change is even added. The latest set of sustainability goals was drafted by a UN working group and presented to the UN General Assembly in September. What we have ended up with is a set of 17 goals, each with various sub-goals, which cover everything from poverty and education to water, climate change and sustainable cities.  While at first glance they appear comprehensive and ambitious, further examination reveals a potentially dangerous lack of understanding of how the different goals will affect each other. As the whole range of goals is so large, we’ll just focus on the interaction between the water, energy and climate change goals. In the official language, those goals are: Goal 6: Ensure availability and sustainable management of water and sanitation for all Goal 7: Ensure access to affordable, reliable, sustainable, and modern energy for all Goal 13: Take urgent action to combat climate change and its impacts Goals 8 and 9 on economic growth and “sustainable” industrialisation are phrased in such a way that they will impact most others, so we’ll consider them too. The above graphic illustrates the ways in which the three goals might affect each other and not always in a positive way. The conflicts are caused, to some degree, by the very nature of the goals.  The water goal focuses on water provision and access to modern water services. The proposed model of provision is  very Western, based on large infrastructure projects, low levels of water re-use and high energy use.  For example, achieving universal access to drinking water and sanitation could be achieved by expanding desalination and waste-water processing, both of which are highly energy intensive. So achieving the water SDGs seems likely to increase energy use, undermining other goals. The energy goal itself appears to be lifted from Ban-Ki Moon’s Sustainable Energy for All initiative. The concern is that it prioritises access and affordability and the very word “sustainable” is absent from the sub-goal that states: “by 2030 ensure universal access to affordable, reliable, and modern energy services”. Without sustainability within this goal, the risk is that countries will focus on coal or gas to ensure they achieve it. This is compounded by the unambitious and vague goals around renewable energy: “increase substantially the share of renewable energy in the global energy mix by 2030” and “double the global rate of improvement in energy efficiency by 2030”.  We would hazard to suggest that, if globally we only “substantially increase” renewable energy share and the rate of energy efficiency improvement (both are only relative, not absolute, targets), then there is very little chance of meeting the climate change SDGs. Energy production and industry also use lots of water, making the water access goals harder to achieve. In both cases, it is the concrete, tangible targets that don’t take into account sustainability and environmental impact. For other “aspirational” goals, such as:  Goal 6.6: By 2020 protect and restore water-related ecosystems, including mountains, forests, wetlands, rivers, aquifers and lakes. It’s hard to say what it might look like in practice, or how it is to be measured. Is it compatible with 6.1: “By 2030, achieve universal and equitable access to safe and affordable drinking water for all”? All that affordable water has to come from somewhere; that somewhere probably means rivers and lakes full of plants and fish and potentially unsustainable new dams or reservoirs. Even aside from the cross-SDG conflicts, the problem with the climate change goals is they do not exactly exist yet. Goal 13 acknowledges that the UN Framework Convention on Climate Change is the international forum for setting climate change targets. However slow progress in negotiations means that the new targets from the UNFCCC will not be agreed until after the official announcement of the SDGs in September 2015.  Of course, as our graphical analysis suggests, if national governments choose to prioritise goals such as: 8.1: Sustain per capita economic growth in accordance with national circumstances, and in particular at least 7% per annum GDP growth in the least-developed countries. and  9.2: Promote inclusive and sustainable industrialisation and by 2030 raise significantly industry’s share of employment and GDP in line with national circumstances and double its share in LDCs [least developed countries]. then all other actions will be constrained. In such a scenario, it seems unlikely that the goals on water, energy or climate change will be achieved.  Such absolute, rather than qualified, targets for economic growth and industrialisation are extremely likely to lead to greater levels of energy demand, water use and GHG emissions. Such confusion emphasises the persistent lack of an environmental, climate change or sustainable development champion within the UN system. If it is left to the existing UN organisations to achieve the targets in their focus areas without sufficient dialogue and co-operation we are likely to see some unexpected and unwanted results. What is now required is a thorough assessment of what checks can be put in place to ensure that the Sustainable Development Goals are genuinely sustainable, as well as what potential negative interactions could take place between the goals. Without this, we might have some goals but we won’t have sustainable development."
"

 ** _State legislatures should_**



• enact punitive damages reforms;  
• eliminate joint and several liability;  
• strengthen judicial review of dubious expert testimony; and  
• prohibit government litigants from engaging private attorneys on contingency fee.



 ** _Congress should_**



• restore meaningful sanctions for meritless litigation in federal court;  
• constrain courts’ long‐​arm jurisdiction over out‐​of‐​state defendants;  
• enact a federal choice‐​of‐​law rule for multistate litigants in product liability cases; and  
• implement further reforms for class actions that cross state lines.



 ** _Both state legislatures and Congress should_**



• strengthen the role of contract and consent‐​based alternatives to tort litigation, including predispute arbitration, venue selection, disclaimers of liability, and assumption of risk.



Although America has long been considered a litigious nation, its lawsuit sector really took off after the 1960s, following changes in the law aimed at making it easier to sue. As a share of the U.S. economy, tort costs are two‐​and‐​a‐​half times as high as in Western Europe and four times as high as they were after World War II. The direct cost of American tort litigation is upward of $250 billion a year, a figure that does not include important categories such as securities litigation and the multistate tobacco settlement. In a global marketplace, that means costs are not competitive, business investment is discouraged, there are fewer jobs, and wealth is reduced.



Widely shared discontent over the many ill effects of litigation has made lawsuit reform a popular issue at both state and federal levels. At the state level, advocates have enjoyed considerable success. For example, with California’s Medical Injury Compensation Reform Act in the lead, most states have enacted curbs on medical malpractice litigation. The result has been a turnaround in what was once a soaring rate of claims and insurance rate increases associated with that sector.



At the federal level, reform has faced tougher resistance. It is true that Congress has enacted two broad‐​based reform laws, applying to securities litigation and to multistate class actions, as well as a number of more specialized bills pertaining to specific areas, such as gun liability and small aircraft liability. One reason the federal government has not taken the lead in more areas is that the predominant share of injury litigation goes on in state courts, rather than federal. Under our constitutional structure, though the federal government does play some role in supervising state courts (for example, when they infringe on constitutional rights, or when one state rules on matters affecting the rights of residents of other states), that role does not extend to broadly displacing state authority over conventional, usually smaller, in‐​state disputes.



Because of the strong ongoing interest in state‐​level reform, lawmakers can choose from a large menu of ideas that have proved themselves in other states. Here are four.



First, states should limit or abolish the availability of punitive damages in civil cases. One good beginning would be to limit them to cases involving actual malice, intentional wrongdoing, or gross — as distinct from ordinary — negligence. Punitive damages share some of the functions of criminal law, and thus call for — yet commonly lack — procedural protections that parallel those afforded criminal defendants. Among those protections is a higher burden of proof than the usual civil standard, which is preponderance of the evidence. Another is double jeopardy protection. Current rules allow punitive damage claims over the same conduct to be made again and again in multiple lawsuits. Another is protection against coerced self‐​incrimination by way of compulsory discovery. Many modern jurisdictions do not allow civil claims for punitive damages at all.



Second, states should dispense with joint and several liability. That’s the “deep pockets” rule that permits plaintiffs to collect all of a damage award from any one of multiple defendants, even if the paying defendant was responsible for only a small fraction of the harm. The better rule is to apportion damages in accord with defendants’ degree of culpability.



Third, holdout states should join the predominant trend toward stronger judicial review of expert testimony (so‐​called Daubert review, after the leading Supreme Court case) to cut down on speculative litigation based on flimsy scientific premises.



Fourth, contingency fee contracts between private lawyers and government entities should be prohibited. Private lawyers acting on behalf of government should bear the same ethical responsibility as in‐​house government lawyers — as public servants beholden to all citizens, including the defendant, and obliged to seek justice. Imagine a state attorney receiving a contingency fee for each indictment, or a state trooper receiving a bonus for each speeding ticket. Contingency fees are equally corrupting.



The Constitution foresees a number of roles for Congress in supervising civil litigation. The least controversial is Congress’s power to prescribe rules for the handling of lawsuits brought in federal courts and those based on the federal government’s own laws. One example is sanctions against meritless litigation in federal courts under so‐​called Rule 11. Congress should enact a measure restoring strong sanctions, which were unwisely cut in 1993 after a decade‐​long experiment in vigorous sanctions. Sanctions should be based on the monetary cost of responding to meritless claims and motions, as specified in the bill known as the Lawsuit Abuse Reduction Act.



Congress also has considerable power to supervise the doings of state courts — for example, when those courts violate litigants’ due process, impair the obligation of contract, or abridge the privileges and immunities of citizens of other states. But its power is not “plenary,” or unlimited; it may act only when it can cite constitutional authority. Some proposals for federal‐​level malpractice reform, for example, are unwisely premised on broad New Deal readings of the power to regulate interstate commerce.



On a practical level, not every national problem requires a federal solution. Most states have capped damages in health care suits, with favorable results for their climate of medical practice, and virtually all have at least considered reforms. In the long run, excessive lawsuit recoveries by in‐​state plaintiffs against in‐​state doctors over in‐​state therapy are likely to generate in‐​state political pressure for reform. The substantive rules of tort law are not commerce, and proposals to override them with federal law because they have some indirect effects on interstate commerce have no obvious stopping point. Congress is better off focusing its energy on lawsuits in which a state is tempted to assert its sovereignty beyond its borders through its courts. Federal procedural reforms do have an important role to play in curbing that behavior.



A guiding principle in supervising interstate litigation is that federal lawmakers and courts are authorized to act when there is a high risk that states will appropriate wealth from the citizens of other states. One federal reform consistent with that principle is to amend the currently lax and ambiguous rules that control state exercise of so‐​called long‐​arm jurisdiction over out‐​of‐​state businesses. Congress might, for example, preclude a local court from hearing a case unless the defendant engages directly in business activities within the state. A company’s mere awareness that the stream of commerce could sweep its product into a particular state should not suffice to confer jurisdiction. A sensible rule would give firms an exit option — that is, they could withdraw from a state and thus avoid the risk of a runaway jury, even if a product somehow ends up in the state.



A second federal reform compatible with federalist principles is a federal choice‐​of‐​law rule to prescribe which law governs in cases where plaintiff and defendant in product liability cases are from different states. It might provide that the applicable law is that of the state where the manufacturer was located, or where the product was first sold to a consumer. Consumers would be on notice of the system and could evaluate the rules, if of a state other than theirs, when deciding whether to buy a particular manufacturer’s product. States would be more likely to balance the voting interest of in‐​state consumers against the in‐​state benefit of a healthy retail or manufacturing sector. In effect, competition among the states would enlist federalism as part of the solution to bad incentives.



Multistate class actions were once a rarely used procedural device designed to litigate an assemblage of largely identical claims. In the last half century, they have morphed into a commonly used device for bundling cases that are often quite dissimilar but which together may command a higher settlement value and steering them into a favorable court.



The 108th Congress attempted to address the latter problem in the Class Action Fairness Act of 2005 (CAFA) by giving defendants the power to remove some class suits from state to federal courts. Although helpful, CAFA left unresolved many issues that courts have had to address through prolonged litigation. Congress should clarify CAFA’s gaps and advance the fairness of the process in ways that go beyond the 2005 law. Following are three suggestions to address gaps and four suggestions to go further.



First, under CAFA, a class action can be removed to federal court so long as at least one‐​third of the class members reside outside the state where the suit was filed and the amount at stake overall exceeds $5 million. The amount‐​in‐​controversy threshold, in particular, occasions needless litigation since plaintiffs’ damage theories at the outset of a case may lack specifics. Congress can and should clarify what types of evidence and level of certainty are needed to establish a basis for removal. In general, because most national class actions do seek more than the $5 million threshold, Congress should set a rebuttable presumption in favor of removal for national classes.



Second, the key make‐​or‐​break stage in a case is typically the motion for class certification. CAFA did not explicitly provide that one federal court’s denial of certification bars attempts to relitigate the question before other federal courts. Congress should spell out that federal courts have power to enjoin multiple bites at the certification apple when one has been adequately argued.



Third, CAFA does not provide a means for removal of cases in which plaintiffs’ lawyers and defendants, in effect, collude against the interests of the class. At present, if they have in mind what is known as a “sweetheart settlement” — one in which the lawyers get a big payoff, defendants get a slap on the wrist, and absent class members recover little or nothing — they can file in a friendly state court and simply not file removal. Congress should provide that absent class members, and not just defendants, can file for removal.



Beyond plugging gaps in CAFA, Congress should seize the opportunity to rethink the class device itself in its current form. The present rules create a presumption that individuals out of court, who have not affirmed their connection to the class, favor being represented on nothing more than the say‐​so of the trial lawyer who steps forward to file the action. Modern class‐​action lawyers often claim to represent the interests of thousands or even millions of people who have no idea that they are litigants at all.



Lawmakers should take four steps to confine class actions to the kinds of cases in which they can best advance justice:



1\. Class action rules should require would‐​be litigants to affirmatively _opt in_ to a class action (for example, by mailing a consent form to the court) before being counted as part of the class.



2\. Class action rules should assure defendants of their due process right to assert defenses that may apply to some but not other individual plaintiffs. Presently, classes are certified even when a governing statute or common‐​law rule requires that key elements of proof — such as reliance, causation, or damages — be shown on an individual basis. That means trial lawyers can use the class device to combine tens of thousands of factually dissimilar claims into one proceeding, making it impossible for defendants to adequately smoke out and identify weak or meritless individual claims. Congress should enact a rule stating that, unless a statute clearly provides otherwise, certification and liability in class actions arising under federal law require proof as to all class members of all the elements of each claim.



3\. Lawmakers should act to head off the problem of certification of classes in low‐​merit cases. Class certification decisions are made very early — before plaintiffs have demonstrated that they have evidence to support their allegations. That allows trial lawyers to game the system by filing cases that are extremely unlikely to succeed at trial, but for which the sheer monetary risk generated by a million‐​member class generates settlement value: Why take even a 1‐​in‐​20 risk of a fluke jury outcome if the stakes are of bet‐​the‐​company magnitude? Congress should nip meritless class actions in the bud by providing that classes may be certified only after the class “representative” — the main plaintiff — is able to make a preliminary factual showing that he or she has a reasonable likelihood of success.



4\. Congress must clarify when, if at all, class actions may go forward on the basis of statistics. Class actions generally must be proved using evidence “common” to all class members, but some federal statutes allow statistical sampling to prove injuries to a large group. Where this is so, plaintiffs sometimes have gotten away with shoddy statistics purporting to show that all class members suffered the same injury. Congress should provide that, before a class action can go forward, plaintiffs’ statistical evidence must meet the same demanding reliability standards imposed on expert evidence sent to a jury.



Allowing parties to set the terms of their own deals reduces the uncertainty that gives rise to litigation and advances the values of individual choice. Yet too often courts and legislators have been hostile to waivers and disclaimers of liability and to contractual provisions that seek to prescribe methods of handling disputes before they arise (such as agreements to arbitrate or mediate, venue selection clauses, and clauses excluding class action treatment of a claim). Arbitration in particular is under attack from organized trial lawyers who would prefer all‐​out, open‐​ended litigation as an alternative. Both state and federal lawmakers should defend consumer arbitration.



Courts and lawmakers have also neglected the vital doctrine of assumption of risk, which gives legal force to the choice consumers make to engage in risky activities, such as recreation. Legislators should act to bolster assumption of risk, where appropriate, by codifying doctrines like the “baseball rule” (spectators at a ball game assume the risk of balls hit into the stands) and suitable doctrines limiting liability for ordinary risks experienced by skiers, hikers, and others in search of recreation.



For the most part, the states have reformed and are continuing to reform their civil justice systems. Under those circumstances, time‐​honored principles of federalism dictate that each state exercises dominion over its substantive tort law. Still, Congress does have appropriate roles to play, both in setting a good example with federal‐​court litigation and in restraining states from exercising inappropriate jurisdiction beyond their borders or discriminating against out‐​of‐​state businesses.



American Tort Reform Foundation. _Judicial Hellholes 2015–2016_. Washington: ATRF, 2015.



Copland, James R. _Trial Lawyers, Inc.: Mass Torts and Class Actions_. New York: Manhattan Institute, 2016.



Judiciary Committee, U.S. House of Representatives. “Lawsuit Abuse Reduction Act of 2013.” Report 113–255. Washington: Government Publishing Office, 2013.



Levy, Robert A. _Shakedown: How Corporations, Government, and Trial Lawyers Abuse the Judicial Process_. Washington: Cato Institute, 2004.



Moller, Mark K. “Common Problems for the Common Answers Test: Class Certification in _Amgen_ and _Comcast_.” _Cato Supreme Court Review: 2012–2013_ , 2013.



—. “Controlling Unconstitutional Class Actions: A Blueprint for Future Lawsuit Reform.” Cato Institute Policy Analysis no. 546, June 27, 2005.



Olson, Walter K. _The Litigation Explosion_. New York: E. P. Dutton, 1991.



Olson, Walter K., and occasional guest contributors. “Overlawyered.” Cato blog on the American legal system, 1999‐​present.



Redish, Martin, and Nathan D. Larsen. “Class Actions, Litigant Autonomy, and the Foundations of Procedural Due Process.” _California Law Review_ 95, no. 1573 (2007).



Trask, Andrew. “Litigation Matters: The Curious Case of _Tyson Foods Inc. v. Bouaphakeo_.” _Cato Supreme Court Review: 2015–2016,_ 2016.
"
"
I am delighted to report that “Our Climate” made it to the Number 1 paid weather App position in the Canadian iTunes store (out of 570 paid weather apps)!   It took only 40 hours to get there. See screen shot below:
click to enlarge
See my review here: New “Our Climate” iPhone app released
“Our Climate” is number 2 in both Norway and the UK,  and number 3 sales rank in the US for ITunes Weather Apps. It has broken into the top 10 list for iPhone Weather Apps in 7 countries already. To help sustain that growth, I have created a sidebar widget for those that wish to help promote it. See below.

Apple has also put “Our Climate” in the number 1 position in their “New and Noteworthy” featured panel (in the weather app category ) in a number of iTunes jurisdictions, including the US, the UK, Australia, the Netherlands and Canada.
In the countries where the App is gaining user reviews, it is generally (read: invariably) gaining 3.5 to 5 stars average ratings.  This is reflective of very good customer satisfaction metrics.  In addition the software is proving highly stable with no reported crash logs.
The list below is a sampling of how we are doing in various countries so far.
Brackets denote current sales rank in ITunes “top paid weather apps”
Featured in New and Noteworthy (generally number one spot – top left):

Australia  (5)
Canada   (1)
Netherlands  (12)
New Zealand (9)
UK (2)
US  (3)

Not featured in New and NoteWorthy, but good sales rank

Norway (2)
Sweden  (6)

New link widget:
To help this app get wide exposure, I’ve created a link widget for anyone to place in the sidebar of their website. Feel free to copy/paste either of these. Free use granted to everyone.
Pixel size 180×340

HTML CODE: (be sure to cut n’ paste into text editor, then past into your website from there to prevent character formatting issues)
<a href=”http://itunes.apple.com/app/our-climate/id371849150?mt=8″ target=”_blank”><img title=”OurClimate for iPhone – click for details” src=”http://wattsupwiththat.files.wordpress.com/2010/07/ourclimate_iphone_screen_drop2.jpg” alt=”” width=”180″ height=”340″ /></a>

With App Store logo (180×400):

HTML CODE: (be sure to cut n’ paste into text editor, then past into  your website from there to prevent character formatting issues)
<a href=”http://itunes.apple.com/app/our-climate/id371849150?mt=8″  target=”_blank”><img title=”OurClimate for iPhone – click for  details”  src=”http://wattsupwiththat.files.wordpress.com/2010/07/ourclimate_iphone_screen_drop3.jpg”  alt=”” width=”180″ height=”340″ /></a>

Or if you just want to provide a link:
http://itunes.apple.com/app/our-climate/id371849150?mt=8
==============================================
UPDATE: For those people that are unable to cut/paste into your blog, please read this.
I’ve tested this HTML. It works.
You have to paste into web pages and blogs as HTML, using the HTML editor of the website. To do that you must first copy the HTML above and paste it into a text editor like Notepad, and then copy and paste into your blog/website HTML editor.
Just pasting the text above into the regular content editor won’t work. You have to switch to HTML editing where you can see all the tags and text.
Failing that, select one of the images, and copy/paste into your content editor.
It really is easy, millions have done it. Just give it a try. – Anthony

Sponsored IT training links:
Subscribe for 642-436 online training and pass your PMI-001 and 70-432 certification exam on first attempt.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e89d03488',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

For nearly a century, Californians have fashioned themselves the innovators the United States and the world follow. Not so on global warming. The California Legislature and Governor Schwarzenegger have just passed and signed global warming legislation that looks an awful lot like a watered‐​down version of the failed Kyoto Protocol. That’s soooo 1990s. 



Kyoto was supposed to reduce our emissions of carbon dioxide, the main human‐​generated global warming gas, to 7% below 1990 levels by 2008–2012. Nationally, carbon dioxide emissions have risen about 18% since then. California legislation cuts state’s emissions to 1990 levels by 2020, a much larger effective cut than Kyoto because of expected population growth in the next fifteen years. 



Why on earth did they do this, and what will it accomplish? 



California’s global warming legislation is all politics. Arnold is up for re‐​election, and California is (and has always been) politically green. Hint: “Sierra Club” stands for Sierra Nevada Mountain Club. While everyone back east pretty much yawns over its antics, people in California pay attention to it much the same way Euros worship Greenpeace (another organization simply ignored here). 



Greens are in record high dudgeon over global warming. Al Gore’s movie has them pumped. The California public is alarmed, and scientists don’t see any incentive to quell the hysteria — after all, it’s quite a living. So it’s totally logical that there has been a political response. 



Specifically, the current clamor revolves around a scientific absurdity: that unless we drastically cut our emissions of carbon dioxide in the next nine years, there will be an irreversible climate catastrophe caused by the rapid shedding of Greenland and Antarctic ice. (While climate populists still say “ten years,” they’ve been making this claim for a year now. Time marches on.) 



It’s science fiction. The slight loss of Greenland ice in the last few years is hardly unprecedented. Its cause is thought to be a reversal of a fifty‐​year cooling trend that ended in the late 1990s over the southern (melting) part of the landmass. For several decades in the early 20th century — before humans could be considered a factor in climate change — Greenland was much warmer than it has averaged in the last decade. Look for yourself. The UN’s climate history is at this site. 



In the early 20th century, Greenland had to have been shedding ice at a much higher rate than it is today (or, God forbid, today’s loss isn’t being driven by warmer temperatures!), and indeed this is documented. Check out “The Present Climate Fluctuation,” published in 1948 by Hans Ahlmann, in _Geographic Journal_ , a peer‐​reviewed periodical of the Royal Geographical Society. 



Antarctica? Suffice it to say that every recent climate model for the 21st century predicts that it will gain, not lose, ice. 



Another big driver of the current hysteria is the notion that hurricanes are getting worse because of global warming. Again, there’s little that’s unprecedented. Today’s frequency of Category 4 and 5 storms, the worst kind, is mathematically indistinguishable in the Atlantic and Western Pacific (the world’s most active hurricane regions) from what it was a half‐​century ago…right around the time Ahlmann published his paper. 



The idea is simple. Warmer water yields more energy for stronger storms. But that notion is simplistic, as other factors that correlate with warmer water serve to mitigate storms. 



Further, the oceans just haven’t been cooperating recently. An upcoming paper by John Lyman in _Geophysical Research Letters_ has the scientific cheerleaders for Gore’s apocalypse worried. It shows, inexplicably, that in the last two years the world’s oceans lost 20% of the heat they had gained in the last half century. 



It’s easy to say that California’s global warming bill rests on nonsensical overkill. But if people insist that all of these horrible things are being caused by global warming, what will California’s leadership do about it? 



The answer, in the rosiest of policy scenarios, is easy: absolutely nothing. Further, if global warming is bad on the whole (a debatable hypothesis), California’s law could easily make things worse. 



Let’s be really rosy, and say that California does lead the nation, and Congress passes a similar law. Further, let’s say that California leads the world, and every nation that has to reduce emissions under the Kyoto Protocol — quotas that virtually no one has met — indeed adopts and meets the California mandates. According to scientists from the U.S. National Center for Atmospheric Research, the amount of global warming the law would prevent by 2060 is .05 degrees Celsius. That’s right, one‐​twentieth of a degree. 



That’s a reasonable estimate, because Kyoto is predicted to prevent .07 degrees of warming along this timeframe, and California’s law doesn’t reduce emissions quite as much as Kyoto. But in any case, there’s no network of global thermometers or satellites that will ever be able to detect such a change, because global surface temperature fluctuates about .15 degrees Celsius from year to year. 



Will California itself meet its own legally imposed emissions limits? Doubtful, unless there will be some chicanery whereby carbon dioxide is fobbed off on, say, power plants in neighboring states. California would have to reduce its emissions substantially while, thanks to immigration, its population rises rapidly. The entry‐​level car for entry‐​level Californians will not be a $30,000 hybrid. While the chi‐​chi may buy them, they will sell their existing cars to the newcomers. Thanks to California’s climate, those beaters will live long lives in the Golden State. 



If people think that current hurricanes are being juiced by global warming, if they think that the calving of Greenland is unprecedented (despite decades of warmer temperatures in the early 20th century), then they will expect some return for their grief. But hurricanes will continue, and more people will be exposed to them. The earth’s temperature trajectory won’t be altered a measurable iota. Despite their efforts to lower emissions, people will see absolutely no current weather change that could possibly be ascribed to this policy. 



Basing policies on hysterical exaggerations is a sure recipe for failure, particularly when the policies will do nothing but sour people on carbon dioxide emission restrictions. So much for Californian leadership. Sounds much more like politics as usual: full of sound and fury, accomplishing nothing. How retro.
"
"In proposing a 30% rather than a 40% energy demand reduction target, the European Commission is increasing the risks that European Union member states face from fossil fuel dependence and slowing the economic and social benefits of better insulated homes and lower energy bills. The EU should have the courage to adopt a legally binding target of 40% energy savings by 2030 as was originally proposed. This would ensure that all member states introduce effective energy efficiency policies and would reinforce the EU’s leadership role in reducing carbon emissions and preventing dangerous climate change.  The proposed 30% target suggests a weakening of political commitment. Several studies have shown how the technology and strategies are available to achieve more ambitious reductions without imposing a burden on the economy. For example, there are already cars currently available that are 40% more fuel-efficient than the current EU standard – and changes in design and materials can reduce emissions by more than 40%.  A legally binding 40% target would potentially reduce EU gas imports by up to 40% compared to 2010, roughly equivalent to the amount of gas currently imported from Russia. It would reduce household energy bills through improved energy efficiency, lowering levels of fuel poverty and reducing the effects of poor-quality housing on health. And it would reduce the scale of investment in renewable energy infrastructure by reducing energy demand. A binding target would ensure political commitment to the task of developing effective energy-efficiency policies and provide long-term confidence for investors delivering commercial goods and services for energy efficiency. It would also drive innovation in energy-efficient products, opening up market opportunities for EU industries around the world. Why adopt a target as well as energy efficiency policies? Improving energy efficiency is the cheapest and fastest way of reducing carbon emissions, while at the same time providing economic, social and environmental benefits. Without an ambitious overall energy-efficiency target it’s unlikely that member states would unlock these benefits. Nor can these benefits be achieved through the carbon price delivered through the EU emissions trading scheme. An aggregate target helps ensure that energy savings in one area are not offset by the rebound effect of increased energy demand in another. A legally binding target at the EU level would help ensure that progress is monitored, action is taken and results achieved. None of this is incompatible with the emissions trading scheme provided the appropriate steps are taken to ensure a minimum carbon price. A 40% target is within our grasp, technically and economically, and would send a strong message that EU intends to lead on these issues. Regional instability in North Africa, the Middle East and now Ukraine has shown time and again that over-reliance on imported fossil fuels makes countries vulnerable to price shocks and supply interruptions. We need to reduce those risks and at the same time protect the climate. Improved energy efficiency comes top of the list for cost-effectiveness and wider benefits. Recent progress has demonstrated that significant reductions in energy consumption can be achieved while maintaining productivity and quality of life – UK energy consumption fell by 12% between 2000-2012, while GDP increased by 58%. Improvements in technology and changes in behaviour will make a 40% reduction by 2030 not only desirable but entirely achievable. But it must be backed up by political commitment."
"Hail, heavy rain, lightning and flash flooding – not necessarily typical summer weather in southeast England. But the recent unexpected deluge saw homes evacuated, stations flooded, and road and rail services interrupted. According to the Met Office, more than half the monthly average total rainfall fell in just an hour. In Hove, Brighton and Worthing, the storm kicked off with a particularly heavy hailstorm leaving many waking up to positively wintry scenes. Such unexpected weather, described as “extreme” in nature, has prompted many to declare that freak weather events are becoming more common and more damaging. But is this really the case? The Met Office is an important source of information on the history of weather extremes. Its national weather records can help put current events into an historical context. However, while it can be difficult to make sense of historical meteorological information, the records held at city and county record offices, libraries and archives can provide a human dimension, transforming meteorological data into stories of people and communities. Those in Sussex affected by the storm used Twitter to share reactions and experiences, whereas in the past letters, diaries, newspapers and official documents recorded the effects of extreme weather. With this documentary archive stretching back hundreds of years we can investigate how one event was described in relation to another, and whether and why they were judged to be unusual or extreme.  The records of Leicestershire County Quarter Sessions document the huge community response to a “dreadful storm of hail” on July 28 1814. A committee was formed to collect subscriptions to provide relief for those who had suffered losses from the storm. From the committee’s papers we know that William Collishaw of Birstall lost a quantity of the fruit from his orchards in the storm, and that John Blockley lost wheat, potatoes, onions and peas to the value of £106.  The same storm is also recorded in the diary of Peter Pegge-Burnell of Winkburn Hall, Nottingham:  Dull close morn betwixt one & two, loud thunder, some lightg & heavy showers – about six in the afternoon came on the most dreadful hailstorm I ever beheld – a number of hailstones pointd and as large as my thumb end – or first joint – sometime after a continuation of some hours of vivid flashing & constant thunder, a deluge of heavey rain followed – the damage by this horrid storms to my corn, hay, garden & windows is very considerable – thank God no lives lost as I have heard. Joseph Woolley, a framework knitter and stocking maker from Nottingham, recorded a hailstorm in his diary entry for August 11, 1809 in which he notes “hail stones seven inches long,” breaking windows in a number of houses at Beeston Rylands.  Records from the Edgbaston Estate papers include a letter from a tenant, E. Whigg, to his landlord’s agent Charles Yates informing him that the severe hailstorm of August 1846 “completely destroyed the windows in the front of our house” and suggesting a change in design (a suggestion rejected by his Landlord). On July 25, 1900 the Haverfordwest and Milford Haven Telegraph reported on a “terrible hailstorm in Northampton”, when “those of the bigness of the thin-shelled English walnut were the average but hail-stones as big as hens’ eggs were in abundance”. So extreme summer hailstorms are not without historical precedent in the UK, as recorded in descriptions found in diaries, letters, official documents and newspapers. With many accounts of the same event, it’s possible to build a picture of how people responded. It’s also possible to build up a picture of how certain events enter a community’s cultural memory – the extremely cold and snowy winter of 1947, the extreme heat of the summer of 1976, and the extreme floods of 2007 – while others are quickly forgotten.  In a letter to Lord Manvers dated February 14, 1795, William Sanday at Holme Pierrepont in describing a flood in Nottingham refers back to an earlier flood:  We have had a most dreadful flood upon the River Trent; it was 3 feet one inch higher than the Midsummer flood, which happened between 50 & 60 years ago; this was ascertained from a mark then made, and which still remains.  Like many accounts of extreme weather events, William Harwood’s diary entry for February 11, 1795 refers directly to flood memory, “SW wind fine day, the largest flood upon the Trent ever remembered.”  Different ways of recording the past transmit information and awareness of extreme weather across generations, beyond the memory of individual lives. Being aware of extreme events that have occurred in the past can help people comprehend the problems of risk and uncertainty in the face of extreme weather events now and in the future."
"**There have been more than 1.6 million confirmed cases of coronavirus in the UK and about 60,000 people have died, government figures show.**
However, these figures include only people who have died within 28 days of testing positive for coronavirus and other measures suggest the number of deaths is higher.
**Find out how the pandemic has affected your area and how it compares with the national average:**
If you can't see the look-up click here.
After the first peak in April, cases started rising again in July, with the rate of growth increasing sharply in September and October, before falling again in the past two weeks.
On Wednesday, the government announced a further 16,170 confirmed cases.
It is thought the infection rate was much higher during the first peak in spring, but testing capacity at the time was too limited to detect the true number of daily cases.
The data for cases can also be broken down by region and comparing the change in those figures by week gives a sense of where there has been a recent increase in newly-reported infections.
Coronavirus infections in England have fallen by about a third during lockdown, according to a major study carried out by Imperial College London.
While some of the worst-hit areas saw the biggest improvements, cases have remained relatively high across England, according to the React-1 study, which is based on tests of more than 100,000 people between 13-24 November.
The latest figures from the Office for National Statistics (ONS), suggest about one in 185 (16,400 people) in Wales had the virus in the week ending 21 November.
In Northern Ireland rates are thought to be decreasing at around one in 145 people (about 12,700 people), while in Scotland, the figure was one in 115 (about 45,700 people).
The average number of daily deaths began to rise again in September, following the first peak in April.
On Wednesday, the government announced a further 648 deaths.
Of these, 555 deaths were in England, 51 in Wales, 38 in Scotland, and four in Northern Ireland.
Rules were amended over the summer to include deaths in the coronavirus total only if they occurred within 28 days of a positive test. Previously in England, all deaths after a positive test were included.
England has seen the majority of UK deaths from Covid-19. Using the 28-day cut-off, there have been more than 52,000.
Although hospital admissions for Covid-19 remain below the levels seen in the spring, there are big regional disparities.
The North West, North East and Yorkshire, and Midlands have seen the highest number of admissions but the situation in all three now appears to be improving.
Cases have risen across large parts of England, with other spikes in areas of Scotland, Wales and Northern Ireland.
The red areas on the map below are those currently seeing the highest number of cases per 100,000 people.
Restrictions have been tightened across the UK in an effort to tackle the number of rising cases.
In England, each local authority has been placed in one of the new three tiers following the end of the recent national lockdown.
Wales has announced a range of further measures, including a ban on pubs, restaurants and cafes serving alcohol, from Friday 4 December.
In Northern Ireland, a further two-week ""circuit-break"" lockdown began on 27 November.
Scotland has a five-tier system of alert levels with different measures in place in different parts of the country.
UK leaders have agreed to allow up to three households to meet indoors during a five-day Christmas period of 23-27 December.
When looking at the overall death toll from coronavirus, official figures count deaths in three different ways.
Government figures count people who died within 28 days of testing positive for coronavirus.
But there are two other measures.
The first includes all deaths where coronavirus was mentioned on the death certificate, even if the person had not been tested for the virus. The most recent figures suggest there had been almost 70,000 deaths by 20 November.
The second measure counts all deaths over and above the usual number at the time of year - that figure was more than 75,000 by 20 November.
The most recent figures available from the ONS are for the third week of November, which show there were 14,276 deaths registered in the UK.
Some 3,038 of these deaths involved Covid-19 - 199 more than the week before.
Deaths normally do rise at this time of the year, but the data from the ONS and its counterparts in Scotland and Northern Ireland show the second wave of the virus has pushed the death rate above the average seen over the past five years by about 21%.
Overall, the figures are still well below the peak of 9,495 deaths recorded in a week, reached on 17 April.
The ""R number"" is the average number of people an infected person will pass the disease on to.
If R is below one, then the number of people contracting the disease will fall; if it is above one, the number will grow.
The government's current estimate for the R number across the whole of the UK is 0.9 to 1.
The estimate for England is 0.9 to 1, while for Scotland it is 0.8 to 1. The estimate for Wales is 0.8 to 1 and in Northern Ireland it is 0.9 to 1.1.
The government has said in the past that the R number is one of the most important factors in making policy decisions."
"The demise of AAP has unexpectedly ignited a war of words between media companies over who is to blame. According to News Corp – one of the major shareholders who actually took the decision to close AAP – the shuttering of the vital news service is the fault of digital giants Google and Facebook … and the ABC and Guardian Australia. Wait. What?  In the fallout over AAP in the last few days, News Corp has used its significant real estate to attack both media organisations, with articles appearing in the Australian, the Daily Telegraph and other Murdoch titles shifting blame to competitors. A page three story in the Australian on Friday accused Guardian Australia of “gobsmacking hypocrisy” for reporting that, along with the very compelling financial reasons for closing the service, News Corp and Nine told staff they no longer wanted to subsidise a breaking news service for their competitors. Neither News nor Nine have denied making the comments. The AAP chairman, Campbell Reid, fired off a statement after the Guardian report saying it was “one of the very companies that slashed the amount it was prepared to pay for AAP”. A senior executive for News Corp, Reid is also furious with the media union, the MEAA, for questioning News Corp’s motives for suddenly closing the wire service and throwing 600 people into unemployment. Guardian hypocrisy over AAP shutdown https://t.co/bonD9uUIdh “[The Guardian] is one of the organisations whose decisions have contributed to the closure of AAP and it and the [Media Entertainment and Arts Alliance’s] leadership should confront the bigger, tectonic forces our entire industry faces rather than trot out this arrant nonsense,” Reid thundered. Guardian Australia’s editor, Lenore Taylor, who was not given a right of reply by the Oz, says: “We were offered a discount by AAP when we renegotiated last year because we were using fewer services as we expanded our own reporting teams.” “Mr Reid’s statement is based on false premises,” Taylor said on Twitter. “No one at Guardian Australia has ever suggested the decision to close AAP was made primarily to hurt small media organisations. We have written that it was a commercial decision. We did publish what Mr Reid TOLD staff at AAP – that as well as commercial considerations, News and Nine felt they were propping up a news wire that helped competitors.” via @p_hannam pic.twitter.com/HJK4anovx0 Then there was that other whipping boy, the public broadcaster. An editorial in the Daily Telegraph argued that Aunty’s free content was cutting their lunch. “Additionally, AAP found itself competing with an ever-expanding ABC, which in defiance of the public good and media viability now dominates a great deal of the online realm through tax-funded content,” editor Ben English editorialised. “The forthcoming loss of AAP will be a crushing blow to media diversity, brought about by behemoth organisations that care little for a plurality of sources.” We know that News Corp is responsible for much of the climate denial published in the Australian media – no matter what Rupert Murdoch claimed – but now we have some hard data to put it in context. First the good news. Reporting on bushfires is now far more likely to mention climate change, a study by Monash University has found. The report from the Monash Climate Change Communication Research Hub, found that 49% of the media coverage of the recent bushfires mentioned climate change, compared with 5% of reports about Black Saturday in 2009. The researchers analysed 1% of articles between 1 September and 31 January and found only 5% of overall coverage featured climate denialism, down from 21% in 2009. But it was News Corp publications that represented 59% of all the denialist discussion of climate change. The former Fairfax papers, now owned by Nine Entertainment, made up 19% of denialism. The coverage of protests by school children and Extinction Rebellion showed that, of the 2% of articles that criticised the actions of the protesters, a whopping 84% appeared in News Corp. The ABC wants the government to reverse its decision to impose an $84m indexation pause, an unlikely outcome with the details of cuts to staff and services due to be unveiled this month and no sign of the government softening. But before the ABC managing director, David Anderson, could make a final plea to parliamentarians on Tuesday, the delicate behind-the-scenes negotiations between the communications minister and the ABC were leaked to the papers – twice. A letter written by the communications minister, Paul Fletcher, to Anderson appeared in the pages of the Sydney Morning Herald. Fletcher had “strongly urged” the ABC to consider selling its capital city offices to cope with the $84m budget cut. Anderson addressed the suggestion in Senate estimates later that day, saying the property portfolio had been examined many times and the idea was not new. He also told senators the summer bushfires added an extra $3m in emergency broadcasting costs to the ABC budget at a time when the corporation had to absorb an ongoing annual budget cut of $105.9m. That $105.9m figure represents all the cuts the Coalition has made to Aunty between 2014, when Tony Abbott promised no cuts to the ABC or SBS, and 2022, when the indexation pause ends. The next day the Australian had another leaked letter, this time from Anderson to Fletcher. Anderson said if the government reversed the cuts the corporation would find $10m to fund additional regional services. Alas, we’re digesting our own ‘indexation pause’ budget cuts .. $84 million over three years, more jobs in the industry will be lost. https://t.co/S1qHcGF6by “If indexation was restored, combined with savings and efficiencies that the ABC has identified in recent months, the corporation would be in a position to commit an additional investment of up to $10m per annum to employ more journos in regional Australia and generate more content from regions for local and international stories,” the MD wrote. With the defence minister, Linda Reynolds, angrily insisting it was an “indexation pause” and ABC executives saying it was a cut, we can’t see the negotiations being successful. The ABC’s editorial director, Craig McMurtrie, was grilled at estimates about whether there had been any political interference in ABC News in relation to a report about sports rorts and another about a Rural Fire Service volunteer, Paul Parker, who told the prime minister to “get fucked from Nelligen” in a viral news clip. ABC’s Media Watch revealed last month that a news story about Parker was filed for the ABC’s 7pm bulletin but didn’t run. Then the story was slated to run on News Breakfast, only that didn’t run either. ABC management told Media Watch it had nothing to do with politics and everything to do with “accuracy, newsworthiness and priorities”. Why the ABC spiked an exclusive interview with the volunteer firefighter who abused the PM on national TV. #MediaWatchhttps://t.co/YaYWzg7xVz pic.twitter.com/CPWKrAM9XI McMurtrie told senators the story didn’t run on the news bulletin because it was unclear whether he had been sacked or was stood down. At the next opportunity the story wasn’t run because the “news cycle had moved”, he said “The important thing was that the newsroom had made the call and there was no pressure or intervention,” McMurtrie said. What did emerge from the exchange was that Anderson has never had a call from Scott Morrison personally – but he has received emailed complaints from the PM’s office. Anderson said the PMO emailed him about a story on the Lilli Pilli sports club, and after the story was examined it was amended and a correction published because it was based on a false assumption in a Facebook post. The story didn’t meet ABC editorial standards, McMurtrie said, and it had nothing to do with political influence. “On 20 January, ABC News Online published a story that suggested the Lilli Pilli Soccer Club may have had prior knowledge of a Sport Australia grant for the second stage of the expansion of its clubhouse,” the ABC correction says. The ABC accepts that was not the case.” Journalists snickered on Monday when a media release arrived in their inboxes trumpeting a world-first event: the first official KFC wedding. Of course Australia’s first “KFC Wedding” was in #Toowoomba 🍗🍟...Super Rooster should have broken into this market already 👰🏻🤵🏻 details @WINNews_TWBA 6pm pic.twitter.com/5OpTNrhWE4 “Having had their first date in KFC in 2017, Kate and Harrison applied to the KFC Weddings competition in September last year and were the first lucky couple to be wed through KFC Weddings,” the media release said. “Having won the competition for their take on the Fresh Prince of Bel-Air theme tune about their love, Kate and Harrison surprised 150 guests to the KFC Wedding complete with the KFC Food Truck, personalised buckets and Colonel themed celebrant and entertainer.” However, the PR firm that sent out the release and their clients KFC had the last laugh. Multiple Australian and international outlets, including news.com.au, 7news.com.au, the Daily Telegraph, 10 Daily, Pedestrian TV, Toowoomba Chronicle, the Courier Mail and KIIS 1065 covered the stunt, complete with multiple pictures and video. Most stories had bylines, and some were even pay-walled. Expect more of this press-release journalism when AAP shutters in June. Before we leave the subject of dumb press releases the great toilet paper shortage provided some publicists with priceless opportunities to flog their clients. We heard from one PR agent on behalf of a manufacturer of bidets. She wondered if Weekly Beast would like to interview him: “In light of the toilet paper shortage over coronavirus fears I thought you might be interested in talking about bidets”. Residents In Vaucluse And Toorak Have Started Panic-Buying Bidets https://t.co/Y9Z5hsYiEF pic.twitter.com/CCz24MDxPQ The manufacturer could talk about: how bidet seats work – “they are often retrofitted on your existing toilet taking the place of the old toilet seat”; how they “provide a better clean than toilet paper and how they are eco-friendly”."
"
Share this...FacebookTwitterNASA has recently issued a press release, here. A recent study by Davies & Molloy (2012) appearing in the Geophysical Research Letters shows that clouds have gotten lower over the first decade of this century. Hat tip: Die kalte Sonne.
Data from NASA's MISR instrument show that global average cloud height declined by about 1 percent over the decade from 2000 to 2010, (Source: NASA)
Here’s the NASA press release (emphasis added):
February 21, 2012
Earth’s clouds got a little lower — about one percent on average — during the first decade of this century, finds a new NASA-funded university study based on NASA satellite data. The results have potential implications for future global climate.
Scientists at the University of Auckland in New Zealand analyzed the first 10 years of global cloud-top height measurements (from March 2000 to February 2010) from the Multi-angle Imaging SpectroRadiometer (MISR) instrument on NASA’s Terra spacecraft. The study, published recently in the journal Geophysical Research Letters, revealed an overall trend of decreasing cloud height. Global average cloud height declined by around one percent over the decade, or by around 100 to 130 feet (30 to 40 meters). Most of the reduction was due to fewer clouds occurring at very high altitudes.
Lead researcher Roger Davies said that while the record is too short to be definitive, it provides a hint that something quite important might be going on. Longer-term monitoring will be required to determine the significance of the observation for global temperatures.
A consistent reduction in cloud height would allow Earth to cool to space more efficiently, reducing the surface temperature of the planet and potentially slowing the effects of global warming. This may represent a negative feedback mechanism a change caused by global warming that works to counteract it. “We don’t know exactly what causes the cloud heights to lower,” says Davies. “But it must be due to a change in the circulation patterns that give rise to cloud formation at high altitude.”
NASA’s Terra spacecraft is scheduled to continue gathering data through the remainder of this decade. Scientists will continue to monitor the MISR data closely to see if this trend continues.
For more information, visit: http://www.auckland.ac.nz/uoa/home/news/template/news_item.jsp?cid=466683.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




MISR, built and managed by NASA’s Jet Propulsion Laboratory, Pasadena, Calif., is one of five instruments on NASA’s Terra spacecraft, launched in December 1999. The instrument uses nine cameras at different angles to produce a stereo image of clouds around the globe, allowing measurement of their altitude and movement. For more on MISR, visit: http://www-misr.jpl.nasa.gov/ . For more on Terra, visit: http://terra.nasa.gov/ .
Another NASA mission that studies clouds is NASA’s CloudSat, also built by JPL and launched in 2006. CloudSat is the first satellite that uses an advanced radar to “slice” through clouds to see their vertical structure, providing a completely new observational capability from space. CloudSat’s primary goal is to furnish data needed to evaluate and improve the way clouds are represented in global models, thereby contributing to better predictions of clouds and thus to their poorly understood role in climate change and the cloud-climate feedback. For information on NASA’s CloudSat mission, visit: http://cloudsat.atmos.colostate.edu/ and http://www.nasa.gov/clouds.”
Cooling is the result of warming? How much more tangled up in a web of fantasies can one possibly get? And when they say “we don’t exactly know”, it really means they don’t have a clue, or they know but it’s a reason they are not supposed to mention.  Wasn’t CO2 supposed to cause positive feedbacks, and not negative feedbacks? Time to rework the models.
Fritz Vahrenholt and Sebastian Lüning at Die kalte Sonne site provide their remarks:
The decrease in high clouds means an additional cooling effect has been in place over the first decade, one that has not been taken into account up to now. It is known that global temperatures have not risen since the year 2000. The exact cause of the newly described cloud effect is still not known.
Larger deviations of the falling effective cloud height appear to be controlled by the Southern Oscillation, which is an internal oceanic cycle (see p. 313-314 in ‘Die kalte Sonne’). Could there be another longer period Pacific Ocean Cyclic, the PDO, behind the cloud trend? This remains speculation. But it is interesting to observe that the PDO also began its downward trend in the year 2000.

Die publication from Davies & Molloy (2012) appeared in the  Geophysical Research Letters of the AGU.
At MeteoKlima Christian Heuer discusses whether this could be Richard Lindzen’s Iris Effect (see p. 168-170 in “Die kalte Sonne”), that is a negative, dampening feedback that counteracts global warming.”
Amazing how everything that Vahrenholt and Lüning wrote in their book, which a number of German scientists have just recently dismissed offhand without reading, is turning out to be spot on.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterHere’s something in line with yesterday’s post…how people can get caught up in mass hysteria (prerequisite: mass ignorance).Hat tip; DirkH
Germany’s online Süddeutsche Zeitung reports here on Environment Minister Nortbert Röttgen’s comments on the results of Durban.
Röttgen calls the outcome of Durban a “huge success”, yet “criticized global climate protection with clear words” in his offical government declaration. Obviously he isn’t happy with the “huge success”.
The following comments from Röttgen and the Süddeutsche Zeitung do not only confirm that mass climate hysteria has spread to the upper levels of the German government, but also to the Süddeutsche Zeitung, which quotes Röttgen:
…climate change is worldwide a central source of conflict and a ‘fundamental threat’ for more and more people.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Especially for people of island nations and desert regions, it is even a question of life and death. And that ‘we are are doing too little,’ Röttgen declared. ‘There is still a scary gap.’ Here it is a ‘question of humanitarian solidarity,’ that has to be committed to those who are impacted.”
In a nutshell – stop questioning the climate threat and start falling into line with the movement. Everything is at stake.
Of course, that is not true. It is hysterical. I wonder if Minister Röttgen or the writers at the Süddeutsche have ever read a single scientific paper on the subject of climate change. This climate “life and death” nonsense is what one typically hears from those who are either completely hysterical, or from people who maliciously spread hysteria.
While climate change is a matter of “life and death” for some, to me it is more a matter of sanity versus insanity, being informed versus being ignorant, or of being curious versus being just plain too lazy to get informed.
For journalists and environment ministers who would like to become informed, I recommend this: Die kalte Sonne.

Share this...FacebookTwitter "
"
By Steve Goddard and Anthony Watts

The Navy requires accurate sea ice information for their operations, and has spent a lot of effort over the years studying, measuring, and operating in Arctic ice both above and below, such as they did in the ICEX 2009 exercise.
The US Navy attack submarine USS Annapolis (SSN 760) rests in the Arctic Ocean after surfacing through three feet of ice during Ice Exercise 2009 on March 21, 2009. The two-week training exercise, which is used to test submarine operability and war-fighting capability in Arctic conditions, also involved the USS Helena (SSN 725), the University of Washington and personnel from the Navy Arctic Submarine Laboratory.
So, if you are planning on bringing a $900 million Los Angeles class submarine through the ice, as the captain might say to the analyst after receiving an ice report: “you’d better be damn sure of the ice thickness before I risk the boat and the crew”.
Below is a blink comparator of U.S. Navy PIPS sea ice forecast data,  zoomed to show the primary Arctic ice zone.

The blink map above shows the change in ice thickness from May 27,  2008  to May 27, 2010. As you can see, there has been a large increase in   the area of ice more than two metres thick – turquoise, green, yellow   and red. Much of the thin (blue and purple) ice has been replaced by   thicker ice.
Source images for the blink comparator:
http://www7320.nrlssc.navy.mil/pips2/archive/pips2_thick/2008/pips2_thick.2008052700.gif
http://www7320.nrlssc.navy.mil/pips2/archive/pips2_thick/2010/pips2_thick.2010052700.gif
This was quantified by measuring the area percentage in the Arctic  Basin of the 0-1, 1-2, 2-3, 3-4, and 4-5 metre ranges. The graph below  shows the results. This technique assumes an equal area projection,  which should be fairly accurate north of 70N.
In 2008, less than half of the ice (47%) was greater than two metres  thick. Now, more than 75% of the ice is greater than two metres thick.  In 2008, 18% of the ice was more than three metres thick. This year that  number has increased to 28%. There has been nearly across the board ice  thickening since 2008. There was slightly more 4-5 metre ice in 2008,  due to the big  crunch in the summer of 2007.

Now on to calculating the volume. That calculation is straightforward  :
volume = (A1 * 0.5) + (A2 * 1.5) + (A3 * 2.5) + (A4 * 3.5) + (A5 *  4.5)
Where A1 is the area of ice less than one metre, A2 is the area of  ice less than two metres, etc.  The 2010/2008 volume ratio came out to  1.24, which means there has been approximately a 25% increase in volume  over the last two years. The average thickness has increased from about  2.0 metres to 2.5 metres. That means an extra 20 inches of ice will have  to melt this summer. So far, this seems unlikely with the cold Arctic  temperatures over the last couple of weeks.

http://ocean.dmi.dk/arctic/plots/meanTarchive/meanT_2010.png
Now let’s look at the volume percentages. In 2010, 87% of the ice (by  volume)  is greater than two metres thick. But in 2008, only 64% of the  ice (by volume) was greater than two metres thick.

A few weeks ago, when extent was highest in the JAXA record, our  friends were asking for “volume, not extent.” Their wishes have been  answered. Ice volume has increased by 25% in the last two years, and  those looking for a big melt are likely going to be disappointed.

Here is the measured data:

Do you think it odd that this increase isn’t prominently mentioned on the PIOMAS  site? It seems very relevant.
———————————————–
If a man will begin with certainties, he shall end in doubts; but  if he will be content to begin with doubts he shall end in certainties.
– Sir Francis Bacon

Sponsored IT training links:
If your are looking for quick success  in 350-018 exam then join today to explore useful 642-974 resources and pass EX0-101 on first try guaranteed.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8bb7ea81',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**A UK-wide approach to coronavirus rules after Christmas is needed, Wales' First Minister Mark Drakeford has said.**
The UK government and ministers in Wales, Scotland and Northern Ireland have agreed three households can meet from 23 December until 27 December.
Mr Drakeford said it ""makes sense"" to ""respond to the consequences of greater household mixing"" together in the aftermath of the five-day period.
The UK government said it was ""a key example"" of a unified UK-wide response.
Mr Drakeford said his own family would make ""some modest use of the freedoms"".
Speaking on BBC Radio Wales, he said: ""I am cheered up by the fact that by meeting together four times, we've been able to reach a common position on the five days of Christmas.
""But I want us to reach a common position on how we approach the aftermath of Christmas as well and I think it makes sense to do that across the United Kingdom as well - have a common approach to responding to the consequences of greater household mixing.
""I do think that getting around the table together to go through a plan for it should be the next step [in] what I think of as the successful way in which we've been able to plan together for the five days of Christmas itself.""
Under the agreement for Christmas, made at a meeting of Cobra on Tuesday afternoon:
Plaid Cymru leader Adam Price called for the Welsh Government to ""keep a close eye"" on infection rates and impose further restrictions if necessary.
Mr Price also called for quicker test results so ""tracing teams can begin their work of clamping down on cases and possible clusters or outbreaks"".
The leader of the Welsh Conservatives in the Senedd, Paul Davies, claimed it was Mr Johnson who had suggested the ""collaborative approach"".
Meanwhile a UK government spokesman added: ""We welcome the desire of the Welsh administration to work even more closely with the UK government, delivering for communities across all four corners of the country.""
However some scientists have warned that the relaxation of Covid restrictions over the festive period could spark another wave of infections and further deaths.
They said a typical Christmas gathering at home was the type of environment where infections could spread.
People have been advised to take precautions when meeting their Christmas bubble, such as washing hands frequently and opening windows to clear potential virus particles.
When asked what his plans were for Christmas, Mr Drakeford said: ""I am looking forward to seeing some members of my family who I haven't been able to meet indoors for many, many months now, but we will do it in a very contained, careful way.
""We certainly won't be mixing with people who are vulnerable or whose age puts them at a particular disadvantage.
""I am looking forward to being able to make some modest use of the freedoms.""
When asked about introducingÂ tougherÂ restrictionsÂ ahead of Christmas, he said his cabinet would meet on Thursday ""to see whether or not the position in Wales means that we have to introduce some further restrictions to create the headroom we need to be able to use those five days over Christmas in a responsible way"". Â Â
On Tuesday, Mr Drakeford said an agreement to relax Covid rules over Christmas was not ""an instruction to meet with other people"".
""So it's not a choice between relaxation or no relaxation. It's having a form of relaxation where there are rules that people will recognise that will allow people to enjoy Christmas, but we'll do it in a controlled way."""
"

The Dakota Access Pipeline (DAPL) is more than just a pipeline. It is a political hot potato. There are a lot of issues underlying the DAPL conversation, including indigenous peoples’ access to ancestral lands, environmental concerns of a potential spill, water rights, and social justice.



One false assumption is that rejecting the DAPL would result in fossil fuels staying in the ground. The lack of a pipeline has not stopped growth in oil production from the Bakken shale formation yet. This oil is currently transported by rail or road, where it has a significantly higher chance of spillage, explosion or tragedy. Higher prices will be passed on to consumers, a regressive policy that inordinately affects the poorest citizens.



Climate change activists have also entered the fray. Anti‐​fossil fuels advocate Bill McKibben said the pipeline couldn’t pass “a climate test” and the Center for Biological Diversity has made DAPL a touchstone of its aggressive climate campaign. Wouldn’t it be great to see the numbers behind the rhetoric?





The environment is important, but not as important to environmentalists as a large coalition.



There are several calculators that use the EPA’s own model — the Model for the Assessment of Greenhouse Gas‐​Induced Climate Change (MAGICC) — to determine the effects of various policy proposals. The model requires we know how much additional oil DAPL will transmit, which is rather difficult to predict. The pipeline’s capacity is currently rated at 470,000 barrels per day from the Bakken shale formation. This is about half of the Bakken’s current production.



Moving this oil by pipeline is about $7/​barrel cheaper than current transport by truck and rail. For the sake of argument, assume that an additional 470,000 barrels come out of the Bakken as a result of the pipeline. (Note: In reality, production changes are determined by a host of unrelated market conditions).



Plugging that figure into the MAGICC model will tell you how much that oil will raise global temperatures by the year 2100 — just 0.006 degrees Celsius. A rise of 0.006°C is roughly the temperature change we experience every few seconds, even in a thermostatically controlled environment.



It’s also too small to measure on a global scale. In addition, the MAGICC model assumes, along with the EPA, the “sensitivity” of global surface temperature to a doubling of atmospheric carbon dioxide is around 3.0°C. There are dozens of reality‐​based experiments in the recent peer‐​reviewed literature showing that assumption to be a serious overestimate.



A large reason for the prominence of the #NoDAPL movement is due to a concerted effort by environmental groups to include minorities and the economically disadvantaged in their association. By melding environmentalism and social justice into “environmental justice,” environmentalists are able to swell their ranks.



They have incorporated issues plaguing minority groups, like systematic racism and poverty, with the specter of apocalyptic climate change. These priorities were on full display in the November defeat of Initiative 732 in Washington — a carbon tax many environmentalists rallied _against_ due to its lack of wealth redistribution. The environment is important, but not as important to environmentalists as a large coalition.



We should note that, come January 20th, Donald Trump will be president. The Army Corps of Engineers’ process will find itself under the guidance of a new executive — one boisterously behind domestic energy production. We find it difficult to believe President Trump won’t address the DAPL.



Trump has publicly voiced his support for the project. This reroute of the project will merely delay the inevitable — oil flowing from the Bakken shale to consumers with no detectable effect on earth’s climate.
"
"Even by the standards of overpriced San Francisco, the Sea Cliff neighborhood is astronomically expensive. Nestled between two gorgeous parks and with what a realtor might describe as commanding views of the Golden Gate, it could hardly be different. Homes in the area routinely go for more than $10m. Jack Dorsey, the CEO of Twitter and the payment service Square, recently bought a place here for $21.5m – next door to his $18m present home. The 0.62-acre compound is recessed from the street and perched on a cliff overlooking the beach. And that’s where things get interesting, because cliffside living has become an increasingly risky proposition in California. Warming ocean temperatures are whipping up stronger surfs and more brutal winter storms, causing cliffs to crumble ever faster into the sea. The consequences for thousands of cliff-top houses such as Dorsey’s could be catastrophic. Still, @Jack’s bet isn’t a bad one: depending on when the house goes over the edge, it might well be the rest of us that gets stuck with the bill.  That’s because most of the cost of protecting California properties from coastal erosion, wildfires and other effects of the climate crisis will eventually have to be met by the state, with public money. This means those costs won’t fall on the disproportionately white and wealthy people who own property. Rather, they’ll be increasingly borne by the working- and middle-class Hispanic, black and brown Californians that make up the majority of the state, many of whom don’t own real estate. Without really grappling with this reality, the state is slipping step by step towards a massive wealth transfer from the general public to the owners of private property. It’s one more way in which the climate crisis is also a crisis of racism and inequality. What Sea Cliff could look like in a few years’ time can be glimpsed in the town of Pacifica, 14 miles to the south. Parts of the town, which is much more middle-class than Sea Cliff, sit directly on beautiful bluffs that overlook – and are tumbling into – the Pacific Ocean. When the town’s mayor proposed a “managed retreat” from the coast, home owners and local realtors revolted: the proposal would have effectively taken their homes off the market, cutting them off from potential profits. (Owners does not mean residents: about a third of Pacifica’s housing stock, including many of the most threatened buildings, consists of rental units.) So instead of a managed retreat, the city is taking money from the public coffers and using it to protect property investments by building sea walls and replenishing eroding beaches with trucked-in sand, among other measures. This is a dynamic we have seen throughout the late capitalist economy. The sociologist Ulrich Beck described it as a change from “a logic of wealth distribution” to one of “risk distribution”. Profits are privatized, but risk is made public. The banks made a bunch of bad bets on crappy mortgage debts? Bail them out with public money and give the executives multimillion-dollar bonuses. Someone half bakes a fundamentally unprofitable tech business? Let them IPO it so they can liquidate hundreds of millions of dollars of stock options while transferring the ultimately worthless company into the hands of public pension funds and workers’ 401ks. That’s the same thing that is now happening in California, where the land is uniquely threatened and at the same time uniquely valuable. There is a concerted political effort not to manage the risk, but rather to keep it from impacting value by making the public bear the costs of the climate crisis through things such as the sorts of publicly funded disaster relief programs and state-subsidized insurance payouts that Jack Dorsey could theoretically benefit from. This is, in fact, what many of the owners of capital and real estate think the government is for: protecting the value of private property at all costs. It’s one of the reasons we have a climate crisis – instead of a robust, rapid transition away from fossil fuels – in the first place. The sheer immensity of the climate crisis, and of California, ensures that more and more of the costs will be borne by the public. The Los Angeles Times estimates that $150bn in California property might be impacted by coastal flooding and erosion by 2100. That’s $150bn in private wealth which the government has made it a public priority to preserve. Those costs are dwarfed by the risks created by the region’s intensifying wildfires, which threaten millions of properties around the state. Individuals and insurance companies currently bear financial responsibility for property damaged by wildfires, but there is already pressure to collectivize these risks. It will go something like this: as houses become astronomically expensive, insurance payouts become astronomically large. In response, in threatened areas, private insurers will cancel coverage, or multiply rates to the point of unaffordability. The state will be forced to step in to stabilize the rates, and keep the land valuable, which will likely involve something like the National Flood Insurance Program, which subsidizes flood insurance provided by private insurers and underwrites the full extent of their losses. Currently, the state is forcing insurance companies not to cancel coverage, but reinsurers are getting worried, meaning the pressure is on to decline coverage – something that is already happening in various parts of the state. This is exactly the point where historically the government has stepped in — and there are already calls for it to do so now. The racist dimension to this wealth transfer must not be overlooked. Fewer than 55% of California households own their dwelling and only 42% of Latino households and 33% of black ones do. Non-urban space, open space, and at-risk space in California is today particularly white, or at least white-owned. Especially in the sorts of rural areas threatened by wildfire, that disparity is highly dependent on California’s history of racial violence and exclusion. The genocide of California’s first peoples; restrictions on the citizenship status of Asian immigrants; the seizure of Japanese American land during the second world war; the arrogation of land for infrastructure projects in the postwar period; discriminatory lending practices, racial covenants and other racist real estate policies, perpetuated by de facto segregation – all worked to ensure that non-white property ownership in rural California has remained low and concentrated in dense cities. All of this creates an unjust mismatch: the collective that is underwriting the risk of climate catastrophe will not be the same as the group that is incurring it. As a result, the siphoning off of public wealth to protect private property will increasingly favor white Californians. Of course, that’s one of the reasons it’s likely to be politically acceptable. It would be difficult to imagine the government sanctioning a massive wealth transfer in the other direction, for example by relieving the mortgage debts of the black and brown Americans who were the primary victims of the subprime crisis. But when fire and other types of home insurance markets fail, as they are already beginning to do and inevitably will, the state will have to step in to shore up the largely white property market with black, brown, working and middle-class public money. As the incalculably large price tag of climate change comes due, those excluded from the property market will increasingly foot the bill for California’s cult of the homeowner. It remains to be seen whether that cult will endure, or whether the state can rethink its relationship to real estate. • This article was updated on 9 March 2020 to emphasize that individuals and insurance companies currently bear the risk for wildfire damage"
"The national infrastructure strategy to invest £100bn in boosting the economy and tackling the climate crisis is expected to be delayed until after the budget. The plan to improve transport connectivity and work towards achieving net-zero emissions by 2050 had been set to be published “alongside” the budget, which is due on Wednesday.  But the chancellor, Rishi Sunak, who took over at the Treasury last month, is not expected to unveil the plans seen as being crucial to the government’s “levelling up” agenda until a later date. Whitehall sources were unable to say when it would be published, but expected the delay to be only a matter of days or weeks. However, the shadow chancellor, John McDonnell, said the delay represented “absolute chaos” in government. “We are facing the threat of climate change and an economy at risk of recession. That’s why we desperately need an immediate start to large-scale infrastructure investment,” he said. “Delaying implementation of investment is unacceptable.” Sir John Armitt, the chair of the national infrastructure commission, said they were “disappointed” at the delay but expressed confidence that ministers remained committed to infrastructure investment. “Naturally we are disappointed about the further delay in the government’s formal response to the national infrastructure assessment, which we published over 18 months ago,” he said. “However, we are encouraged by the evident focus the government wishes to place on investing in the UK’s future infrastructure. “Prioritising that investment within a long-term plan is key to success and if a short delay leads to a better strategy that more comprehensively addresses our recommendations, it will be worth the wait.” A Downing Street spokesman said: “It is vital that we give these decisions the proper time and care they deserve. The national infrastructure plan will follow in the coming months and government officials are working on it as a priority.”"
"
Story from AFP via Breitbart, h/t to Leif Svalgaard. Maybe the Chinese had it right way back then with this gadget:
The earliest seismoscope was invented by the Chinese philosopher Chang Heng in A.D. 132. This was a large urn on the outside of which were eight dragon heads facing the eight principal directions of the compass. Below each dragon head was a toad with its mouth opened toward the dragon. When an earthquake occurred, one or more of the eight dragon-mouths would release a ball into the open mouth of the toad sitting below. Image: USGS

Toad is a telltale for impending quakes:  scientists
For ages, mankind has craved a tool that can  provide early warning of that terrifying moment when the earth begins to  shake.
But if a scientific paper published on Wednesday is confirmed, we may at  last have found one.
The best hope yet of an earthquake predictor could lie in a small,  brown, knobbly amphibian, it suggests.
The male common toad (Bufo bufo) gave five days’ warning of the  earthquake that ravaged the town of L’Aquila in central Italy on April 6, 2009, killing more than 300 people  and displacing 40,000 others, the study says.
Biologist Rachel  Grant of Britain’s Open University embarked on a toad-monitoring project at San Ruffino  lake, 74 kilometres (46 miles) north of L’Aquila, 10 days before the 6.3-magnitude quake  struck.
Her two-person team observed the site for 29 days, counting toad numbers  and measuring temperature, humidity, wind  speed, rainfall and other conditions.
By March 28, more than 90 male toads had mustered for the spawning  season, but two days later, their numbers suddenly fell, Grant reports.
By April 1 — five days before the quake — 96 percent of the males had  fled.
Several dozen ventured back on April 9 for the full moon, a known  courtship period for toads, although the tally was some 50-80 percent  fewer than in previous years.
After this small peak, the numbers fell once more, only picking up  significantly on April 15, two days after the last major aftershock,  defined as 4.5 magnitude or higher.
In addition, the number of paired toads at the breeding site also  dropped to zero three days before the quake. And no fresh spawn was  found at the site from April 6 until the last big after-tremor.
Grant says  the toads’ comportment is a “dramatic change” for the species.
Once male toads hole up at a breeding site, they usually never leave  until the annual spawning season is over, she notes.
Eager to answer the riddle, Grant obtained Russian measurements of electrical activity in the ionosphere,  the uppermost electromagnetic layer in the atmosphere, which were picked  up by very low frequency (VLF) radio receivers.
The toads’ two periods of exodus both coincided with bursts of VLF  disruption.
Read the entire article at Breitbart


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8cd3bace',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"I’ve heard it many a time, and you probably have too. It’s supposedly the trump card to any argument on addressing climate change globally: “Yeah, but what’s the point? Isn’t China building a new coal plant every week?”   If the world’s largest country, with a population of 1.4 billion and counting continues its unwavering march to build carbon intensive fossil fuel generation, what meaningful negotiations can happen on climate change?  The factual origin of the “one plant a week” claim is difficult to trace, but clearly warrants some investigation. If you’re a straight-to-the-point kind of person, the answer is no. When it was coined it was likely to have been true, but in a dynamic and growing economy, it’s one of those “facts” that is outliving the conditions it emerged from. The present-day story is a little more complex. True, China has seen rampant growth in coal energy over the past decade and we know the country has relied on cheap coal to fuel its growth; buckets of the stuff in fact. In 2010, China alone consumed about 3.3 billion tonnes (around 47% of the world total) and it maintains a planning pipeline of 363 new projects under consideration; a whopping total of 558GW additional coal.  That’s compared to a total installed coal capacity of 313GW in the US, the world’s second biggest coal user. Spread those planned Chinese projects evenly over the next 15 years, that’s roughly one every two weeks. But this simplistic extrapolation is outdated and misleading. Since those coal plants were proposed, China has changed its energy policy to curb carbon emissions and pollution. A five-year plan for the coal industry was introduced in 2012, with a target to cap annual domestic coal consumption to 3.9 billion tonnes by 2015.  Since then, the net buildout of coal plants has dropped dramatically.  Planning rejections have been on the rise and the coal industry has been overtaken by new renewable energy. About one-third of the proposed new coal–fired plants that have been approved are delaying the start of their construction, resulting in a big slowdown in newly added coal power capacity. At the same time, coal generation is being phased out (80GW of old capacity was removed from 2001-2010) and there are plans to  phase out a further 20 GW of coal.  Consider the graph below; even as China’s GDP continues to rise on a fairly stable path, coal consumption is beginning to tail off. So why the change in heart?  First and foremost, 70% of China’s coal companies are reportedly losing money as rising production costs squeeze the viability of adding more coal.   Renewable energy meanwhile, is growing from strength to strength. The country is already the world’s largest producer of wind power, and it plans to double capacity by 2020. New renewable capacity surpassed new fossil fuel and nuclear for the first time last year. The Chinese renewables boom comes as its citizens are increasingly worried about air pollution. This is the other reason the country’s leadership has gone off coal – persistent smog in industrial and developed areas is hard to ignore, especially when it almost ruined the Beijing Olympics.  Since then, there has been mounting social unrest and growing discontent at the expansion of coal and its impact on health. China’s leadership has been anxious to head off potential sources of unrest, hence its decision to slash coal consumption and close polluting mills, factories and smelters. These considerations point to more optimism than the 558GW pipeline of coal would suggest. Coal build-out rates are slowing dramatically while China continues to make the world’s biggest investments in renewables.  If someone brings out the “one coal plant a week” argument, you can arm yourself with the knowledge that the Chinese coal juggernaut is wounded and slowing, and will, based on China’s own policy objectives, soon trundle to a halt.  As world leaders continue to meet and negotiate the global scale of the climate challenge, it would be unfair to claim that China is not pulling its weight."
"London’s cycle hire scheme has become a prominent fixture in the capital’s transport network since it opened in 2010. Known as “Boris Bikes”, it is Barclays Bank that has provided commercial sponsorship for the scheme from the beginning, a relationship that is due to end in 2015. So the search is now on for a successor with deep pockets, one that is willing to play a role in shaping the future of the scheme. Many bike hire schemes begin small, with the number of bikes initially in the hundreds rather than thousands. But in London, helped by a swelling population of more than 8m people and the support of the city mayor, the scheme opened with 5,000 bikes and has gradually expanded to 11,200. It is now the second largest scheme in Europe, after Paris. The financial support pledged by Barclays (£25m over five years) was certainly a factor that enabled the scheme to open at this scale. The end of 2013 saw a decline in the number of journeys made, in comparison to the same period in 2011 and 2012, before picking up again in 2014 to hit a milestone of 30 million journeys. A study of the scheme’s users found they were disproportionately male and from more affluent areas of the city. Hopefully this issue will be addressed by the extension of the scheme to other parts of London, encouraging access to a wider spectrum of the city’s population.  For many schemes, including London’s, private sponsorship is an important element of the business model. JCDecaux and Clear Channel (both outdoor advertising companies) are involved in many European schemes. They typically manage the scheme and supply capital for the start-up and running costs in exchange for rights to a proportion of the advertising boards across the city. The London scheme differs here in that the sponsor’s investment provides advertising of their brand, as opposed to increasing the share of the market they operate in.    For London, this external sponsorship is vital – Transport for London are looking for £37.5m – and the scheme has not yet shown to be profitable. As Barclays withdrew their financial support, the scheme’s expansion into southwest London in 2013 was taxpayer funded. Nearby councils were reported to have jointly paid around £4m towards the £10m cost.  Schemes have sometimes relied upon an individual to champion the policy and ensure its success, especially in the early days of a scheme. London mayors Ken Livingstone and Boris Johnson have had important roles for London, but a champion will continue to be needed to prevent the scheme from faltering.  As the London cycle hire scheme reaches a crossroads, what can be learnt from other schemes? The Paris scheme is seen as a great success but it relies upon high user numbers to offset the expense of sustaining it. Smaller schemes – for example those run by Nextbike– offer a greater likelihood of financial sustainability, but lower running costs are a key factor in this. Crucially, in many cities cyclists benefit from wider roads and more defined space. In contrast, one of the most pressing issues for London is the safety of cyclists, which is a problem for the city as a whole, including those using the bike hire scheme.  Busy, narrow roads and insufficient or absent cycling infrastructure dissuade many from using the scheme. Data suggests that a London hired bike is used far less frequently over the course of a day than a bike would be in many schemes elsewhere. Infrastructure problems are seen as a key factor in this, and this raises the issue of value for money. Resolving the safety and infrastructure problems are of course not easy tasks, and real change in authorities’ attitudes towards cycling is occurring very slowly. But concerted effort and change here may well be the key to reigniting the initial success of the scheme. The importance of a suitable sponsor for the scheme cannot be underestimated as their financial support will be essential. Public funding will undoubtedly continue to be needed but to a lesser extent if the scheme prospers. It has been contested that Barclays’ decreasing interest in the scheme may be the result of the growing cycling safety issues in London. This is perhaps the most difficult hurdle that the scheme, and whoever its new sponsor will be, must overcome in coming years. Bikes that aren’t used are no use to anyone, whoever pays for them."
nan
"**When it comes to vaccine making, India is a powerhouse.**
It runs a massive immunisation programme, makes 60% of the world's vaccines and is home to half a dozen major manufacturers, including Serum Institute of India - the largest in the world.
Not surprisingly, there's no lack of ambition when it comes to vaccinating a billion people against Covid-19. India plans to receive and utilise some 500 million doses of vaccines against the disease and immunise up to 250 million people by July next year.
This confidence is bolstered by its track record of immunising large numbers of people every year. India's 42-year-old immunisation programme, one of the world's largest health programmes, targets 55 million people - mainly newborns and pregnant women who receive some 390 million free doses of vaccines against a dozen diseases every year. The country also has a well-oiled electronic system to stock and track these vaccines.
Yet vaccinating a billion people, including hundreds of millions of adults for the first time, against Covid-19 is going to be a daunting and unprecedented challenge, say experts.
Five of the 30 vaccine candidates being developed in India are in clinical trials. They include the Oxford-AstraZeneca vaccine which is being tested by Serum and a home-grown one being developed by Bharat BioTech. ""Having a home-grown vaccine is a top priority,"" Dr Renu Swarup, secretary of India's Department of Biotechnology, told me.
From choosing a bouquet of vaccines to grappling with distribution to identifying groups for the early jabs, ""everything is a challenge"", says Dr Gagandeep Kang, a microbiologist and the first Indian woman to be elected Fellow of the Royal Society of London.
""We are underestimating the complexity of the exercise. It will take at least a couple of years to get half of Indians vaccinated.""
Here are some of the main challenges:
India has some 27,000 ""cold chain"" stores from where stocked vaccines can reach more than eight million locations. (Nearly all vaccines need to be transported and distributed between 2C and 8C in what comprises the so-called cold chain.) Will that be enough?
India will also need enough auto-disabled syringes that will prevent reuse and possible reinfection. The country's biggest syringe maker says it will be making a billion such syringes by next year to meet rising demand.
Then there are questions about smooth supplies of medical glass vials. And what about the disposal of the huge amount of medical waste that will be generated by this mass vaccination drive?
Nearly four million doctors and nurses power India's immunisation programme, but India will need more to carry out Covid vaccinations.
""I worry about how we can [extend all the resources] to rural India,"" Kiran Mazumdar Shaw, founder of Biocon, the country's leading biotechnology enterprise, told me.
Vaccine supplies will be tight next year, and deciding who will get the jabs first is going to be tricky.
Health Minister Harsh Vardhan says private and government health care workers and frontline workers ""of other departments"" will receive the early doses.
Experts believe it's not going to be easy.
""We will never have sufficient supply of vaccines. The prioritisation of recipients is going to be a considerable challenge,"" says epidemiologist Dr Chandrakant Lahariya.
Consider this. In a country where the majority of healthcare is private, will a private health worker get priority over a public one? Will permanent workers get priority over people working on contracts?
If elderly people with underlying conditions are eligible for early shots, how will different co-morbidities be prioritised?
India, for example, has more than 70 million diabetics, the second highest in the world. Will all of them be given a blanket preference?
Rolling out the vaccine in all the 30 states will not be possible. So will early supplies go to states worst-hit by the pandemic?
Questions about equity and non-partisanship are inevitable.
Stitching up manufacturing contracts with vaccine makers with a ""reasonably good portfolio"" of vaccines should help India give sufficient doses to people relatively quickly, according to Prashant Yadav, who studies health care supply chains at the Washington-based Centre for Global Development.
But the success at routine immunisation doesn't guarantee success with Covid-19 vaccines, he says.
""The routine immunisation infrastructure has a huge footprint, but is mostly for government-run clinics. There is no large-scale adult vaccination programme and adults don't routinely seek primary care in government public health care centres,"" says Dr Yadav. A well-regulated public-private partnership is the only way out this time, he adds.
People like Ms Shaw and Nandan Nilekani, a co-founder of Infosys, one of India's biggest information technology services companies, suggest that India should use Aadhaar, the unique 12-digit identification number that over a billion Indians use to access welfare and pay taxes, to record and track each dose.
""We need to design a system than can do 10 million vaccinations a day across the length and breadth of the country but all unified by a digital backbone,"" Mr Nilekani told a newspaper.
Some of the concerns are about corruption over access to vaccines.
How do authorities prevent fraud such as people getting fake papers to include themselves in lists of people who are selected for early shots? And how do you prevent fake vaccines being sold in remote markets?
Vaccines come with side effects for some people. India has a 34-year-old surveillance programme for monitoring such ""adverse events"" following immunisation.
But researchers have found that benchmarks for reporting side effects still remain weak and the number of serious adverse events are still far less than the expected numbers.
A failure to transparently report adverse effects could easily lead to fear-mongering around vaccines.
This is possibly the biggest question. Will the government acquire all the doses and roll out a state-run free or subsidised vaccination programme? Or will the affluent pay for their doses at market prices through private distribution and sale?
Experts like Dr Lahariya believe that the government should be footing the bill for vaccinating every Indian until the pandemic is over. Others like Dr Shaw say that private firms could pay to vaccinate their employees.
Mr Nilekani reckons that with vaccines costing between $3 and $5 (Â£2.24 and Â£3.74) in the beginning, a dual dose vaccine could cost up to $10 for each Indian and $13bn for India. That would be very expensive.
That's why, says Gagandeep Kang, a good vaccine for India should cost below 50 cents a shot, be plentifully available and delivered as a single dose.
**Follow Soutik**on Twitter"
"In 2014, Joe Duggan started reaching out to climate scientists to ask them a question: how did climate change make them feel? “I was just blown away when I started getting the letters back,” he says.  Duggan, a science communicator at Australian National University, set up a website and starting publishing the mostly handwritten responses. “[Professor] Katrin Meissner was one of the first, and her letter really hit me. It was so ... unscience-y. Almost poetic.” “It makes me feel sad. And it scares me,” Meissner wrote. “It scares me more than anything else. I see a group of people sitting in a boat, happily waving, taking pictures on the way, not knowing that this boat is floating right into a powerful and deadly waterfall.” In the end, more than 40 scientists responded – many leaders in their field. Some wrote neatly on lined notepaper, others scrawled on the back of student papers they were marking. “It became a big part of my life,” Duggan says. “I felt a little bit out of my depth. It took its toll on me and in the end I felt I had to step away. I went into my shell and pretty much turned off my phone for three years. “But I’ve got some emotional resilience back now. My partner and I found out we’re pregnant – due in August. I don’t want that kid to grow up asking why we didn’t actually do anything.” So Duggan has returned to his “passion project” – Is This How You Feel – by asking the scientists to write again. Have their feelings changed in the intervening years? The first 10 return letters are emotional outpourings of despair, hope, fear and determination in the age of the climate crisis, from the people helping the world understand its impacts while also being mums, dads and grandparents. Since the first letters were written, two Australian correspondents Tony McMichael and Michael Raupach have died. But Duggan is trying to reach their family members to see if they can keep the legacy moving. Meissner, now director of the Climate Change Research Centre at the University of New South Wales, didn’t hesitate to respond partly because “it was the right thing to do”. “But also because we have not been very good at communicating climate science to the public and I believe that it is my duty as a citizen to alert people to the urgency of the situation.” But does Meissner think there’s a risk in scientists lifting their veil of cool objectivity to show their personal feelings? Could it cause some to question their objectivity? “I actually think that the opposite is the case,” she says. “When I saw the whole collection of letters a few years ago, I was surprised by the number of colleagues who had participated. “We are talking here about world-leading scientists, people who built their career on facts and data, who are spending their lives questioning every result they find, over and over again. People who are continuously challenging the status quo. People who are trained to be objective. “When these people start to speak up about their feelings, about being frustrated, desperate, worried, angry or scared, then we really should listen very carefully.” Duggan wants anyone who has read the letters to write their own, and share them. Here are some excerpts from the latest scientist letters from Duggan’s project. How do I feel about it? I am still very worried. I am also profoundly sad. I am probably sadder than I was five years ago. I feel powerless and, to a certain extent, guilty. I feel like I have failed my duty as a citizen and as a mother because I was not able to communicate the urgency of the situation well enough to trigger meaningful action in time.What we are doing right now is an uncontrolled, risky experiment with the planet we live on. I’m angry because the lack of effective action on climate change, despite the wealth not only of scientific information but also of solutions to reduce emissions, has now created a climate emergency. The students are right. Their future is now being threatening by the greed of the wealthy fossil fuel elite, the lies of the Murdoch press, and the weakness of our political leaders. These people have no right to destroy my daughter’s future and that of her generation. My emotions haven’t really changed since I last wrote one of these letters, but things around me have. The beacon of light that is Greta Thunberg, speaking truth to power. Our own wonderful, passionate school kids taking to the streets, making me cry with pride. The only way to cope with all of this is to focus on what I can do, what I’m best at, and hope like hell that enough people, doing what they do best, can overcome. I have some very dark moments, but more than ever before, I feel wrapped in a blanket of collective determination. Hope is a necessary emotion, but more than that, it must be our fundamental strategy to keep us going. Lose it, and we are lost. For the most part my comments of 19 September 2014 still apply except that the glimmer of hope has diminished if not vanished entirely. With Obama as US president and the Paris agreement in late 2015, a glimmer of hope seemed to emerge, but with Trump and his ignorant accomplices, the hope has vanished. I am close to retirement and as I was cleaning up in 2019 I found some old VHS tapes recording me on shows, such as the Lehrer News Hour on PBS in 1988, and the message then was much the same as now except we are now more confident and the progress has been nil. It was depressing. My solution has been to move back to New Zealand along with my daughter and family (grandchildren). Realistically, we are already too late to meet a 1.5 degree target and will struggle to achieve 2 degrees.So, the future, basically, looks bad. Hard to stay hopeful. Change is too slow, too late.Yet we have to stay optimistic. Dear Joe,​Climate Change feels very real and I think this summer we reached a tipping point in Australia. As I write this my husband, a bushfire fighter, is battling a fire in Canberra and I’m working from home as a freak hailstorm destroyed my car three days ago. In four days, we’ve been smashed by our climate: hail, extreme winds, toxic smoke and fire. …. So how do I feel? Frustrated, angry that our science is ignored by politicians, scared for my husband and all the others who are on the frontline fighting these fires and trying to help. But mostly I feel devastated for my son, and his generation, who will have to heal this planet and live with the mass environmental destruction we have caused. I feel scared for the future when faced with simple downright ignorance from some political leaders.I feel tired, tired that in spite of bushfires, floods etc I still seem to be banging my head against a brick wall to convince people that the threat of climate change is severe.I feel relieved that now I am retired I don’t have to live and breathe this every minute of every day.I feel guilty that I am stepping back from the frontline, so even though I am retired I feel compelled to carry on working.I feel unspeakable joy at the news that I am to become a grandfather for the first time, but fearful of the world my grandchild will grow up in. I feel relieved that when my grandchild grows up and asks me why we did nothing to stop climate change I can at least say that I did my best.As I sit writing this on a bench looking out over the moors I feel uplifted that despite everything the world is still the most beautiful place. The full collection of letters is available at Is This How You Feel."
"We know elements of the story. It was 1911, as Robert Scott and Roald Amundsen raced to the South Pole. Temperatures were below -50˚C. Scott was British; Amundsen a Norwegian. Sled dogs were dying, and the explorers suffered from frostbite. The stakes were high, with financing of future explorations hanging in the balance of which team would be first to reach the South Pole.  But in a sense human impact, if not humans themselves, had beaten both of them to it. More than 100 years after Amundsen won the race to the South Pole, my research group found that industrial pollution had reached Antarctica more than 20 years before the race to the pole. Thousands of kilometres away, a source of lead, zinc, and silver had been discovered in 1883 at Broken Hill in Australia. Mining and processing operations began soon after, and smelting began at nearby Port Pirie in 1889.  Scott and Amundsen were travelling over apparently untrammelled snow that was in fact heavily contaminated from smelting and mining in Australia, with lead pollution at the time almost as high as at any time since.  Using data from 16 ice cores collected from widely spaced locations in Antarctica, including the South Pole, our team created the most accurate and precise reconstruction to date of lead pollution over Earth’s southernmost continent. This effort required braving temperatures as low as -75˚C with wind chill, as it was at our shallow ice core site about 15km from South Pole. Our new record spans a 410-year period from 1600 to 2010, and is published in the Nature journal, Scientific Reports.  As well as the ice core samples we had taken, our study used data from others sampled by the British Antarctic Survey, the Australian Antarctic Division, and the Alfred Wegener Institute in Germany. These cores from our international collaborations were critical in that they allowed us to examine records from parts of Antarctica rarley visited by US-based scientists, such as the Law Dome region of East Antarctica and a region visited by the Norwegian-United States Scientific Traverse of East Antarctica.  All measurements of lead and other chemicals from this study were made with my collaborators using a unique continuous ice core analytical system that I developed as director of the Desert Research Institute’s ultra-trace ice core analytical laboratory. Lead is a toxic heavy metal with proven strong potential to harm humans, animals and ecosystems. While the concentrations measured in Antarctic ice cores are very low they record that atmospheric concentrations and the rate of accumulation increased six-fold in the late 1880s – the same time mining began at Broken Hill and smelting at Port Pirie. The similar timing and magnitude of changes across Antarctica, as well as the characteristic isotopic signature of lead from Broken Hill that was found throughout the continent, suggest that this single source of emissions in southern Australia was responsible for polluting Antarctica at the end of the 19th century, and remains a significant source of pollutants today. Lead ore is found in deposits containing different isotopes of lead – atoms which contain different numbers of neutrons in the nucleus. This gives different lead deposits mined in different areas a characteristic and recognisable signature, and as lead is found in the atmosphere in generally low background concentrations this makes it an ideal tracer of industrial pollution. Data from our new set of ice cores show that concentrations of Antarctic lead reached a peak in 1900 and remained high until the late 1920s, with brief declines during the Great Depression and the end of World War II. Then there was a rapid increase in lead concentrations until 1975, remaining high until the 1990s. Lead concentrations have declined across Antarctica since, but are still are about four-fold higher than before industrialisation, despite stricter controls on lead pollutants from industrial sites and the phasing out of leaded transport fuels in many countries. Our measurements indicate that about 660 tonnes of industrial lead have reached the snow-covered surface of Antarctica during the past 130 years, and clearly detectable pollution continues to accumulate today."
"
Share this...FacebookTwitterIt’s not a well known fact but it’s pretty much just the EU and a few other activists scattered across the rest of the world who are supporters of forcing CO2 emissions reductions through binding greenhouse gas emission treaties. Indeed about 86% of the world opposes binding, Kyoto-type treaties, and so disagree with the remaining 14% fringe EU minority.
 
Europe’s emissions law threatening trade war. Photo: Alan Radecki (Akradecki)
Countries like India, China and Russia only support such treaties if they themselves are exempt from compliance and if the US isn’t.
The EU has decided to defy the vast global majority and is now demanding that all airlines flying into or from its territory purchase GHG emission permits. Furious, 23 countries (among them China, USA, Russia, India, etc.) convened in Moscow last week and signed a joint declaration expressing their disapproval and threatening the EU with a trade war should it continue to defy international will.
Read more here in English at http://www.spiegel.de/international/europe/0,1518,817426,00.html
 
Share this...FacebookTwitter "
"**US President-elect Joe Biden has called for an end to the ""grim season of division"", as the country faces a long, hard winter with Covid-19.**
In a speech for the Thanksgiving holiday, he said Americans were at war with coronavirus, not each other.
The US saw more than 1.2 million cases last week, with 2,200 deaths on Tuesday - the highest number since late May.
Meanwhile, President Donald Trump urged supporters to work to overturn the results of the 3 November election.
Speaking via phone from the White House to an event organised by Republican state legislators in Pennsylvania, Mr Trump repeated unsubstantiated claims about widespread electoral fraud.
""We have to turn the election over,"" he said, adding that it was ""rigged"".
Mr Trump had been expected to attend the event in person but the trip was cancelled after two associates of his lawyer Rudy Giuliani tested positive for the virus. Mr Giuliani attended in person.
Mr Biden won the election with a comfortable victory in electoral college votes, and the transition to his presidency is already well under way. Mr Trump's efforts to challenge the results in key states in courts have so far failed.
On Wednesday, China's President Xi Jinping sent a message congratulating Mr Biden, more than two weeks after his victory was projected by US media.
However, a number of world leaders have still not reached out to the president-elect, including Russia's Vladimir Putin and Mexican President AndrÃ©s Manuel LÃ³pez Obrador, who said on Wednesday that he would not offer congratulations until ""the electoral process in the US ends"".
In his speech on Wednesday, Mr Biden told the nation: ""I believe you always deserve to hear the truth from your president. We have to slow the growth of this virus. We owe it to the doctors and the nurses and the frontline workers... We owe it to our fellow citizens.""
He said Covid-19 had ""brought us pain and loss and frustration"" and cost many lives.
""It's divided us, angered us, set us against one another. I know the country's grown weary of the fight, but we need to remember - we're at war with the virus, not one another.
""We have to steel our spines, redouble our efforts and recommit ourselves to the fight.""
The president-elect urged Americans to modify their Thanksgiving celebrations. He said that instead of the usual large gathering he would be spending the holiday with just his wife Jill and their daughter and son-in-law, while the rest of the family would be in small groups.
Millions of Americans are travelling to be with their loved ones despite warnings from health officials, although numbers are down on previous years.
The president-elect vowed that in due course, the pandemic would be beaten.
""I know that we can and will beat this virus,"" he said. ""Life is going to return to normal, I promise you. I believe this grim season of division... is going to give way to a year of light and unity.""
The Thanksgiving holiday comes as new cases of the virus continue to increase in the US.
More than 260,000 Americans have now died with the virus, the largest number of any country in the world, according to a tally from Johns Hopkins University.
Mr Trump finally agreed to allow the formal transition process to begin on Monday, nearly three weeks after the presidential election.
Mr Biden can now access key government officials and millions of dollars in funds as he prepares to take over the presidency on 20 January.
He will also receive the Presidential Daily Brief - an update on international threats and developments. Aide Jen Psaki said he would get his first briefing on Monday, and classified information was already being shared with Mr Biden's senior team.
On Tuesday he named six key posts in his administration, including his picks for secretary of state and national security adviser. He is set to name more staff including his economic team next week.
Most of his picks will need to be confirmed by the Senate."
"Shell is to end its relationship with two of the UK’s leading arts institutions amid growing concern about big oil’s role in the escalating climate crisis. The fossil fuel corporation has confirmed it is not renewing its corporate membership deals with the Southbank Centre and the British Film Institute (BFI) when they come up for renewal later this year.  Campaigners say the decision underlines the shrinking “social licence” of fossil fuel companies in the midst of the climate crisis. It follows similar moves by the Royal Shakespeare Company (RSC), National Theatre and National Galleries Scotland, which have all severed ties with major oil companies in the last year. Chris Garrard, from the campaign group Culture Unstained, said the end of Shell’s involvement with the BFI and the Southbank Centre was a crucial milestone in the campaign. “From its HQ on the South Bank, Shell has pursued a business plan that has trampled indigenous people’s rights and pushed the world deeper into climate crisis,” said Garrard. “Meanwhile, it has sponsored its cultural neighbours as part of a cynical attempt to deflect attention from the damage it was causing. But the show is over for Shell.” A spokesperson for Shell said the decision not to renew the contracts had been taken last year and mutually agreed with the Southbank and the BFI. “Last year we decided not to renew annual memberships with the BFI or the Southbank Centre, collectively worth around £20,000, when they expire later this year,” it said. The BFI confirmed it had been Shell’s decision. Harriet Finney, the BFI’s director of external affairs, said the institute was “committed to supporting a sustainable future”. “We are in the process of reviewing the impact of our own activities across all our sites; how we can better support the UK’s screen industries to move towards sustainable practice and how we respond culturally to the climate and ecological emergency.” The Southbank Centre has had a relationship with Shell stretching back to 2006 and lists the company as a partner on its website. A spokesperson said the decision to end the two-year corporate membership had been mutual and declined to comment further. The leading tenor Mark Padmore, who will perform at the Royal Festival Hall in October, said he was delighted with Shell’s decision. “Today, more than ever, we all need to examine our way of life and the implications of our actions, as we respond to the growing climate emergency,” he said. “Making beautiful music does not excuse us from seeking to understand how our work is funded and asking questions about the kind of unsustainable businesses those partnerships might promote.” Last year, the actor Mark Rylance resigned as an associate artist with the RSC after 30 years over its sponsorship deal with BP, arguing it allowed the company to “obscure the destructive reality of its activities”. A few months later, the RSC announced it was cutting its links to BP after a “careful and often difficult debate” internally. The latest move increases pressure on other arts institutions such as the British Museum, National Portrait Gallery and Science Museum Group, which have all faced criticism over their oil sponsorship deals in the past 18 months. Last month, the activist theatre group BP or not BP? occupied the British Museum for three days, sneaking a “Trojan horse” into the courtyard and staging a mass protest in the museum involving 1,500 people."
"
Share this...FacebookTwitterSome German professors are beginning to speak up against the climate shenanigans. Take for example Prof. Dr. Dr.Knut Löschke, physicist, who gave a speech on Climate Policy titled “Give Reason Another Chance!” at the University of Passau last Friday. Ralph Bärligea has the story at eingentümlich frei.de.
Bärligea summarizes Löscke’s speech. Here’s an excerpt:
Man-made climate change as a hypothesis is in the end one that has never been confirmed by any single experiment and does not harmonize in any way with existing physical theory. But even so, the hypothesis is implemented in real politics. Representatives of the IPCC do not shy away from using fraud and falsifications in its effort to fulfill its political agenda: which is to show that man influences the global climate. This is proven by the Climategate Scandal, and an especially crass example of a falsification that Professor Löschke introduced in his presentation. By spreading the hypothesis of man-made climate change and the “solution proposals” for global “climate control”, dangerous limits that go beyond the absurd have long since been over-stepped.”
Löschke thinks the whole climate issue is a dangerous political sham and called on the public: “Wehret den Anfängen!“ This is a call to defend against a dangerous movement. Those are the milder points he brought up.
At the end of his speech Professor Löschke compared the “international climate regime“ to the socialist regimes in Germany. According to Bärligea, up to 8 people walked out.
So, some are speaking up in Germany, and doing so loudly!
Well done! I say.
Knut Löschke is a university lecturer, business owner and a member of the supervisory board at the Deutsche Bahn AG.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterHere comes the sun!
Climate skepticism is doing more than just striking a chord here in Germany. It’s turning into a full blown concert! Yesterday we wrote about how Prof. Dr. Fritz Vahrenholt’s and Dr. Sebastian Lüning’s book Die kalte Sonne – Warum die Klimakatastrophe nicht stattfindet (The cold sun – why the climate catastrophe is not taking place) reached No. 4 on the Amazon.de list for ecology and environment books.
Today it was at No. 1 on the Amazon.de list of ecology and environment books.

Not considering it is still not even at the bookshops. It’ll be available next week!
I urge every German reader to pick up extra copies and to give them away as birthday presents, or for whatever occasion.
Share this...FacebookTwitter "
"

We don't need no stinkin' environmental regulations to save the earth -- all we need are well functioning property rights for environmental resources and common law courts to protect that property against trespass. Pollution is simply a neighbor's garbage dumped in your backyard without permission. If we simply recognize and enforce property rights for nature, the need for most environmental regulation goes away.   
  
That's the libertarian pitch anyway, and it goes by the moniker ""Free Market Environmentalism,"" or ""FME"" to its acolytes. FME was given a firm theoretical foundation by Ronald Coase, embellished and blessed by libertarian economist Murray Rothbard, given academic life by the Political Economy Research Center and the Foundation for Research on Economics and the Environment, popularized in Washington by the Competitive Enterprise Institute, and even pitched by yours truly to the Board of Trustees of the Natural Resources Defense Council about nine years ago.   
  
Alas, there has never been much evidence to suggest that libertarians were making much headway with these arguments and I have come to believe that they have less promise than I had once imagined. But what do you know? FME is now all the rage amongst environmentalists who have discovered that suing polluters for tresspass is easier than passing satisfactory laws against the same.



Think I'm pulling your leg? Read this from Darren Samuelsohn in today's issue of _Greenwire_ (subscription required): 



_Efforts to force a stronger U.S. global warming policy through the courtroom came under sharp scrutiny yesterday as eight states, New York City and conservation groups pressed for reduced greenhouse gas emissions from the nation's five largest electric utilities._   
  
_A three-judge panel of the 2nd U.S. Circuit Court of Appeals pressed plaintiffs over why their case was necessary when other avenues exist for addressing global warming -- from Capitol Hill to state courts. ""My basic question is should we be invoking this doctrine in this very unusual case when there are many other remedies available?"" asked Judge Sonia Sotomayor, the lone Democratic appointee on the 2nd Circuit's panel._   
  
_Connecticut Attorney General Richard Blumenthal (D) replied that the utilities' emissions violate federal common law by harming residents in multiple states. The utilities' emissions are creating a public nuisance and must be reduced to counteract a variety of global warming effects, including California's diminished snow pack and more intense heat waves._   
  
_Addressing Sotomayor's question, Blumenthal said his case is not unusual compared with other seminal common law challenges upheld by the Supreme Court, including suits over Illinois sewer water running into Lake Michigan and air pollution from two Tennessee smelters._   
  
_""We're dealing with a developing area of science where federal common law provides a remedy under the doctrines that exist,"" Blumenthal said._   
  
_Plaintiffs singled out the five companies and their subsidiaries for litigation almost two years ago because they are the largest emitters of carbon dioxide from the power sector in the United States._   
  
_... The electric utilities' defense covered some of the same ground offered successfully last summer before a federal district court, which dismissed the case on the grounds it raised political questions better left to the other two government branches. Both current and former sessions of Congress and presidents have not adopted such an aggressive climate change policy, argued Washington-based industry attorney Joseph Guerra._   
  
_Guerra also insisted federal common law has not been applied to an issue of such sweeping scale. Of the Supreme Court precedents Blumenthal cited, Guerra replied, ""None of those cases could have possibly affected the entire U.S. economy.""_   
  
_Pushing another line of the industry's defense, Guerra cautioned the litigation would be a precursor to more global-warming nuisance claims -- with no end in sight as plaintiffs tick through other sources of greenhouse gas emissions._   
  
_But Sotomayor, who asked the bulk of the questions during the hearing, took issue with the line of industry defense. ""That's the nature of every tort action,"" she told the utility attorney._   
  
_Sotomayor also said she had a problem with dismissing the case just because potential remedies were so large._



OK, I'll grant that enviros are going the common law route less out of conviction than out of necessity. But so what? What was once a fringe argument has now migrated into the political and legal mainstream with a vengeance. Good news for libertarians, right?   
  
Well, if libertarians and fellow-travelling conservatives are popping champagne bottles, it has escaped my attention. FME blogs are dead silent. Conservatives are taking the corporate line that common law is an inappropriate venue for all of this with no dissenters that I can tell. In short, FME'ers either aren't paying attention or aren't willing to back their doctrines when they are employed by the Left.   
  
Sure, one can argue that the plaintiffs don't have proper standing, that there is really no nuisance here to begin with, that the tort system is so messed up that employing it in such cases is problematic, etc. But nonetheless, this is a growing trend and libertarians seem surprisingly ambivalent about it.


"
"Even large ecosystems the size of the Amazon rainforest can collapse in a few decades, according to a study that shows bigger biomes break up relatively faster than small ones. The research reveals that once a tipping point has been passed, breakdowns do not occur gradually like an unravelling thread, but rapidly like a stack of Jenga bricks after a keystone piece has been dislodged.  The authors of the study, published on Tuesday in the Nature Communications journal, said the results should warn policymakers they had less time than they realised to deal with the multiple climate and biodiversity crises facing the world. To examine the relationship between an ecosystem’s size and the speed of its collapse, the authors looked at 42 previous cases of “regime shift”. This is the term used to describe a change from one state to another – for example, the collapse of fisheries in Newfoundland, the death of vegetation in the Sahel, desertification of agricultural lands in Niger, bleaching of coral reefs in Jamaica, and the eutrophication of Lake Erhai in China. They found that bigger and more complex biomes were initially more resilient than small, biologically simpler systems. However, once the former hit a tipping point, they collapse relatively faster because failures repeat throughout their modular structure. As a result, the bigger the ecosystem, the harder it is likely to fall. Based on their statistical analysis, the authors estimate an ecosystem the size of the Amazon (approximately 5.5m km2) could collapse in approximately 50 years once a tipping point had been reached. For a system the size of the Caribbean coral reefs (about 20,000 km2), collapse could occur in 15 years once triggered. The paper concludes: “We must prepare for regime shifts in any natural system to occur over the ‘human’ timescales of years and decades, rather than multigenerational timescales of centuries and millennia. “Humanity now needs to prepare for changes in ecosystems that are faster than we previously envisaged through our traditional linear view of the world, including across Earth’s largest and most iconic ecosystems, and the social-ecological systems that they support.” The paper says this could be the case in Australia where the recent Australian bushfires followed protracted periods of drought and may indicate a shift to a drier ecosystem. Scientists were already aware that systems tended to decline much faster than they grew but the new study quantifies and explains this trend. “What is new is that we are showing this is part of a wider story. The larger the system, the greater the fragility and the proportionately quicker collapses,” John Dearing, professor in physical geography at the University of Southampton and lead author of the study, said. “What we are saying is don’t be taken in by the longevity of these systems just because they may have been around for thousands, if not millions, of years – they will collapse much more rapidly than we think.” Dearing said he was concerned that one of the possible implications of the study was that complete destruction of the Amazon could occur within his grandchildren’s lifetimes. “This is a paper that is satisfying from a scientific point of view, but worrying from a personal point of view. You’d rather not come up with such a set of results,” he said. A separate study last week warned the Amazon could shift within the next decade into a source of carbon emissions rather than a sink, because of damage caused by loggers, farmers and global heating. Experts said the new findings should be a spur to action. “I think the combination of theory, modelling and observations is especially persuasive in this paper, and should alert us to risks from human activities that perturb the large and apparently stable ecosystems upon which we depend,” said Georgina Mace, professor of biodiversity and ecosystems at University College London, who was not involved in the studies. “There are effective actions that we can take now, such as protecting the existing forest, managing it to maintain diversity, and reducing the direct pressures from logging, burning, clearance and climate change.” These views were echoed by Ima Vieira, an ecologist at Museu Emílio Goeldi in Belém, Brazil. “This is a very important paper. For Brazil to avoid the ecosystem collapse modelled in this study, we need to strengthen governance associated to imposing heavy fines on companies with dirty supply chains, divestment strategies targeting key violators and enforcement of existing laws related to environmental crimes. And we have to be quick.” However, the methodology was not universally accepted. Erika Berenguer, a senior research associate at the University of Oxford and Lancaster University, said the regime shifts paper relied too much on data from lakes and oceans to be useful as an indicator of what would happen to rainforests. “While there is no doubt the Amazon is at great risk and that a tipping point is likely, such inflated claims do not help either science or policy making,” she said. The authors said their study was not a forecast about a specific region but a guide to the speed at which change could occur."
"

Does global warming threaten to permanently cripple the global economy? According to a new report from the British Treasury prepared by economist Nicholas Stern, that’s exactly what will happen unless we cut greenhouse‐​gas emissions to 25 percent below current levels by 2050. Should we do it? A close reading of the report reveals that the answer is “not necessarily.”



Not to be flip about it, but why should the relatively poor (us) sacrifice for the relatively rich (our children and grandchildren)? The Stern Report argues that the emissions cuts necessary to stave off disaster will likely cost about one percent of global GDP every single year, or about $1,154 in current dollars per household in the United States. A small price to pay, we’re told, when GDP losses will likely total 5–10 percent of global GDP every year if we do absolutely nothing.



But even with a ten‐​percent reduction in GDP relative to what it would have been, 100 years from now, people will still be extraordinarily well off by current standards. For example, since 1950 real U.S. GDP per capita has increased by about two percent a year. Given that growth rate, real GDP per capita 100 years hence would be $321,684, or more than seven times higher than it is at present ($44,403). If global warming cuts GDP by ten percent a year beginning about 50 years from now, then GDP per capita will be $289,515 in 2106 rather than $321,684.



Would anyone, let alone liberals, ever propose a one‐​percent tax on those who make $44,000 to create benefits for those who make $289,000? In short, paying now to head off warming is a regressive intergenerational tax that takes from the poor and gives to the rich.



The direct costs associated with greenhouse gas emission controls include avoidable deaths in the developing world. The United Nations, for example, reports that about two million people on this planet die every year because they don’t have electricity and must burn biomass for heating and cooking. This results in greatly elevated levels of indoor air pollutants and premature deaths. Increasing the cost of electricity — an unavoidable consequence of ridding the global economy of the fossil fuels that generate greenhouse gases — will slow our ability to conquer this problem. 



Higher fossil fuel costs will also slow the general march out of poverty. Not only is poverty the number one killer on the planet, it is also the number one cause of environmental ruin. Deforestation, habitat loss, and air and water pollution are all strongly correlated with per capita income.



Nor are citizens in the industrialized West immune from the health effects associated with reduced income. Academics have established that every $15 million reduction of aggregate income causes one statistical death. That stands to reason; the poorer we are, the less likely we are (on average) to eat well, exercise, procure necessary health care services, and avoid unhealthy lifestyles. This effect alone suggests that in the U.S., greenhouse gas abatement, on the scale suggested by the Stern report, would cost more than 8,800 lives per year.



Of course, the Stern Report argues that the GDP losses associated with doing nothing dwarf the GDP losses associated with effective emissions controls. In a world with no doubts, spending one percent of U.S. GDP to eliminate a loss of ten percent of U.S. GDP every year beginning 50 years from now passes a cost‐​benefit test if we assume that GDP grows two percent per year, we discount future costs and benefits by five percent a year, and run our analysis out for 1,000 years. That calculation reveals that the present value of the costs would total $15,541 while the present value of the benefits would total $36,477. If the future stream of benefits were only five percent of future GDP, however, then it’s about a wash; $15,541 would get us only $18,239 in benefits.



But climate predictions are not certain. The Stern report argues that there’s at least a 50–50 chance that temperatures will rise five degrees Celsius over pre‐​industrial levels if we do nothing. You won’t find that argument in the latest report of the International Panel on Climate Change (IPCC), however, which offers a wide band of possible warming scenarios. The Stern Report’s estimate is within the upper boundary of what’s possible, but median warming projections are around 2–3 degrees Celsius.



It’s worth noting that when economists have crunched those median‐​warming projections in the academic literature, they have found that the costs associated with climate change are 0–2 percent of GDP rather than the 5–10 percent asserted in the Stern report. If the benefits are only two percent of future U.S. GDP, then $15,541 in costs in present value terms produces only $7,295 in benefits.



Finally, none of the above calculations consider the possibility that the costs will buy no benefits at all. The latest IPCC report, for instance, notes that the warming we’ve detected thus far is “unlikely (bordering on very unlikely) to be entirely the result of internal variability,” and that “natural forcing alone [i.e., solar and/​or volcanic activity] is unlikely to explain the increased rate of global warming since the middle of the 20th century.”



No matter how you read that, it’s clear that there is greater than zero chance that greenhouse‐​gas‐​emission cuts will produce no economic gains at all. Accordingly, all the benefit estimates above must be discounted to some degree (how much is in dispute) to reflect that possibility.



Think of the Stern Report as an elaborate economic pitch for an expensive insurance policy. Well, we’re not buying … yet.
"
"**In 2020, the billion-dollar blockbuster has been defeated by Covid-19 more convincingly than by any on-screen villain.**
Most of the year's proposed blockbusters - films with a budget of more than Â£100 million - are on hold.
The James Bond film No Time To Die has been postponed twice; Disney's live-action Mulan was released on the studio's streaming platform; and Top Gun: Maverick is still riding a motorbike to nowhere.
Even Marvel films such as Black Widow - reliable stalwarts of the summer event season - have been pushed back indefinitely, as studios wait for a return to normality.
But while screen heroes can't currently save the world, they may still be able to save the big screen experience, says Screen International's chief film critic, Finn Halligan.
""It's like we've been having a staring contest,"" she says, of the stand-off between film studios and cinemas. ""Someone's got to blink.""
A small sign of eye movement came with recent news that Wonder Woman 1984 would be released simultaneously at both US cinemas and online, on Christmas Day 2020.
The film, which plunges Gal Gadot, as the returning superhero, into an '80s universe, cost around Â£145m ($US 200m) to make. Originally scheduled to open in June, its release has already been delayed twice.
""The studios haven't wanted to sacrifice any potential billion-dollar movie during the pandemic,"" explains Halligan. ""They're too much of a valuable commodity.""
But the longer cinemas remain shut, the harder these decisions become.
According to The Hollywood Reporter, No Time To Die is costing film studio MGM $1m in interest every month. That money, which it originally borrowed to make the film, can't be made back until 007 hits the big screen.
Last year, nine films made more than $1bn at the global box office - including The Lion King, Joker, Avengers: Endgame and Captain Marvel.
Fast forward to summer 2020, and Christopher Nolan's Tenet - a film with a budget of $205m (Â£150m) - was the only mega-budget movie to be released in cinemas, grossing around $350m (Â£270m).
""The profits of Tenet spooked them, although I don't think it did badly in the circumstances,"" says Halligan.
""Studios still hope they can get the numbers, but the crunch point isn't the future existence of the blockbuster, the stress point will be the cinemas themselves.
""Will audiences feel safe to come back for a new Marvel film in the cinema, or wait for it on Disney+? And how long can cinemas survive in this situation?""
However, Asia may already be pointing the way towards a movie-going recovery. Wonder Woman 1984 will have a full theatrical release in China a week before the film is released in the US.
Up until now, Hollywood has refused to show its biggest movies first to audiences in Asia, Australia and New Zealand - where many cinemas are open again - partly due to piracy fears.
It's also significant that China is behind 2020's biggest blockbuster so far - Hu Guan's war epic, The Eight Hundred, about a group of Chinese soldiers under siege by the Japanese army. It made $468m (Â£345m) at the box office.
""2020 is the year that China, not the US, became the world's biggest movie market,"" Asian film critic Stevie Wong says. ""It's surpassed $1.9bn (Â£1.4bn) this year.
""And without Hollywood movies, local films have had a bigger chance in cinemas,"" Wong adds, citing the success of Chinese drama My People, My Homeland and Japanese Anime movie Demon Slayer: Kimetsu No Yaiba.
""The Eight Hundred's made close to half a billion dollars, although that can't compare with cinema profits from 2019,"" says Wong.
""But there are more local blockbusters coming, like Andy Lau's Shock Waves 2 or Daniel Wu's Caught in Time, that should bring in the audiences again.""
Film traffic between the US and Asia has historically been one-way, to Hollywood's benefit. Yet a Jackie Chan movie, Vanguard, the veteran action star's latest collaboration with director Stanley Tong, has just enjoyed one of the biggest ever North American releases for an Asian film.
The lavish action movie, which was made across five different countries including the UK, India and China, is playing on 1500 cinema screens replacing the delayed Bond film, No Time to Die.
""It was only about eight weeks ago that we acquired the film,"" explains Nolan Gallagher, the CEO of Gravitas Ventures. ""We moved fast.""
Gallagher believes that where cinemas are open, audiences are eager to see big-screen action.
""There is a business for blockbusters. Yes, it's only a fraction of what it was before the pandemic, but there's still a box office business,"" he says.
""People are looking for enjoyment over the Thanksgiving holiday, especially if you're looking for something that's got that globe-trotting action experience to it.""
The sight of busy cinemas in Asia have also given hope to Hollywood, according to Mark Gill, President of Solstice Studios, based in Los Angeles. The independent film company has just bought the rights to Gerard Butler action thriller The Plane, which starts shooting in 2021 and is set to be released, in cinemas, in 2022.
""China, Japan and Korea have showed us this year that fundamental movie-going habits haven't changed,"" Gill argues.
""The film Demon Slayer, which was such a hit in Japan, wasn't necessarily the most sophisticated film ever, but clearly there was pent-up demand for audiences to go to the cinema.
""I think it shows that one good blockbuster can be a real tipping point, if the conditions are right.""
Solstice was the first company to release a new film in US cinemas following the first wave of the pandemic.
""We feel that we got into the movie business to show films in cinemas,"" he explains. ""Someone had to go first.""
The film in question was psychological thriller Unhinged, starring Russell Crowe.
""Certainly, the box office was less than in normal times, but it was solid. And the reaction from Hollywood was amazement that we pulled it off - and helped us get a lot more movies going.""
The release plan for Wonder Woman 1984 - which sees Asia, Europe and Africa get the film before is Christmas Day debut in the US - might suggest Hollywood is waking up to Asia's growing self-sufficiency in the blockbuster market.
""It's yet another challenge to Hollywood's way of doing things,"" says Steven Gaydos, executive editor of content at Variety magazine.
""Asia has a freestanding movie industry making its own films, for its own audiences.
""Hollywood has historically relied on the rest of the world for about 65% of its movie profits. If Asia has a self-sufficient movie industry, they're saying that they don't need Hollywood films - that's a huge blow to the accepted wisdom.""
Yet Gaydos believes the behemoth-budget blockbuster is one of the few films guaranteed a future in Hollywood, with budgets unlikely to be cut at the top.
""The blockbuster is going nowhere,"" he says. ""Hollywood makes almost nothing else apart from them - they account for 95% of the box office. These film studios that make them have bet their own future on their continued success.
""These big expensive films are actually better bets than the cheaper movies, as you're pre-selling the spectacular production values and the stellar cast - that's the built-in appeal.
""But the whole world of independent movies and dramatic cinema - basically risky films that won't guarantee a return - was already drifting to streaming services,"" he adds.
It seems unlikely streaming services will be content to stop there, especially given reports that the makers of No Time to Die were in recent, unsuccessful, talks to put the Bond film on a home entertainment platform.
Netflix has just announced that Don't Look Up, a space-asteroid comedy starring Jennifer Lawrence and Leonardo DiCaprio is in production and will premiere on its app.
""Before Covid, in Hollywood, there was a room on fire,"" Gaydos comments. ""The pandemic has poured gasoline on the rest of the house.
""I never expected to wake up and read that Leo Di Caprio - one of the names in Hollywood that can launch a film in cinemas - will premiere on Netflix.""
If Wonder Woman 1984 performs strongly, and with reports of successful vaccines on the horizon, 2021 may still save the traditional big-screen blockbuster.
But Finn Halligan warns that studios have to act decisively, bearing in mind the immediate financial plight of many cinemas.
""Film companies should remember if you want to achieve those billion-dollar profits, you'll need a lot of cinema screens on which to show your films.""
_Vanguard is on release in cinemas across the US._"
"

Mr. Chairman, distinguished members of the subcommittee:



My name is Roger Pilon. I am vice president for legal affairs at the Cato Institute and director of Cato’s Center for Constitutional Studies. 1 I want to thank you, Mr. Chairman, for inviting me to testify today on “Guns and Butter: Setting Priorities in Federal Spending in the Context of Natural Disasters, Deficits, and War”—the purpose of the hearing being, as your letter of invitation states, “to focus on the limits and role of our federal government as outlined in the Constitution.”



I can well understand your concern to focus on that issue, Mr. Chairman. In Federalist 45, James Madison, the principal author of the Constitution, spoke to a skeptical nation, worried that the document the Constitutional Convention had just drafted gave the central government too much power. Be assured, he said, the powers of the new government were, and I quote, “few and defined.” How things have changed. Yet in its 218 years, the Constitution itself has changed very little. The questions before us, then, are (1) under that Constitution, how did we go from limited to essentially unlimited government, (2) what are the implications, and (3) what should be done about it?



A closely related question is whether Madison understood and correctly reported on the document he’d just drafted, or whether modern interpretations of the Constitution, which have allowed our modern Leviathan to arise, are correct. Let me say here that Madison was right; the modern interpretations are wrong. As a corollary, most of what the federal government is doing today is unconstitutional because done without constitutional authority. That contention will doubtless surprise many, but there you have it. I mean to speak plainly in this testimony and call things by their proper name.



But before I defend that contention by addressing those questions, let me note that the nominal subject of these hearings—“setting priorities in federal spending”—concerns mainly a matter of policy, not law. Unless some law otherwise addresses it, that is, how Congress prioritizes its spending is its and the people’s business—a political matter. By contrast, the subtext of these hearings, which I gather is the subcommittee’s principal concern, is “the limits and role of our federal government as outlined in the Constitution,” and that is mainly a legal question. I distinguish those questions, let me be clear, for a very important reason. It is because we live under a Constitution that establishes the rules for legitimacy. Thus, in the case at hand, Congress may have pressing policy reasons for prioritizing spending in a given way, but such reasons are irrelevant to the question of whether that spending is constitutional.



 **Constitutional Legitimacy**



Because that distinction and the underlying issue of legitimacy are so central to these hearings, they warrant further elaboration at the outset. In brief, our Constitution serves four main functions: to authorize, institute, empower, and limit the federal government. Ratification accomplished those ends, lending political and legal legitimacy to institutions and powers that purported by and large to be morally legitimate because grounded in reason. Taken together, the Preamble, the first sentence of Article I, the inherent structure of the document, and especially the Tenth Amendment indicate that ours is a government of delegated, enumerated, and thus limited powers. The Constitution’s theory of legitimacy is thus simple and straightforward: To be legitimate, a power must first have been delegated by the people, as evidenced by its enumeration in the Constitution. That is the doctrine of enumerated powers, the centerpiece of the Constitution. For the Framers, it was the main restraint against overweening government. In fact, the Bill of Rights, which we think of today as the main restraint, was an afterthought, added two years later for extra precaution.



Once that fundamental principle is grasped, a second follows: Federal powers can be expanded only by constitutional amendment, not by transient electoral or congressional majorities. Over the years, however, few such amendments have been added. In the main, therefore, Article I, section 8 enumerates the 18 basic powers of Congress—the power to tax, the power to borrow, the power to regulate commerce with foreign nations and among the states, and so forth, concluding with the power to enact such laws as may be necessary and proper for executing the government’s other enumerated powers. It is a short list, the idea being, as the Tenth Amendment makes explicit and the _Federalist_ explains, that most power is to remain with the states—or with the people, never having been delegated to either level of government. 2



In fact, given the paucity and character of the federal government’s enumerated powers, it is plain that the Framers meant for most of life to be lived in the private sector—beyond the reach of politics, yet under the rule of law—with governments at all levels doing only what they have been authorized to do. Far from authorizing the ubiquitous government planning and programs we have today, the Constitution allows only limited government, dedicated primarily to securing the conditions of liberty that enable people to plan and live their own lives. I turn, then, to the first of the questions set forth above: How did we move from a Constitution that limited government to one that is read today to authorize effectively unlimited government?



 **From Limited to Unlimited Government**



The great constitutional change took place in 1937 and 1938, during the New Deal, all without benefit of constitutional amendment; but the seeds for that change had been sown well before that, during the Progressive Era. 3 Before examining that transition, however, I want to lay a proper foundation by sketching briefly how earlier generations had largely resisted the inevitable pressures to expand government. It is an inspiring story, told best, I have found, in a thin volume written in 1932 by Professor Charles Warren of the Harvard Law School. Aptly titled, _Congress as Santa Claus: or National Donations and the General Welfare Clause of the Constitution,_ this little book documents our slow slide from liberty and limited government to the welfare state—and that was 1932! In truth, however, Warren’s despair over that slide notwithstanding, the book is a wonderful account of just how long we lived under the original design, for the most part, before things started to fall apart during the Progressive Era. And so I will share with the subcommittee just a few snippets and themes from the book, along with material from other sources, to convey something of a sense of how things have changed—not only in the law but, more important, in the culture, in our attitude toward the law.



When Thomas Jefferson wrote that it was the natural tendency for government to grow and liberty to yield, he doubtless had in mind his rival, Alexander Hamilton, for hardly had the new government begun to operate when Hamilton proposed a national industrial policy in his 1791 _Report on Manufactures._ 4 To Hamilton’s argument that Congress had the power to pronounce upon the objects that concern the general welfare and that these objects extended to “the general interests of learning, of agriculture, of manufacturing, and of commerce,” 5 Madison responded sharply that “the federal Government has been hitherto limited to the specified powers, by the Greatest Champions for Latitude in expounding those powers. If not only the _means,_ but the _objects_ are unlimited, the parchment had better be thrown into the fire at once.” 6 Congress shelved Hamilton’s _Report._ He lost that battle, but over time he won the war.



The early years saw numerous attempts to expand government’s powers, but the resistance mostly held. In 1794, for example, a bill was introduced in the House to appropriate $15,000 for the relief of French refugees who had fled to Baltimore and Philadelphia from an insurrection in San Domingo, 7 whereupon Madison rose on the floor to say that he could not “undertake to lay [his] finger on that article of the Federal Constitution which granted a right to Congress of expending, on objects of benevolence, the money of their constituents.” 8 Two years later a similar bill, for relief of Savannah fire victims, was defeated decisively, a majority in Congress finding that the General Welfare Clause afforded no authority for so particular an appropriation. 9 As Virginia’s William B. Giles observed, “[The House] should not attend to what… generosity and humanity required, but what the Constitution and their duty required.” 10



Those early attempts to expand Congress’s power, and the resistance to them, centered on the so‐​called General Welfare Clause of the Constitution, found in the first of Congress’s 18 enumerated powers. 11 Hamilton argued that the clause authorized Congress to tax and spend for the general welfare. Not so, said Madison, Jefferson, and many others. South Carolina’s William Drayton put it best in 1828:



If Congress can determine what constitutes the General Welfare and can appropriate money for its advancement, where is the limitation to carrying into execution whatever can be effected by money? How few objects are there which money cannot accomplish! …Can it be conceived that the great and wise men who devised our Constitution… should have failed so egregiously… as to grant a power which rendered restriction upon power practically unavailing? 12



Stated differently—with reference to constitutional structure—what was the point of enumerating Congress’s powers if any time it wanted to do something it was not authorized to do, because there was no power granted to do it, Congress could simply say it was spending for the “general welfare” and thus make an end‐​run around the limits imposed by the doctrine of enumerated powers? Enumeration would have been pointless.



That argument largely held through the course of the 19th century. To be sure, inroads on limited government were made on other constitutional grounds, as Warren recounts. Congress made gifts of land held in trust under the Public Lands Clause, for example, with dubious consideration given in return; then gifts of revenues from the sale of such lands; and finally, gifts of tax revenues generally. 13 But there were also numerous examples of resistance to such redistributive schemes. Thus, in 1887, 100 years after the Constitution was written, President Grover Cleveland vetoed a bill appropriating $10,000 for distribution of seeds to Texas farmers suffering from a drought. 14 In his veto message he put it plainly: “I can find no warrant for such an appropriation in the Constitution.” 15 Congress sustained the veto. And as late as 1907 we find the Supreme Court expressly upholding the doctrine of enumerated powers in _Kansas v. Colorado:_



The proposition that there are legislative powers affecting the Nation as a whole which belong to, although not expressed in [,] the grant of powers, is in direct conflict with the doctrine that this is a government of enumerated powers. … The natural construction of the original body of the Constitution is made absolutely certain by the Tenth Amendment. 16



Thus, although the doctrine of enumerated powers faced political pressure from the start, and increasing pressure as time went on, the pattern we see through our first 150 years under the Constitution can be summed up as follows. In the early years, measures to expand government’s powers beyond those enumerated in the Constitution rarely got out of Congress because they were stopped by objections in that branch— _constitutional_ objections. Members of Congress actually debated whether they had the power to do whatever it was that was being proposed; they didn’t simply assume they had the power and then leave it to the courts to check them. _Congress took the Constitution and the limits it imposed on congressional action seriously._ 17 Then when constitutionally dubious bills did get out of Congress, presidents vetoed them—not simply on policy but on constitutional grounds. And finally, when that brake failed, the Court stepped in. In short, the system of checks and balances worked because the Constitution was taken seriously by sufficient numbers of those who had sworn to uphold it.



The Progressive Era called all of that into question. Marked by a fundamental change in the climate of ideas, it paved the way for the New Deal. In fact, as early as 1900 we could find _The Nation,_ before it became an instrument of the modern left, lamenting the demise of classical liberalism. In an editorial entitled “The Eclipse of Liberalism,” the magazine’s editors surveyed the European scene, then wrote that in America, too, “recent events show how much ground has been lost. The Declaration of Independence no longer arouses enthusiasm; it is an embarrassing instrument which requires to be explained away. The Constitution is said to be ‘outgrown.’ ” 18



The Progressives to whom those editors were pointing, sequestered often in elite universities of the East, were animated by ideas from abroad: British utilitarianism, which had supplanted the natural rights theory on which the Constitution rested; German theories about good government, as reflected in Chancellor Otto von Bismarck’s social security experiment; plus our own homegrown theories about democracy and pragmatism. 19 Combined with the emerging social sciences, those forces constituted a heady brew that nourished grand ideas about the role government could play in improving the human condition. No longer viewing government as a necessary evil, as the Founders had, Progressives saw the state as an engine of good, an instrument through which to solve all manner of social and economic problems. In a word, it was to be better living through bigger government. 20



But a serious obstacle confronted the political activists of the Progressive Era—that troublesome Constitution and the willingness of judges to enforce it. Dedicated to liberty and limited government, and hostile to government planning garbed even in “the public good,” the Constitution stood as a bulwark against overweening government, much as the Framers intended it would. Not always, 21 to be sure, but for the most part.



With the onset of the New Deal, however, Progressives shifted the focus of their activism from the state to the federal level. But they fared little better there as the Court found several of President Franklin Roosevelt’s schemes unconstitutional, holding that Congress had no authority to enact them. 22 Not surprisingly, that prompted intense debate within the administration over how to deal with “the nine old men.” It ended early in 1937, following the landslide election of 1936, when Roosevelt unveiled his infamous Court‐​packing scheme—his plan to pack the Court with six new members. The reaction in the country was immediate. Not even the overwhelmingly Democratic Congress—nearly four to one in the House—would go along with the scheme. Nevertheless, the Court got the message. There followed the famous “switch in time that saved nine” and the Court began rewriting the Constitution—again, without benefit of constitutional amendment.



It did so in two main steps. In 1937 the Court eviscerated the doctrine of enumerated powers. Then in 1938 it bifurcated the Bill of Rights and invented a bifurcated theory of judicial review. For the purpose of these hearings, it is one half of the 1937 step that is most important, the rewriting of the General Welfare Clause; but the rest merits a brief discussion as well, to give a more complete picture of this constitutional revolution.



In 1936, in _United States v. Butler,_ 23 the Court had found the Agricultural Adjustment Act 24 unconstitutional. But in the course of doing so it opined on the great debate between Madison and Hamilton over the meaning of the so‐​called General Welfare Clause, coming down on Hamilton’s side—yet only in dicta and hence not as law. A year later, however, following the Court‐​packing threat, the Court elevated that dicta as it upheld the Social Security Act 25 in _Helvering v. Davis._ 26 The words were ringing: “Congress may spend money in aid of the ‘general welfare,’ ” 27 said the 1937 Court. Moreover, “the concept of the general welfare [is not] static. Needs that were narrow or parochial a century ago may be interwoven in our day with the well‐​being of the nation.” 28 Thus were the floodgates opened. The modern welfare state was unleashed.



But if Congress could now engage in unbounded redistribution, so too could it regulate at will following the Court’s decision that same year in _NLRB v. Jones & Laughlin Steel Corp._ 29 The issue there was the scope of Congress’s power to regulate interstate commerce, a power Congress had been granted to address the impediments to interstate commerce that had arisen under the Articles of Confederation as states were imposing tariffs and other measures to protect local merchants and manufacturers from out‐​of‐​state competition. Thus, the power was meant mainly to enable Congress to ensure the free flow of goods and services among the states—to make that commerce “regular,” as against state and other efforts to impede it. 30 It was not a power to regulate anything for any reason. Yet that, in effect, is what it became as the 1937 _Jones & Laughlin_ Court held that Congress had the power to regulate anything that “affected” interstate commerce, which is virtually everything.



The doctrine of enumerated powers now effectively eviscerated—the floodgates open for the modern redistributive and regulatory state to pour through—only the Bill of Rights stood athwart that unbounded power. So in 1938, in famous footnote 4 of _United States v. Carolene Products,_ 31 the Court addressed that impediment to Leviathan by distinguishing “fundamental” and “nonfundamental” rights, in effect, and inventing a bifurcated theory of judicial review to complement that distinction. If a law implicated “fundamental” rights like speech or voting, the Court would apply “strict scrutiny” and would doubtless find it unconstitutional. By contrast, if a law implicated “nonfundamental” rights like property, contract, or the rights we exercise in ordinary commercial relations, the Court would uphold the law as long as there was some “rational basis” for it. 32 That judicial deference to the political branches regarding economic rights, coupled with strict scrutiny for political rights, amounted to the democratization and to the politicization of the Constitution, to opening the door to political control of economic affairs, public and private alike, beyond anything the Framers could have imagined. 33



The rest is history, as we say, with redistributive and regulatory schemes, federal, state, and local, pouring forth. Others on this panel can testify as to the numbers that illustrate that explosion in government programs. My concern, rather, is to outline how it happened that under a Constitution meant to limit government we got a government of effectively unlimited power.



Toward that end, and beyond the history of the matter, let me add that most of the spending that is the focus of these hearings has arisen under the so‐​called General Welfare Clause, which the Court has also referred to as the Spending Clause. In truth, however, there are no such clauses in the Constitution, 34 which is why I have invoked the term “so‐​called.” A careful reading of the first of Congress’s 18 enumerated powers, which is the nominal source of those so‐​called clauses, coupled with reflection on the structure of the document, will reveal merely a power to tax at the head of Article I, section 8, much as the second of Congress’s enumerated powers is the power to borrow. If Congress exercises either or both of those powers—or its Article IV power to “dispose” of public lands, for that matter—and it wants then to appropriate and spend the proceeds on any of the ends that are authorized to it, it must do so under the Necessary and Proper Clause. For taxing, borrowing, disposing, appropriating, and spending are distinct powers. The first three are expressly authorized to Congress. Appropriating and spending, by contrast, are necessary and proper _means_ toward executing the powers authorized to the government—means provided for under the Necessary and Proper Clause. As such, they are not _independent_ but only _instrumental_ powers, exercised in service of ends _that in turn limit their use to those ends._ Put simply, Congress cannot appropriate and spend for any end it wishes, but only for those ends it is authorized to pursue—and they are, as Madison said, “few and defined.”



We come, then, to the nub of the matter. Search the Constitution as you will, you will find no authority for Congress to appropriate and spend federal funds on education, agriculture, disaster relief, retirement programs, housing, health care, day care, the arts, public broadcasting—the list is endless. That is what I meant at the outset when I said that most of what the federal government is doing today is unconstitutional because done without constitutional authority. Reducing that point to its essence, the Constitution says, in effect, that everything that is not authorized—to the government, by the people, through the Constitution—is forbidden. Progressives turned that on its head: Everything that is not forbidden is authorized.



But don’t take my word for it. Take the word of those who engineered the constitutional revolution. Here is President Roosevelt, writing to the chairman of the House Ways and Means Committee in 1935: “I hope your committee will not permit doubts as to constitutionality, however reasonable, to block the suggested legislation.” 35 And here is Rexford Tugwell, one of the principal architects of the New Deal, reflecting on his handiwork some thirty years later: “To the extent that these new social virtues [i.e., New Deal policies] developed, they were tortured interpretations of a document [i.e., the Constitution] intended to prevent them.” 36 They knew exactly what they were doing—turning the Constitution on its head. That is the legacy we live with today.



 **Implications of the Constitutional Revolution**



That legacy has many implications. Let me distinguish five. First, and perhaps most important, is the loss of legitimacy—moral, political, and legal. Today, we tend to think mainly of political legitimacy, failing to see how the several grounds of legitimacy go together. We imagine that the people, by their periodic votes, tell the government what they want; and to the extent that it responds to that expression of political will, consistent with certain state immunities and individual rights that might check it, the government and its actions are legitimate. Whatever moral legitimacy flows from that view is a function of the moral right of self‐​government, but that right is largely open‐​ended regarding the arrangements it might produce. It could produce limited government. But it could as easily produce unlimited government. 37 And without a keen sense of the role and place of moral legitimacy, we are indifferent as to which it is.



That view characterizes legitimacy in a parliamentary system, more or less; it is not how legitimacy operates in our constitutional republic. Rather, as shown by the Declaration of Independence, the main principles of which shaped the Constitution, we find our roots in Lockean state‐​of‐​nature theory and its underlying theory of natural rights. 38 Legitimacy is first defined by the moral order, by the rights and obligations we have with respect to each other. Only then do we turn to political and legal legitimacy, through the social contract—the Constitution—that facilitates and reflects it. As outlined earlier, the federal government gets its powers by delegation from the people through ratification—reflecting mainly the (natural) powers the people have to give it—not through subsequent elections, which are designed primarily to fill elective offices. To be sure, many of the powers thus delegated leave room for discretion by those elected. That is why elections matter: different candidates may have different views on the exercise of that discretion—the discretion to declare war, to take a clear example. But through elections the people can no more give government a power it does not have than they can take from individuals a right they do have. In a constitutional republic like ours, it is the Constitution that sets the powers, not the people through periodic elections.



But when powers or rights are expanded or contracted not through ratification but through elections and the subsequent actions of elected officials, and the courts fail to check that, the Constitution is undermined and the powers thus created are illegitimate. That happened when the New Deal Court bowed to the political pressure brought on by Roosevelt’s Court‐​packing threat. And that paved the way for powers that have never been _constitutionally_ authorized by the people—for illegitimate powers, that is—and for the accompanying loss of rights.



Some would argue that we could correct that problem of illegitimacy simply by putting our present arrangements to a vote through the supermajoritarian amendment and ratification procedures provided for in Article V. Were that vote successful, that would indeed produce political and legal legitimacy. But because the Constitution as it stands today reflects fairly closely, in my judgment, the moral order that can be justified—in other words, the Framers and those who subsequently amended the document got it right, for the most part—I would object to amending the Constitution simply to lend political and legal legitimacy to the modern welfare state. Better, I believe, to be able to point not simply to that state’s moral illegitimacy but to its political and legal illegitimacy as well.



The second untoward implication of our departure from the Constitution is the chaos that follows for law more generally. 39 The judicial methodology the Constitution contemplates for most constitutional questions is really quite simple. Assuming a court has jurisdiction in a case challenging a given federal statute, the first question is whether Congress had authority to enact the statute. If not, that ends the matter. If yes, the next question is whether and how the act may implicate rights, enumerated or unenumerated.



Those questions are not always easy to answer and often involve close calls. But the difficulties are multiplied exponentially when the floodgates are opened and federal, state, and local legislation pours through, producing often inconsistent and incoherent “law” from every direction. Add to that, as noted above, the tendentious and politicized judicial methodology that flowed from _Carolene Products_ —today we have three and sometimes four “levels” of judicial review, 40 each with its own standards, and multi‐​factored “balancing” tests—and it soon becomes clear that we are far removed from a Constitution that was written to be understood at least by the educated layman. Life is complicated enough on its own terms. When government intrudes in virtually every corner of life, the complications can easily become overwhelming and unbearable. The Constitution was meant to bring order. If under it “anything goes,” order goes too, and chaos follows.



Closely related to those two implications is a third: disrespect for the Constitution entails disrespect for the rule of law itself. If Congress can redistribute and regulate virtually at will, unrestrained by the limits the Constitution imposes, the rule of law is at risk. By definition, unauthorized powers intrude on rights retained by the people; but a cavalier attitude toward powers can lead more directly to the same attitude toward rights: if powers can be expanded with impunity, so too can rights be contracted. 41 In fact, a “living constitution,” interpreted to maximize political discretion, can be worse than no constitution at all, because it preserves the patina of constitutional legitimacy while unleashing the political forces that a constitution is meant to restrain. And how long can “anything goes” for officials go unnoticed by the citizenry? A general decline in respect for law must follow.



Fourth, when constitutional integrity declines we lose the discipline a constitution is designed to impose on government. A constitution makes it harder for government to act, which is one of the main reasons for having one. This implication speaks to one of the basic functions of a constitution, which is not only to empower but to _limit_ the government that is created through it. In the original position, when we created and ratified the Constitution, we agreed to limit the government’s power as an act of self‐​discipline. We could have set no limits on the government’s power, of course; but that would have left us to a future determined by the political winds, and experience had taught us the perils of that course. Thus, we struck what we thought was a careful balance, giving the government enough power to do what we thought it should do, but reserving to ourselves the liberty appropriate to a free people. With that balance struck, the Constitution would serve to discipline us and future generations who might be tempted, given the circumstances, to grant the government more power than, in our considered judgment, we thought prudent.



Future generations could adjust that balance, of course, by amending the Constitution, provided sufficient numbers among them wanted to do so. In fact, that is just what happened following the Civil War. Troubled as the Framers were about the institution of slavery, which they recognized only obliquely in the Constitution to ensure union, they left its regulation to the states. After the Civil War, however, a new generation not only abolished slavery but, through the Fourteenth Amendment, fundamentally changed the balance between the federal government and the states. With the ratification of that amendment we finally had federal remedies against state violations of our rights. 42 Thus, although the amendment is properly read as having expanded _federal_ power, it was done to discipline _state_ power. A new balance was struck, to be sure, but because it was done through the constitutional process it did not amount to abandoning the discipline a constitution imposes, which is what happens when we stray from the document’s principles. In fact, the contrast between the different ways in which the Civil War and the New Deal generations changed the rules is stark and instructive. The Civil War generation did it the right way—through the ratification process. The New Deal generation, faced with a choice between amending the Constitution and changing it by judicial legerdemain, chose the latter.



But the larger picture regarding discipline should not be lost. For just as the Constitution disciplines the government, so too it disciplines the people in their daily lives. Professor Warren captures that point nicely with a quote from South Carolina’s Warren R. Davis, speaking in the House on April 4, 1832:



This system of transferring property by legislation—of giving pensions and gratuities to individuals, companies, corporations, and the States— … will degrade the States by inducing them to look for bounties, to the Federal Government; will degrade and demoralize the people, by making them dependent on the Government; will emasculate the free spirit of the country …. As soon as the people of ancient Rome were taught to look to the public granaries for support, the decay of public virtue was instantaneous. 43



Vast numbers of Americans today look to Washington for a rich array of “entitlements” that speak of nothing so much as the illusion of something for nothing. And politicians nurture that illusion, propelling us all in the downward spiral that Thomas Hobbes aptly called a war of all against all. Stated otherwise, as contributors to public largesse become fewer and recipients more numerous, the downward spiral becomes a death spiral. And we are headed in that direction as discipline continues to erode.



Finally, and closely related, let me little more than mention the economic implications of effectively unlimited government as I expect that others on the panel will address those more fully. By this point in human history, and especially after the collapse of the socialist experiments of the 20th century, we have a fairly clear understanding of the connection between liberty and prosperity—a connection that Adam Smith articulated so well in 1776, 44 and economists like Mises, Hayek, and Friedman, among many others, have refined and extended in our own time. What that understanding points to, once again, is the prescience of the Framers in drafting a constitution dedicated to securing our liberty and hence our extraordinary prosperity. But neither liberty nor prosperity is guaranteed by a mere parchment, especially by one that is ignored. The American economy has proven resilient enough to withstand the blows imposed by the galloping government of the 20th century—although we will never know how much more prosperous we might have been had that government been better reined. In future, however, to the extent we ignore the lessons of economics we invite the consequences that have befallen so many other nations that have chosen economic planning over economic liberty. And the basic lesson of economics is that liberty, property, and contract are the fundamental preconditions of prosperity.



 **What Is to Be Done?**



We did not create our overextended, unconstitutional government overnight. We cannot restore constitutional government overnight—too many people have come to rely on the irresponsible promises that have been made. But we can begin the process of restoration. For that, the most important thing to do now is to start restoring a constitutional ethos in the nation. And that should be the business of all branches, not simply the Court, which can hardly do the job by itself, even if it were the right body to do so. What we have here, in short, is not simply or even mainly a legal problem. Rather, it is a political and, more deeply still, a moral problem.



Because I have discussed what needs to be done in some detail in chapter 3 of the _Cato Handbook on Policy,_ 45 copies of which are available in every congressional office, I will simply outline those proposals here.



Limits on government today, when we’ve had them, have come largely from political and budgetary rather than from constitutional considerations. It has not been because of any perceived lack of constitutional authority that government in recent years has failed to undertake a program but because of practical limits on the power of government to tax and borrow—and even those limits have failed in times of economic prosperity. To restore truly limited government, therefore, we have to do more than define the issues as political or budgetary. We have to go to the heart of the matter and raise the underlying constitutional questions. In a word, we have to ask the most fundamental question of all: Does the government have the authority, the constitutional authority, to do what it is doing?



That means, of course, that we are going to have to come to grips with the present state of public debate on the subject. It surely counts for something that a substantial number of Americans—to say nothing of the organs of public opinion—have little apprehension of or appreciation for the Constitution’s limits on activist government. Thus, when thinking about how and how fast to reduce government, we have to recognize that the Court, after nearly 70 years of arguing otherwise, is hardly in a position, by itself, to relimit government in the far‐​reaching way a properly applied Constitution requires. But neither does Congress at this point have sufficient moral authority, even if it wanted to, to end tomorrow the vast array of programs it has enacted over the years with insufficient constitutional authority.



For either Congress or the Court to be able to do fully what should be done, therefore, a proper foundation must first be laid. In essence, the climate of opinion must be such that a sufficiently large portion of the American public stands behind the changes that are undertaken. When enough people come forward to ask—indeed, to demand—that government limit itself to the powers it is given in the Constitution, thereby freeing individuals, families, and communities to solve their own problems, we will know we are on the right track.



Fortunately, a change in the climate of opinion on such basic questions has been under way for some time now. The debate today is very different than it was in the 1960s and 1970s. But there is a good deal more to be done before Congress and the courts are able to move in the right direction in any far‐​reaching way.



To continue the process, Congress should take the lead by engaging in constitutional debate in Congress, much as happened in the 19th century, thereby encouraging constitutional debate in the nation. That was urged by the House Constitutional Caucus during the 104th Congress. Under the leadership of House freshmen like J. D. Hayworth and John Shadegg of Arizona, Sam Brownback of Kansas, and Bob Barr of Georgia, together with a few more senior congressmen like Richard Pombo of California, an informal Constitutional Caucus was established in the “radical” 104th Congress. Unfortunately, the caucus has been moribund since then. It needs to be revived—along with the spirit of the 104th Congress—and its work needs to be expanded.



By itself, of course, neither the caucus nor the entire Congress can solve the problem before us. To be sure, in a reversal of all human experience, Congress in a day could agree to limit itself to its enumerated powers and then roll back the countless programs it has enacted by exceeding that authority. But it would take authoritative opinions from the Supreme Court, reversing a substantial body of largely post‐​New Deal decisions, to embed those restraints in “constitutional law”—even if they have been embedded in the Constitution from the outset, the Court’s modern readings of the document notwithstanding.



The ultimate goal of the caucus and Congress, then, should be to encourage the Court to reach such decisions. But history teaches, as noted above, that the Court does not operate entirely in a vacuum—that to some degree public opinion is the precursor and seedbed of its decisions. Thus, the more immediate goal of the caucus should be to influence the debate in the nation by influencing the debate in Congress. To do that, it is not necessary or even desirable, in the present climate, that every member of Congress be a member of the caucus—however worthy that end might ultimately be—but it is necessary that those who join the caucus be committed to its basic ends. And it is necessary that members establish a clear agenda for reaching those ends.



To reduce the problem to its essence, every day members of Congress are besieged by requests to enact countless measures to solve endless problems. Indeed, one imagines that no problem is too personal or too trivial not to warrant _federal_ attention, no less. Yet most of the “problems” Congress spends most of its time addressing—from health care to day care to retirement security to economic competition—are simply the personal and economic problems of life that individuals, families, and firms, not governments, should be addressing—quite apart from the absence of constitutional authority to address them.



Properly understood and used, then, the Constitution can be a valuable ally in the efforts of the caucus and Congress to reduce the size and scope of government. For in the minds and hearts of most Americans, it remains a revered document, however little it may be understood by a substantial number of them.



If the Constitution is to be thus used, however, the principal misunderstanding that surrounds it must be recognized and addressed. In particular, the modern idea that the Constitution, without further amendment, is an infinitely elastic document that allows government to grow to meet public demands of whatever kind must be challenged. More Americans than presently do must come to appreciate that the Framers, who were keenly aware of the expansive tendencies of government, wrote the Constitution precisely to check that kind of thinking and that possibility. To be sure, they meant for government to be our servant, not our master, but they meant it to serve us in a very limited way—by securing our rights, as the Declaration of Independence says, and by doing those few other things that government does best, as spelled out in the Constitution.



In all else, as discussed above, we were meant to be free—to plan and live our own lives, to solve our own problems, which is what freedom is all about. Some may characterize that vision as tantamount to saying, “You’re on your own,” but that kind of response simply misses the point. In America individuals, families, and organizations have never been “on their own” in the most important sense. They have always been members of communities, of civil society, where they could live their lives and solve their problems by following a few simple rules about individual initiative and responsibility, respect for property and promise, and charity toward the few who need help from others. Massive government planning and programs have upset that natural order of things—less so in America than elsewhere, but very deeply all the same.



Those are the issues that need to be discussed, both in human and in constitutional terms. We need, as a people, to rethink our relationship to government. We need to ask not what government can do for us but what we can do for ourselves and, where necessary, for others—not through government but apart from government, as private citizens and organizations. That is what the Constitution was written to enable. It empowers government in a very limited way. It empowers people—by leaving them free—in every other way.



To proclaim and eventually secure that vision of a free people, the Constitutional Caucus should reconstitute itself and rededicate itself to that end in the 109th Congress and at the beginning of every Congress hereafter. Standing apart from Congress, the caucus should nonetheless be both of and above Congress—as the constitutional conscience of Congress. Every member of Congress, before taking office, swears to support the Constitution—hardly a constraining oath, given the modern Court’s open‐​ended reading of the document. Members of the caucus should dedicate themselves to the deeper meaning of that oath. They should support the Constitution the Framers gave us, as amended by subsequent generations, not as “amended” by the Court’s expansive interpretations.



Acting together, the members of the caucus could have a major impact on the course of public debate in this nation—not least, by virtue of their numbers. What is more, there is political safety in those numbers. As Benjamin Franklin might have said, no single member of Congress is likely to be able to undertake the task of restoring constitutional government on his own, for in the present climate he would surely be hanged, politically, for doing so. But if the caucus hangs together, the task will be made more bearable and enjoyable—and a propitious outcome made more likely.



On the agenda of the caucus, then, should be those specific undertakings that will best stir debate and thereby move the climate of opinion. Drawn together by shared understandings, and unrestrained by the need for serious compromise, the members of the caucus are free to chart a principled course and employ principled means, which they should do.



They might begin, for example, by surveying opportunities for constitutional debate in Congress, then making plans to seize those opportunities. Clearly, when new bills are introduced, or old ones are up for reauthorization, an opportunity is presented to debate constitutional questions. But even before that, when plans are discussed in party sessions, members should raise constitutional issues. Again, the caucus might study the costs and benefits of eliminating clearly unconstitutional programs, the better to determine which can be eliminated most easily and quickly.



Above all, the caucus should look for strategic opportunities to employ constitutional arguments. Too often, members of Congress fail to appreciate that if they take a principled stand against a seemingly popular program—and state their case well—they can seize the moral high ground and prevail ultimately over those who are seen in the end to be more politically craven.



All of that will stir constitutional debate—which is just the point. For too long in Congress that debate has been dead, replaced by the often dreary budget debate. This nation was not established by men with green eyeshades. It was established by men who understood the basic character of government and the basic right to be free. That debate needs to be revived. It needs to be heard not simply in the courts—where it is twisted through modern “constitutional law”—but in Congress as well.



Before concluding, Mr. Chairman, let me leave the subcommittee with three basic recommendations, which I have discussed more fully in the _Cato Handbook_ I referenced above:



 **Conclusion**



America is a democracy in the most fundamental sense of that idea: authority, or legitimate power, rests ultimately with the people. But the people have no more right to tyrannize each other through democratic government than government itself has to tyrannize the people. When they constituted us as a nation by ratifying the Constitution and the amendments that have followed, our forefathers gave up only certain of their powers, enumerating them in a written constitution. We have allowed those powers to expand beyond all moral and legal bounds—at the price of our liberty and our well‐​being. The time has come to return those powers to their proper bounds, to reclaim our liberty, and to enjoy the fruits that follow.



BIOGRAPHICAL SKETCH OF ROGER PILON



Roger Pilon is vice president for legal affairs at the Cato Institute where he holds the B. Kenneth Simon Chair in Constitutional Studies and directs Cato’s Center for Constitutional Studies, which he founded in 1989. Prior to joining Cato he held five senior posts in the Reagan Administration, at the Office of Personnel Management, the State Department, and the Justice Department. A philosopher of law by profession, Mr. Pilon did his undergraduate work at Columbia University, earning a B.A. in philosophy in 1971. He did his graduate work at the University of Chicago, earning an M.A. in 1972 and a Ph.D. in 1979, both in philosophy. In 1988 he earned a J.D. from the George Washington University School of Law. He taught philosophy at the California State University at Sonoma in 1977 and philosophy of law at the Emory University School of Law from 1978 to 1979. From 1979 to 1980 he was a national fellow at the Hoover Institution on War, Revolution and Peace at Stanford University and from 1980 to 1981 an Institute for Educational Affairs fellow at the Institute for Humane Studies in Menlo Park, California. Mr. Pilon has published and lectured widely in the area of moral, political, and legal theory. He testifies often before Congress and is a frequent guest on television and radio programs discussing legal issues of the day. In 1989 the National Press Foundation and the Commission on the Bicentennial of the U.S. Con¬stitution presented him with the Benjamin Franklin Award for excellence in writing on the U.S. Constitution. In 2001 Columbia University’s School of General Studies awarded him its Alumni Medal of Distinction.



1 A biographical sketch is attached.



2 The Tenth Amendment states: “The powers not delegated to the United States by the Constitution, nor prohibited by it to the States, are reserved to the States respectively, or to the people.”



3 For a discussion of the Progressives’ approach to the Constitution, see Richard A. Epstein, “The Monopolistic Vices of Progressive Constitutionalism,” 2004–2005 _Cato Supreme Court Review 11_ (2005); Richard A. Epstein, _How Progressives Rewrote the Constitution_ (Cato Institute, 2006) (forthcoming).



4 See Arthur Harrison Cole ed., _Industrial and Commercial Correspondence of Alexander Hamilton_ 247 (A. M. Kelley, 1968).



5 Id.



6 Letter to Henry Lee, in 6 _The Writings of James Madison,_ at 81n. (Gaillard Hunt ed., G. P. Putnam’s Sons, 1906) (original emphasis).



7 Act of Feb. 12, 1794, 6 Stat. 13.



8 4 Annals of Cong. 170 (1794).



9 6 Annals of Cong. 1727 (1796).



10 Id. at 1724.



11 The Congress shall have Power To lay and collect Taxes, Imposts and Excises, to pay the Debts and provide for the common Defense and General Welfare of the United States; …”



12 4 Reg. Deb. 1632–34 (1828). Madison made a similar point on several occasions. See, e.g., James Madison, “Report on Resolutions,” in 6 _The Writings of James Madison_ 357 (Gaillard Hunt ed., G. P. Putnam’s Sons, 1900): “Money cannot be applied to the _general welfare,_ otherwise than by an application of it to some particular measure conducive to the general welfare. Whenever, therefore, money has been raised by the general authority, and is to be applied to a particular measure, a question arises whether the particular measure be within the enumerated authorities vested in Congress. If it be, the money requisite for it may be applied to it; if it be not, no such application can be made.” (emphasis in original). And Jefferson also addressed the issue. See, e.g., “Letter from Thomas Jefferson to Albert Gallatin” (June 16, 1817) in _Writings of Thomas Jefferson_ 91 (Paul Leicester Ford ed., New York, 1899): “[O]ur tenet ever was, and, indeed, it is almost the only landmark which now divides the federalists from the republicans, that Congress had not unlimited powers to provide for the general welfare, but were restrained to those specifically enumerated; and that, as it was never meant they should … raise money for purposes which the enumeration did not place under their action; consequently, that the specification of powers is a limitation of the purpose for which they may raise money.”



13 Charles Warren, _Congress as Santa Claus_ 32 (Arno Press, 1932).



14 H.R. 10203, 49th Cong., 2d Sess. (1887).



15 18 Cong. Rec. 1875 (1887).



16 _Kansas v. Colorado_ 206 U.S. 46, 89 (1907).



17 Contrast that with Congress’s enactment of the Gun‐​Free Schools Act of 1990 (18 U.S.C. § 922 (q)(1)(A) (1988 ed., Supp. V), which the Court found unconstitutional in 1995, holding for the first time in nearly 60 years that Congress had exceeded its authority under the Commerce Clause. _United States v. Lopez,_ 514 U.S. 549 (1995). In enacting the statute, Congress had not even bothered to cite its constitutional authority for doing so.



18 _The Nation,_ Aug. 9, 1900, p. 105.



19 See Robert S. Summers, Pragmatic Instrumentalism: America’s Leading Theory of Law, 5 _Cornell Law Forum_ 15 (1978).



20 Progressives did not limit their attention to economic regulation. In 1927, for example, we find Justice Oliver Wendell Holmes, the “Yankee from Olympus,” writing for the Court to uphold a Virginia statute that authorized the sterilization of people thought to be of insufficient intelligence. _Buck v. Bell,_ 274 U.S. 200 (1927). There followed in this country some 70,000 sterilizations. For an insightful discussion of the case and surrounding issues, see William E. Leuchtenburg, Mr. Justice Holmes and Three Generations of Imbeciles, ch. 1 in _The Supreme Court Reborn: The Constitutional Revolution in the Age of Roosevelt_ (1995).



21 _Buck v. Bell, supra_ note 20, is a good example, as is _Euclid v. Ambler Realty,_ 272 U.S. 365 (1926), which upheld a zoning ordinance involving a regulatory taking of property without compensation.



22 Thus, on “Black Monday,” May 27, 1935, in three 9–0 decisions, the Court invalidated the National Industrial Recovery Act and the Frazier‐​Lemke Act on mortgage moratoria and, in _Humphrey’s Executor v. United States,_ circumscribed the president’s power to remove members of independent regulatory commissions. For a discussion of this era, see Leuchtenberg, _The Supreme Court Reborn,_ supra note 20.



23 262 U.S. 1, 65–66 (1936).



24 7 U.S.C.A. 601 (1933).



25 49 Stat. 620 (1935).



26 301 U.S. 619, 640 (1937).



27 Id.



28 Id. at 641.



29 301 U.S. 619 (1937); see also _Wickard v. Filburn,_ 317 U.S. 111 (1942)./p>



30 See Randy E. Barnett, The Original Meaning of the Commerce Clause, 68 U. Chi. L. Rev. 101 (2000); Brief of _Amicus Curiae_ Cato Institute, _Jones v. United States,_ 529 U.S. 848 (2000) (visited Oct. 21, 2005).; Cf., Richard A. Epstein, The Proper Scope of the Commerce Power, 73 _Va. Law Review 1387_ (1987).



31 304 U.S. 104 (1938). For a devastating critique of the politics behind the _Carolene Products_ case, see Geoffrey P. Miller, The True Story of _Carolene Products,_ 1987 _Supreme Cato Review_ 397.



32 I have discussed that methodology in Roger Pilon, Foreword: Substance and Method at the Court, 2002–2003 _Cato Supreme Court Review_ vii. (2003).



33 See Bernard H. Siegan, _Economic Liberties and the Constitution_ (1980).



34 See Gary Lawson, Making a Federal Case Out of It: _Sabri v. United States_ and the Constitution of Leviathan. 2003–2004 _Cato Supreme Court Review_ 119 (2004).



35 Letter from Franklin D. Roosevelt to Rep. Samuel B. Hill (July 6, 1935), in 4 _The Public Papers and Addresses of Franklin D. Roosevelt_ 91–92 (Samuel I. Rosenman ed., 1938).



36 Rexford G. Tugwell, A Center Report: Rewriting the Constitution, _Center Magazine,_ March 1968, at 20. This is a fairly clear admission that the New Deal was skating not simply on thin ice but on no ice at all. For comments from the other side, see, e.g., Gary Lawson, The Rise and Rise of the Administrative State, 107 _Harvard Law Review_ 1231 (1994): “The post‐​New Deal administrative state is unconstitutional, and its validation by the legal system amounts to nothing less than a bloodless constitutional revolution;” Richard A. Epstein, Commerce Clause, _supra_ note 30, at 1388: “I think that the expansive construction of the [commerce] clause accepted by the New Deal Supreme Court is wrong, and clearly so.”



37 That was pretty much the view of Justice Holmes in his famous dissent in _Lochner v. New York,_ 198, U.S. 45 (1905). Declaring that the case was “decided upon an economic theory which a large part of the country does not entertain,” and adding that his “agreement or disagreement [with the theory] has nothing to do with the right of a majority to embody their opinions in the law,” Holmes proceeded to read out of the Constitution all economic substance: “a constitution is not intended to embody a particular economic theory, whether of paternalism and the organic relation of the citizen to the state or of laissez faire.” Id. at 75. But we find a similar view in many modern conservatives as well. Thus, Robert H. Bork speaks of the “two opposing principles” of what he calls the “Madisonian dilemma.” Our first principle, Bork says, “is self‐​government, which means that in wide areas of life majorities are entitled to rule, if they wish, simply because they are majorities. The second is that there are nonetheless some things majorities must not do to minorities, some areas of life in which the individual must be free of majority rule.” Robert H. Bork, _The Tempting of America_ 139 (Touchstone, 1990). That gets Madison exactly backward. Madison’s vision was that in wide areas of life individuals are entitled to be free simply because they are born free. Nonetheless, in _some_ areas majorities are entitled to rule because we have authorized them to rule, giving them powers “few and defined.”



38 John Locke, _The Second Treatise of Government,_ in _Two Treatises of Government_ (1960) (1690).



39 I have discussed this issue more fully in Roger Pilon, Foreword: Can Law this Uncertain Be Called Law? 2003–2004 _Cato Supreme Court Review_ vii (2004).



40 For my critique of an opinion by Justice Anthony Kennedy distinguishing four “levels” of review, _Turner Broadcasting System v. FCC,_ 512 U.S. 622 (1994), see Roger Pilon, A Modest Proposal on “Must‐​Carry,” the 1992 Cable Act, and Regulation Generally: Go Back to Basics, 17 _Hastings Comm/​Ent. Law Journal_ 41 (1994).



41 That is arguably what happened in _McConnell v. FEC,_ 124 S. Ct. 619 (2003), upholding the McCain‐​Feingold Campaign Finance Act, 116 Stat. 81 (2002), which President George W. Bush signed while saying it was unconstitutional. See Eric S. Jaffee, _McConnell v. FEC:_ Rationing Speech to Prevent “Undue Influence,” 2003–2004 _Cato Supreme Court Review_ 245 (2004).



42 See Robert J. Reinstein, _Completing the Constitution: The Declaration of Independence, Bill of Rights, and Fourteenth Amendment,_ 47 _Temple Law Review_ 361 (1993). In 1833 the Court had ruled that the Bill of Rights applied only against the government created by the document (the U.S. Constitution) to which it was appended. _Barron v. Mayor and City Council of Baltimore,_ 32 U.S. 243 (1833).



43 Warren, _Santa Claus, supra_ note 13, front page, citing only to 22d Cong., 1st Sess.



44 Adam Smith, _An Inquiry Into the Nature and Causes of the Wealth of Nations_ (1776).



45 Roger Pilon, Congress, the Courts, and the Constitution, ch. 3, in _Cato Handbook on Policy_ (2005).
"
"Conservative politicians have long declared there is no alternative to capitalism. Many of capitalism’s cruelties, from housing crises and crumbling public amenities to increasingly precarious forms of employment, are most visible in towns and cities. But it’s also in these places that new movements are emerging and rebuilding politics from the bottom up. In cities such as Barcelona, Amsterdam, Berlin and Naples, local activists are defending human rights and public services against a rising tide of anti-immigrant xenophobia and fiscal austerity. We call these urban movements “municipalism”. By achieving small victories around the world, municipalist movements are proving that there is another way of doing politics – one that begins in the places closest to us. It’s thanks to this movement that someone such as me, a woman from a working-class family who began my political career as a housing activist, can today govern a city such as Barcelona. A tide of municipal movements connects cities across the world, creating networks of alliances and shared objectives. Together, we have put pressure on our national governments and demanded greater powers to fight gentrification, increase the stock of affordable housing, and safeguard our collective right to the city. In Barcelona we have curbed the Airbnb rentals that drive up demand for a limited housing supply, and have repossessed unused housing owned by banks. The city of Berlin has pledged to freeze rents for five years in an effort to halt gentrification. New York City has promised to divest $5bn from fossil fuels and to sue oil companies for their contribution to global warming. These small victories show that alternatives to our dominant economic system are within reach – and that cities are a key part of this future. This doesn’t mean urban politics is without challenges. There’s a risk that we’ll be reduced to resolving quotidian problems and fall short of our ambition to confront systemic crises. Though cities will be central to the transition towards a fossil fuel-free future, the climate emergency doesn’t respect borders, and demands networked, international solutions. For this reason, it’s crucial that the climate emergency declarations made in cities including Barcelona, Amsterdam and New York transcend mere symbolic gestures – and that we hold our national leaders to account. What does municipalism have to do with the future of Europe? Everything. Europe has been immersed in a crisis of legitimacy for the past decade. The EU has functioned as a single market, but not as a joint democratic project. It has suffered from a lack of citizen participation, with a distanced parliament and a cruel migration policy that has violated human rights and betrayed the principles of solidarity agreed by Europe’s leaders in the wake of the second world war. Part of our work in Barcelona has been to develop an approach to migration that protects the rights of residents in our city, and their access to public services, regardless of their immigration status. We firmly believe that border crossings should be places of meeting and welcome, not of death. Europe can only be strong if it is capable of reinventing itself from the bottom up. To secure its future, Europe must recommit itself to its founding values: the guarantee of human rights and democracy. Today, the politics of hate and xenophobia are the main threats to the values that the EU once espoused. We urgently need to avert their spread and build societies that are fair, inclusive and diverse. The municipal movements in cities across Europe are already building networks of solidarity that will be essential in fighting the political forces threatening the union, and in resisting the siren call of the far right. It is my deep conviction that there is no greater power than that which is built by people working together at the grassroots, and that our neighbourhoods, towns and cities are the only places where this can happen. • Ada Colau is the mayor of Barcelona"
"
Share this...FacebookTwitterThe days when Europe considered the rest of the world its colony and servant are over. But some EU bureaucrats and bossy greens obviously haven’t grasp that yet. Hat tip: Manfred Messmer here.
A group of EU climate commissars lead by Connie Hedegaard once got the idea they could boss the rest of the world, and impose a CO2 reduction scheme on the world’s airlines. Read here, background.
China and India, once ruthlessly exploited by European colonial rule, are sending tough messages back to Brussels: If you think you can still boss us around, then you’ve got another thing coming.
Al Jazeera reports on news which the European mainstream media are too embarrassed to make public in Europe. The EU’s unilateral move to charge for carbon emitted by flights in and out of Europe is escalating an international row and threatens to turn into an all out global trade war – one that Europe would certainly lose big time.
India is now following China’s lead and is set to ask its airlines not to take part in the European Union emissions trading scheme. In February China barred its airlines from participating in the European emissions-reduction scheme. Other powers like the USA and Russia are also joining in with China and India.
Al Jazeera writes that an Indian official “told Reuters news agency that India will soon ask local airlines not to share emissions data with the bloc or buy any carbon credits.” And the official added:
‘We have lots of measures to take if the EU does not go back on its demands. We have the power of the economy, we are not bleeding as they are,’ the government official said, adding that Europe’s position would harm its own economy and airlines. ‘The questions is, are you (EU) provoking the world into a trade war?’ the official said.”
China has already suspended the purchase of 10 more Airbus jets, and India has left that option open. China and India are important growth markets for Airbus. Cancelling orders for dozens of planes would deal a crushing blow for Europe’s aviation industry. Al Jazeera writes:
European planemaker Airbus has a 73 per cent share of the commercial plane market in India. It has orders for more than 250 planes with IndiGo, Go Air and Kingfisher Airlines, making fast-growing India a crucial growth market. Foreign governments say the EU is exceeding its legal jurisdiction by charging for an entire flight, as opposed to just the part covering European airspace.”
The European Commission, however, claims that all this is necessary to rescue the climate from a certain Armageddon – never mind the data.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




To send a signal to show it means business, India disrupted the flight schedules of many European airlines to let them know “how disruptive a dispute with the country could be.”
Al Jazeera quotes the Indian official:
If things continue like this, then European airlines will be forced to avoid flying over India and go over the Indian Ocean and the Bay of Bengal. That’s not viable for them. They won’t have fuel to do that.”
The European Voice reminds readers of the gravity of the measures now being taken by China:
What we see today is that the Chinese authorities are blocking airlines from placing firm orders with Airbus. Airlines are likely to now consider the competition. And that could destroy years of efforts to bring Airbus to a market-leading position in China.”
And reminds the EU government that the European Trading Scheme for taxing CO2 is misguided policy:
It is time for European politicians to see the facts. Over the past decade, aviation achieved 45% growth while consuming only 3% more fuel. That is the best evidence for our industry’s prolonged and continuing efforts to reduce our environmental impact in all areas, and to allow for sustainable growth.”
I can’t imagine what Europe is thinking here. Are they dreaming that they can treat the world like its colony to boss around? Do the climate commissars really believe they can get away with this?
Clearly Europe is trying to fool the world with the climate climate issue in order to get back to the good old days of colonialism – when it bossed everyone around.
These climate commissars and green Napoleons are about to learn, however, that their days of running colonies are over.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMore bad news for the catastrophe-insisting climate alarmists who claim 95% of climate change is due to 0.04% trace gas CO2. Yet another prominent scientist, this one a big-league heavy hitter, has expressed serious doubt on CO2’s sole dominance during a recent interview. The once much ballyhooed consensus keeps falling apart.

Professor Wolfgang Baumjohann, Director of the Institute for Space Research of the Austrian Academy of Sciences. Graz, Austria. (Photo credit: Sissi Furgler)
Professor Wolfgang Baumjohann, Director of the Institute for Space Research of the Austrian Academy of Sciences, one of the world’s heavyweights in physics, gave an interview with the online Austrian flagship daily Der Standard here. Hat-tip: http://kaltesonne.de/.
The interview was in part to get his opinion on Fritz Vahrenholt’s and Sebastian Lüning’s bestselling skeptic book Die kalte Sonne, which has been creating a row within the scientific community throughout Germany and Europe since it was released earlier this month.
When asked about the role of solar activity on the Earth’s climate and whether Vahrenholt’s claims were nonsense, Baumjohann said:
There’s not a serious scientist claiming that CO2 emissions can be neglected. However, one cannot say that it’s the sole reason for global warming when it is obvious that increased solar activity correlates. One has to take that into account. When the solar dynamo runs more strongly, then a warming is logical.”
and
One seriously has to separate all the various cycles and make comparisons to see just how strongly solar activity impacts the climate.”
Actually, Vahrenholt and Lüning did precisely just that in their book. And the data that is available now show a clear, indisputable correlation. Here Baumjohann would likely have used much bolder words had he read that section of the book. Or maybe he’s just being diplomatic.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




On the subject of cosmic rays and weakening magnetic fields (h/t: DirkH) Baumjohann is completely open to Svensmark’s theory and does not disguise that the theory is entirely plausible and just comes out and says that they directly impact the Earth’s climate (emphasis added):
Indeed, more cosmic rays and more solar particles would hit the top of the atmosphere – and this would have direct implications for our weather. We can’t tell yet whether these will be positive or negative consequences. Long term, climatic changes depend on cosmic rays and their influences on cloudiness.”
This is as major an endorsement as you’ll ever get!
We’ll remind readers that Vahrenholt in no way neglects CO2 as a factor. He is being chastised for cutting it down to size as a climate driver, saying that it is likely responsible for up to half of last century’s warming. But he dismisses that we are headed for an imminent catastrophe.
Note how Baumjohann contradicts Max Plank Institute Director Jochem Marotzke, who never even bothered to read Vahrenholt’s book, and who remains stuck on pre-AR4 science, i.e. focusing only on total solar irradiance and thus insisting the sun has not played any important role over the last century.
Baumjohann adds:
Us humans certainly know what life-giving energy the sun holds. Everyone feels it in the springtime. That’s a really personal experience.”
The latter part of the interview looks at the Earth’s magnetic field and the financing of scientific institutes.
Baumjohann’s Career Summary here
 
Share this...FacebookTwitter "
"

And people thought I was being impertinent when I wondered in these pages whether or not global warming actually _reduced_ the impacts of Superstorm Sandy.   
  
  
Now comes this abstract from a paper by Elizabeth Barnes and colleagues just published in the _Proceedings of the National Academy of Sciences_ :   




Superstorm Sandy ravaged the eastern seaboard of the United States, costing a great number of lives and billions of dollars in damage. Whether events like Sandy will become more frequent as anthropogenic greenhouse gases continue to increase remains an open and complex question. Here we consider whether the persistent large‐​scale atmospheric patterns that steered Sandy onto the coast will become more frequent in the coming decades. Using the Coupled Model Intercomparison Project, phase 5 multimodel ensemble, we demonstrate that climate models consistently project a decrease in the frequency and persistence of the westward flow that led to Sandy’s unprecedented track, implying that future atmospheric conditions are less likely than at present to propel storms westward into the coast.



Just because global warming enthusiasts are quick to link all weather disasters to climate changes from human greenhouse gas emissions, doesn’t mean they really are. In fact, just the opposite may be the case—global warming may be acting to _avert_ some weather disasters. I know, I know, I am being impertinent again.
"
"**A North East airport has warned it could take up to four years before its passenger numbers return to pre-coronavirus levels.**
About 5.5m people flew through Newcastle International Airport in 2019, but disruption caused by Covid-19 has seen nearly all flights cancelled.
Passengers numbers were currently ""2 to 3%"" of normal levels, bosses said.
Charter flights have been scrapped with only a small number of essential business routes operating.
""In the original lockdown we had zero passengers through the airport,"" Graeme Mason, planning and corporate affairs director, said.
""It crept up to about 20% later in the summer but during the second lockdown we've been running 2 to 3% of what we'd have expected in a November period.
""It's going to be a long road to recovery, several years - possibly three or four years - to get back to passenger numbers we had in 2019.""
The airport hopes a scheme reducing the isolation period for travellers will aid its recovery.
From 15 December people arriving in England from abroad will be able to shorten their quarantine by more than half if they pay for a Covid test after five days.
The tests from private firms will cost between Â£65 and Â£120.
Mr Mason said he believed it would ""help encourage people to travel"".
_Follow BBC North East & Cumbria on _Twitter _,_Facebook _and_Instagram _. Send your story ideas to_northeastandcumbria@bbc.co.uk _._"
"

Over at the Huffington Post, enviro activist Laurie David complains today that the media is willing to give some ink to my colleague, Prof. Pat Michaels, on the issue of global warming. One of her main complaints is that Pat is nobody (scientifically speaking) and the fact that he has ""(finally) gotten a paper published"" does not qualify him as an expert.   
  
And Laurie has published peer reviewed papers ... where? Anyway, Prof. Laurie has nothing substantive to say about the arguments in the Michaels paper that sent her around the bend.   
  
It's truly a wondrous thing when Hollywood celebs with no scientific training feel free to attack the credentials of academics with Ph.Ds in their (momentary) field of interest. She did a similar smear-job on MIT Prof. Richard Lindzen. More such attacks are likely to come.   
  
Regardless, Laurie's ad hominem attack is bogus. Pat is in fact one of the most widely published climate change experts in the peer-reviewed literature. If she had ever bothered to actually read the U.N.'s ""state of the science"" IPCC reports she claims to have digested, she would have seen multiple references therein to his work.   
  
But for the record, Pat's peer-reviewed papers and presentations since 2000 follow:   




Michaels, P. J., P. C. Knappenberger, and R E. Davis, 2006. Sea-surface temperatures and tropical cyclones in the Atlantic basin, _Geophysical Research Letters_ , **33** , L09708, doi:10.1029/2006GL025757.   
  
Davis, R.E., Michaels, P.J., Knappenberger, P.C., 2006. Global warming and Atlantic hurricanes. 2006 Annual Meeting of the Association of American Geographers, Chicago, IL, March 7-11.   
  
Michaels, P.J., Knappenberger, P.C., and C. Landsea, 2005. Comments on “Impacts of CO2-Induced Warming on Simulated Hurricane Intensity and Precipitation: Sensitivity to the Choice of Climate Model and Convective Scheme”. _Journal of Climate_ , **18** , 5179-5182.   
  
Michaels, P.J., Knappenberger, P.C., and R.E. Davis, 2005. Sea surface temperature and tropical cyclone intensity: Breaking the paradigm, 15th Conference on Applied Climatology, American Meteorological Society, Paper No. 2.4, Savannah, GA, June 19-23.   
  
Davis , R.E., Knappenberger, P.C., Michaels, P.J., and W.M. Novicoff, 2005. Changing Heat Wave Sensitivity in U.S. Cities, 15th Conference on Applied Climatology, American Meteorological Society, Paper No. 4.6, Savannah, GA, June 19-23.   
  
Davis, R.E., Knappenberger, P.C., Michaels, P.J., and W.M. Novicoff, 2005. Evidence of Adaptation to Increasing Heat Wave Intensity and Duration in U.S. Cities. 17th International Congress on Biometeorology, Garmisch-Partenkirchen, Bavaria, Germany, September 5-9.   
  
Davis, R.E., Knappenberger, P.C., Michaels, P.J., and W.M. Novicoff, 2004. Changing Heatwave Mortality in U. S. cities. _Proc. 14th Appl. Clim. Conf_., Seattle, WA, paper no. J8.4.   
  
Davis, R.E., Knappenberger, P.C., Michaels, P.J., and W.M. Novicoff, 2004. Seasonality of climate-human mortality relationships in U.S. cities and impacts of climate change. _Climate Research_ , **26** , 61-76.   
  
Davis, R.E., Knappenberger, P.C., Michaels, P.J., and W.M. Novicoff, 2004. Heat Wave Mortality in Large U. S. cities. _Proc. 16th Conf. Biometeorol. Aerobiol. and the 17th ISB Cong. Biometeor_., Vancouver, British Columbia, WA, paper no. 6A.3.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2004. Presentation of “Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2003. Decadal changes in summer mortality in the U. S. cities, _International Journal of Biometeorology_ , **47** , 166-175,” to the Association of American Geographers in accepting the 2004 “Paper of the Year” award from the Climate Specialty Group.   
  
Douglass, D.H., Pearson, B.D., Singer, S.F., Knappenberger, P.C., and P.J. Michaels, 2004. Disparity of tropospheric and surface temperature trends: New evidence. _Geophysical Research Letters_ , **31** , doi:10.1029/2004GL020212.   
  
McKitrick, R., and P. J. Michaels. 2004. A Test of Corrections for Extraneous Signals in Gridded Surface Temperature Data. _Climate Research_ , **26** , 159-193.   
  
Michaels, P.J., McKittrick, R., and P.S. Knappenberger, 2004. Economic Signals in Global Temperature Histories. 14th Appl. Clim. Conf., Seattle, WA, paper no. J1.1.   
  
Michaels, P.J., Knappenberger, P.C., Frauenfeld, O.W., and R.E. Davis, 2004. Trends in Precipitation on the Wettest Days of the Year across the Contiguous United States. _International Journal of Climatology_ , **24** , 1873-1882.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2003. Decadal changes in summer mortality in the U. S. cities, _International Journal of Biometeorology_ , **47** , 166-175.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2003. Winter Mortality, Climate, and Climate Change in U.S. Cities. 37th Canadian Meteorological and Oceanographic Society Congress, Ottawa, Ontario, Canada.   
  
Davis, R.E., Knappenberger, P.C., Michaels, P.J., and W.M. Novicoff, 2003. Changing heat-related mortality in the United States. _Environmental Health Perspectives_ , **111** , 1712-1718.   
  
Douglass, D.H., Clader, B.D., Christy, J.R., Michaels, P.J., and D.A. Belsley. 2003. Test for harmful collinearity among predictor variables used in modeling global temperature. _Climate Research_ , **24** , 15-18.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2002. On seasonal differences in weather-related mortality trends in the United States. _Proc. 13th Appl. Clim. Conf_., Portland, OR, 326–330.   
  
Michaels, P.J., Knappenberger, P.C., Davis, R.E., and O.W. Frauenfeld, Rational analysis of trends in extreme temperature and precipitation, _Proc. 13th Appl. Clim. Conf_., Portland, OR, 153–158.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2002. Climate change adaptations: trends in human mortality responses to summer heat in the United States, _Proc. 15th Conf. Biometeorol. Aerobiol. and the 16th ISB Cong. Biometeor_., Kansas City, MO, Paper 9B.1.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2002. Spatial pattern of human mortality seasonality in U. S. cities since 1964, _Proc. 15th Conf. Biometeorol. Aerobiol. and the 16th ISB Cong. Biometeor_., Kansas City, MO, Paper 2B.2.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2002. Decadal changes in heat-related human mortality in the Eastern United States. _Climate Research_ , **22** , 175-184.   
  
Michaels, P.J., Knappenberger, P.C., Frauenfeld, O.W., and R.E. Davis. 2002. Revised 21st century temperature projections. _Climate Research_ , **23** , 1-9.   
  
Knappenberger, P.C., Michaels, P.J., and R.E. Davis, 2001. The nature of observed climate changes across the United States during the 20th century. _Climate Research_ , **17** , 45–53.   
  
Michaels, P.J., Knappenberger, P.C., and R.E. Davis, 2001. Integrated Projections of Future Warming based Upon Observed Climate During the Attenuating Greenhouse Enhancement. _Proceedings of the1st International Conference on Global Warming and The Next Ice Age_ , co-sponsored by the Atmospheric Science Program at Dalhousie University, the Canadian Meteorological and Oceanographic Society, the American Meteorological Society and the European Space Agency, 19-24 August, 2001, at Dalhousie University in Halifax, Nova Scotia, Canada, pp.162–167.   
  
Michaels, P.J., Knappenberger, P.C., Balling, R.C., and R.E. Davis, 2000. Observed Warming in Cold Anticyclones. _Climate Research_ , **14** , 1-6.   
  
Balling R.C., MacCracken, M.C., Michaels, P.J., and A. Robock, 2000. Assessment of uncertainties of predicted global climate change modeling: Panel 1. _Technology_ , **7** , 231–256.   
  
Michaels, P.J., and P.C. Knappenberger, 2000. Natural Signals in the MSU Lower Tropospheric Temperature Record. _Geophysical Research Letters_ , **27** , 2905–2908.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2000. Decadal Changes in Summer Mortality in the United States. _Proceedings of the 12th Conference on Applied Climatology_ , Asheville, NC, 184–187.   
  
Michaels, P.J., Knappenberger, P.C., Gawtry, S.D., and R.E. Davis, 2000. Anticyclonic Warming. _Proceedings of the 12th Conference on Applied Climatology_ , Asheville, NC, 119–122.   
  
Davis, R.E., Knappenberger, P.C., Novicoff, W.M., and P.J. Michaels, 2000. Decadal Shifts in Summer Weather/Mortality Relationships in the United States by Region, Demography, and Cause of Death. _Proceedings of the 14th Conference on Biometeorology and Aerobiology_ , Davis, CA, 250–251.


"
"**The coronavirus pandemic could wipe out 25 years of increasing gender equality,**new global data from UN Women **suggests.**
Women are doing significantly more domestic chores and family care, because of the impact of the pandemic.
""Everything we worked for, that has taken 25 years, could be lost in a year,"" says UN Women Deputy Executive Director Anita Bhatia.
Employment and education opportunities could be lost, and women may suffer from poorer mental and physical health.
The care burden poses a ""real risk of reverting to 1950s gender stereotypes"", Ms Bhatia says.
Even before the pandemic, it was estimated women were doing about three quarters of the 16 billion hours of unpaid work that are done each day around the world.
In other words, before coronavirus, for every one hour of unpaid work done by men, three hours was done by women. Now that figure is higher.
""If it was more than three times as much as men before the pandemic, I assure you that number has at least doubled,"" says Ms Bhatia.
Though the 38 surveys carried out by UN Women primarily focused on lower and middle-income countries, data from more industrialised countries show a similar picture.
""More alarming is the fact that many women are actually not going back to work,"" says Ms Bhatia.
""In the month of September alone, in the US, something like 865,000 women dropped out of the labour force compared to 200,000 men, and most of that can be explained by the fact that there was a care burden and there's nobody else around.""
UN Women warns that the ripple effect from having fewer working women will be dire on not only women's wellbeing but their economic progress and independence.
BBC 100 Women has spoken to three women, looking at how the pandemic has impacted the amount of work they do. They were asked to keep a time diary, noting down how they used the hours in a typical day, covering a 24-hour-period.
Even before the pandemic, women in Japan spent on average almost five times longer than men on unpaid care work and chores.
Teni Wada is a brand consultant based in Tokyo and was working a part-time nursery teacher before lockdown began.
""It's 5am and I'm desperately trying to complete this article on sake. The deadline isn't for a few days, but I like to stay ahead of the game. 'Mum life' is unpredictable, and I don't want this unpredictability to cost me a pay cheque,"" she writes in her diary.
Teni says time is a luxury she doesn't have in between home-schooling, planning meals, working and doing the laundry.
During lockdown, Teni and her husband have both been working from home, but their days look very different.
""He works from 9.30am to around 5-6.30pm, and I do feel like he has the luxury of going into a room and can concentrate on his work, but I don't have that luxury, she says, ""I do feel it's a bit unfair.""
At home, Teni says she does around 80% of the unpaid work which includes home-schooling her three-year-old daughter.
""The first two-three months were awful, mentally I reached my limit almost every day, my daughter would be crying and then I'd be crying,"" she recalls.
""We are seeing worrying impacts, including high levels of stress and mental health challenges, particularly for women, partly as a result of the increased workloads,"" says Papa Seck, Chief Statistician at UN Women.
Delina Velasquez is a farmer from the Cercado province in the southern city of Tarija in Bolivia.
Her days usually start around 5am, and she splits most of her time between working in the greenhouse and housework. But every two months she travels to the city's farmers' market to sell the vegetables she's been growing.
""The days are very exhausting in the field, at least for me, because I have other tasks in the house, but for now my daughter helps me, she is my right hand. She helps me in the house, in the field, in the greenhouse,"" she says.
Traditional gender norms reinforce the idea that men are the breadwinners while women are the homemakers, and girls are often expected to take on housework.
""When it comes to children's assistance [in unpaid work], parents are more likely to cite help from daughters than sons,"" says Mr Seck.
But Delina is happy that she gets to spend more time with her family during the pandemic.
""Before, I had to do everything alone in the nursery, buying seeds, storing, propagating, watering, cooking, cleaning,"" she says.
""But now that the school year has closed, my daughter helps me with cleaning, cooking, washing clothes; my little boy helps me in the nursery, my husband spends more time with us and helps us in everything he can. It's more relaxing for me.""
Dr Ijeoma Kola is a Nigerian-American woman living in Nairobi, Kenya.
She says part of the reason she has been able to juggle becoming a new mum and her job is because her husband is supportive and they can afford to hire someone to help them at home.
""Not all women have that, or are an economic position where they can afford help. But I still wake up every day at 6 or 7 to nurse our son,"" she says.
Ijeoma says society is not economically set up in favour of women and instils gender norms that make it impossible for the average women to be able to have it all.
""Women can have it all, but not all at the same time and not without major sacrifices,"" she explains.
""I think that they're probably very few of us and I count myself very lucky to be able to have most things, if not everything.""
Being able to hire someone to help out, made lockdown a bit easier for Ijeoma and her family.
""There was about a month where it was just us and I was miserable,"" she says.
""I felt like I just had so much work to do and couldn't get any professional work done because I was doing so much household work.""
Although her husband is a good partner when it comes to parenting and takes the lead on things like cleaning, dishes, and laundry, she says she often feels that the responsibility of managing the home falls on her.
""My mind is always thinking about things he doesn't think about like the grocery list, our son's first birthday, whether we should take family photos for the holidays, or scheduling a Zoom hangout with friends,"" she says.
The mental load - having to juggle things like healthcare appointments, meal plans and house repairs - can take a toll on women's physical and mental health as well.
Women's unpaid work often covers the cost of care that sustains families, supports economies and fills in for the lack of social services, but it's rarely officially recognised as work.
""The key point here is that this has always been undervalued and it has always been treated as something that you didn't have to worry about because there wasn't compensation involved,"" says Ms Bhatia.
""The pandemic has shone a spotlight on the fact that unpaid work has really been the social safety net for the world and has made it possible for others to go out and earn a productive income, while actually hampering the growth opportunities and the employment opportunities of those women who are carrying the care burden.""
Women who do the bulk of unpaid work will either have less time to engage in paid labour, or work longer hours, and often face financial insecurity either way.
""You cannot underscore enough how big a problem this is and how big an impact it's going to have if governments and businesses don't do something,"" says Ms Bhatia.
The UN is calling on governments and businesses to acknowledge that unpaid work exists and implement measures such as extra family leave, or extra paid leave, and keeping childcare centres open.
""This is not just a question of rights, it's also a question of what makes economic sense,"" says Ms Bhatia.
""And it makes economic sense that women participate fully in the economy,""
_Additional reporting by Will Dahlgreen and illustrations by Sana Jasemi._
BBC 100 Women _names 100 influential and inspirational women each year and shares their stories. Find us on Facebook, Instagram and Twitter, and use #BBC100Women._"
"

I came here today as president of the free and democratic Czech Republic.a country that succeeded more than 17 years ago in getting rid of communism; a country that quite rapidly, smoothly, and without unnecessary additional costs overcame its communist heritage and transformed itself into a normally functioning European‐​style parliamentary democracy and market economy; a country that is an integral part of the free world, a member of NATO and of the European Union, and a good friend of the United States of America.



Everyone has a list — mostly an implicit one — of issues, problems, and challenges that he feels and considers — on the basis of his experiences, prejudices, sensitivities, preferences, and priorities — to be crucial, topical, menacing, and relevant. I will reveal at least some of the items on my own list. All are inevitably related to something that was absent during most of my life in the communist era. 



What I have in mind is, of course, freedom.something that Americans value very highly, in spite of the fact that they have not experienced its nonexistence or absence personally. The experience of living under communism provides me with a special sensitivity, if not an oversensitivity, to lack of freedom.



Where do I see the main dangers to freedom at the beginning of the 21st century? I will not speak about the current headlines, and I will decline to speak about our external enemies, such as the Taliban, al‐​Qaeda, and Islamic fundamentalism, because I have nothing special to say or add to the issue of terrorism and I don’t want to just repeat well‐​known arguments and facts. Suffice it to say that our ability to go ahead and eventually face external dangers depends to a large extent on our beliefs, visions, convictions, internal strength, coherence, ability to function, and so on.



I consider it more important, therefore, to speak about our internal challenges, three of which are main challenges of the current era.



 **Neostatism**



My first topic is connected to communism. The Czech Republic — as did all the other former communist countries — had to undergo a difficult transition. We came to understand very early on that the transition had to be homemade as it was impossible to import a system devised abroad. We also came to understand that such a fundamental change was not an exercise in applied economics but a man‐​made evolutionary process and that we had to find our own path, our “Czech way,” toward an efficiently functioning society and economy.



Over the last 15 years, I spoke many times in the United States about the process of transition; about its nonzero costs; about its benefits, tenets, and pitfalls. Now, when it is over, we face a different problem.



We succeeded in getting rid of communism, but along with many others, we erroneously assumed that attempts to suppress freedom, and to centrally organize, mastermind, regulate, and control society and the economy, were matters of the past, an almost‐​forgotten relic. Unfortunately, those centralizing urges are still with us. I see more examples of such urges in Europe and in most international organizations than in the United States, but they can be found here as well.



The reason for my concern is the emergence of new, very popular and fashionable, “isms” that again put various issues, visions, plans, and projects ahead of individual freedom and liberty. There is social‐​democratism, which is nothing more than a milder and softer version of communism, and there is human‐​rightism, which is based on the idea of mostly positive rights applicable all over the world. There are also internationalism, multiculturalism, europeism, feminism, environmentalism, and other similar ideologies.



Communism is over, but attempts to rule from above are still here, or perhaps they have merely returned.



 **Europeism**



The second main challenge that I see is connected to our experience with the European Union, but goes beyond the EU, because it is part of a broader tendency toward denationalization of nation‐​states and toward worldwide supranationalism and global governance.



The special sensitivity that I and many of my countrymen have makes me view many current trends in Europe rather critically. My opponents do not seem to hear my arguments. They keep rejecting the views that they don’t like a priori. To understand my criticism requires knowledge of developments in the EU — its gradual metamorphosis from a community of cooperating nations to the union of nonsovereign nations — and of prevailing supranationalistic tendencies. Those developments are not well‐​known in the United States.



I have always been in favor of a friendly, peaceful, and mutually enriching cooperation and collaboration among European countries. However, I have many times pointed out that the move toward an ever‐​closer Europe, the so‐​called deepening of the EU, as well as rapid political integration and Europe’s supranational tendencies that are not buttressed by an authentic European identity or European demos, are damaging to democracy and freedom.



Freedom and democracy — those two precious values — cannot be secured without parliamentary democracy within a clearly defined state territory. Yet that is exactly what the current European political elites and their fellow travelers are attempting to eliminate.



 **Environmentalism**



I see the third main threat to individual freedom in environmentalism. To be specific, I do understand the concerns about eventual environmental degradation, but I also see a problem in environmentalism as an ideology.



Environmentalism only pretends to deal with environmental protection. Behind their people‐ and nature‐​friendly terminology, the adherents of environmentalism make ambitious attempts to radically reorganize and change the world, human society, our behavior, and our values.



There is no doubt that it is our duty to rationally protect nature for future generations. The followers of the environmentalist ideology, however, keep presenting us with various catastrophic scenarios with the intention of persuading us to implement their ideas. That is not only unfair but also extremely dangerous. Even more dangerous, in my view, is the quasi‐​scientific guise that their oft‐​refuted forecasts have taken on.



What are the beliefs and assumptions that form the basis of the environmentalist ideology?



All of those beliefs and assumptions are associated with social sciences, not with natural sciences. That is why environmentalism — unlike scientific ecology — does not belong to the natural sciences and can be classified as an ideology. That fact is, however, not understood by the average person and by numerous politicians. 



The hypothesis of global warming and the role of humanity in that process is the last and, to this day, the most powerful embodiment of the environmental ideology. It has brought many important “advantages” to the environmentalists:



It is not my intention here to present arguments for the refutation of that hypothesis. What I find much more important is to protest against the efforts of the environmentalists to manipulate people. Their recommendations would take us back into the era of statism and restricted freedom. It is therefore our task to draw a clear line and differentiate between ideological environmentalism and scientific ecology.
"
"
By Blake Snow – 				 				FOXNews.com
Image: NASA / Goddard Institute for Space Studies – Maps from NASA’s GISS reveal temperatures where  no data exist, thanks  to mathematical extrapolation of data.

NASA was able to put a man on the moon, but the space agency can’t  tell you what the temperature was when it did. By its own admission,  NASA’s temperature records are in even worse shape than the besmirched  Climate-gate data.
E-mail messages obtained by a Freedom of Information Act request  reveal that NASA concluded that its own climate findings were inferior  to those maintained by both the University of East Anglia’s Climatic  Research Unit (CRU) — the scandalized source of the leaked Climate-gate  e-mails — and the National Oceanic and Atmospheric Administration’s  National Climatic Data Center.
The e-mails from 2007 reveal that when a USA Today reporter  asked if NASA’s data “was more accurate” than other climate-change data  sets, NASA’s Dr. Reto A. Ruedy replied with an unequivocal no. He  said “the National Climatic Data Center’s procedure of only  using the best stations is more accurate,” admitting that some of his  own procedures led to less accurate readings.
“My recommendation to you is to continue using NCDC’s data for the  U.S. means and [East Anglia] data for the global means,” Ruedy told the  reporter.
“NASA’s temperature data is worse than the Climate-gate temperature  data. According to NASA,” wrote Christopher Horner, a senior fellow at  the Competitive Enterprise Institute who uncovered  the e-mails. Horner is skeptical of NCDC’s data as well,  stating plainly: “Three out of the four temperature data sets stink.”
…
Global warming critics call this a crucial blow to advocates’ arguments  that minor flaws in the “Climate-gate” data are unimportant, since all  the major data sets arrive at the same conclusion — that the Earth is  getting warmer. But there’s a good reason for that, the skeptics say:  They all use the same data.
…
Neither NASA nor NOAA responded to requests for comment. But Dr. Jeff  Masters, director of meteorology at Weather Underground,  still believes the validity of data from NASA, NOAA and East Anglia  would be in jeopardy only if the comparative analysis didn’t match. “I  see no reason to question the integrity of the raw data,” he says.  “Since the three organizations are all using mostly the same raw data,  collected by the official weather agency of each individual country, the  only issue here is whether the corrections done to the raw data were  done correctly by CRU.”
Corrections are needed, Masters says, “since there are only a few  thousand surface temperature recording sites with records going back  100+ years.” As such, climate agencies estimate temperatures in various  ways for areas where there aren’t any thermometers, to account for the  overall incomplete global picture.
“It would be nice if we had more global stations to enable the groups  to do independent estimates using completely different raw data, but we  don’t have that luxury,” Masters adds. “All three groups came up with  very similar global temperature trends using mostly the same raw data  but independent corrections. This should give us confidence that the  three groups are probably doing reasonable corrections, given that the  three final data sets match pretty well.”
But NASA is somewhat less confident, having quietly decided to tweak  its corrections to the climate data earlier this month.
In an  updated analysis of the surface temperature data released on  March 19, NASA adjusted the raw temperature station data to account for  inaccurate readings caused by heat-absorbing paved surfaces and  buildings in a slightly different way. NASA determines which stations  are urban with nighttime satellite photos, looking for stations near  light sources as seen from space.
Of course, this doesn’t solve problems with NASA’s data, as the  newest paper admits: “Much higher resolution would be needed to check  for local problems with the placement of thermometers relative to  possible building obstructions,” a  problem repeatedly underscored by meteorologist Anthony Watts  on his SurfaceStations.org Web site. Last month, Watts told FoxNews.com  that “90 percent of them don’t meet [the government’s] old, simple rule  called the ‘100-foot rule’ for keeping thermometers 100 feet or more  from biasing influence. Ninety percent of them failed that, and we’ve  got documentation.”
Read the entire story at Fox News.com


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8cf3ea0c',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"I run 50km per week on my treadmill and eat a calorie-restricted diet; this is something our ancestors didn’t have to do. But then they didn’t sit at a desk all day and certainly did not have access to such energy rich food. Unfortunately our animals have joined us on the couch. Take a walk down the pet food aisle in the supermarket and you may be surprised to see rows of diet cat and dog food. In the US more than 50% of cats and dogs are obese or overweight, just 10% less than the human population.  Obese people are less likely to recognise that their pet is also obese: a body perception failure which will result in a cramped sofa. Thus, the world obesity crisis is not just affecting humans but also the animals that live with us.   Just as with humans, obesity has an extremely negative effect on animal health, and their causes appear to be similar: sedentary life style and easily available energy rich foods. In both humans and animals the consequences include diabetes, cancer, hypertension or heart-disease. In the case of pets we are killing them with “kindness”. We as humans are responsible for our own health and the health of the animals that share our lives. This includes animals in zoos. A study published this year showed that more than 40% of elephants in captivity are obese. They are so obese that it is negatively affecting their longevity and fertility. Fertility rates in the captive elephant population are so low that it is not self-sustaining; this could result in the need to collect individuals from the wild. Pot-belly problems affect all groups of zoo animals from primates such as lemurs to crocodilians. Food means life.  It is for this reason that your parents constantly checked if you were eating properly as a child – in our evolutionary history filling your children up with food meant increasing their chances of survival.  But in an environment where energy rich food is permanently available the opposite is true. Food isn’t just nutrition, the possession or control over food also represents power and status. We have all bribed our kids to do things with sweets – and food treats are the reward most used by people to train animals. Thus, food is power.  In the animal world it may also represent status – for instance in carnivores such as wolves and lions it is the dominant animal that eats first. In modern human society food can also be a status symbol, think about caviar or wagyu beef. Food can be bling. Outside of our pets, the animals we most commonly feed are garden birds.  Ironically, many people who feed birds are aware of the need to provide them with healthy food but may ignore this advice for themselves.  The impacts of this activity on bird populations has shown to be mixed.  For example, it may enhance overwinter survival but reduce clutch sizes.  Extra food for wild animals, as per humans, it would seem is a two-edged sword. So what is to be done about this problem of animal obesity?  For captive animals we can of course put them on a diet and increase their activity levels. But what type of diet?  We should definitely avoid “fad diets” and crash diets for animals. Research on fish has shown that crash dieting (and yo-yoing weight) reduces lifespan by 25%. The simple answer is calorie restriction, which of course animals just like humans do not find pleasant, but it is a part of our natural ecology. Unhappily, calorie restriction does not appear to increase lifespan in primates as it does in rats. Physical activity helps you burn up calories and stay at a healthy weight. So why are humans and captive animals so prone to inactivity? Energy is a limited resource for wild animals and one not to be wasted frivolously. In captivity, animals still behave in this manner, as do humans.  This explains the difficulty in motivating individuals to undertake physical activity.  One solution to this is to reward individuals for their physical activity: research I have recently carried out with colleagues has shown this to be highly effective with rats. I suspect that the problem in rewarding people and animals for exercising is that rewards need to be very frequent and not just an “endorphin high” after an hour on the treadmill."
"**Paul Gilley says he has never seen so few new jobs in the UK hospitality sector - across restaurants, bars and hotels.**
Recruitment is bad overall but in hospitality it is ""non-existent"", says the boss of London-based recruitment firm PJ Search & Selection.
Mr Gilley has run his business for 20 years, specialising in the hospitality sector. Back in March, he says that everything stopped overnight.
""Contracts were being cancelled, all permanent vacancies were drying up and within a week we had nothing,"" he says.
Despite England being set to come out of the current lockdown on 2 December, returning to a tier-based system and with Christmas fast approaching, Mr Gilley does not see things improving until well into 2021.
""The hospitality sector is going to try its damnedest to have a good Christmas, but with social distancing rules in place you can have only less than half the normal number of customers, so extra staff just aren't needed,"" he says.
""Places are opening their doors not to make money, but to lose less.""
Recruitment agencies are a very good barometer of a country's economy. And across the UK they have seen business dry up, as unemployment has risen due to Covid and the subsequent lockdowns and tier restrictions.
The latest official figures show that the UK unemployment rate rose to 4.8% in the three months to September, up from 4.1% in the previous quarter. And the unemployment rate among 16 to 24-year-olds, who make up much of the staff across restaurants, bars and hotels, is now 14.6%, also according to official data. Overall UK unemployment is now expected to reach 7.5% next year.
This bleak situation also applies to retail, and is replicated globally, says Ann Swain, the chief executive of APSCo, an international trade body that represents the recruitment sector.
""In March, education recruitment fell off a cliff because schools were closed down, and other markets followed with permanent recruitment dying for weeks or longer for the likes of retail and hospitality,"" she says.
But Ms Swain says recruitment has since picked up in areas such as distribution, healthcare and the pharmaceutical sector, where firms have been looking for Covid vaccines.
In fact, some entrepreneurs are launching new recruitment firms to capitalise on these trends. One such is UK industry veteran David Spencer-Percival, who has started Life Sciences People, focusing on the pharmaceutical and life sciences sector.
""The sector is seeing record investment,"" he says. ""If you are already in a downturn or recession then there's everything to play for if you time it right, as the economy can only move one way - up.""
New Economy is a new series exploring how businesses, trade, economies and working life are changing fast.
Looking at how the UK's recruiters have fared this year compared with other countries, Ms Swain says German firms have had an easier time, because Germany has had fewer coronavirus cases.
Meanwhile in Australia, the situation has varied from city to city, she says. The stricter the Covid restrictions, the more unwilling firms have been to recruit. As a result, recruiters in Melbourne were badly affected while the situation was much better for those in Sydney.
""In Singapore and South East Asia it has been a lot of 'on-off', whereby everything goes back to some normality, then closes down, therefore permanent recruitment has been restricted,"" says Ms Swain.
Kathryn Woof, managing director of 33 Talent, a Singapore recruitment firm for the public relations and marketing sectors, says she might have had to close her business if it had only focused on recruitment.
In March ""we went from working on a million dollars' worth of jobs to zero in three weeks,"" she says.
""Even though our sector was not as affected as hospitality, a lot of our clients didn't have the luxury of proceeding as if nothing was wrong. They had to freeze their headcount, reduce wages and shorten work weeks because they were assuming the worst.""
Ms Woof says her business was already doing some human resources consulting and training work, so pivoted her team to focus on those two areas instead.
As a result of gaining business in these areas, as well as moving to a four-day week, she has been able to keep all 12 of her staff employed.
While the recruitment side of the business is now slowly recovering, it is only working on about 20% of the number of jobs compared with pre-Covid levels, she says.
The bounce back for recruitment firms in other parts of the world has been better. This has been the case for MatcHR in Ukraine, which helps western firms employ remote tech staff. Its clients include Booking.com, TikTok, Stripe and Merck.
""In March the whole world stopped, so in a matter of two to three weeks we lost 70% of our turnover. We had to fire 60% of our staff, and we were still bleeding money,"" says MatcHR co-founder Adriaan Kolff.
A deal with TikTok signed in February kept the business going, he says. Then in recent months a growing number of US firms have been wanting to hire Ukrainian tech workers.
Mr Kolff say this has helped MatcHR return to making 90% of its pre-pandemic earnings and it has hired back some of the staff it had made redundant.
While MatcHR is one of the lucky ones, many recruitment firms are pinning their hopes on the roll-out and success of the Covid-19 vaccines.
Until then, Paul Gilley in London says he is more focused on an e-commerce business he set up earlier this year, to bring in a much-needed income.
APSCo's Ann Swain says: ""The global recruitment market is always a bellwether for the economy because the minute organisations or governments feel unease they stop recruiting."""
"

Trade and globalization have become more inviting targets during the current economic downturn. As output falls and unemployment rises, politicians in Washington are questioning not only imports but U.S. companies that invest in production abroad.



The incoming president, Barack Obama, pledged during his campaign that, “Unlike John McCain, I will stop giving tax breaks to corporations that ship jobs overseas and I will start giving them to companies that create good jobs right here in America.“1 That campaign refrain, echoed by a number of other successful candidates, raises three basic questions:



Why do U.S. multinational companies establish affiliates abroad and hire foreign workers? What kind of tax breaks are they receiving? And should the new Congress and new president change U.S. law to make it more difficult for U.S. multinational corporations to produce goods and services in foreign countries?



 **Reaching millions of new customers**



To demonize U.S. multinationals operating production facilities abroad is to indict virtually every major American company. At latest count more than 2,500 U.S. corporations own and operate a total of 23,853 affiliates in other countries. In 2006, according to the U.S. Department of Commerce, majority‐​owned foreign affiliates of U.S. companies posted $4.1 trillion in sales, created just under $1 trillion in value added, employed 9.5 million foreign workers, and earned $644 billion in net income for their U.S.-based parent companies.2



The primary reason why U.S. companies invest in affiliates abroad is to sell more products to foreign customers. Certain services can only be delivered on the spot, where the provider must have a physical presence in the same location as its customers. Operating affiliates abroad allows U.S. companies to maintain control over their brand name and intellectual property such as trademarks, patents, and engineering expertise. U.S. companies also establish foreign affiliates because of certain advantages in the host country‐ lower‐​cost labor, ready access to raw materials and other inputs, reduced transportation costs and proximity to their ultimate customers. Yes, the motivations can include access to “cheap labor,” but labor costs are not the principal motivation for most U.S. direct investment abroad.



Politicians focus most of their attention on comparing exports and imports, but the most common way American companies sell their goods and services in the global market today is through overseas affiliates. In 2006, U.S. multinational companies sold $3,301 billion in goods through their majority‐​owned affiliates abroad and $677 billion in services. For every $1 billion in goods that U.S. multinational companies exported from the United States in 2006, those same companies sold $6.2 billion through their overseas operations. For every $1 billion in service exports, U.S.- owned affiliates abroad sold $1.6 billion.3



Contrary to popular myth, U.S. multinational companies do not use their foreign operations as an “export platform” back to the United States. Close to 90 percent of the goods and services produced by U.S.-owned affiliates abroad are sold to customers either in the host country or exported to consumers in third countries outside the United States. Even in Mexico and China, where low‐​wage workers are supposedly too poor to buy American products, more than half of the products of new and existing U.S. affiliates are sold in their domestic markets, whereas customers in the United States account for only 17 percent of sales.4



 **More Jobs Abroad, More Jobs at Home**



Investing abroad is not about “shipping jobs overseas.” There is no evidence that expanding employment at U.S.- owned affiliates comes at the expense of overall employment by parent companies back home in the United States. In fact, the evidence and experience of U.S. multinational companies points in the opposite direction: foreign and domestic operations tend to compliment each other and expand together. A successful company operating in a favorable business climate will tend to expand employment at both its domestic and overseas operations. More activity and sales abroad often require the hiring of more managers, accountants, lawyers, engineers, and production workers at the parent company.



Consider Caterpillar Inc., the Peoria, Illinois‐​based company known for making giant earth‐​moving equipment. From 2005 through 2007, the company enjoyed booming global sales because of strong growth in overseas markets, especially those with resources extracted from the ground. According to the company’s 2007 annual report, Caterpillar earned 63 percent of its sales revenue abroad, including $1 billion in sales in China alone. As a result, Caterpillar ramped up employment at its overseas affiliates during that time from 41,238 to 50,788, an increase of almost 10,000 workers. During that same three‐​year period, the company expanded its domestic employment from 43,878 to 50,545, a healthy increase of 6,667.5



Caterpillar’s experience is not unusual for U.S. multinational companies. A 2005 study from the National Bureau of Economic Research found that, during the 1980s and 1990s, there was “a strong positive correlation between domestic and foreign growth rates of multinational firms.” After analyzing the operations of U.S. multinational companies at home and abroad, economists Mihir A. Desai, C. Fritz Foley, and James R. Hines Jr. found that a 10 percent increase in capital investment in existing foreign affiliates was associated with a 2.2 percent increase in domestic investment by the same company and a 4 percent increase in compensation for its domestic workforce. They also found a positive connection between foreign and domestic sales, assets, and numbers of employees.6 “Foreign production requires inputs of tangible or intellectual property produced in the home country,” the authors explained. “Greater foreign activity spurs higher exports from American parent companies to foreign affiliates and greater domestic R&D spending.“7



The positive connection between foreign and domestic employment of U.S. multinational companies has continued into the current decade. As Figure 1 shows, parent and affiliate employment have tracked each other since the early 1980s. More recently, employment rose briskly for parents and affiliates alike in the boom of the late 1990s, fell for both during the downturn and slow recovery of 2001 through 2003, and then rose again from 2003 through 2006.8 Although the numbers have not been reported yet for 2007 and 2008, it’s likely that the loss of net jobs in the domestic U.S. economy will be mirrored by much slower growth or outright decline in foreign affiliate employment.



 **Modest Investment in China and Mexico**



Investment in China and Mexico drew the most fire on the campaign trail. In a primary debate in Texas in February 2008, then‐​senator Obama said, “In Youngstown, Ohio, I’ve talked to workers who have seen their plants shipped overseas as a consequence of bad trade deals like NAFTA, literally seeing equipment unbolted from the floors of factories and shipped to China.“9 That makes for a good sound‐​bite in the heat of a campaign, but it does not accurately reflect the broader reality of outward foreign investment by U.S. manufacturers.





Outflows of U.S. manufacturing investment to Mexico and China have been modest by any measure. Between 2003 and 2007, U.S. manufacturing companies sent an average of $2 billion a year in direct investment to China and $1.9 billion to Mexico. That pales in comparison to the average $22 billion a year in direct manufacturing investment “shipped” to Europe during that same period, but talking about equipment being unbolted from the floors of U.S. factories and shipped to England just doesn’t have the same bite.10 The modest annual outflow in investment to China and Mexico is positively dwarfed by the annual $59 billion inflow of manufacturing investment to the United States from abroad during those same years11 and the average of $165 billion per year that U.S. manufacturers invested domestically in plant and equipment.12



The fear of manufacturing jobs being shipped to China and Mexico is not supported by the evidence. While U.S. factories were famously shedding those 3 million net jobs between 2000 and 2006, U.S.-owned manufacturing affiliates abroad increased their employment by a modest 128,000 jobs. An increase in 172,000 jobs at U.S.-owned affiliates in China was partially offset by an actual decline of almost 100,000 jobs at affiliates in Mexico.13 The large majority of factory jobs lost in the United States since 2000 were not “shipped to China” or anywhere else, but were lost to automation and other sources of increased efficiency in U.S. manufacturing.



U.S. manufacturing investment in China remains modest compared to the huge political investment that candidates and pundits have made in making it an issue. U.S. direct investment in China remains a relatively small part of China’s overall economy, and a small part of America’s total investments abroad. Of the nearly 10 million workers that U.S. affiliates employ abroad, fewer than 5 percent are Chinese; Americanowned affiliates employed just as many manufacturing workers in high‐​wage Germany in 2006 as they did in low‐​wage China.14



 **“Tax breaks” Keep U.S. Companies Competitive**



Politicians are not usually specific about exactly what “tax breaks” they want to repeal. The biggest tax exemption for U.S. companies that invest abroad is the deferral of tax payments for “active” income. U.S. corporations are generally liable for tax on their worldwide income, whether it is earned in the United States or abroad. But the relatively high U.S. corporate tax rate is not applied to income earned abroad that is reinvested abroad in productive operations. U.S. multinationals are taxed on foreign income only when they repatriate the earnings to the United States. Not surprisingly, the deferral of active income gives U.S. companies a powerful incentive to reinvest abroad what they earn abroad, but this is hardly an incentive to “ship jobs overseas.”



Such deferral may sound like an unjustified tax break to some, but every major industrial country offers at least as favorable treatment of foreign income to their multinational corporations. Indeed, numerous major countries exempt their companies from paying any tax on their foreign business operations. Foreign governments seem to more readily grasp the fact that when corporations have healthy and expanding foreign operations it is good for the parent company and its workers back home.15



If President Obama and other leaders in Washington want to encourage more investment in the United States, they should lower the U.S. corporate tax rate, not seek to extend the high U.S. rate to the overseas activities of U.S. companies. Extending high U.S. tax rates to U.S.-owned affiliates abroad would put U.S. companies at a competitive disadvantage as they try to compete to sell their goods and services abroad. Their French and German competitors in third‐​country markets would continue to pay the lower corporate tax rates applied by the host country, while U.S. companies would be burdened with paying the higher U.S. rate. The result of repealing tax breaks on foreign earnings would be less investment in foreign markets, lost sales, lower profits, and fewer employment and export opportunities for parent companies back on American soil.



Politicians who disparage investment in foreign operations are wedded to an outdated and misguided economic model that glorifies domestic production for export above all other ways for Americans to engage in the global economy. They would deny Americans access to hundreds of millions of foreign customers and access to lower‐​cost inputs through global supply chains. In short, they would cripple American companies and their American workers as they try to compete in global markets.
"
"

The politics of happiness research just got a bit more interesting. British Conservative leader David Cameron is now campaigning on a happiness platform. In a speech at a conference organized by Google in Hertfordshire, Cameron said, 



It's time we admitted that there's more to life than money, and it's time we focused not just on GDP, but on GWB---General Well-Being.



This is interesting because up until now, the politics of ""well-being"" have been primarily a welfare-liberal or social democratic phenomenon. So why the happiness schtick for the Tories? Why now? The Financial Times editorial page says:   




Mr Cameron's call for the Tories to address GWB is not a coded cry for redistribution. After green issues and childcare it is another sensible step towards increasing the opposition party's appeal by redefining popular values in modern Britain. From the Thatcher era onwards, the Conservatives have faced the charge of being cold and uncaring. Mr Cameron's task is, in part, to persuade voters that the Tories are warm and cuddly.



Although there is much support in the happiness literature for proposals to allow individuals greater control over our lives, I worry that creating a climate hospitable to risk-taking, entrepreneurship, and greater personal control (and, necessarily, greater personal responsibility) may be perceived as bracing, but not so much as ""warm and cuddly."" In his talk, Cameron dilated on the wonders of Howies, a ""socially conscious"" Welsh company in the mold of the US's American Apparel, praising their lack of hierarchy and the flexibility in work arrangements.   
  
Now, greater work flexibility is great, and that's a big part of what it would mean policy-wise to enhance well-being by giving people more control over their lives. But what does Cameron have in mind? Is this anything more than emotionally appealing talk? If so, genuine work flexibility requires deregulating the labor market, allowing individuals to bargain terms of employment for themselves, rather than getting stuck with the terms their union (which workers in certain areas often have little choice but to join) negotiated, or with terms set by the government, independent of the desires of the parties to the agreement. A system in which a certain wage, a certain package of benefits, certain labor conditions, etc., are mandated by the government is a system in which it is harder for people to opt in and out of the labor market, or to negotiate flexible contracts that uniquely suit their individual and family needs. There is a lot to be said in favor of companies that create a hospitable, flexible climate for their employees. But as the _FT_ editorialist points out: 



Not every employer can introduce flexible work practices and not every job carries high satisfaction levels. To behave as though this were possible could invite cause for dissatisfaction.



If Cameron seeks to mandate Howie's-like flexible work practices, rather than removing existing labor market interference from unions and government, he will end up reducing real flexibility for workers. Furthermore, as UCLA law professor Stephen Bainbridge points out, not every worker wants a non-hierarchical work environment. Not everyone likes being saddled with participation in management decisions in addition to their regular work. Companies should certainly be encouraged to create work environments that inspire loyalty and productivity from their workers---and good returns for their shareholders. And if you're a consumer for whom the production process is part of what you're buying, you should feel free to patronize businesses that reflect your values. But mandating flexibility, or a particular ""work-life balance,"" won't deliver it. The heirs of Thatcher should know this, and it is sad if they think thay have to act like they don't. We'll see.   
  
In defense of GDP, it is worth pointing out that focus on the size of the economy does not imply the state's endorsement of a narrow-minded, acquisitive ethos. Wealth is not a morally questionable, or even a morally neutral, end. It is easy for people to imagine that the size of the economy grows magically, due to some incomprehensible ju ju down in the basement at Google Labs or something. But it's not magic; it's virtue. The economy grows primarily because innovations in knowledge enable us to produce more, and therefore to offer more, to others in cooperative exchange. GDP growth is the steady increase in the size of the surplus from human cooperation. Extended, peaceful, increasingly effective human cooperation is not an easy thing to sustain, and the institutions, and the habits of heart and mind, that do sustain it are moral triumphs. As Deidre McClosky draws out in the brand new Cato Policy Report : 



""Modern economic growth,"" as the economists boringly call the fact of real income per person growing at a ""mere"" 1.5 percent per year for 200 years, to achieve a rise in per capita income by a factor of 19 in the countries that most enthusiastically embraced capitalism, is certainly the largest change in the human condition since the ninth millennium BC. It ranks with the first domestications of plants and animals and the building of the first towns. Possibly, modern economic growth is as large and important an event in human history as the sudden perfection of language, in Africa around 80,000 to 50,000 BC. In a mere 200 years our bourgeois capitalism has domesticated the world and made it, from Chicago to Shanghai, into a single, throbbing city.



There has been no force in history that has done more to promote ""general well-being"" than economic growth. There is no force that will do more good in the foreseeable future. I hope that Cameron takes note that in cross-national econometric studies the only variable that correlates with reported well-being more strongly than GDP per capita is a society's degree of economic freedom.   
  
There _is_ a politics of limited government and personal repsonsibility lurking in the happiness data. If Cameron is going to run on happiness, let's hope he is able to find it, and allay Frank Furedi's worries, and mine, about an illiberal, infantalizing therapeutic state.


"
"
In 2005, the European Union (EU) put into place a  carbon trading scheme. Prices for carbon permits promptly plunged, and have remained depressed since then. The price for a permit to emit a tonne of CO2 went from 21.59 Euros in 2005, to 17.28 in 2006, to 0.68 in 2007, to 2.16 in 2008, to 13.03 in 2009. Today, however, you will be glad to know that some academics declared the scheme a resounding success …

Say what? Here’s what Reuters News Service had to say:

(Reuters) – The European Union’s Emissions Trading Scheme (EU ETS) is a success and its flaws have not harmed its basic aim of reducing carbon dioxide emissions, multi-national research showed on Friday.
 
Experts at French state bank Caisse des Depots, the Paris-Dauphine University, the Center for Energy and Environmental Policy Research in the United States and University College Dublin collaborated to evaluate the scheme’s trial period, which has widely been viewed as a failure.
 
The EU’s flagship carbon trading scheme requires companies to buy permits for each tonne of carbon they emit. Carbon output is capped and the level is lowered year by year.
 
The scheme’s first trading phase ran from 2005 to 2007. Installations in the 27-nation bloc were over-allocated with carbon permits and the carbon price fell to zero.
 
The research concluded that although there were many problems in the first phase, they were overcome and did not hamper the scheme’s ultimate objective of reducing emissions. …   SOURCE  
Now, as some of you might have noticed, I’m a suspicious fellow and I like to run the numbers myself. So, what numbers should we be looking at here?
After some thought, I decided that I would look at the change from the four years prior to the institution of the carbon trading scheme (2001 through 2004), to the first four years of the scheme (2005 through 2008). [Figures for 2009 are not yet available] That would let me see if things improved or got worse.
The most logical measures to look at, it seemed to me, were per capita fuel use and CO2 emissions . (Excel spreadsheet) Using per capita figures removes the effects of  population changes .  If we just looked at fuel use, for example, a population increase would affect the fuel use. I didn’t want to be measuring the effect of population changes, so I used per capita figures.
Using those measures, I decided to compare the EU with the US. Their economies are of a comparable size and development. Since the US is the global CO2 pariah, and has no carbon trading scheme, that would give me a good baseline to compare with the EU performance.
Without further prologue, here are my results:

Figure 1. Percentage change from the period before the EU carbon trading scheme (average 2001-2004) to the period after the carbon trading scheme (average 2005-2008). All measurements are per capita.
By every single measure, the US has outperformed the EU. And the most telling point is that per capita, EU carbon dioxide emissions have increased since 2005 when the scheme started, while US carbon dioxide emissions have decreased. For a scheme designed to reduce emissions, that’s not good news.
The US did better by every measure than the EU, and did it without any restriction on carbon. Now perhaps some folks in a think-tank somewhere call that a whacking great success for the trading scheme … but not on my planet. Call me crazy, but my conclusion is that the EU carbon trading scheme was a failure.




			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8ce308d3',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"**South Africa, which had one of the world's earliest and strictest lockdowns, is marking a significant shift in its fight against coronavirus, writes BBC Africa correspondent Andrew Harding.**
It was hardly a ""mission accomplished"" moment.
South Africa's President Cyril Ramaphosa looked appropriately dour, and sounded appropriately cautious, as he appeared on national television this week to warn of the dangers of a second wave of infections and to urge the public against relaxing their guard against the virus.
And yet the president's key message was a simple, optimistic and impressive truth.
""We have succeeded in overcoming the worst phase of this epidemic,"" he declared.
As the infection rate here sinks below an important threshold of one new case per day per 100,000 people, South Africa is moving - with relief, and with some pride - into a new phase.
What the president and his scientific advisers describe as ""a new normal"".
With almost all economic activity resuming, the nation's borders slowly opening, and one of the world's earliest and strictest lockdowns ending, this feels like a significant moment - an opportunity to take stock, even to celebrate, and to explore the ever-thorny issue of who, or what, should share most credit for containing Covid-19.
""I had visions of Italyâ¦ that we're not ready, that we're going to get overwhelmed,"" recalled Professor Salim Abdool Karim - chair of the government's Covid-19 advisory panel and the public face of the scientific community - thinking back to March, and to what he and the government publicly warned was an oncoming viral ""storm"".
Instead, very few hospitals were overwhelmed, and the official death toll of some 15,000 is significantly lower than even the most optimistic modelling predicted.
Speaking on an internet link from his office in Durban, Prof Karim does not disguise the relief he feels.
But, like many scientists, his inclination is not to sit back and enjoy the good news, but rather to keep probing and testing hypotheses in order to better understand both Covid-19, and South Africa's response to it.
There is plenty of data to wade through now.
Much of it contradictory. Or rather, much of it still needing to be put in proper context.
Take South Africa's long battle against HIV and tuberculosis.
New evidence suggests TB patients are particularly vulnerable to Covid-19.
But, on the flip side, the systems put in place to cope with both pre-existing diseases, ""assisted us and better prepared us to cope with Covid,"" said Prof Karim.
And while South Africa may have good reason to celebrate its successes, there is plenty to criticise too.
""We've had a pretty bad epidemic,"" said Prof Karim.
""At one stage we were the fifth worst in the world. I wouldn't call that something to be proud of.
""I'd have been really proud if we'd been able to mitigate the impact to a much greater extent.""
As we've reported here in recent months, there have been instances of appalling mismanagement, alarming allegations of corruption, and some grave errors in handling the outbreak.
I will leave the economic impact of the lockdown - and the legitimate debate, enriched by hindsight, about whether the government got the balance right - to another day.
But what of the reasons for South Africa's relative success in fighting the virus?
Prof Karim has drawn up a list of nine factors, or hypotheses, which he applies not just to South Africa, but to other countries - not least on this continent - which appear to have been spared the worst.
Nine theories. But true to form, Prof Karim is not fully convinced by any of them, at least not without further proof.
""I doubt that any one of these is a major contributor that explains the entire difference [of why some countries have done better than others],"" he said.
""Even in combination, these would not explain the bulk of the difference we are seeing. It remains intriguing to me."""
"**The Government of Jersey has been given the power by the States Assembly to make wearing masks in shops mandatory.**
Members also approved laws to limit the size of gatherings, as part of updated Covid-19 regulations.
Currently the wearing of masks is not legally enforceable, with the government continuing to promote them in guidance.
The regulations have not created new rules, rather they have set the terms of possible restrictions.
The maximum penalty for individuals breaching any mask or gathering law would be set at Â£1,000.
Children under 12 years old would not have to wear a mask, along with people exempt for health or disability reasons, according to the regulations.
If a law requiring wearing of face coverings is introduced, it would apply to specific workplaces where a member of the public is present as a customer.
The regulations also allow orders to oblige businesses to collect personal data to aid contact tracing and to refuse service to those not wearing masks.
Any restrictions on the size of gatherings will only apply to groups of 10 or more people.
Visiting people's homes in Jersey was banned during the first wave of the pandemic before the ban was lifted in May, although public health guidance has discouraged meeting indoors since."
"
Share this...FacebookTwitterLast week parts of Germany’s media were reporting on the latest (again) alarmist findings of the Max Planck Institute (MPI), which announced that the Arctic was melting faster than expected, and that its latest model scenarios projected an ice-free Arctic in the summertime by the middle of the 21st century and, should CO2 emissions continue their rise, the Arctic would also be ice-free in the wintertime.
The Arctic is melting faster than expected, alarmist Max Planck Institute claims (US Navy photo)
But today something is different. Back just a couple of years ago, media coverage of such announcements in Germany were far more intense and spectacular. Not so today. Fewer media are turning up for the weekly end-of-world press conferences. Major media outlets are gradually losing interest in the fading climate catastrophe. Indeed it’s as if some are realizing that something is rotten in Germany’s once prestigious climate science institutes – and in those around the world.
For example, top selling German daily Bild did not even bother to feature the MPI’s Arctic meltdown press conference. Instead Bild featured a story on how clouds have been getting lower and that a negative feedback seems to be in play and is acting to cool the planet.
German flagship news magazine Spiegel also skipped reporting on the MPI doom and gloom crystal ball model findings, at least online up to now. Instead it featured a story on the Gleick stolen identity and document theft scandal in the USA, thus further tarnishing the already soiled image of climate science today.
So when Bild newspaper and Spiegel shift gears and change directions, then it’s undoubtedly a worrisome development for those on-board for the climate catastrophe joyride. Gone are the days of universal, lock-step media consensus.
Germany’s movement of skepticism started some years ago, and then picked up steam in 2009 in the wake of the Climategate emails and Germany’s 2nd international skeptic climate conference. A series of brutal winters, combined with weird Politburo-type explanations claiming it was caused by warming, provided yet more fertile ground for the seeds of skepticism. German skeptic blogs also sprouted and coordinated. The Internet buzzed with skepticism and before you knew it, the global warming establishment began having fits about the budding open discussion.
Then came Vahrenholt and Lüning.
Bild Feb. 6 page 2 story.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




And with them a mushroom cloud. On February 6, influential Hamburg-based publisher Hoffmann & Campe released a skeptic book called “Die kalte Sonne” – on what happened to be Germany’s coldest day of the winter. The release of the book also coincided with Bild’s smashing page 2 story “CO2 Lies – Renowed Team of Scientists Catastrophe Is Panic Mongering” and Spiegel’s “We’re Being Fooled” interview with Vahrenholt.
Die Welt newspaper followed the next day with a full page report called “The Sun is Giving Us Time“. In no time Vahrenholt’s and Lüning’s book became a bestseller. The grand climate gig was over.
Even more revealing was the reaction of the German environmental press and the alarmist climate institutes. Jochem Marotzke, director of the Max Planck Institute for Meteorology in Hamburg slammed the book, but did so without even reading it. So did Mojib Latif. Both claimed that the book’s line of argumentation had long since been dispelled. But this was a ridiculous claim since the book’s conclusion is based in large part on the latest scientific findings, which are now just in the process of being discussed. The few other counter arguments that they offered were of pre-IPCC AR4 nature. They fully neglected solar amplification mechanisms and ocean cycles. Horrifying is the appearance that these renown scientists are not even aware of historical climate cycles.
Lüning recently wrote that he had expected much tougher counter argumentation and is surprised that it’s been so easy so far.
Hartmut Grassl, former Director of the Max Planck Institute for Meteorology, took on an indignant attitude in a TV interview, refusing to even acknowledge the book and insisting his catastrophe fantasy is real.
The University of Osnabrück even cancelled a scheduled speech by Vahrenholt at the last minute, saying it wasn’t interested in his kind of discussion – calling it “provocative”. One student later told me that she found the University’s reaction strange and had nothing to do with expanding knowledge.
Today these institutes wonder why influential media like Spiegel and Bild are no longer bothering to report on their science. It’s not surprising – you can hear “We’re right, and we don’t want to discuss it!” only so many times before you lose interest altogether.
 
Share this...FacebookTwitter "
"

Nearly eight‐​and‐​a‐​half years after its initial application, the Keystone XL pipeline project has been given the green light (“subject to a renegotiation of terms by us”) by an executive order signed by President Trump today. Finally.   
  
  
Whether the impetus and economics is still there to build it (with oil prices in the mid-$50 barrel range) remains to be seen. But I’d imagine so, if nothing more than as an infrastructural investment in the future.   
  
  
But from the federal government standpoint, this shouldn’t matter. If private monies want to take the risk, the federal government should not stand in the way. After all, the Keystone XL pipeline passed each and every environmental impact/​safety assessment along the way. Even the climate impact, much touted and hyped by the previous Administration and its supporters, was shown, dispassionately, to be inconsequential—a mere 1/100th of a degree of warming by century’s end (and that’s being generous).   
  
  
President Obama rejected the pipeline for no other reason than for appearances—to make it seem to the rest of the world that the U.S. was serious about climate change. Apparently, he didn’t see the irony.   
  
  
His successor is resurrecting the pipeline for the same reason—appearances. In this case, the appearance of creating jobs. But as I exasperatingly explained in these pages some two years ago (“Keystone XL Pipeline: Enough Already!”):   




This project is so small in the grand scheme of _any_ thing it boggles the mind anyone outside of those directly involved in building and operating it gives it a second thought…   
  
  
At this point, the Keystone XL is just another construction project. In fact, that is all it ever was. If it didn’t require crossing the border with Canada (which required a “presidential permit”), we never would have heard a peep about it.



With the pipeline’s apparent revival, now at least, all the government resources spent examining and re‐​examining and fretting and re‐​fretting, etc. over the project will have amounted to something—even though that something should have been decided (and approved) some four or five years ago.   
  
  
What executive powers taketh away, executive powers giveth. I’m sure this won’t be the last of Obama’s symbolic actions on climate change that President Trump overturns. Each will better clear the way for us to move on to more important matters.   
  
  
—   
  
  
Update: With the release of the actual text of the Executive Order (made available several hours after Trump signed it), it’s not so much an “approval” of the Keystone XL pipeline as it is an invitation for TransCanada to resubmit its application with the promise that it will be decided upon within 60 days with, wink, wink, a more favorable outcome. So, it seems though this won’t be the last we’ve heard of it, this battle is moving closer to its completion.
"
"**Here are five things you need to know about the coronavirus pandemic this Wednesday evening. We'll have another update for you tomorrow morning.**
The chancellor has warned the ""economic emergency"" caused by coronavirus has only just begun in the UK. In his Spending Review, Rishi Sunak said the pandemic would deal lasting damage to growth and jobs, and that it had triggered the largest fall in Britain's economic output for 300 years. He added that the UK economy is expected to shrink by 11.3% this year and not return to its pre-crisis size until the end of 2022. And he confirmed a pay freeze for most public sector workers and a cut in overseas aid. Our economics editor Faisal Islam says the UK economy remains ""in rescue mode"". Read the key points from the chancellor's statement, how the Spending Review will affect you and why some young people think Mr Sunak hasn't gone far enough.
The number of unemployed people will surge to 2.6 million by the middle of next year, according to the government's independent forecaster, the Office for Budget Responsibility. The latest figures show 1.62 million people are unemployed, a number which has risen by more than 300,000 since last year amid the coronavirus pandemic. The last time the UK unemployment figure was as high as 2.6 million was in May to July 2012. The number exceeded 3 million from 1983 to 1987 and for a few months in early 1993. In his Spending Review, the chancellor said government borrowing will rise to its highest outside of wartime to deal with the economic impact. So, why is unemployment rising?
People have been urged to consider the risk of spreading coronavirus when rules are relaxed over Christmas. It comes after it was confirmed that up to three households will be allowed to stay together and form a ""Christmas bubble"" from 23 to 27 December, as agreed by all four UK nations. Prime Minister Boris Johnson told people to use ""personal judgement"" on whether or not to visit elderly or vulnerable relatives. Meanwhile, there have been calls for a UK-wide approach to coronavirus rules after Christmas. Wales' First Minister Mark Drakeford said it ""makes sense"" to ""respond to the consequences of greater household mixing"" together in the aftermath of the five-day period. Here's our guide to the Christmas rules and how to keep the virus at bay this festive season.
The number of domestic abuse offences recorded by police in England and Wales has increased during the pandemic. However, the Office for National Statistics said such offences gradually rose in recent years so it cannot be determined if it was related to the pandemic. Police recorded 259,324 domestic abuse offences between March and June - 7% up on the same period in 2019. During and after the first lockdown in April, May and June, roughly one-fifth of offences involved domestic abuse.
Intensive care nurse Valerie Bednar, who struggled to get face masks to fit her, has inspired the design of custom-fit ones for frontline healthcare workers. Her husband Gareth Smith set up MyMaskFit, which is aiming to become the first in the UK to make custom-fit, reusable, filtering face piece masks to a medical grade standard. Based in Swansea, the firm hopes to further develop a prototype designed by researchers at Birmingham University and King's College London - with the aim of making them available to the NHS in Wales in the new year. Read Valerie and Gareth's story.
Get a longer news briefing from the BBC in your inbox, each weekday morning, by signing up here.
Find more information, advice and guides on our coronavirus page.
Plus, remind yourself of the rules for visits to pubs and restaurants over the Christmas period.
**What questions do you have about coronavirus?**
_ **In some cases, your question will be published, displaying your name, age and location as you provide it, unless you state otherwise. Your contact details will never be published. Please ensure you have read our**_terms & conditions _ **and**_privacy policy.
Use this form to ask your question:
If you are reading this page and can't see the form you will need to visit the mobile version of the BBC website to submit your question or send them via email to YourQuestions@bbc.co.uk. Please include your name, age and location with any question you send in."
"The challenges of growing enough food to feed the world have grown more severe in the 21st century. We need to feed more people with limited agricultural land and resources. We need to make better use of land, light and logistics for an increasingly urban population. And we need to incorporate zero-waste and low-energy technologies into the task of food production. What can achieve the intensification of food supply we require, but in a way that is also sustainable and less harmful to the environment?  There is an urgent need to develop new methods for sustainable food production. This includes a greater emphasis on urban agriculture such as vertical farming which, properly designed and planned, could provide the sustainable means to improve food supply we need. Ideally, urban agriculture fits neatly alongside or within existing buildings in a self-contained and sustainable manner without competing for resources. Such urban plots can be at ground level or on rooftops. They can use greenhouses in order to take advantage of the sun’s energy, or grow indoors with the help of artificial lights. Vertical Farming is promising because it requires no soil, and can save space and energy – and improve crop yield. It takes advantage of the vertical space of city buildings rather than turning over wide expanses of land to agriculture and uses advanced greenhouse technology: hydroponics or aeroponics, and environmental controls that regulate temperature, humidity and light to produce vegetables, fruits and other crops year-round.  In large cities such as New York, Chicago, Tokyo and Singapore, these ideas are taking root. Singapore has taken local urban farming to a high level – Skygreens has built the world’s first commercial vertical farm in large three-storey greenhouses, providing a sustainable source of fresh vegetables.  Vertical farming’s biggest limitation is energy consumption. Considerable energy is required to power a closed, indoor greenhouse facility’s artificial lighting, heating and cooling, and hydroponic or aeroponic growing systems. The amount of energy required per unit of product is an important factor for ensuring not only that the farm is sustainable, but that it is economically viable. Recently, more and more studies have focused on pairing solar panels and wind turbines with greenhouses to provide self-generated renewable electricity on-site.  But the single technology that will be key to making vertical farms possible is lighting. New LED light technology is the key that makes it possible to build vertically integrated farms. This kind of artificial light has an extremely high photoelectric conversion efficiency, consuming only one eighth the power of incandescent lamp, half of the power of fluorescent lamp, and using a lower supply voltage (6-24V) that makes it safer to work with and reduces transmission losses.  They’re also physically small, have a long service life, lower power consumption, generate less heat, and can produce light of varying intensity. Because it produces less heat, the light can be moved closer to the plants. This increases efficiency, not just in terms of energy use but by allowing layers of growing plants to be more densely packed, making more efficient use of space.  LED lights can be tuned to emit only a narrow wavelength of light, they can be combined to create perfect lighting that provide light on the ideal spectrum for a plant’s growth. Evidence is emerging that specific wavelengths of light have distinct effects on crop yield, quality, and even pest and disease resistance.  There is potential for these multifunctional techno-greenhouses built around LED grow lights to increase the quality of the food we eat and the amount that we can grow with the same land and resources: the very 21st-century problems we now face – and through technology are getting closer to solving."
"
Cover page
Just a note to let everyone know that the Parliamentary inquiry into Climategate has produced the final report and that I have an advance copy, which is embargoed until 5:01PM PDT (00:01 GMT).
I’ll be posting it then, be sure to check in.
There are some wins in it, and there are some disappointments too. I’ll also provide links to other analysis and commentary that arises after the embargo lifts.
Layman readers should bear in mind that this report comes from a bunch of policy wonks, so there’s that sort of flavor to it. OTOH, they seem to have done a better than usual job of trying to communicate their findings.
Unfortunately, the inquiry failed to interview key people, such as Steve McIntyre, and for that they deserve an earful IMHO.
In the meantime, Mike Haesler points out in comments that the Irish Times apparently didn’t wait for the embargo to lift:
Climate unit criticised for stonewalling sceptics
http://www.irishtimes.com/newspaper/breaking/2010/0330/breaking78.html


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8d20675e',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterDonna Laframboise attended the 4th International Climate and Energy Conference in Munich, Germany last November, and granted an interview with Achgut.TV here.

Die kalte Sonne 3 from Tim Maxeiner on Vimeo.
We know that one third of the 34 authors of the IPCC summary report are connected to either Greenpeace or the WWF. Professor Fritz Vahrenholt, author of the bestselling German skeptic book Die kalte Sonne, brought this up in a recent interview:
It is indeed interesting that of the 34 members of the IPCC editorial team that wrote the summary report, one third are connected to the WWF and Greenpeace. That is legitimate, but that has to be made transparent. Imagine just the opposite and the editorial team were one third Exxon supporters. Wouldn’t people say: ’Hello! Is that really necessary?’”
Can activists be trusted to make objective judgements?
In a court of law, the guilt of the accused person is not decided exclusively by the prosecution or by the defense. To decide on guilt, we need an objective jury to weigh the evidence. And the accused never gets put away “just to be on the safe side”.
Humanity is on the dock when it comes to climate change, but 2 things are missing in the climate court: 1) a chance for the defense to present its case unobstructed and 2) an objective jury. So far we’ve had neither. In fact it could be argued that in some cases all we’ve seen so far is an angry lynch mob donning green pillow cases and armed with phony evidence, pitchforks, clubs, and torches.
 
Share this...FacebookTwitter "
"
In the New York Times:
For science that’s accessible but credible, steer clear of polarizing  hatefests like atheist or eco-apocalypse blogs. Instead, check out scientificamerican.com, discovermagazine.com and Anthony Watts’s blog, Watts Up With That?
Of course, we can’t have that, now the howling begins. Some context below.
More from the New York Times Virginia Heffernan:
Clearly I’ve been out of some loop for too long, but does everyone take  for granted now that science sites are where graduate students,  researchers, doctors and the “skeptical community” go not to interpret  data or review experiments but to chip off one-liners, promote their  books and jeer at smokers, fat people and churchgoers? And can anyone  who still enjoys this class-inflected bloodsport tell me why it has to  happen under the banner of science?
Hammering away at an ideology, substituting stridency for contemplation,  pummeling its enemies in absentia: ScienceBlogs has become Fox News for  the religion-baiting, peak-oil crowd. Though Myers and other science  bloggers boast that they can be jerky in the service of  anti-charlatanism, that’s not what’s bothersome about them. What’s  bothersome is that the site is misleading. It’s not science by  scientists, not even remotely; it’s science blogging by science  bloggers. And science blogging, apparently, is a form of redundant and  effortfully incendiary rhetoric that draws bad-faith moral authority  from the word “science” and from occasional invocations of  “peer-reviewed” thises and thats.
Under cover of intellectual rigor, the science bloggers — or many of the  most visible ones, anyway — prosecute agendas so charged with bigotry  that it doesn’t take a pun-happy French critic or a rapier-witted Cambridge atheist to call this whole ScienceBlogs enterprise what it is, or has become: class-war claptrap.
This is all about Pepsigate. See Heffernan’s column The Medium
h/t to Tim Lambert of Deltoid, hosted by Scienceblogs who couldn’t bring himself to reference anything else here at WUWT with his collection of supposed gotchas, only the one point where he was sure he could get a dig in:
Heffernan reckons that Whats Up With That presents credible science.   This is a blog that argues that Venus is hot, not because of the  greenhouse effect, but because of the high pressure in the atmosphere  (so hence Jupiter and Saturn are the hottest planets right?) .  Look:
If there were no Sun (or other external energy source) atmospheric  temperature would approach absolute zero. As a result there would be  almost no atmospheric pressure on any planet -> PV = nRT
Only if there was no such thing as gravity.
Umm, Tim, can you tell me what gases on Venus remain in a non-solid state at temperatures approaching absolute zero? What happens to solidified gases like dry ice (Frozen Carbon Dioxide) in a (planetary) gravitational field? Here’s an experiment to help you get the answer:
1. Acquire some dry ice
2. Go outside
3. Toss it upwards into the atmosphere
4. Observe
The point that was being made in that article by Goddard is that with no external energy source (the Sun) Venusian atmospheric gases would contract and eventually freeze at near absolute zero and cling to the surface of the planet, thanks to gravity.
PhysLink agrees:
Question

What will happen to the gas at absolute zero temperature (0 K)?

Asked by: Rohit
Answer

First of all, the gas will no longer be a gas at absolute zero, but rather a solid.  As the gas is cooled, it will make a phase transition from gas into liquid, and  upon further cooling from liquid to solid (ie. freezing).  Some gases, such as  carbon dioxide, skip the liquid phase altogether and go directly from gas to solid.
…
First off, 0K can never be achieved, since the amount of entropy in a system can  never be equal to zero, which is the statement of the second law of thermodynamics.  This can be nicely illustrated by your question:
Using the state equation for an ideal gas:
PV = nRT
T, the thermodynamic temperature will be equal to 0, so the product of the molar  gas constant R (8.31 J/mol/K) and the amount of moles n, will also be zero.
Therefore the product of PV must be zero also.   the pressure of the gas must be zero   or volume of the gas must be zero
As an example, look at the Ice Caps of Mars, still well above absolute zero but below the freezing point of Carbon Dioxide:

From Wiki:
The polar caps at both poles consist primarily of water ice. Frozen  carbon dioxide accumulates as a thin layer about one metre thick on the  north cap in the northern winter only, while the south cap has a  permanent dry ice cover about eight metres thick.[62]
As we see in the Physlink description, a planetary wide near absolute zero temperature (if the sun blinked off), all the rest of Mars atmosphere would be bound to the surface as a solid too. The result: no atmosphere and no atmospheric pressure.
UPDATE: As is typical anytime somebody not on the team that gets a voice or mention, those who deal in mudslinging and angry rhetoric swarm in to squash it and convince the writer of the “wrongness” of it all.
Here’s a comment from Virginia Heffernan after she’s had the treatment here. Note the number of angry labels preceding her response.
Virginia Says:
July 31st, 2010 at 12:00 am
I’m grateful for all the replies. Nice to meet you here, David.
I get the sense that Pepsigate was the last straw – or not the first,  anyway – for at least some of the dissenters from ScienceBlogs. Out of  curiosity: Did no one quietly resign over PZ Myers’s Mohammad cartoons?  Or question whether they wanted to be part of a network to which he’s  the main draw?
In my experience, legacy media types, who do kick up furors over  stuff like Mohammad cartoons, nonetheless see *debate* over ad-ed  breaches as common, especially now because of the confusion what  old-media road rules mean in digital times.
With notable exceptions, blogging, as a form, seems to me to have  calcified. Many bloggers who started strong 3-5 years ago have gotten  stuck in grudge matches. This is even more evident on political blogs  than on science blogs. In fact, after being surprised to find the same  cycles of invective on ScienceBlogs that appear on political blogs  (where they’re well documented), I started to think the problem might be  with the form itself. Like many literary and art forms before it (New  Yorker poetry, jazz, manifestos) blogs may have had a heyday – when huge  numbers of people were inspired to make original contributions –  before, seemingly all at once, the moment is gone. Some people keep  doing it, and doing it well, but the wave of innovation passes, and the  form itself needs new life. (Twitter? Tumblr?)
I have no training in science. My surprise at ScienceBlogs was akin  to the surprise a scientist who might feel if he audited a PhD seminar  on Wallace Stevens. Why aren’t they talking about “Anecdote of the  Jar”?! Why are they talking about how “misogyny intrinsic to the  modernist project”? I saw political axe-grinding bring the humanities  almost to a standstill in the 1990s. I thought science was supposed to  be above that!
One regret: the Watts blog. Virtually everyone who emailed me pointed  out that it’s as axe-grinding as anything out there. I linked to it  because has a lively voice; it’s detail-oriented and seemingly not  snide; and, above all, it has some beautiful images I’d never seen  before. I’m a stranger to the debates on science blogs, so I frankly  didn’t recognize the weatherspeak on the blog as “denialist”; I didn’t  even know about denialism. I’m don’t endorse the views on the Watts  blog, and I’m extremely sorry the recommendation seemed ideological.
All best,
Virginia Heffernan
heffernan@nytimes.com


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e89e9e5ad',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"It is set to be one of the largest ever co-ordinated protests. The People’s Climate March is due to take place in cities all over the world this weekend to try and influence the UN climate summit that follows on September 23. The marches promise to be a major global event, billed by organisers as an “unprecedented mobilisation”. No doubt it will be enjoyable to take part in – but that’s no guarantee it will work. The anti-war protests in 2003 mobilised somewhere between 6m and 10m people across 60 countries but famously failed to prevent an attack on Iraq. There is of course a substantial risk that a climate change march will similarly have no immediate discernible effect on climate policy. On the other hand, the 2003 anti-war demos may still be affecting debates about the use of force and security and ongoing efforts to take account of opinion. Popular protests have of course toppled governments and even political systems before. And sometimes it takes years or even decades to recognise what protests and revolutions really meant, including wider changes in values and priorities. So it is not that simple. A better question is: when does protest work, and when not? Sorting out clear causal effects and hard and fast rules in systems as chaotic as entire societies is of course nearly impossible. But social science research tries anyway. Current findings seem to indicate a few things which will have a bearing on the success or otherwise of the People’s Climate March: Firstly, even if marches come and go without immediate effect, one review ventures that public opinion matters to policy-making “roughly three quarters of the times”, especially by making issues “salient”. If protests actually affect public opinion then they can work indirectly. Obviously mobilisation is then required: you have to be in it to win it. Among political sociologists “resource mobilisation theory” emphasises the importance of the ability to mobilise support and marshal resources effectively. Be big and beautiful as a movement. At the same time, tightly co-ordinated action has been linked to success, and efficient organisations therefore seem also to be a key factor. Other research indicates that mobilisation is not enough and organisations don’t matter much. A rival theory focused on “political opportunity structures” says that mobilisation happens all the time – what matters is contextual factors and whether the system is ready. In particular, there have to be strong allies on the inside to convert pressure from the outside into policy change. These days media framings of protest appear also to be important, but they are rarely kind to direct action protests. Inevitably, timing also matters. A crisis moment can be a perfect moment to break down institutional barriers – although it may also make the system close ranks.  In sum: luck is when preparation meets opportunity, as Roman philosopher Seneca reputedly said (long before sociologists reached a similar conclusion). To maximise chances of success, climate change marchers will need a lot of factors to come together: high mobilisation and wide public sympathy, strong allies on the inside, a constructive media and perhaps a crisis of some description to weaken  the defences of the vested interests blocking decisive action. How does this bode for the People’s Climate March? Overall, quite well.  Firstly, public support for climate action seems to have risen slowly but steadily over the past 20 years but evidence shows that globally awareness is patchy and there is clearly potential for more awareness and support to be garnered. If the march is to add to – rather than detract from – this then size, but also charm, will be important to winning over public opinion: In terms of size, the march itself appears to be well co-ordinated: events are autonomously planned in more than 2,500 locations (compared to 600 in 2003). There are multiple agents in multiple cities and countries, with a clear message that is being communicated effectively via social media. It may beat the 2003 record set by the anti-war demos – but social movements are unpredictable entities. In terms of beauty, organisers are committed to non-violence and peaceful demonstration, which is a good start. If the media focus on the festival rather than the fringes, even better. Secondly, to be a success, the march should be adding its weight to some strong “internal” actors and institutions with similar ideas who can take things forward more consistently – what is sometimes called an “advocacy coalition”. The coalition is probably growing. The scientific community started it of course, and pressure groups and some politicians have taken it up. But businesses have begun to come on side as the opportunities for energy transition and new industries become apparent. The march may be part of a coalition, but to be part of a winning one, it has to match – and eventually overcome – opponents to change. And there are still strong opponents and almost intractable problems in organising collective actions as states wait for others to take the lead. On the other hand, for some, the global fossil fuels industry is showing signs of a crisis of sorts, as record investments have failed to bring commensurate new supplies on stream. This could be the right kind of crisis, if renewables keep falling in price and utilities are left floundering – although another financial crisis triggered by a carbon bubble bursting probably won’t help much. In any case, urgency dictates that now is probably the best time to try to make headway. However, the biggest problem in predicting success is perhaps that it is not clear what “winning” really would look like. Climate change is such a wicked problem, that it shouldn’t really be considered as a single problem at all. Dealing with climate change means addressing numerous different goals and dilemmas, not all of which can be solved at the same time. Preventing more than two degrees of global average warming acts as a rough proxy, but for some this is too much and averages miss the point anyway. But that should not worry the marchers on Sunday unduly. Their job is primarily to push the question, garner salience and apply pressure. And to enjoy themselves."
"**A top council officer says Middlesbrough is planning for the highest tier of covid-19 restrictions.**
The second lockdownÂ ends on 2 December and a three tier system will then be introduced, with an announcement due on Thursday revealing each area's fate.
Tony Parkinson, chief executive of the council, said rates had dropped but were ""still high"" compared to others.
The ""very high"" tier three restrictions would see bars and restaurants remain closed except for takeaways.
Middlesbrough mayor Andy Preston said there was talk of the whole of the North East going into the top tier, the Local Democracy Reporting Service said.
Mr Parkinson gave an update on how the council planned to recover from the impacts of the pandemic at the latest Middlesbrough Council executive on Tuesday.
""Our rate has come down from about 507 per 100,000 to about 307 per 100,000 which is great,"" he said.Â
""Thank you to everyone who has conformed and sacrificed everything.Â
""We're still higher than average in the country so we've got to expect tier three, the rumours are tier three but until Thursday we don't know.""
Strict rules would also remain in place to prevent households mixing, apart from between 23 and 27 December when up to three households will be able to meet at Christmas.
Mr Preston told BBC Breakfast on Tuesday that Middlesbrough would be in tier three if he had to bet on it but was hoping for Tier Two, again pointing to falling infection rates.Â
The NHS data dashboard showing rolling covid rates from 16 to 22 November records a rate of 307.1 per 100,000 people.
Redcar and Cleveland has fallen below the 300 mark on 292.4 per 100,000 with Stockton on 299 per 100,000 over the same seven day period.Â
The Government has indicated it will look at the rate of covid among over 60s, whether rates are rising or falling, the ""positivity rate"" - or number of positive covid cases as a percentage of the number of tests - and pressure on the NHS in deciding the tiers.
_Follow BBC North East & Cumbria on _Twitter _,_Facebook _and_Instagram _. Send your story ideas to_northeastandcumbria@bbc.co.uk _._"
"We’ve all been caught out by a thunderstorm or freezing winter morning down on planet Earth, but up in space things are rather different. Fluctuations in the weather up there won’t make you cold or damp, but they could end up crippling much of our technology. The UK government recognises this worry: “severe space weather” was added to the most recent National Risk Register for Civil Emergencies alongside flu pandemics, volcanoes and floods. Now the Met Office has opened a Space Weather Operations Centre in Exeter.  But what is this “space weather” anyway, and why does it matter so much? So-called space weather storms occur when radiation from the Sun disturbs the Earth’s magnetic field and the upper extremes of the atmosphere, a region known as the ionosphere. Such storms happen when solar flares suddenly release flashes of electromagnetic radiation or when explosions on the Sun called coronal mass ejections release charged particles, which interact with and perturb the Earth’s magnetic field and the ionosphere. This space weather in the ionosphere creates what most of us know as the Northern Lights. At present relatively little is understood about the likelihood of a huge space weather storm happening soon. We know there have been such storms in the past however, most famously the Carrington Event of 1859 which disrupted telegraph systems across Europe and North America. In those days, electronic communication was relatively new and rare. Today we have very different technology that supports our everyday lives. As society has advanced, so it has become far more vulnerable to the effects of space weather storms. Solar storms can induce current surges strong enough to knock out power supplies, as happened in 1989 when a solar storm cut power to millions of people in Quebec for nine hours. Satellite navigation systems including GPS would also be hit, with limited availability and reduced accuracy. Think of all the core services that now rely on GPS for navigation or timing: the national grid, internet banking, mobile phones, TV, aircraft landing systems and so on. As a result, understanding the impact of large solar storms on GPS accuracy is increasingly essential. Researchers at the University of Bath’s Invert Centre for Imaging Science have figured out a way to warn of the effects on the ionosphere from natural solar events and correct for them. By studying images of the ionosphere during solar storms, we can quantify the effects and correct for GPS errors. To enable this, the university runs a network of GPS scintillation receivers located from the Arctic to the South Pole, which take 50 GPS measurements per second and provide information about rapid variations in signal strength and timing. In the polar regions, where the Earth’s geomagnetic field is near-vertical, the upper atmosphere is exposed to solar radiation continuously. Lower latitudes such as the UK are only exposed during the most extreme solar storms. By studying these areas, we can understand the physical interactions underlying the processes disturbing GPS signals. Using this information, the team has developed an algorithm which gives us real-time imaging of the earth’s ionosphere. This means ionospheric errors can be measured and largely removed, allowing for more accurate GPS timing and real-time positioning.  This is part of the technology the Met Office is now using to provide real-time space weather ionosphere forecasting. The new centre will give us an insight into what the weather is like in space at any given moment and should help address how vulnerable our infrastructure and services are to a rogue solar storm. Where next? Well, we’re working to help the global satellite and communications industry model space weather effects in a sophisticated commercial GPS simulator. This would mean that GPS receivers can in the future be more robust against space weather."
nan
nan
"**The US Supreme Court has temporarily blocked New York from enforcing attendance limits at places of worship in areas hit hard by coronavirus.**
In a 5-4 vote, the court ruled that the state's congregational cap violated rights to religious freedom.
In an unsigned order, it said the rules ""single[d] out houses of worship for especially harsh treatment.""
This was one of the first consequential rulings since conservative Justice Amy Coney Barrett was appointed.
President Donald Trump appointed her to replace liberal predecessor Ruth Bader Ginsburg, who died in September.
Justice Barrett voted in the majority, along with other Trump appointees Neil Gorsuch and Brett Kavanaugh.
The three liberal justices dissented, as did conservative Chief Justice John Roberts.
Earlier this year, before Justice Ginsburg's death, the court voted to leave similar restrictions in place in California and Nevada.
The US is continuing to battle the world's largest outbreak of coronavirus. Over 12.7 million cases have been recorded nationally, and more than 262,000 deaths, according to a tally by Johns Hopkins University.
The Supreme Court's decision was a major victory for the Roman Catholic Diocese of Brooklyn and Agudath Israel, an Orthodox Jewish congregation, which had challenged the restrictions imposed by New York's Governor Andrew Cuomo.
On 6 October, Governor Cuomo shut down non-essential businesses in targeted areas where coronavirus infections had spiked, as part of efforts to control infection rates. Places of worship were also limited to gatherings of 10 in ""red"" zones, and 25 in ""orange"" ones.
In court, the Catholic Diocese of Brooklyn said the restrictions unfairly singled out places of worship. Agudath Israel of America also argued that its members were subject to ""discriminatory targeting.""
New York argued in response that it had been the epicentre of the US coronavirus outbreak in the spring. It also said religious gatherings were being treated less stringently than secular gatherings like concerts, which were banned entirely.
But the Supreme Court's unsigned majority ruled that ""even in a pandemic, the Constitution cannot be put away and forgotten. The restrictions at issue here... strike at the very heart of the First Amendment's guarantee of religious liberty.""
The court's action will not have an immediate impact since the groups that sued are no longer subject to the restrictions they fought against."
"

Last August, the _Federal Register_ announced a period of public commentary on information germane to a new set of Corporate Average Fuel Economy (CAFE) standards for the 2022–2025 period. The extant standard, of roughly 50 miles per gallon (MPG) for passenger cars and other light vehicles, was put in place in January 2017, right at the end of the Obama Administration.   
  
  
It is not surprising that EPA Administrator Scott Pruitt announced the Obama standards are _not_ to stand; we hope our extensive public comments submitted on September 27 exerted some influence on this decision.   
  
  
We noted:   




There is a paradigm‐​shift occurring in global warming that is highly relevant… It began with the revelation of remarkable and increasing discrepancies between the climate models…in the most recent report of the U.N’s Intergovernmental Panel on Climate Change (IPCC), and observations in the bulk atmosphere over vast swaths of the planet.



Figure 1 (below) shows this discrepancy.   






Figure 1. Average of the IPCC computer model projections for the tropical mid‐​troposphere versus three standard sets of observations: weather balloons, temperature sensed from satellites, and “reanalysis” data used to initialize the daily weather map. The growing discrepancy is obvious, even with the 2016 El Nino warm spike at the end.   






Figure 2 (above) shows the problem in the vertical tropics, where as much as _seven times as much_ warming has been predicted at high altitude since the satellites became operational in 1979.   
  
  
Figure 2 has enormous consequences for weather. It is the vertical distribution of temperature that determines how much moisture is wafted sky ward in the fetid tropics. Much of the extratropical temperate zone depends upon this juice.   
  
  
It is noteworthy that models in general predict the greatest amounts of future warming, while observationally‐​based studies, often about interglacial‐​glacial transitions, or differences between geological eras, tend to come up with less warming. Given data or a model, most folks will pick the former.   
  
  
We detail our reasons for re‐​examining the 2022–25 CAFÉ standards here. Have a look and we think you’ll agree that Administrator Pruitt has pretty sound science behind the need to revisit standards that were generated absent some of this very important data.
"
"British companies are expected to spend more than £12bn switching their fossil fuel vehicles for clean electric versions over the next two years.  A survey found that nearly half of UK businesses are planning to invest in chargeable cars and vans in advance of the government’s ban on sales of new internal combustion engine vehicles by 2035.  The Treasury is expected to accelerate the trend in this week’s budget by signalling an end to a decade of freezes on fuel duty for millions of drivers, as part of plans to meet tougher climate laws. Sales of electric vehicles are climbing quickly but official figures show that they still accounted for only 2% of new car registrations last year. The uptake of low-emissions driving is a key pillar of the government’s plans for cutting carbon emissions to virtually zero by 2050 to end the UK’s contribution to the climate crisis. Cars make up slightly less than a fifth of the UK’s total carbon footprint, a proportion that has risen in recent years in part thanks to the popularity of energy-hungry SUVs. Rachel Maclean, the transport minister, said: “It is encouraging to see UK businesses investing in electric vehicles and embracing greener technology to decarbonise our transport network. “Businesses having confidence in electric vehicles is crucial to end the UK’s contribution to climate change and improve air quality for all.” More than a third of companies say the government’s looming ban on petrol and diesel cars has made them bring forward plans to shift to clean driving, according to a survey by the owner of British Gas. The same proportion of companies told Centrica that access to ultra-low emissions driving zones was also a factor in their decision. Alan Barlow, managing director at Centrica’s business solutions division, said: “There is clear recognition among UK businesses of the increasingly important operational role electric vehicles can play in meeting decarbonisation goals. But concern is still widespread over how to finance this change, particularly for those with large petrol and diesel fleets.” More than two-thirds of companies said they were discouraged from investing in electric vehicles by the cost of new cars and vans, and concerns over a spike in their energy bills. Barlow said companies intending to switch to electric vehicles would be able to limit their bills by investing in solar panels and battery packs, or smart software that automatically charges vehicles at night, when energy prices are at their lowest."
"

Last January, media outlets reported that cancer had overtaken heart disease as the number one killer in the United States. Sounds scary, no? 



Fear not. As is usually the case, beyond the scary headline, deep into the copy, came the real story. _Both_ diseases are in steady decline. Cancer rates and deaths from cancer have fallen every year since the early 1990s. The thing is, incidence and mortality rates of heart disease and stroke have fallen _even more_ over the same period (25 percent since 1990). So while it’s true that cancer has “overtaken” heart disease, that’s really not the story. The story is that both are in decline, heart disease remarkably so.



Late last February, another health story hit the wires: Americans are living longer than ever before. Life expectancy is up across the board, among both genders and all ethnicities. The gaps in life expectancy between men and women and between black and white are shrinking, too. 



At the same time all of this good news has transpired, the number of Americans classified as “obese” and “overweight” has been on a steadily upward trajectory since about the mid‐​1970s. In 1985, 8 states reported that at least 10% of their populations were obese. By 1990, the number rose to 33. By 2001, it was all fifty. 



Of course, as you might expect, the scariest numbers about the condition of America’s waistline are overblown – there are significant problems with the way the government measures obesity, which I’ll discuss in a moment. But most researchers agree that the average American is carrying 10–15 more pounds than he was thirty years ago. 



If you believe media, nutrition activists, and public officials, those extra 10–15 pounds portend a looming healthcare catastrophe. U.S. Surgeon General Richard Carmona, for example, said in 2004 that childhood obesity is “every bit as threatening to us as the terrorist threat.” A congressionally commissioned report from the Institute of Medicine published in the fall of 2004 called for massive government intervention to stave off the crisis. One author said we need “nothing short of a revolution.” The World Health Organization warned “If immediate action is not taken, millions will suffer from an array of serious health disorders.”



But if we’ve been getting fatter for 30 years, shouldn’t we be seeing at least the front end of this coming crisis? Why are we getting _healthier_? In fact, a closer look at the statistics suggests that even some of the diseases most associated with obesity are in retreat.



Take cancer, for example. In 2002, the BBC reported researchers had found that “the more excess weight a person carries, the greater their risk of certain types of cancer.” In 2004, _USA Today_ echoed that claim. “The nation’s current epidemic of overweight and obesity is likely to drive up cancer rates in coming years,” the paper wrote. The Associated Press wrote that, “heart disease and diabetes get all the attention, but expanding waistlines increase the risk for at least nine types of cancer, too” (other sources put it at ten).



But of the ten types of cancer commonly associated with obesity, deaths from nine – pancreatic, ovarian, gall bladder, stomach, prostate, kidney, colal‐​rectal, cervical‐​uteran, and breast – have _decreased_ since 1992, some of them significantly. Only one – pancreatic cancer – has seen an increase in mortality rates over that period.



And heart disease? Case Western Reserve University researcher and obesity skeptic Paul Ernsberger notes that “The greatest improvements are in cardiovascular disease deaths, which are most strongly linked to obesity.”



As noted, the gap in life expectancy between black and white is shrinking. But at the same time, blacks as a group have put on more weight than whites. Incidence of obesity among black women, for example, jumped 11.7% between 1988 and 2001, compared to 7.3% among white women. Yet black women increased their life expectancy by 2.3 years, versus 1.3 years for white women over that period. It’s true with men, too. The rate of obesity among black men jumped by 7.5%, versus 7.0% among white men., yet black men on average added 4.2 years to their lives, versus 2.8 for white men. So blacks have narrowed the longevity gap with whites, even while widening (pardon the pun) the “obesity gap.”



In 2003, the _Journal of the American Medical Association_ published a study commissioned by the Center for Disease Control that said 400,000 annual American deaths are attributable to obesity. A Lexis search reveals that as of late fall of 2004, that 400,000 figure had been cited over 1,000 times in mainstream media outlets. It was also routinely cited by politicians, activists, and bureaucrats as justification for large‐​scale government intervention to curb our pudginess. At a Time Magazine‐​ABC News summit on obesity in June of 2004, attendees were inundated with the refrain that “obesity will soon overtake smoking as the number one cause of preventable death in America.” Demands for government action inevitably followed.



But there were fatal flaws in the CDC study’s methodology. First, it was a “meta” study, which incorporated data from dozens of other studies, some of them dating back to the 1940s, and attempted to apply that data to today’s demographics. Second, the study used the Body Mass Index as its arbiter of obesity, a crude formula that factors only height and weight, and which consequently mislabels as “overweight” or “obese” people who are extremely fit. According to the BMI, for example, half the National Basketball Association is either overweight or obese. But few would suggest they’re out of shape or unhealthy. Third, the study assumed that all premature deaths by obese people were caused by obesity – a leap of faith, to say the least. Finally, the study lumped the “overweight” in with the “obese,” even though there’s little evidence that overweight has any seriously ill‐​effects on health. The study’s own data, in fact, showed no correlation between being overweight and premature death, and in fact showed some benefit.



In December of 2004, the CDC reluctantly admitted its study was flawed, but only by a little — 20 to 25 percent. Critics insisted the flaws in the study’s methodology was much more significant, and in response the National Institutes for Health finally commissioned a review. In April, an independent team of researchers led by the University of North Carolina’s Katherine Flegal released a new study sharply at odds with the original 400,000 study. Flegal’s team determined the original study exaggerated the effects of obesity by some 300 percent. She put the real number of annual deaths attributable to overweight and obesity closer to 100,000. What’s more, the new study found that modest overweight actually _protects_ against premature death. When adjusted for the lives _saved_ by extra weight, the number of deaths due to obesity falls to around 25,000 — putting the original figure off by a factor of fifteen.



A subsequent internal investigation revealed that CDC officials were actually made aware of the original study’s flaws during the peer review process. So why was the more alarmist study published and relentless promoted anyway? 



As it turns out, one of the co‐​authors of the original 400,000 study was Dr. Julie Gerberding. Gerberding also happens to be the current Director of the Center for Disease Control. Comments from members of the internal investigation team reveal that the study was likely published over objections from other scientists at the CDC because the head of the agency’s name was on the study.



Gerberding still refuses to accept the new numbers. She has told the media that the CDC will continue with its anti‐​obesity campaign, and the campaign will continue to ignore the subsequent study. 



Local and state legislatures, the U.S. Congress, regulators at all levels of government, and public health advocates have since seized on the idea that nearly a half million people are needlessly dying every year because of their love handles. The Bush administration has earmarked millions of federal dollars for anti‐​obesity initiatives (though not nearly enough for the obesity warriors). Congress is considering menu‐​labeling laws, some in Washington have suggested taxes on high‐​fat or high‐​sugar foods, and others are calling on the FTC to regulate the marketing of junk food. Many states have banned junk food from school cafeterias and vending machines. And the Medicare program announced last summer that it would begin considering paying for treatment for obesity, a new entitlement that could prove to be more costly as the prescription drug benefit.



America is at war with obesity. We could eventually come to find, however, that this war’s origins are dubious as the sinking of the Maine.



None of this is to say extreme or morbid obesity is healthy, or even benign (though again, there seems to be some modest protective effects to carrying some excess weight). The decline in incidence and deaths from heart disease and cancer are almost certainly due to advances in medical research and technology. We’re getting better at uncovering these diseases early, and with pharmaceutical marvels like Statin drugs and chemotherapy, we’re making huge leaps in treatment once we’ve diagnosed them. And it’s of course likely that the gains we’ve made would be even more significant were the most obese among us a bit more svelte. 



But the notion that our expanding waistlines have put us on the verge of a calamitous offensive against our health care system simply isn’t borne out by the evidence. And so these incessant calls for immediate, large‐​scale government interference in how we grow, process, manufacture, market, prepare, sell, and eat our food ring hollow, hyperbolic, and needlessly invasive. 



The _Seattle Times_ recently did an investigation of the obesity hype, and found that much of the panic could be traced back to an aggressive campaign in the late 1990s by the pharmaceutical companies with diet drugs like Phen‐​Phen in the pipeline to get the government in the business of weight‐​watching. In 1996, the industry convinced the federal government to move the goalposts when it comes to determining the definition of “overweight” and “obesity.” At hearings dominated by researchers with ties to the pharmaceutical industry, an FDA panel eventually agreed to the change. One magical night in 1997, then, some 29 million Americans went to bet healthy, and woke up the next morning “overweight” or “obese.” And none of them gained a pound.



Debunking junk science studies and bogus chicken‐​little pronouncements are important to refute the idea that obesity represents a looming healthcare crisis. But those of us who value free markets and personal liberty wouldn’t support government intervention even if the worst pronouncements of the anti‐​fat activists were proven true. What we put into our mouths, how often we exercise, and what we feed our children are simply none of the government’s business. How did we get to the point where it could be? 



There are two answers to that question, and they should be considered separately. First, we’ve vastly expanded the concept of “public health” to include government intervention into nearly every sphere of our lives. And second, our health care system is slouching toward socialism, a troubling trend that undermines personal responsibility, and exacts a public cost on private behavior.



 **Public Health**



The proper conception of “public health” is innocuous enough. There are unquestionably some threats to our health and safety for which the remedies constitute a legitimate public good. They’re limited to risks to which no rational person would submit himself – examples might include communicable diseases like tuberculosis or typhoid, calamitous events like asteroid impacts or tsunamis, or biological or chemical terrorism. Under these limited circumstances, it’s understandable, even advisable, for a government limited to protecting the lives and property of its citizens to take collective measures to eradicate or minimize such risks, or minimize the damage should they come to pass.



But “public health” as it’s advocated today goes well beyond public goods. Over the last century, “public health” has come to mean state pressure coercing us to avoid risks, even risks we knowingly and willingly undertake. The most obvious and conspicuous example was alcohol prohibition. And though Prohibition took an untold number of lives, bred corruption, and legitimized criminal behavior, it is distinguishable from more recent expansions of public health in that lawmakers at least recognized it as a failure, and repealed it (Unfortunately, we don’t seem to have learned. The last twenty years have seen increasingly aggressive restrictions on the production, sale, and consumption of alcohol by local, state, and federal government).



But the Harrison Act – which fired the first shots of the drug war – was passed even earlier, in 1914. Drug prohibition has marched onward since. Its episodic ratchetings‐​up and coolings‐​down have commenced to a particularly aggressive and militaristic incarnation over the last twenty‐​five years.



Once we’ve accepted a definition of “public health” expansive enough for government to dictate what we can and can’t put into our bodies, it’s a short leap to seat belt laws, motorcycle helmet laws, assisted suicide bans, and prohibitions and restrictions on all sorts of other risky behavior. More recently, we’ve been given “public” smoking bans that extend to private businesses such as bars and restaurants. The Supreme Court recently upheld an Alabama ban on sex toys and marital aides. And parents are all too aware of the myriad regulations on the risks to which they can legally subject their children. Over just the last several years, governments at some level have prohibited motor scooters, “pocket bikes,” all‐​terrain vehicles, snowmobiles, alcohol vaporizers, and fireworks, to name just a few — all designed to keep people from hurting themselves. 



So it shouldn’t be the least bit surprising that “public health” might now come to include the size of our pants and the content of our refrigerators.



The justification for expansions of the government’s power to promote the “public health” is typically couched in “the number of lives this will save.” Sometimes, we’re told that a law will add x number of years to the average life. The most‐​used and easiest tactic is to simply state that the law’s necessary to protect “the children.” 



The _ad naseum_ recitation of the 400,000 figure is a good example. As is a report released in January of 2004 stating that being overweight at forty would cut several years off the typical life. The public health activists at the Center for Science in the Public Interest have long been fighting for marketing restrictions on junk food, particularly on programs directed “at our children.” 



Longevity seems to be an obsession among the public health crowd. There seems to be no limit to the costs they’re willing to endure if some policy promises to lengthen lives. It seems improbable to them that there may be people who’d sacrifice a month or two of their senior years for the lifetime of pleasure some get from a daily cigarette, a night of hard‐​drinking, or a slice of cherry pie after dinner. It’s as if adding more days to the end of our lives were the only reason for living. 



Even then, as British doctor and author Michael Fitzpatrick explains in his book _The Tyranny of Health_ , death can’t be prevented. It can only be postponed. And “death can generally be postponed only for a relatively short time by relatively intensive preventative measures,” Fitzpatrick writes. That is, high‐​cost measures that would typically add just a few days or months to the average life.



There’s certainly nothing wrong with studies or public awareness campaigns designed to discover and inform us about how we can make healthier choices. It’s that the “advice” rarely stops there. Inevitably, such studies and campaigns lead to calls for government policies aimed at increasing longevity, and in so doing, take options and choices away from people who may value pleasure, convenience, or indulgence more than perfect health or a prolonged geriatry.



In the eloquent polemic _Cigarettes Are Sublime_ , Richard Klein writes, “Healthism in America has sought to make longevity the principle measure of a good life. To be a survivor is to acquire moral distinction. But another view, a dandy’s perhaps, would say that living, as distinct from surviving, acquires its value from risks and sacrifices that tend to shorten life and hasten dying.”



Classical liberals should argue against the ever‐​expanding “public health” initiatives not only because they’re supported by junk science or manipulated data (though that’s often the case), but because the freedom to risk, indulge, and “sin” are essential to preserving individual liberty and a free society. Governments of free people aren’t authorized to ensure good health, they’re charged with securing liberty, which most certainly includes the liberty to hold bad habits.



 **Socialized Medicine**



The other chief reason why “public health” has been able to include ridiculous measures like obesity legislation and seat belt laws is because of our increasingly collective system of healthcare. Even private health care has a collective component to it. Today, routine, maintenance‐​oriented doctor visits are typically paid for by employer‐​provided health insurance, calling to mind the old Milton Friedman axiom about how generous we tend to be with other people’s money. Health insurance by definition pools risk. But many states (as well as the general culture of the health care industry) put restrictions on so‐​called “medical underwriting” – or allowing health insurers to vary premiums base don risk, the same way auto or life insurers do. All of these factors together create a system of perverse incentives which undermine the notion that we ought to let people take personal responsibility for their own health and well being. Healthy people subsidize unhealthy people. When the consequences of poor decisions are shared, there’s less incentives to make good decisions.



And that’s just the private sector. At the same time, politicians seem to be falling all over themselves in a rush to expand Medicare and Medicaid benefits for the aging, politically potent Baby Boom generation. The Cato Institute estimates that the new prescription drug benefit could in the end exceed a trillion dollars. Medicare’s noodling with the idea of covering obesity treatments could very well end up costing nearly as much.



This creeping socialization of medicine gives government new license to meddle with our private affairs. It creates a climate where excessive state interference in the most intimate of personal matters – what we put into our mouths – becomes not only acceptable among the electorate, but _desirable_. After all, if that cheeseburger you’re eating clogs your arteries and puts you in the hospital, your poor choices will be reflected in my health insurance premiums. If you’re on Medicare or Medicaid, it’ll show up in my taxes.



That’s exactly the argument the government put forward in the summer of 2004 when the Department of Health and Human Services announced that Medicare would consider covering the costs of obesity treatments, including diet plans, counseling, and gastro‐​bypass surgery, all new frontiers for preventative government intervention. HHS officials insisted that the change would save taxpayers money over the long haul if obesity were prevented or treated before the ill‐​health effects associated with the condition begin to present themselves.



It isn’t difficult to see how this argument could be applied in a larger sense – that we need to tax fatty or sugary foods, for example, to save everyone money on health insurance premiums and to keep the obesity problem from bankrupting Medicare and Medicaid. In fact, that exact argument _has_ been made – and by a credentialed _conservative,_ no less. Writing on _National Review Online,_ David Frum wrote:



And as Americans struggle with an epidemic of obesity — and the ensuing costs to the taxpayer — conservatives who favor (as almost all conservatives do favor) Medicare and Medicaid need to ask themselves whether their easy libertarian attitude to the worst practices of the fast food industry retains its relevance. Big Gulp drinks and super‐​sized fries are making America sick — and you are paying the bill. A little moderation would cure a lot of medical and fiscal ills; and a little incentive might induce that moderation.



It’s bad enough hearing that kind of talk from the left. But when it comes from the right, too, it’s a bad harbinger for what might be ahead.



The solution to this is to return some semblance of personal responsibility to the health care system. Health or Medical Savings Accounts, for example, enable consumers to roll money not spent on routine medical procedures into a retirement account, tax free. In contrast to the current system — which if anything incentivizes poor decisions — HSAs or MSAs encourage consumers to take care of themselves. Money not spent on visits to the doctor’s office is money saved for retirement.



Another suggestion would be to free up health insurers to do medical underwriting. The Bush administration has said it sees no federal barriers to the practice, so to the extent that barriers exist, they’re likely at the state level. Congress could facilitate the process by passing legislation (justified by the Commerce Clause) that would allow consumers in any state to purchase health insurance from companies in any other state, under the laws and regulations of the state where the insurer is incorporated. This would not only free up health insurers to medically underwrite, it would create a kind of competition between the states to ease regulatory burdens to attract insurers.



The result would unleash market forces on the task of finding the best carrot‐​and‐​stick approach to encouraging healthy lifestyles. Insurers would compete amongst themselves for customers, while states would lower regulatory barriers while competing for insurers. Currently, there’s much debate over whether the ill‐​health effects often associated with obesity are from obesity itself, or from the sedentary activity levels that often accompany being overweight. Hundreds of insurers competing with one another to both attract consumers and develop plans that reward the healthiest habits among their patrons (which of course benefits the insurers in the way of lower healthcare costs) might bring us closer to an answer to such questions. At the very least, if each us were solely responsible for the consequences of our diet and activity level, the point would be rendered moot from a public policy perspective.



The bizarre thing about the obesity debate is that less than a decade ago, the very thought of it was often discussed only in parody, or in a _reductio ad absurdum_ context. Opponents of the tobacco lawsuits often invoked the idea of trial lawyers suing fast food restaurants as one example of the “parade of horribles” that might follow should the tobacco suits be allowed to go forward. 



Well, we’re here now. This is post‐​reductio America. If the anti‐​obesity proposals currently up for debate become law, it’s difficult to come up with any aspect of our lives that’s out of the reach of the public health activists. Or, as one advocacy group that represents the food industry has put it, the question will no longer be “what’s next?” …but _“what’s left?”_
"
"**The Irish government plans to ease Covid restrictions for ""close to two weeks"" over Christmas.**
Tighter rules will only be brought back in if virus rates are increasing, according to the tÃ¡naiste (Irish deputy prime minister).
Leo Varadkar said it made sense to ease restrictions ""in phases"" and a full reopening next week was ""not safe"".
Gyms, retail, hairdressing and personal services will reopen first, he confirmed.
The reopening of bars and restaurants next week has not been ruled out, according to the tÃ¡naiste, but he said it was still ""a matter of discussion"".
He added that as virus rates in the Republic were lower than in the UK, the Irish government hoped to ease restrictions for longer than the five days being allowed there.
Mr Varadkar said consideration was being given to allowing three households to mix during the festive period, like the four UK nations.
The Republic of Ireland is currently under level five restrictions, the highest level of its Covid-19 tier system.
Under the rules, people can only exercise within 5km (three miles) of their home, many non-essential shops are shut and takeaway services can only be offered by bars and restaurants.
A final decision is set to be taken on new restrictions by the Irish government after a cabinet meeting at 13:00 local time on Friday, RTÃ reports.
On Wednesday, a further six deaths linked to Covid-19 were reported, bringing the Republic of Ireland's total to 2,033.
There have been 71,187 confirmed cases of the virus after an additional 269 positive tests were recorded."
"Einstein probably didn’t say “insanity is doing the same thing over and over again and expecting a different result”, but might have done had he kept tabs on the impact of the annual climate negotiations. We have now had 25 of them – the 26th Conference of the Parties (Cop26) will take place in Glasgow in November – yet greenhouse gas concentrations continue to rise inexorably. Cops – especially the one in Paris in 2015 – have changed attitudes and influenced policy. But to meet the goal of reducing global emissions to net zero by mid-century we have to start doing something substantial and different in addition to seeking stronger commitments at Cop26. The good news is that there are now real grounds for optimism that we can slow and ultimately stop greenhouse gas emissions. Renewable energy currently outcompetes fossil fuels in many areas and continues to become cheaper every year. New energy storage options, ranging from cheaper batteries to green ammonia, are emerging. New ways to produce proteins at scale without destroying rainforests are being developed.  When these solutions become so good, and so cheap, that they routinely outcompete their fossil fuel and biodiversity-destroying counterparts, greenhouse gas emissions will decline to near zero. Getting there, though, needs some serious focus on green technologies supported by policies that will get them rolled out. For almost three decades, world governments have met every year to forge a global response to the climate emergency. Under the 1992 United Nations Framework Convention on Climate Change, every country on earth is treaty-bound to “avoid dangerous climate change”, and find ways to reduce greenhouse gas emissions globally in an equitable way. Cop stands for conference of the parties under the UNFCCC. The UK will host Cop26 this November in Glasgow. In the Paris agreement of 2015, all governments agreed for the first time to limit global heating to no more than 2C above pre-industrial levels, and set out non-binding national targets on greenhouse gases to achieve that. However, these targets are insufficient, and if allowed to stand would lead to an estimated 3C of heating, which scientists say would spell disaster. For that reason, the Cop26 talks in Glasgow are viewed as the last chance for global cooperation on the emergency, with countries expected to come with tough new targets on emissions. The negotiations will be led by environment ministers and civil servants, aided by UN officials. Nearly every country is expected to send a voting representative at the level of environment secretary or equivalent, and the big economies will have extensive delegations. Each of the 196 nations on earth, bar a few failed states, is a signatory to the UNFCCC foundation treaty. The Cops, for all their flaws, are the only forum on the climate crisis in which the opinions and concerns of the poorest country carry equal weight to that of the biggest economies, such as the US and China. Agreement can only come by consensus, which gives Cop decisions global authority. Fiona Harvey Environment correspondent A research group in Oxford, led by my co-authors and myself has been identifying groups of “unicorn” technologies, named by analogy with “unicorn” startups valued at over $1bn, that can each deliver a reduction of at least a billion tonnes of CO2 a year. Unicorns don’t depend on fundamental new discoveries so should be ready for large-scale deployment within a decade. With a moderate investment in research and development or other support, they could in combination unlock multiple benefits across whole “energy ecosystems”. One example of such an ecosystem centres on converting cheap renewable energy – either from sunny places with few people, or spare wind from the North Sea – into hydrogen and ammonia, to provide zero-carbon fuel for shipping, heavy goods vehicles and even potentially aviation. They could provide the energy storage needed to complement variable wind and solar energy, process heat for industry, and turn iron ore into steel. The technologies that would unlock this ecosystem are the next generation of high-efficiency solar cells, low-cost electrolysers, and hydrogen and ammonia fuel cells and engines. All are proven technologies that simply need to be cheaper – further development could rapidly unlock a virtuous circle of falling costs and increased deployment. Another example is exceptionally water-efficient plants that can grow in semi-arid areas or on degraded land – prickly pear, pineapples and euphorbias are examples. Such plants could sequester carbon in soil on a large scale, and be fermented to proteins in place of soya beans, whose growth causes widespread deforestation and huge greenhouse gas emissions; they could even be used to make plastics. The unicorn technologies in this case include learning how to grow plants that we have historically ignored, along with precision separation and fermentation of the biomass. Getting a bold, unanimous agreement to ratchet up global ambition to act on climate at Cop26 will be very hard at this stage of the game, with the usual cabal of petro-states and coal producers doing their utmost to dilute any decisions of consequence. However, an approach focused around “coalitions of the willing” in the bottom-up spirit of the Paris climate agreement, could enable substantial progress without being stymied by vested interests. Each of these coalitions, built from nation states but also regions and even corporates, could focus on one or more of the unicorns. They would support research and development, advance demonstrators, or provide lower-cost finance or performance guarantees to encourage rollout and help the technologies become cheaper. They would allow least-developed and developed nations to share ambitions and interests in technologies where they have comparative advantages, such as solar resources, land or skills. Management and licensing of intellectual property could encourage coalitions to form and accelerate technology deployment. The formation of these coalitions could be seen as evolution of an earlier UK initiative called Mission Innovation. It targeted sectors or problems, rather than – as we are proposing – selected technology areas that underwrite whole energy ecosystems, which we believe would be a very much more productive approach.  This should not be seen as “picking winners”, but rather as “picking runners”. Funders should be prepared to see failures as well as successes. As co-chair with Italy of Cop26, the UK has an excellent opportunity to build coalitions that would lead to cheaper alternatives to fossil fuels. The UK is home to several companies and world experts in both the “hydrammonia” economy and semi-arid plants, and British businesses could be leading players in these two examples of ecosystems. In parallel with preparing for Cop26, the government should also change the UK’s broad approach. Neither academia nor industry on their own has the principal objective of solving the climate crisis. They have neither skills nor funding to develop technologies that are (nearly) out of the laboratory, build demonstrators when necessary, and create the technical and financial conditions needed to enable large-scale rollout. We believe the UK needs something like the Advanced Research Projects Agency-Energy, created in the US, which “advances high-potential, high-impact energy technologies that are too early for private-sector investment”. By fostering coalitions of the willing, which would focus on clusters of unicorn technologies, the UK could make a major contribution to solving the climate crisis. Cop26 could indeed be a turning point – but it cannot simply be more of the same. • Mike Mason is a fellow at the Smith School of Enterprise and the Environment, University of Oxford. This piece was written in collaboration with Cameron Hepburn, director of the Smith School, and Chris Llewellyn Smith, of the department of physics"
"

It’s official: 2006 is the warmest year in the temperature history of the lower 48 states. The records go back to 1895, and so far, with the exception of the far West, the winter of 2006–7 hasn’t been much cooler than your average fall. Last summer was the third hottest of all. 



Our hot summers have tended to be about 2 degrees F warmer than the century‐​scale average, while our winters have warmed by about 4 degrees. But a global warming or cooling trend doesn’t guarantee that any individual year or season will be warm or cold. The summer of 2004, for example, was the 15th coldest since 1895, and the winter 2000-01 was pretty chilly across the entire country. 



Let’s be candid. This is the way global warming is supposed to work. It raises the probability that a given season will be above average, but it doesn’t guarantee it. Further, it’s been known for well over a hundred years — long before scientists were taking regular measurements of U.S. temperatures — that putting carbon dioxide in the air will warm winters here much more than summers. 



There’s another peculiar (and predicted) characteristic about the winter warming: more than anything else, it’s the coldest days of winter that have warmed the most since 1976, while the hottest days of the summer have budged very little. 



Just as not all “global warming” winters are warm, there were some spectacularly warm ones in the early 20th century. It’s nothing new. 



“The official Washington temperature climbed to 76 degrees yesterday to tie the all‐​time January maximum temperature,” the _Washington Post_ reported on January 15, 1932. “Flowers have never ceased to bloom in the capital this year, coaxed out by the succeeding days of warm weather…frogs are croaking in the reservoir…just like they do in the summer.” 



The warmth of the eastern half of the U.S. in the winter of 1931–2 is like one of those baseball records people thought would never be topped. But, of course, both baseball and climate change, assisted by modern chemistry and technology, break old records. Barry Bonds hit 73 home runs, and one winter will eventually best 1931–32. 



And that winter will probably be even more enjoyable. As the _Post_ further reported that year, “Coatless citizens pluck pansies and pussy willows at New Haven, Conn.…Cleveland schoolboys go swimming in Lake Erie with temperature at 70.” 



Sounds like people were having fun back then, just as they are now. Hard to find a downbeat face, even here in politically shocked Washington. Maybe people are thinking about their heating bills. Maybe they are relieved not to have to experience the sheer terror that a single inch of snow causes around here. 



Temperatures began their recent climb with a sudden climate shift in the Pacific Ocean in 1976. In the succeeding three decades, winters warmed more than summers, colder temperatures rose more than hot ones, some places were drier, and some were wetter. 



But meanwhile, life expectancy, per‐​capita income, and crop yields went up, while the real cost of most commodities dropped. Global warming didn’t make all those salubrious things happen — although it had a little to do with higher crop yields — but it surely did not stop them. 



That prosperity and Washington’s smiling winter faces won’t stop the new legislative express on global warming. Nor will it stop naysayers who correctly proclaim that no politically viable proposal will ever do anything to slow planetary warming in a fashion that can even be measured. 



It’s not just the usual suspects who tout this. Scientists way on the left of the global warming spectrum, like Tom Wigley of the National Center for Atmospheric Research in Boulder, and Germany’s Paul Crutzen, now speak of technological “fixes,” such as injecting particles into the stratosphere to block sunlight, precisely because they appreciate how little any global warming law could accomplish, and how much it would cost. 



That, coupled with the people’s general satisfaction with the warm winter and their prosperity as the planet warms, should provoke the real debate concerning global warming. If, in fact, we can develop technology to choose the planet’s mean temperature, where should we set it? 



Before we began burning much fossil fuel, the hemisphere was mired in the “Little Ice Age.” Glaciers threatened European villages. Want to go back there? Or, maybe we’d like it like it is now, or even warmer. 



I don’t know the answer, but that’s the question society will ultimately wrestle with as it enjoys warmer winters, and finally acknowledges the futility of attempting to stop warming with impotent legislative acts
"
"
Share this...FacebookTwitterHere’s Germany’s solution to saving energy and reducing its carbon foortprint- make electricity affordable only to a few rich people! German online DIE WELT daily has an article titled: Hundreds Of Thousands Have Had Their Power Turned Off.
Germany’s power and gas has become so expensive thanks to its Renewable Energy Feed-in Act that it is now an unaffordable commodity for many among the poor.
Under the feed-in act, power companies are forced to buy up the expensive renewable energy from producers and pay them exorbitant tariffs. This has driven Germany’s electricity prices up and has made them among the most expensive in the world. So much so, that many can no longer pay for it.
According to DIE WELT:
Because of unpaid electricity bills, an estimated 600, 000 households in Germany had their power cut off in 2010, according to the Consumer Agency of North Rhine Westphalia in Düsseldorf. […] Price increases of about 15% for electricity and gas over the past 2 years have made energy an unaffordable commodity for many households.” said Chairman Klaus Müller. The increasing energy poverty is alarming.”
DIE WELT also writes that power companies had to send out millions of payment reminders. Many of these consumers, who were in arrears, paid their bills, but a portion were unable to do so.
 
Share this...FacebookTwitter "
nan
"

In March 1990, NASA’s Roy Spencer and University of Alabama-Huntsville’s (UAH) John Christy dropped quite a bomb when they published the first record of lower atmospheric temperatures sensed by satellites' microwave sounding units (MSUs). While they only had ten years of data, it was crystal clear there was no significant warming trend.   
  
It was subsequently discovered by Frank Wentz of Remote Sensing Systems (RSS), a Santa Rosa (CA) consultancy, that the orbits of the sensing satellites successively decay (i.e., become lower) and this results in a spurious but slight cooling trend. Using a record ending in 1995, Wentz showed a slight warming trend of 0.07⁰C/decade, about half of what was being observed by surface thermometers.   
  
In 1994, Christy and another UAH scientist, Richard McNider, attempted to remove “natural” climate change from the satellite data by backing out El Niño/La Niña fluctuations and the cooling associated with two big volcanoes in 1983 and 1991. They arrived at a warming trend of 0.09⁰C/decade after their removal.   
  
Over the years, Spencer and Christy slightly revised their record repeatedly, and its latest iteration shows a total warming trend of 0.13⁰C/decade, which includes natural variability. But it is noteworthy that this is biased upward by very warm readings near the end of the record, thanks to the 2015–16 El Niño.   




Recently, Christy and McNider carried out a similar analysis to what they did in 1994 and found removing the volcanoes and natural sea surface temperature changes resulted in a warming trend nominally the same as their 1994 finding, at 0.10⁰C/decade—far, far beneath the 0.2–0.3⁰C/decade predicted for the current era by the models in the latest (2013) report of the UN’s Intergovernmental Panel on Climate Change.   
  
Much as Christy and McNider said in 1994, it appears that the sensitivity of temperature to carbon dioxide changes in those models is just too high.   
  
Here’s the illustration at the heart of the paper:   




![Because the print is so small in the figure legend, we’ll paraphrase it here. The top plot \(red\) is the temperature of the lower troposphere \(“TLT”\), from the surface to about eight kilometers in altitude.  The blue plot is the “natural” sea surface temperature \(SST\) component, now a combination of El Niño and other known oscillations, such as the Pacific Decadal Oscillation \(PDO\) and the Atlantic Multidecadal Oscillation \(AMO\). The middle black plot is the raw satellite data minus the oceanic oscillations, and the bottom one adjusts that for the two big volcanoes in 1983 and 1992. ](https://object.cato.org/sites/cato.org/files/wp-content/uploads/christy2017.png)



_Because the print is so small in the figure legend, we’ll paraphrase it here. The top plot (red) is the temperature of the lower troposphere (“TLT”), from the surface to about eight kilometers in altitude. The blue plot is the “natural” sea surface temperature (SST) component, now a combination of El Niño and other known oscillations, such as the Pacific Decadal Oscillation (PDO) and the Atlantic Multidecadal Oscillation (AMO). The middle black plot is the raw satellite data minus the oceanic oscillations, and the bottom one adjusts that for the two big volcanoes in 1983 and 1992._



The new Christy and McNider paper also calculates the “transient sensitivity” of temperature to increasing carbon dioxide. The transient sensitivity is the temperature change observed at the time that atmospheric carbon dioxide doubles from its preindustrial background. Given observed rates of increase, this should occur sometime around 2070. The sensitivity works out to 1.1⁰C, which is slightly below half of the average transient sensitivity of all the climate models in the latest (2013) report of the UN’s Intergovernmental Panel on Climate Change.   
  
This is another indication that if business-as-usual continues, including a continued transition from coal to natural gas for electrical generation, the world will easily meet the Paris Accord target of total anthropogenerated warming of less than 2.0⁰C by the year 2100.   
  
Note that this is based on the satellite-sensed lower atmospheric temperatures. Our next post will compare them to the reanalysis data described in our last Global Science Report.


"
"

Al Gore’s cinematic lecture contends, in part, that rising global temperatures from industrial greenhouse gas emissions are at this very moment melting the Greenland Ice Sheet, a phenomenon that will eventually inundate global coastal areas and submerge countless cities. True? Not according to a new paper that appears in the June 13 issue of _Geophysical Research Letters_ , a prominent peer‐​reviewed publication of the American Geophysical Union. The authors conclude their study with the following discussion: 



We have analyzed temperature time series from available Greenland locations and we have found that:   
  
  
i) The years 1995 to 2005 have been characterized by generally increasing temperatures at the Greenland coastal stations. The year 2003 was extremely warm on the southeastern coast of Greenland. The average annual temperature and the average summer temperature for 2003 at Ammassalik was a record high since 1895. The years 2004 and 2005 were closer to normal being well below temperatures reached in 1930s and 1940s (Figure 2).   
  
  
Although the annual average temperatures and the average summer temperatures at Godthab Nuuk, representing the southwestern coast, were also increasing during the 1995–2005 period, they stayed generally below the values typical for the 1920–1940 period.   
  
  
ii) The 1955 to 2005 averages of the summer temperatures and the temperatures of the warmest month at both Godthaab Nuuk and Ammassalik are significantly lower than the corresponding averages for the previous 50 years (1905–1955). The summers at both the southwestern and the southeastern coast of Greenland were significantly colder within the 1955–2005 period compared to the 1905–1955 years.   
  
  
iii) Although the last decade of 1995–2005 was relatively warm, almost all decades within 1915 to 1965 were even warmer at both the southwestern (Godthab Nuuk) and the southeastern (Ammassalik) coasts of Greenland.   
  
  
iv) The Greenland warming of the 1995–2005 period is similar to the warming of 1920–1930, although the rate of temperature increase was by about 50% higher during the 1920–1930 warming period.   
  
  
v) There are significant differences between the global temperature and the Greenland temperature records within the 1881–2005 period. While all the decadal averages of the post‐​1955 global temperature are higher (warmer climate) than the pre‐​1955 average, almost all post‐​1955 temperature averages at Greenland stations are lower (colder climate) than the pre‐​1955 temperature average.   
  
  
An important question is to what extent can the current (1995–2005) temperature increase in Greenland coastal regions be interpreted as evidence of man‐​induced global warming? Although there has been a considerable temperature increase during the last decade (1995 to 2005) a similar increase and at a faster rate occurred during the early part of the 20th century (1920 to 1930) when carbon dioxide or other greenhouse gases could not be a cause. The Greenland warming of 1920 to 1930 demonstrates that a high concentration of carbon dioxide and other greenhouse gases is not a necessary condition for period of warming to arise. The observed 1995–2005 temperature increase seems to be within a natural variability of Greenland climate. A general increase in solar activity [Scafetta and West, 2006] since 1990s can be a contributing factor as well as the sea surface temperature changes of tropical ocean [Hoerling et al., 2001].   
  
  
The glacier acceleration observed during the 1996–2005 period [Rignot and Kanagaratnam, 2006] has probably occurred previously. There should have been the same or more extensive acceleration during the 1920–1930 warming as well as during the Medieval Warm period in Greenland [Dahl‐​Jensen et al., 1998; DeMenocal et al., 2000] when Greenland temperatures were generally higher than today. The total Greenland mass seems to be stable or slightly growing [Zwally et al., 2005].   
  
  
To summarize, we find no direct evidence to support the claims that the Greenland ice sheet is melting due to increased temperature caused by increased atmospheric concentration of carbon dioxide. The rate of warming from 1995 to 2005 was in fact lower than the warming that occurred from 1920 to 1930. The temperature trend during the next ten years may be a decisive factor in a possible detection of an anthropogenic part of climate signal over area of the Greenland ice sheet.



So who are you going to believe—a couple of scientists from Los Alamos and an atmospheric physicist … or a politician who is, _ahem_ , NOT a scientist and his similarly uncredentialed Hollywood friends? The latter group may turn out to be right, of course, but if you only paid attention to what was in the _New York Times_, you’d think studies such as the one above are the paid figments of oil company imagination. They are not.
"
"The world is “way off track” in dealing with the climate emergency and time is fast running out, the UN secretary general has said. António Guterres sounded the alarm at the launch of the UN’s assessment of the global climate in 2019. The report concludes it was a record-breaking year for heat, and there was rising hunger, displacement and loss of life owing to extreme temperatures and floods around the world.   Scientists said the threat was greater than that from the coronavirus, and world leaders must not be diverted away from climate action. The climate assessment is led by the UN’s World Meteorological Organization (WMO), with input from the UN’s agencies for environment, food, health, disasters, migration and refugees, as well as scientific centres. In 2019 the oceans were at the hottest on record, with at least 84% of the seas experiencing one or more marine heatwaves. Surface air temperatures around the world were the hottest ever recorded, after a natural El Niño event boosted figures in 2016. The report says results from the World Glacier Monitoring Service indicate 2018-19 was the 32nd year in a row in which more ice was lost than gained. The melting of land ice combined with thermal expansion of water pushed sea levels up to the highest mark since records began.  The long-term decline of Arctic sea ice also continued in 2019, with the September average extent – usually the lowest of the year – the third worst on record. “Climate change is the defining challenge of our time. We are currently way off track to meeting either the 1.5C or 2C targets that the Paris agreement calls for,” said Guterres. 2019 ended with a global average temperature of 1.1C above pre-industrial levels. “Time is fast running out for us to avert the worst impacts of climate disruption and protect our societies.” He added: “We need more ambition on [emission cuts], adaptation and finance in time for the climate conference, Cop26, in Glasgow, UK, in November. That is the only way to ensure a safer, more prosperous and sustainable future for all people on a healthy planet.” Prof Brian Hoskins, of Imperial College London, said: “The report is a catalogue of weather in 2019 made more extreme by climate change, and the human misery that went with it. It points to a threat that is greater to our species than any known virus – we must not be diverted from the urgency of tackling it by reducing our greenhouse gas emissions to zero as soon as possible.” The physicist Edward Teller tells the American Petroleum Institute (API) a 10% increase in CO2 will be sufficient to melt the icecap and submerge New York. “I think that this chemical contamination is more serious than most people tend to believe.” Lyndon Johnson’s President’s Science Advisory Committee states that “pollutants have altered on a global scale the carbon dioxide content of the air”, with effects that “could be deleterious from the point of view of human beings”. Summarising the findings, the head of the API warned the industry: “Time is running out.” Shell and BP begin funding scientific research in Britain this decade to examine climate impacts from greenhouse gases. A recently filed lawsuit claims Exxon scientists told management in 1977 there was an “overwhelming” consensus that fossil fuels were responsible for atmospheric carbon dioxide increases. An internal Exxon memo warns “it is distinctly possible” that CO2 emissions from the company’s 50-year plan “will later produce effects which will indeed be catastrophic (at least for a substantial fraction of the Earth’s population)”. The Nasa scientist James Hansen testifies to the US Senate that “the greenhouse effect has been detected, and it is changing our climate now”. In the US presidential campaign, George Bush Sr says: “Those who think we are powerless to do anything about the greenhouse effect forget about the White House effect … As president, I intend to do something about it.” A confidential report prepared for Shell’s environmental conservation committee finds CO2 could raise temperatures by 1C to 2C over the next 40 years with changes that may be “the greatest in recorded history”. It urges rapid action by the energy industry. “By the time the global warming becomes detectable it could be too late to take effective countermeasures to reduce the effects or even stabilise the situation,” it states. Exxon, Shell, BP and other fossil fuel companies establish the Global Climate Coalition (GCC), a lobbying group that challenges the science on global warming and delays action to reduce emissions. Exxon funds two researchers, Dr Fred Seitz and Dr Fred Singer, who dispute the mainstream consensus on climate science. Seitz and Singer were previously paid by the tobacco industry and questioned the hazards of smoking. Singer, who has denied being on the payroll of the tobacco or energy industry, has said his financial relationships do not influence his research. Shell’s public information film Climate of Concern acknowledges there is a “possibility of change faster than at any time since the end of the ice age, change too fast, perhaps, for life to adapt without severe dislocation”. At the Rio Earth summit, countries sign up to the world’s first international agreement to stabilise greenhouse gases and prevent dangerous manmade interference with the climate system. This establishes the UN framework convention on climate change. Bush Sr says: “The US fully intends to be the pre-eminent world leader in protecting the global environment.” Two month’s before the Kyoto climate conference, Mobil (later merged with Exxon) takes out an ad in The New York Times titled Reset the Alarm, which says: “Let’s face it: the science of climate change is too uncertain to mandate a plan of action that could plunge economies into turmoil.” The US refuses to ratify the Kyoto protocol after intense opposition from oil companies and the GCC. The US senator Jim Inhofe, whose main donors are in the oil and gas industry, leads the “Climategate” misinformation attack on scientists on the opening day of the crucial UN climate conference in Copenhagen, which ends in disarray. A study by Richard Heede, published in the journal Climatic Change, reveals 90 companies are responsible for producing two-thirds of the carbon that has entered the atmosphere since the start of the industrial age in the mid-18th century. The API removes a claim on its website that the human contribution to climate change is “uncertain”, after an outcry. Exxon, Chevron and BP each donate at least $500,000 for the inauguration of Donald Trump as president. Mohammed Barkindo, secretary general of Opec, which represents Saudi Arabia, Kuwait, Algeria, Iran and several other oil states, says climate campaigners are the biggest threat to the industry and claims they are misleading the public with unscientific warnings about global warming. Jonathan Watts The WMO said its report provided authoritative information for policymakers on the need for climate action and showed the impacts of extreme weather. A heatwave in Europe was made five times more likely by global heating, and the scorching summer led to 20,000 emergency hospital admissions and 1,462 premature deaths in France alone. India and Japan also sweltered and Australia started and ended the year with severe heat and had its driest year on record. Australia had “an exceptionally prolonged and severe fire season”, the WMO noted. Floods and storms contributed most to displacing people from their homes, particularly Cyclone Idai in Mozambique and its neighbours, Cyclone Fani in south Asia, Hurricane Dorian in the Caribbean, and flooding in Iran, the Philippines and Ethiopia. The number of internal displacements from such disasters is estimated to have been close to 22 million people in 2019, up from 17 million in 2018. The US saw heavy rains, with the total from July 2018 to June 2019 being the highest on record. Total economic losses in the US for the year were estimated at $20bn, the WMO said. Unpredictable climate and extreme weather was a factor in 26 of the 33 nations that were hit by food crises in 2019, and was the main driver in 12 of the countries. “After a decade of steady decline, hunger is on the rise again – over 820 million suffered from hunger in 2018, the latest global data available,” the report says. The WMO said unusually heavy precipitation in late 2019 was also a factor in the severe desert locust outbreak in the Horn of Africa, which is the worst for decades and expected to spread further by June 2020 in a severe threat to food security. Prof Dave Reay, of the University of Edinburgh, said: “This annual litany of climate change impacts and inadequate global responses makes for a gut-wrenching read. Writ large is the ‘threat multiplier’ effect that is climate change on the biggest challenges faced by humanity and the world’s ecosystems in the 21st century.”"
"Full marks to colleagues at the World Wildlife Fund and the Zoological Society of London for the Living Planet Report 2014 and its headline message which one hopes ought to shock the world out of its complacency: a 52% decline of wildlife populations in the past 40 years.   Over the summer I re-read Fairfield Osborne’s 1948 classic Our Plundered Planet – the first mass-readership environmental book that detailed the scale of the damage humanity wrought on nature. Faced with the figures in this report it is easy to slip into despondency and to blame others. But this would be a mistake. At the time, Osborne’s report must have been equally alarming, but the eclectic conservation movement of which he was part responded with confidence, hope and vision.  Their achievements were huge: the creation of a reserve network that forestalled the extinction of African creatures such as the elephant and rhino, the creation of a nature conservation agency, the International Union for Conservation of Nature) (IUCN) within the UN, and a raft of international wildlife agreements.   Today, conservation-minded people will probably be wondering what can be done to reverse wildlife declines. For me the question is how can today’s conservationists leave a wildlife legacy for the 21st century, and I think there are five ways we can change conservation to better fit the circumstances we face.  The effort to ensure that nature conservation became a policy area of the UN necessitated developing a strong international conservation regime. This has served us well, but the world has changed: centralised authority has given way to messy, networked governance organised across many levels.  If the Balinese want to restore Bali Starling populations in coconut plantations I say applaud their vision and learn from their innovation. What matters is that wildlife populations flourish, not that some institutionalised notion of a “wild species” gains global consensus. It is time to nurture diversity in conservation practice. Since the 1990s conservation has become overly technocratic, with nature framed as a natural resource and stock of capital available for human economic development. Given human self-interest this just leads to arguments over who gets what share.  I suggest a better way to frame environmental policy is in terms of natural assets – places, attributes and processes that while representing forms of value to invest in, are also at risk of being eroded and must be protected. We’ve done this before – think of great national parks where wildlife conservation, natural beautification and outdoor recreation combine for the benefit of wildlife, while also emphasising regional or national identity, health and cultural and economic worth.  Re-wilding is gaining traction. I see re-wilding as an opening, an opportunity for creative thinking and action that will affect the future. A key theme is restoration of trophic levels – in which the missing large animals at the top of the food chain are reintroduced, allowing natural ecosystem processes to reassert themselves. We might ask whether today’s reported declines in wildlife are a symptom of the ecosystem becoming more simple and, if so, whether re-wilding will lead to more abundant wildlife. Ecological intuition suggests the latter but in truth we don’t know.  In my view we need large-scale, publicly-financed re-wilding experiments to explore and develop new ways of rebuilding wildlife populations as an asset for society.   It’s clear that wildlife conservation is moving from being a data-poor to a data-rich science. The methods that underpin the Living Planet Report are state-of-the art, but even so we have yet to capture the analytical potential of “big data”.  Recent rapid developments in sensor technologies look set to bring about a step change in environmental research and monitoring. In ten year’s time, I predict that the challenge for indexing the planet will shift from searching out and compiling data sets to working out how to deal with an environmental “data deluge”. Despite this, wildlife conservation lacks a coherent vision and strategy. There are plenty of interesting technological innovations, but they are fragmented and individualistic in nature. We need leadership and investment to better harness them. Like it or not, the wildlife conservation movement was at its most influential – as a policy and cultural imperative – when it was filled with active members drawn from the political, aristocratic, business, scientific, artistic and bureaucratic elites.  This was between 1890 and 1970. Over the past 40 years conservation organisations have become more professional, building close working relations with bureaucrats, but approaching other elites simply as sources of patronage, funds and publicity. Conservation organisations must open-up, loosen their corporate structures and let leaders from other walks of life actively contribute their opinion, insight and influence to the cause.  These are five starting points for discussion rather than prescriptions. Perhaps the greatest asset we have is the deep-rooted sense of concern for wildlife found across cultures, professions and classes. It’s time to open up the discussion, to put forward new ideas for debate, and to ask others to suggest new and novel ways to save wildlife."
"

When Amazon announced that half of its new corporate headquarters would be in Long Island City, it was revealed that the company also hit the jackpot with up to $3 billion in New York state and local subsidies. This angered a lot of people, including Rep.-elect Alexandra Ocasio‐​Cortez, D‐​Queens, but officials dug their heels in. As Gov. Andrew Cuomo said, “It’s not a level playing field to begin with … All things being equal, if we do nothing, [Amazon is] going to Texas.”



But all things are not equal between New York and Texas, and New York should fix its policies rather than hand out pork. There is considerable room for improvement, as New York state has the second‐​worst business tax climate and New York City has some of the most expensive housing per square foot in the nation. To fix the problem, New York should lean out taxes and regulation.



Cuomo is right that high taxes are a turn‐​off for business. But rather than provide Amazon with a special, targeted break, why not improve the rules for everyone? In order to attract business, states could cut or repeal corporate income taxes, which account for only 2% of state and local revenues yet act as a major growth hurdle given how mobile corporate investment is today.





Company‐​specific subsidies put the retail giant’s interests ahead of everyone else’s.



Because half of all business income flows through individual income taxes, these taxes also deter investment. New York should reduce income taxes to be more competitive. High taxes in places like New York are driving wealthy entrepreneurs out to zero‐​income‐​tax Florida and other low‐​tax states.



Governments could also reform property taxes and reduce development fees, which are a drag on business and residential development. Property taxes are by far the largest state and local tax burdens on businesses, and in many states don’t just hit land and structures but also machinery and equipment. States and cities with heavy business property taxes dissuade investment by capital‐​intensive businesses such as manufacturing.



Poor state and local policy isn’t only a drag on business: it also affects workers’ lives. High tech‐​firms need to hire talent, but workers won’t be so interested if livability is low and costs are high. For example, $200,000 only buys 126 square feet of living space in Manhattan, the worst in the nation. But the regulatory tax associated with zoning is estimated to account for 50% of the cost of housing there. This is something that policymakers should change.



Increasing allowable development density in New York’s boroughs and streamlining discretionary development approval processes would help support the growth New York needs, improve affordability for current and future residents, and even ease gentrification pressures when big business arrives.



Other policy reforms could reduce the cost of living. For example, occupational licensing increases the cost of services such as child and medical care that working families need. One study suggests that just requiring lead day care teachers have a high school degree is associated with an increase in child care costs of 25% to 46%. New York City has more restrictive occupational licensing requirements, and the state has the fourth‐​most expensive child care in the U.S.



Policymakers in New York should attend to these issues rather than handing out pork. Instead, they generated a series of one‐​off incentives and subsidies that were Amazon‐​specific, putting Amazon’s interests ahead of everyone else’s.



That would be less offensive if economic development incentives were critical to sustained economic growth. But mega‐​companies do less for cities’ long‐​term economic growth and health than smaller, organically grown companies do. And as Harvard economist Edward Glaeser argues in _Triumph of the City_ , having a diversity of industries, rather than a large and economically dominant company, is vital for cities’ long‐​term health.



Only broad‐​based reforms can provide a diverse and competitive economy. If governments were genuinely interested in the benefits of economic development for their residents, they would look for opportunities to improve the economic and regulatory landscape in an inclusive way. After all, businesses and workers don’t need more pork, they need lean government.
"
"
Share this...FacebookTwitter
German “intellectual” online daily Die Zeit here interviews four (state-funded) alarmists (some more, some less) just to reassure its readers that the world is indeed coming to a catastrophic end.
Here it’s interesting to compare the remarks of Hans von Storch and Stefan Rahmstorf on the subject of sea level rise of the North Sea, as measured by tide gauges.
Rahmstorf:
Especially important for us here in Germany was a study on North Sea sea level. Scientists at the University of Siegen showed what consequences climate change is already having on our own coastlines. The evaluation of the data from 13 gauge stations over the last one and a half centuries confirm a sea level rise – and an acceleration over the last few decades.”
Hans von Storch:
Through an anylsis of synchronous fluctuations at many gauges, a rise in sea level of about 20 cm per century could be now be estimated.”
That’s a whole 2 mm per year, which is one seventh the rate of what Ramstorf envisions in his tamer wet dreams. Moreover, the link that Rahmstorf provides has a chart which clearly shows the rate of rise during the end of the 19th century was greater than what has occurred over the last few decades. He forgot to mention that.
One thing is clear: sea level measurement is fraught with complexity, and thus it would be easy for any shifty scientist to get the results he wants. But not to worry, we all know that they are, to quote Mark Antony,  “ambitious and honorable men”.
As far as the other content in the DIE ZEIT piece, it’s just the usual, alarmist pre-Durban crap. (Don’t waste your time)
Share this...FacebookTwitter "
"
Share this...FacebookTwitterA new book is coming out. Personally I believe it’s going to cause a political storm in Germany, if not Europe. It’s going to upset a large number of climate Scrooges and the profiteers of doom.
The book Die kalte Sonne, Warum die Klimakatastophe nicht stattfindet (The Cold Sun, Why The Climate Catastrophe Is Not Taking Place) seriously challenges global warming alarmism. The book is written by Prof. Dr. Fritz Vahrenholt and Dr. Sebastian Lüning. Deliveries start at Amazon.de February 22, 2012. But I’m told the date may actually be February 8!
The publisher is influential publishing house Hoffmann & Campe in Hamburg.
What compelled the authors to write the book?
In short, being trained scientists, they noticed stark contradictions between model projections and real-life observations. Nothing matched up, something was wrong with the science, the models, and the IPCC. They explain it in detail in the book and in layman’s terms. The German Amazon description writes:
The IPCC is sure: The climate warming is because of man. However, are the infamous climate gases really the primary driver of our climate? And why hasn’t it been getting warmer? Vahrenholt and Lüning have taken a close look at the various climate models during their research. They reach the conclusion that a part of the Earth’s warming of the last 150 years is because of a natural cycle that is predominantly controlled by the sun. The next decades are more likely to lead us to a slight cooling instead of a warming. This provides the time to rationally develop and expand renewable energy sources, and to carry out the energy transformation in an economically,
sensible and sustainable way.”
The book is up-to-date, and its content is well-researched – over 800 footnotes. Many of the cited sources are the most recent peer-reviewed scientific papers and findings. Also many of the well-known climate blogs and sites are cited as well. Some blogs are prominently featured, like Climate Audit, WUWT, and Real Climate. I had the privilege of reading the manuscript, so I’m familiar with the book’s content. I really wish I could spill more about it. The book concludes, paraphrasing:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




 The IPCC is in error, the models are bogus, and the climate catastrophe is not coming. The climate debate has to be started anew.”
Die Kalte Sonne also features guest contributions by leading international scientists.
I think this book is surely going to change the minds of a lot of readers here in Germany, and hopefully lead to a new and rational discussion, which is so badly needed here. The authors make a powerfully convincing case that the science behind global warming alarmism is extremely shaky and dubious, and that the current, panicked energy transformation stampede cannot continue on its current path without something very painful happening.
The book also underscores that a transition to renewable energy source is essential and that we need to do it. But it has to be done rationally and in a sensible step-by-step approach. Only in this way will it be possible to make an energy transition that assures the needs of 9 billion people on our home planet are humanely met.
Why not order here and give a voucher for Christmas!
About the authors
Fritz Vahrenholt
Prof. Dr. Fritz Vahrenholt is a professor of chemistry at the University of Hamburg. He has been active in politics and renewable energy for 30 years. From 2001 to 2007 he was Chairman of the Board of wind turbine manufacturer REpower Systems, Since 2008 he has been the CEO of RWE Innogy, the renewable energies arm of German energy giant RWE. Vahrenholt was also a member of the council for Sustainable Development under Chancellors Gerhard Schroder and Angela Merkel.
Sebastian Lüning
Dr. Sebastian Lüning has a doctorate in geology and paleontology. He has been involved in the reconstructions of natural environmental changes for 20 years. He was a guest professor at the University of Vienna, and has received a number of awards for his studies and research. He is currently a geological expert for Africa for RWE Dea.
Share this...FacebookTwitter "
"
I swear, I had nothing to do with this. Speaking tonight in Canberra, details here. Weather records for Sydney here.
From the “weather is not climate department”:
Sydney recorded its coldest June morning today since 1949, with   temperatures diving to 4.3 degrees just before 6:00am (AEST).
Cold snap set to stay By Amy Simmons

 


  
Experts say it is unusual to  see such widespread cold weather in June. (User submitted photo: Rick Box)

//

People across south-east Australia are complaining  about unusually chilly temperatures and experts say there will be no  relief from the cold until Sunday at the earliest.
From Brisbane this morning, Miss7t7 wrote on Twitter “Still in bed,  so dam cold.. What’s going on Brisbane !!!!”. While in Melbourne,  lexandraKR tweeted “Waiting for frostbite to set in… Sooo cold in  Melbourne! Too scared to get out of bed incase I get hypothermia”.
Others are embracing the weather and urging those who are complaining  to toughen up.
“I am in love with this cold weather. Melbourne reminds me of Paris  at the moment. How can that be a bad thing?” wrote hannahjtoy. “Is it  seriuosly newsworthy that sydney temps are in the low single digits?  seriuosly? it not cold! suck it up!” FilthiAssistant tweeted.
But ABC weather specialist Graham Creed says people’s complaints are  justified.
“It’s definitely quite unusual to see such widespread cold weather in  June, it would be more typical in July and August,” he said.
“So people are complaining about the cold for a good reason.”
Mr Creed says most areas across the south-east are experiencing  temperatures well below average.
“Last weekend a cool change moved through and that introduced some  significantly colder air across most of south-east Australia,” he said.
“Quickly in behind that we had a high pressure ridge move through,  producing clear skies during both the day and the night, but it’s also  helping to trap that cold air in.
“The clear skies mean we are losing what little daytime heating there  is and overnight temperatures are dropping into the minuses through  many of those states, producing widespread frosts.
“On top of that we’ve got quite a breeze in certain areas and the air  is very dry so that’s producing very low wind chill, so not only is the  sun not providing much warmth, you’ve also got the assistance of the  wind making it feel colder than it actually is.”
He says Queensland is in for a particularly rough few days, as  widespread rainfall will see the conditions change from cold and sunny  to cold, cloudy and wet.
Yesterday, an icy blast through Adelaide brought enough rain to  supply the city for a month, with a hail storm capping off the  exceptionally wintry day.
Yesterday was also the coldest day in Melbourne in nearly two years,  with the city not reaching its maximum temperature of 10.8 degrees  Celsius until 7:55pm (AEST).
If the temperature in Melbourne fails to hit its forecast maximum  today, it will be the first time in 14 years the city has recorded three  consecutive days of temperatures below 12 degrees.
Last night Brisbane was coldest at 9:00pm (AEST), when the mercury  dropped to below 8 degrees, but experts say it will be even cooler  tonight.
Sydney recorded its coldest June morning today since 1949, with  temperatures diving to 4.3 degrees just before 6:00am (AEST).
more at ABC Radio


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a8ad639',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Is it possible for humans to fulfil their needs without also destroying the environment? It’s a question we need to find an answer to soon, as the world’s poorer regions demand the same perks that come with development. On one hand, people need to consume some of a region’s resources so that those living there can drink clean water, grow nutritious food and get access to health services and education. But such consumption comes with unavoidable impacts. If these impacts increase beyond a region’s ability to continue to provide services such as water, pollination, soil stabilisation and climate regulation then the process of development can actually hinder rather than improve people’s welfare and well-being.  Striking the right balance is tricky and requires a new way of defining places that are both environmentally safe and socially just. Over the past two years, working with an international group of scientists, we have developed such a definition of safe and just operating spaces. In doing so we have tackled the tension that often exists in low-income regions between raising standards of living and keeping environmental impacts within bounds that allow the environment to supply vital services. The findings of our research have been published this month in the journal Global Environmental Change.   Such a formula must factor in everything humans need for themselves and all of their impact on the environment. While environmental impacts and human needs can be loosely grouped together, they don’t necessarily exert pressure in the same direction – think of how demand for more jobs differs from better health, for instance. This calls for a more rounded idea of a safe and just space, where human needs exert an outward pressure and environmental boundaries constrain humanity.  Think of it as a doughnut: If we wish to help people out of poverty then we must remain within the doughnut – the safe and just space – where people are above a social foundation in which they have what they need, but are not exceeding environmental ceilings by stressing nature beyond breaking point.  In order for our approach to have practical use, we needed to show how to define both social foundations and environmental ceilings for a particular region.  For defining social foundations, we built on the work of the economist Kate Raworth who synthesised nationally and internationally agreed minimum living standards. Meeting these minimums means moving into the “doughnut zone”. But this zone is of course constrained by impact on nature and we propose four different types of environmental ceiling – cross any of the points below and you’ve escaped the doughnut and are into unsustainable territory. The red line is a limit that is deemed unacceptable to go beyond. A good example is air pollution. The Beijing skyline disappearing behind thick clouds of smog is producing iconic images of the environmental impacts of development in China. What is deemed an acceptable level of air pollution varies from country to country. The runaway can be explained with a cycling metaphor. Zooming downhill on a bike can be a thrilling experience. Unfortunately, fun can quickly turn to terror if you realise that your brakes are not slowing you down and in fact you are going faster and faster. Continual over-fishing of certain species on coral reefs can produce a series of rapidly unfolding disruptions to the entire system that quickly get out of hand and lead to the collapse of the reef.  The tipping point is how close to a critical transition a system may be. A good example here is the sudden change in water quality in a lake that within weeks can go from a seemingly healthy system with clear water and teeming with fish, to green and clogged with suffocating algae. Moving the system back to the clear-water state can be as challenging as putting Humpty Dumpty back together again.  The early warning signal can be best explained with another cycling metaphor. Your brakes may be able to handle very steep slopes but you may be unfortunate to experience a speed wobble where the front wheel begins to oscillate. These wobbles can feed back on themselves until the entire bike starts shaking from side to side. In such situations you slow down either gradually by applying the brakes or much more suddenly by getting thrown off the bike and sliding across the road. But there is hope that for some systems we may be able to detect these oscillations in time to be able to reduce our impacts. Consequently, detecting early warning signals themselves can be considered as a threshold that we should be wary of.  Two of our co-authors Rong Wang and Ke Zhang analysed environmental and socio-economic data to help define the social foundations and environmental ceilings for two case-study regions in China: Shucheng County and Erhai Lake. In both regions, intense agricultural development since 1960 has reduced poverty, but at significant environmental cost. The regional doughnut for Shucheng County shows that water quality, air quality and sediment quality have breached the environmental ceiling while access to clean water, sanitation and education is well below the social foundation.  Identifying such environmental ceilings is of little use if we simply power on past them. We hope that our integrated approach will lead to sustainable strategies that are based on a better understanding of the ecosystems that we all ultimately depend upon.  We may not be able to completely avoid all environmental impacts associated with poverty alleviation – we cannot have our cake and eat it – but we can try to ensure as many people as possible enjoy living within the doughnut."
"
Share this...FacebookTwitterIf your “Globe” Is Only 10 Meters From Your Door – It’s Warming!
By guest writer Ed Caryl
In A Recent Temperature History – Part 1, 22 stations in the midwest U. S. were examined. On an average, these stations were cooling slightly over one AMO cycle, from 1934 to 2000, but there was much variability. The greatest cooling was –0.76°C, and the greatest warming was 0.59°C. As these sites are all within a few hundred kilometers of each other, why the large variation? Was it population density? Or is it something else?
The towns in this group are all small, according to GISS under 10,000 population. The actual population was found to be from about 500 to just less than 7000, with one outlier at 24,900. The station distance from the center of that city is more than 7 kilometers, so GISS can be forgiven for that classification.
But perhaps it isn’t the surrounding population that counts, but simply the closest heated dwelling. To test that hypothesis, this author researched each station at the SurfaceStations.org website, and found the distance from each measurement sensor (MMS) to the nearest heated building. For some it was necessary to go to Google maps using the latitude and longitude along with other clues, to find the information. For others it was necessary to estimate the distance from photographs. This information was then plotted in Figure 1.

Figure 1. This is a plot of the temperature trends for 22 mid-western U. S. stations versus town population (black) , and distance from the measuring instrument to the nearest heated building (pink and red), usually a residence.
As can be seen on the plot, town population made almost no difference to the trend. The dots are nearly completely random with respect to population. On the other hand, the distance from a heated dwelling made a much larger difference. The two coolest sites were more than 100 meters from the nearest building. Within the population limits of this study, the Urban Warming Influence is simply the distance to the nearest heated building, not the size of the city.
This phenomenon is the reason for much of the Arctic warming. Urban Warming in the Arctic, and indeed in the Antarctic, is an occupied-building-to-temperature-sensor distance problem. In the polar regions, the temperature differential between occupied buildings and the outdoor temperature sensors is much greater than in the temperate mid-west U. S., so the distance must be greater to avoid the UWI problem. But man doesn’t like digging long cable trenches in ice or permafrost (it’s like concrete!), or walking long distances in –40° weather, so the measurements are not done properly.
It is clear to this author that measured “Global Warming” is simply due to increasing nearby energy use and the temperature sensor proximity to the resulting heat. Of course if we all reduce our “carbon footprint”, this reduced energy use will surely slow “Global Warming”; but it will not be because CO2 emission is reduced, and it will result in all of us freezing.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterWarmist Spiegel journalist Axel Bojanowski presents today a story on Peter Gleick’s Fakegate scandal and on what it means. In a nutshell: climate science is far from settled and there is a bitter war waging between the skeptics and alarmists. Consensus does not exist!
Climate scientist pilfers secret documents from a lobbyist group“
Spiegel writes at the top of its report in bold print that the documents, which were intended to discredit the Heartland Institute:
…ended up disgracing the person revealing them.” Renowned climate scientist Peter Gleick using a fake name, succeeded in obtaining documents from a lobby group. He led a group on scientific ethics.”
Here Spiegel’s juxtaposition of Gleick’s seedy behaviour and his leadership of a group on ethics could not be more profound. Spiegel mentions that the bitter conflict between the skeptics and alarmists has been raging for 20 years (there never ever was a consensus).
Slowly one gets the feeling that the influential Spiegel is getting tired of the warmists obvious shenanigans and deception, and are not letting it go unnoticed, as much of the media are doing.
Even Spiegel seems to be going skeptic (at times). Get a load of this statement in the article (emphasis added):



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The UN climate report, which is summarized every few years with the involvement of hundreds of scientists, comes to worrisome conclusions. However, the environment comprising air and earth is so complex that there are still huge gaps of knowledge – and they provide the fuel for fierce debate.”
So much for settled science. Bojanowski, a journalist who has written some of the warmist of articles in the past, doesn’t seem to believe in settled science anymore.
Spiegel explains how Gleick obtained the documents and how they were published by Desmogblog, and informs readers that “a simple apology will not suffice” and that Heartland is “demanding a complete clarification” from Gleick and that “legal consequences will follow”and that the integrity of many members and the reputation of the institute were damaged.
Spiegel goes into Gleick’s “downfall” – from being a leader of an ethics workgroup for the renowned American Geophysical Union (AGU) – to now reaping the outrage from Mark Fennel of the AAAS, and how Kevin Knobloch of the Union of Concerned Scientists has distanced himself from Gleick.
As the war between skeptics and alarmists intensifies in bitterness, Spiegel concludes with the following observation:
The recent affair fully confirms that the complexity of the climate topic is presenting challenges that are simply too much for the public debate to handle. Even intelligent scientists like Peter Gleick can lose their rationality.”
Indeed the science is complex and far from being settled. But we should remind Spiegel why intelligent scientists lose their rationality in the first place. It has something to do with the quality of their arguments and their failure to convince.
Share this...FacebookTwitter "
"**Six members of Pakistan's cricket team have tested positive for Covid-19 while on tour in New Zealand.**
All six have been moved from managed isolation into quarantine and the team's exemption from social-distancing rules for training has been suspended.
Health officials said all 53 members of the visiting squad were tested on arrival in the country.
New Zealand, widely praised for its pandemic response, had previously seen a total of 2,040 cases and 25 deaths.
It implemented a stringent but brief lockdown at the start of the crisis, along with targeted testing and successful surveillance. The country reported its most recent case of transmission within its borders on 18 November.
Pakistan meanwhile has seen 356,198 confirmed cases and 7,843 deaths.
New Zealand's cricket authorities said two of the six cases were ""historical"" and the other four were new. Historical can refer to a positive test returned some time after a person has recovered.
Some members of the Pakistan team had contravened protocols on their first day in managed isolation in Christchurch and would be reminded of their responsibilities, New Zealand Cricket (NZC) said.
A health ministry spokeswoman told Stuff.co.nz that several members of the Pakistan team had been seen on CCTV breaking the rules and the team was now on its ""final warning"". The rules had been broken despite ""clear, consistent and detailed communication of expected behaviour"", the spokeswoman was quoted as saying.
All members of the Pakistan squad had earlier tested negative four times before leaving the Pakistani city of Lahore.
The outcome was ""disappointing for the Pakistan squad"" but the ""testing outcomes and the actions taken show the government system is working"", NZC said.
Earlier this month the West Indies cricket squad - who are also in New Zealand - were also briefly banned from training and confined to their hotel rooms after CCTV showed them sharing meals and mingling together in breach of managed isolation guidelines.
The Pakistan team is scheduled to play two Test matches and three T20 matches while in New Zealand."
"
Share this...FacebookTwitterThe Church of Global Warming is shattering in Germany, one of the last bastions of the movement. Even the environmental bishops are leaving the Church.The print edition of FOCUS magazine has an article today on a new upcoming skeptic climate book, Die kalte Sonne, authored by former warmist Prof. Dr. Fritz Vahrenholt and geologist/paleontologist Dr. Sebastian Lüning.
Even though the book will not be available until February 6th, it has climbed to no. 4 on the Amazon-Germany bestseller list  under the category of environment and ecology.
(Thanks Die Zeit!)
That number will of course rise soon now that national weekly FOCUS has a write-up in today’s issue, and once it’s officially launched on February 6.
Only 31% of Germans are afraid of global warming
One very interesting statistic in today’s FOCUS article that even surprised me:
Only 31% of Germans are afraid of a global warming. In 2006 that number was double.”
Indeed skepticism has reached a point where now even leading environmentalists are abandoning the movement, as profoundly demonstrated by Vahrenholt’s and Lüning’s book. Many simply feel they have had the wool pulled over their eyes. Although there have been skeptic books in Germany, none had the impact that the soon-to-be-released Die kalte Sonne is expected to deliver. With the book ready to take off in Germany, preparations have already been taken for a possible launch of an international edition in English.
The book cites more than 800 sources, many are peer-reviewed papers that appeared after the IPCC 2007 report. It’s the latest summary of the state of climate science out there. It does not dispute CO2 as a driver. The book simply cuts it down to size, and backs it up with hard literature and data.
No more trust in the IPCC
Undeniably there’s a feeling that the stars are now aligned, the mood has swung, and key players are changing their minds. As FOCUS reports, even the most die-hard of warmists are converting, or at least softening their tones. Prof. Fritz Vahrenholt, a renewable energy expert, was once one of the fathers of the modern green movement in Germany and believed everything the IPCC preached – until 2 years ago. FOCUS writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Fritz Vahrenholt, one of the fathers of the green movement, no longer trusts the forecasts of the IPCC.”
and FOCUS tells us why, quoting Vahrenholt:
Doubt came two years ago when he was an expert reviewer of an IPCC report on renewable energy. ‘I discovered numerous errors and asked myself if the other IPCC reports on climate were similarly sloppy.”
In his book he explains how he dug into the IPCC climate report and was horrified by what he had found. Then add the 10 years of stagnant temperatures, failed predictions, Climategate e-mails, and discussions he had with dozens of other skeptical elite scientists. That was more than enough. FOCUS quotes:
I couldn’t take it any more. I had to write this book.”
Latif, Schellnhuber and Edenhofer softening?
In December we wrote about Mojib Latif backpedalling away from alarmism here, greatly scaling back from his earlier alarmist scenarios.
FOCUS also reports that even Climate Pope Hans Schellnhuber appears to be softening his tone. Recently at a speech he made at a seminar before agricultural experts, he admitted that “warmer temperatures and high CO2 concentrations in the air could very well lead to higher agricultural yields”. Is Schellnhuber preparing a back exit?
And FOCUS adds that even Ottmar Edenhofer might be softening his climate hard line. A few days after Schellnhuber’s admission, Vahrenholt and Edenhofer were both at a press conference in Munich, where Vahrenholt claimed that temperatures had not risen in a decade and that they would likely cool a bit in the future. FOCUS tells us Edenhofer’s reaction:
Edenhofer did not wish to contradict, even when requested.”
 
Share this...FacebookTwitter "
"Each of the 125 leaders attending the New York climate summit this week has been given four minutes to speak to the world. They (or their aides) may well have dipped into the climate literature to add scientific ballast to their speeches. But they may not be as familiar with the vast array of academic studies on effective communication about climate change. They should be. If world leaders and climate advocates really want to improve the chances of mobilising political will and citizen action behind a new deal, they will need to think carefully about what sort of key messages actually work. Clearly there is a balance to strike between doom-ridden messages and “bright-side” opportunities, and uncertainties around the science and the expected effects of climate change must be factored in too. Can risk language help? Part of their challenge is that the world’s media need – and use – overarching narratives to describe the climate change “mega-story”.  Alarming stories of more famine, sea level rises, floods, hurricanes and droughts are easy ones to grab attention. This “disaster” story is by far the most common one in the coverage of climate change, as shown by several studies. At times, this “alarming” story morphs into the more “alarmist” language of catastrophe, calamity or doom. A new study I carried out for the Reuters Institute for the Study of Journalism shows that in the television reporting of the three recent blockbuster reports by the Intergovernmental Panel on Climate Change (IPCC), the disaster narrative was still by far the most common in the six countries it examined. The study examined the coverage on television, which is still in most countries the most used and trusted source of information for news in general, and for news about science. For instance, just one evening news bulletin often enjoys far more audience that the circulation of a national newspaper. The channels monitored in the study have a combined audience of about 50m viewers. It is not surprising that disaster should be more common than the other “frames” or narratives the study surveyed (uncertainty, opportunity and explicit risk). The IPCC reports were full of the adverse impacts from runaway greenhouse gas emissions, which make for compelling news. But it is surprising that the risk narrative hardly got a look in. In the press release and communication efforts around the second report released early this year, the IPCC went to considerable lengths to portray the climate change challenge as one of “risk management”. The co-chair of the working group responsible for the report, climate scientist Chris Field, spoke repeatedly and eloquently about the need, in the face of uncertainty, to weigh up the risks of possible outcomes. Part of the explanation is that television news needs pictures to tell stories and is better at telling stories than dealing with issues. The disaster frame lends itself to a strong narrative, whereas risk is more of an issue than a story. Why is this important?  Doom-laden depictions of climate change are ubiquitous in the media. But results from focus groups show that such disaster narratives are good at attracting attention, but not so good at motivating genuine personal engagement or behaviour change. Some scientists are really tackling this problem head on. An inquiry this year on communicating climate science led by Professor Chris Rapley at the UCL spelled it out: strong appeals to fear are unlikely to avert danger and can generate defensive avoidance (“this is too scary to think about”) or worries of being pressured or constricted (“they are trying to manipulate me”). As the report says, initial states of worry and anxiety can change over time to numbness, desensitisation and disengagement from the issue altogether. But nor should one jump into overdoing positive narratives about climate change as the antidote to all the disaster narratives.  A balance needs to be struck. Last week’s New Climate Economy report was a good example of giving a sober assessment of the challenges (rapid urbanisation, growing populations, resource constraints, climate change), accompanied by a positive story that cutting greenhouse emissions can be low cost and improve people’s lives. Many politicians and climate reports now talk about risk, which works for some audiences – particularly in the business sector – who deal every day with assessing investment, insurance and other types of uncertain outcomes. They were clearly the target audience for a groundbreaking report out in June this year called Risky Business, which used a risk management perspective to lay out the threat to agriculture, energy and coastal real estate in the US. One of the authors was the former Republican treasury secretary Hank Paulson. As he explained: “taking a cautiously conservative stance – that is, waiting for more information before acting – is actually taking a very radical risk”. As the Columbia Journalism Review noted, the report helped to shift the nature of the climate change story in the media. It became a business story on the business pages, reaching a new and powerful audience. Now that’s a story."
"The Great British Bake Off has been attracting its highest-ever ratings after a return to our screens. While many different explanations have been offered for the show’s success, the current popularity of baking – along with other domestic crafts such as growing vegetables, sewing, knitting and mending – seems to be one important factor.  It is often said that viewers of Bake Off are simply content to watch cake being baked, rather than doing it themselves, but the show’s reported impact on the sale of baking equipment and ingredients tells another story. The context for this revival of interest in baking and sewing is, of course, austerity. In the wake of the financial crisis, we have tightened our belts, donned our aprons, and taken on board the historical lessons of “austerity Britain” – that period during and after World War II when rationing was imposed and British citizens learned how to “dig for victory”, “make do and mend” and “win the war on the kitchen front”. More than five years after prime minister David Cameron warned that a Conservative government would bring about a new “age of austerity”, popular media culture continues to be saturated with reference to this period. We can’t get enough of the stories of thriftiness, resourcefulness, and resilience. Many commentators have been highly disparaging of this backward-looking popular austerity culture, arguing that it provides ideological backup for the coalition government’s austerity measures. Some have argued that “austerity nostalgia” is nothing but an opportunity to moralise about the virtues of “making do” – a morality that reinforces class distinction and difference, because of its particular appeal to the middle classes.   These critics make an important point. Viewed in the context of the revival of austerity Britain, the popularity of shows like Bake Off do seem to provide evidence of a general acquiescence to the strictures of economic austerity, and of our consent to a scaling-back of our expectations and prospects.  In romanticising wartime resilience in the face of crisis, austerity culture is arguably guilty of exploiting the “very real hardships” currently experienced by many in the UK. Yet this analysis of Bake Off and austerity nostalgia obscures an alternative and highly significant interpretation. Long before the financial crisis, environmental campaigners put a great deal of work into reinventing the concepts of “austerity” and “thrift” for green purposes. And the historical period of austerity Britain became an absolutely critical resource for this campaigning activity.  As far back as 2001, the writer Andrew Simms – then policy director at the think-tank the New Economics Foundation – was arguing that Britain’s experience in wartime is highly relevant to the challenge of climate change. This intervention inspired many others, from the Green Party’s New Home Front project to the turn to “dig for victory” in the allotment movement. Gardening, sewing, knitting and mending are central to this eco-austerity movement because they are seen as part of the “great re-skilling” necessary for transition to a post-growth economy. The revival of popular slogans from that era has given new meaning and value to these activities. You aren’t just baking a cake or knitting a jumper; you’re doing your bit. The resurgence of interest in these practices – evidenced by the widely-reported phenomenon of waiting lists for allotments – is part of a growing attentiveness to material scarcity and environmental responsibility. On Simms’s account, shows such as Bake Off, The Great British Sewing Bee, and The Big Allotment Challenge are indicative of Britain’s appetite for re-learning these skills and for a vision of a more sustainable future. But hang on: how does cake-baking sit within environmental politics? Given that the show appears to boost sales of non-essential commodities such as piping bags and mixing bowls, what kind of green credentials can be claimed for Bake Off and its audience?  Here, critics who argue that austerity culture is no longer about any environmentalism seem to gain ground. Indeed, some have claimed that the nebulous eco-austerity credentials of domestic crafts have actually served to reinforce the morality of “war-style cuts in people’s choices and living standards” and to shame those who aren’t seen to be living adequately “austere” lives. I don’t think we have to choose one or other interpretation of Bake Off and austerity culture. Because so many different actors have made use of the iconography of austerity Britain, it’s very hard to discern the political implications of a particular show.  Bake Off offers both an exemplary lesson in ideological compliance and an endorsement of “re-skilling” for a transition towards a sustainable economy. It’s an extremely contradictory vision of the future. On the one hand, austerity for transition envisions a de-growth or post-growth economy, while on the other, austerity as implemented by the government is notionally aimed at cutting the deficit and boosting growth. And even as the UK does return to economic growth, the echo of eco-austerity should still remind us that the challenges of global warming and climate change have not gone away. Austerity culture may yet provide us with important critical resources to imagine and to develop just and sustainable economic and environmental futures."
"The UN Climate Summit in New York brought together politics, business and civil society to build up momentum for major climate change talks in Paris next year. After the disappointments of the acrimonious Copenhagen meeting in 2009, there is now a chance for a global agreement on action against climate change. Low carbon development pledges and substantial financing of the Green Climate Fund are one side of the coin. But climate justice is also about social justice, and leaders must address the demands and respect the needs of people most vulnerable and already suffering from the impacts of climate change. The world’s poorest people are the worst affected by climate change and these groups were certainly represented in New York, but will they be listened to? If it is to have a lasting impact, the Paris meeting must successfully integrate a “top-down” global agreement to restrict global warming to 2°C, together with a “bottom-up” strategy whereby countries set their own contributions to reduced emissions. However this latter strategy must go beyond emissions and do more to ensure that action on climate change listens to the grassroots and prioritises the world’s poorest and most vulnerable groups. The summit looked promising for proponents of an inclusive, “bottom-up” strategy. Its key themes included forests, agriculture and resilience to climate change, all of which have a sizable body of evidence to show that placing people directly affected at centre stage is a critical opportunity for success. There was also a thematic session on Voices from the Climate Front Lines which gave a platform to children, women and indigenous people suffering the effects of climate change. However the outcomes don’t match the hype. There were specific examples of progress: the president of Peru outlined a strategy for reducing emissions from deforestation and degradation that he said would put the country on a path to sustainability by reaching out to indigenous groups and securing a vast area of land under indigenous rights.  He won public support from both Germany and Norway, and France also pledged funds to help the poor cope with climate change, but the global commitment to social justice called for by the Rights and Resources Initiative and the World Resources Institute was largely missing.   The anticipated, voluntary New York declaration on forests was marred by Brazil’s refusal to sign up, and the seven action statements released following the summit directly address local people’s rights and roles just twice (and one of these requires action from indigenous civil society groups rather than national or international governments). Similarly, the Global Agricultural Alliance aims to secure “climate smart” agriculture for 500m farmers by 2030. However it was left to civil society organisations to release a joint statement prioritising making food systems socially just and protecting the poorest and most vulnerable in these efforts. The recently published New Climate Economy report outlines a vision for “better growth, better climate”, a win-win scenario that ties investment and innovation to poverty and hunger reduction. But while investment and innovation may be able to secure the 70% more calories they estimate humans will collectively require by 2050, it is unclear how it will address the political aspects of access to those calories, and whether such strategies can support the livelihoods and resilience of the poorest farmers. Without putting social justice at the core of our thinking on climate action, we risk harming the most vulnerable groups of people. For example environmental concerns have been used by big corporations and national governments to justify claiming land for themselves, a process known as green grabbing that threatens the well-being of groups dependent on natural resources. Perhaps we can eventually find a way to put people on an equal footing with the green economy but, judging from developments in New York, we don’t seem to be there yet. Paris must be about much more than the pledges on emissions and the green economy that have dominated the headlines since the UN summit. It appears New York was yet another example of a big international climate forum recognising the importance of social justice (itself a big achievement) without actually clarifying how it will be built into objectives or commitments. People will remain on the agenda, but not quite centre stage."
"

The rise of anti–Americanism in Europe is a danger to both American and European pocketbooks, and our collective liberty. Here is why: Europe and America are each other’s biggest trading and investment partners, and anything that damages that relationship is harmful to everyone involved.



This past year more than one trillion dollars flowed between the U.S. and the EU. The EU now accounts for 21 percent of U.S. merchandise exports and 19 percent of U.S. merchandise imports, and about 34 percent of U.S. services exports and 37 percent of U.S. services imports.



The U.S. is not only the largest recipient of foreign direct investment, but far and away the world’s largest investor elsewhere. Of the more than two trillion dollars the U.S. has invested directly abroad, a little more than half ($1.1 trillion) is invested in Europe. Europeans account for 70 percent ($1.2 trillion) of the direct investment in the U.S.



The bottom line is that the U.S. and Europe are economically joined at the hip, and any actions which damage trade and investment between these two economic giants hurt everyone. The U.S. and EU have a combined population of about 650 million people, and their combined GDP equals 57 percent of the world’s total.



The U.S. has also provided a security umbrella over Europe for almost 65 years. Europe has adopted much of American culture — from movies and music to fast food and dress, and increasingly the English language (the American version). Even France has about a thousand McDonald’s restaurants. Given the growing economic and cultural ties, why the rise in anti–Americanism (despite the hopeful signs coming from Sarkozy’s election)?



Some Europeans will argue that it is only anti–Bush–ism — in that they dislike the Bush foreign policy and his personal style. And it is generally true that Europeans dislike Bush more than they dislike Americans. But there is more to it. Europe by and large was pro–American when Europe was growing faster than the U.S., and the U.S. was protecting them from the Soviet menace. But over the last two decades, the major European economies have grown more slowly than the U.S., and the Soviet threat has disappeared.



The increasingly globalized world where the U.S. appears to be more aggressive and economically competitive causes fear and resentment. The U.S. success and dominance highlights the weaknesses of the European welfare state. Only the U.S. morass in Iraq and the relatively low level of the dollar (which most likely will soon be reversed) has given the Europeans reasons to smile.



If the anti–Americanism were confined to verbal belly aching, it would not be much of a problem. However, it is now leading to destructive policies. The Europeans have been more reluctant to further liberalize global trade than the Americans and, in fact, destructive protectionist forces on both sides of the Atlantic are gathering strength.



Some of the European nations have been concerned about capital out–flows (brought on by their own excessive taxation and regulation), and demanded that other countries help them enforce their tax laws (e.g., the EU Tax Saving Directive). Recently, some of the new Democratic leaders in the U.S. Congress have proposed equally destructive proposals to prevent U.S. monies from flowing into lower tax jurisdictions — some of which are in Europe (e.g., Senators Dorgan’s and Levin’s bills to penalize certain capital outflows).



When members of Congress and others whine about U.S. companies moving abroad, they have no one to blame but themselves, because they have made it uncompetitive for some companies to come to or stay in the U.S. The U.S. used to have one of the lowest corporate tax rates in the world but now it is at the top of the list. The EU has an average maximum corporate income tax rate of 25 percent (with some EU members as low as 10 percent) versus 40 percent in the U.S. Even France and Germany now have lower corporate tax rates than the U.S. The Europeans correctly rely more on consumption taxes (the VAT), which are rebated on exports. There is no rebate for corporate income taxes, putting U.S. firms at a disadvantage.



The EU has brought anti–trust actions against some U.S. multinationals, not because these companies’ activities hurt EU consumers, but because they hurt their EU competitors. The EU has also challenged the protection of intellectual property held by some U.S. companies. The EU has attacked the U.S. for not doing enough about climate change, even though EU members have not met the goals of agreements they signed, such as the Kyoto Protocol.



Economic warfare between the EU and U.S. can be averted if officials on both sides will act more responsibly. Many tax disputes would disappear if the U.S. would move to a territorial tax system (like most European nations have) and to a consumption–based tax system, such as a national sales tax, rather than an income tax — which would have the significant side benefit of increasing economic growth in the U.S. The EU needs to move more aggressively towards trade liberalization and deregulation — which would greatly increase economic growth in the EU. The solution to much, but not all, of the tension between the EU and U.S. is to create more economic opportunity on both sides of the Atlantic — but particularly in Europe.
"
"Despite the significant benefits they have and will continue to provide, the traditional approaches of protected areas and in situ conservation management alone cannot shield vulnerable species from the growing threats they face. Habitat loss and fragmentation, over-exploitation, invasive species, pollution and climate change are all problems that have grown as the world’s human population increases and expands.  This is why we have to consider more risky and intensive conservation options such as translocations: the intentional movement and release of endangered creatures for conservation benefit. There is a spectrum of conservation translocations. Reinforcing existing threatened populations by “topping up” with individuals taken from other areas where they thrive increases numbers and genetic diversity, which improves their ability to withstand change and disease. Reintroductions are attempts to restore populations after they have gone locally extinct.  More risky and uncertain is the controversial technique of conservation introductions. The two techniques are assisted colonisation, in which species are moved from their native range where they are threatened to somewhere they have never naturally inhabited in order to preserve them, and ecological replacements, where a suitable substitute species is introduced to perform the ecological role of one that has become extinct. Understandably, given the history of terrible consequences from ill-planned species introductions – perhaps most obvious in Australasia – these are seen as extreme methods and not actions to be undertaken lightly. The key challenge is therefore to understand and manage the risks involved. It’s also necessary to have an exit strategy – to be sure you can reverse the releases if things do not go as planned. For threatened species at low-population densities released into confined areas of habitat this would be feasible. There are already great gains being made using conservation translocations of all kinds. Reintroductions are restoring whole suites of species – mostly mammals and birds, but increasingly plants, reptiles, amphibians, fish and invertebrates are being released into suitable areas. For example some 55 species of birds have been translocated in more than 1,000 projects, and populations of reptiles and amphibians are now also being restored in New Zealand. Assisted colonisation is also used in Australia and New Zealand, where native species have been moved beyond their normal range in order to protect them from the threats posed by exotic mammals. And on islands in the Indian Ocean giant tortoises have been introduced as ecological replacements for extinct species, to restore the seed dispersal and vegetation grazing functions that had been lost. Early conservation translocations have had low success rates, but as techniques are developed and refined, results are getting better and we are seeing an exponential increase in the number of translocation projects worldwide. There is however still a bias towards the more charismatic species of birds and mammals, but this is slowly changing. But there is a major challenge facing conservation translocations. If we are seeking to restore wildlife populations we must ask the question: restore to what? What is the target state, the ideal we are seeking? In the New World, perhaps in the past the answer would have been to restore the environmental balance to how things were before (European) human settlement. But there is a growing awareness that pre-European landscapes were not the pristine wilderness of our imagination. It is unrealistic to seek such ideals in the anthropocene, our modern human-dominated world. We need to move away from the idea of having free-ranging wild species roaming over large areas of wilderness untouched by human influences. We must understand now that virtually every ecosystem on earth has been modified by humans, and some of those modifications go back to prehistory. An obvious example is the extinction of megafauna species or massive deforestation across Europe after the first arrival of humans in the Pleistocene period, many tens of thousands of years ago. We need instead to think about how we can restore “wildness” rather than the unobtainable “wilderness”. By that I mean finding a place for wildlife to persist in areas alongside humans, both for their sake and ours. Too quickly we can lose a sense of how much we have lost, with each generation handed a natural world to grow up in that is progressively more impoverished than the last. Species restorations give people a chance to experience, appreciate and learn to cherish their natural heritage."
"
Guest Post by Willis Eschenbach
In the US House of Representatives, there is something curiously yclept the “Select Committee on Energy Independence and Global Warming” despite the lack of connection between the energy independence and warming. They have a very professionally done website, filled with some of the most outrageous misrepresentations imaginable. It is designed to promote the “Waxman-Markey” cap and trade carbon tax bill by means of the historically tried and tested “Big Lie” method, viz:
All this was inspired by the principle–which is quite true within itself–that in the big lie there is always a certain force of credibility; because the broad masses of a nation are always more easily corrupted in the deeper strata of their emotional nature than consciously or voluntarily; and thus in the primitive simplicity of their minds they more readily fall victims to the big lie than the small lie, since they themselves often tell small lies in little matters but would be ashamed to resort to large-scale falsehoods.
It would never come into their heads to fabricate colossal untruths, and they would not believe that others could have the impudence to distort the truth so infamously. Even though the facts which prove this to be so may be brought clearly to their minds, they will still doubt and waver and will continue to think that there may be some other explanation. For the grossly impudent lie always leaves traces behind it, even after it has been nailed down, a fact which is known to all expert liars in this world and to all who conspire together in the art of lying.
I’m going to take the website’s misrepresentations one at a time, as time permits. The first one is from a page entitled “Impact Zone – U.S. New England“, which contains this lovely photograph designed to tug at the heartstrings:

Figure 1. Photo of maple trees in New England, professionally chosen for maximum emotional impact.
The accompanying text says (emphasis mine):

Global Warming in New England: Slushier Slopes and Faded Foliage
Life and economic activity across New England is marked by the seasons – maple sugaring in the spring, trips to the beach in the summer, the riot of color of the fall foliage, and the swoosh of skis and skates in the winter. This familiar cycle is already changing in noticeable ways.
Changing seasons
Since the 1970’s average winter temperatures have risen more than 4 degrees Fahrenheit in the Northeast region. If the current rate of heat-trapping emissions continues, by 2070 summers in Boston will feel like those of South Carolina today. By the end of the century, temperatures could rise up to 14 degrees Fahrenheit in the region. Cities across New England, which historically experience only one or two days per year above 100 degrees each summer, could average 20 such days per summer, while more southern cities such as Hartford could average nearly 30 days.
The character of the seasons will change significantly. Spring could arrive three weeks earlier, with summer lengthening by about three weeks, autumn becoming warmer and drier, and winter becoming shorter and milder.
So what’s wrong with that?
Well, once we note the conjectures (marked by the weasel words in bold), we see that most of it is nothing but unfounded, un-cited alarmist claims about imaginary future calamities. They have presented only one claim of fact – that winter temperatures in the Northeast Region have risen by more than 4°F.
Now, the USHCN has the data for all of the states, as well as by region. The Northeast Region is the data that starts with “101” in the first column. Figure 2 shows the temperature record for the four seasons, as well as the annual average temperature, for the Northeast Region:

Figure 2. Annual and seasonal temperatures, US Northeast Region. Photo shows winter surf in New England. PHOTO SOURCE.
As you can see, there has not been much of a change over the last 115 years in any of the seasons. The trend for all of the datasets is not significantly different from zero (winter p=0.06, spring p=0.15, summer p=0.34, fall p=0.68, annual p=0.06).
And more to the point, the winter trend over the last 40 years (1970-2009) is only 2.7°F, not the “more than 4 degrees Fahrenheit” claimed by their website. Such a swing is not surprising in a dataset such as the winter temperatures, which shows a 10 °F swing in one year, from 2001 to 2002.
But wait … there’s more. Because of the short length (40 years) and high variability of the 1970-2009 winter temperatures, the 1970-2009 trend is not significantly different from zero either (p = 0.12, a ways from significant).
SUMMARY: Their web page contains two misrepresentations of fact about US Northeast winters, two implied misrepresentations, and a big lie:
Misrepresentation of fact 1: the 1970-2009 winter temperatures have not “risen more than 4 degrees Fahrenheit”, they have risen 2.7 degrees Fahrenheit. There is no rise of more than 4 °F in the winter temperature record, no matter where you start.
Misrepresentation of fact 2: the 1970-2009 winter trend is not statistically significant, so we cannot reject the null hypothesis that there is no trend at all, much less a claimed 4 °F trend.
Implied misrepresentation 1: The US Northeast winters are not warming. Over the full period of record (1895-2009), there is no statistically significant trend in the winter record.
Implied misrepresentation 2: The seasonal temperatures in the US Northeast are not warming. Over the full period of record (1895-2009), there is no statistically significant trend in the overall record for any season.
THE BIG LIE: When you look at the full record for the US Northeast, there is no statistically significant trend anywhere. Neither spring, summer, winter, fall, nor the full annual average temperatures have any statistically significant trend for the period of the study, 1895-2009. And remember, this is measured by ground stations that contain spurious UHI warming, and there still is no warming trend.
The big lie is that the US Northeast is warming. The best records that we have say that it is not.
I will examine more of the malarkey from their web site as time permits, although the statements are so obviously untrue that it’s hardly sporting. It’s like shooting fish, not in a barrel, but in a bucket …
w.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8ae0a327',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
The months of flatlining at the Chicago Climate Exchange (CCX) should be a hint to the rest of the world that carbon trading is dead. Time to take it off life support. Even at 10 cents a ton, nobody wants it. At it’s peak in July 2008, it traded for $7.50 per ton of CO2.

Chicago Climate Exchange close on June 30th, 2010 - click for source
See who is on the CCX advisory board here
From ACM:
Token Gesture Alert as the government of New Zealand, unable to think  straight thanks to years of green environmental propaganda, brings in  its emissions trading scheme. 
New Zealand emits about 0.1% of global  CO2. So even if New Zealand reduced its emissions to zero overnight,  AND it were demonstrated that the climate sensitivity is large enough  to notice (which it hasn’t been), it would make not the slightest  bit of difference to the climate.
Not only that, but I hardly think  that China and India are going to look at New Zealand, and, wracked  with guilt and remorse by the plucky little country’s valiant efforts to  save the planet, stop their coal fired economies in their tracks. Not  on your life. China and India are far too busy building their prosperity  and lifting their populations out of poverty. It’s only wealthy  countries can afford the luxury of pointless environmental gestures like  this.
So the only result will be higher prices for poor Kiwis. Everything  will cost more: electricity, petrol, groceries, consumer goods –  everything – since everything (virtually) requires energy for its  production or transportation. As the ABC reports:
New Zealanders are bracing for higher electricity  and fuel prices with the introduction of an emissions trading scheme  (ETS).
From today New Zealanders will pay around three cents a litre more for fuel.
Electricity bills are set to increase by up to 5 per cent as companies pass on the costs of buying carbon credits to consumers.
Environment minister Dr Nick Smith says New Zealand had to act  because its greenhouse gas emissions have increased by 25 per  cent over the past 20 years. [So from absolutely tiny, to  slightly less absolutely tiny]
“It’s actually about New Zealand starting the path, starting  the change to a less carbon intensive economy,” he said. (source)
Good luck with that. Just watch your industries move offshore, and  your economy decline for no purpose whatsoever.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a54b0af',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterFor Christmas I present to you my favourite Scrooge film – with Seymour Hicks. It’s a classic.
Let’s hope that the climate Scrooges among us, those who think that 6 billion people or more are “surplus population” and see only the dark side of everything, will open their hearts and minds for once, and stop being so pessimistic and morose about the future of our planet.

Note how both Scrooge and alarmists get mad when we burn coal and spend our money on consumerism, or advocate throwing people who think differently in prison.
If we can convert one Scrooge alarmist out there, then we can call this Christmas a success. But don’t let your expectations get to far ahead of you. The alarmists are truly a pessimistic, unhappy, and difficult-to-convert bunch. You have to view them as Nephew Fred views Scrooge.
Enjoy –
MERRY CHRISTMAS EVERYBODY!!
Share this...FacebookTwitter "
"
Share this...FacebookTwitterI’ll spare you all the old warmist warnings of balmy winters with rare and exciting snowfalls.
Now, as global warming advances faster than ever seen (so say the “experts”) Europe should now expect colder and colder winters instead. That’s what their new models show. Looks like they’re right. Check out all the warming that’s coming up in the days and weeks ahead. The warmer it gets – the colder it gets!
Reader DirkH brings our attention to a weather warning for the next two weeks from wetter.t-online.de, which warns that temperatures in parts of Germany may plunge to 25°C below zero.
Perfect timing for the launch of Drs Lüning and Vahrenholt’s book on February 6. Critics have already accused the two authors of denying the warming. Incidentally the two authors warn in their book that it will likely get cooler over the next few decades, and not warmer. The greens laugh at this. But we’ll see who laughs last.
Nuclear power-free South Germany to get hit the hardest
According to Andreas Wagner of the Meteomedia Storm Centre site, “Temperatures of -15°C during the daytime and strong wind gusts will make the temperature feel like -25°C in some regions – it’s going to be really bitter warm cold.” And Wagner warned that “Arctic conditions will prevail during the nights by the end of the week. That concerns large regions in Southern Germany.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Good time to buy a Honda home generator – just in case
Southern Germany? Isn’t that where the government forced the shut down of 8 nuclear power plants? I think everybody ought to go out and buy electric heaters and test the new green energy supply system :). Actually, please don’t. I get the feeling there could be a nasty power supply interruption coming. You may want to go out and buy a Honda portable generator instead to power the furnace. Don’t rule anything out. Just think about who the masterminds behind energy management are right now.
If the grid crashes, there will certainly be holy hell to pay. The government would be wise to screw CO2 eimissions reductions and recommission any moth-balled coal plant they can find – and right now!
!! MUST READ !! (h/t: mwhite)
http://www.dailymail.co.uk/sciencetech/article-2093264/Forget-global-warming–Cycle-25-need-worry-NASA-scientists-right-Thames-freezing-again.html
 
Share this...FacebookTwitter "
"
Readers may recall a story on WUWT from April titled: Solar Dynamics Observatory – STUNNING first images and movies
Now, SDO imagery of the sun is online. This week spaceweather.com has started using SDO sunspot imagery in place of the familiar SOHO MDI image on their left sidebar.  See all resolutions: 4096, 1024,              256 The upside of the 4096 pixel image is that the detail is striking, the downside is that even tiny sunspecks are now visible in exquisite detail.
SDO sunspot image - click to enlarge
The real question now is; what will this new detail do to sunspot counts. As we saw in August 2008, when SIDC retroactively counted a sunspeck to snatch away a spotless month, will the SDO now be the new speckometer? Older telescopes and projection methods would never have seen the sunspecks we see today.
As we see with Geoff Sharp’s Layman’s Sunspot Count, both SIDC and NOAA’s counts are higher than the layman’s count. Now with SDO imagery, will even more miniscule sunspecks widen the gap between them? See the graph below comparing SIDC, NOAA, and LSC:

click to enlarge
From Geoff Sharp’s website, here’s how the new Layman’s count works:
THE LAYMAN’S COUNT METHOD & HISTORY
There has been a lot of comments recently  about the tiny specks that have been counted as sunspots. A tiny speck  can get a daily count of 11 which severely skews the record. Also I have  noticed on the SIDC record some days where the Sun is completely blank  but the records show a sunspot count. NOAA is another magnitude higher  than the SIDC, NOAA using a different method not meant to compare with  the historical count. During times of high speck count we need a new  standard to record sunspots that gives us a realistic measure of today’s  activity verses the last Grand Minimum.
Robert Bateman a very motivated amateur solar enthusiast and myself started a thread at www.solarcycle24.com (which has unfortunately developed into an anti Landscheidt, Pro AGW  forum) and soon devised a plan to come up with a reliable standard. We  would use the existing SOHO 1024 x 1024 Continuum images and measure the  pixels involved in a Sunspot. Initially it had to be determined what a  standard sunspot should represent in size and density, to try and  represent a minimum counter like Wolf may have done 200 years ago. After  some deliberation and advise from Robert who also dabbles in Astronomy  with his own equipment, we came up with a minimum standard.

To be counted, a sunspot or group must have 23 pixels which have a reading in the green channel of 0-70 for at least 24 hours.
All pixels in a digital image have a RGB  reading which split out into separate Red, Blue, Green channels and can  be easily measured and counted in one action using a freeware graphics  program called GIMP.
So the standard was set, which now enabled us to go back over the records and weed out the offending specks and blank days.
The official Layman’s Sunspot Count is  compared against the SIDC record which is considered conservative when  compared with other institutions involved. Basically we use the same  sunspot number as SIDC but replace them with zero on days that don’t  make the grade. When the SIDC count is made up of two or more areas and  if any of the area’s do not make the Layman’s Count, the overall SIDC  daily count will be reduced by the areas that fail. Spots that count 23  pixels and over before midnight and then continue on to pass the 24 hour  rule will take the SIDC value of that day. Existing Spots that have  made the grade but measure less than 23 pixels at midnight are not  counted on the next day.
===================================================
Unless solar science comes up with a way to deal with the advances in technology and properly merge it into the older human-optical record, the sunspot record will start looking like the surface temperature record, with upwards trends due to adjustments (or lack thereof).
I think Sharp and Bateman are on to something, and if you’ll provide me a graphic that isn’t drop shadowed onto a dark background, I’ll add it to the upcoming WUWT solar page with a link to yours. – Anthony


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a2c4fc3',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"Who should political leaders follow when it comes to climate change:  environmental scientists, powerful corporations, or a million marchers? Sometimes the three groups disagree, sometimes they concur; but even then, their claims to authority are based on different and frequently conflicting ideas. The recent United Nations climate summit highlighted the confusion over how best to make progress. Gaining agreement on an emissions treaty will require governments of all kinds to pitch in and there are competing ideas of how even democratic states make climate policy. One idea concerns supranational government: the dream of liberal internationalists since at least the post-World War I invention of the League of Nations, it is incarnated today in the UN. The organisation is founded on a utopian faith in the possibility of transcending narrow national interests in favour of the general good of humanity. This goal has proven elusive because the anarchic world of international relations, driven by economics and ethnicity, has resisted pacification. The other aspect of supra-nationalism is more technical, and has seen greater success. UN bodies such as the Food and Agriculture Organization and the World Health Organization are occasionally branded as political, but have become almost technical spaces for the application of rationality. This faith in a disinterested expertise that can triumph through the power of objective evidence dominates hopes for positive summit outcomes. A second view of the state regards it as subject to competing perspectives, which determine its conduct. Parliamentary democracies are open to influence when voices are loud, cogent, numerous and attached to material interests. The remarkable power of the oil, coal and gas industries is clear when lobby groups and unscientific deniers stake a place alongside technical experts. The UN’s Intergovernmental Panel on Climate Change does not have the same status as the FAO or the WHO, because of the opposition lined up against it. Politicians’ platitudes on the environment are easily uttered, even as their policies and programmes are based on ephemeral self-interest and pseudo-science. This gloomy reality dominates pessimism about the outcome of the summit, because corporate power and short-term priorities trump existential crisis. Then there is the idea that states are inherently undemocratic and hopelessly compromised by these interest groups, but can be forced through spectacle to watch, listen, and learn. This assumes that sovereignty resides in universal values expressed through righteous indignation that transcend government to represent the popular will in an unmediated way via civil society. Hence groups believing that anti-climate change gatherings of a few hundred thousand in a population of two billion signify a people’s message. Theirs was the authentic assembly, not the UN. There are fascinating contradictions at play here about knowledge and elitism. On the one hand, many environmental activists are animated by scientific research. On the other, they claim legitimacy through grassroots connections, not expertise. So bodies such as the IPCC are invoked, but experiential stories are privileged. Claims to organic community ties and a need for business and state transparency are asserted at the same time as small numbers of operatives work clandestinely to disrupt corporate activity. Hence Greenpeace occupying a coal train in England’s East Midlands last Tuesday while Leonardo DiCaprio and David Cameron were addressing an assembly on the Upper East Side. One of these activities is about agitprop and illegality, the other about speechmaking and legitimacy. One is naughty attention-seeking, the other is haughty attention-seeking. One claims to be community-based while being vanguardist, the other claims to be democratically based while being elitist. In the lonely hour of the last instance, alternatives must be found to the use of limited resources that in turn threaten our most basic resource, life itself. It’s clear that supra-national deals are necessary to mitigate the dangers we face, because the climate itself is supranational. Can and should the three theories come together to account for this mazy, hazy world of policy-making and offer better outcomes? We need the technical authority and quiet science that come with avoiding controversy and establishing proofs. The science is hard to contest, even as it is uncertain on some detail – and it should be, given the difficulty of prediction. We must also acknowledge that corporate power manifests itself again and again on national and global stages, and disclose its malevolent impact on public policy. And we should recognise that pranks by non-government organisations can draw attention to the silent and invisible way that fossil fuels can distort democracy and compromise sovereignty. All three ideas about states have their uses here: the technical possibilities of a rational world, the sceptical capacity to counter powerful distortions of the truth and the magical self-anointment of spectacle-based activism. If our crisis is to be averted – or rather, survived – we need contributions from all three models, despite their contradictions."
"
By Steve Goddard

The   last piece of ice remaining in the Arctic
The death spiral continues, with Arctic ice extent and thickness  nearly  identical to what it was 10 years ago.



The graph above shows superimposed volume data (calculated  from PIPS) for 2010, on top of the NSIDC extent data. Interesting  to note that volume continued to increase for about a month after extent  started to decline. This is because the Arctic Basin has remained below  freezing, while the lower latitudes have been melting.
In the video of 2010 ice below, you can see how ice has been piling  up to a depth of nearly five metres (red) on the windward side of  Wrangel Island, the New Siberian Islands, and the Taymyr Peninsula.

Ice thickness in Barrow, AK seems to have reached it’s maximum this  week, at about 4.3 metres feet.

University  of Alaska – Barrow Ice Sensor
Temperatures in the Arctic interior have remained cold, and well  below freezing. Not much opportunity for melt.

http://ocean.dmi.dk/arctic/meant80n.uk.php
You can see the Arctic temperature anomalies over the last 30 days in  the video below:


The four major extent indices continue to diverge, with the next  couple of weeks showing almost no year over year variability.

http://ocean.dmi.dk/arctic/plots/icecover/icecover_2010.png
The modified NSIDC image below shows in red where ice has disappeared  since early April.

The modified NSIDC image below shows in red where ice has disappeared   in the last week.

The modified NSIDC image below shows a comparison between 2010 and  2007. Areas in green have more ice than 2007. Areas in red have less ice  than 2007.

The modified NSIDC image below shows in red areas of ice deficiency  relative to the 30 year mean, with areas of excess shown in green. The  cold Pacific side has excess ice, while the warmer Atlantic side has a  deficiency..

This corresponds quite closely with sea surface temperature anomalies  seen below.

http://weather.unisys.com/surface/sst_anom.html
The image below from September 15, 2007 is the one which most  interests me this week. After the big “melt” of 2007, it was widely  reported that researchers expected  the ice to be gone by 2013, and that “in the end, it will just melt away  quite suddenly.”

How is five metre thick ice supposed to “just melt away quite  suddenly?”
————————————————————————————-
From the linear predictions department :
Temperatures in Colorado have warmed up 20 degrees in the last two  weeks. If that trend continues, it will become hot enough to boil water  before Christmas. And  the Arctic will be ice free by 2013.

Sources:
http://seaice.alaska.edu/gi/observatories/barrow_sealevel/brw2010/BRW_MBS10_overview_complete.png
http://seaice.alaska.edu/gi/observatories/barrow_sealevel/brw2010/BRW_MBS10_overview_complete.png
And finally, GLOBAL sea ice has returned to normal:
Click to enlarge


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b485c7f',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Yes, our forebears started global warming by hunting the woolly mammoth. Right. Must be the mammoth albedo effect, much like the sheep albedo effect. Oh, wait, no it’s birch trees albedo calculated via pollen proxy. The mammoths stopped eating birch trees, that’s wot did it. And those hunters used cooking fires too. Gosh. I wish I had more time to refute this, travel beckons, but I’m sure readers can lend a hand in comments.
UPDATE: Carl Bussjaeger points out in comments that;
Just last month, USA Today told us that Felisa Smith of the University of New Mexico in Albuquerque discovered that…
Mammoth extinction triggered climate COOLING
http://content.usatoday.com/communities/sciencefair/post/2010/05/mammoth-extinction-triggered-climate-cooling/1
Woolly mammoths (Mammuthus primigenius) in a late Pleistocene landscape in northern Spain. (Information according to the caption of the same image in Alan Turner (2004). National Geographic Prehistoric Mammals. Washington, D.C. Image: Wikipedia
Man-made global warming started with ancient hunters
AGU Release No. 10–15 Link here
 30 June 2010
For Immediate Release
WASHINGTON—Even before the dawn of agriculture, people may have caused the planet to warm up, a new study suggests.
Mammoths used to roam modern-day Russia and North America, but are now extinct—and there’s evidence that around 15,000 years ago, early hunters had a hand in wiping them out. A new study, accepted for publication in Geophysical Research Letters, a journal of the American Geophysical Union (AGU), argues that this die-off had the side effect of heating up the planet.
“A lot of people still think that people are unable to affect the climate even now, even when there are more than 6 billion people,” says the lead author of the study, Chris Doughty of the Carnegie Institution for Science in Stanford, California. The new results, however, “show that even when we had populations orders of magnitude smaller than we do now, we still had a big impact.”
In the new study, Doughty, Adam Wolf, and Chris Field—all at Carnegie Institution for Science—propose a scenario to explain how hunters could have triggered global warming.
First, mammoth populations began to drop—both because of natural climate change as the planet emerged from the last ice age, and because of human hunting. Normally, mammoths would have grazed down any birch that grew, so the area stayed a grassland. But if the mammoths vanished, the birch could spread. In the cold of the far north, these trees would be dwarfs, only about 2 meters (6 feet) tall. Nonetheless, they would dominate the grasses.
The trees would change the color of the landscape, making it much darker so it would absorb more of the Sun’s heat, in turn heating up the air. This process would have added to natural climate change, making it harder for mammoths to cope, and helping the birch spread further.
To test how big of an effect this would have on climate, Field’s team looked at ancient records of pollen, preserved in lake sediments from Alaska, Siberia, and the Yukon Territory, built up over thousands of years. They looked at pollen from birch trees (the genus Betula), since this is “a pioneer species that can rapidly colonize open ground following disturbance,” the study says. The researchers found that around 15,000 years ago—the same time that mammoth populations dropped, and that hunters arrived in the area—the amount of birch pollen started to rise quickly.
To estimate how much additional area the birch might have covered, they started with the way modern-day elephants affect their environment by eating plants and uprooting trees. If mammoths had effects on vegetation similar to those of modern elephants , then the fall of mammoths would have allowed birch trees to spread over several centuries, expanding from very few trees to covering about one-quarter of Siberia and Beringia—the land bridge between Asia and Alaska. In those places where there was dense vegetation to start with and where mammoths had lived, the main reason for the spread of birch trees was the demise of mammoths, the model suggests.
Another study, published last year, shows that “the mammoths went extinct, and that was followed by a drastic change in the vegetation,” rather than the other way around, Doughty says. “With the extinction of this keystone species, it would have some impact on the ecology and vegetation—and vegetation has a large impact on climate.”
Doughty and colleagues then used a climate simulation to estimate that this spread of birch trees would have warmed the whole planet more than 0.1 degrees Celsius (0.18 degrees Fahrenheit) over the course of several centuries. (In comparison, the planet has warmed about six times more during the past 150 years, largely because of people’s greenhouse gas emissions.)
Only some portion—about one-quarter—of the spread of the birch trees would have been due to the mammoth extinctions, the researchers estimate. Natural climate change would have been responsible for the rest of the expansion of birch trees. Nonetheless, this suggests that when hunters helped finish off the mammoth, they could have caused some global warming.
In Siberia, Doughty says, “about 0.2 degrees C (0.36 degrees F) of regional warming is the part that is likely due to humans.”
Earlier research indicated that prehistoric farmers changed the climate by slashing and burning forests starting about 8,000 years ago, and when they introduced rice paddy farming about 5,000 years ago. This would suggest that the start of the so-called “Anthropocene”—a term used by some scientists to refer to the geological age when mankind began shaping the entire planet—should be dated to several thousand years ago.
However, Field and colleagues argue, the evidence of an even earlier man-made global climate impact suggests the Anthropocene could have started much earlier. Their results, they write, “suggest the human influence on climate began even earlier than previously believed, and that the onset of the Anthropocene should be extended back many thousands of years.”
This work was funded by the Carnegie Institution for Science and NASA.
Notes for Journalists
As of the date of this press release, the paper by Doughty et al. is still “in press” (i.e. not yet published). Journalists and public information officers (PIOs) of educational and scientific institutions who have registered with AGU can download a PDF copy of this paper in press.
Or, you may order a copy of the paper by emailing your request to Maria-José Viñas at mjvinas@agu.org. Please provide your name, the name of your publication, and your phone number.
Neither the paper nor this press release are under embargo.
Title:
“Biophysical feedbacks between the Pleistocene megafauna extinction and climate: The first human‐induced global warming?”
Authors:
Christopher E. Doughty, Adam Wolf, and Christopher B. Field, Department of Global Ecology, Carnegie Institution for Science, Stanford, California, USA
======================
Readers, I urge you to write to newspapers and magazines that carry this story.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a64f07f',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"
Share this...FacebookTwitterThe warmists keep insisting that it’s CO2 and that the sun is not playing a role in our climate today. According to them, the sun has been on strike and stopped playing a role since mankind started its sinful use of CO2.
Yet another study is out and shows that the warmists are off in Cuckooland with their CO2 science.
Die kalte Sonne website brings our attention to a paper by Nozomu Hamanakaa, Hironobu Kana, Yusuke Yokoyamad, Takehiro Okamotoc, Yosuke Nakashimag and Toshio Kawanah of Okayama University titled:
Disturbances with hiatuses in high-latitude coral reef growth during the Holocene: Correlation with millennial-scale global climate change, where an ancient coral reef was studied.
The study was published in the journal Global and Planetary Change in January 2012.
A 6000-year old coral reef on the Japanese island of Kodakara, which was exposed during street construction works, was studied in great detail and reporesents a valuable climate archive of the last several thousand years. The reef was lifted over the surface of the water by tectonic action two and half thousand years ago.
Field observations and coral radiocarbon dating of excavated trench walls of the uplifted middle-to-late Holocene coral reef on Kodakara Island show evidence of the existence of disturbances with hiatuses in coral reef growth and coral composition differences before and after the disturbances. The scientists found three disconformities in the reef occurred at approximately 5.9 to 5.8, 4.4 to 4.0, and 3.3 to 3.2 cal yr B.P.
The abstract also writes (emphasis added):



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The coral composition clearly changed before and after the disturbances, with gradually reduced diversity resulting in a reef dominated by acroporiid coral. These data led to the hypothesis that coral reef growth was interrupted by suborbital millennial-scale global climate change induced by persistent solar activity during the Holocene in high-latitude coral reefs, such as those in the Northwest Pacific, leading to low diversity in the reefs that experienced each disturbance. Our results may provide new insights into theories of past and future coral reef formation worldwide.
As recent studies have shown, the new study shows that climate changes occurred globally and cyclicly – in sync with the 1000-year solar cycles. Die kalte Sonne writes:
The scientists found by comparison with other studies that the coral die-off events occurred in times when the current weakened and the ocean apparently cooled off because of the cold Asian winter monsoons, and did so to the point that the corals could no longer live. Interesting is the fact that the cooling phases were synchronous with solar activity minima, the solar quiet periods of the combined Hallstatt and Eddy cycles (see Chapter 3 in “Die kalte Sonne“).”
Once again the claims made in the skeptic book “Die kalte Sonne” are reinforced. Critics are left standing there without an explanation. The results of the Japanese study also add yet more evidence that cooling periods are global, and not just isolated local events. Die kalte Sonne summarizes:
One has to be permitted to ask in what magical way the sun was able to have this enormous impact on the climate. When one believes the claims made by the last IPCC report, then this in fact has to be a miracle. According to the IPCC, the climatic impact of the known solar cycles is ‘negligible’ and is only a couple of tenths of a degree, which is in stark contradiction to the real geological findings from various regions all over the globe. Now that the IPCC is just working on its latest report, don’t you think they would correct this obvious error? You guessed wrong! As we have learned, the IPCC has reduced the sun’s impact on climate even more.
They can try of course. But as the science mounts with every passing study, the dogmatic warmists are going to look more and more like the lone fool at the town square that everyone ignores.
 
Share this...FacebookTwitter "
"
By Steve Goddard
Earlier in the month I wrote an article showing the trend in Arctic ice since 2002.

I took a lot of criticism from people for not measuring “crest to crest or trough to trough.”
Any  one schooled in analysis of cyclical data would know that one must go  from crest-to-crest or trough-to-trough, to maintain some semblance of  symmetry about the x-axis.
It is time now to see how serious people are about their belief  systems. We have passed the 2010 El Niño peak, and can see what the  “real” trend is since the cyclical El Niño peak of 1998.


http://www.woodfortrees.org/plot/rss/from:1998/last:2010/plot/rss/from:1998/last:2010/trend
Hansen claims :
“Global  warming on decadal timescales is continuing without let-up … we  conclude that there has been no reduction in the global warming trend of  0.15-0.2C/decade that began in the late 1970s.”
Talk about cherry-picking! Look at his start point. He chose the worst case trough to crest to measure his trend.

Question for readers. Is Hansen correct, or does he need some serious graphing lessons? Below are the trend graphs from 1998-present for all four sources. GISS is way out of line.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e89fcd5a5',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

 _Global Science Report_ _is a feature from the_ _Center for the Study of Science_ _, where we highlight one or two important new items in the scientific literature or the popular media. For broader and more technical perspectives, consult our monthly “Current Wisdom.”_   
  
  
—   
  
  
Making headlines today (like the one above) is a new paper by Zoë Doubleday and colleagues documenting an increase the population of cephalopods (octopuses, cuttlefish, and squid) over the past 61 years. The authors, after assembling a data set of historical catch rates, note that this population increase, rather than being limited to a few localized areas, seems to be occurring globally.   
  
  
End of analysis.   
  
  
From then on its speculation.   
  
  
And the authors speculate that human‐​caused climate change may be behind the robust cephalopod increase. After all, the authors reason, what else has had a consistent large‐​scale impact over the past six decades? No analysis relating temperature trends (spatially or temporally) to cephalopod trends, no examination of other patterns of climate change and cephalopod change, just speculation. And a new global warming meme is born—“Swarms of octopus are taking over the oceans.”   
  
  
There is an overwhelming tendency to relate global warming to all manner of bad things and a great hesitation to suggest a potential link when the outcome is seemingly beneficial. We refer to this as the global‐​warming‐​is‐​bad‐​for‐​good‐​and‐​good‐​for‐​bad phenomenon. It holds a great majority of the time.   
  
  
In the case of octopuses, squids, and cuttlefish, the authors are a bit guarded as to their speculation of impact of the increase in cephalopod numbers—will they decimate their prey populations or will they themselves provide more prey to their predators? Apparently we’ll have to wait and see.   
  
  
No doubt, the outcome will be a complex one as is the case behind the observed population increases. Depletion of fish stocks, a release of competitive pressure, and good old‐​fashioned natural environmental variability are also suggested as potential factors in the long‐​term population expansion. But complex situations don’t make for great scare stories. Global‐​warming‐​fueled bands of marauding octopuses and giant squid certainly do.   
  
  
**Reference:**   
  
  
Doubleday, Z. A., et al., 2016. Global proliferation of cephalopods. _Current Biology_ , **26** , R387–R407.
"
"
By Steven Goddard
I found a computer  simulation of Arctic ice produced by The University Of Washington,  which struck me as being particularly disconnected from reality.
This group is forecasting that September extent will be lower than  last year.

Below is their simulation map.

http://psc.apl.washington.edu/zhang/IDAO/seasonal_outlook.html
After watching their map animate, I noticed something which bothered  me.  They are showing that by August 18, all ice will be gone north of  Barrow, AK.

The problem is that NSIDC shows 3+ year old ice in that region:


Cropped from : http://nsidc.org/images/arcticseaicenews/20100406_Figure6.png
The computer model is predicting that 3+ year old ice (which is  probably in excess of 10 feet thick) is going to melt by early August.  That seems rather far fetched.  Below is an overlay of the NSIDC map and  the U of W simulation for August 18.  Note all the multi-year ice that  needs to melt.

Last June, temperatures  in Barrow averaged 35F.  In July they averaged 44F.  It is a tall  order to melt 10 feet of ice at those temperatures.  This is how Barrow  looks today:

http://www.gi.alaska.edu/snowice/sea-lake-ice/barrow_webcam.html
I am a big fan of computer models – when they produce useful  information.  Garbage in, garbage out.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8c5228d9',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterYesterday we read how EU and German bureaucrats want to force homeowners make costly home renovations, for the sole sake of saving some energy. This of course would seriously drive up rental rates for tenants, hitting the poor especially hard.

And if it isn’t difficult enough for the poor to pay for their housing, take a look at the cost for mobility. We learn today that this is already unaffordable for many – thanks to the high price of fuel from government policy.
The leftist German daily TAZ reports here on a survey by research institute Forsa published last Thursday. Over 3000 citizens were surveyed and results show that one quarter are reducing their use of public transportation or their automobiles because of costs.
According the TAZ:
24 percent of the 3212 persons surveyed from all German states are refraining from planned or necessary trips with automobile, bus, rail or planes because of cost reasons.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




These 24% of course are those with limited financial and income means. The middle class and rich will worry much less about the costs of travel as they are able to pay the prices. The energy policy is impacting mainly the poor – making their struggle to make ends meet even worse with each passing day.
There is now spiralling energy inflation in Germany. The TAZ adds:
‘Compared to cost of living increases of about 11 percent between 2005 and 2011, the prices for air and rail trave,l as well as fuel prices, have exploded,’ said Allianz-pro-Schiene Director Dirk Flege. Last year a German Railway train ticket cost 22 percent more than it did 6 years ago.
In the same time period, air travel costs rose 34 percent. Fuel prices for cars went up 28%. The reason for the price increases are rising energy costs.”
Already many of the poor are unable to afford electricity and now will neither have anywhere to go nor the means to travel. In response, the government is considering social programs to alleviate their plight. But these programs are ineffective and amount to pick-pocketing 5 euros from one pocket, and putting one euro in the other, and claiming to be good Samaritans for it.
The greens and environmentalists are of course pleased about 24% of the population cutting back, and they view it as progress for the climate. But they are demanding more – 95% if possible (5%, green officials, would be exempt and continue to fly to places like Bali, Cancun, Durban, etc.).
 
Share this...FacebookTwitter "
"
Guest Commentary by Paul Driessen
Figure 1. Chart from professional paper analyzing Michael Mann’s “hockey stick” graphs that purported to find average global temperatures suddenly skyrocketing at an exponential – and physically impossible – rate in recent decades. Willie Soon, David Legates and Sallie Baliunas, “Estimation and representation of long-term (>40 year) trends of Northern-Hemisphere-gridded surface temperature: A note of caution,” Geophysical Research Letters, Vol. 31, 2004. 
“Scientific debates should be played out in the academic arena,” insists University of Virginia environmental sciences professor David Carr. “If Michael Mann’s conclusions are unsupported by his data, his scientific critics will eventually demonstrate this.”
Carr and 809 other Virginia scientists and academics signed a petition launched by the activist Union of Concerned Scientists, protesting Commonwealth Attorney General Ken Cuccinelli’s investigation of former University of Virginia professor Michael Mann. The American Association of University Professors likewise opposes Cuccinelli, who is seeking documents from UVA, to determine whether there are grounds to prosecute Mann for violating the Fraud Against Taxpayers Act, by presenting false or misleading information in support of applications for state-funded research.
Carr claims Cuccinelli is attempting to “drown out” scientific debate.” Others have accused the AG of conducting a “witch hunt,” engaging in “McCarthyite” tactics, and “restricting academic freedom.”
It’s time to clear a few things up.
Mann is the former UVA professor, whose “hockey stick” temperature chart was used to promote claims that “sudden” and “unprecedented” manmade global warming “threatens” human civilization and Earth itself. The hockey stick was first broken by climatologists Willie Soon and Sallie Baliunas, who demonstrated that a Medieval Warm Period and Little Ice Age were clearly reflected in historic data across the globe, but redacted by Mann. Analysts Steve McIntyre and Ross McKitrick later showed that Mann’s computer program generated hockey-stick patterns regardless of what numbers were fed into it – even random telephone numbers; that explained why the global warming and cooling of the last millennium magically disappeared in Mann’s “temperature reconstruction.”
The Climategate emails revealed another deliberate “trick” that Mann used to generate a late twentieth-century temperature jump: he replaced tree ring data with thermometer measurements at the point in his timeline when the tree data no longer fit his climate disaster thesis.
Not surprisingly, he refused to share his data, computer codes and methodologies with skeptical scientists. Perhaps worse, Climategate emails indicate that Mann and others conspired to co-opt and corrupt the very scientific process that Carr asserts will ultimately condemn or vindicate them.
This behavior certainly gives Cuccinelli “probable cause” for launching an investigation. As the AG notes, “The same legal standards for fraud apply to the academic setting that apply elsewhere. The same rule of law, the same objective fact-finding process, will take place.” Some witch hunt.
There is simply no room in science, academia or public policy for manipulation, falsification or fraud. Academic freedom does not confer a right to engage in such practices, and both attorneys general and research institutions have a duty to root them out, especially in the case of climate change research.
Work by Mann and other alarmist scientists is not merely some theoretical exercise that can be permitted to “play itself out” over many years, if and when the “academic arena” gets around to it. These assertions of climate crisis are being used right now by Congress, states, courts and the Environmental Protection Agency to justify draconian restrictions on energy use and greenhouse emissions. They would shackle our freedoms and civil rights and hammer our jobs, economy, health, welfare and living standards.
If the science is wrong – or far worse, if it is manipulated, fabricated, fraudulent and covered up – then grave damage will be done to our nation, liberties and families, before the truth gets its boots on.
As to “scientific debate” over global warming, there has been virtually none in the academic arena. The science is viewed as “settled,” debate has been squelched, and those who seek to initiate debate are attacked, vilified, harassed and shipped off to academic Siberia.
Dr. Patrick Michaels, another former UVA climate researcher, was fired as Virginia State Climatologist by then-Governor Tim Kaine for raising inconvenient questions and facts on climate science. When Greenpeace demanded access to Michaels’ emails, UVA promptly acceded – before contesting AG Cuccinelli’s request for Mann’s.
The 810 protesters and their UCS and AAUP consorts were silent. Their principles and objections do not seem to apply to shrill activist groups infringing on the academic and scientific freedom of “politically incorrect” researchers, even when there is no suggestion of dishonesty. Other “skeptical” climate researchers have met with similar fates. The pungent scent of hypocrisy fills the air.
No surprise there. The massive US government climate change research gravy train alone totaled some $9 billion in grants during 2009, courtesy of hardworking taxpayers. IPCC, EU & Company climate grants – plus billions more for renewable energy research – fatten the larder still further. Now that money, prestige and power are threatened.
Climategate and other revelations about the lack of evidence for the “manmade climate disaster” thesis have sent belief in AlGorean gloom and doom plummeting. Global warming consistently comes in dead last on any list of environmental concerns. Three-fourths of Americans are unwilling to spend more than $100 a year to prevent climate change. China, India and other developing nations properly refuse to sign a carbon-cutting economic suicide pact.
The public is rightly concerned that in-house investigations by Penn State University (Mann’s current institution), East Anglia University (home of Phil Jones and the Climategate emails) and the IPCC have the patina of a Tom Sawyer whitewash. Independent investigations like Cuccinelli’s are absolutely essential, to ferret out fraud and misconduct – which may be rare but must be dealt with when it happens.
Dr. Andrew Wakefield falsified studies to create a connection between autism and trace mercury in vaccines against measles, mumps and rubella. Britain stripped him of his right to practice medicine. But meanwhile, a lingering stench remains over double standards; World Wildlife Fund press releases and rank speculation masquerading as peer-reviewed science; computer models enshrined as “proof” of looming climate disasters; and billions being squandered on research purporting to link global warming to nearly every malady and phenomenon known to man.
We the taxpayers are paying for this work. We the people will pay the price – in soaring energy bills, fewer jobs, lower living standards and lost freedoms – for draconian energy and emission laws enacted in the name of saving the planet.
We have a right to insist that the research be honest and aboveboard. That the work products stay in the public domain, available for scrutiny. That researchers share their data, computer codes and analytical methodologies, and engage in robust debate with skeptics and critics. That those who violate these fundamental precepts forfeit their access to future grants. And that our tax dollars no longer fund bogus acne-and-climate-change studies and alarmist propaganda. (Talk about budget cutting opportunities!)
It’s certainly understandable that scientists, academics, eco-activists and the AAUP and UVA would line up behind Mann and against Cuccinelli. There’s a lot of power, prestige and cash on the line. But it is essential that the attorney general and law-abiding citizens insist on transparency, integrity, credibility and accountability in the climate change arena.
We should support what Ken Cuccinelli is doing – and demand that Eric Holder and other state AGs take similar action.
Paul Driessen is senior policy advisor for the Committee For A Constructive Tomorrow (www.CFACT.org) and author of Eco-Imperialism: Green Power – Black Death.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b6c214d',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"The US oil firm ExxonMobil met key European commission officials in an attempt to water down the European Green Deal in the weeks before it was agreed, according to a climate lobbying watchdog. Documents unearthed by InfluenceMap revealed that Exxon lobbyists met Brussels officials in November to urge the EU to extend its carbon-pricing scheme to “stationary” sources, such as power plants, to include tailpipe emissions from vehicles using petrol or diesel. Green groups believe this would be the least effective way to disincentive fossil fuel vehicles, and would rather allow countries to set their own emissions standards and targets for road emissions. The move appears to be an attempt to stall the rollout of electric vehicles by keeping a lid on the cost of driving a traditional combustion engine vehicle running on fossil fuels. The European commission stopped short of proposals to phase out combustion engine vehicles and has plans to consult on whether to include vehicles in its carbon-pricing scheme. Edward Collins, a director at InfluenceMap, said the document “represents yet another evidence piece” of ExxonMobil’s long-term strategy of delaying climate action by focusing on “long-term technical solutions” to try to avert “decisive regulatory action” that is urgently required to tackle the climate crisis. A Guardian investigation last year found that Exxon has spent €37.2m (£32.4m) lobbying the EU since 2010, more than any other major oil company, according to the EU’s transparency register. It revealed that Shell spent €36.5m and BP spent €18.1m lobbying Brussels officials to shape EU climate policy. Exxon is also facing legal action in the US courts after accusations that it misled investors over the business risks caused by regulations aimed at addressing the climate crisis. The lawsuit claims that Exxon scientists told the company’s management in 1977 there was an “overwhelming” consensus that fossil fuels were responsible for increasing the levels of carbon in the atmosphere that lead to global heating. In 1981, an internal company memo warned that “it is distinctly possible” that CO2 emissions from the company’s 50-year plan “will later produce effects which will indeed be catastrophic (at least for a substantial fraction of the Earth’s population)”. Exxon’s latest lobbying efforts have surfaced after documents emerged earlier this year showing that BP successfully lobbied US policymakers to weaken a landmark environmental law to clear the way for fossil fuel projects to move forward. A spokesman for ExxonMobil said the company “complies fully” with the EU’s transparency rules and supports the Paris climate agreement. He added that Exxon, “like many companies”, had “a responsibility” to engage in a public policy dialogue that impacted its business."
"
Guest Post by Willis Eschenbach
Following up on the excellent initiative of Dr. Judith Curry (see Judith’s  post and my  response ), I would like to see what I can do to rebuild the justifiably lost trust in climate science. I want to bring some clarity to terms which are used all the time but which don’t seem to have an agreed upon meaning. In the process, I want to detail my own beliefs about the climate and how it works.
Figure 1. Dr Judith Curry tries to warn the greenhouse warming scientists … from  Cartoons By Josh.
I don’t know about you, but I’m weary of the vague statements that characterise many of the discussions about climate change. These range from the subtle to the ridiculous. An example would be “I believe in climate change”. Given that the climate has been changing since there has been climate, what does that mean?
We also hear that there is a “consensus” … but when you ask for the actual content of the consensus, what exactly are the shared beliefs, a great silence ensues.
Often we see people being called unpleasant terms like “deniers”, with the ugly overtones of “Holocaust deniers”. I’ve been called that myself many times … but what is it that I am being accused of denying?
In an attempt to cut through the mashed potatoes and get to the meat, let me explain in question and answer format what I believe, and provide some citations for my claims. (These are only indicative citations from among many I could provide on each topic.) I will also indicate how much scientific agreement I think there is on the questions. First, some introductory questions.
Preface Question 1. Do you consider yourself an environmentalist?
I bring this up to get rid of the canard that people who don’t believe the “consensus science” on global warming are evil people who don’t care about the planet. I am a passionate environmentalist, and I have been so since 1962 when I first read Silent Spring upon its publication. I believe that we have an obligation to respect the natural ecosystems that we live among. My reasons are simple. First, we have a responsibility to be good guests and good stewards here on this amazing planet. Second, I worked extensively in my life as a commercial fisherman, and I would like for my grandchildren to have the same opportunity. The only way to do this is to monitor and be careful with our effects on the earth and the biosphere.
Preface Question 2. What single word would you choose to describe your position on climate science?
Heretic. I am neither an anthopogenic global warming (AGW) supporter nor a skeptic, I believe the entire current climate paradigm is incorrect.
Question 1. Does the earth have a preferred temperature which is actively maintained by the climate system?
To me this is the question that we should answer first. I believe that the answer is yes. Despite millennia-long volcanic eruptions, despite being struck by monstrous asteroids, despite changes in the position of the continents, as near as we can tell the average temperature of the earth has only varied by about plus or minus three percent in the last half-billion years. Over the last ten thousand years, the temperature has only varied by plus or minus one percent. Over the last 150 years, the average temperature has only varied by plus or minus 0.3%.  For a system as complex and ever-changing as the climate, this is nothing short of astounding.
Before asking any other questions about the climate, we must ask why the climate has been so stable. Until we answer that question, trying to calculate the climate sensitivity is an exercise in futility.
I have explained in “The Thermostat Hypothesis” what I think is the mechanism responsible for this unexplained stability. My explanation may be wrong, but there must be some mechanism which has kept the global temperature within plus or minus 1% for ten thousand years.
I am, however, definitely in the minority with this opinion.
Question 2. Regarding human effects on climate, what is the null hypothesis?
If we are trying to see if humans have affected the climate, the null hypothesis has to be that any changes in the climate (e.g. changes in temperature, rainfall, snow extent, sea ice coverage, drought occurrence and severity) are due to natural variations.
Question 3. What observations tend to support or reject the null hypothesis?
As I show in “Congenital Climate Abnormalities”, not only are there no “fingerprints” of human effects in the records, but I find nothing that is in any way unusual or anomalous. Yes, the earth’s temperature is changing slightly … but that has been true since the earth has had a temperature.
There is no indication that the recent warming is any different from past warmings. There is more and more  evidence that the Medieval Warm period was widespread, and  that it was warmer than the present.  The Greenland ice cores show that we are at the cold end of the Holocene (the current inter-glacial period). There have been no significant changes in rainfall, floods, sea level rise, Arctic temperatures, or other indicators.
In short, I find no climate metrics that show anything which is anomalous or outside of historical natural variations. In the absence of such evidence, we cannot reject the null hypothesis.
Question 4. Is the globe warming? 
This is a trick question. It is a perfect example of a frequently asked question which is totally meaningless. It shows up all the time on public opinion polls, but it is devoid of meaning. To make it meaningful, it needs to have a time period attached to it. Here are some examples of my views on the question:
1 During the last century, the earth warmed slightly (less than 1°C).
2 The earth has generally cooled over the last 12,000 years. We are currently at the cold end of the Holocene (the period since the end of the last Ice Age. See the  Greenland and  Vostok ice records.
3 The earth has generally warmed since the depths of the Little Ice Age around 1650, at a rate somewhere around a half a degree Celsius per century. See  Akasufo, the  Central England Temperature (CET), and the  Armagh records.
4 The largest warming in any instrumental record occurred around 1680 – 1730. See the CET and Armagh records.
5 The earth was either stable or cooled slightly from about 1945 to 1975.
6 The earth warmed slightly from about 1975 to 1998.
7 There has been no significant warming from 1995 to the present (Feb. 2010). See  The Reference Frame,  Phil Jones.
I would say that there is widespread scientific agreement on the existence of these general trends. The amount of the warming, however, is far less certain. There is current controversy about both the accuracy of the adjustments to the temperature measurements and the strength of local effects (UHI, poor station siting, warmth from irrigation, etc.). See e.g.  McKitrick,  Spencer,  Christy and Norris,  Ladochy et al..,  Watts,  SurfaceStations, and  Jones on these questions.
Question 5. Are humans responsible for global warming?
This is another trick question that often shows up on polls. The question suffers from two problems. First is the lack of a time period discussed above. The second is the question of the amount of responsibility. Generally, the period under discussion is the post-1900 warming. So let me rephrase the question as “Are humans responsible for some part of the late 20th century warming?”
To this question I would say “Yes”. Again, there is widespread scientific agreement on that simplistic question, but as usual, the devil is in the details discussed in Question 4.
Question 6. If the answer to Question 5 is “Yes”, how are humans affecting the climate?
I think that humans affect the climate in two main ways. The first is changes in land use/land cover, or what is called “LU/LC”. I believe that when you cut down a forest, you cut down the clouds. This mechanism has been implicated in e.g. the decline in the Kilimanjaro Glacier. When you introduce widespread irrigation, the additional water vapor both warms and moderates the climate. When you pave a parking lot, local temperatures rise. See e.g.  Christie and Norris,  Fall et al.,  Kilimanjaro.
The second main way humans affect climate is through soot, which I will broadly define as black and brown carbon. Black carbon comes mostly from burning of fossil fuels, while brown carbon comes mostly from the burning of biofuels. This affects the climate in two ways. In the air, the soot absorbs incoming solar radiation, and prevents it from striking the ground. This reduces the local temperature. In addition, when soot settles out on ice and snow, it accelerates the melting of the ice and snow. This increases the local temperature by reducing the surface albedo. See e.g.  Jacobson.
There is little scientific agreement on this question. A number of scientists implicate greenhouse gases as the largest contributor. Other scientists say that LU/LC is the major mover. The IPCC places values on these and other so-called “forcings”, but it admits that our scientific understanding of many of forcings is “low”.
Question 7. How much of the post 1980 temperature change is due to human activities?
Here we get into very murky waters. Is the overall balance of the warming and cooling effects of soot a warming or a cooling? I don’t know, and there is little scientific agreement on the effect of soot. In addition, as shown above there is no indication that the post 1980 temperature rise is in any way unusual. It is not statistically different from earlier periods of warming. As a result, I believe that humans have had little effect on the climate, other than locally. There is little scientific agreement on this question.
Next, some more general and theoretical questions.
Question 8. Does the evidence from the climate models show that humans are responsible for changes in the climate?
This is another trick question. Climate models do not produce evidence. Evidence is observable and measurable data about the real world. Climate model results are nothing more than the beliefs and prejudices of the programmers made tangible. While the results of climate models can be interesting and informative, they are not evidence.
Question 9. Are the models capable of projecting climate changes for 100 years?
My answer to this is a resounding “no”. The claim is often made that it is easier to project long-term climate changes than short-term weather changes. I see no reason to believe that is true. The IPCC says:
“Projecting changes in climate due to changes in greenhouse gases 50 years from now is a very different and much more easily solved problem than forecasting weather patterns just weeks from now. To put it another way, long-term variations brought about by changes in the composition of the atmosphere are much more predictable than individual weather events.” [from page 105, 2007 IPCC WG1, FAQ 1.2]
To me, that seems very doubtful. The problem with that theory is that climate models have to deal with many more variables than weather models. They have to model all of the variables that weather models contain, plus:
• Land biology
• Sea biology
• Ocean currents
• Ground freezing and thawing
• Changes in sea ice extent and area
• Aerosol changes
• Changes in solar intensity
• Average volcanic effects
• Snow accumulation, area, melt, and sublimation
• Effect of melt water pooling on ice
• Freezing and thawing of lakes
• Changes in oceanic salinity
• Changes in ice cap and glacier thickness and extent
• Changes in atmospheric trace gases
• Variations in soil moisture
• Alterations in land use/land cover
• Interactions between all of the above
• Mechanisms which tend to  maximise the sum of work and entropy according to the Constructal Law.
How can a more complex situation be modeled more easily and accurately than a simpler situation? That makes no sense at all.
Next, the problem with weather models has been clearly identified as the fact that weather is chaotic. This means that no matter how well the model starts out, within a short time it will go off the rails. But the same is true for climate, it is also chaotic. Thus, there is no reason to assume that we can predict it any better than we can predict the weather. See  Mandelbrot on the chaotic nature of climate.
Finally, climate models have done very poorly in the short-term. There has been no statistically significant warming in the last fifteen years. This was not predicted by a single climate model. People keep saying that the models do well in the long-term … but no one has ever identified when the changeover occurs. Are they unreliable up to twenty-five years and reliable thereafter? Fifty years?
Question 10. Are current climate theories capable of explaining the observations?
Again I say no. For example, the prevailing theory is that forcing is linearly related to climate, such that a change of X in forcing results in a change of Y in temperature. The size of this temperature change resulting from a given forcing is called the “climate sensitivity”. In 1980, based on early simple computer climate models, the temperature resulting from a change in forcing of 3.7 watts per square meter (W/m2) was estimated to result in a temperature change of between 1.5 and 4.5 degrees Celsius. See e.g.  Green and Armstrong  2007.
Since 1980, there has been a huge increase in computing power. Since 1980, there has also been a huge increase in the size and complexity of computer models. Since 1980, thousands of man hours and billions of dollars have been thrown at this question. Despite these advances, the modern estimate of the climate sensitivity is almost unchanged from its 1980 value.
To me, this lack of any advance in accuracy indicates that we have an incorrect understanding of the forces governing the climate. Otherwise, our bigger, faster and better models would have narrowed the uncertainty of the climate sensitivity. But they have not.
Question 11. Is the science settled?
To this one I would answer no, no, a thousand times no. We are just a the beginning of the study of climate. New information and new theories and new forcings are put forward on a regular basis. See e.g.  Lu. The data is poor, short, and full of holes. The signal is tiny and buried in a huge amount of noise. We don’t know if the earth has a thermostat. In short, the study of climate is an infant science which is still poorly understood.
Question 12. Is climate science a physical science?
Well, sort of. It is a very strange science, in that to my knowledge it is the only physical science whose object of study is not a thing, not a physical object or phenomenon, but an average. This is because climate is defined as the average of weather over a suitably long period of time (usually taken to be 30 years.) The implications of this are not widely appreciated. Inter alia, it means that statistics is one of the most important parts of climate science.
Unfortunately, a number of what I might call the “leading blights” of climate science, like Michael Mann with his HockeySchtick, have only the most rudimentary understanding of statistics. This initially got him into trouble in his foray into the area of paleoclimate statistics, trouble which he has only compounded by his later statistical errors.
Question 13. Is the current peer-review system inadequate, and if so, how can it be improved?
There are a number of problems with the current peer-review system, some of which are  highlighted in the abuses of that system  revealed in the CRU emails.
There are several easy changes we could make in peer review that would help things immensely:
1. Publish the names of the reviewers and their reviews along with the paper. The reviews are just as important as the paper, as they reveal the views of other scientists on the issues covered. This will stop the “stab in the back in the dark” kind of reviewing highlighted in the CRU emails.
2. Do not reveal the names of the authors to the reviewers. While some may be able to guess the names from various clues in the paper, the reviews should be “double-blind” (neither side knows the names of the others) until publication.
3. Do the reviewing online, in a password protected area. This will allow each reviewer to read, learn from, and discuss the reviews of others in real time. The process often takes way too long, and consists of monologues rather than a round-table discussion of the problems with the paper.
4. Include more reviewers. The CRU emails show that peer review is often just an “old-boys club”, with the reviewing done by two or three friends of the author. Each journal should allow a wide variety of scientists to comment on pending papers. This should include scientists from other disciplines. For example, climate science has suffered greatly from a lack of statisticians reviewing papers. As noted above, much of climate science is statistical analysis, yet on many papers either none or only the most cursory statistical review has been done. Also, engineers should be invited to review papers as well. Many theories would benefit from practical experience. Finally, “citizen scientists” such as myself should not be excluded from the process. The journals should solicit as wide a range of views on the subject as they can. This can only help the peer review process.
5. The journals must insist on the publication of data and computer codes. A verbal description of what mathematics has been done is totally inadequate. As we saw in the “HockeyStick”, what someone thinks or says they have done may not be what they actually did. Only an examination of the code can reveal that. Like my high science teacher used to say, “Show your work.”
Question 14. Regarding climate, what action (if any) should we take at this point?
I disagree with those who say that the “precautionary principle” means that we should act now. I detail my reasons for this assertion at “Climate Caution and Precaution”.  At that page I also list the type of actions that we should be taking, which are “no regrets” actions. These are actions which will have beneficial results whether or not the earth is warming.
So that is where I stand on the climate questions. I think that the earth actively maintains a preferred temperature. I think that man is having an effect on local climate in various places, but that globally man’s effect is swamped by the regulating action of clouds and thunderstorms. I think that the local effect is mainly through LU/LC changes and soot. I think that the climate regulating mechanism is much stronger than either of these forcings and is stronger than CO2 forcing. I think that at this point the actions we should take are “no regrets” actions.
Does that make me a “denier”? And if so, what am I denying?
Finally, I would like to invite Dr. Judith Curry in particular, and any other interested scientists, to publicly answer these same questions here on Watts Up With That. There has been far too much misunderstanding of everyone’s position on these important issues. A clear statement of what each of us thinks about the climate and the science will go a long way towards making the discussion both more focused and more pleasant, and perhaps it will tend to heal the well-earned distrust that many have of climate science.




			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8c8db2db',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**England enters a tougher version of its three tier system of restrictions on Wednesday, as a four-week lockdown ends.**
Northern Ireland has a two-week circuit-breaker lockdown, while Wales is banning the sale of alcohol in pubs, cafes and restaurants from Friday. Scotland has its own five-tier system.
Across the UK, some restrictions will be relaxed over Christmas, to allow three households to form a ""Christmas bubble"".
From just after midnight on Wednesday 2 December, areas will be placed in one of three tiers: medium, high and very high.
About 99% of England has been placed into the high and very high coronavirus risk category - tiers two and three.
The placing of areas in each tier will be reviewed every 14 days, with the first review on 16 December.
**Areas in tier two**
**Tier two (high) rules**
**Areas in tier three**
**Tier three (very high) rules**
Additional restrictions apply:
**Areas in tier one**
Only three areas have been placed in the lowest tier:
**Tier one (medium) rules**
Areas in the lowest tier will have some restrictions relaxed:
There are exceptions in all tiers for childcare and support bubbles. More details of the plan are here.
The new coronavirus tier restrictions will mean 55 million people will be banned from mixing with other households indoors. The decision about which tier to place an area in is based on:
Lockdown restrictions in Wales were eased on 9 November.
**The current rules say:**
People who you don't live with still cannot come into your home socially, unless you are in an extended household (bubble) with them. Tradespeople can enter your home to carry out work.
However, from **Friday 4 December:**
Read Wales' official guidance.
Northern Ireland started a two-week circuit-breaker lockdown from 00:01 GMT on Friday 27 November.
Read Northern Ireland's official guidance.
Each area of Scotland has been placed in one of five tiers.
Eleven local authority areas in west and central Scotland have recently moved from level three to level four, affecting two million people.
First Minister Nicola Sturgeon told MSPs the level four measures would be lifted at 18:00 GMT on Friday 11 December.
**Areas in level zero**
No areas have been placed in the lowest tier.
**Level zero (nearly normal) rules**
**Areas in level one**
**Level one (medium) rules**
Additional restrictions apply:
**Areas in level two**
**Level two (high) rules**
Additional restrictions apply:
**Areas in level three**
**Level three (very high) rules**
Additional restrictions apply:
**Areas in level four**
**Level four (lockdown) rules**
Additional restrictions apply:
Schools stay open in all levels, and here must also be no non-essential travel between Scotland the rest of the UK.
**Do you meet other people for exercise? Have you been out walking during the November lockdown? You can share your experiences by emailing**haveyoursay@bbc.co.uk **.**
Please include a contact number if you are willing to speak to a BBC journalist. You can also get in touch in the following ways:"
"

Some of my favorite conservative commentators appear dismayed that the White House and press paid little attention to news that “Coalition forces have recovered approximately 500 weapons munitions [in Iraq] which contain degraded mustard or sarin nerve agent.” 



That item came from a one‐​page memo by John D. Negroponte, director of national intelligence, sent to placate Michigan Rep. Peter Hoekstra, chairman of the House Intelligence Committee. Pennsylvania Sen. Rick Santorum also got involved. Along with many Republican enthusiasts, they believe the president should stand up and shout: “See, I _told_ you so. Saddam really did have weapons of mass destruction!”



L. Brent Bozell III, the persuasive president of the Media Research Center, complained that major newspapers buried this story. Yet the media could not possibly have done that if the administration had trumpeted the news. Mr. Bozell suspects that “Team Bush” has been silenced “out of intimidation by the media.” Not likely. 



First, finding those 500 artillery shells was not much of a surprise. My column last November, “No Intelligence,” critiqued the 2002 CIA report about weapons of mass destruction (WMD) in Iraq. Among few concrete facts within that otherwise slippery report, I remarked, was that “Iraq has not accounted for … about 550 artillery shells filled with mustard agent.” 



That information came from the vilified U.N. Monitoring, Verification and Inspection Commission (UNMOVIC). I did not doubt such artillery shells might be left over from the 1991 Iraq war. But, I asked, how anyone could “actually imagine that terrorists could simply… fire artillery shells from cannons on U.S. streets?” 



Heavy artillery shells are battlefield weapons — not something easily hidden in terrorist suitcases. A 155‐​millimeter shell is more than 6 inches in diameter and requires a cannon 10 feet to 12 feet long. A mere tank will not suffice to launch such shells. A 155‐​millimeter German howitzer weighs 55 tons. 



The Negroponte memo concerns “Iraq’s filled and unfilled pre‐​Gulf war chemical munitions.” This refers to “sarin‐ and mustard‐​filled projectiles,” meaning 155‐​millimeter artillery shells. “While agents degrade over time,” the memo continues, “chemical warfare agents remain hazardous and potentially lethal.”



Most chemicals are hazardous waste. But “potentially lethal” could mean anything, including swallowing a pound of the stuff. The nerve gas sarin can certainly be lethal if it is fresh and nearby. Sarin was used in a 1995 terrorist attack on the Tokyo subway system that killed 12 and in a 1994 attack that killed seven in Matsumoto, Japan. 



Nineteen deaths are as close to “mass destruction” as the world has seen from terrorist use (as opposed to battlefield use) of chemical or biological agents. Yet sarin degrades very quickly. UNMOVIC concluded years ago it would be “unlikely that (Iraq’s sarin‐​filled munitions) would still be viable today.” 



What about the heavy artillery shells filled with old “mustard gas” (sulfur mustard)? That is hazardous waste material, to be sure — anyone who opened those shells without the proper gloves would still be badly blistered. But it is a highly unlikely weapon of mass destruction, particularly in this form at this late date. 



In 2000, the Federal Emergency Management Agency reported: “The United States Congress has directed that the U.S. Army destroy certain kinds of chemical weapons stockpiled at eight U.S. Army installations in the continental United States over the next several years. Experts believe the chance of an accident involving these obsolete chemical munitions is remote.” The U.S. quietly got rid of its obsolete sulfur mustard by February 2005 without any risk of mass destruction. 



Sulfur mustard is commonly called “mustard gas,” but it is neither mustard nor a gas. It is liquid at temperatures above 58 degrees Fahrenheit and called “mustard” because of its odor and color. It causes blisters and is potentially harmful to the lungs and eyes (which is why infantry carry gas masks). 



According to the Centers for Disease Control: “Exposure to sulfur mustard is usually not fatal. When sulfur mustard was used during World War I, it killed fewer than 5 percent of the people who were exposed and got medical care.” Most estimates of lethality range from 1 percent to 3 percent. 



Sulfur mustard inside Iraq’s old heavy artillery shells was a battlefield weapon. Its strategic value might have been to slow opposing troops by forcing them to wear protective suits and gas masks in Iraq’s extremely hot climate. 



Artillery shells of any sort are not terrorist weapons, but shells filled with conventional explosives are far deadlier than those with sulfur mustard. Any degraded sulfur mustard left inside such shells would be very difficult to remove without destroying the chemical agent (and the person doing the removal).



The reason sulfur mustard was banned by the Geneva Convention in 1925 was not because it was lethal (it is far less lethal than legal explosives), but because blistering caused extreme pain and sometimes blindness. 



The concept of antique mustard gas as some awesome new “weapon of mass destruction” appears traceable to an oft‐​repeated story about Kurdish deaths due to other causes (including sarin). The Council on Foreign Relations Web site says: “Saddam Hussein used mustard gas on the Kurds. … The worst attack occurred in March 1988 in the Kurdish village of Halabja; a combination of chemical agents including mustard gas and sarin killed 5,000 people.” Yet the October 2002 CIA report claimed only “hundreds” of casualties at Halabja and said the intended targets were Iranians. 



The Negroponte memo purports to be worried that “pre‐​Gulf war Iraqi chemical weapons could be sold on the black market. Use of these weapons by terrorists or insurgent groups would have implications for Coalition forces in Iraq. The possibility of use outside Iraq cannot be ruled out.” 



This is the same sort of devious “what if” conjecture that filled the 2002 CIA report. We cannot rule out the possibility aliens in flying saucers are about to take over the Earth. And we cannot rule out the possibility unicorns really do exist.



In reality, any “use of these weapons (artillery shells) by terrorists or insurgent groups” would require their possession of 55‐​ton self‐​propelled howitzers. Can you imagine finding one of those heavily armed vehicles cruising around unnoticed in Baghdad, much less in New York City? Even if terrorist could fire heavy artillery shells in either city, why would they want them filled with something that causes blisters much more often than death? 



The president was judicious to downplay this nonstory about finding a few hundred heavy artillery shells filled with pre‐​1991 sulfur mustard. To have done otherwise could have proved very embarrassing. His conservative critics would likewise be wise to drop it.
"
"
Share this...FacebookTwitterProphetic revelations of disturbing end of world visions…
PIK Makes The Ice Melt Away
By Meteorologist Klaus Eckart Puls
(Translated, condensed by P Gosselin)
The Potsdam Institute for Climate Impact Research (PIK) and the Universidad Complutense de Madrid recently came out with computer-model generated scenarios showing that Greenland would melt away [1]. This scenario of course was all designed to produce spectacular headlines of a coming apocalypse for the media. And that, it did. The PIK study contained the following core statement:
Here, using a fully coupled model, we show that this criterion systematically overestimates the temperature threshold and that the Greenland ice sheet is more sensitive to long-term climate change than previously thought. We estimate that the warming threshold leading to a monostable, essentially ice-free state is in the range of 0.8–3.2°C, with a best estimate of 1.6°C ” … For 2.0°C regional summer warming, which is just above the deglaciation threshold in the representative case, complete melting of the GIS takes about 50,000 years. In contrast, with warming of 4,0°C, the ice sheet needs about 8,000 years to melt completely, and for warming of 8°C, 20% of the ice sheet melts in just 500 years and the entire ice sheet melts within about 2,000 years.”
All of this is based on a model – written up to produce a desired result. And from the desired model results, the scientists concluded:
Therefore, if anthropogenic CO2 emissions in the coming century drive the temperature considerably above the deglaciation threshold, irreversible total loss of the GIS will be difficult to avoid, ensuring continued substantial sea-level rise for millennia.”
The PIK press release even went so far to claim that their scenarios for the future are likely spot on:
The Model has proven that it can not only correctly calculate today’s observed ice cover, but also its development all the way back to the last ice age. That’s why the simulation is also trusted to correctly estimate the future. All this makes the new estimations more reliable than the previous.”
So this produces the impression that anthropogenic CO2 leads to continued warming with the catastrophic consequences for Greenland ice and sea level.
Now is a good time to tell readers why the PIK’s model scenarios are a load of manure: First, we have models where nature always ends up doing everything completely different. What are model speculations for centuries and even millenia into the future worth when already the current trends are talking a completely different language?
(1) Not predicted by a single model: The Earth has not warmed in 14 years [3] .
(2) For 14 years there has not been any correlation between CO2 and global temperature.
(3) This correlation is fundamentally, hotly and increasingly disputed [2].
(4) Sea level rise shows that over the last years, and foremost now, there is no acceleration [7] – instead we have a deceleration.
(5) And the most absurd of all: the study and the press release are speculating thousands of years into the future, as if it were like next month.
All the speculation is based on a computer model. Models are computer scenarios, and are not prognoses. Just as prognoses– e.g. for economics, weather, social structure, etc. – for political, business and private decisions are fraught with uncertainty, model scenarios for decisions for far-reaching measures are useless.
Another important question amid all this is being avoided: How is it that the Greenland Ice Sheet never experienced extensive melting (let alone a complete meltdown) over the Holocene when at times it was warmer than today over hundreds of years, see figure below?



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Alpine glaciologist E. Patzelt [5] also writes:
Proxy temperature records for the temperature development show that 65% of the last 10,000 years the summer half-year was just as warm or warmer than today. The current temperature development is within the normal range of variability. Warm phases of this type have always been called ‘climate optimums’.”
One needs to take this much more into consideraion in the current climate discussion. This will not lead to a complete melting of the glaciers, neither in the Alps, nor in Greenland.
Finally, veteran meteorologist Dr. Wolfgang Thüne puts it in plain words (emphasis added) when asked what he thought about the PIK’s thousand-year model prognoses [6] :”
Nothing! Theoretically, you can think up anything, dress it up in formulae and calculate that the end of the world will occur in exactly 1900 years. In 2000 years, when it comes to an ice-free Greenland, man will have been defrauded. The Potsdam Institute for Climate Impact Research reminds me of the Greek ‘Oracle of Delphi’, or the ‘Book of Revelation’, the vision of the apocalypse with its prophetic picture sequences . The world was supposed to end already back in 1033 and the IPCC prophesied in 2007 a climate collapse for 2020. With their super computers the climate scientists would have us believe that they have opened up the ‘Seven Seals’ and revealed ‘God’s Plan’.”
References:
[1] http://www.pik-potsdam.de/aktuelles/pressemitteilungen/gronlands-eismassen-konnten-komplett-schmelzen-bei-1-6-grad-globaler-erwarmung; 11.03.2012
[2] A.Robinson, R.Calov and A.Ganopolski;  Multistability and critical thresholds of the Greenland ice sheet; NATURE CLIMATE CHANGE / ADVANCE ONLINE PUBLICATION, www.nature.com/natureclimatechange , © 2012 Macmillan
Publishers Limited. All rights reserved.
[3] http://www.eike-klima-energie.eu/news-cache/g-l-o-b-a-l-c-o-o-l-i-n-g-wo-bleibt-die-erderwaermung/; 25.02.2012
[4] F.Vahrenholt & S.Lüning, Die Kalte Sonne, Hoffmann u. Campe, (2012)
[5] G. Patzelt, Gletscherschwund und Vorzeitklima, Bergauf, 2 (2008), S. 34-35, Innsbruck
[6] Luxembg. Tageblatt,15. März 2012, Das Orakel von Delphi; http://www.tageblatt.lu/nachrichten/story/-Orakel-von-Delphi–11105134
Also read here: http://drtimball.com/2012/sensationalist-and-distorted-climate-stories-increase-as-climate-science-failures-exposed/
 
Share this...FacebookTwitter "
"October 9 2014 was a big day in eco-activism: Lego announced that it would not renew a product-placement deal with Shell, following concerted pressure from Greenpeace as part of a campaign to ban Arctic oil exploration by attacking firms associated with such activities. It is a common tactic of major energy companies to engage in collaborations with companies such as Lego as part of their quest for what they call a “social license” to operate. That means winning local, national and international community support.  For its part, Lego benefits from the money that comes with product placement; as per a James Bond movie, the producers defray their costs well in advance of sales to customers by accepting funding from firms that want to be associated with a happy, friendly, trustworthy image.  In this case, the firm is Greenpeace’s sworn enemy, Shell. As a sub-plot, Lego has been boasting of its green credentials. On July 1 2014, Lego said: “A co-promotion contract like the one with Shell is one of many ways we are able to bring Lego bricks into the hands of more children.” It went on: The Greenpeace campaign focuses on how Shell operates in a specific part of the world. We firmly believe that this matter must be handled between Shell and Greenpeace. We are saddened when the Lego brand is used as a tool in any dispute between organisations. Now, Lego’s tune differs: We continuously consider many different ways of how to deliver on our promise of bringing creative play to more children. We want to clarify that as things currently stand we will not renew the co-promotion contract with Shell when the present contract ends. We do not want to be part of Greenpeace’s campaign and we will not comment any further on the campaign. We will continue to deliver creative and inspiring Lego play experiences to children all over the world. This is, surely, one of those moments when a big but pusillanimous multinational corporation withers in the face of critique from a gallant but small non-government organisation – when activism trumps business, ethics triumphs over size, and scale is helpless in the face of righteousness. It has been hailed by Greenpeace true believers as “one of the most high-profile victories in its history” thanks to “guerrilla tactics”. The organisation itself immodestly announced in an email to its supporters that: “Today was a great day for the Arctic, and for people power.” But was it? Perhaps this was a smart, sophisticated, well-heeled multinational marketing campaign, undertaken via a vast network, using the services of advertising agencies and borrowing trademarks and copyrights to make a political point? Is this actually about what happens when multinationals fall out, when two vast companies (Shell and Lego) are separated by another powerful not-for-profit multinational (Greenpeace) revelling in the fantasy that it is David taking on Goliath? One version of these events might read: Greenpeace has not achieved very much in its critiques of Shell, so it went after a soft target. Lego caved in, the victim of a form of secondary boycott. While the charity argues that its grassroots campaign and direct-action pranks were crucial, one might also say that “wot won it” was a couple of ingenious videos. The first and most popular took music, words, images, and logos from one of the most successful films of the year, [The Lego Movie](http://www.boxofficemojo.com/movies/?id=lego.htm](http://www.boxofficemojo.com/movies/?id=lego.htm), to create a post-modern pastiche aimed at the heartstrings. The second, artier and less direct, was targeted at parents. The first, a brilliant video trope, worked magnificently and has become a case study for ad agencies. As the industry bible AdWeek put it, Greenpeace took “a page from Chipotle’s marketing playbook – haunting animation plus a distressing cover of a well-known song”. Other actions, such as a few children building anti-oil Lego figures in central London, some adults climbing models at a theme park and fun Lego figures placed in protests across major world cities, were minor irritants at best, drawing predictably minimal press coverage but incarnating a grassroots legitimacy that appeals to donors and old-fashioned activists from pre-social media eras. But even as the triumph occurred, Shell was luxuriating in Pele’s endorsement of it for providing “the world’s first player-powered community football pitch in the centre of Rio Di Janeiro’s favela”. It will take more than a sophisticated stunt by vanguardist apparatchiks to answer Pele. And it won’t be the action of a brave wee David against a big nasty Goliath – more a contest between rivals for multinational space and control. Greenpeace is well-placed to participate, thanks to its vast resources and smart links to ad agencies. But is people power one more marketing tool in this admittedly worthy struggle?"
"
From a University of Leeds press release, comes this scary headline that seems to be picked up by the MSM. A Google search yields 16,400 hits on the title below.
Melting icebergs causing sea level rise
(Note: Be sure to see the reality punch line at the end of the article)

Scientists have discovered that changes in the amount  of ice floating in the polar oceans are causing sea levels to rise.

The research, published this week in  Geophysical Research Letters, is the first assessment of how quickly  floating ice is being lost today.
According to Archimedes’ principle, any floating object displaces  its own weight of fluid. For example, an ice cube in a glass of water  does not cause the glass to overflow as it melts.
But because sea water is warmer and more salty than floating ice,  changes in the amount of this ice are having an effect on global sea  levels.
The loss of floating ice is equivalent to 1.5 million Titanic-sized  icebergs each year.  However, the study shows that spread across the  global oceans, recent losses of floating ice amount to a sea level rise  of just 49 micrometers per year – about a hair’s breadth.
According to lead author Professor Andrew Shepherd, of the  University of Leeds, it would be unwise to discount this signal. “Over  recent decades there have been dramatic reductions in the quantity of  Earth’s floating ice, including collapses of Antarctic ice shelves and  the retreat of Arctic sea ice,” said Prof Shepherd.
“These changes have had major impacts on regional climate and,  because oceans are expected to warm considerably over the course of the  21st century, the melting of floating ice should be considered in future  assessments of sea level rise.”
Professor Shepherd and his team used a combination of satellite  observations and a computer model to make their assessment. They looked  at changes in the area and thickness of sea ice and ice shelves, and  found that the overall signal amounts to a 742 cubic kilometres per year  reduction in the volume of floating.
Because of differences in the density and temperature of ice and sea  water, the net effect is to increase sea level by 2.6% of this volume,  equivalent to 49 micrometers per year spread across the global oceans.
The greatest losses were due to the rapid retreat of Arctic Sea ice  and to the collapse and thinning of ice shelves at the Antarctic  Peninsula and in the Amundsen Sea.
For more information 
To arrange an interview with Prof Andy Shepherd, contact Hannah Isom  in the University of Leeds press office on 0113 343 4031 or email h.isom@leeds.ac.uk
Notes to editors 
“Recent loss of floating ice and the consequent sea level  contribution” by Andrew Shepherd, Duncan Wingham, David Wallis,  Katharine Giles, Seymour Laxon, and Aud Venke Sundal is published this  week in Geophysical Research Letters (doi:10.1029/2010GL042496).
ICE SHELVES are thick, floating platforms of ice that form where a  glacier or ice sheet flows down to a coastline and onto the ocean  surface. Ice shelves are found mainly in Antarctica , and range from  about 100 to 1000 metres in thickness.
SEA ICE is formed on the surface of sea water as the ocean freezes,  and is typically less than 3 metres in thickness. It is found  extensively in both the Arctic and Antarctic regions, and it’s extent  varies considerably over the seasons.
This study was funded by the UK National Centre for Earth  Observation and the Philip Leverhulme Trust.
==========================================
OK here’s the reality punch line:
Assuming their theory of 49 micrometers per year rise (this conversion equals 0.0019 inch or 0.00016 feet ) due to the differences is salty and fresh water holds true, then we can assess the threat level.
At this rate, to see an inch of sea level rise from melting icebergs we’d need:
1 inch/0.0019 inch/yr  = 526 years
Yeah, I’m worried about that.



			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8bd9a9ce',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Guest Post by Willis Eschenbach
Yesterday, I discussed the Shepherd et al. paper, “Recent loss of floating ice and the consequent sea level contribution” (which I will call S2010). I also posted up a spreadsheet of their Table 1, showing the arithmetic errors in their Table.
Today, I’d like to discuss the problems with their method of calculating the loss in the Arctic Ice Pack. To start with, how big is the loss? Here is a graphic showing the change in area of the Arctic ice pack from one year’s loss of ice, with the ice pack area represented by a circle:

Figure 1. One-year change in the area of the Arctic Ice Pack, using the average annual loss which occurred 1996–2007. Note the obligatory polar bears, included to increase the pathos.
OK, so how do they calculate the Arctic ice loss in S2010?

Here is their description from the paper:
We estimated the trend in volume of Arctic sea ice by considering the effects of changes in both area and thickness. According to ERS and Envisat satellite altimeter observations, the 1993-2001 (average wintertime) thickness of Arctic sea ice was estimated to be 273 cm (Laxon et al., 2003), the thickness decreased by 6.7 ± 1.9 cm yr-1 between 1992 and 2001 (Laxon et al., 2003), and the thickness decreased by 4.8 ± 0.5 cm yr-1 between 2003 and 2008 (Giles et al., 2009).
We combined these datasets to produce a new estimate of the 1994-2008 thickness change. Published satellite microwave imager observations (Comiso et al., 2008) show that the 1996-2007 Arctic sea ice area trend was -111 ± 8 x 10^3 km2 yr-1 and, based upon our own analysis of these data, we estimate that the 1990-1999 average wintertime area of Arctic sea was 11.9 x 10^6 km2.
The combined reductions in Arctic sea ice area and thickness amount to a decrease in volume of 851 ± 110 km3 yr-1 during the period 1994 to 2007, with changes in thickness and area accounting for 65 % and 35 % of the overall loss, respectively.
What is the problem with that method?
The problem is that they have assumed that the ice is the same thickness over the entire area. As a result, the reduction in area is causing a large loss of ice, 35% of the loss by their estimate.
But the ice is not all the same thickness. The perimeter of the ice, where the loss occurs, is quite thin. As a result, they have overestimated the loss. Here is a typical example of the thickness of winter ice, from yesterday’s excellent article by Steve Goddard and Anthony Watts:

Figure 2. Ice thickness for May 2010. Note that the thickness of the ice generally tapers, from ~ 3.5 metres in the center to zero at the edges.
So their method will greatly overestimate the loss at the perimeter of the ice. Instead of being 273 cm thick as they have assumed, it will be very thin.
There is another way to estimate the change in ice volume from the melt. This is to use a different conceptual model of the ice, which is a cone which is thickest in the middle, and tapers to zero at the edges. This is shown in Figure 3

Figure 3. An alternative model for estimating Arctic ice pack volume loss.
Upon looking at this drawing, I realized that there is a way to see if my model fits with the facts. This is to use my model to estimate how much of a thickness change would be necessary to create the 111,000 square kilometre loss. It turns out that to get that amount of loss of area, it would require a ~4 cm ice loss over the entire surface … which is a good match to their estimate of ~ 5 cm of loss.
So, what difference does this make in the S2010 estimate of a global loss of 746 cubic kilometres per year? Lets run the numbers. First, I’ll use their method. I have used estimates of their numbers, as their description is not complete enough to give exact numbers.
Thickness loss: (11,900,000 km^2 – 111,000 )* 5 cm / (100,000 cm/km) = 589 cubic km (66 % of total).
Area loss: 111,000 km^2 * 273 cm /  (100,000 cm/km) = 303 cubic km (34% of total)
Total: 892 cu km, which compares well with their answer of 851 cubic km. Also, the individual percentages I have calculated (66% and 34%)  compare well with their numbers (65% and 35%). The difference is likely due to the decreasing area over the period of the analysis, which I have not accounted for.
So if we use a more realistic conceptual model of the ice (a conical shaped ice pack that is thick in the middle, and thin at the edges), what do we get?
The formula for the volume of a cone is
V (volume) = 1/3 * A (area of base) * h (height)
or
V = 1/3 * A * h
The difference in volume of two cones, therefore, is
V = 1/3 * (A1*h1 – A2*h2)
This means that the volume lost is
V = 1/3 * (11900000 km^2 * 273 cm – 11789000 km2 * 268 cm) / (100000 cm/km)
= 297 cubic km
This is much smaller than their estimate, which was 851 cubic km. And as a result, their estimate of global ice loss, 746 km^3, is reduced by 851 – 297 = 554 km^3, to give a final estimate of global ice loss of 192 cubic kilometres.
FINAL THOUGHTS
1. Is my estimate more accurate than theirs? I think so, because the simplistic assumption that the ice pack is equally thick everywhere is untenable.
2. How accurate is my estimate? I would put the 95% confidence interval (95%CI) at no less than ± 25%, or about ± 75 km^3. If I applied that same metric (±25%) to their estimate of 851 km^3, it would give a 95%CI of ±210 km^3. They give a 95%CI in their paper of ±215 km^3. So we are in agreement that this is not a WAG*, it is a SWAG*.
3. This exercise reveals some pitfalls of this kind of generally useful “back-of-the-envelope” calculation. First, since the final number is based on assumptions rather than data, it is crucial to be very clear about exactly what assumptions were made for the calculations. For example, from reading the paper it is not immediately evident that they are assuming constant thickness for the ice pack. Second, the change in the assumptions can make a huge change in the results. In this case, using my assumptions reduces the final value to a quarter of their global estimate, a value which is well outside their 95%CI estimate.
To close, I want to return to a separate point I made in my last post. This is that the S2010 paper has very large estimates of both gains and losses in the thickness of the Antarctic ice shelves. Now, I’m not an ice jockey, I’m a tropical boy, but it seems unlikely to me that the Venable ice shelf would lose a quarter of a kilometre in thickness in 15 years, as they claim.
Now it’s possible my math is wrong, but I don’t think so. So you colder clime folks out there … does it make sense that an ice shelf would lose 240 metres thickness in fifteen years, and another would gain 130 metres thickness in the same period? Because that is what they are claiming.
As mentioned above, I have posted their table, and my spreadsheet showing my calculations, here. here I’d appreciate anyone taking a look to make sure I have done the math correctly.
PS:
* WAG – Wild Assed Guess, 95%CI = ±100%
* SWAG – Scientific Wild Assed Guess, 95%CI = ±25%
[UPDATE] My thanks to several readers who have pointed out that I should not use 273 cm as the peak thickness of the ice. So following this NASA graphic of submarine measured winter and summer ice, I have recalculated the peak as being about 4 metres.
Using this value, I get arctic ice loss of 344 km^3, and a global ice loss of 239 km^3.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b934ca4',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

After years of promoting the Kyoto Protocol on global warming, British Prime Minister Tony Blair his finally seen the light: the Protocol is simply not the way to deal with planetary warming, and it will take away capital that would more wisely be invested in technological development. 



Blair’s venue was as important as his words. He killed Kyoto in front of former president Bill Clinton, whose vice president, Al Gore, made Kyoto possible. Speaking at the former president’s “Clinton Global Initiative” conference in New York last month, Blair declared, “I would say probably I’m changing my thinking about [global warming] in the past two or three years…We have got to start from the brutal honesty about the politics of how we deal with it. The truth is no country is going to cut its growth or consumption substantially in light of a long‐​term environmental problem.” 



Blair recognized Kyoto’s fatal flaw: The U.S. is simply not going to implement it. “Some people have [ratified] Kyoto, some people haven’t signed Kyoto, right. That’s a disagreement. It’s there. It’s not going to be resolved.” 



Further, Blair eschewed another Kyoto‐​style treaty: “I don’t think people are going, at least in the short term, to start negotiating another major treaty like Kyoto,” he said. 



What’s remarkable is how close Blair’s position on climate change has become to that of the Bush administration: Kyoto won’t do anything about global warming. Instead, a rational approach to climate change — should policy changes really be necessary — requires major technological development and investment. 



It’s well known in scientific circles that Kyoto would only change global temperature by seven‐​hundredths of a degree Celsius in fifty years. But it would require reductions in carbon dioxide emissions to 7 percent below 1990 levels by the period 2008–2012. The only way this is possible is with a massive series of highly regressive energy taxes. 



How high must they be? No one knows, but a mini‐​experiment is currently running in the United States, thanks to the reverberations of Hurricane Katrina on limited gasoline and oil supplies. If prices at or near current levels continue for an extended period of time (and some economists think that may be the case), what’s going to be the impact on consumption? Whatever number, it’s not going to be the 25 percent drop required for the U.S. to meet Kyoto. The average annual growth rate in our emissions since 1990 has been 1.3 percent. 



Three dollars a gallon for gasoline translates to proportional increases across all other fossil fuels, all of which directly impact consumers’ spending on energy and transportation. It also indirectly raises the price of everything that requires fossil energy for manufacturing. People wind up paying more, which leaves them less to invest. 



On the subject of investment in efficient technologies, Blair asked Clinton’s forum, “How do we put these incentives in the system so that the private sector, as well as the public says, this is the direction policy is going to go?” 



The answer is obvious: If we want people to invest in the technologies of the future, they must have funds for investment. Taking money away in a futile attempt to affect the climate, like Kyoto, destroys that capital, putting it in the hands of governments that must of necessity bias their investments in ineffective, politically correct technologies like solar energy and windmills. 



Tony Blair has seen the light. With regard to planetary temperature, the future is not today’s Kyoto Protocol or any future sibling. Instead it lies in investment. For some reason, though, he has not yet learned that this is much better done by individuals than by governments, upon whom lobbyists force inefficient choices. 



Blair has also seen the light about the futility of the Kyoto Protocol and the importance of private investment. Now, if someone could only illuminate him with the notion that politics makes government a bad investor.
"
nan
"
Share this...FacebookTwitterEnergy giant British Petroleum (BP) announced that it was shutting down its solar module business for good. In 2000 the corporation had announced that it would expand aggressively into promising renewable energies, and dubbed itself “Beyond Petroleum”.Today, according to the online leftist “TAZ” daily here:
Already last year the company shut down its own solar modules plants, and now also its business with project development is ended – 30 years after BP Solar was founded.
BP is the latest in the long string of failures that have swept over the solar industry recently. Massive subsidies by governments had caused a boom in solar installations, but with solar electricity costs still sky high, governments have recently cut back subsidies dramatically, thus making investment in solar modules less attractive. Massive competition from low-cost countries in Asia, including China, have led to plummeting prices and over capacity in solar module supply. The TAZ writes:
Annual production capacity is about 50 gigawatts, but the global demand this year is only about 21 gigawatts.”
This is certainly not good news for all the German solar plants that opened with much fanfare just few years ago, especially in East Germany – many with government support. These solar module plants were ballyhooed as high tech job machines and rescuers of the climate. Today you have to feel awfully sorry for the poor workers – duped again by bogus future scenarios and false promises.
Of course the German solar cell manufacturers are crying about “unfair trade practices” by Asian producers. You see, it’s not enough that their customers are opulently subsidized in the purchase of their solar modules, German manufacturers also want trade protection as well. Then the solar energy playing field would be level!


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“It all comes down to reestablishing fair competition,” said Solarworld CEO Frank Asbeck. The TAZ also writes how things don’t look sunny for the German solar industry:
The solar industry in Germany faces a collapse. […] The Sarasin Bank puts companies Conergy, Q-Cells, Solar-Fabrik, and Sunways under the category of ‘endangered’.”
In summary, the very people who warned us of catastrophic global warming, climate change, global weirding, extreme weather events, also told us that solar energy was the future – the job machine! Indeed, just when everything solar is collapsing around them, many politicians are still cluelessly running around a preaching us the virtues of solar energy.
Don’t waste your breath telling these pols that global temperatures haven’t risen in over a decade.
Also also read more here at Bloomberg (The rest of the MSM is ignoring this embarrassment).
NEWS: German manufacturer Solar Millenium announces it is insolvent –Read at Der Spiegel!
Share this...FacebookTwitter "
nan
"Many of us know from personal experience that raising children can be stressful, but a new study reveals that stress can be enough to affect the quality of parenting – in mongooses, at least.  A recent study investigates the relationship between stress hormones and parental care in the banded mongoose, a small African mammal that lives in large family groups. The research team found that individual banded mongooses that spend a lot of time caring for pups lose weight and have elevated levels of stress hormones (glucocorticoids). This in turn affects the care they can invest in subsequent litters of pups. A feedback loop is created between care and stress, with attentive care leading to stress, and high stress levels then leading to a reduction in care. As is the case in humans, the decisions animals make will affect them later in life. In ecology this is called a “carry-over effect”. While this is a well-known concept in biology, little is known about the physiological mechanism that lies behind it. This study from Jenni Sanderson and colleagues shows stress hormones are likely to be responsible.  The mongoose is well-suited to the study because, unusually, it is a “cooperative breeder” that rears pups in large communal litters. Several females become pregnant at the same time and give birth together, down to the same night. The resulting litter of pups is reared communally by the group, with most adult members contributing something towards pup care. Also unusual is that, after weaning, each pup from the communal litter forms a bond with a single adult (not necessarily the parent) known as an escort. This adult feeds its escorted pup, but also carries, grooms and protects it from predators. Some adults are diligent escorts, others less so, or choose not to escort a pup at all. By controlling for factors such as age, sex, and quality of the territory they live in, the researchers found that the care each adult gives varies considerably, suggesting that stress hormone levels may be the cause. This research is possible because of a 20 year long research project on banded mongooses living wild in Queen Elizabeth National Park in Uganda, following the lives of individual mongooses from birth to death. All the mongooses in the study are accustomed to the presence of researchers, so observers can stand just metres away and still be ignored by their subjects. They have even been trained to step onto portable electronic scales so that they can be weighed and body condition monitored – essential for a study such as this one. Hormone levels are monitored by collecting and testing their droppings. The quality of care provided by escorts could have a huge effect on their pups: pups with good escorts get more food, grow faster and are more likely to survive than those with poor escorts. This stretches into adulthood, as better escorted pups start breeding earlier and so may have greater evolutionary fitness. The results of this study don’t only apply to mongooses, but are likely to apply to other species too (perhaps even humans). Links between stress hormones and reproduction have been shown in other species such as house sparrows. However, species where one or two parents care for offspring may differ from banded mongooses in their response to stress. For bi-parental species, stressed females may lead to smaller broods or litters, smaller eggs or young, or a reduced chance of conceiving. In contrast, carers in cooperative breeding species may have little ability to control what happens prior to the birth of the litter – instead stressed carers are limited to varying the care they give their pups. These effects may also apply to humans. Stress hormones have been shown to interfere with the human ovulatory cycle. However, the complexities of the presence of siblings of different ages, different needs, and the many ways in which parents care for their children would make studying this effect in humans extremely difficult."
"**Most of England is expected to be placed in the two toughest tiers of coronavirus restrictions when the national lockdown ends next Wednesday.**
Health Secretary Matt Hancock will set out the plans in the Commons later.
BBC political editor Laura Kuenssberg said she understood only a ""handful"" of areas would have the lowest level of restrictions, tier one.
Most areas, including London, would be in tier two with ""significant numbers"" in tier three - the highest level.
Differences between the tiers include limits on where households can meet up - for instance, in the new tier one, the rule of six applies indoors and out. In tier two, the rule of six remains outdoors but there is no household mixing indoors.
Chancellor Rishi Sunak told BBC Breakfast the new tiers represent a ""tangible change compared to the last four weeks"" of lockdown in England.
""There are significant differences to that - more of our life can resume, more of our economic activity can resume,"" he said.
The system will be regularly reviewed and an area's tier level may change before Christmas - the first review is scheduled for 16 December.
Decisions on tiers are based on public health recommendations informed by the following factors:
An area could be moved up a tier if these indicators are not improving, and likewise down to a lower one if they improve.
Mr Sunak said a meeting of the Cabinet would consider the new tiers on Thursday morning, before Mr Hancock addresses the Commons.
The final decisions will be made by Prime Minister Boris Johnson, the government said. He will lead a Downing Street news conference later.
The new system will be stricter than the previous one and more local authorities will be in higher tiers.
Mr Hancock has urged people to follow the rules so ""together we can get out of these tough measures"".
""I know for those of you faced with tier three restrictions this will be a particularly difficult time but I want to reassure you that we'll be supporting your areas with mass community testing and extra funding,"" he said.
Areas placed in tier three will be eligible for rapid or ""lateral flow"" tests - which give results in about 20 minutes without the need for a lab - to help bring down infections and reduce restrictions.
And they will be offered support by NHS Test and Trace and the armed forces to deliver a six-week rapid community testing programme.
Tier allocations will be reviewed for the first time by 16 December, allowing for ""the possibility of areas which continue to make progress in slowing the spread of the disease"" to be moved down a tier before Christmas, the government said.
On Wednesday, the government recorded another 696 UK deaths within 28 days of a positive Covid test, the highest daily figure reported since 5 May. Total deaths now stand at 56,533.
A further 18,213 lab-confirmed cases of coronavirus were also reported.
It is clear the government is taking a tougher approach to regional tiers post lockdown.
Not only has it beefed up the system - the top two tiers in particular have stricter rules for hospitality - but very few local authority areas will end up in the bottom tier with the most relaxed restrictions.
By the time England went into lockdown 170 local authority areas - well over half - were still in tier one, meaning mixing indoors was allowed.
Very few will start there this time.
That's because an analysis by the University of East Anglia found the bottom tier was not effective at suppressing the virus.
But it did find the top two tiers had an impact.
One of the problems, it said, was that the government was too slow to move areas up a tier when infection rates started to rise.
The government will be much more cautious this time, starting from the premise that it is better to have areas in higher tiers and move them down over time rather than the reverse.
But for the public it means post-lockdown life will still see some very strict restrictions for the immediate future.
London Mayor Sadiq Khan said it would be the ""right and sensible decision"" for the capital to be placed in tier two, as he warned that tier three would be a ""hammer blow"" to businesses.
Liverpool City Region Mayor Steve Rotheram said he hoped the area - which was the first area of England to enter the highest tier in October - would not return to tier three restrictions.
He said the city region had made ""remarkable"" progress since being put into tier three, with infection rates in two areas dropping from about 750 per 100,000 people ""to 180 across the city region"".
Mayor of Liverpool Joe Anderson told BBC Radio 4's Today programme the city's mass testing programme had enabled it to reduce infections.
He said the armed forces have been in the city for three weeks carrying out mass testing and bringing the virus ""back under control again"".
Meanwhile, Greater Manchester Mayor Andy Burnham said it was ""more likely than not"" his area would be put into tier three.
He said although infection numbers in Greater Manchester were still high, the rates were falling.
Elsewhere, Lancashire's council leaders have submitted a proposal to the government to divide the county into two different tiers when the lockdown ends next week - as coronavirus rates are lower in places like Lancaster and Wyre than they are in East Lancashire.
A request has been made for Hyndburn, Rossendale, Burnley, Pendle and Preston to go into tier three restrictions while Fylde, Wyre, Lancaster, Chorley, South Ribble, Ribble Valley and West Lancashire would go into tier two.
This would mean there would be different restrictions on socialising and the hospitality sector in different parts of Lancashire.
Meanwhile, the Nightingale Hospital in Exeter will receive its first coronavirus patients on Thursday, officials have confirmed.
The 116-bed hospital built on the site of a former retail unit will treat people with Covid-19, taking patients transferred from the Royal Devon and Exeter NHS Foundation Trust as it is ""very busy"".
Devolved administrations in Scotland, Wales and Northern Ireland have the power to set their own coronavirus regulations, though all four UK nations have agreed a joint plan for Christmas.
In Scotland, there is a new five-tier system of restrictions and all non-essential travel between Scotland and the rest of the UK is not allowed.
The Scottish government has also said that Christmas bubbles of three households there should contain no more than eight people. Children under 12 are not counted towards the eight.
In Wales, lockdown restrictions were eased on 9 November and current rules allow two households to form a bubble with up to 15 people able to meet for organised indoor activities.
And Northern Ireland will go into a two-week circuit-break lockdown from 00:00 GMT on Friday 27 November."
"**A tougher three-tiered system of local restrictions will come into force in England when the lockdown ends on 2 December, Downing Street has said.**
Boris Johnson is expected to set out his plan - including details of how families can see different households at Christmas - to MPs on Monday.
More areas are set to be placed into the higher tiers to keep the virus under control, No 10 said.
And some tiers will be strengthened to safeguard lockdown progress.
Some local measures will be the same as those in the previous three-tier system, which was in place in England until the current lockdown began.
But the government's Scientific Advisory Group for Emergencies (Sage) is expected to publish research on Monday saying the previous restrictions were not strong enough.
The government will identify the tiers that each area will be placed into on Thursday.
Chancellor Rishi Sunak told the BBC's Andrew Marr the 10pm closing time for pubs and restaurants was one of the things it was looking to ""refine"".
It is understood rules will be relaxed to give people an extra hour to finish their food and drinks after last orders at 10pm.
Kate Nicholls, chief executive of UK Hospitality, said this would help businesses - but would be ""meaningless"" unless people were allowed to socialise with friends and family, particularly over the crucial Christmas period.
Pre-lockdown, there were three tiers of restrictions - medium, high, and very high:
Newspaper reports suggest rules could be temporarily relaxed UK-wide over Christmas. Several families could be allowed to join in one ""bubble"" and mix between 22 and 28 December, according to the Daily Telegraph.
Ministers have made clear the festive season will be different to normal - with some restrictions expected to remain in place.
BBC political correspondent Nick Eardley said conversations about Christmas between the different nations of the UK were ongoing.
Sources believe a deal is probable later next week - but it is unlikely to be signed off before the prime minister's announcement on Monday.
The four nations have different Covid rules but ministers are hoping to agree a joint approach for the festive period.
Government ministers and advisers have been hinting about new tougher tiers over the past week.
Before lockdown there was some evidence that tiers two and three were having an impact, but not tier one.
Crucially, both the top two tiers involved banning mixing inside homes, so one option being discussed behind the scenes is introducing a ban across all the tiers until winter is over.
The exception will, of course, be Christmas.
That is a move that divides opinion. But the government sees it as a necessity, believing significant numbers of people will ignore any attempt to ban gatherings over the festive period.
It is also a recognition the public needs a break from the long hard slog of the pandemic.
Infection rates will of course rise, but that will be offset to some extent by a wider boost to wellbeing.
Prof Calum Semple, from the University of Liverpool, said he hoped it would be possible to relax rules over Christmas if the new tiered system worked but warned ""there will be a price"", including tighter restrictions in the future.
However, Prof Semple, who is a member of Sage, told Sky News's Sophy Ridge there was ""a lot to be optimistic about"".
He said he expected mass vaccination of the general population to happen towards next summer, which would give ""broad immunity"" and allow a ""return back to normal"".
MPs are expected to vote on the new tier system in the days before it comes into force.
Many Conservative MPs are opposed to stricter measures, with 70 signing a letter coordinated by the recently-formed Covid Recovery Group (CRG), saying they cannot support a tiered approach unless they see evidence measures ""will save more lives than they cost"".
Earlier this month, 32 Conservatives rebelled by voting against the current lockdown and 17 more, including former Prime Minister Theresa May, abstained.
In a letter to the prime minister on Saturday, the CRG, led by former chief whip Mark Harper and ex-Brexit minister Steve Baker, warned against inflicting ""huge health and economic costs"".
The letter said: ""We cannot live under such a series of damaging lockdowns and apparently arbitrary restrictions, and expect our constituents to be grateful for being let out to enjoy the festive season, only to have strict restrictions imposed on them afterwards that cause them health problems and destroy their livelihood.""
Asked whether he would publish a cost-benefit analysis of any future measures, as called for by the CRG, the chancellor told Sky News it was ""very hard to be precise"" on the economic impacts of individual restrictions.
Labour has so far supported the need for restrictions to slow the spread of Covid-19, making a Commons defeat on the plan unlikely.
But shadow chancellor Anneliese Dodds told the BBC her party wanted clarity from the government over how tiers would be decided and the support available for businesses.
On Saturday, the UK recorded another 19,875 new coronavirus cases and 341 deaths within 28 days of a positive test.
The number of deaths was down from 511 on Friday, and 462 on Saturday 14 November."
"British Gas has teamed up with Volkswagen to accelerate the rollout of its electric vehicles (EV) across UK roads by helping drivers to charge up at home at a lower price. The UK’s biggest energy company has agreed a three-year deal with the carmaker to offer owners of new electric VW vehicles a one-stop package to help plug into home charging. Under the exclusive agreement British Gas engineers will be responsible for installing the fastest home car-charger available, alongside an energy tariff that offers cheaper rates for nighttime charging. The tie-up could help make it easier for drivers to switch to an electric VW vehicle, and may also provide a new earnings stream for the embattled energy supplier, which fell to an all-time low last year. Alex Smith, the managing director of Volkswagen UK, said 2020 would be a “landmark year” for group, after launching the ID.3 model. It plans to produce 330,000 vehicles a year by 2021. The cars are capable of travelling for 205-340 miles on a single charge, and Smith believes the deal with British Gas could “give customers even more confidence, as they make the switch to emission-free driving”. The collaboration could help British Gas fend off rising competition from a string of challenger brands by relying more on energy services such as boiler repairs, insurance cover and home car charging to generate revenue. The agreement with VW comes less than a year after the owner of British Gas, Centrica, struck a deal with Ford to market its car chargers and EV-charging tariffs from US carmaker’s forecourts across the UK. A similar strategy is being pursued by Ovo Energy, the UK’s second-largest energy supplier, and Scottish Power, which have both collaborated with Nissan on small-scale deals to help install compatible home chargers for its Nissan Leaf model. Centrica is under pressure to prove to shareholders that its strategy will pay off, after reporting a loss of more than £1bn for 2019, after the government’s energy price cap cut earnings at British Gas to all-time lows. The chief executive, Iain Conn, is to step down this year and the company is yet to announce a successor. Sarwjit Sambhi, the head of Centrica’s consumer business, said it was committed to finding “a pathway for the energy transition”, which is in line with the Paris agreement by “helping our customers reduce their emissions, reducing the emissions of the energy system as a whole, and reducing our own”. “We made material progress on all of these during 2019 and are committed to a plan for delivering net zero by 2050,” he said."
"It is a global emergency that has already killed on a mass scale and threatens to send millions more to early graves. As its effects spread, it could destabilise entire economies and overwhelm poorer countries lacking resources and infrastructure. But this is the climate crisis, not the coronavirus. Governments are not assembling emergency national plans and you’re not getting push notifications transmitted to your phone breathlessly alerting you to dramatic twists and developments from South Korea to Italy. More than 3,000 people have succumbed to coronavirus yet, according to the World Health Organization, air pollution alone – just one aspect of our central planetary crisis – kills seven million people every year. There have been no Cobra meetings for the climate crisis, no sombre prime ministerial statements detailing the emergency action being taken to reassure the public. In time, we’ll overcome any coronavirus pandemic. With the climate crisis, we are already out of time, and are now left mitigating the inevitably disastrous consequences hurtling towards us.  While coronavirus is understandably treated as an imminent danger, the climate crisis is still presented as an abstraction whose consequences are decades away. Unlike an illness, it is harder to visualise how climate breakdown will affect us each as individuals. Perhaps when unprecedented wildfires engulfed parts of the Arctic last summer there could have been an urgent conversation about how the climate crisis was fuelling extreme weather, yet there wasn’t. In 2018, more than 60 million people suffered the consequences of extreme weather and climate change, including more than 1,600 who perished in Europe, Japan and the US because of heatwaves and wildfires. Mozambique, Malawi and Zimbabwe were devastated by cyclone Idai, while hurricanes Florence and Michael inflicted $24bn (£18.7bn) worth of damage on the US economy, according to the World Meteorological Organization. As the recent Yorkshire floods illustrate, extreme weather – with its terrible human and economic costs – is ever more a fact of British life. Antarctic ice is melting more than six times faster than it was four decades ago and Greenland’s ice sheet four times faster than previously thought. According to the UN, we have 10 years to prevent a 1.5C rise above pre-industrial temperature but, whatever happens, we will suffer. Pandemics and the climate crisis may go hand in hand, too: research suggests that changing weather patterns may drive species to higher altitudes, potentially putting them in contact with diseases for which they have little immunity. “It’s strange when people see the climate crisis as being in the future, compared to coronavirus, which we’re facing now,” says Friends of the Earth’s co-executive director, Miriam Turner. “It might be something that feels far away when sitting in an office in central London, but the emergency footing of the climate crisis is being felt by hundreds of millions already.” Imagine, then, that we felt the same sense of emergency about the climate crisis as we do about coronavirus. What action would we take? As the New Economic Foundation’s Alfie Stirling points out, a strict demarcation between the two crises in unwise. After all, coronavirus may trigger a global slowdown: the economic measures in response to this should be linked to solving the climate crisis. “What tends to happen in a recession is policy-makers panic about what the low-lying fruits are; it’s all supply chains and sticking plasters,” he tells me. During the 2008 crash, for example, there was an immediate cut in VAT and interest rates, but investment spending wasn’t hiked fast enough, and was then slashed in the name of austerity. According to NEF research, if the coalition government had funded additional zero-carbon infrastructure, it would not only have boosted the economy but could have reduced residential emissions by 30%. This time round, there’s little room to cut already low interest rates or boost quantitative easing; green fiscal policy must be the priority. What would be mentioned in that solemn prime ministerial speech on the steps of No 10, broadcast live across TV networks? All homes and businesses would be insulated, creating jobs, cutting fuel poverty and reducing emissions. Electric car charging points would be installed across the country. Britain currently lacks the skills to transform the nation’s infrastructure, for example replacing fuel pumps, says Stirling: an emergency training programme to train the workforce would be announced.  A frequent flyer levy for regular, overwhelmingly affluent air passengers would be introduced. As Turner says, all government policies will now be seen through the prism of coronavirus. A similar climate lens should be applied, and permanently. This would only be the start. Friends of the Earth calls for free bus travel for the under-30s, combined with urgent investment in the bus network. Renewable energy would be doubled, again producing new jobs, clean energy, and reducing deadly air pollution. The government would end all investments of taxpayers’ money in fossil fuel infrastructure and launch a new tree-planting programme to double the size of forests in Britain, one of Europe’s least densely forested nations. There is a key difference between coronavirus and climate crisis, of course, and it is shame. “We didn’t know coronavirus was coming,” says Stirling. “We’ve known the climate crisis was on the cards for 30 or 40 years.” And yet – despite being inadequately prepared because of an underfunded, under-resourced NHS – the government can swiftly announce an emergency pandemic plan. Coronavirus poses many challenges and threats, but few opportunities. A judicious response to global heating would provide affordable transport, well-insulated homes, skilled green jobs and clean air. Urgent action to prevent a pandemic is of course necessary and pressing. But the climate crisis represents a far graver and deadlier existential threat, and yet the same sense of urgency is absent. Coronavirus shows it can be done – but it needs determination and willpower, which, when it comes to the future of our planet, are desperately lacking. • Owen Jones is a Guardian columnist"
"The UK faces the possibility of blackouts due to electricity shortages in the near future – maybe even this winter. The country therefore needs a strong balanced mix of traditional and renewable energy more than ever.  As Scotland generates more electricity than it uses, most of these potential blackouts will be in England. Therefore it is all the more puzzling that the UK government has failed lamentably to ensure adequate support for offshore wind.  For a windy island nation, offshore wind power generation is vital; it not only complements traditional generation methods but does so in a more sustainable way. And yet projections have been significantly scaled back: UK government estimates of expected offshore wind generation by 2020 have gone from 18 gigawatts (DECC, back in 2012) down to just 10 GW (Crown Estate, June 2014). This short-sighted approach has seen many projects in Scottish waters being mothballed or cancelled altogether in the past couple of years. RWE, Scottish Power, Centrica and SSE – four of the UK’s “big six” energy suppliers – have all dropped out of new wind projects in the past year. The latest casualty is the French behemoth Technip which is withdrawing from offshore wind-power production in Scotland with a possible loss of 190 jobs. The cancellations have been caused by a variety of issues – political will, challenging ground conditions, potential environmental impacts. These factors combine to affect the economic viability of new wind farms. Accessing finance for these large, capital-intensive projects is a major challenge and investors don’t want to put their money into a sector with an uncertain future.  This is the worst of both worlds: fewer wind farms than expected, which in turn may be insufficient to drive costs down to the target of £100/MWh for offshore wind. It is at this rate the industry is viewed to be commercially viable – and innovative companies across the industry such as Technip have already made significant efforts to deliver wind power this cheaply. Government policy could address this but the coalition’s flagship initiative – Electricity Market Reform (EMR) – is in a state of disarray and has led to a hiatus in offshore wind investment. The pot of government money available does not appear to be sufficient to fund new and very expensive nuclear plants at the same time as offshore wind. Wind has been the sacrificial lamb, in favour of the Conservatives’ ideological preference for nuclear power. Under the coalition, the UK renewables programme faces stagnation, despite stronger public support for renewable energy over the nuclear option. What is particularly disappointing about the Technip announcement is that the company’s prior experience in building oil and gas rigs could have been useful in the development of floating offshore wind farms, which offer great potential for cost reduction and exploitation of wind resources further from shore in deeper water.  However, it’s clear that Technip just can’t see continued involvement as a good deal and this is of concern to the wider industry. After all a healthy supply chain depends on a succession of new offshore wind projects to stimulate demand and investment. Scots may have voted No to independence but the debates over devolution and powers to set policy aren’t going anywhere. An increased voice for Scotland on its energy policy may not come a moment too soon for offshore wind and national energy security, even if that nation is the UK."
"**There have been more than 1.6 million confirmed cases of coronavirus in the UK and about 60,000 people have died, government figures show.**
However, these figures include only people who have died within 28 days of testing positive for coronavirus and other measures suggest the number of deaths is higher.
**Find out how the pandemic has affected your area and how it compares with the national average:**
If you can't see the look-up click here.
After the first peak in April, cases started rising again in July, with the rate of growth increasing sharply in September and October, before falling again in the past two weeks.
On Wednesday, the government announced a further 16,170 confirmed cases.
It is thought the infection rate was much higher during the first peak in spring, but testing capacity at the time was too limited to detect the true number of daily cases.
The data for cases can also be broken down by region and comparing the change in those figures by week gives a sense of where there has been a recent increase in newly-reported infections.
Coronavirus infections in England have fallen by about a third during lockdown, according to a major study carried out by Imperial College London.
While some of the worst-hit areas saw the biggest improvements, cases have remained relatively high across England, according to the React-1 study, which is based on tests of more than 100,000 people between 13-24 November.
The latest figures from the Office for National Statistics (ONS), suggest about one in 185 (16,400 people) in Wales had the virus in the week ending 21 November.
In Northern Ireland rates are thought to be decreasing at around one in 145 people (about 12,700 people), while in Scotland, the figure was one in 115 (about 45,700 people).
The average number of daily deaths began to rise again in September, following the first peak in April.
On Wednesday, the government announced a further 648 deaths.
Of these, 555 deaths were in England, 51 in Wales, 38 in Scotland, and four in Northern Ireland.
Rules were amended over the summer to include deaths in the coronavirus total only if they occurred within 28 days of a positive test. Previously in England, all deaths after a positive test were included.
England has seen the majority of UK deaths from Covid-19. Using the 28-day cut-off, there have been more than 52,000.
Although hospital admissions for Covid-19 remain below the levels seen in the spring, there are big regional disparities.
The North West, North East and Yorkshire, and Midlands have seen the highest number of admissions but the situation in all three now appears to be improving.
Cases have risen across large parts of England, with other spikes in areas of Scotland, Wales and Northern Ireland.
The red areas on the map below are those currently seeing the highest number of cases per 100,000 people.
Restrictions have been tightened across the UK in an effort to tackle the number of rising cases.
In England, each local authority has been placed in one of the new three tiers following the end of the recent national lockdown.
Wales has announced a range of further measures, including a ban on pubs, restaurants and cafes serving alcohol, from Friday 4 December.
In Northern Ireland, a further two-week ""circuit-break"" lockdown began on 27 November.
Scotland has a five-tier system of alert levels with different measures in place in different parts of the country.
UK leaders have agreed to allow up to three households to meet indoors during a five-day Christmas period of 23-27 December.
When looking at the overall death toll from coronavirus, official figures count deaths in three different ways.
Government figures count people who died within 28 days of testing positive for coronavirus.
But there are two other measures.
The first includes all deaths where coronavirus was mentioned on the death certificate, even if the person had not been tested for the virus. The most recent figures suggest there had been almost 70,000 deaths by 20 November.
The second measure counts all deaths over and above the usual number at the time of year - that figure was more than 75,000 by 20 November.
The most recent figures available from the ONS are for the third week of November, which show there were 14,276 deaths registered in the UK.
Some 3,038 of these deaths involved Covid-19 - 199 more than the week before.
Deaths normally do rise at this time of the year, but the data from the ONS and its counterparts in Scotland and Northern Ireland show the second wave of the virus has pushed the death rate above the average seen over the past five years by about 21%.
Overall, the figures are still well below the peak of 9,495 deaths recorded in a week, reached on 17 April.
The ""R number"" is the average number of people an infected person will pass the disease on to.
If R is below one, then the number of people contracting the disease will fall; if it is above one, the number will grow.
The government's current estimate for the R number across the whole of the UK is 0.9 to 1.
The estimate for England is 0.9 to 1, while for Scotland it is 0.8 to 1. The estimate for Wales is 0.8 to 1 and in Northern Ireland it is 0.9 to 1.1.
The government has said in the past that the R number is one of the most important factors in making policy decisions."
"
Share this...FacebookTwitterAll the green jobs of the future that were promised – have now turned into dashed dreams. On the scrap heap along with the promises of communism, redistribution, third ways, etc.
FOCUS magazine here brings us up-to-speed on the trials and misery of Germany’s much maligned solar industry. The situation is worse than we thought.
It’s in a rapid death spiral, and it has claimed its latest victim: Solarhybrid AG. Last Tuesday evening, just a few dozen months after the company went public in 2008 amid the usual hoopla, it announced that it is bankrupt and is now seeking protection from its creditors. The sunny days are gone.
Solarhybrid’s collapse follows on the heels of Solon and Solar Millennium, who also recently went bust. The great German solar energy bubble has popped. With the current feed-in rates ending on April 1st, set to drop another 20%, the real monster crash still remains to come.
Solarhybrid was a specialist for large solar power plants, and was even optimistic about the future just as recently as October 2011. I bet the investors who jumped on board in October are really amused.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The German solar industry suffers from severe global over-capacity and falling government subsides, without which they can’t compete. Yet it should not be a surprise that it has come to this. Half of the world’s solar power generation capacity is installed in Germany, a country that gets as much sunshine as Alaska. It was only a matter of time before the reality of economics caught up. So far Germany has committed over €100 billion in solar subsidies over the next 20 years – for a power source that will hardly make a dent.
Other German solar companies such as giants Conergy und Q-Cells are beginning their death throes. Even once bullish Solarworld director Frank Asbeck, the die-hard optimist of the industry, is warning of really tough times ahead (emphasis added):
If the subsidy reductions continue, the entire branch will be forced to sell its products below cost. We can’t take this very long,’ he said Tuesday regarding the solar subsidy reductions. In the entire branch there is not a single company that is in the black. The same is true for Chinese manufacturers.”
If that doesn’t sound awful enough, then read what Klaus-Dieter Maubach, Technology Chairman at power giant Eon, is quoted as saying to Bloomberg (emphasis added):
In view of the competition from China, Germany’s solar industry will disappear completely within 5 years. Not a single employee will be working for a German solar company, because by then they will all have gone bankrupt.”
 
Share this...FacebookTwitter "
"England’s green belts have had, and continue to have, a major impact on town planning. The idea of a ring of countryside surrounding an urban area to prevent sprawl originated in the 1930s and spread to post-war London and was adopted nationally in 1955. Today, about 13% of England is green belt land. But what made sense in the 1950s seems outdated and rather stale now. A one-size-fits-all approach to tackling complex planning issues tends to create more problems than it solves. You don’t need a belt-shaped area of land to check urban sprawl; you don’t need to block all development to promote greener outcomes. Perhaps in the 21st century it is time to admit that green belts are no longer fit for purpose. In theory, the idea of green belts still has strong protection within the government’s planning framework, within five strategic purposes under local authority control: But green belts have been attacked by a range of vested interests for failing to meet these purposes, with different ideas proposed in response. The head of Persimmon housebuilders, for instance, has called for a relaxation of green belt controls to ease the housing crisis. The chancellor wanted more imagination from local planning authorities in where houses are built – including possible incursions into the green belt.  Natural England, the government body responsible for safeguarding England’s natural environment, has previously called for a major policy rethink. In any case green belt protection is potentially illusory.  Greenfield sites (including green belt) are increasingly favoured by developers as they are cheaper to exploit than brownfield sites which have much higher transaction costs. Here economic growth priorities and national planning policy tends to push development pressures onto the urban fringe areas rather than more costly brownfield land.  There is clear evidence that while green belts have stopped urban expansion (for some cities), they have resulted in unintended consequences such as higher-density development at the urban fringe, including disconnected “edge cities”, and “leapfrogging” development over the green belt to undermine other areas of countryside. Green belts have a presumption against development and thus little incentive to be positively managed for environmental, community or economic purposes. This leads to degraded landscapes that, while having a valid planning function, produce limited benefit to communities and the environment – unless of course you are lucky enough to live in or next to one. As with natural assets more generally, the lack of incentive for active management is the greatest cause for concern.  It’s time for a fundamental rethink of the green belt. The “belt” metaphor has had its day. We should define bespoke areas that are functional to local geography and the needs of the cities and towns concerned; so wedges, fingers, belts, bananas or whatever shapes may equally apply. Rather than have green belts used for just major cities we should have a more inclusive, ubiquitous and positive zoning that applies to large towns and major settlements. Rather than a impose a rigid presumption against development we should aim for zones that encourage innovative uses that generate investment in environmental and community benefits in keeping with the principles of sustainable development. Finally, rather than enabling politically convenient incursions into the green belt under the guise of sustainable urban extensions, local planning authorities should define these zones set against the long-term development needs of the area looking 50 years into the future rather than the present 25 years. These principles lead me to propose the idea of “green investment zones”; new positive spaces to invest in. Thus the urban fringe can be rejuvenated by, for example, community food-growing initiatives for health and recreation or wetland creation for flood protection and biodiversity. A green investment zone would be flexible enough to incorporate whatever new initiative an entrepreneur might propose.  Local planning authorities will need to think strategically set within bolder and long term visions about the kind of town or city they want to create. The current 25-year planning lifecycle is not long enough.  Developers shouldn’t see these zones as automatic no-go areas. While housing should not be normally be allowed in them, they act as valuable green spaces that can help to protect new and existing housing development from floods and drought;  they can provide local food growing areas and spaces for play and recreation. They also can be used to protect our agriculture and perhaps more controversially for energy production (solar, anaerobic digestion or biomass) which are neglected planning factors.   In this green belt debate we need to move out of the silo thinking that separates housing, industry, transport, community, landscape and environment needs leading to disintegrated development. The green belt may no longer be fit for purpose but it must not be allowed to become a developers’ charter for just the short-term pursuit of economic growth. We need to create a more equitable and environmentally and socially responsible zoning tool that addresses current planning shortfalls and promotes a more positive image for planning."
"Protests against a proposed waste incinerator power plant involving thousands of residents took place in southern China over two weekends in mid-September.  The demonstrations, in Boluo county, Guangdong province, were the largest yet against a project that has caused numerous smaller demonstrations since its environmental impact assessment was formally released two years ago. A government plan detailing the likely site for the plant was released in June this year, increasing opposition to the proposal. Investment in waste incinerators is seen as a solution to the inability of China’s infrastructure to handle the mountains of trash the country produces. The number of incineration projects has risen steadily and by last year between 15% and 20% of the country’s household waste was burned. The government intends to double this to 35% by 2015. As in Boluo, many of these projects also double as power generation plants. On the surface this seems ideal for a country that is not only the world’s largest consumer of energy but also its largest producer of rubbish, at about 300m tonnes per year. Because they generate power, the enthusiasm for waste incineration plants is also driven by financial incentives. One 2012 analysis said such plants could earn profits for up to 22 years. The Gao’antun plant in Beijing, the report said, earns up to US$16m from electricity sales annually. But this energy source comes with other costs – and waste incinerator plants are meeting growing resistance. Based on my social media analysis, at least 20 projects have sparked protests across China over the past three years, although the actual number may be even higher. Protesters’ primary grievance is pollution. In Boluo, residents fear that emissions will cause cancer and that the local water source, the Dongjiang River, would be polluted. Their concerns are warranted. Globally, the environmental impact of incinerators is somewhat debatable. In Sweden, where the government has said 99% of all household waste is recycled, of which 50% is burned at waste incineration plants to produce energy, the plants are not controversial. But in the US, proposals for new plants face significant hurdles due to opponents who argue they may worsen air pollution and harm recycling efforts. Even if there was a consensus that such projects in well-regulated environments are safe, “well-regulated” is not guaranteed in China. Many of the country’s waste incinerators are built to extremely low standards and are run by operators who fail to properly dispose of toxic by-products. And while some facilities may be installed with the proper air-pollution control systems, these are expensive to operate and many plants do not use them. As a result, Chinese waste incinerators might serve no purpose other than to trade one waste pollution problem off for another. In response to the recent protests, Boluo officials promised to listen to public opinion and have allowed the public three months to suggest alternative locations. However, because local residents have opposed the plant since the first public consultation period in November 2012, it seems unlikely that the new process will change things significantly. Officials have offered guarantees to residents that the proposed plant at Boluo will be safe but residents question the government’s honesty, a situation that is indicative of a much wider issue in China: a fundamental lack of trust in officialdom. For environmental protests, much of the distrust toward government claims stems from a lack of transparency on the controversial projects. The central government at least recognises transparency is an issue, and vice environmental minister Li Ganjie has called on local authorities to share more information with the public.  However, such “sharing” is only effective if the information is truly transparent. Boluo officials have arguably released enough information regarding the project and have gone through the motions of a public consultation process, but locals still do not trust the government’s word. Added to this is the issue of conflicting environmental priorities between central and local government. For the central government, maintaining social stability is closely linked to the Communist Party’s legitimacy, whereas local government officials tend to prioritise social stability when it impacts on economic stability. Therefore local governments have a strong incentive to push ahead with controversial projects if they can rely on them as even a short-term source of revenue. The ongoing events in Boluo, and similar protests elsewhere, are certainly disruptive in the short-term but their long-term effectiveness is more questionable. Even if protesters succeed in forcing a project’s suspension, they rarely force an outright cancellation. In the end the Boluo project may be relocated, possibly to an area where equally disgruntled villagers have less power. A solution of sorts, but one that leaves the fundamental issues unresolved. The only way to persuade the public that projects such as waste incinerators do not pose environmental and health hazards is to start meeting higher standards. Perhaps this process has already started. In January this year, the government released revised emissions standards for major industries, including pollution control at municipal solid waste incineration plants. Even so, this may not be enough to undermine unrest. Until China’s local governments prioritise the environment and social stability over short-term economic gain, the problems will persist and the proliferation of environmental protest will likely continue."
"Nick Stern is back with another report on climate change – colloquially known as Stern 2.0. It’s another offering from the Global Commission on the Economy and Climate. Since his 2006 review, Stern has been regularly in the news, claiming climate change is worse than we thought. The new report fits the mould. The summary was released before the main report and we are invited to believe its findings without inspecting the evidence. It seems, though, that Stern has produced another far-fetched piece of work.  The new report makes three claims, none of which stand up: that climate policy stimulates economic growth; that climate change is a threat to economic growth; and an international treaty is the way forward. “Well-designed policies … can make growth and climate objectives mutually reinforcing,” the report claims. The original Stern Review argued that it would cost about 1% of global GDP to stabilise the atmospheric concentrations of greenhouse gases around 525ppm CO2e. In its report last year the Intergovernmental Panel on Climate Change (IPCC) put the costs twice as high. The latest Stern report advocates a more stringent target of 450 ppm and finds that achieving this target would accelerate economic growth. This is implausible. Renewable energy is more expensive than fossil fuels, and their rapid expansion is because they are heavily subsidised rather than because they are commercially attractive. The renewables industry collapsed in countries where subsidies were withdrawn, as in Spain and Portugal. Raising the price of energy does not make people better off and higher taxes, to pay for subsidies, are a drag on the economy. Climate policy need not be expensive. Study after study has shown that it is possible to decarbonise at a modest cost and Stern has missed an opportunity to point this out.  But low-cost climate policy is far from guaranteed – it can also be very, very expensive. Europe has adopted a jumble of regulations that pose real costs for companies and households without doing much to reduce emissions. What is the point of the UK carbon price floor, for instance? Emissions are not affected because they are capped by the EU Emissions Trading Systems, but the price of electricity has gone up. The subsidies and market distortions that typify climate policy do, of course, create opportunities for the well-connected to enrich themselves at the expense of the rest of society. Perhaps Stern 2.0 mistook rent seeking for wealth creation. The report says that if, in the long run, “climate change is not tackled, growth itself will be at risk.” The new report claims climate change would be a threat to economic growth. The original Stern Review argued that the damage would be 5-20% of global income. In the worst case, we would not be four times as rich by the end of the century, but only 3.8 times. The IPCC reckons Stern 1.0 exaggerated the impacts by a factor 10 or more, while the new Stern report agrees that the old Stern was off by an order of magnitude, but in the opposite direction. Over the past two decades, economists have re-investigated the relationship between economic development and geography. This has not led to a revival of the climate determinism of Ellsworth Huntington – the Yale professor who argued that a nation’s prosperity could be predicted by its location and climate. On the contrary, most research finds that climate plays at most a minor role in economic growth, and that the impact of climate is moderated by technology and institutions. Just consider Iceland and Singapore. Stern 2.0 goes against the grain of a large body of literature. “A strong … international agreement is essential,” the Stern report says, calling for an international treaty with legally binding targets. Albert Einstein defined insanity as doing the same thing over and over again and expecting a different result. Since 1995, the parties to the UN Framework Convention on Climate Change have met year-after-year to try and agree on legally binding targets – and they have failed every time.  The reasons are simple. It is better if others reduce their emissions but you do not. No country likes to be bound by UN rules for its industrial, agricultural and transport policies. The international climate negotiations have been successful in creating new bureaucracies, but not in cutting emissions.  Stern also argues that “[d]eveloped countries will need to show leadership.” The EU has led international climate policy for two decades, but without winning any followers. The broken record that is Stern 2.0 is unlikely to inspire enthusiasm for more expensive energy. The Stone Age did not end because we ran out of stones, but because we found something better: bronze. The fossil fuel age will end when we find an alternative. The current renewables are simply not good enough – except for the happy few who profit from government largesse.  The environmental movement’s aversion to nuclear power and shale gas increases emissions and creates an impression of Luddism, whereas climate policy should focus on accelerating technological change in energy.  The unfounded claims in Stern’s new report do not build the confidence that investors and inventors need to take a punt on a carbon-free future. Exaggeration is great for headlines, but sober analysis is more convincing in the long run."
"**One man has been arrested and 14 people were fined after police were called to deal with house parties and anti-social behaviour in Belfast's Holyland area.**
A crowd of about 50 young people gathered in groups on Agincourt Street shortly after 02:00 GMT on Wednesday, according to police.
They arrested a 23-year-old man for assaulting police and other offences.
Earlier, officers visited two properties where they issued 14 Â£200 fines for breaching Covid restrictions.
A further six people who were in the properties were given formal warnings for breaching the rules about gatherings in private homes.
Ch Insp Gavin Kirkpatrick said it was the second night in a row that police responded to complaints about parties and anti-social behaviour in the Holyland area.
""I am sure many people will have seen the footage on social media showing the appalling behaviour of some people police had to deal with,"" he said.
""Police will robustly challenge and deal with people who are either disregarding the health regulations or engaging in this type of anti-social and criminal behaviour.""
The Holyland is a residential area popular with students and police have been called to the vicinity several times since term started in September to break up house parties.
Ch Insp Kirkpatrick said police patrols in the area have increased again and the PSNI ""will continue to liaise with the universities, colleges and other partners to address this issue"".
""Indeed, where appropriate, the universities and colleges will consider their own sanctions against any students involved.""
The officer added that Holyland residents ""do not want to be kept awake all night with parties, their property damaged, or the area left in a mess by a relatively small group of mainly young adults who are old enough to know better"".
""As huge numbers of people across the country make sacrifices - whether isolating, working from home or having to again temporarily close their businesses to try and prevent the spread of Covid 19 - those who are visiting or staying in this residential area must take responsibility for their behaviour.""
He also appealed to parents and guardians of young people living in the Holyland to ensure that ""they are behaving responsibly""."
"The Aral Sea has reached a new low, literally and figuratively; new satellite images from NASA show that, for the first time in its recorded history, the largest basin has completely dried up.  However, the Aral Sea has an interesting history – and as recently as 600-700 years ago it was as small, if not smaller, than today. The Aral recovered from that setback to become the world’s fourth largest lake, but things might not be so easy this time round. Today, more people than ever rely on irrigation from rivers that should instead flow into the sea, and the impact of irrigation is compounded by another new factor: climate change. Sandwiched between Kazakhstan and Uzbekistan, the Aral Sea is actually a lake, albeit a salty, terminal one. It is salty because evaporation of water from the lake surface is greater than the amount of water being replenishing through rivers flowing in. It is terminal because there is no outflowing river. This makes the Aral Sea very sensitive to variations in its water balance caused either by climate or by humans.  Indeed, the sea has long been a cause celebre in the world of environmental catastrophes, an exemplar of the devastating harm that ill thought-out economic policies can have on the environment. Intensive irrigation of cotton plantations in the deserts of the western Soviet Union prevented water reaching the Aral Sea, leading to the drastically low levels we see today. This in turn meant the highly-salty waters killed off many plants and animals. During early Soviet Union times, the Aral Sea and its fringing wetlands were a significant resource for the fishing industries, agriculture, animal husbandry and fur trapping. But in the 1950s, the extent of irrigated land used for “white gold” (cotton) increased dramatically from 4 million to 8 million hectares, with Uzbekistan becoming one of the world’s largest cotton producers. To feed cotton’s insatiable demand for water, the Karakum Canal was built out of the desert sands and because it was unlined, water losses were extremely high.  During the late 1960s, the amount of water evaporating from the Aral Sea become greater than the amount of water entering the lake, so lake levels declined dramatically in the 1970s and 1980s. More than 75% of the surface area and more than 90% of the lake’s volume has been lost. In 1987-1988, the lake split into two, and the Large and Small Aral Sea basins were created. International efforts have been made to protect the Small Aral Sea through the construction of dams, and this has meant that lake levels here have increased. The Large Aral Sea continued to shrink and subsequently split itself into two basins; a deeper, smaller west Large Aral and a more shallow, but expansive, east Large Aral. And it is this latter basin which NASA images show had dried out completely this summer. The environmental impact of the drying Aral has been devastating. Hundreds of thousands of people have been displaced and hundreds of species have disappeared. Toxic metals and agrochemicals (herbicides, pesticides, insecticides), used to prevent disease and pests from lowering cotton yields, found their way into the sea through its rivers. But because the Aral is a terminal lake, the pollutants were never washed out, and they instead sunk to the bottom sediments. Now these bottom sediments are exposed to the air, they are blown up into the atmosphere as toxic, salty dust storms, which can spread for many hundreds of kilometres causing increased deaths and chronic disease, especially the young. However, lower lake levels have also exposed ancient irrigation systems and mausoleums surrounded by settlements (some remains of which are still under water), built during the late Middle Ages. This means that in certain parts of the Aral, lake levels during 13th-14th century must have been lower.  We still aren’t sure exactly what caused such extreme regression, but a cooler, drier climate played a role. The 13th century Mongol invasion of central Asia also led to the Amu Dar'ya, one of two major rivers that feed the Aral, being diverted to the Caspian Sea. Clearly humans were a major factor in the Aral’s previous dry spell.   By the late 16th century, the Aral Sea started to fill up again, in part because irrigated channels meant the Amu Dar'ya once more flowed into the lake. A key question that remains today therefore is how much of the lake’s current regression is due to intensive irrigation and how much may be due to climate change over the past 50 years. Recent studies suggest only 14% of the shrinking of the Aral Sea since the 1960s was caused by climate change, with irrigation by far the biggest culprit.  Researchers looking at what will happen to Aral Sea levels with global warming over the next few decades have combined several model predictions together and expect net water loss to increase as more evaporation leads to less river inflow. However, if irrigation of the rivers continues, then net water loss will be even greater as river flow into the Aral Sea will essentially cease.  Climate change may be one of the world’s great problems but over-irrigation is at least possible to reverse with the right policy changes. But the two issues together make a disastrous combination. The future for much of the Aral Sea does not look great."
"Tensions at the Greek-Turkish border and the coronavirus show why the European Union needs a climate law that binds member states to net zero emissions by 2050, the EU’s top official on climate action has said. Frans Timmermans, a European commission vice-president who leads on the climate emergency, said the different crises facing Europe underscored the need for a climate law in order not to lose track of reducing emissions. The long-awaited climate law unveiled on Wednesday is the centrepiece of the European Green Deal, a plan to transform Europe’s economy, promised by the European commission president, Ursula von der Leyen, within her first 100 days. “It will be our compass for the next 30 years and it will guide us every step as we build a sustainable new growth model,” Von der Leyen said announcing the law.  Some political leaders have argued that the commission needs to focus on the protection of the EU’s external border, rather than the climate crisis – arguments that Timmermans rejected. “The focus this week should be completely on the happening in Syria, in Turkey and what is happening in Greece, should be on containing the coronavirus and solving it. That’s absolutely a priority,” he said. The climate law was “so important”, because “it allows you to focus on other things without losing track of what you need to do to reach climate neutrality”. “Even if the Eye of Sauron is on something else for a bit, the trajectory to 2050 will be clear,” he said, in a reference to the dark forces in the Lord of the Rings. “Because we discipline ourselves with the climate law.” Speaking to the Guardian and six other European newspapers shortly before the law was published, Timmermans said the proposal was revolutionary because all EU legislation would have to be in line with net zero emissions by the mid-century. Even before the text was officially released, the climate activist Greta Thunberg and teenage school strike leaders across Europe gave a blistering verdict, accusing the commission of ignoring climate science. Thunberg, who is meeting Von der Leyen, Timmermans and the rest of the commission’s top team, described the law as “surrender”. In an open letter, she said it failed to respect the goal of capping global heating at 1.5C above pre-industrial levels – an aspiration the EU signed up to in the 2015 Paris agreement. She repeated that message at a meeting with MEPs on the European parliament’s environment committee on Wednesday. “In November 2019 the European parliament declared a climate and environment emergency,” she said. “You stated that yes, the house is actually burning, this was no false alarm, but then you went back inside, finished your dinner and watched your movie and went to bed without even calling the fire department. “When your house is on fire you don’t wait a few more years to start putting it out, and yet this is what the commission are proposing today.” Earlier at a private meeting with EU commissioners the teenage activist was told by Timmermans that the movement she started was the reason the European Green Deal and climate law exists. European Union leaders in 2019 agreed to reduce greenhouse gas emissions to net zero by 2050, meaning more emissions will be removed than expelled into the atmosphere. The climate law proposed by the European commission makes that 2050 promise legally-binding. If an EU member state fails to make progress, the commission can take it to the European court of justice, which has the power to impose hefty daily fines for non-compliance. The commission, the body that drafts and enforces EU law, describes the draft regulation as revolutionary, because all EU legislation – whether farming, energy or transport – will have to be consistent with the 2050 climate target. Climate campaigners, notably Greta Thunberg who described the law as “surrender”, argue that it does not go far enough to reduce emissions in the next decade – a critical window if the world is to avoid climate breakdown that will come from overshooting the aspiration agreed at the 2015 Paris climate talks to keep warming to 1.5C above pre-industrial levels. The climate law does not include an emissions-reduction target for 2030, although the commission will table a proposal in September. EU governments are likely to object to the powers the commission wants to give itself to propose climate targets for 2035, 2040 and 2045. Under the powerful legal tool of “delegated acts”, the EU executive would be able to set targets with limited input from ministers and MEPs. That could prove tricky with governments and the European parliament, who must approve the climate law before it comes into force.  The climate scientist Jean-Pascal van Ypersele, a former vice-chair of the UN Intergovernmental Panel on Climate Change (IPCC), said the EU was aiming too low and its current targets on reducing emissions set in 2014 were not in line with the 1.5C goal. An IPCC report in 2018 showed that going beyond 1.5C, even by half a degree, would significantly increase the risks of drought, floods, extreme heat and poverty for millions of people. Van Ypersele said the EU should be aiming for carbon neutrality one decade earlier. “If a region as technologically rich, as scientifically rich as the EU is only able to achieve that by 2050 how can you imagine that the rest of the world will do that by the same year? I don’t think it’s very likely.” A dozen EU member states have also voiced reservations about Timmermans’ timetable for proposing an EU climate target for 2030, widely seen as a crucial goal if the world is not to exceed its carbon budget. Timmermans plans to set out the EU’s 2030 goal in September, but the dozen countries argue this is too late to galvanise the rest of the world to make commitments at crucial UN climate talks in Glasgow at the end of the year. The vice-president rejected these arguments, saying his officials needed the summer to do a thorough impact assessment of the 2030 goal. “If the commission were to come out with a not duly assessed number we would have months and months of discussion about a percentage and then the EU would not have a position either.” He said the EU’s 2030 target would be in time for the EU to have a position at the Cop26 talks in Glasgow. Timmermans also voiced confidence in the British government’s preparations for Cop26. Campaigners have been concerned about a shaky start, with the new Cop26 president – the business secretary, Alok Sharma – only appointed three weeks ago, after his predecessor was abruptly sacked. The UK has yet to set out a strategy or timetable for the cconference, widely seen as critical to getting the world back on track with the 2015 Paris goals. This is Europe is a new stream of Guardian journalism that investigates the big challenges that transcend national boundaries, and seeks out the solutions that could benefit us all. These are testing times, and crises are not limited by national borders. But then neither are we.  “The UK has formidable capacities in this area,” he said, adding that Brexit had not created a rift between the EU and UK over climate goals. “Brexit weakens the EU, full stop. And, in my view, weakens the UK, full stop,” he said. “I don’t see any object of discord, or disagreement or confrontation between EU and United Kingdom on this issue, of making a success of Glasgow.” But he is likely to face a tougher response from governments in central and eastern Europe that are wary of rapid action on the climate emergency, especially Poland, which generates 80% of its electricity from coal. The climate law means governments failing to meet targets could be taken to the European court of justice and fined. Timmermans said “the hardest, hardest thing we will have to do” is guaranteeing that the European Green Deal will benefit the whole of society. He said he was angered by claims that tackling climate change was against the poor, while acknowledging that a failure to benefit everyone carried risks. “If we are not able to show that it is done in a fair way more and more people will say no, we will give food to extremist parties, who will try to demonstrate that this is only a plan for Tesla-driving tofu eaters. “But the real victims of the climate crisis will be the poorest people in society. They have no other place to go.”"
"Landslides happen everywhere and in different geological locations. This can be because of flooding, which allows sodden soil to move, or rockfalls and slower, continuous movements of land due to gravity. Landslides are particularly dangerous when they happen without warning, as recently happened in India and Japan. Tens of thousands were killed in the Vargus disaster in Venezuela in 1999. Some places are prone to flooding – even, in the case of India, monsoons – but to know where a landslide will happen or when it might happen we need good tools. Currently equipment to measure landslides includes rain gauges, such as those used in the Chittagong region of Bangladesh, which record levels of rainfall that can then be compared to previous data of levels that triggered a landslide.  But many current systems use point-based sensors, in other words systems that rely on ground plugged devices that are able to monitor only from fixed positions. We’ve been working on a new way of measuring to predict landslides using optical fibres in cables as sensors. When installed, these sensors can permanently monitor changes happening to the land. The system, called Stimulated Brillouin Scattering, uses the interaction of light with acoustic waves. Basically, when the soil undergoes collapse or sliding, the embedded fibre stretches and we detect this. These sensing optical fibre cables can be embedded in shallow trenches in the ground to monitor both large landslides and slow slope movements through the elongation induced in the sensing fibre. If you imagine the land as a body, a distribution of these optical fibre sensors act as the “nerve system”. They have the ability to detect a change of one centimetre over a distance of a kilometre. Being able to measure and track early pre-failure soil movements, it is then possible to detect the signs of an imminent landslide. Unlike these conventional tools, optical fibres make measurements along the whole sensing cable which allows for a  fully  distributed measurement of land deformation. The advantage is the continuous monitoring of large areas with high  accuracy. They can also be used in difficult-to-access places, for example underneath bridges, outside the walls of tunnels, near dams and along pipelines and railways in remote rural areas. These sensors can also be used to cover very large areas (several square kilometres) with a single fibre cable and to pinpoint the location of failure signs. In traditional point-based systems you have to be lucky to place a sensor in the critical position where something happens otherwise you miss the event.  The optical fibres can also be controlled from a remote point, so fibres can be laid and left with no need for regular inspections, while the data is transmitted via wireless or optical fibre networks. They are also cheaper than traditional point sensors because a single fibre does the trick and no in-situ visits are required. Optical fibres have been used to measure creep in road boundaries and to monitor bridges and pipelines. So far, only small-scale tests have been used with regard to landslides. But we believe they could change the way we measure and predict these deadly occurrences."
"**There have been more than 1.6 million confirmed cases of coronavirus in the UK and about 60,000 people have died, government figures show.**
However, these figures include only people who have died within 28 days of testing positive for coronavirus and other measures suggest the number of deaths is higher.
**Find out how the pandemic has affected your area and how it compares with the national average:**
If you can't see the look-up click here.
After the first peak in April, cases started rising again in July, with the rate of growth increasing sharply in September and October, before falling again in the past two weeks.
On Wednesday, the government announced a further 16,170 confirmed cases.
It is thought the infection rate was much higher during the first peak in spring, but testing capacity at the time was too limited to detect the true number of daily cases.
The data for cases can also be broken down by region and comparing the change in those figures by week gives a sense of where there has been a recent increase in newly-reported infections.
Coronavirus infections in England have fallen by about a third during lockdown, according to a major study carried out by Imperial College London.
While some of the worst-hit areas saw the biggest improvements, cases have remained relatively high across England, according to the React-1 study, which is based on tests of more than 100,000 people between 13-24 November.
The latest figures from the Office for National Statistics (ONS), suggest about one in 185 (16,400 people) in Wales had the virus in the week ending 21 November.
In Northern Ireland rates are thought to be decreasing at around one in 145 people (about 12,700 people), while in Scotland, the figure was one in 115 (about 45,700 people).
The average number of daily deaths began to rise again in September, following the first peak in April.
On Wednesday, the government announced a further 648 deaths.
Of these, 555 deaths were in England, 51 in Wales, 38 in Scotland, and four in Northern Ireland.
Rules were amended over the summer to include deaths in the coronavirus total only if they occurred within 28 days of a positive test. Previously in England, all deaths after a positive test were included.
England has seen the majority of UK deaths from Covid-19. Using the 28-day cut-off, there have been more than 52,000.
Although hospital admissions for Covid-19 remain below the levels seen in the spring, there are big regional disparities.
The North West, North East and Yorkshire, and Midlands have seen the highest number of admissions but the situation in all three now appears to be improving.
Cases have risen across large parts of England, with other spikes in areas of Scotland, Wales and Northern Ireland.
The red areas on the map below are those currently seeing the highest number of cases per 100,000 people.
Restrictions have been tightened across the UK in an effort to tackle the number of rising cases.
In England, each local authority has been placed in one of the new three tiers following the end of the recent national lockdown.
Wales has announced a range of further measures, including a ban on pubs, restaurants and cafes serving alcohol, from Friday 4 December.
In Northern Ireland, a further two-week ""circuit-break"" lockdown began on 27 November.
Scotland has a five-tier system of alert levels with different measures in place in different parts of the country.
UK leaders have agreed to allow up to three households to meet indoors during a five-day Christmas period of 23-27 December.
When looking at the overall death toll from coronavirus, official figures count deaths in three different ways.
Government figures count people who died within 28 days of testing positive for coronavirus.
But there are two other measures.
The first includes all deaths where coronavirus was mentioned on the death certificate, even if the person had not been tested for the virus. The most recent figures suggest there had been almost 70,000 deaths by 20 November.
The second measure counts all deaths over and above the usual number at the time of year - that figure was more than 75,000 by 20 November.
The most recent figures available from the ONS are for the third week of November, which show there were 14,276 deaths registered in the UK.
Some 3,038 of these deaths involved Covid-19 - 199 more than the week before.
Deaths normally do rise at this time of the year, but the data from the ONS and its counterparts in Scotland and Northern Ireland show the second wave of the virus has pushed the death rate above the average seen over the past five years by about 21%.
Overall, the figures are still well below the peak of 9,495 deaths recorded in a week, reached on 17 April.
The ""R number"" is the average number of people an infected person will pass the disease on to.
If R is below one, then the number of people contracting the disease will fall; if it is above one, the number will grow.
The government's current estimate for the R number across the whole of the UK is 0.9 to 1.
The estimate for England is 0.9 to 1, while for Scotland it is 0.8 to 1. The estimate for Wales is 0.8 to 1 and in Northern Ireland it is 0.9 to 1.1.
The government has said in the past that the R number is one of the most important factors in making policy decisions."
nan
"More than £200m has been spent on failed waste management projects, according to a scathing report by a cross-party group of MPs. The Public Accounts Committee blamed “lax” and “poorly drafted” public-private funding arrangements. But though MPs are right to criticise these contracts, they fail to oppose the obsession with private finance itself. We shouldn’t be afraid to say it: waste management is simply cheaper and more effective in public hands. The problems date back to Private Finance Initiative (PFI) contracts signed in the late 90s. Under PFI, private businesses stump up the money to build new infrastructure and the public sector pays them back over time. Such schemes have proven controversial and MPs have in the past criticised PFI in roads, hospitals, schools and the London underground, as well as waste management.  In this case, some projects have simply not been finished. For instance the UK government has paid Surrey County Council £124m since 1999, tied to the council’s deal with a contractor to build two waste-to-energy plants. Fifteen years on, these plants have still not been built. And the money? If only waste could be incinerated this easily. The latest report shows how the commercial interest in profitable incinerators can distort policies for dealing with waste, at the expense of recycling and re-use. Waste disposal is rapidly developing and MPs are right to highlight how inflexible these contracts are in the face of such change. Fixed 25-30 year contracts are standard in PFI deals, but they struggle to factor in new technologies and uncertain forecasts of the amount of rubbish produced and the extent of recycling.  But these problems were predictable – and clearly identified by critics of privately financed incinerators. Friends of the Earth warned in 2008 that PFI waste operators were pressing councils to commit to high and growing future waste levels, despite evidence of a levelling-out and even decline. The problems with a proposed PFI waste incinerator in Norfolk, highlighted in the committee report, were very clearly set out several years ago by Chris Edwards of the University of East Anglia. Even waste management firms themselves sometimes admit there is excess incineration capacity across Europe.  The deals nevertheless went ahead, driven by the well-known problem of exaggerated demand forecasts in all kinds of public-private partnerships. Just as road and rail schemes come with excessive traffic forecasts, and new stadiums or sporting events exaggerate their supposed “economic impact”, so proposals for waste treatment plants come with unrealistic consumption projections. Such claims – usually made by consultants with a vested interest – make the projects more likely to be approved.  Exaggeration also raises the level of business guaranteed under PFI contracts – a further incentive. According to a survey by Danish academics, the distortion of forecasts is so consistent and widespread it was only explicable as: systematic misrepresentation, that is, lying … The problem of misinformation is an issue of power and profit and must be dealt with as such, using the mechanisms of transparency and accountability. The UK government was responding to the problems after they emerged, not challenging the projections or the investigating alternative possibilities beforehand. Even the EU, despite its own enthusiasm for uniting the public and private sectors, has proved capable of saying no. Earlier this year, for instance, it refused to subsidise a number of incinerators in the Czech republic where demand couldn’t justify the costs. One obvious solution to the whole financing mess would be for local councils to simply build, own and operate incinerators themselves. However, government credits are only available for PFI schemes, and the committee report is also silent about the option of direct public financing. Local authorities are effectively locked in to public-private deals for waste management if they want to get the benefit of government “PFI credits”. As the MPs report puts it, this “incentivises the use of PFI to construct waste management assets over other options for reducing the amount of waste sent to landfill”. In Sweden, Germany and Denmark, groups of municipalities have built and run incinerators themselves. Some local authorities in the US own their own incinerators too, including at least two in New York state. This reduces and shares risks, but it also erodes potential profits from the market and the dominance of the private companies. No surprises then that the waste-to-energy companies aren’t too pleased – but the European Court of Justice rejected a legal challenge against an inter-municipal incinerator set up by a group of local authorities around Hamburg.  The core reason to build new infrastructure with public funds is financial. It is intrinsically less expensive than PFI or other public-private partnerships and avoids the risk of expensive and inflexible long-term commitments. Even the Republican governor of Alaska – successor to Sarah Palin – has recently scrapped a public-private plan for a bridge in favour of direct government provision, because: “Having the state, rather than a private developer, fund the project could save hundreds of millions of dollars.” The UK, however, remains frozen in its commitment to private operators, in waste and elsewhere – as far as government support is concerned, there really is no alternative. The committee’s report does nothing to change this. It calls for the government to help “improve local authorities’ contracting capability”, but not to develop the capacity to run their own systems. It concludes that 25-30 year PFI contracts are too inflexible, but without acknowledging that the private sector will not build and operate incineration plants without such contracts.  While the report provides further evidence of the need for a break from the political orthodoxy of the past 25 years in order to recreate a mainstream option of direct municipal operations, the PAC itself does not make that break."
"Environmental campaigners say a cocktail night involving the fossil fuel industry and federal politicians represents an “insidious” lobbying effort to undermine climate action. The pro-coal Liberal MP Craig Kelly and Labor’s Joel Fitzgibbon hosted a cocktail event at Parliament House to discuss carbon capture and storage with industry leaders on Wednesday night.  An invite seen by the Guardian was sent out by Kelly and Fitzgibbon, who chair the parliamentary friends of resources, together with representatives of Santos and the carbon capture body CO2CRC. The event is described as a “cocktail event to mark the inaugural meeting of the CO2CRC Carbon Capture and Storage Policy Forum”. That forum features companies such as BHP, Chevron, Coal21, ENI, Exxon, the Global Carbon Capture and Storage Institute, JPower, Shell and Woodside. The invite says the forum aims to “work with governments, industry and other stakeholders” to create “suitable policy settings and a regulatory framework to accelerate the development and deployment of CCS technology in Australia”. “CCS has the potential to create a new wealth-creating industry for Australia, breathe new life into existing industries by reducing carbon emissions, and underpin the development of new energies such as hydrogen,” the invite said. Environment group 350 Australia says the event shows the need to “crack down on the undue influence of lobby groups on our democracy”. The 350 Australia chief executive, Lucy Manne, said the event was an “insidious effort by the fossil fuel lobby to undermine action on the climate crisis”. Manne said carbon capture and storage had proven a “pipe dream of the coal and gas lobby” and diverted millions away from proven renewables. “The climate crisis has been felt across the country this past summer, with communities suffering due to extreme bushfires, drought, floods and heatwaves,” she said. “It’s outrageous that instead of working out how to rapidly transition to the renewable energy future the vast majority of Australians and businesses want, our elected representatives will tonight be sipping cocktails with the coal lobby and discussing how to extend the life of dirty coal-burning power stations.” Such lobbying is generally hidden from the public unless revealed by the media. The Fitzgibbon-Kelly cocktail event was reported in News Corp papers. It does not appear in any of the transparency measures governing lobbying. Federal ministers are also not required to disclose who they have met with, unlike in states like Queensland and New South Wales. “One of the things that we’re calling for is the politicians to pledge for a whole range of transparency reforms so we have much better transparency around donations,” Manne told the Guardian. “We also want more transparency around lobbying. We do have a lobbying register. But it really doesn’t give us a true picture of who’s lobbying our politicians.”"
"
Share this...FacebookTwitterAs it becomes more and more evident that renewable energies such as solar and wind are turning out to be far costlier than ever anticipated, and will do nothing to the climate, the masterminds behind them don’t want to hear it. Now they are going to do whatever it takes to make them work – no matter the cost.
In Germany, BARD company, located in the northern seaport of Emden, has just announced it will lay off its 100 employees at its windmill rotor blade factory. The reason? Lack of demand. Offshore wind companies are hesitating to invest in offshore windparks due the high risks surrounding the technical challenges.
Hat-tip  EIKE, which writes:
Offshore company BARD is closing its rotor blade production in East Friesian Emden. ‘100 employees are impacted,’ said the Chairman of Management Bernd Ranneberg in Emden on Monday.”
So how do you encourage companies to invest in high risk renewable energy projects? Simple – you eliminate their risk. This is what a working group now advises the German government to do: It is the lowly consumers who should pick up the risks and costs for the adventurous business of offshore windparks. The companies investing in them won’t have to worry, and so can dive right in.
Germany daily Die Welt yesterday writes:
To bring the stalled offshore wind power back into gear, the State and power consumers will overtake the risks from the investors. This is the only way of assuring the construction of wind turbines needed for meeting the objectives of the country. The main point is the takeover of the liability risks of the power grid operating companies, which have been the main cause of delay.”
Socializing the risks and costs. Die Welt quotes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




‘To the extent that possible damages cannot be insured despite technical and organisational measures, the compensation for damage is to be socialized,’ says a paper produced by a working group that is represented by power grid companies, windpark operators, and suppliers such as Siemens, as well as the Ministry of Economics. Possible would be an intervention by the federal government, or rolling over all the power grid costs and fees onto the power customers.”
Astronomical costs ahead. As Die Welt writes, there are other costs:
Other possible cost drivers in connection with the energy transformation, such as high buying prices for power from the construction of new power plants, or the rising payments for renewable energies, are not included in the calculation. A study by the Technical University of Berlin summed up the direct and indirect costs of the Renewable Energy Feed-In Act until 2030 and pegged them at € 335 billion.”
Poor Germany. Finally, EIKE writes that the German Federal Power Grid Agency warns that power consumers need to expect “massive power price  hikes.” The German news agency DPA writes:
The reason the necessary expansion of the power grid for alternative energies…the investment range is from about 30 to 47.5 billion euros.”
High prices normally would drive companies out of Germany. But no problem here, too. Large power consumers like industries are exempt from paying high power prices. The entire costs will be borne by the lowly little consumers. The government saw to that last summer. The DPA writes:
Higher costs for consumers were assured by a law called the Power Grid Charge Regulation passed during the summer of 2011, where large power consumers can apply for a discount…more than 1600 applications have poured into the Federal Agency up to now. The discounts or full exemptions have a volume 400 million euros annually – money that will have to be paid by the remaining power consumers.”
Clearly huge costs are in the pipeline for German consumers. Call it fuel for social anger.
Share this...FacebookTwitter "
"When the UK Environmental Audit Committee investigated the issue of protecting our marine environment last month, it concluded that there had been a woeful lack of decisive action from the government so far. The committee, led by the MP for Stoke-on-Trent, Joan Walley, questioned the government’s commitment to introducing Marine Conservation Zones after less than a quarter of the 127 sites recommended by independent project groups were designated as conservation areas. And even in those that were established, there are serious concerns remaining over the adequacy of the enforcement provisions put in place. None of them, for example, ban the use of damaging fishing gear such as trawls and dredges, equipment that causes long-term damage to the sea bed and obliterates fish spawning areas. And as an example of why that’s such an important omission, the paper we’ve published, a scientific study of commercial fishing catches in the English Channel over the past 90 years, reveals the true impact that industrial fishing has had upon marine life. Fish landings from the Channel grew from 9,146 tonnes in 1920 to 50,924 tonnes in 1970, peaking at 177,793 tonnes in 1983 and stabilising around 130,000-150,000 tonnes over the last decade. In that time the amount of cod, haddock and hake dropped from 48% to just 4% of the catch. Sharks and rays fell from 34% of catch in 1920 to 6% in 2010. There’s been a huge decline in what is called white fish, those species that live near the sea bed such as cod, ling, hake and haddock which are prized for their delicious flakes of white flesh. Fish such as halibut that can grow as big as a man, and the common skate have disappeared completely off the southern coast of England and northern France.  When we examine the footprint of mobile fishing gear, like beam trawlers and scallop dredgers, the reason is screamingly obvious – Britain’s sea bed is repeatedly gouged by tonnes of heavy fishing gear. It’s no wonder that the only fish left are tiddlers. Our supermarkets stock cod and haddock freighted in from Iceland and Norway, where fishing with trawls and dredges is banned in coastal waters because of the damage it does to the fishes’ spawning areas. Most of the salmon, bass and bream we eat come from from fish farms, because we simply cannot catch enough of those species in UK waters to meet consumer demand. The ecological balance of the seas around us has changed dramatically. Intense fishing of the English Channel by fleets from all over Europe has wiped out stocks of larger fish, allowing commercially undesirable species – the cockroaches, rats and mice of the sea – to thrive. Perversely, business is booming for the scallop-dredging fleet since scallops have tough shells and thrive in heavily trawled areas. But most of this catch is destined for the export market – it seems crazy to export what we catch and import what we eat. A common misconception, one that is perpetuated by fisheries ministers throughout the European Union, is that there are too many fishermen catching too few fish. The problem is quite the opposite: there are too few fishermen catching too many fish. Large vessels manned by a skeleton crew trawl up vast quantities of sea life, burning fuel that is subsidised by the tax payer. I want to see harbours bustling with small fishing vessels catching delicious food in a sustainable manner. The only way to achieve that is to prevent widespread damaging activities. We know from our own research in south-west England that marine life soon recovers once the use of mobile gear is stopped in inshore waters. If you dive in shallow waters off the Azores or Norway, where the seabed is left alone, the seabed is teeming with life, with small fish that grow up to become the fish that feed the offshore fishing industry and, ultimately, feed us. As Walley concluded: “When a rare species or biodiverse stretch of sea bed is destroyed it may be lost forever. The government must therefore act on the best available evidence and base its decisions on new marine conservation zones on the precautionary principle, rather than demanding unobtainable evidence.” The scientific evidence is in. Now is the time for the government to act. Setting aside areas where marine life can recover makes sense and is the right thing to do."
"The Mediterranean Sea holds some of the most heavily fished waters in the world, and a recent paper has revealed the extent to which the sea – which has 19 nations on its shores – has been exploited.  Academics from the Institute of Marine Biological Resources and Inland Waters in Greece, writing in the journal Current Biology, examined catches of nine species including hake, mullet, anchovy, sardine, sole and turbot from 1990-2010. The decline of the Mediterranean fisheries started much longer ago, but compared to the success of the EU Common Fisheries Policy in reversing the decline of fish stocks in parts of the North Atlantic and North Sea over the same period, current fishing patterns have prevented any recovery. With many stocks in continued decline, the authors argue this “skeleton in the closet” must be addressed, as the social and economic impact of a collapse of Mediterranean fisheries would be immense. The better managed North Atlantic fisheries benefit from three advantages over the Mediterranean. Most important is selecting for adult fish rather than juveniles, as the taking of young fish in the Mediterranean (using a minimum 40mm square or 50mm diamond net, compared with larger than 100mm used in the North Atlantic) is the main cause of over-exploitation. Greater fish species selectivity in the North Atlantic sees fishing concentrated on a few key stocks in specific areas, which minimises the problems of unwanted by-catch found in mixed fisheries. And fishing regulations are generally better implemented and enforced in the North Atlantic than in the Mediterranean.  The focus on large fish, characteristic of small-scale fisheries which are still very important in the Mediterranean, has affected species’ reproductive potential. By hunting only the larger fish, it’s possible to eradicate some of the best genetic material of the species – larger spawners also usually have higher fertility and better egg quality. So the strategy of “fishing for big ones” followed by some fishers in the Mediterranean must be well managed – something which is not yet happening.  For the millions of tourists heading to the Mediterranean in summer, a marine reserve or natural park means a beautiful place where they can enjoy the sea and its creatures during their holidays. But marine reserves are vital for fisheries management too, as they protect the fish inside, providing a safe haven for building up stocks of larvae and adults who then move behind their watery frontiers to replenish stocks elsewhere. Existing marine reserves are mostly coastal but new reserves to protect the deeper waters offshore should be planned. Large spawners – older, strong and fertile fish important for ensuring a strong subsequent generation – often inhabit particular habitats offshore that for many years functioned as refuges, with fishing pressure absent or low. But increasingly even these areas have been exploited, using techniques such as bottom long-lines to reach large fish, such as the hake found in underwater canyons in the Gulf of Lions in the northwest Mediterranean.  At the other end of the lifecycle, young fish also tend to concentrate in particular areas of the seabed. It’s vital to protect spawning grounds (where spawners come to breed) and nurseries (where juveniles concentrate) through the establishment of new Mediterranean marine protected areas. This should be part of an ecosystem-based management approach, together with technical requirements to improve fishing gear and techniques to ensure better selectivity of fish size and species. The small net mesh size used in the Mediterranean leads to a much higher rate of fish discards. The Common Fisheries Policy now aims to reduce unwanted by-catch and consequently reduce discards policy by requiring all catch to be landed. But the ecological benefits of this policy are very doubtful – fish that would otherwise be discarded may end up driving new markets for protein and oil, either for humans or as animal feed. The tide could turn against the discard policy if it provides incentives for fishers to target fish species or sizes that were previously ignored.  A final problem yet to be solved is that fisheries management is based on constraints and quotas set largely in accordance with social and political targets. Yet the seas are subject to ecological forces, many still largely uncontrolled. Unavoidable climate changes will lower productivity of certain stocks and favour others. Any changes we make through ecosystem-based management must maximise benefits today, but only if they don’t damage prospects for the future."
"
Cites nearly half a million dollars in state grant-funded climate research  conducted while [Dr. Michael ] Mann— now director of the Earth System Science Center at  Penn State— was at UVA between 1999 and 2005.
Virgina Attorney General Ken Cuccinelli - Image: Cuccinelli Campaign
From The Hook, it seems satirical YouTube videos will be the least of Dr. Mann’s worries now.
=================
No one can accuse Virginia Attorney General Ken Cuccinelli of shying  from controversy. In his first four months in office, Cuccinelli   directed public universities to remove sexual orientation from their  anti-discrimination policies, attacked the Environmental Protection  Agency, and filed a lawsuit challenging federal health care reform. Now,  it appears, he may be preparing a legal assault on an embattled  proponent of global warming theory who used to teach at the University  of Virginia, Michael  Mann.
In papers sent to UVA April 23, Cuccinelli’s office commands the  university to produce a sweeping swath of documents relating to Mann’s  receipt of nearly half a million dollars in state grant-funded climate  research conducted while Mann— now director of the Earth System Science  Center at Penn State— was at UVA between 1999 and 2005.
If Cuccinelli succeeds in finding a smoking gun like the purloined emails that led to the international scandal  dubbed Climategate,  Cuccinelli could seek the return of all the research money, legal fees,  and trebled damages.
“Since it’s public money, there’s enough controversy to look in to  the possible manipulation of data,” says Dr. Charles Battig, president  of the nonprofit Piedmont Chapter Virginia Scientists and Engineers for  Energy and Environment, a group that doubts the underpinnings of climate  change theory.
…
The Attorney General has the right to make such demands for documents  under the Fraud Against  Taxpayers Act, a 2002 law designed to keep government workers honest.
=================
more at The  Hook
h/t to Chip Knappenberger


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8c158e06',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**Families on Universal Credit face ""agonising uncertainty"" after Rishi Sunak did not confirm what would happen to their benefits next year, campaigners say.**
Universal Credit claimants were given a Â£20-a-week boost in response to the coronavirus pandemic in April.
The temporary rise is due to come to an end in April 2021.
The chancellor did not say whether the increase would be extended, or cut, in his spending review.
Speaking after delivering his statement to MPs, he said the increased payment would continue until next spring.
He added: ""Let's get through winter, see where we are with the virus and what the economy looks and decide then how best to support people.
""Everyone can rest assured we remain committed to making sure we look after the most vulnerable in our society.""
Footballer and anti-poverty campaigner Marcus Rashford tweeted: ""Is the Universal Credit uplift going to be taken away in April?""
Paul Noblet, from youth homelessness charity Centrepoint, said: ""The government's failure to commit to retaining the current uplift in Universal Credit is hugely disappointing and will weigh heavily on the minds of millions of people for whom the Â£20 a week increase has made a huge difference.
""There is still time for the government to reflect on this issue between now and the end of March and we urge them to think again.""
The chancellor set out his spending priorities for the year ahead earlier, warning that unemployment is set to peak at 2.6 million next year, according to the Office for Budget Responsibility.
But he faced criticism from opposition MPs for not mentioning what would happen to benefit rates in his speech.
Labour MP Stephen Timms, chairman of the work and pensions committee, said: ""Millions of people on Universal Credit are now facing the Christmas period in agonising uncertainty, not knowing whether the government will cut their income by Â£20 a week next April.
""Meanwhile, those on older benefits, who have already missed out on the rise because the DWP's systems are too old-fashioned, will receive an increase of just 0.5% next year.
""The government must think again."""
"
The scientist behind the controversial ‘hockey stick’ graph has said it was ‘somewhat misplaced’ to make his work an ‘icon of the climate change debate’. 

From the Telegraph, By Louise Gray,  Environment Correspondent
Professor Michael Mann plotted a graph in the late 1990s that showed  global    temperatures for the last 1,000 years. It showed a sharp rise in  temperature    over the last 100 years as man made carbon emissions also increased,    creating the shape of a hockey stick.

The graph was used by Al Gore in his film ‘An Inconvenient Truth’ and  was    cited by the United Nations body the Intergovernmental Panel on  Climate    Change (IPCC) as evidence of the link between fossil fuel use and  global    warming.

But the graph was questioned by sceptics who pointed out that is it  impossible    to know for certain the global temperature going back beyond modern  times    because there were no accurate readings.
The issue became a central argument in the climate change debate and was     dragged into the ‘climategate’ scandal, as the sceptics accused Prof  Mann    and his supporters of exaggerating the extent of global warming.
However, speaking to the BBC recently, Prof Mann,  a climatologist at    Pennsylvania State University, said he had always made clear there  were “uncertainties”    in his work.
“I always thought it was somewhat misplaced to make it a central icon of     the climate change debate,” he said.
…


Professor John Christy, an atmospheric scientist from the University of    Huntsville in Alabama, said just a quarter of the current warming is  caused    by man made emissions. He said that 10 to 30 per cent of scientists  agree    with him and are fairly sceptical about the extent of man made global    warming.
==========
full story here




			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8af0b419',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterDutch scientist and chemical engineer Dr. Arthur Rörsch has distributed a working paper to Dutch officials in his country to request a comprehensive review of the results and recommendations of the IPCC, especially its upcoming 5th assessment report.H/t: http://www.kaltesonne.de/?p=926:
In his paper Rörsch, former vice-president of the Netherlands Organisation for Applied Research, writes that the IPCC has “deviated from the traditional scientific principles”.  On man-made warming from CO2, he writes “that no indisputable scientific proof, or even strong empirical evidence, has been provided for such an effect, which therefore remains a matter of speculation.”
Read his entire working paper here.
He adds:
These reviews would best be undertaken by senior and established scientists whose reputation rests in the traditional enabling disciplines that underpin climate science, specifically physics, chemistry, geology and meteorology.”
The draft volume for WG1 AR5 is a summary and compilation of papers published in scientific journals up to 2011. Rörsch makes two observations:
– The prevailing hypothesis of the assessment report is that Dangerous Anthropogenic Global Warming (DAGW) is occurring; this hypothesis has been under challenge for many years by numerous independent scientists. These scientists were not invited to participate in the preparation of the AR5 report.
– The scientific literature cited in the draft AR5 is selective towards papers that support the DAGW hypothesis, and even the papers that are included are then selectively analysed towards the same ends. These two underlying biases set the tone of the message that the authors of the AR5 report want to transmit.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Rörsch particularly criticizes the following points:
1. The IPCC assumes that atmospheric CO2 is a dominant forcing agent for global temperature without providing evidence.
2. The report authors are instructed to express their conclusions in terms of a qualitative (i.e. opinion-based) probability scale.
3. The IPCC’s use of “self-appointed experts”.
4. There’s arrogance and intolerance for alternative views displayed by the self-appointed climate experts. These experts should be treated with extreme suspicion.
5. The style of the draft AR5 report marks it as a political rather than a scientific document, for it has been fashioned within the framework of a particular cultural paradigm.
Here’s what Dr. Rörsch concludes:
The IPCC’s draft AR5 report shows insufficient objectivity, and lacks the ‘traditional’ scientific balance necessary for it to be used as the basis for policy making. Regrettably, the report exemplifies some of the worst features of the ‘post-modern’ approach to science…”
 
Share this...FacebookTwitter "
"**Across the UK, three households will be allowed to create a temporary bubble this Christmas.**
All four nations say coronavirus rules will be relaxed for five days between 23-27 December to let families celebrate together.
Each ""Christmas bubble"" can meet at home, at a place of worship or an outdoor public place, but any existing, more restrictive rules on meeting in pubs and other hospitality venues will be maintained throughout the festive period.
There will be no limit to the number of people in a household joining a bubble in England, Wales and Northern Ireland, although the England guidance says it should be ""as small as possible"".
The Scottish government has said that Christmas bubbles can have a maximum of eight people, and should only contain one ""extended household"". Children under 12 will not count in the total.
A bubble is defined as a group of people with whom you have close physical contact.
The aim is to help people who've been cut off from friends and family.
Bubbles must be ""exclusive"". Once in one, you can't start another with a different household.
People in each bubble can stay overnight in each other's homes, visit outdoors places together and do not have to socially distance.
Support bubble counts as one household - which means for the Christmas period that bubble can join with two other households.
In England, single adults living alone - or single parents whose children are under 18 - can form a support bubble with one other household.
The second household can be of any size and can include ""at risk"" people who were previously shielding.
Wherever possible, the government recommends that a support bubble should be with another local household to avoid unnecessary travel. Anyone in the bubble contacted as part of England's test and trace programme must stay at home. If they develop coronavirus symptoms, everyone in the bubble must self-isolate.
Support bubbles have been allowed to continue during lockdown.
From 2 December, when England leaves lockdown and enters a tier system, people will be allowed to form support bubbles with those who live in an area with a higher tier rating.
Bubbles can be cross-border with Scotland and Wales, subject to local restrictions.
The government says it will be expanding the eligibility of support bubbles from 2 December to help families with very young children or people with continuous care needs, meaning households can form a support bubble with another household, if at least one of them has:
As well as the support bubble rules, the government in England also has a set of rules that apply to families with children under 14 (as well as to vulnerable adults).
They can form a childcare bubble with one other household to provide informal (unpaid and unregistered) childcare. This must always be between the same two households. They can provide the childcare in either or both of the homes from the two households.
Over Christmas, registered childcare and childcare bubbles are permitted.
Full government guidelines for England are here.
As of 9 November, two households of any size can form an exclusive bubble and meet in their own homes and gardens.
People in the same bubble can stay in each other's homes overnight. And they can meet up in groups of larger than four in some other outdoor places.
If you have been part of a temporary extended household during the firebreak period, or were in one before that, you are not required to stay in the same extended household. You can make a new bubble, instead. However, once you have agreed and joined that new extended household, neither household can leave to form a new one.
Under the five tier system in Scotland, people who live on their own or only with children under 18 can form an extended household with people from one other household.
This group of people can visit each other's homes and go inside. They do not have to stay 2m (6ft) apart and can stay overnight.
People in extended households are counted as one household, and so can continue to meet and socialise with each other despite general restrictions on households mixing.
Couples who do not live together can also form an extended household, which can include any children they each live with.
A household must not form an extended household with more than one other. However, one of them can end the arrangement at any time, and - as long as they wait at least 14 days - then form a new extended household with someone else.
If any member of an extended household develops symptoms or tests positive for Covid, everyone in the bubble must self-isolate.
Two households of any size can form a support bubble.
The members can spend time indoors and stay overnight with each other.
Under the latest restrictions, these bubbles are limited to a maximum of 10 people, including children, at any one time.
Read more from the Northern Ireland Executive here.
Schools are using year group and/or class bubbles to support social distancing and reduce close contact between pupils as much as possible.
Maintaining distinct groups which do not mix makes it quicker and easier when a positive case occurs to identify those who may need to self-isolate and minimise their number."
"We are inclined to think that trees are a renewable natural resource. Yet precious hardwood trees have already been almost completely logged out from many countries across the tropics. Myanmar is the latest country to experience the insatiable demand for its precious rosewood. Rosewood, also known as bois de rose, is an umbrella term for a whole group of tropical timber species, mostly from the genus Dalbergia, Pterocarpus, Diospyros, and Milletia, which all have a dark red hue and high quality timber in common. The vast majority of rosewood is imported to China where it’s fashioned into luxurious, highly-priced ornamental furniture in the Ming and Quing dynasty style. Myanmar, one of the most important biodiversity hotspots in Asia, has also several species of rosewood highly prized by the Chinese furniture trade. Even though Myanmar’s forest and hardwood stocks have been diminishing for several decades already (less than 10% of the land is now forested, the rosewood logging and smuggling has increased to an unprecedented level in the last three years.  In 2013 alone, Myanmar exported 237,000m3 of rosewood to China, triple the volume of the previous year. This amounts to one thirteenth of the estimated remaining rosewood stock of Myanmar – at current logging rates, Myanmar’s forests will have been stripped of rosewood in just 13 years. As Chinese hunger for the luxuriant, dark red timber grows and spreads across the greater Mekong region, rosewood species might face not only commercial extinction, but also final, biological extinction. It is hardly just the loss of a few species that is at stake. Forest overexploited for timber is likely to lose many species of animals, its ability to absorb carbon dioxide from the atmosphere deteriorates, and it is more likely to experience fires. Logging also brings about more hunting and increases the chances of complete deforestation. In Myanmar illegal logging also brings with it a raft of socioeconomic problems. Loggers undertake long and dangerous scouting expeditions into the forest, or take the risk of timber smuggling in conflict-ridden border regions, such as Kachin at the border with Yunnan province, China – one of the main rosewood smuggling routes. Not every logger returns from these expeditions. Besides the fact that logging in the tropics is rated as one of the most dangerous jobs, there is in Myanmar an added danger of being shot in a timber-related conflict. Moreover, loggers are often rewarded by various stimulating drugs. So why isn’t Myanmar establishing commercial rosewood plantations? Some tropical timber can indeed be mass-produced in plantations, especially faster growing species such as rubberwood, eucalyptus, or teak. But the extremely slow growing, high density rosewood trees take many decades to grow to a commercially viable size, requiring several generations of tree planters to wait for the profit. Such long-term investment is commendable, but unlikely in a conflict-ridden, poor country like Myanmar, with unstable land tenure and an explosive political climate. It is in Myanmar’s interest to completely stop the illegal logging and export of rosewood to China. As almost all processing of Burmese rosewood is done in China, no value is added in Myanmar. Worse still, almost no tax is generated: Myanmar lost an estimated US$6 billion through illegal logging between 2013 and 2014. Instead of the desperately needed cash for healthcare, education, and environmental protection, laundered rosewood money goes to corrupt officials and government cronies. If Myanmar wants to escape its rosewood crisis with at least some viable rosewood populations left, it should take lessons from other countries that have already undergone the “rosewood massacre”. On April 1 this year, the Myanmar government put in place a ban on raw timber export, but without enforcement this cannot be effective. Myanmar has to show its dedication to a permanent, non-negotiable, exception-free rosewood export ban. In Madagascar, we have an example of how temporary and unclear bans only lead to a more dynamic and thriving rosewood black market. During periods of temporary bans, illegal rosewood logging continues, and traders simply accumulate rosewood stockpiles. Meanwhile, rosewood prices go up, stimulating even bigger bouts of logging when the ban is lifted. However, even an effective national ban on rosewood export might not be enough to stop the rosewood crisis in Myanmar. In some cases, a national export ban caused China’s rosewood appetite to shift to a new country.  In other cases, for example Vietnam, China simply grabbed the opportunity of cheaper labour and moved its basic rosewood processing to Vietnam, effectively circumventing the raw timber export ban. This may bring some economic benefit to Vietnam, but does nothing to alleviate the pressure on the forests. Of the 33 species that pass China’s strict hongmu quality standards for rosewood, more than a third is already deemed vulnerable by the IUCN Red List of Threatened species and six are listed by the Convention on International Trade in Endangered Species (CITES). The convention binds signatory countries to regulate or stop trade in the listed species, depending on the degree of protection. Whereas China offers high levels of support to protect its growing rosewood industry, for customers and businesses, it appears to have a complete lack of interest in regulating the industry’s environmental impact or improving its sustainability. Europe, the US and Australia all tightened their regulations regarding rosewood import in recent years. But with Chinese domestic demand growing significantly since 2011, only stricter regulations in China can save Myanmar’s rosewood forests."
"**South Africa, which had one of the world's earliest and strictest lockdowns, is marking a significant shift in its fight against coronavirus, writes BBC Africa correspondent Andrew Harding.**
It was hardly a ""mission accomplished"" moment.
South Africa's President Cyril Ramaphosa looked appropriately dour, and sounded appropriately cautious, as he appeared on national television this week to warn of the dangers of a second wave of infections and to urge the public against relaxing their guard against the virus.
And yet the president's key message was a simple, optimistic and impressive truth.
""We have succeeded in overcoming the worst phase of this epidemic,"" he declared.
As the infection rate here sinks below an important threshold of one new case per day per 100,000 people, South Africa is moving - with relief, and with some pride - into a new phase.
What the president and his scientific advisers describe as ""a new normal"".
With almost all economic activity resuming, the nation's borders slowly opening, and one of the world's earliest and strictest lockdowns ending, this feels like a significant moment - an opportunity to take stock, even to celebrate, and to explore the ever-thorny issue of who, or what, should share most credit for containing Covid-19.
""I had visions of Italyâ¦ that we're not ready, that we're going to get overwhelmed,"" recalled Professor Salim Abdool Karim - chair of the government's Covid-19 advisory panel and the public face of the scientific community - thinking back to March, and to what he and the government publicly warned was an oncoming viral ""storm"".
Instead, very few hospitals were overwhelmed, and the official death toll of some 15,000 is significantly lower than even the most optimistic modelling predicted.
Speaking on an internet link from his office in Durban, Prof Karim does not disguise the relief he feels.
But, like many scientists, his inclination is not to sit back and enjoy the good news, but rather to keep probing and testing hypotheses in order to better understand both Covid-19, and South Africa's response to it.
There is plenty of data to wade through now.
Much of it contradictory. Or rather, much of it still needing to be put in proper context.
Take South Africa's long battle against HIV and tuberculosis.
New evidence suggests TB patients are particularly vulnerable to Covid-19.
But, on the flip side, the systems put in place to cope with both pre-existing diseases, ""assisted us and better prepared us to cope with Covid,"" said Prof Karim.
And while South Africa may have good reason to celebrate its successes, there is plenty to criticise too.
""We've had a pretty bad epidemic,"" said Prof Karim.
""At one stage we were the fifth worst in the world. I wouldn't call that something to be proud of.
""I'd have been really proud if we'd been able to mitigate the impact to a much greater extent.""
As we've reported here in recent months, there have been instances of appalling mismanagement, alarming allegations of corruption, and some grave errors in handling the outbreak.
I will leave the economic impact of the lockdown - and the legitimate debate, enriched by hindsight, about whether the government got the balance right - to another day.
But what of the reasons for South Africa's relative success in fighting the virus?
Prof Karim has drawn up a list of nine factors, or hypotheses, which he applies not just to South Africa, but to other countries - not least on this continent - which appear to have been spared the worst.
Nine theories. But true to form, Prof Karim is not fully convinced by any of them, at least not without further proof.
""I doubt that any one of these is a major contributor that explains the entire difference [of why some countries have done better than others],"" he said.
""Even in combination, these would not explain the bulk of the difference we are seeing. It remains intriguing to me."""
"
Portland police say the masseuse failed a polygraph and the DNA didn’t match (because there was none).

Gore’s aides made a statement:
“Mr. Gore unequivocally and emphatically denied this accusation when he  first learned of its existence three years ago,” spokeswoman Kalee  Kreider said in a statement. “He respects and appreciates the thorough  and professional work of the Portland authorities and is pleased that  this matter has now been resolved.”
From KOIN TV in Portland the story
And another from the Associated Press


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e89dbd19d',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**Two pubs have been linked to a coronavirus outbreak which forced the closure of a number of schools and a college campus in a west Wales town.**
Ceredigion council said 55 new cases in the Cardigan area suggested there was ""significant community transmission"".
The council called on people who attended the Red Lion and Bell pubs on or after 9 November to be vigilant.
The closure of 13 schools in the area was blamed on ""super-spreader events"" such as ""parties"" and ""pub crawls"".
There have been 43 new coronavirus cases in the area in the past week, according to Public Health Wales.
In a statement, the council said its contact tracing team had identified in excess of 300 cases and contacts to date, adding the ""alarming rate of spread"" had affected a number of services in the area.
""We are asking all residents who attended The Red Lion and The Bell Inn public houses on or after 9 November to be extra vigilant and to self-isolate and book a test immediately if you have any symptoms.
""Businesses who have been found not complying with coronavirus regulations have been served with closure or improvement notices and further inspections will continue over the coming days.""
Earlier in the pandemic, Ceredigion council was widely praised for its response, which helped put its death rate second-lowest only to the Isles of Scilly across England and Wales.
But in recent months, the case rate has been creeping up with outbreaks linked to Aberystwyth University and a care home in the town.
Additional testing had been made available at the Fairfield Car Park, Cardigan, which could be booked through the government website or by calling 119.
Both the Red Lion and Bell pubs have been asked to comment."
"The French Ministry of Ecology and Sustainable Energy Development has launched a trial scheme where commuters are paid to cycle to work. For six months, 20 companies with about 10,000 employees between them will offer tax-free payments of €0.25 per kilometre for employees to commute to and from work by bicycle, while data is collected to see what effect the scheme has. While this scheme has gained some attention, some countries already offer bicycle commuter benefits of one sort or another. Similar to the French scheme, employers in Belgium and the Netherlands can offer tax-free payment of €0.22, and €0.19 per kilometre of bike commuting respectively. In Germany commuters biking to work can deduct €0.30 per kilometre from their taxable income.  Other efforts are aimed at providing incentives to buy bicycles. For example, in the UK more than 10,000 companies use the cycle to work scheme that allows employees to purchase bikes using pre-tax income, thereby saving income tax and other deductions on their pay. The German federal government allows employers to offer “company-paid private bicycles” as a benefit to their employees – very much like popular company car programs in various European countries. Other programs subsidise bicycle-related expenditures in general.  In the US, cyclists can deduct a flat rate of US$20 per month from their taxable income for bicycle repair and maintenance. US employers can also provide cash incentives for employees who give up free car parking at work and choose to commute by other means. However, cash paid to non-driving employees is taxable, while the value of free parking is largely in the tax concession. Workplace wellness programs have incorporated bike commuting  as part of a more general recognition of the health benefits of regular physical activity. Some employers in the US, for example, have begun using an electronic tracking system for bike commuters, offering “wellness points” that reduce employee’s health insurance premiums. Increasingly bike-aware employers in Europe and North America also provide facilities such as showers, secure bike parking, and clothes lockers for storage. Despite growing interest in making bike commuting more popular, bicycle-related benefits are typically dwarfed by the benefits offered for travelling by other modes of transport, especially the car. For example, in the US free car parking is the most common commuter benefit offered – only about 5% of US commuters pay for car parking. The value of those free parking spaces at work is typically well above the US$20 a month awarded to cycle commuters. In Germany, drivers can take advantage of the same €0.30 per kilometre commuting deduction as cyclists, plus companies offer company cars. Distances travelled by car are longer than those by bicycle, and the higher values of cars compared to bicycles mean the benefits that accrue to drivers are worth more. A forthcoming study of commuter choice of transport and benefits in the Washington DC region confirms this, finding that available benefits to promote walking, cycling and taking public transport to work were rendered ineffective where there was free parking on offer. Besides the larger value of incentives for commuting by car, another problem with the schemes to promote alternative modes of transport is that employees are often required to choose one type of benefit and can’t claim for a combination of driving, taking public transport or cycling. For example, the new French trial scheme only allows commuters to combine cycling and public transport benefits if the two are regularly used together, for example cycling to a railway station. In the US, employees have to choose only one. A study of mobility policies in Belgium found that driving to work dominated despite incentives for alternative modes, suggesting that allowing the benefits to be combined would help cut car commutes. Perhaps a greater attraction to people thinking of cycling is an investment in facilities at work. For example, a recent study of bike commuting in the Washington DC region found that showers and lockers as well as secure bike parking are significantly correlated with increased cycling to work. Several studies have also found that bike infrastructure, such as dedicated on-street facilities and off-street paths, effectively encourage bike commuting.  So it appears that merely paying people to cycle to work is unlikely to cause a significant shift in their commuting behaviour. For this to happen will require a package of policies, including financial incentives for cycling, disincentives for driving, and investments in infrastructure and facilities, as well as efforts to encourage cycling. The French trial is a step forward in encouraging bike commuting, but by itself it’s just not enough."
"
Guest Post by Willis Eschenbach
Once again, I return to that endless font of misinformation, the Waxman Markey website. In this case, I look at their claims about Alaska. This one will be short and sweet. Their claim is that Alaska is roasting, as in the picture below:

Figure 1. The dessert known as “flaming baked Alaska”. Ice cream covered with meringue, doused with brandy, and set on fire. Sweet.
The Waxman Markey website page on Alaska  says:
Over the past 50 years, Alaska has warmed by 4 to 7 degrees Fahrenheit, much more than anywhere in the lower 48 states.  This dramatic temperature change is causing the landscape of Alaska to change faster than anywhere else in the United States, threatening infrastructure, wildlife, and Native Alaskan culture.
I fear that these numbers must from the well-known Government Misinformation Agency.

Figure 2 shows the real numbers:

Figure 2. Alaskan temperatures, as the average of all first-order stations in the state.
There are a few things we can see here. First, Fig. 1 clearly shows the dependence of Alaska temperatures on the Pacific Decadal Oscillation (PDO). The PDO is a long-term shift in Pacific sea surface temperatures. The PDO has a warm phase and a cool phase, as shown in Figure 3. It shifts from one phase to the other every thirty years or so.

Figure 3. Cool (positive) and warm (negative) phases of the PDO. IMAGE SOURCE
The PDO shifted to the cool phase in the late 1940s. It went back to the warm phase in 1976-77. And recently, it has gone back to the cool phase. This is clearly visible in the Alaska temperatures. As much as Waxman Markey wants to blame the shift in Alaskan temperatures on “global warming”, the science says otherwise. The changes are due to the shifts in the PDO.
Second, their claim that Alaska has “warmed by 4 to 7 degrees Fahrenheit” is not true. The largest trend to 2009 in the Alaska temperatures is 1954-2009, which is 3.24 degrees.
I also note that they are using a very different period from the one they used in their claims about the US Northeast, where they used the trend from “the 1970’s”. Obviously, they are picking their time period to exaggerate their claims …
The main point here is that because the PDO gives Alaska warm periods and cool periods, it is meaningless to use any trend starting from a cool period and ending in a warm period, or vice versa. Yes, you can get a positive trend from anywhere on the left half of the graph to anywhere on the right side of the graph … but that doesn’t tell us anything about what’s happening.
Short and sweet.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a7aca86',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"

As I noted in an earlier post, I’m supportive of Bob’s legal argument that the President’s NSA surveillance program is illegal and unconstitutional. (My level of certainty on this: moderate). But for me this doesn’t settle the matter. There’s a separate question: What should the Supreme Court do about it?   
  
For me, this is the hard but all important question. In _Baker v. Carr_ , the Court suggested (in so many words) that justices may want to avoid resolution of a constitutional question if, for example, there is a significant chance another branch might ignore its decision. The reason for this seemingly weak-kneed approach to constitutional adjudication is straightforward. The Supreme Court, a tribunal of nine geriatric lawyers, doesn’t have much muscle. It can’t arrest a recalcitrant President. It relies on the force of its mystique as the oracle of our fundamental law and its soft political power to confer public legitimacy on political branch actions. That’s generally enough to compel the grudging respect and deference of Congress and the President. But in extraordinary times, its possible that a headstrong President convinced of the rightness of his mission, and backed by popular support and a waffling Congress, might simply ignore the Supreme Court. If that happens too often, the Court risks losing its power to command. And a disrespected Court that is repeatedly ignored is far, far worse for the long-term protection of liberty than a Court that occasionally ducks the wrong fight.   
  
So what should the Court do about the NSA surveillance program?   




There are seven red flags counseling caution: 


"
"
Share this...FacebookTwitterYesterday the Maybrit Illner talkshow on ZDF television was about Germany’s attempt to shift to renewable energy in the wake of the shutdown of 7 nuclear power reactors after the Fukushima tsunami disaster.
The political talkshow, moderated by Maybrit Illner, asked if consumers are being asked to pay too much for the transition to a power supply based on renewable energies. Electricity rates have jumped 15% in Germany in just 2 years. Interesting were the comments from German Environment Minister, Norbert Röttgen. In the past he always based the need to switch to renewable energy on “climate change”. Not anymore it seems. Except maybe once in passing, Röttgen didn’t mention the word “climate” once. In fact no one uttered it. It appears that protecting climate has lost its appeal.
So what could be driving the change over to renewable energy if it isn’t the climate? Röttgen cited two reasons: 1) The need to get off nuclear power and 2) the fact that fossil fuels are resources on Earth that are limited. No mention of climate. Suddenly climate change is losing its urgency.
The other members of the talkshow included a Karl Marx look-alike (Michael Sladek) who demands that power generation be taken away from big corporations and be decentralized by putting it in the hands of private individuals. Isn’t that what mankind did thousands of years ago when everyone had his own campfire?
Another guest was an anti-nuclear power activist who claimed that nuclear power was too dangerous and thus had to be stopped. She said the same thing about 10 times, but used different words each time.
The director EON was also a guest and he was content to perch himself high up on the fence, not taking any sides at all. I found his performance spineless. The other guest was Dirk Maxeiner, a long-time critic of the green movement. Citing biogas and windmills, he claimed that the green movement did more harm than good to the environment. He’s right of course.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Is Schellnhuber discretely changing the timescale?
Reader asmilwho informs that Hans Joachim Schellnhuber was interviewd on German radio this morning. As I listened to the director of the alamist fantasy factory Potsdam Institute of Climate Impact Research, I couldn’t help but notice that he seems to have modified his tune when it comes to a timetable for his envisioned “Great Transformation of Society” and climate urgency overall (emphasis added):
For the most part the course has to be set over the next 20 years for an almost carbon-free world economy.”
Now it’s two decades “to set the course” to transform society, and not to actually transform it. It turns out that some countries like Germany, Spain and Italy, all set their green course years ago, and all have since discovered that it’s too expensive to follow. Thus they’ve since begun to abandon these courses by cutting back on or eliminating the subsidies that had been designed to keep them on their courses to begin with. The “course” to transform society turned out to be a path to failure and had to be abandoned.
“Setting the course for a renewable energy economy” over the next 20 years is not going to curb global CO2 emissions at all. China, India and the rest of the booming developing world aren’t going to accept delaying any longer the prosperity that the western world has been enjoying for over half a century. Poverty cannot pay for expensive energy. The path to renewable energy can only go through prosperity, and the path to prosperity is paved with cheap energy. The developing world is not going to abstain from using cheap fossil fuels. Thus CO2 concentrations will certainly continue their rise. In 10 years it’ll be clear what the real impact of CO2 on climate truly is.
Another misleading comment Schellnhuber makes is claiming that “surveys show globally that 90% of the population wants the transition renewable energies”. Well if they’re cheap and plentiful, who doesn’t? But the reality is that these energy sources are still astronomically expensive and cause more environmental destruction than protection. They cannot lift countries out of poverty.
 
Share this...FacebookTwitter "
"


Engineering a cooler Earth
Researchers brainstorm radical ways  to counter climate  change

By Erika  Engelhaupt
None of the scientists in the room so much as blinked when David  Keith suggested saving the world with spy planes spraying sulfuric acid.
Keith,  a physicist at the University of Calgary in Canada, was facing an  audience not likely to be shocked: nearly 200 other researchers, some of  whom had their own radical ideas for fighting global warming. His  concept was to spray a mist of sulfuric acid high in the stratosphere to  form particles called sulfate aerosols, which would act like a  sprinkling of tiny sunshades for the overheating Earth.
Keith’s  idea may sound outrageous, but it is just one of many proposals for  bumping the global thermostat down a couple of degrees by tinkering  directly with the planet’s heating and cooling systems. Plans to cool  the Earth range from shading it to fertilizing it, from seeding clouds  to building massive supersuckers that filter greenhouse gases from the  air. The schemes are all part of a growing field known as  geoengineering: a subject once taboo for all but the scientific fringe,  but now beginning to go mainstream.
So far the tinkering happens  mainly in computer models, where researchers are trying to figure out  geoengineering’s potential side effects. Yet some technologies are in  the prototype stage, governments are starting to consider geoengineering  seriously and budding geoengineers are working out how to proceed  safely, and ethically, with real-world experiments.
“It truly is  asking giant questions which nobody really knows the answers to,” Keith  says — “like how we manage the whole Earth.”
In March, Keith and  other experts met in a dimly lit chapel-turned-auditorium at the  Asilomar resort near Monterey, Calif. In 1975, molecular biologists met  at the same resort to write landmark guidelines to regulate DNA  experiments. This time around, cloud physicists, legal scholars and  government bureaucrats debated the relative merits of brightening clouds  versus building artificial trees. In the end, the meeting-goers  concluded that geoengineering research should cautiously proceed, in  case Earth’s climate proves broken beyond the current means of repair:  ratcheting down fossil fuel use.
Researchers have kicked around  the idea of large-scale climate manipulation since at least the 1960s,  when Soviet scientists suggested damming the Bering Strait as part of a  scheme to warm Siberia and free shipping lanes of sea ice. But  mainstream scientific attention began only about five years ago.
===================
read the rest at Science News Engineering  a cooler Earth


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8b7e95ad',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Issued today 4/28/2010
Lisa P. Jackson - EPA
EPA Press Office
press@epa.gov
202-564-4355
FOR IMMEDIATE RELEASE
April 28, 2010
Statement of Lisa P. Jackson Administrator, U.S. Environmental  Protection Agency
Legislative Hearing on Clean Energy Policies That Reduce Our  Dependence on Oil
House Subcommittee on Energy and the Environment
WASHINGTON – Chairmen Markey and Waxman, Ranking Members Upton and  Barton, Chairman Emeritus Dingell, and Members of the Subcommittee,  thank you for inviting me to testify about the Environmental Protection  Agency’s work to reduce America’s oil dependence and greenhouse gas  emissions. That work stems from two seminal events.
First, in April 2007, the U.S. Supreme Court concluded in  Massachusetts v. EPA that the Clean Air Act’s definition of air  pollution includes greenhouse gases. The Court rejected  then-Administrator Johnson’s refusal to determine whether that pollution  from motor vehicles endangers public health or welfare.
In response to the Supreme Court’s decision, and based on the best  available science and EPA’s review of thousands of public comments, I  found in December 2009 that motor-vehicle greenhouse gas emissions do  endanger Americans’ health and welfare.
I am not alone in reaching that conclusion. Scientists at the 13  federal agencies that make up the U.S. Global Change Research Program  have reported that unchecked greenhouse gas emissions pose significant  risks to the wellbeing of the American public. The National Academy of  Sciences has stated that the climate is changing, that the changes are  mainly caused by human interference with the atmosphere, and that those  changes will transform the environmental conditions on Earth unless  counter-measures are taken.
The second pivotal event was the agreement President Obama announced  in May 2009 between EPA, the Department of Transportation, the nation’s  automakers, America’s autoworkers, and the State of California to seek  harmonized, nationwide limits on the fuel consumption and greenhouse gas  emissions of new cars and light trucks.
My endangerment finding in December satisfied the prerequisite in the  Clean Air Act for establishing a greenhouse gas emissions standard for  cars and light trucks of Model Years 2012 through 2016.  So I was able  to issue that final standard earlier this month, on the same day that  Secretary of Transportation Ray LaHood signed a final fuel efficiency  standard for the same vehicles.
Using existing technologies, manufacturers can configure new cars and  light trucks to satisfy both standards at the same time. And vehicles  complying with the federal standards will automatically comply with the  greenhouse gas emissions standard established by California and adopted  by 13 other states.  This harmonized and nationally uniform program  achieves the goal the President announced last May.
Moreover, the EPA and DOT standards will reduce the lifetime oil use  of the covered vehicles by more than 1.8 billion barrels. That will do  away with more than a billion barrels of imported oil, assuming the  current ratio of domestic production to imports does not improve. The  standards also will eliminate more than 960 million metric tons of  greenhouse gas pollution.
But if Congress now nullified EPA’s finding that greenhouse gas  pollution endangers the American public, that action would remove the  legal basis for a federal greenhouse gas emissions standard for motor  vehicles. Eliminating the EPA standard would forfeit one quarter of the  combined EPA-DOT program’s fuel savings and one third of its greenhouse  gas emissions cuts. California and the other states that have adopted  California’s greenhouse gas emissions standard would almost certainly  respond by enforcing that standard within their jurisdictions, leaving  the automobile industry without the nationwide uniformity that it has  described as vital to its business.
I would like to mention one more action that EPA has taken to reduce  America’s oil dependence and greenhouse gas emissions. In February, I  signed a final renewable fuels standard.  It substantially increases the  volume of renewable products – including cellulosic bio-fuel – that  refiners must blend into transportation fuel. EPA will implement the  standard fully by the end of 2022. In that year alone, the standard will  decrease America’s oil imports by 41 and a half billion dollars. And  U.S. greenhouse gas emissions that year will be 138 million metric tons  lower thanks to the standard.
EPA’s recent work on vehicles and fuels shows that enhancing  America’s energy security and reducing America’s greenhouse gas  pollution are two sides of the same coin.
R133
==============================
h/t to WUWT reader Michael C. Roberts


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8c66e3af',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterBy Ed Caryl
The recent issuing of four papers by Dr. Richard Muller, et al, has increased the on-line discussions of temperatures over the last decade. There are several claims in the first of these papers that deserve study:
1. “…The global land mean temperature has increased by 0.911 ±0.042 C since the 1950s…”
2. “The World Meteorological Organization (WMO) gives an operational definition of climate as the average weather over a period of 30 years (Arguez and Vose 2011).”
3. “No part of the Earth’s land surface shows appreciable cooling.”
These assertions will be addressed in the course of this article. For material, 83 locations were selected from the GISS database. In an attempt to limit urban warming affects and the “adjustments” applied by GISS, a strict selection process was used. The selection criteria were: less than 10,000 population, as much as possible, a continuous record from 1940 or before to the present, and no splicing of records. Fifty-six of these locations are in the U. S. in four regions. Twenty-two stations were in the mid-west, in Kansas, Nebraska, and Iowa; fifteen stations in the north-west “inland empire,” eastern Oregon, Washington, and western Idaho; nine stations in the desert south-west, southern Utah and New Mexico; and ten stations in the south-east, Alabama and Georgia.
In the rest of the world, ten stations were found in the Arctic and Siberia, six stations bordering the North Atlantic Ocean, and thirteen stations in the southern hemisphere, in South American, Australia, the south Atlantic, and south Pacific. All of these stations are well away from any population centers and are isolated or in or close to very small towns and villages. These will be explored in Part 2.
For each station, a temperature anomaly was computed, using the average temperature from 1930 to 1980 as the baseline. This baseline was chosen because it is in the middle of the period for many of the records, and because it includes both a warm and a cold era. Figure 1 shows the result for the 22 stations in the U.S. mid-west.

Figure 1. This is the temperature anomaly from a 1930-1980 baseline for 22 mid-western small-town locations. The bold black trace is the average for those stations.
It can be seen that for this region, the highest temperature occurred in 1934, the next highest in 1921, and the third highest in 1931. The year 2000 was only the fourth highest in the twentieth century. Since 1930, the mid-west U.S. temperature trend has been cooling by about 0.1° C. (Figure 2)

Figure 2: This is the average anomaly and a linear trend plot from 1930 to 2011 for the mid-western U.S. showing about 0.15 degrees C cooling over that period. Since 2005 the cooling has been about 1.5 degrees C.

Figure 3. The Temperature Anomalies for 15 northwest U.S. stations. The bold black trace is the average anomaly for those stations.
In Figure 3, the trend for the last century has been warming, but taken in 30-year periods described at the top of this article, the first 30 years was flat, followed by a sudden warming, then cooling until 1980, then another sudden warming, followed by a sudden cooling since 2003. The warmest year was again 1934, almost a degree warmer than 1992, 1998, and 2003.

Figure 4: These are the temperature anomalies for 9 stations in the southwest U.S. The bold trace is the average temperature anomaly for the SW U.S.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




In Figure 4, the situation is the same as the other regions: flat from 1900 to 1930, a sudden warming to the warmest year, 1934, cooling until 1980, warming to 2000, then cooling in the last decade.

Figure 5: Temperature anomalies in the SE region of the U.S. The bold black traces are the average anomaly and a linear trend line applied to that average.
In Figure 5, the trend for the entire 20th century has been cooling in this region by nearly half a degree C. The four warmest years are all in the 1920’s, 1921, 22, 25, and 27. The next warmest is 1933. 1998 and 99 are not even in the top 10.
If all 56 locations are averaged together, the trend is warming from the late 19th century to the late 1930’s. After that date, the trend is cooling until 1980, and then warming by the same amount to 2000. See figure 6, showing the temperature anomaly for all the U. S. locations examined, with a trend line from 1934 to 2000, one complete cycle of the 66-year peak-to-peak temperature cycle.

 
Figure 6: The average U.S. temperature anomaly for 56 rural stations from 1934 to 2000, with a linear trend line plotted. The trend over that period is about -0.06° C, or -0.074° C per century cooling.
Conclusion
Now, let’s revisit the claims by Dr. Richard Muller:
 …The global land mean temperature has increased by 0.911 ±0.042 C since the 1950s…”
Strictly speaking, that claim is true. But what is left out is that the same amount of cooling took place from the late 1930’s to the late 1950’s. The temperature is cycling with a period of about 66 years, with about one degree amplitude. Dr Muller is only looking at one-half of the temperature cycle.
The World Meteorological Organization (WMO) gives an operational definition of climate as the average weather over a period of 30 years (Arguez and Vose 2011).”
See 1 above. That definition is too short by at least a factor of two. There are many cycles seen in the temperature record. See this paper from the Chinese Science Bulletin. They mention 110, 199, 800, and 1324-year cycles; and their Fourier
analysis plot shows other cycles at 66 (one third of the 199 year cycle) and about 38 years. The 66-year cycle is clearly seen in the above plots. The 38-year signal may reflect the slower cooling part of the cycle followed by quicker warming. This author submits that any attempt to define climate as some time-average weather is a futile exercise.
No part of the Earth’s land surface shows appreciable cooling.”
Dr. Muller did not define appreciable, or a time period. For over 80 years, the SE and mid-west U. S. are cooling. Over the last decade, the U.S. and Canada are cooling. Anthony Watts here, and Matti Vooro here, have described this phenomenon. The so-called climate scientists must get over thinking that the linear trend over the last thirty years is telling them anything about the climate.
In Part II, the other (global) 27 rural and isolated stations will be analyzed.
 
 
Share this...FacebookTwitter "
"**The number of domestic abuse offences recorded by police in England and Wales has increased during the pandemic.**
But the Office for National Statistics said such offences gradually rose in recent years so it cannot be determined if it was related to the pandemic.
Police recorded 259,324 domestic abuse offences between March and June - 7% up on the same period in 2019.
During and after the first lockdown in April, May and June, roughly one-fifth of offences involved domestic abuse.
The ONS data, released on Wednesday, includes information from a range of sources - including police forces' own figures on the number of offences recorded and then flagged as related to domestic abuse.
Domestic abuse is not a specific criminal offence, so police record incidents under the type of offence (for example, assault with injury) but then flag that it is related to domestic abuse.
In April, May and June - which covers the period during and immediately after the first national coronavirus lockdown - domestic abuse offences took up a larger proportion of all offences compared to previous years.
Around 20% of all offences recorded by police were flagged as domestic abuse related during these months - compared to less than 15% in previous years.
The number of offences also rose each month, the figures showed.
One woman, Davina, told the BBC that it was increased time at home with her abuser that made her seek help.
""Lockdown was the worst time in my life,"" she told BBC Scotland's The Nine programme. ""That was when I first paid attention to Women's Aid, I wondered if they could get me out the situation, so took the number from the television.
""I wasn't allowed to use the phone in the house so I took the number and went out with the dog and I phoned it.
""I wasn't ready to go but they had nowhere for me anyway. But I was in constant contact with Rebecca from Women's Aid and she helped me eventually leave.
""If it hadn't been for them I don't know what would have happened. I think eventually I would be dead. Mentally, physically, emotionally - I couldn't do it any more.""
Davina was allocated a place in a refuge and although she says it took her a month to stop waking up in the night crying, she finally feels safe.
Read more here.
As the lockdown eased, the proportion of offences flagged as domestic abuse went down. But this was likely because the overall amount of criminal offences increased when lockdown was lifted.
Between March and June, police recorded 206,492 ""violence against the person"" offences that were flagged as domestic abuse - a 9% rise on the same period in 2019.
The ""violence against the person"" category includes offences such as harassment, assault and murder. Other offences outside this category can also be flagged as linked to domestic abuse, such as sexual offences.
And provisional data showed there were 64 domestic homicides in England and Wales recorded by police between January and June 2020 - 30 of them in the period between April and June.
This is nearly 10 more than the same period in 2019, although the figure is slightly lower than in 2018.
""The number of domestic abuse-related crimes recorded by the police continued to increase in the year ending March 2020; this may reflect improvements in police recording and an increase in victims' willingness to come forward,"" said Helen Ross, from the ONS's Centre for Crime and Justice.
""Up-to-date evidence shows this increase continued into the lockdown period - however, it cannot be determined whether this can be directly attributed to the coronavirus pandemic.""
Ms Ross added that data showed there had been an increase in demand for domestic abuse support services during the pandemic, particularly following the easing of lockdown measures.
""Data suggests that experiences of domestic abuse may have intensified during the lockdown and that victims faced difficulties in safely seeking support under these conditions,"" she said.
Charities dealing with domestic abuse have reported a surge in appeals for help since the start of the pandemic.
Earlier this week, train companies and charity Women's Aid confirmed they were extending a scheme that offers free travel to people fleeing domestic abuse.
The ""Rail to Refuge"" scheme - which provides free tickets for women, men and children travelling to refuge services - will continue until March next year.
The charity New Era, which helps victims in Staffordshire and Stoke-on-Trent, said the ONS figures was ""more disturbing"" evidence and showed there was ""more to do to tackle and end relationship abuse"".
Meanwhile, London Mayor Sadiq Khan has announced that Â£3.7m of City Hall and government money would be invested in measures to support victims of domestic abuse.
He said it would be funding new ""safe spaces"" for victims, training for police and schemes focused on perpetrators, adding: ""Sadly, we already know that during lockdown home is not always a safe place for everyone."""
"
No mention of missing “M’s” here in this press release from University of Melbourne
This data visualization from the AMSR-E instrument on the Aqua satellite show the maximum sea ice extent for 2008-09, which occurred on Feb. 28, 2009. Credit: NASA Goddard's Scientific Visualization Studio
Melting sea ice has been shown  to be a major cause of warming in the Arctic according to a University  of Melbourne study.
 Findings published in  Nature today reveal the rapid melting of sea ice has dramatically  increased the levels of warming in the region in the last two decades.
Lead author Dr James Screen of the School of Earth Sciences at the  University of Melbourne says the increased Arctic warming was due to a  positive feedback between sea ice melting and atmospheric warming.
“The sea ice acts like a shiny lid on the Arctic Ocean. When it is  heated, it reflects most of the incoming sunlight back into space. When  the sea ice melts, more heat is absorbed by the water. The warmer water  then heats the atmosphere above it.”
“What we found is this feedback system has warmed the atmosphere at a  faster rate than it would otherwise,” he says.
Using the latest observational data from the European Centre for  Medium-Range Weather Forecasting, Dr Screen was able to uncover a  distinctive pattern of warming, highly consistent with the loss of sea  ice.
“In the study, we investigated at what level in the atmosphere the  warming was occurring. What stood out was how highly concentrated the  warming was in the lower atmosphere than anywhere else. I was then able  to make the link between the warming pattern and the melting of the sea  ice.”
The findings question previous thought that warmer air transported  from lower latitudes toward the pole, or changes in cloud cover, are the  primary causes of enhanced Arctic warming.
Dr Screen says prior to this latest data set being available there  was a lot of contrasting information and inconclusive data.
“This current data has provided a fuller picture of what is happening  in the region,” he says.
Over the past 20 years the Arctic has experienced the fastest warming  of any region on the planet. Researchers around the globe have been  trying to find out why.
Researchers say warming has been partly caused by increasing human  greenhouse gas emissions. At the same time, the Arctic sea ice has been  declining dramatically. In summer 2007 the Arctic had the lowest sea ice  cover on record. Since then levels have recovered a little but the  long-term trend is still one of decreasing ice.
Professor Ian Simmonds, of the University’s School of Earth Sciences  and coauthor on the paper says the findings are significant.
“It was previously thought that loss of sea ice could cause further  warming. Now we have confirmation this is already happening.”


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8bfe41d0',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**Coronavirus cases in one of the country's worst affected areas have more than halved in two weeks.**
Scarborough's infection rate has fallen to 296 per 100,000, with 17 new Covid-19 cases recorded in the past 24 hours.
On 11 November the town's infection rate stood at 611, the second-highest in England.
Cases across North Yorkshire have also declined with the average for the county now 196 cases, lower than the national average of 207.
According to the Local Democracy Reporting Service, health officials hope the county could avoidÂ the toughest tier of coronavirus restrictions as the national lockdown ends next week.
Richard Webb, the county's corporate director of health and adult services, told a briefing that falling infection rates had given the region some optimism that it could escape the tightest controls set to be announced by the government on Thursday.
However, he warned Covid cases were still 10 times higher than summer, and urged residents toÂ fight downÂ any over-optimism.
Mr Webb said: ""We are still seeing people dying from Covid and behind all the numbers are human stories.""
The county was under Tier 1 restrictionsÂ as it entered the national lockdown which will now end on 2 December.
_Follow BBC Yorkshire on_Facebook _,_Twitter _and_Instagram _. Send your story ideas to_ yorkslincs.news@bbc.co.uk _or_send video here _._"
"Brazilians head to the polls in October to decide on their new president. The country’s votes always produce surprises such as the election of a clown in 2010 and in 1959 the election of a rhinoceros named Cacareco with 100,000 votes as a city councillor of São Paulo.   Cacareco was arguably Brazil’s first celebrity animal but the Belo Horizonte Zoo, through captive breeding, has produced the first two “Brazilian” gorillas in the past month.  Once their names have been chosen, these baby gorillas will no doubt become celebrities. The zoo just needs to be careful with the naming – after a public competition in the 1970s its first gorilla was called Idi Amin Dada, after the African dictator. London Zoo’s most famous resident Guy the Gorilla became a national icon in the 60s and 70s; he too was named after an infamous character, 17th century would-be terrorist Guy Fawkes. Superstar zoo animals long pre-date social media and demonstrate that animal celebrity culture is nothing new.  But modern zoos find it difficult to balance celebs with conservation. Celebrity culture is all about the individual and species conservation is all about the population. Thus, zoos need to strike a happy medium between public (over-)interest in certain star attractions and doing what is right for the whole species. The problem is it takes a lot of captive animals to save a certain species from extinction, and most zoos are too small to do this by themselves. For large mammals with long lives, for example, we need approximately 250 individuals in captivity to maintain a genetically healthy population. When it comes species’ with shorter generation times (birth to sexual maturity) we need even more individuals in captivity to avoid the loss of genetic diversity: so to save a small rodent with a generation interval of a few months we would need thousands of individuals.   Paradoxically it can be more expensive to save a territorial mouse species from extinction than a species of elephant because of the need to construct hundreds, if not thousands, of mouse enclosures. Genetic diversity is important because it allows species to adapt to their environment. But zoo animals in captivity are not subject to natural selection. Despite this, the goal of many zoos is to create a safety net population of species to guarantee the survival of their wild counterparts; this might be by reintroducing animals to the wild. Zoos get over the numbers problem by thinking globally. International co-operation means all the gorillas in zoos participating in the captive breeding programme are managed as a metapopulation. That is, although each zoo has its own group of gorillas they are managed as if they are part of a single global population – and issues such as genetic diversity or gender balance are considered in terms of the 850+ in the programme rather than the five or six in any particular zoo. A studbook keeper uses genetic management software to decide who should breed, who should not breed and who should be paired with who. A digital-age cupid if you like. But here decisions are based on the genetic value of the individual not their celebrity or good looks.  The more genetically important the individual, the greater the chance he will be given the nod to breed.  Studbook keepers also select against individuals with genetic illnesses. An individual is genetically important if there are few copies of their genes among others: the aim being to maintain as much genetic diversity in the captive population as possible for as long as possible. This approach has been incredibly successful – the Przewalski horse, for instance, the only surviving breed of truly “wild” (never domesticated, non-feral) horse, was once down to as few as 13 individuals. Thanks to captive breeding it was brought back from the brink of extinction to number in the thousands and is now being reintroduced to Mongolia. Reproductive technologies such as artificial insemination can help with captive breeding, but in general zoos still favour producing offspring the old fashioned way. Mainly because this exposes the animals to less risk; that is, no need for it to participate in an invasive medical procedure. But this does imply that we need to move animals around the world for dating purposes. Leon, the male gorilla at the Belo Horizonte Zoo, came from Spain – and the two females, Imbi and Loulou came from the UK. These animals are on loan as part of the international gorilla captive breeding programme. Loaning animals across international borders could be a legal nightmare; if there were some sort of dispute in this case – the ownership of the baby gorilla, for instance – which of the three legal systems should be followed in the case of a dispute?  In the spirit of co-operation this problem has been solved in a simple means by zoos through the use of what are essentially gentlemen’s agreements. In this day and age when lawyers seem to run the world it is refreshing to know that trust can win out for species conservation."
"That eating beef is environmentally costly is by now widely appreciated. But little has been done to curtail the amount of cattle farmed for meat consumption. To try and address this, my colleagues and I decided to calculate just how costly beef production is for the environment, and how it stacks up against pork, poultry, dairy and eggs. Our hope is that better knowledge of the environmental costs of raising animals for food will help improve both the dietary choices people make and agricultural policies. Our research, which was published in the Proceedings of the National Academy of Sciences of the US, found that raising beef cattle is far more environmentally costly than poultry, pork, dairy or eggs. Per calorie, cattle requires on average 28 times more land and 11 times more water to farm. Farming cattle releases five times more greenhouse gases and uses six times as much nitrogen as the average of other animal products.  When compared with staple plant foods, these ratios roughly double. So, a beef calorie requires about 50 times more land than a wheat calorie. By comparison, pork, poultry and eggs are all roughly on the same level of environmental cost. In terms of greenhouse gas emissions, water use and the levels of nitrogen discharge from fertiliser run-off, dairy is comparable to pork, poultry and eggs.  While it’s long been clear that vegetarian diets produce lower environmental costs than ones involving produce from animals, people are still intent on eating food derived from animals – and with ever-increasing gusto. Taking note of this, we sought to identify the types of animal-based food that are least environmentally harmful. Though numerous studies have addressed elements of this issue, they have mostly used data from individual farms, typically one or at most a handful. But farms differ markedly geographically, from season to season and year to year, and are thus not necessarily representative of the big picture.  By contrast, we used the reverse, top-down approach by analysing national level data. While previous studies mostly addressed one environmental burden at a time (typically greenhouse gas emissions, but also water or land use), we simultaneously addressed each of them in order to offer a multi-dimensional view of the environmental performance of the livestock industry in the US.  We measured greenhouse gas emissions, water and land use, and reactive nitrogen discharge levels from manure or fertiliser. Reactive nitrogen is environmentally important because it is the most common cause of degradation in freshwater ponds, streams and lakes, and around coastlines where fertiliser run-off washed into rivers reaches the sea. We address the five main animal based products in the American diet: dairy, beef, poultry, pork and eggs, calculating the environmental costs per nutritional unit, calorie or gram protein. Our key challenge was devising accurate values of how much land, water, and reactive nitrogen livestock required, and the amount of greenhouse gasses they emit. Working out these estimates required navigating numerous subtleties. For example, grazing cattle in the arid to semi-arid western US uses an enormous amount of land, but little or no irrigation. Grain-fed feedlot cattle, by contrast, use much less land, but require cultivated grains that depend strongly on nitrogen fertiliser. We needed to fairly account for these differences across the country, while determining figures that reflect, approximately, the true environmental costs. These findings have a number of implications. First, this research can inform environmentally minded individuals so they can make environmentally better dietary choices. Perhaps more importantly, the paper can also help inform agricultural policy, in the US and worldwide. In a companion paper in the Journal of Agricultural Science (forthcoming) we have laid down a foundation for analysing the environmental costs of any diet, including plant-based diets and those of other nations.  Perhaps our key contribution is to highlight areas in which improvement is most likely, and where a focused effort is likely to yield the most desirable change. Applying these methods to global diets can help improve long term global food security in light of the effects of climate change, water and land shortage, and rising population."
"
Share this...FacebookTwitterOilprice.com has conducted a very interesting interview with the well known climatologist Judith Curry, who runs the excellent Climate Etc. blogsite.
You’ll recall that Professor Curry was once a staunch AGW proponent. Later the scientific evidence cooled her down to lukewarm.
The interview is balanced and readers may be interested in reading about Judith’s concerns for climate science, how climate change is affecting the planet, reasons for the increase in scepticism and why climate scientists have lost touch with the public.
The IPCC might have outlived its usefulness. Let’s see what the next assessment report comes up with. But we are getting diminishing returns from these assessments, and they take up an enormous amount of scientists’ time.”
You can read the full interview at: http://oilprice.com An-Interview-with-Judith-Curry.
Some of Judy’s quotes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Because of recent criticisms of the IPCC and a growing understanding that the climate system is not easily understood, an increasing number of scientists are becoming emboldened to challenge some of the basic conclusions of the IPCC, and I think this is a healthy thing for the science.”
and on the IPCC:
…we put the CO2 stabilization policy ‘cart’ way before the scientific horse.”
and on the green industrial complex (emphasis added):
Yet, we have allowed it to dictate global policy and form a trillion dollar green industrial complex – all without applying a single quality system, without a single performance standard for climate models, without a single test laboratory result and without a single national independent auditor or regulator. It all lives only in the well known inbred, fad-driven world of peer review.
You can read the full interview at: http://oilprice.com An-Interview-with-Judith-Curry
 
Share this...FacebookTwitter "
"

Media Contact: (202) 789‑5200





WASHINGTON–On Wednesday, the Supreme Court will hear oral argument in _Massachusetts v. EPA_. Filed by a group of states and environmental groups, the case asks the justices to decide whether the Environmental Protection Agency must regulate American carmakers’ contributions to “global warming.” 



Cato scholars have filed two _amicus_ briefs on the EPA’s behalf, one addressing the scientific claims of global warming alarmists and the other addressing the legal questions in the case. The first, science‐​oriented brief, authored by Cato senior fellow Patrick J. Michaels and filed by the Competitive Enterprise Institute, questions the notion that global warming will exert a net negative impact on human health and welfare. 



“Our brief repeatedly stresses that no comprehensive analysis of the net costs and/​or benefits of reasonably projected climate change has ever been performed”, said Michaels. “Regulation without a commensurate basis in scientific fact is hardly what our founders, such as Thomas Jefferson, would have wanted”. 



Cato’s brief on the legal issues, filed on behalf of the Cato Institute by Cato lawyers Tim Lynch and Mark Moller, argues that federal law provides no mandate for global warming regulation and that the Constitution requires petitioners to direct their broad complaints about global warming to Congress, not courts. Cato’s brief is authored by environmental law professor Jonathan Adler and joined by law professors James L. Huffman and Andrew Morriss.



“The stakes in this case are very large,” explains Cato senior fellow Mark Moller, a co‐​counsel for Cato in the case. “If the petitioners win, American carmakers may face the equivalent of Kyoto global warming standards, imposed by judicial fiat, despite Congress’s umpteen rejections of the Kyoto regime. Complex regulatory decisions of this magnitude should be made by Congress, not federal judges.”
"
"

In his State of the Union address, President Bush spoke a lot about energy independence and alternative energy sources such as ethanol. According to the president, ethanol is the magical elixir that will solve virtually every economic, environmental, and foreign policy problem on the horizon. In reality, it’s enormously expensive and wasteful. 



Untruths and misconceptions about ethanol include: 



**Ethanol will lead to energy independence.** If all the corn produced in America last year were dedicated to ethanol production (14.3 percent of it was), U.S. gasoline consumption would drop by 12 percent. For corn ethanol to completely displace gasoline consumption in this country, we would need to appropriate all U.S. cropland, turn it completely over to corn‐​ethanol production, and then find 20 percent more land for cultivation on top of that. 



The U.S. Energy Information Administration believes that the practical limit for domestic ethanol production is about 700,000 barrels per day, a figure they don’t think is realistic until 2030. That translates to about 6 percent of the U.S. transportation fuels market in 2030. 



**Ethanol is economically competitive now.** According to a 2005 report issued by the Agriculture Department, corn ethanol costs an average of $2.53 to produce, or several times what it costs to produce a gallon of gasoline. Without the subsidies, costs would be higher still. A study last fall from the International Institute for Sustainable Development found that ethanol subsidies amount to $1.05-$1.38 per gallon, or 42 percent to 55 percent of ethanol’s wholesale market price. 



**Ethanol reduces gasoline prices.** If you lived in California and other areas that used reformulated gasoline last summer – that’s the environmentally “clean” gasoline required for areas with air pollution problems, and that’s where most of that ethanol went – you might have paid up to 60 cents a gallon more for gasoline than you would have otherwise. That’s because the federal government required oil refineries to use 4 billion gallons of ethanol in 2006 regardless of price, and gasoline pump prices last summer reflected the fact that ethanol was twice as expensive as wholesale conventional gasoline. 



**Ethanol is a renewable fuel.** According to a group of academics from UC Berkeley who published in _Science_ magazine last year, 5 percent to 26 percent of the energy content of ethanol is “renewable.” The balance of ethanol’s energy actually comes from the staggering amount of coal, natural gas and nuclear power necessary to produce corn and process it into ethanol. 



**Ethanol reduces air pollution.** A review of the literature by Australian academic Robert Niven found that, when evaporative emissions are taken into account, E10 (fuel that’s 10 percent ethanol and 90 percent gasoline, the standard mix) increases emissions of total hydrocarbons, nonmethane organic compounds, and air toxics compared to conventional gasoline. The result is greater concentrations of photochemical smog and toxic compounds. 



**Ethanol reduces greenhouse gas emissions.** At best, E10 reduces greenhouse gas emissions by from zero to 5 percent; pure ethanol by 12 percent. The International Energy Agency, however, estimates that it costs about $250 to reduce a ton of greenhouse gases this way, or more than 10 times what Yale economist William Nordhaus thinks is economically sensible given the economics of climate change. Ethanol as an anti‐​warming policy is what academics refer to as “crazy talk.” 



**Ethanol subsidies are necessary to “level the playing field.”** Petroleum subsidies are something less than $1 billion a year – six to eight times less than ethanol subsidies – and work out to about 0.3 cents per gallon. 



**Switchgrass (aka, “cellulosic ethanol”) will set us free.** Guy Caruso, the head of the EIA, noted in a speech last December that the capital costs associated with cellulosic ethanol production were five times greater than those associated with conventional corn ethanol production. Estimates like that are a bit soft, however, because there is no cellulosic ethanol industry in existence at present, so data is hard to come by. Betting the farm on an industry that doesn’t yet exist to produce a product that is known to be staggeringly expensive isn’t the best use of tax dollars. 



If ethanol has commercial merit, it doesn’t need the subsidy. If it doesn’t, no amount of subsidy will bestow it. And that’s the truth. 
"
nan
nan
"When my six-year-old daughter is stressed she bites her fingernails. Children in maths lessons often respond to the anxiety that doing mathematics causes by swinging their legs. Arturo the polar bear at Mendoza Zoo in Argentina responds to stress by pacing up and down whilst swinging his head from side to side.  So why does Arturo’s abnormal behaviour lead to outcries concerning his psychological well-being? The difference between Arturo and my daughter or reluctant children in maths lessons is that that the stress-related behaviour is no longer related to its triggers. What does this expression of abnormal behaviour from Arturo tell us about his psychological state? Such behaviour in animals is indicative of a state of poor welfare. In effect, his behaviour tells us there is something wrong. It is common to see such behaviour in animals kept in un-stimulating environments such as barren cages in poor quality zoos. Referred to as stereotypic behaviour, defined by its repetitive movements, unvarying and with no apparent function, it may indicate that the animal is depressed. Studies have shown that changes in the brain chemistry of certain animal species performing such behaviours are similar to those observed in the brains of depressed humans. Infamously, in the 1990s the Calgary Zoo tried to treat its stereotypic polar bears with Prozac. Stereotypic animal behaviour often looks like obsessive compulsive behaviours in humans, and certain types of abnormal behaviour such as body rocking, pacing, skin picking and hair plucking are common to distressed animals and humans. In fact, Kathy Carlstead at the Honolulu Zoo once made a documentary on abnormal behaviour in captive bears and afterwards received letters from American prisoners saying they did the same thing when locked in their cells.   Some anti-zoo protesters have tried to claim that such abnormal behaviour shows that animals are going mad. This is going too far. These animals are using a strategy to cope with a situation that has negatively affected their sense of well-being. In fact there is behavioural and physiological evidence that this is, in fact, a coping strategy, possibly mediated through the release of neurotransmitters that make creatures feel better. For example leg swinging by children in class is a natural beta-blocker, reducing heart rate and making them feel less anxious.  Thus, some argue the animal is coping with its environment. A university professor and the father of two small children, I can cope with lots of stress over prolonged periods of time, but no-one – least of all I – would argue that such a situation is good for my well-being (whether or not I mitigate the sense of the walls closing in by pacing around my office). A lot of my sense of well-being is highly dependent on how I see my situation.  Is the glass half empty or half full?  This is something easy to ask a human, but we cannot ask an animal. Mike Mendl at the University of Bristol came up with a simple method to find out animals’ attitudes. He trained animals that if they went to a point on one side of a room they would get a reward from a bucket, and if they went to the other side the bucket would contain something unpleasant.  Placing the bucket in the middle of the room between the two points creates an ambiguous situation. An animal that runs quickly towards the bucket therefore feels there will be something worth having, despite the lack of evidence either way – an optimistic outlook. Mendl found that animals from enriched, stimulating environments run more quickly towards the bucket than those from barren environments. Dogs that wreck their owner’s home when left alone only slowly approach the ambiguous option compared to those that are not home-wreckers. The test gives an opportunity to sense an animal’s outlook, whether optimistic or pessimistic. The well-being of animals is not a simple thing to measure or define, and so it is very difficult to encapsulate in law. In the UK, animal welfare laws are based on the Five Freedoms, which require that animals must be free from hunger and thirst; discomfort; pain, injury or disease; fear and distress; and should be free to express their natural patterns of behaviour. Should any of these freedoms be restricted, it’s fair to say the animal’s well-being is eroded. I run 8km every morning because prevention is better than cure; the same applies to animal welfare – we need to avoid animals developing problems, and this can be done by applying the Five Freedoms and by ensuring rich environment for them to inhabit. Animals with welfare problems like Arturo can be helped by this approach, but it may be that their view of the world is too dark to fully recover."
"

A few days ago, the British government released the Stern report, a voluminous study arguing that the costs associated with stabilizing carbon dioxide concentrations at 550 parts per million were far less than the costs associated with doing nothing. Although the study acknowledged rather large bounds of uncertainty, the median estimates therein suggested that business as usual (that is, we do nothing) would mean a loss of 5–10% of global GDP every year forever. Most of those harms, however, could be avoided if we spent 1% of global GDP to cut back on greenhouse gas emissions.   
  
There are very good reasons to suspect that Stern's estimates regarding the cost of cutting back on greenhouse gas emissions are too low and that the damages forecast by Stern are too high. The underlying assumptions of the analysis producing Stern's estimates have been well dissected by statistician Bjorn Lomborg, climate scientist Roger Pielke, Jr., and economist Richard Tol. But for the moment, let's put those complaints aside.   
  
My colleague Peter Van Doren and I have done three present value calculations assuming that business as usual (BAU) will reduce global GDP by 2%, 5%, and 10% beginning in 2056 and then in each and every year through the end of time. Don't worry about the silliness of such a proposition. Oddly enough, once you try calculating beyond 200 years, the numbers don't really change much given the need to discount future costs and benefits by 5%.   
  
First, we calculated the cost of using 1% of GDP every year through the end of time to reduce greenhouse gas emissions. The net present value of that cost is $15,541 per person in the United States.   
  
Then, we calculated the benefits for U.S. citizens (global GDP figures are pretty dodgy, so we stuck with U.S. GDP figures for the purposes of this exercise). They amount to $36,447 is you accept -10% GDP as your BAU scenario, $18,239 if you accept -5% GDP as your BAU scenario, and $7,295 if you accept -2% GDP as your BAU scenario.   
  
In other words, Stern's investment advice makes sense only if you think that warming will hammer GDP by 10% a year. You don't gain much at all from emission cuts, however, if you think GDP will only drop by 5% a year if we do nothing. And if you think warming will only cost the global economy 2% of GDP every year (the ""concensus"" belief among economists, which comes from a widely cited analysis from Yale economist William Nordhaus), then Stern's investment advice is shere lunacy.   




And that's not even taking into consideration the fact that reducing greenhouse gas emissions might produce no benefits at all. The latest IPCC report — as all other reports before it — acknowledge that the evidence that anthropogenic emissions are primarily driving the warming we’ve detected is strong but circumstantial. Scientists disagree about how large the chances are that we're wasting our time cutting greenhouse gas emissions, but there’s no disagreement within the latest IPCC report that there’s a chance that anthropogenic emissions are not particularly important factors in climate at present.   
  
Is global warming insurance a good buy? Probably not. And that's particularly true given the fact that the relative poor (us) will pay the premium so that the relatively rich (our children and grandchildren) will get the benefits if there are any. For example, since 1950 real GDP per capita has increased by about 2% per year. Given that growth rate, U.S. GDP per capita in 100 years would be $321,684 in current dollars, or more than seven times higher than it is at present ($44,403). If global warming cuts GDP by even 10%, then GDP per capita will be $289,515 in 2106 rather than $321,684. Would anyone, let alone liberals, ever propose a 1% tax on those who make $44,000 to create benefits for those who make $289,000?


"
"
Borrowing a phrase from NSIDC’s Dr. Mark Serreze, Phytoplankton are now apparently in a “Death Spiral”. See Death spiral of the oceans and the original press release about an article in Nature from a PhD candidate at Dalhousie University, which started all this. I’m a bit skeptical of the method which they describe in the PR here:
A simple tool known as a Secchi disk as been used by scientists since  1899 to determine the transparency of the world’s oceans. The Secchi  disk is a round disk, about the size of a dinner plate, marked with a  black and white alternating pattern. It’s attached to a long string of  rope which researchers slowly lower into the water. The depth at which  the pattern is no longer visible is recorded and scientists use the data  to determine the amount of algae present in the water.
Hmmm. A Secchi disk is a proxy, not a direct measurement of phytoplankton. It measures turbidity, which can be due to quite a number of factors, including but not limited to Phytoplankton. While they claim to also do chlorophyll measurements, the accuracy of a SD measurements made by thousands of observers is the central question.

From the literature: The Secchi disk transparency measurement is  perhaps one of the oldest and simplest of all measurements. But there is  grave danger of errors in such measurements where a water telescope is  not utilized, as well as in the presence of water color and inorganic  turbidity (source: Vollenweider and Kerekes, 1982). I’ll have more on this later. – Anthony
======================================================
Diatoms are one of the most common types of phytoplankton.
Phytoplankton need cap and trade
By Steve Goddard
Yesterday, Joe Romm reported :
Nature Stunner: “Global warming blamed for 40% decline in the ocean’s phytoplankton”
“Microscopic life crucial to the marine food chain is dying out. The consequences could be catastrophic.”
That sounds scary. Does it make any sense? Phytoplankton thrive everywhere on the planet from the Arctic to the tropics.  One of the primary goals of this year’s Catlin expedition was to study  the effect of increased CO2 on phytoplankton in the Arctic. They reported:

Uptake of CO2 by phytoplankton increases as ocean acidity increases
That sounds like good news for Joe!  We also know that phytoplankton have been around for billions of years, surviving average global temperatures 10C higher and CO2 levels 20X higher than the present.

http://ff.org/centers/csspp/library/co2weekly/2005-08-18/dioxide.htm
Phytoplankton growth/reduction in the tropics correlates closely with ENSO. El Nñio causes populations to reduce, and La Niña causes the populations to increase.
During an El Niño year, warm waters  from the Western Pacific Ocean spread out over much of the basin as  upwelling subsides in the Eastern Pacific Ocean. Upwelling brings cool,  nutrient-rich water from the deep ocean up to the surface. So, when  upwelling weakens, phytoplankton do not get enough nutrients to maintain  their growth. As a result, surface waters turn into “marine deserts”  with unusually low populations of phytoplankton and other tiny  organisms. With less food, fish cannot survive in the surface water,  which then also deprives seabirds of food.
During La Niña conditions, the opposite effect occurs as the easterly  trade winds pick up and upwelling intensifies, bringing nutrients to the  surface waters, which fuels phytoplankton growth. Sometimes, the growth  can take place quickly, developing into what scientists call  phytoplankton “blooms.”
The phytoplankton must be loving life now!

The author of this study (Boris Worm) also reported last year “if fishing continued at the same rate, all the world’s seafood stocks would collapse by 2048”
So we know that phytoplankton have survived for billions of years in a  vast range of climates, temperatures and CO2 levels. Apparently they  have become very sensitive of late – perhaps from all the estrogens  being dumped in the oceans? Or maybe they have been watching too much  Oprah?
The standard cure for hyperventilation is to increase your CO2 levels by putting a bag over your head.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8a3de143',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
nan
"As ships resume the search for missing Malaysian Airlines flight MH370 in the depths of the Indian Ocean this week, we often hear that the oceans are “95% unexplored” and that we know more about the surface of the Moon or Mars than the ocean floor.  But is that true, and what do we really mean by “explored”? The entire ocean floor has now been mapped to a maximum resolution of around 5km, which means we can see most features larger than 5km across in those maps. That’s the resolution of a new global map of the seafloor published recently by David Sandwell of Scripps Institute of Oceanography in San Diego and colleagues, who used some nifty tricks with satellites to estimate the landscape of the sea floor and even reveal some features of the Earth’s crust lurking beneath sea-floor sediments. Unlike mapping the land, we can’t measure the landscape of the sea floor directly from satellites using radar, because sea water blocks those radio waves. But satellites can use radar to measure the height of the sea’s surface very accurately. And if there are enough measurements to subtract the effects of waves and tides, satellites can actually measure bumps and dips in the sea surface that result from the underlying landscape of the ocean floor. Where there’s a large underwater mountain or ridge, for example, the tiny local increase in gravity resulting from its mass pulls sea water into a slight bump above it. If instead there is an ocean trench, the weaker local gravity produces a comparative dip in the ocean surface. Reading those bumps and dips in the sea’s surface is an astounding feat of precision measurement, involving lasers to track the trajectory of the measuring satellite and inevitably a lot of maths to process the data. The new map uses data from the Cryosat-2 and Jason-1 satellites and shows features not seen in earlier maps using data from older satellites. The previous global map of the ocean floor, created using the same techniques and published in 1997, had a resolution of about 20km. So we do actually have a map of 100% of the ocean floor to a resolution of around 5km. From that, we can see the main features of its hidden landscape, such as the mid-ocean ridges and ocean trenches – and, in that sense, the ocean floor is certainly not “95% unexplored”. But that global map of the ocean floor is admittedly less detailed than maps of Mars, the Moon, or Venus, because of our planet’s watery veil. NASA’s Magellan spacecraft mapped 98% of the surface of Venus to a resolution of around 100 metres. The entire Martian surface has also been mapped at that resolution and just over 60% of the Red Planet has now been mapped at around 20m resolution. Meanwhile, selenographers have mapped all of the lunar surface at around 100 metre resolution and now even at seven metre resolution. To map the ocean floor back home in greater detail, we have to use sonar instead of satellites. Modern sonar systems aboard ships can map the ocean floor to a resolution of around 100 metres across a narrow strip below the ship. Those more detailed maps now cover about 10%-15% of the oceans, an area roughly the size of Africa. Mapping from ships at the level of detail achievable by ship’s sonar systems still reveals plenty of surprises. The first phase of searching for Malaysian Airlines flight MH370 in the Indian Ocean, which involved mapping from ships to plan future surveys by underwater vehicles, found underwater mountains and other features that were not shown on satellite-derived maps for the area. But if we want to detect things just a few metres in size on the ocean floor, such as the wreckage of missing aircraft or the mineral spires of undersea volcanic vents that my team investigates, we need to take our sonar systems much closer to the sea bed using underwater vehicles or towed instruments. So far, less than 0.05% of the ocean floor has been mapped to that highest level of detail by sonar, which is an area roughly equivalent in size to Tasmania.  And of course, actually to see the sea floor using cameras or our own eyes means getting even closer, using remotely operated vehicles or manned submersibles. So the “95% unexplored” meme doesn’t really tell the full story of our exploration of the oceans. When it comes to having a large-scale map, the ocean floor is perhaps not as unexplored as we might think, with 100% coverage to a resolution of 5km and 10%-15% coverage at around 100m resolution.  That 10%-15% is similar in resolution to the current global maps of Mars and Venus. But our exploration of the oceans depends on what we want to know about them. If our questions are: “What does it look like down there?” or: “What’s going on down there?”, then the area that has been “explored” is arguably even less than the 0.05% mapped so far at the very highest resolution by sonar. Philosophically, when it comes to exploring anywhere on our dynamic world, how and when do we decide that somewhere has “been explored”? Do we declare “mission accomplished” once we’ve seen a location for the first time? The local woods where I walk my dog look very different in winter compared with summer, with different species flourishing at different times. Should I have considered them “explored” after my first visit in just one season?  Exploring our world starts with mapping, but perhaps doesn’t really have an end.   The University of Southampton is running a free online course (a “MOOC”) on Exploring Our Oceans."
"This winter has been by far the hottest recorded in Europe, scientists have announced, with the climate crisis likely to have supercharged the heat. The EU’s Copernicus Climate Change Service (C3S) data dates back to 1855. It said the average temperature for December, January and February was 1.4C above the previous winter record, which was set in 2015-16. New regional climate records are usually passed by only a fraction of a degree. Europe’s winter was 3.4C hotter than the average from 1981-2010.  The unseasonal heat has led to the failure of the ice-wine harvest in Germany and snow having to be imported for sporting events in Sweden and Russia. In Helsinki, Finland, the average temperature for January and February was more than 6C higher than the 1981-2010 average. In the UK, serious flooding is likely to have been made worse by higher temperatures, as in 2015. “Whilst this winter was a truly extreme event in its own right, it is likely that these sorts of events have been made more extreme by the global warming trend,” said Carlo Buontempo, director of C3S. But he added: “Seeing such a warm winter is disconcerting, but does not represent a climate trend as such. Seasonal temperatures, especially outside the tropics vary significantly from year to year.” Nonetheless, scientists expect global heating to increase the number of temperature extremes and this is continuing around the world. Australia, which has suffered catastrophic bushfires, has just recorded its second-hottest summer on record, only a little cooler than the record set the year before. In Antarctica, the temperature rose above 20C for the first time on record in February, almost a full degree higher than the previous record set in 1982. Across the globe as a whole, 2019 was the second hottest on record for the planet’s surface and both the past five years and the past decade were the hottest in 150 years. The previous hottest year was in 2016, but temperatures were boosted that year by a natural El Niño event. The heat in the world’s oceans reached a new record level in 2019, showing “irrefutable and accelerating” heating of the planet, according to scientists. In the UK, the Met Office said in January that a series of high temperature records were broken in 2019 as a consequence of the climate crisis. This included the hottest temperature ever recorded in the country: 38.7C on 25 July in Cambridge. 2020 is a crucial year in the fight to halt the climate emergency and prevent the damaging impacts worsening. The UK is hosting a vital UN climate summit in November at which the world’s nations must dramatically increase their pledges to cut carbon emissions to avoid a disastrous 3-4C rise in global temperatures."
"**Tougher restrictions in Wales are being considered for the run up to Christmas, the first minister has confirmed.**
Mark Drakeford said he is ""looking carefully"" at similar coronavirus rules to those that will be in place in areas in the upper end of the tier systems of England and Scotland.
However he said they would ""most likely"" be imposed on a Wales-wide basis, rather than a tier system.
The Welsh Government cabinet is due to discuss the matter on Thursday.
Mr Drakeford told BBC Wales Live he believes, unless further action is taken, ""we could end up at Christmas with a virus really heading very fast in the wrong direction"".
He said: ""We're looking carefully at the tier system that they've got now in Scotland and in England, looking at what further restrictions they have at that point in the tier system where it begins to be effective, seeing if there's anything more we can take from that for Wales.
""Let me be clear I'm not talking about using a tiered system.
""I'm looking to see what measures are in place at, say, tier three in Scotland and England.
""Are there things that they do there that we're not doing here in Wales, that we would do, most likely, on a Wales-wide basisâ¦ in the run up to Christmas. We've got four weeks left.""
England's new tier system comes into force when its lockdown ends next week, with Tier 3 being the highest level of restrictions.
Under Tier 3, people must not meet indoors or in most outdoor places with people they do not live with or who are not in their support bubble, pubs and restaurants are closed except for takeaway and hotels and indoor entertainment venues must close.
Scotland has a five-level system that runs from 0 to four. At Level 3 alcohol sales are not allowed and cafes and restaurants can only serve food and non-alcoholic drinks and must close at 18:00.
Mr Drakeford said preventing people getting together would have helped moves to control the spread of coronavirus.
However he admitted that Christmas was ""too important"" to people to ask them to not celebrate.
""If we could have persuaded people that this wasn't the year to get together over Christmas that would have been better from the virus's perspective, but we were never going to be able to do that,"" he said.
""In an incredibly difficult year we weren't going to be able to persuade people that they could just act as though Christmas wasn't happening.""
Asked whether Wales was ready to distribute a coronavirus vaccine, Mr Drakeford said: ""We have everything in place once a vaccine gets regulatory approval.""
He added: ""Even the most promising vaccine is yet to have approval by the regulator. Once it gets it, within a week we are ready to start vaccinating people in Wales.""
If Wales were to use the Pfizer vaccine, which has to be stored at -70 degrees, he said the plan is to use equipment from the Welsh Blood Service.
""We can use the equipment the Wales Blood service already has to store material at that temperature and we can make it available for this vaccine,"" he said.
""The vaccine will have limitations, it will be difficult to transport but we will find ways of doing it. Whatever vaccine comes our way, we will want to use here in Wales."""
"Are animals jealous? How would we know? Scientists are educated to have a deep scepticism about attributing sophisticated mental abilities to non-human animals. Anthropomorphism is regarded as a scientific sin. However, the paradox is that scientists are all Darwinists, and Darwin’s great contribution to psychology was the argument for the continuity of mind across species, not the uniqueness of humans. He was explicit that animals and humans shared a wide range of emotions, including jealousy. Many contemporary theories of jealousy focus on its development during infancy and childhood. A paper published in the journal PLOS One takes a leaf out of such studies to conduct an experiment with dogs. The paper’s findings suggest that dogs show behaviour indicative of jealousy when their owners interacted with lifelike stuffed dogs, and not when they interacted with other, non-doglike objects. Jealousy is thought to develop after basic emotions such as anger and fear, and is thought to require relatively sophisticated cognitive capacities including elements of self-consciousness. The requirement of self-consciousness, in combination with the natural reluctance of scientists to be caught anthropomorphising, makes any claim of jealousy in animals controversial. The scepticism over the existence of sophisticated emotions such as jealousy, guilt or empathy in animals is on reflection odd. Most scientists are happy to grant animals basic emotions such as anger and fear. It would not be anthropomorphic to say that an animal is angry or scared. Anger and fear have a clear evolutionary function for animals and humans, and even though animals may not experience such emotions in precisely the same way as humans, there is a clear continuity. When we consider the function of jealousy it would seem equally important for many social species. All jealousy shares the characteristic of being focused on relationships. Jealousy in essence is a reaction to a threat to a social relationship whether that is parental, sexual or a friendship or alliance. All such relationships are potentially vital in social species.  We know animals form alliances and bonds (contemporary scientists are deeply reluctant to talk about animal friendships even though Darwin frequently did) as they are often vital to survival in hierarchical social species. We all need allies. To have a mechanism that makes animals sensitive to potential threats to such alliances provides a clear evolutionary advantage. It would be foolish to claim that animals experience the existential pain that can be part of the human experience of jealousy. But given the functional necessity of something like jealousy in any social species, it seems equally unlikely that jealousy emerged from a clear blue sky as a uniquely human adaptation. Emotions are the functional adaptations that help organise behaviour, and jealousy has a similar function across a range of species. Jealousy is classed as a secondary or social emotion, in contrast to primary or basic emotions. Secondary emotions such as empathy, pride, embarrassment and guilt and are thought to be important for maintaining stable social structures, rather than providing the immediate survival benefits of basic emotions such as fear. There is very clear evidence that basic emotions are tied to particular sites in the brain, and these are the same across species. The same link of emotion to location is not the case with secondary emotions. This may be because secondary emotions are the result of more distributed networks of neurons than primary emotions. However, mammal brains (including humans) are remarkably similar in structure and have all the same bits in all the same places, so from an anatomical point of view there is no reason to preclude animals having secondary emotions. Humans do not seem to be uniquely designed to support secondary emotions.    Being certain about the mental state of any person (let alone a member of another species) other than ourselves is problematic as we cannot know their mental states directly. This is known as the problem of other minds. However, we can have reasonable confidence that a range of species experience basic emotions such as anger, as the behaviour and even facial expressions associated with basic emotions are consistent and recognisable across species. But emotions such as jealousy do not have any unique behaviours or facial expressions associated with them. Jealousy can manifest as anger or as distress, for example. Despite all the folk psychology and human projection that often suggests otherwise, there will always be arguments about whether a dog can show jealousy, empathy, or guilt, because of the difficulty of measuring emotion in any non-human animal. "
"
Share this...FacebookTwitterControversy is swirling over new upcoming skeptic book.
It begins with DIE ZEIT’s latest article on the controversial new skeptic book authored by Prof Dr. Fritz Vahrenholt (renewable energy expert) and Dr. Sebastian Lüning (expert geologist) which will hit the bookstores on February 6, published by the renown Hoffmann & Campe in Hamburg. It has the warmist activists scared out of their wits.

The book German warmists fear.
An old saying goes: Better to remain quiet and let people think you may be dumb, than to open your mouth and to confirm it. Two authors at the German online DIE ZEIT nationwide weekly, Stefan Schmitt and Christian Tenbrock, not only confirmed it, but they also jumped right into it, feet first, in their latest hit piece here.
DIE ZEIT labels skeptic scientists “deniers”
Worse, the once respectable DIE ZEIT weekly, which Wikipedia calls “highly respected for its quality journalism”, stooped into the gutter and maliciously labelled scientists who doubt the catastrophic global warming religion as “deniers”. We all know why the word denier was chosen, and not “skeptic”. They ought to be served papers for defamation.
They haven’t even read the book
Schmitt und Tenbrock’s article is filled with Rahmstorfian-type falsehoods. What’s remarkable is that they go after the book and its two authors without having ever read it! (book release is February 6). If they had waited a little longer to read it, they would have spared themselves all the embarrassment of their ridiculous claims, falsehoods, and thus confirmation of some dumbness.
Lüning and Vahrenholt are luke-warmers
Their only crime of course is that the book’s authors are open-minded and have also evaluated skeptic arguments in their overall assessment. Their book Die kalte Sonne cites more than 800 sources from both sides, and from the middle. In fact, Vahrenholt was once a more or less a devout warmist – until he dug deeper. Yet, DIE ZEIT writes at the very beginning:
“RWE manager Fritz Vahrenholt doubts further global warming.”
He does not. Indeed it helps to read the book first.
Schmitt and Tenbrock then claim Vahrenholt and Lüning insist the impacts of CO2 emissions can be neglected. But anyone who is familiar with the contents of the book, as I am, can say that this is also false. The truth is that Drs. Lüning and Vahrnholt clearly state that CO2 is responsible for perhaps half of the warming. This is in line with what Prof. Mojib Latif believes. DIE ZEIT is trying to frame it as a yes-or-no issue. Their sole interest is starting a food-fight, and preventing a discussion.
DIE ZEIT imposes a thought-ban
Schmitt and Tenbrock of DIE ZEIT also blast the two authors for attending a skeptic conference in Munich last November. What’s wrong with that?  Why not listen to both sides of the argument? Has a thought-ban been enacted in Germany? Or is this something one finds only at DIE ZEIT? Are we only to march like drones, never questioning green dogma?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




It just happens that some of the speakers at the Munich Conference are also guest authors of the book and who happen to be distinguished scientists, among them Henrik Svensmark and Nir Shaviv. If Schmitt and Tenbrock had waited and read the book first, they would have known of their contribution to the book, and certainly would have learned to spell their names correctly. Tells you what they really know about climate science.
Ignorant when it comes to the CERN CLOUD experiment
Schmitt und Tenbrock are also not only unaware of the book’s contents, but also of what CLOUD project at CERN is about. They claim that CLOUD results don’t confirm anything, and make it sound like the experiment is finished.  They appear not to know that only Phase I is completed. And preliminary results indeed do fit Svensmark’s theory – like a glove. The next phase of the experiment will test to see if the tiny aerosols can form into larger ones, and is expected to end in 2014. Not only should they wait and read the book, they also ought to wait for the results of CLOUD before opening their mouths and confirming more dumbness.
Lüning and Vahrenholt “against 1000s of scientists”
DIE ZEIT (Schmitt and Tenbrock) use the old worn out consensus argument. The global warming sham is in reality perpetuated by a only few dozen scientists who have high stakes in the game. As I already wrote, Lüning and Vahrenholt cite hundreds of sources, many peer-reviewed, that challenge the AGW hypothesis and which the IPCC simply ignores. And what did the Wall Street Journal just publish? Obviously Schmitt and Tenbrock have not read that either. Do they read at all?
On page 2, DIE ZEIT uses the unfortunate “denier” slur to criminalize skeptic scientific views. I wonder if they would say that to Nir Shaviv’s face. Obviously that has backfired big time and it fully exposes their real, malicious, agenda.
Finally Schmitt and Tenbrock claim:
At the latest since the 1980s, the Earth has been warming differently than it did in pre-industrial times, and no longer in sync with solar activity.“
Last I’ve looked, the Earth hasn’t warmed at all over the last 15 years. And if they had waited and read the book, the DIE ZEIT authors would have seen that the 22nd and 23rd solar cycles were intense ones. And, like the IPCC, DIE ZEIT simply ignores the major roles played by oceanic cycles.
To judge a book, it first helps to read it
It’s obvious that Schmitt und Tenbrock, who appear to be hopelessly biased, have long closed their minds. They were never interested at all in finding out the truth. If they had been, they would have waited and read the book – or at least interviewed Lüning and Vahrenholt.
And so with such journalists, the question arises of whether DIE ZEIT is to be taken as an open, intellectual weekly, or if it has devolved itself to being a narrow-minded purveyor of dogmatism. Can we really take DIE ZEIT seriously?
To answer that question. let’s hope Vahrenholt and Lüning send a letter of rebuttal to Die Zeit. If they are truly open, DIE ZEIT will publish it, and have alittle talk with their journalists.  But I’d bet a king’s fortune they won’t. I can tell you the answer already, I had the chance of reading the book’s  manuscript, and I know Lüning and Vahrenholt would take the DIE ZEIT piece apart in short order. Papers are not in the habit of further embarrassing themselves.
DIE ZEIT’s modus operandi
These types of journalists appear underworld-like. Journalistic drive-by shootings are sadly no longer new at DIE ZEIT and now appear to be their modus operandi. They did the same with Fred Singer, read here.
Hopefully, DIE ZEIT will someday get back to the practice of intelligent journalism, and end the cheap character assassinations and smearing. Now would be a good time for DIE ZEIT to keep their mouths closed – and to not reopen them until after February 6th.
Surely between now and then they’ll find something intelligent to say.
Share this...FacebookTwitter "
"When commercial whaling was banned in 1986 it put an end to a harvest that threatened the existence of some of the most majestic animals on Earth. With several species reduced to tiny fractions of their original populations, once the moratorium was introduced the expectation was that whale populations would recover. But in the decades since, only some have. There are many possible reasons why this might be, including chemical pollution, climate change, man-made noise, and loss of cultural knowledge among whales that prevent their descendants returning to habitats in their former range. A further risk, highlighted by a new study of blue whales off the coast of California, is deaths and injury caused by being struck by ships. In most populations, we don’t yet know how big a problem it is, but for some it is almost certainly holding back recovery. In recent years reports of the arrival of large vessels into port with the carcass of a large whale pinned to the bow bulb have become a regular occurrence in the news. Of course, these are only those cases that make it to port – an unknown number of strikes leave their victims at sea, and are sometimes encountered by chance. In fact the impact on the vessel is so insignificant that the crew is typically unaware that it has happened until it reaches port. But why this apparent increase in numbers? Is there just more interest, or are there now more whales to hit, are newer ships somehow more dangerous (modern, more efficient technology is often quieter), or are the whales moving into more dangerous busy shipping lanes? We don’t know, which is why studies like one published in the journal PLoS One are so important. Oregon State University researcher Ladd Irvine and his colleagues attached satellite tags to 171 blue whales over a period of 15 years starting in 1993. For a study of whales this is a huge dataset representing a massive investment, largely in terms of researcher time, and provides a really robust insight into the whale’s habitat use.  They found two core areas heavily used by the whales, in the Gulf of the Farralones off San Francisco Bay, and north of the Channel Islands, near Los Angeles. The whales’ presence there wasn’t year-round, but heavily concentrated between July and October as they followed high concentrations of their food, krill, that accumulate after the spring plankton bloom in these productive waters. Some individuals returned to the same spots at the same times over many years, suggesting the whales relied on their knowledge and sense of location rather than an ability to track prey, highlighting the important role that habitat knowledge plays in these animals’ lives. By plotting the whale distribution maps against those of heavily-used shipping lanes along the California coast, the problem is clear. The shipping lanes run through some of the areas most heavily used by the whales, putting them at high risk of ship strikes. The shipping lanes are typically placed where they are heavily used and most economical, such as the shortest distance between two points. No shipping companies would change their routes and incur costs without solid evidence of a problem, and this is exactly the kind of evidence this study provides. It’s hard to comprehend in an age when we are mapping the surface of Mars just how ignorant we are about these huge ocean creatures. How do you figure out how many blue whales there are in the deeply inhospitable Southern Ocean? Sometimes technology can help, such as the satellite tags used for this study. Shipping lanes into Boston on the eastern US seaboard are now equipped with acoustic buoys that report detections of critically endangered right whales in near real-time, hopefully reducing significant numbers of deaths from ship strikes. Of course, we could find out more – it just takes money. The constraint is economic and political, not a lack of technology or ingenuity. Scientists are accumulating evidence that might help us appreciate just how much healthy whale populations could be doing for us. As large, apex predators they structure the ecosystems in which they live, they provide ecosystem services by recycling nutrients throughout the water column, and their huge carcasses fuel entire deep-sea ecosystems for years. Even their excrement plays a vital role in fertilising nutrient-poor surface waters, seeding the seas with iron, which boosts phytoplankton growth and potentially plays a part in the dynamics of climate change.  It seems that marine habitats with healthy whale populations might actually be more productive than ones without. It’s never made more sense to invest in saving the whales."
"

To help you keep an eye on it, I have the satellite imagery here along with animated loops.

Click image for full size or animate this image: Click for loop>>> 
============

WTNT31 KNHC 300231
TCPAT1
BULLETIN
HURRICANE ALEX ADVISORY NUMBER  18
NWS TPC/NATIONAL HURRICANE CENTER MIAMI FL    AL012010
1000 PM CDT TUE JUN 29 2010
…ALEX BECOMES THE FIRST HURRICANE OF THE 2010 SEASON AND THE FIRST JUNE ATLANTIC HURRICANE SINCE 1995…

SUMMARY OF 1000 PM CDT…0300 UTC…INFORMATION
———————————————–
LOCATION…23.1N 94.8W
ABOUT 195 MI…315 KM ESE OF LA PESCA MEXICO
ABOUT 255 MI…415 KM SE OF BROWNSVILLE TEXAS
MAXIMUM SUSTAINED WINDS…75 MPH…120 KM/HR
PRESENT MOVEMENT…W OR 280 DEGREES AT 9 MPH…15 KM/HR
MINIMUM CENTRAL PRESSURE…973 MB…28.73 INCHES
WATCHES AND WARNINGS
——————–
CHANGES WITH THIS ADVISORY…
NONE.
SUMMARY OF WATCHES AND WARNINGS IN EFFECT…
A HURRICANE WARNING IS IN EFFECT FOR…
* THE COAST OF TEXAS SOUTH OF BAFFIN BAY TO THE MOUTH OF THE RIO
GRANDE
* THE COAST OF MEXICO FROM THE MOUTH OF THE RIO GRANDE TO LA CRUZ
A TROPICAL STORM WARNING IN IN EFFECT FOR…
* THE COAST OF TEXAS FROM BAFFIN BAY TO PORT OCONNOR
* THE COAST OF MEXICO SOUTH OF LA CRUZ TO CABO ROJO
FOR STORM INFORMATION SPECIFIC TO YOUR AREA IN THE UNITED
STATES…INCLUDING POSSIBLE INLAND WATCHES AND WARNINGS…PLEASE
MONITOR PRODUCTS ISSUED BY YOUR LOCAL NATIONAL WEATHER SERVICE
FORECAST OFFICE. FOR STORM INFORMATION SPECIFIC TO YOUR AREA OUTSIDE
UNITED STATES…PLEASE MONITOR PRODUCTS ISSUED BY YOUR NATIONAL
METEOROLOGICAL SERVICE.
DISCUSSION AND 48-HOUR OUTLOOK
——————————
AT 1000 PM CDT…0300 UTC…THE CENTER OF HURRICANE ALEX WAS LOCATED
NEAR LATITUDE 23.1 NORTH…LONGITUDE 94.8 WEST.  ALEX HAS MOVED
MOSTLY WESTWARD NEAR 9 MPH…15 KM/HR…OVER THE PAST FEW HOURS BUT
A GENERAL WEST-NORTHWESTWARD MOTION IS EXPECTED OVER THE NEXT 24 TO
48 HOURS.  ON THE FORECAST TRACK…THE CENTER OF ALEX WILL APPROACH
THE COAST OF NORTHEASTERN MEXICO OR SOUTHERN TEXAS ON WEDNESDAY AND
MAKE LANDFALL IN THE HURRICANE WARNING AREA LATE WEDNESDAY OR
WEDNESDAY NIGHT.
MAXIMUM SUSTAINED WINDS HAVE INCREASED TO NEAR 75 MPH…120
KM/HR…WITH HIGHER GUSTS.  ALEX IS A CATEGORY ONE HURRICANE ON THE
SAFFIR-SIMPSON HURRICANE WIND SCALE.  ADDITIONAL STRENGTHENING IS
FORECAST PRIOR TO LANDFALL.  ALEX WILL BEGIN TO WEAKEN AFTER ITS
CENTER CROSSES THE COASTLINE.
HURRICANE FORCE WINDS EXTEND OUTWARD UP TO 15 MILES…30 KM…FROM
THE CENTER…AND TROPICAL STORM FORCE WINDS EXTEND OUTWARD UP TO 175
MILES…280 KM.
THE MINIMUM CENTRAL PRESSURE REPORTED BY AN AIR FORCE HURRICANE
HUNTER PLANE WAS 973 MB…28.73 INCHES.
HAZARDS AFFECTING LAND
———————-
RAINFALL…ALEX IS EXPECTED TO PRODUCE TOTAL RAINFALL ACCUMULATIONS
OF 6 TO 12 INCHES OVER PORTIONS OF NORTHEASTERN MEXICO AND SOUTHERN
TEXAS…WITH ISOLATED MAXIMUM AMOUNTS OF 20 INCHES.  THESE RAINS
COULD CAUSE LIFE-THREATENING FLASH FLOODS AND MUD SLIDES…
ESPECIALLY IN MOUNTAINOUS TERRAIN.  RAINBANDS ASSOCIATED WITH ALEX
ARE SPREADING ONSHORE IN NORTHEASTERN MEXICO AND SOUTHERN TEXAS.
WIND…TROPICAL STORM CONDITIONS ARE EXPECTED TO REACH THE COAST
WITHIN THE HURRICANE AND TROPICAL STORM WARNING AREAS BEGINNING LATE
TONIGHT OR EARLY WEDNESDAY…MAKING OUTSIDE PREPARATIONS DIFFICULT
OR DANGEROUS.
STORM SURGE…A DANGEROUS STORM SURGE WILL RAISE WATER LEVELS BY
AS MUCH AS 3 TO 5 FEET ABOVE GROUND LEVEL ALONG THE IMMEDIATE COAST
TO THE NORTH OF WHERE THE CENTER MAKES LANDFALL.  THE SURGE COULD
PENETRATE INLAND AS FAR AS SEVERAL MILES FROM THE SHORE WITH DEPTH
GENERALLY DECREASING AS THE WATER MOVES INLAND.  NEAR THE COAST…
THE SURGE WILL BE ACCOMPANIED BY LARGE AND DESTRUCTIVE WAVES.
TORNADOES…ISOLATED TORNADOES ARE POSSIBLE OVER PORTIONS OF EXTREME
SOUTHERN TEXAS ON WEDNESDAY.
NEXT ADVISORY
————-
NEXT INTERMEDIATE ADVISORY…100 AM CDT.
NEXT COMPLETE ADVISORY…400 AM CDT.
============================================
I find it amazing that today the world connectivity allows me to get notified of this bulletin, publish this post, and include live satellite content all from a coin operated net kiosk at Melbourne Airport.
We live in interesting times.
Anthony


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8ab3a750',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"**Criminal gangs used Personal Protective Equipment (PPE) shipments in an attempt to smuggle illegal drugs in Northern Ireland, the justice minister has said.**
Naomi Long revealed the attempts in her annual report on organised crime.
Mrs Long said organised crime groups had also exploited the need for PPE, including selling non-existent stock online.
She said it was ""reprehensible"" criminals had exploited the Covid-19 pandemic.
""The fact that criminals would stoop so low as to exploit the circumstances created by a pandemic shows they care about nothing other than lining their own pockets,"" she added.
""PPE is an essential part of keeping people safe from the virus so to use shipments of it to conceal drugs is beyond reprehensible.""
The Organised Crime Task Force annual report also said drugs were found concealed in flooring packaging and in washing powder.
The taskforce had helped rescue ""111 potential victims of modern slavery"", the report added.
The report also revealed 5.7m cigarettes, 65,000 litres of alcohol and more than 2,000 items of counterfeit goods ""had been prevented from entering Northern Ireland"".
""It is critical that we strive to make organised crime unprofitable and to bring criminals to justice,"" Mrs Long added.
""Next year, new legislation will be introduced to enhance powers for law enforcement agencies here, bringing Northern Ireland into line with the rest of the UK.
""Unexplained Wealth Orders, account freezing and forfeiture powers, and the ability to seize criminal assets are just three of the additional measures that will be available to strengthen collective efforts to tackle organised crime.
""In addition work will continue on proposals for new organised crime offences.""
PSNI crime department Assistant Chief Constable Barbara Gray said the criminality of organised crime gangs ""knows no bounds as has been witnessed during the Covid-19 pandemic when they have continued to make money regardless of the pressures on the lives of others"".
""The Organised Crime Task Force is committed to disrupting and frustrating the criminal gangs involved.
""This year's annual report recognises the contribution and significant successes of the law enforcement agencies over the past 12 months including the seizure of illegal drugs, rescuing victims of human trafficking, and seizing counterfeit goods.""
The Organised Crime Task Force was established in 2000 and includes the Police Service of Northern Ireland, An Garda SÃ­ochÃ¡na (Irish police), the Department of Justice and Her Majesty's Revenue and Customs."
"Boris Johnson’s government must spend an additional £33bn a year on measures to tackle the climate emergency if it is to meet its target of cutting carbon of emissions to zero by 2050, according to a detailed analysis published on Sunday.  Investment in low-carbon transport – including more infrastructure for charging electric vehicles, improved railways and better facilities for cyclists – would have to rise by £12bn a year, and spending on low-carbon homes and other buildings would need to be increased by £10bn annually.  The huge sums of extra spending required have been produced before Wednesday’s budget by the Institute for Public Policy Research thinktank, which says the necessary measures would not only help tackle climate change but would also deliver an economic boost and help Johnson’s ambition to “level up” the country. Last summer the government signed into law a commitment requiring the UK to bring all greenhouse gas emissions to net zero, replacing the previous pledge to reduce them by at least 80% compared with 1990 levels. But the IPPR argues in its study that in order to do so ministers will have to loosen their own fiscal rules, which cap borrowing for investment at 3% of GDP annually. The former Labour leader Ed Miliband, a co-chair of the IPPR’s environmental justice commission, said the budget needed to put climate change at its heart. “This will take investment but making these decisions will create hundreds of thousands of jobs, improve our natural environment, cut air pollution and make Britain a better place to love,” he said. “It makes economic and environmental sense.” In order to hit net zero within 30 years, the UK will need to be running on renewable energy with industry using mostly carbon-free processes. All homes and other buildings will have to be fully insulated and public transport will need to be greener and more efficient. Currently the government spends about £17bn a year on measures related to the climate and environment, which, the study shows, would not even be sufficient for it to meet its previous target of an 80% reduction in greenhouse gas emissions by 2050. The IPPR calculates it would need to spend an additional £11bn just to meet that previous target. The Green MP Caroline Lucas, another co-chair of the environmental justice commission said that the economic shock to the economy from the coronavirus made investment in the green economy even more necessary. “This budget will be a litmus test of whether the government understand the climate crisis, and on the basis of the evidence they are falling terrifyingly short of what is needed,” Lucas said. “With likely shocks to the economy because of the coronavirus outbreak, and the accelerating climate emergency, investing in a green new deal is now more important than ever. “It wouldn’t only help us address the climate and nature emergencies, it would transform almost every aspect of our economy and society and deliver on government promises to level up the nation by making our economy fairer and fit for the future.”"
"Ice sheets respond slowly to changes in climate, because they are so massive that they themselves dominate the climate conditions over and around them. But once they start flowing faster towards the shore and melting into the ocean the process takes centuries to reverse. Ice sheets are nature’s freight trains: tough to start moving, even harder to stop. We know this process has been going back and forth throughout history – it’s why we’ve had ice ages and warm periods. But until now we haven’t known exactly how quickly ice sheets retreated and reformed. New research published in the journal Nature Communications gives us an answer, and it isn’t great news.  It turns out sea levels often rose at scary rates in response to natural climate changes, long before mankind began pumping carbon into the atmosphere. In the short-term sea level is affected by ocean warming and so-called “thermal expansion”, or melting glaciers based on land. These changes can occur quickly – within a decade – but their impact on sea level is relatively small, in the tens of centimetres. The drivers of longer-term sea level rise, over decades or centuries, are the continental ice sheets of Greenland and Antarctica.  On the fringes of these ice sheets are “ice shelves” stretching far out into the ocean. Ice shelves can be hundreds of meters thick and, because 90% of ice in water floats below the surface, they remain “grounded” on the sea floor as long as the sea is less deep than 90% of the ice shelf thickness. Where the sea floor is deeper or the ice shelf gets thinner, there will be an area of floating land ice; here, warming ocean water can get underneath and melt the ice. Once sufficiently destabilised, an ice shelf can break up catastrophically.  Such an ice shelf collapse takes the brakes off the ice stream that feeds into the ice shelf, and land ice starts to flow much quicker towards the ocean.  Ice flow is a relatively slow process, and it takes some forcing to get a major ice sheet to systematically respond (like trying to set a fully loaded freight train into motion). Once moving, however, it will be equally hard to arrest that movement (like trying to stop a moving, fully loaded freight train).  Still, we cannot ignore it, because the sheer volume of land ice on Earth is enormous – equivalent to more than 65m of global sea level rise; Greenland alone accounts for 6 to 7m, West Antarctica for some 5-6m, and East Antarctica for the remainder. These melting ice sheets will dominate major sea level changes for centuries to come.  We can learn something about what to expect by examining sea level changes during the past five ice-age cycles (past half million years), especially through comparing them with the total amount of ice on the planet at the time. During a peak ice age, Earth held almost three times as much land ice as it holds today. For instance, during the most recent ice age the ice sheet over North America was 10-20% larger than the one we see today over all of Antarctica. During warm periods in between ice ages the sea was often close to its present level but occasionally reached up to 8 or 9m above today’s shoreline – the equivalent of melting 1.3 Greenlands today. To get a sense of how quickly the sea went up and down, we need highly detailed and well-dated records. Over the past decade I’ve led a team of scientists at the University of Southampton and the Australian National University who have developed such records using data from the Red Sea. The Red Sea has a very shallow and narrow connection with the open Indian Ocean. It also evaporates quickly – the equivalent of 2m of water each year – so new water must constantly flow in to top up sea levels and to avoid it getting too salty.  But such inflow is restricted by the tiny gap between Djibouti and Yemen, and in the past that connection was even smaller. As a result, the Red Sea was much saltier during previous ice ages, when sea level stood more than 100m below the present. Using microfossils from drill cores from the sea floor we can measure salinity through time and translate this to sea level changes in the Red Sea connection with the Indian Ocean. We were able to assess timings more accurately by comparing these sea level records to climate records from caves, which can be precisely dated by looking at radioactive decay in uranium. So now we had a detailed sea level record, with a well-defined timescale. Finally, we could work out rates of past sea level changes, and compare changing sea levels with well-dated reconstructions of temperature and CO2 changes (from ice cores). This allowed us to assess the speed of some 120 sea level rises in the past. Previously, this was possible only for one recent event. Now, for the first time, we had the information to look at how sea levels responded to natural climate change. It appears the sea level could rise as quickly as 5.5m per century. However this only happened at the abrupt endings of ice ages, starting with about three times the modern ice volume. When starting with double the modern ice volume or less, sea levels did not rise faster than 2m per century. When global ice volume was similar to the present, the sea typically rose less than 1 to 1.5m per century.  So it seems the fastest losses of ice occur when there is more ice. Not much of a surprise, perhaps, but now at least we have some real numbers to say how fast, and how much ice. And the speed the sea can rise during periods with modern ice volumes is still worrying – a 1m rise this century would hugely affect millions of people. Given that Earth has achieved these rates even when warming was much slower than today, such a rise is very possible. In the 120 different events we looked at, ice sheets went from initial change to maximum retreat within 400 years 68% of the time, and within 1100 years for 95%. In other words: once triggered, ice sheet reduction (and therefore sea level rise) kept accelerating relentlessly for many centuries.  Research we carried out previously found that modern sea level rise seems to be conforming to what we would expect from (high end) natural responses to warming. That is: after 150 years of increasing (man made) warming, the ice sheets would only recently be reaching the point where they start making a noticeable contribution to sea level rise.  But that time has come and, once ice sheets start to melt, the freight train is in motion. It will then keep moving for many centuries to come, no matter how hard we stamp on the brakes."
"**The covid crisis is on track to cut average pay packets by Â£1,200 a year by 2025, according to new analysis.**
The prediction comes from the Resolution Foundation, a think tank focused on improving living standards for people on low-to-middle incomes.
It comes a day after Chancellor Rishi Sunak warned unemployment could surge to 2.6 million by mid-2021.
The economic downturn will continue to squeeze living standards in Britain warned the foundation.
""The Covid crisis is causing immense damage to the public finances, and permanent damage to family finances too, with pay packets on track to be Â£1,200 a year lower than pre-pandemic expectations,"" warned Torsten Bell, chief executive of the Resolution Foundation.
Its new research published on Thursday, Here Today, Gone Tomorrow, says that ""the combined effects of weaker pay growth and higher unemployment will serve to prolong Britain's living standards squeeze"".
Its analysis shows household incomes have been growing at a slower pace even before the pandemic.
They are on course to grow just 10% during the 15 years from the start of the 2008 global financial crisis until 2023.
But household incomes grew by a much higher 40% in the 15 years leading up to the financial crisis.
The Resolution Foundation says further pressure will come next April, when about six million households will lose more than Â£1,000 through reduced Universal Credit payments.
It also warned the bulk of the government's extra spending to deal with the ""economic emergency"" will need to come from tax rises.
""While the priority now is to support the economy, the permanent damage to the public finances mean taxes will rise in future,"" added Mr Bell.
""The pandemic is just the latest of three 'once in a lifetime' economic shocks the UK experienced in a little over a decade, following the financial crisis and Brexit,"" he added.
""The result is an unprecedented 15-year living standards squeeze.""
In Mr Sunak's Spending Review he pledged Â£280bn this year to help get the country through the pandemic downturn.
""But which taxes those will be, like which Brexit we can expect, are questions the chancellor left for another day.""
The chancellor told MPs the UK economy is predicted to shrink by 11.3% in 2020, which has been described as the ""largest fall in output for more than 300 years""."
"
Share this...FacebookTwitterToday we have learned that a true champion and warrior in the fight against global warming and CO2 emissions has passed away, read, and see video here.
Kim Jong Il, The Great Climate Protection Leader Jr., died of a heart attack at the age of 69. No leader had done more in capping CO2 emissions, saving energy, and taking responsibility for rescuing the world climate than Kim Jong Il. See for yourself:
This North Korean society, led by the guiding hand of an all-knowing leader and class, is the perfect role model for true global warming activists. This is climate protection at its best. Has the IPCC put out a statement on the Great Climate Leader’s death?
James Hansen not long ago praised China‘s autocratic regime as a beacon of hope, for example. There, sustainable living could be decreed by law. No doubt Hansen, along with Gore, Schellnhuber, and their likes, are all deeply moved by North Korea’s exemplary social austerity, all benefiting the climate.
Hysterical collective mourning like hysterical climate fear in the west
When you get down to it, the propaganda methods used by North Korea to herd its people into a mass collective mourning are hardly different than those used by the extreme climate alarmists in herding people into climate fear today.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




When I saw the images of people collectively weeping and sobbing hysterically in the Reuters report linked above or the clip that follows, it immediately reminded me of how collective hysteria has swept through the ill-informed – dis-informed – here in our society, people all drugged up with propaganda.
Isn’t the North Korean mourning hysteria eerily similar to the extreme weather hysteria we are witnessing today among the multitudes of kooks of our society today? The hysteria is in fact being fanned by the duped media, duped politicians, and leading “scientists”. When are people going to wake up from this trance?
Look at the kook warmists today – running around with carbon calculators, a copy of AIT at home, fretting about every gram of emitted CO2, worrying about the weather in 100 years, thinking every weather anomaly is caused by SUV-driving, changing their entire lifestyles thinking that it’ll render us nice weather.
My daughter today had to watch “The Day After Tomorrow” at the Gymnasium upper secondary school. The teacher thinks its real! Just like in North Korea. In a few months she’ll complete her A-levels and be out of that nuthouse.
In the meantime they have to be as dis-informed and nutty as those sobbing hysterically over the loss of a brutal tyrant.
UPDATE: Excellent documentary of life in Utopia.

Share this...FacebookTwitter "
"
Guest Post by Willis Eschenbach
Having spent a reasonable amount of time there, I have the highest regard for Australia and Australians. In general they are good, level-headed folks.
Unfortunately, the same can’t be said for the people who wrote the Waxman-Markey website page on Australia. I discussed the first of their “Impact Zones” here, please read it for an overview of the Waxman Markey site. This thread discusses why you need to be very careful with the Waxman Markey “facts” about Australia – they bite.

Figure 1. An Australian example of what we surfers call “the man in the gray suit”.
The website says:
Drought
Global warming is a major contributor to Australian drought. Record high temperatures are increasing evaporation, damaging vegetation and reducing water for irrigation in the continent’s agricultural basin. Sustained high temperatures are as hazardous for people as they are for plants. The average annual death toll from heat waves is over 1,100 people in Australia and that number only stands to increase.
In 2006, Australia experienced its worst drought in the last millennium. The Murray-Darling River System, which produces well over half of the country’s water supply, dropped 54 percent below its record low.
BZZZZT! Bad website, no cookies! Another factual error, and another big lie.

First, the factual error. The website links the claim of the “worst drought in the last millennium” to that noted scientific journal, the Guardian newspaper. It in turn says:
Australia suffers worst drought in 1,000 years
Australia’s blistering summer has only just begun but reservoir levels are dropping fast, crop forecasts have been slashed, and great swaths of the continent are entering what scientists yesterday called a “one in a thousand years drought”.
With many regions in their fifth year of drought, the government yesterday called an emergency water summit in Canberra. The meeting between the prime minister, John Howard, and the leaders of New South Wales, Victoria, South Australia, and Queensland was told that more than half of Australia’s farmland was experiencing drought.
David Dreverman, head of the Murray-Darling river basin commission, said: “This is more typical of a one in a 1,000-year drought, or possibly even drier, than it is of a one in 100-year event.”
What’s wrong with their statement? A number of things. First, “scientists” didn’t say anything about a one in a thousand year drought. That was said by David Dreverman, who is the head of the local Murray-Darling river commission.
Second, Mr. Dreverman did not base that statement on a thousand years of drought records preserved in tree rings, or on other proxies, or on any observations at all. It was simply a mathematical estimate of what is called a “return period” based on a probability distribution, not a scientific statement of historical fact. Here is a link (PDF) to how it was calculated.
Third, his statement was only peripherally connected to the drought. He was actually talking, not about the drought, but about the return period of the flow of the Murray River.
Fourth, he either didn’t notice or didn’t want to comment on the other reasons why the Murray River is so low.  Here (PDF) are some of the reasons:
So why is there less water?
The amount of water that ends up in the Murray river has changed because:
•	More farm dams have reduced run-off by between 660 and 2,400 gigalitres (Gl) per year
•	Groundwater pumping has reduced run-off by 327 gigalitres per year
•	regrowth from the bushfires in early 2003, when over a million hectares of
native forest was burnt, could reduce run-off by 430 gigalitres by 2020
•	new plantations could have further reduced inflows by 1,100-1,400 gigalitres per year
•	farmers have increased the water holding capacity of their soil by adopting minimum tillage.
So that’s the factual error. The 2006 drought was serious, there’s no question about that. But there is no scientific evidence that it was the biggest drought in a thousand years. That’s just alarmist hype.
If that’s the factual error, where’s the big lie?
The big lie is that global warming is making Australia drier. Or as the website says:
Global warming is a major contributor to Australian drought. Record high temperatures are … reducing water for irrigation in the continent’s agricultural basin.
Why is that a big lie? Because Australia has has been getting wetter as the globe warmed over the last century.
How do I know that? Well, that’s what the Australian Bureau of Meteorology says. Here’s their information about Australian rainfall, from their website.

Figure 2. Changes in rainfall, Australia, 1900-2009
No sign of a problem there, rainfall is increasing. It has increased by about 80 mm (3″) over the last century. Note that (as has been true for millennia), the rainfall in Australia comes in fits and starts. It is not uncommon for a year to have twice the rain of an adjacent year.
Now I can hear you thinking “But what about the places that were hit by the drought? The Murray-Darling River basin (of “1,000 year drought” fame) and West Australia and South Australia were all hit very hard in 2006. They must be drying out.”
We are nothing if not a full service website:

Figure 3. Changes in rainfall, Murray Darling Basin

Figure 4. Changes in rainfall, South Australia.

Figure 5. Changes in rainfall, West Australia.
No reduction in rainfall there either. Yes, there was very little rainfall in 2006 in South Australia and the Murray Darling Basin and West Australia … but in all cases, there have been worse years in the historical record.
Finally, there must be some areas of Australia that are getting dryer, aren’t there? Of course. It’s a big place. Here’s an overview of the country, showing the changes since 1900:

The overwhelming majority of the country has gotten wetter. A few places have dried slightly.
SUMMARY: Their web page contains one misrepresentation of fact about droughts, and one big lie.
Misrepresentation of fact: the 2006 drought was not the biggest in a thousand years. Most places it was not even the biggest drought in the historical record.
THE BIG LIE: When you look at the full record for Australia, it is evident that as the globe warms, Australia is not drying out. It is getting wetter.
The big lie is that “global warming” is reducing the rainfall in Australia. In fact, it is increasing the rainfall … go figure.


			__ATA.cmd.push(function() {
				__ATA.initDynamicSlot({
					id: 'atatags-1460517861-5fc7e8aa28569',
					location: 120,
					formFactor: '001',
					label: {
						text: 'Advertisements',
					},
					creative: {
						reportAd: {
							text: 'Report this ad',
						},
						privacySettings: {
							text: 'Privacy settings',
						}
					}
				});
			});
		Share this:PrintEmailTwitterFacebookPinterestLinkedInRedditLike this:Like Loading...

Related
 "
"
Share this...FacebookTwitterThe Wall Street Journal Germany has an in depth analysis of the collapse of German solar module giant, Q-Cells: Too Close to the Sun – The Rise and Fall of Q-Cells.
It’s worse than we thought!
Last Tuesday the solar company based in Thalheim in Saxony-Anhalt, once the largest module manufacturer in the world, very quietly announced its results for 2011 – a blood bath. The company lost 850 million euros and is now teetering on the brink of bankruptcy, with no hope of a rescue. It is the latest in a series of spectacular solar company failures now ripping through the industry. The number of weird economic events keeps surging.
The Wall Street Journal reports how the company was founded by engineers in 1999 amid flourishing hope and optimism in what was supposed to become the cornerstone of Germany’s dreamed “Solar Valley”. The newly elected Socialist-Green coalition government, led by the newly elected Gerhard Schroeder, hailed it as the beginning of a new industrial era would sweep Germany into the 21st century. That future was secured by the passage of the Energy Feed-in Act (EEG) in 2000, which guaranteed producers of green energy fixed rates for 20 years and cheap low-cost credits for solar systems. This led to a boom in the solar industry and wind industry over the decade that followed.
Among the solar companies that sprouted overnight was Q-Cells. By 2005 the company had grown to 750 employees with annual sales of €300 million. Consulting company Ernst & Young named then Chief Executive Milner as Entrepreneur of the Year. Q-Cells expanded production and opened plants overseas, one in USA.
By 2007 the company had grown to over 1700 employees and sales of €860 million and profits of €150 million. Green energy seemed to be the way to go.
Today things don’t look rosy at at all. Q-Cells shares today can be bought for a €0.23, down from its peak of over €80 a few years back (click on 5 J., which is 5 years). Insolvency appears imminent. What happened? Everything seemed to be going right just a couple of years ago. But as the Wall Street Journal writes, everything actually had gone wrong.
As the industry boomed in Germany, thanks to mandatory feed-in rates paid to solar power producers, cheap manufacturers from China got into the act. Asian manufacturers tooled up on a massive scale and produced the modules at far lower prices. The price of solar modules on the global market plummeted. Then came the crash of 2009, the government rolled back the feed-in rates, Q-Cells had also neglected to invest in R&D. Single woes compounded and caught up. Now the company looks hopelessly doomed.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The Wall Street Journal writes:
2011 – the prices dropped further – Q-Cells succumbed to high operating costs. Old production lines at its headquarters were no longer profitable. They are going to be closed, written off, the employees will have to go. By the end of the year the company had booked a loss of €850 million. Even worse: The company doesn’t see any profit until the year 2014. What remains is pure desperation.”
Is there a chance of a rescue? Stephan Wulf of Warburg Research is gloomy. For him the question is “whether Q-Cells can avoid insolvency and if it will be able to find a place on the global photovoltaic market. Looking at the strong competition from China, I have considerable doubt. about the prospects of Q-Cells surviving. ”
Those are hardly words that will encourage investors.
The Tagesspiegel also has a report  on how many renewable energy companies rode the gravy train for years, but did not bother to invest in R&D. Now it’s time to pay the piper.
Warmist scientist on supervisory board
By the way, one of Q-Cells supervisory board members is Prof. Dr. Eicke Weber, Director of the Fraunhofer Institute for Solar Energy Systems ISE, Freiburg. and a harsh critic of Fritz Vahrenholt’s and Sebastian Lüning’s skeptic book “Die kalte Sonne“. I guess there’s a lot we could learn from Prof. Weber.
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterBy Ed Caryl
In the BEST paper Influence of Urban Heating on the Global Temperature Land Average Using Rural Sites Identified from MODIS Classifications. Red dots are warming trend sites and blue are cooling trend sites. This article will show that Dr. Richard Muller did not go far enough in looking at that influence, and failed to account for winter temperatures as one moves further north.

Figure 1. This is Figure 4 from the BEST paper.

Figure 2. This is the Annual Mean temperature in North America. Source
Most of the temperature measuring sites examined by Dr. Richard Muller et al are in the U. S. In the paper cited above, they determined that 33% of the sites were cooling, and found a Gaussian distribution (Figure 3 below) in the heating and cooling that they blamed on measurement error. This seems odd, because the cooling sites shown on the map above do not have a random distribution, as they would if the Gaussian distribution was due to random error. Many are concentrated in the southeast quadrant of the U. S. It is very obvious that the red dot concentration around urban areas is due to Urban Heat Island (UHI) effect. But what is causing the blue, cooling effect in the southeast? Figure 2 is another map, the annual mean temperature in North America from 1950 to 2000. Note that the cooling area in Figure 1 is the warm area in Figure 2. Dr. Muller offered no explanation for the cooling in Figure 1.

Figure 3. From the BEST paper cited above showing the Gaussian trend distribution.
This author downloaded data from 71 sites with long, continuous, records (at least 1930 to 2000) scattered across the U.S. and Canada, concentrating on the cooling region and the areas north and west of it. Each location was (if possible) examined at Anthony Watts’ SurfaceStations.org web site, for metadata, especially the distance from the thermometer to the closest heated building. The populations of the surrounding areas were obtained from Wikipedia. The December, January, and February (winter) temperatures were downloaded from GISS, and the temperature trends from 1934 to 2000 were calculated for each site, as well as the average winter temperatures. Figure 4 is a plot of the average winter temperature versus the winter temperature trend for 71 locations.

Figure 4. This is the average winter temperature for 71 sites versus the warming or cooling trend over the period from 1934 to 2000. The average winter temperature was calculated over the period from 1930 to 1980.
The warming trend is obvious for locations with cold winters. The extreme example is Edmonton, Alberta, Canada, with 4.4 degrees C warming, with an average winter temperature of –11.9° C. The warming is, of course due to UHI. Edmonton grew from about 80,000 people in 1931 to 666,000 in 2001. The cold winter temperatures exaggerate the UHI effect. Figure 5 is a plot of warming versus current population.

Figure 5. This is a combined plot of the winter temperature trend (1934 to 2000) versus population (blue) and the distance from the thermometer to the nearest heated building, usually a residence (pink).
It seemed clear to this author before this study was begun, that a heated building close to the thermometer might skew the readings in a warm direction, and that this could be detected with a large sample. Figure 5 shows this is not generally true. The large surrounding population makes a large warming effect. This is exaggerated in the winter due to the difference between inside and outside temperatures causing more heat lost to the outside. This is not noticeable for single structures close by. The numbers were tortured until they confessed; there is little warming due to one farmer’s house 3 meters away, but several thousand homes in the immediate area produces a “heat bubble” that makes a difference. Heat going up chimneys far outweighs heat escaping from walls.
There are exceptions, of course. Figure 6 shows one notable one.

Figure 6. This is the weather station at Grand Forks, North Dakota. It is located at the NOAA/NWS Eastern North Dakota Weather Forecast Office. The Cotton Region Shelter (CRS) is located about 3 meters in front of the vent on the office heating/cooling plant. The Photo is from SurfaceStations.org.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The winter temperature trend at the Grand Forks NWS office is 2.9° C warming, about 1.5° C above what the population alone would account for. Another exception is the site at Albert Lea, Minnesota. (Figure 7.) The winter warming at Albert Lea is about 2.5°C over what the population would cause.

Figure 7. This is the water treatment plant at Albert Lea, MN. Buildings, water tanks, and waste-treatment ponds surround the MMTS. The Photo is from SurfaceStations.org.
These exceptions, and other locations like them, along with cities with large and growing populations, account for the red dots in figure one. The blue dots represent what the climate is really doing… cooling. The measured cooling does not extend into the cooler north and west because UHI warms these areas more than the south. UHI is exaggerated by the colder winters.
Is UHI a problem with rural sites with smaller populations, under 10,000? From the site collection, 50 sites with populations below 10,000 were sorted. These were in turn sorted into two groups by winter average temperatures. Figure 8 is the cooler group, Figure 9 the warmer.

Figure 8. These are plots of Winter Temperature and Temperature Trend versus Population at 25 sites with winter temperatures between 0°C and –10°C.

Figure 9. These are plots of Winter Temperature and Temperature Trend versus population at 25 sites with winter temperatures between 0°C and 10 °C.
Both Figures 8 and 9 show no change in temperature trend from 1934 to 2000 due to population. The average winter warming in both groups from 1934 to 2000 is about 0.5°C. But, there is significant winter temperature difference in both groups due to population. For locations with populations over 1000, winters are warmer, not getting warmer, but warmer all along. Why? These are all small towns and villages. They have been growing slowly, if at all, since the thermometers were installed. Population growth has been paced by improvements in heating system and insulation efficiency. But size is important. The absolute temperature in the winter is also important. BEST (and GISS) should recognize the need to reduce their rural population limit to 1000. Just looking for lights in the vicinity by satellite isn’t good enough. They must actually research the population and the location metadata. For locations with winters with average temperatures below freezing, special care should be taken to avoid close-by heat sources. It may be handy to locate a MMTS at the local water treatment plant, but it isn’t a good idea when measuring temperature.
What happened in the last decade? For a global view, GISS has a trend mapping application on their site. This was set to map the trend from 2001 to the end of 2011. Figure 10 shows the result.

Figure 10. The GISS map of annual (January to December) temperature trend (change) from 2001 to 2011. The –0.01 in the top right corner is the global trend figure, 0.01°C cooling. Source.
In Figure 10, the red grids showing 2°C to 4°C warming represent about 10 measuring sites, most on the Siberian Arctic coast. Those are warming because the wind is moving the ice away from the Siberian coast. Compare Figure 10 with Figure 1. Many red dots in figure 1 fall in the cooling area in Figure 10 above, the opposite of what the BEST paper shows. Those sites may have been warming over the period BEST used, but they are cooling now.
Note that in Figure 10, the continents appear to be cooling, with only land stations on the Arctic coast showing warming. The Pacific Ocean and the North Atlantic are mostly cooling. They will cool further as the continents continue cooling. We are now ten years into the next cycle in the regular 60 to 70 year warming and cooling cycles, and at the
end of a 200 year cycle that the earth has been experiencing since the Dalton Minimum (1790 to 1830). If the sun is indeed going into another Grand Minimum, similar to the Dalton or Maunder Minimums, and it looks like it will be most like the latter, the cooling may be very deep, and last for 40 or 50 years.
The USDA just released a plant hardiness zone map, moving the growing season northward by about one zone compared to the previous map. They may want to rethink that move. Last winter in southern New Mexico and west Texas the cold killed many Mexican palms trees, and other tropical plants, that had survived up to 100 years of previous winters. Thermometers may be made to lie, but plants can’t be fooled.
Conclusion
In the BEST paper, Dr. Muller failed to notice the change in UHI effect in northern stations, and thus missed the fact that cooling is really taking place in the continental U. S. as for myself, I wonder how cold it will be before Berkeley Earth discovers the cooling.
 
Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitterCFACT was one of the sponsors of the 4th International Climate Conference, which took place in Munich last weekend. What follows is a worthwhile interview with the Chairman of the European Institute for Climate and Energy (EIKE), Holger Thuss, presented by CFACT.
4th Climate Conference in Munich, 2011
=================================================
On Friday and Saturday, November 25
& 26, as the UN prepared to kick off COP17, the UN Conference
on Climate Change, in Durban, South Africa, CFACT, the European Institute for
Climate and Energy (EIKE) and others co-sponsored a climate conference of our
own in beautiful Munich, Germany. EIKE was launched in 2007 in Berlin. CFACT is
a proud founding member.
CFACT: What has been the public mood in Germany about global
warming?
For years, large parts of the population were buying into the
IPCC’s position without question. Others had some doubt, but could not find any
reliable source in their own language to educate themselves about anything
about climate that did not favor the Green’s narrative. It was terribly
one-sided.
Are things changing?
The media, while still often hostile, now takes serious interest
in our activities and today is willing to openly question whether the IPCC and
climate campaigners are always right. Today, more and more people in Germany
realize they have been misinformed and I can say without exaggerating that our
work played an important part in this. We see a real change, not just among
ordinary citizens, but also business leaders, lawmakers, media executives and
the consulting industry (which is very influential in Germany). People from
every sector of society are giving positive feedback, attending events, buying
our publications and are now not shy about giving us advice. People read the
newspaper and decided for themselves that something didn’t smell right. EIKE
with the help from CFACT gave them the facts and a way to meet one another,
organize and communicate.
Even more attended than last year!
What was it like organizing the first real organization in Germany to
question climate orthodoxy?
We had resistance from all sides. We needed 1 1/2 years to register
and organize – it took that long to overcome bureaucratic resistance. It was
even worse to deal with the hostile media which didn’t hesitate to tell
outright lies about our funding, research and the qualifications of our experts
– who are distinguished academics from prestigious universities! Some climate
radicals tried to make a big deal about the relationship between EIKE and CFACT
and just can’t seem to grasp that organizations can be friends too and
cooperate together to do great work. Today EIKE is proud to welcome cooperation
and support from many diverse and talented people and organizations. The
momentum is on our side.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Tell us about the climate conference program.
We have now conducted two workshops and four major conferences.
Every one has been a success and each was larger than the one before. There is
real excitement. We just completed our first conference in Munich, which was
timed to take place at the start of the UN climate conference in Durban. I was
very pleased to realize that 90 percent of the people attending were new. They
heard we were going to be in their region, wanted to be with us and were
willing to reach into their own pockets to support the conference financially.
They came not only from Southern Germany, but from Austria, Switzerland and
even South Korea and Paraguay.  We are rather proud to be able to offer
attendees simultaneous German and English translations throughout the
conference.
What were some highlights of this weekend’s conference?
Almost every presentation was a highlight because we heard state of the art science
from such distinguished researchers as Henrik Svensmark from Denmark, Nir Shaiviv
from Israel, Gernot Patzelt from Austria and Jan Veizer from Canada. We also
covered policy and legal aspects related to the downsides of renewable energy
and of course the Climategate scandal parts one and two from fascinating
speakers such as Donna Lafromboise from Canada and Chris Horner from the U.S.
We had so many more truly brilliant presenters that I hesitate to mention any
names at all, because each is worthy and we are extremely grateful to them all.
What message can CFACT carry from Munich to the UN’s COP17 in Durban?
We want the UN and everyone reading this to know that the IPCC
reports have been proclaiming their conclusions as unquestionable scientific
facts, when actually their science is faulty and Climategate shows the UN has
placed its trust in the wrong people. We call for open minds and vigorous
debate without fear. The IPCC should be replaced by a more credible
institution, perhaps one uniting research institutions from around the world,
free from bias and advocacy.
================================================
Visit CFACT here: http://www.cfact.org/
 
 
Share this...FacebookTwitter "
"

Readers of recent news reports may think it’s news that U.S. emissions of carbon dioxide, the main global‐​warming gas, are at an all‐​time high. The real news would be if they dropped steeply, which could only occur with a very warm winter (less space heating), a very cold summer (less air conditioning) or a huge recession, because it takes energy to make things. 



Carbon dioxide has been called breath of our civilization, and as we are technologically constituted, it most certainly is. We burn fossil fuels (which combust mainly to carbon dioxide and water) for manufacturing, to go places, and to produce electrical power. While we could certainly substitute in more nuclear fuels for power production, the same forces that are so exercised about global warming being caused by carbon dioxide, in general, won’t permit the nuclear option. (That being the definition of environmental insincerity.) 



So it is not news at all that our emissions are at a record high along with GDP. What is more newsworthy is how the emissions per unit of GDP — the economic bang for the energy buck — continue their steady decline. We now produce a constant dollar’s worth of goods and services with only 78% of the energy we used in 1990. In 1990, we used about two‐​thirds of the energy we used in 1970 for the same dollar’s worth. These are remarkable increases in efficiency in the last 35 years. 



The New York Times recently reported that the 2004 change in overall emissions was nearly double the annual average, neglecting to report that single‐​year statistics are virtually meaningless. If one had taken the average of the last five years and compared that to figures generated back to the mid-‘90s, percent changes in emissions of carbon dioxide turn out to be remarkably constant. 



For 1999–2004 the increase averaged 0.8% per year. From 1996 through 2001 the change averaged 1.0%. Given year‐​to‐​year fluctuations, these numbers are indistinguishable from each other. 



The same applies on a global scale. Our computer models for global warming have assumed, for decades, that carbon dioxide would increase at 1% per year in the atmosphere. For those decades the real rate of increase has been quite constant, and less than half of 1%. In the ten years ending in 2004, the average rate of increase was 0.49%. Ten years before it was 0.41%, and ten years before that, 0.42%. This is why climate models have generally predicted too much warming, too fast — about twice as much, in fact. 



Taken together, all of these facts mean that most of the assumptions about the growth of global warming gases in the atmosphere have to be thrown out. There’s little, if any, exponential increase, and the vibrant economies continue to produce more and more things with fewer increments of carbon dioxide. 



But, if carbon dioxide is the cost of economic growth, it would seem obvious that it will continue its upwards ascent for the foreseeable future. 



Will it? The answer lies in the well‐​established trends towards increasing efficiency in economies such as the United States’ (despite the large number of SUV’s panting in increasingly long traffic jams). This did not happen here because of concerns about global warming — because no one really gave much of a care about it until New Orleans got smacked by a Category 3 (yes, it’s been downgraded) hurricane. 



Instead, the increases in efficiency resulted because businesses compete with each other to produce things that cost less to run and build. And, if they are built, people will come. And so do investors. 



As an example of this process, get on your Yahoo financial tracker and plot the stock performance of Honda, Toyota, GM and Ford for the last two years. You’ll find the share price of the producers of the Accord and the Camry up an average of 40% while the American companies have dropped 50% in value. 



This creates a snowball effect in a warming world. People in vibrant economies have capital to invest in increasingly efficient companies, which rewards them with more capital, which is re‐​invested etc. 



The prospering companies are efficient in many ways. They use less energy to produce cars in their newer plants. Their cars use less energy on the road. Their labor forces tend to be relatively young and they haven’t been promised the moon in benefits and retirement with 40% of their time on earth left to run. 



As these companies accumulate capital, they have been reinvesting it in development of even more efficient vehicles, some of which may emit no carbon dioxide at all, which means that some day the pressures for efficiency may indeed drive carbon dioxide emissions down. But, without investment in those technologies — made by private individuals in publicly traded corporations — be assured that development of the clean machines of the future will be delayed until the planet gets warmer than some might want it. 



(Disclosure: The author owns shares in Honda and Toyota, sold all of his shares of Ford in 2002, and a GMAC bond in 2005.)
"
"

Tony Blair is deeply unpopular and has already announced that he will soon step down as England’s prime minister. But that does not mean he will go quietly into that good night. As reported by the _Daily Mail_ , the UK government has announced a series of totalitarian steps to compel less energy use: 



Homeowners who refuse to make their properties energy efficient will face financial penalties under drastic government plans to transform Britain into the world's first 'green' economy. …The Government said that every new home should be ""carbon neutral"" within ten years — and existing properties subject to a ""home energy audit"" to assess how green they are.



Critics correctly note this is a massive intrusion into the private lives of homeowners:   
  
Blair Gibbs, of the Taxpayers' Alliance, said: ""It's bad enough that politicians want to take so much of our money away in tax. For them also to intrude into our homes in order to have the ability to penalize us even further is simply unacceptable.""   
  
But the government is undaunted, and, in a classic case of the pot calling the kettle black, Tony Blair even has the gall to state that his totalitarian initiative is akin to the fight against fascism:



People are to be encouraged to make ""more sustainable"" travel choices, including greater use of public transport, walking and cycling. The Government is also to invest in solar, wind and wave power. …Mr Blair compared the fight against climate change to the battle against fascism.



Sadly, the British people cannot count on the Tories to defend individual freedom. Under the feckless leadership of David Cameron, the Conservative Party is even further to the left than Labor. The Party of Margaret Thatcher has become a hollow shell, judging from the _Daily Mail_ 's reporting: 



Opposition politicians and green campaigners said the Government's proposals did not go far enough, insisting binding targets on emissions should be annual. Tory spokesman Peter Ainsworth said: ""There is a danger that the fiveyear approach will enable responsibility for failure to be shunted on from one government to another.""


"
"

In the last two years, a remarkable amount of disturbing news has been published concerning global warming, largely concentrating on melting of polar ice, tropical storms and hurricanes, and mass extinctions. The sheer volume of these stories appears to be moving the American political process toward some type of policy restricting emissions of carbon dioxide.



It is highly improbable, in a statistical sense, that new information added to any existing forecast is almost always “bad” or “good”; rather, each new finding has an equal probability of making a forecast worse or better. Consequently, the preponderance of bad news almost certainly means that something is missing, both in the process of science itself and in the reporting of science. This paper examines in detail both recent scientific reports on climate change and the communication of those reports.



Needless to say, the unreported information is usually counter to the bad news. Reports of rapid disintegration of Greenland’s ice ignore the fact that the region was warmer than it is now for several decades in the early 20th century, before humans could have had much influence on climate. Similar stories concerning Antarctica neglect the fact that the net temperature trend in recent decades is negative, or that warming the surrounding ocean can serve only to enhance snowfall, resulting in a gain in ice. Global warming affects hurricanes in both positive and negative fashions, and there is no relationship between the severity of storms and ocean‐​surface temperature, once a commonly exceeded threshold temperature is reached. Reports of massive species extinction also turn out to be impressively flawed.



This constellation of half‐​truths and misstatements is a predictable consequence of the way that science is now conducted, where issues compete with each other for public support. Unfortunately, this creates a culture of negativity that is reflected in the recent spate of global warming reports.
"
