"
Share this...FacebookTwitter5300 years ago sea level near Surinam and Guyana was about 1m higher than today
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P. Gosselin)
A paper authored by Khan et al. 2017 looked at the Caribbean over the past 10,000 years.
After the end of the last ice age some 11,000 years ago, sea level rose around Surinam and Guyana at a rate of 11 mm per year. That’s about 5 times faster than today.
During the middle and late Holocene, i.e. over the past 5000 years, sea level rise was only 2.4 mm per year. By the way: 5300 years ago sea level at both countries was about 1 meter higher than today’s level. Surprised? Abstract:
Drivers of Holocene sea-level change in the Caribbean
We present a Holocene relative sea-level (RSL) database for the Caribbean region (5°N to 25°N and 55°W to 90°W) that consists of 499 sea-level index points and 238 limiting dates. The database was compiled from multiple sea-level indicators (mangrove peat, microbial mats, beach rock and acroporid and massive corals). We subdivided the database into 20 regions to investigate the influence of tectonics and glacial isostatic adjustment on RSL. We account for the local-scale processes of sediment compaction and tidal range change using the stratigraphic position (overburden thickness) of index points and paleotidal modeling, respectively. We use a spatio-temporal empirical hierarchical model to estimate RSL position and its rates of change in the Caribbean over 1-ka time slices. Because of meltwater input, the rates of RSL change were highest during the early Holocene, with a maximum of 10.9 ± 0.6 m/ka in Suriname and Guyana and minimum of 7.4 ± 0.7 m/ka in south Florida from 12 to 8 ka. Following complete deglaciation of the Laurentide Ice Sheet (LIS) by ∼7 ka, mid-to late-Holocene rates slowed to < 2.4 ± 0.4 m/ka. The hierarchical model constrains the spatial extent of the mid-Holocene highstand. RSL did not exceed the present height during the Holocene, except on the northern coast of South America, where in Suriname and Guyana, RSL attained a height higher than present by 6.6 ka (82% probability).The highstand reached a maximum elevation of +1.0 ± 1.1 m between 5.3 and 5.2 ka. Regions with a highstand were located furthest away from the former LIS, where the effects from ocean syphoning and hydro-isostasy outweigh the influence of subsidence from forebulge collapse.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterTop Swiss meteorologist Jörg Kachelmann blasts the quality of modern weather information in Germany, warning that 80-90% of weather stories found in the online media are “false information” or even “made-up nonsense”, and feels his field has become “a hoard of anarchy.”

Swiss meteorologist Jörg Kachelmann. Photo source: https://weather.us/
Yesterday here I reported how veteran Swiss meteorologist Jörg Kachelmann, 59, called the blaming of single weather events on climate change “complete idiocy”.
The quality of weather reporting and information, and the overall knowledge of natural sciences, have gotten so bad in Germany, according to Kachelmann, that he felt compelled to comment at the online Hannoversche Allgemeine Zeitung (HAZ). He wrote (link added by author):
 In matters concerning natural sciences, a collective educational precariat rules.”
Meaning: when it comes to knowledge of natural sciences, and especially meteorology, Germany is in trouble, and the citizens are being terribly disinformed.
Excessive, click-baiting media hype
One of the major reasons behind the destructive development, according to Kachelmann, is all the “nonsense” that gets reported by the media concerning the weather.
One example is the often-made claim today that severe thunderstorms or heavy downpours are linked to “climate change”. What in the past used to be just called a storm or bad weather, now gets recorded by countless mobile devices and sent to some studio, where it is hyped and sold as a 100-year event of Biblical proportions.
“Anarchy” ruling day-to-day weather reports
Kachelmann comments how today one often finds weather tips in the German media, e.g. for golfers and mountaineers, but which are in fact “complete idiocy”. Much of the nonsense, the Swiss meteorologist believes, is driven by the media’s insatiable appetite for clicks. “There’s anarchy in the weather report,” Kachelmann writes.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Today every north wind in the wintertime gets dubbed the “Siberian whip!” or every warm summer breeze from the south now gets labelled as a “Saharan heat wave!”, he describes.
Meteorology has become a hoard of anarchy
Kachelmann’s observations are spot on. But we could add that the rush to crank out sensational headlines is not limited to tabloids, but also flagship media outlets and once renowned weather and climatological institutes, who are now getting into the click-baiting, attention-seeking extreme weather frenzy.
For example “renowned” institutes are increasingly linking foul weather to climate change, and warn things are only going to get worse! “We’re toast!” the AP once warned, citing serious scientists.
“80 to 90% false information” …”or made up”
In Kachelmann’s view the field of meteorology has deteriorated so much that he comments at HAZ:
It’s truly a drama: Today 80 to 90 percent of the weather stories in the German online media are false information or often freely made-up nonsense. My science has become a hoard of anarchy.”
He adds:
The absence of knowledge about nature allows every nonsense to be printed — in order to generate clicks — yet not be recognized as such.”
So why has the German citizenry become so weather-disinformed?
Kachmann points to the educational system, where children are allowed to bypass natural science classes at schools. He comments at HAZ:
It is breathtaking what only a few decades and the allowance to skip school subjects can do to a country that, at least in folksongs, was long familiar with storms.”
============================================
Jörg Kachelmann runs Kachelmannwetter.com and, in cooperation with Dr. Ryan Maue, weather.us. He was formerly the meteorologist for flagship ARD German television.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThere’s capital to be derived from climate change, and now spiritual leaders and organized religion are getting in the act. And they offer a real Hell you can believe in – even certified by science!
Religion comes up with an all new, improved Hell
As enlightenment over the past decades and centuries have led the masses to doubt the once colorful concept of Hell — that fire-filled place reserved for the incorrigibly unvirtuous and run by reptilian demons — spiritual leaders have seen their clout in modern society erode. No longer is it so easy for them to control people’s behavior with feelings of guilt and threats of eternal damnation.
Recently, however, spiritual leaders have uncovered a new instrument to gain back some control over the masses: climate change – the new, and this time real Hell – yes, that’s been confirmed by 97% of the climate prophets – so disbelieve at your own risk!
Holy Words
This was demonstrated not long ago by Pope Francis’s Laudato si, His second encyclical. According to Wikipedia: “In it, the Pope critiques consumerism and irresponsible development, laments environmental degradation and global warming, and calls all people of the world to take ‘swift and unified global action’.”
The new Hell certified by “leading scientists”!
In a nutshell, do as they say or perish in climate hell. Laudato si was authored in large part by the Pope of Climate Doom himself, Prof. Hans-Joachim Schellnhuber of the ultra-alarmist Potsdam Institute for Climate Impact Research (PIK).
And just earlier this week, according to the online thecourier.com here  now the orthodox Christians are getting in on the act too. Once again Orthodox leaders too can let themselves stand morally above all others and preach to us on our sinful ways. And should we, the masses, not heed their Holy Science-Certified Words, then the new Hell (climate change) will ferociously engulf us as never seen before.
Hat-tip: a reader


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Frustrated scientists: message “not reaching people”
According to The Courier, leading climate change experts and campaigners gathered in Greece so that they could “work with the leaders of the Orthodox Church and other religions to fight global warming”.
Apparently activists and scientists are frustrated that their message is not reaching people fast enough. The two-day conference was inaugurated by “Green Patriarch” Bartholomew.
If science fails – then move on to faith!
Of course in attendance was the former PIK director and now accepted prophet Hans-Joachim (John) Schellnhuber. He told those in attendance:
Faith can help us because we scientists have tried everything. We can’t say what’s happening in a more compelling way when we warn about the end of civilization.”
According to the Courier, “hundreds of islanders” greeted Bartholomew “upon his arrival by boat”. The conference also included “long-breaded Orthodox priests” who got around in “golf carts and horse-drawn carriages”.
Climate visionaries and dignitaries
Also in attendance was a climate adviser to the Pope: Bill McKibben of 350.org; Jane Lubchenco, former NOAA head under Obama; Patricia Espinosa, UNFCC replacement for Christiana Figueres; Christiana Figueres herself, now Mission 2020; WAPO journalist Juliet Eilperin; and Jeffrey Sachs, economist, Columbia Earth Institute and climate adviser to the Pope.
No word if they came in on row boats, or horse-drawn carriages.
Share this...FacebookTwitter "
"While the G7 leaders have been pledging to stop using fossil fuels by 2100, we’re still waiting to hear the details of the Conservative government’s plans for renewable energy. The party’s manifesto commitment to “end any new public subsidy” for onshore wind farms does not bode well, however.  And virtually the first smoke signal issued by Amber Rudd, the new UK energy secretary, was that there could be an early end to the onshore wind subsidies paid to wind farms that have been built in previous years. This pleased many Conservative MPs and Scottish Conservatives, who were even more viscerally opposed to onshore windfarms in their election manifesto than their counterparts in other parts of the UK.  Industry, especially the electricity industry, does not want subsidies scrapped for existing or future onshore wind farms. Neither do NGOs involved in tackling climate change. Onshore wind is clearly the cheapest low-carbon form of electricity generation. With existing wind-farm owners threatening to sue and Scottish energy minister Fergus Ewing insisting that the Scottish government be consulted as a big contributor to UK wind overall, the latest reports are that the UK government has postponed an imminent announcement to consult first.  Conservative policy certainly puts the Scottish government in a bind. On one hand it needs to pursue its green-energy targets both to protect its left flank and to appease large sections of the Scottish energy industry. On the other hand the problem exposes the Scottish government’s reliance on English money to fund renewables in Scotland.  Yet at the same time, Scottish policy is central to UK-wide EU targets for 15% of energy to be renewable by 2020 (requiring about 30% renewable electricity). Almost two-thirds of the consented (but not yet commissioned) UK windfarm capacity is sited north of the border. The Scottish government’s own target is to source the equivalent of 100% of its electricity from renewable sources by 2020. By 2014 almost 50% of Scottish electricity generation came from renewables, predominantly wind and hydroelectricity (compared to 19% for the UK).  There is now sufficient capacity either installed, under construction, or given firm premium-price contracts to reach about two-thirds of the Scottish 2020 target. But even if all of the consented Scottish onshore wind farms that are still looking for funding are also implemented, the target would still only be 90% met – meaning that the two consented offshore wind projects in the Moray Firth need to go ahead too.  Yet during and since the independence debate, the Scottish government has carefully avoided the proposition that it should be given a portion of the UK renewable funding pot to spend on low-carbon energy. The pot was capped last autumn at £200m a year, and is funded by income from the electricity bills of UK consumers.  Behind this Scottish-government reticence lurks a fear that in future, Scotland would have to fund its renewable subsidies from the pockets of Scottish electricity consumers. Given that fewer than 10% of UK consumers are in Scotland, and that more than 25% of UK renewable energy incentives have been spent on Scottish renewables, such a change could end up severely limiting future Scottish renewables deployment. 
This helps to explain why the Scottish government has merely demanded that it be made a statutory consultee when changes to renewable policies are being made at Westminster.  Cynics might argue that Amber Rudd’s kite-flying about seeking an early end to subsidies for onshore wind under the old renewables-obligation scheme (which ends in 2017) is to show her wind-turbine-hating Tory colleagues that, in practice, being anti-onshore-wind is not so popular. She can then disavow the kite and, ultimately, be congratulated for her munificence by announcing the continuation of a policy of funding onshore wind until 2020.  She would say that the manifesto policy of ending subsidies was only for wind farms that had not yet been given planning consent, and could roll out extra funding for new projects under the new contracts-for-difference scheme to be implemented by early 2021.  But this loses sight of the bigger challenges. These revolve around greenhouse gas reduction, where the Scottish government is already being berated for not keeping up with its targets. We need to make substantial progress towards decarbonising heat and transport, which means supplying a lot more of it through electricity. This requires green power well beyond the current 100% target.  That is because we need to encourage electric cars and also supply low-carbon heat through heat pumps and district heating, not to mention having more green power to export south of the border. It would take longer and be more expensive to do this solely through offshore wind farms. Really Scotland needs to continue to embrace onshore wind and (also in the future) ground-mounted solar photovoltaics if its targets are to be achieved speedily and economically. In order to finesse away Tory opposition to future onshore wind farms in the UK, some authority over renewables financing could to be given back to the Scottish government – it has such power under the old renewables-obligation scheme, but not under contracts for difference. A compromise could emerge whereby the Scottish government took decisions over how to spend a part of the low-carbon incentives, and developers of renewables projects in Scotland could have a choice whether to fund projects out of that pot of money or the (bigger) Westminster fund.  Of course Scottish Renewables, the industry association, would be worried about how such legislation is drafted, fearing that here may be a drift towards stopping Scottish schemes being funded at all by Westminster. But provided it is drafted correctly, the Scottish government’s new statutory rights of consultation would most likely be a barrier to any slippage. This would mean that the UK’s policy of reducing carbon emissions could be defended at least in Scotland, if not in England and Wales."
"Fifty years ago, I concluded that the best thing for the planet would be a peaceful phase-out of human existence. We’re causing the extinction of hundreds of thousands of other species. With us gone, I believe ecosystems will be restored and there will be enough of everything. No more fighting over resources. The idea wasn’t as well received as I had hoped. My journey to advocating for voluntary human extinction began at school. I was born in the post-war baby boom in a small desert town in Oregon, in the US. There were more new students than the elementary school could cope with, so classes overflowed into churches. In my fourth year, we were taught in the county library; people checked out books as we learned. High school was the same: the cafeteria had to be converted into classrooms. There just weren’t enough resources – a situation that remains the same as we boomers enter our final decades.  After an involuntary stint in the army, I read Paul Ehrlich’s book Population Bomb, which argued that overpopulation would lead to food shortages and famine, and soon joined a movement called Zero Population Growth. Their slogan was Stop at Two, but it didn’t take much maths to work out that this would take too long. We were already overpopulated at 3.7 billion: instead of stopping at two children, we needed to stop at once.  At 25, I wanted to show I was serious. A medical school gave me a discounted vasectomy in exchange for being a student doctor’s first try at the procedure, which was successful. I became a supply teacher, which gave me plenty of free time to study population issues. In the summers, I hitchhiked around the US, as many thousands did in the 1970s. Everywhere, people told me that their locale used to be so nice before all these people moved in, and it became too crowded. In the late 1980s, I settled in Portland, Oregon, and began to call this concept the Voluntary Human Extinction Movement. Our message is simple: we encourage people to stop procreating so the biosphere might return to its former glory, and everyone already here will be able to live life more abundantly. In 1996, when we got a website, things took off. People from all over the world emailed me, saying they had thought they were alone. I got hate mail, too. “You first,” is a common taunt. OK, I got snipped; you next. My favourite encounters are with people who thoroughly question the concept: I’ll take thoughtful disagreement over mindless agreement any day. I don’t know how many share my beliefs, but I speak to hundreds of advocates each year. We have active volunteers across the world, from India to Mexico. In my own relationships, I’ve always explained that pregnancy is impossible. Marriage never made sense to me anyway: I would have missed getting to know many wonderful women had I stuck with one. Today, Extinction Rebellion and the climate strike movement haven’t quite embraced the population’s contribution to the crisis. Other high-profile population awareness organisations are working hard to be acceptable, so suggest zero or one offspring, and still say stop at two. Two is too many: computer models suggest even one-child families would result in 5-10 billion people by 2100. Although the basic concept of the movement is the same, my motivations have evolved. I was a deep ecologist at first, caring more about our impact on the ecosphere than human needs. I’ve become more concerned about any new humans being brought into existence. Procreation today is the moral equivalent of selling berths on a sinking ship. It’s true that society would be greatly diminished without children, but it isn’t right to create them just because we like having them around. People worry that we won’t have enough workers to support pensioners, but economic systems are artificial and can be adjusted. We don’t need to breed more wage slaves to prop up an obsolete system. If we go extinct, other species will have a chance to recover. I’ll never see the day when there are no humans on the planet, but I can imagine what a magnificent world it would be – provided we go soon enough. ● As told to Freya Pratty If you would like your comment on this piece to be considered for Weekend magazine’s letters page, please email weekend@theguardian.com, including your name and address (not for publication). Do you have an experience to share? Email experience@theguardian.com"
"Egyptian billionaire Naguib Sawiris recently announced plans to buy a Greek island to give refugees from the Middle East and Africa a country of their own. Though Sawiris referred to his proposal as a “crazy idea” on Twitter, it pales in comparison to an earlier scheme for the Mediterranean from the first half of the 20th century, which was seriously considered by heads of state and, at one point, even the United Nations. It was called Atlantropa, and would have involved the partial draining of the Mediterranean Sea and the creation of a Eurafrican supercontinent.   Atlantropa was the brainchild of the German architect Herman Sörgel, who tirelessly promoted his project from 1928 until his death in 1952. His experience of World War I, the economic and political turmoil of the 1920s and the rise of Nazism in Germany convinced Sörgel that a new world war could only be avoided if a radical solution was found to European problems of unemployment, overpopulation and, with Saudi oil still a decade away, an impending energy crisis. With little faith in politics, Sörgel turned to technology. Dams across the Strait of Gibraltar, the Dardanelles, and eventually between Sicily and Tunisia, each containing gigantic hydroelectric power plants, would form the basis for the new supercontinent. In its final state the Mediterranean would be converted into two basins, with the western part lowered by 100 meters and the eastern part by 200 meters and a total of 660,200 km2 of new land reclaimed from the sea – an area larger than France. Later plans for Atlantropa also included two dams across the Congo River and the creation of a Chad and Congo Sea, which Sörgel hoped would have a moderating influence on the African climate making it more pleasant for European settlers. In line with the colonial and racist attitudes of the times, Sörgel envisaged Africa with its resources and its land to be entirely at the disposal of Europe, a continent with plenty of space to accommodate Europe’s huddled masses. While Sörgel’s proposal may sound absurd to our ears, it was taken seriously by architects, engineers, politicians and journalists at the time. The extensive Atlantropa archive in the Deutsche Museum in Munich abounds with architectural drawings for new cities, the dams and bridges of the future continent as well as letters of support and hundreds of articles about the project, which appeared in the German and international popular press as well as in specialised engineering and geographical magazines. What made Atlantropa so attractive was its vision of world peace achieved not through politics and diplomacy, but with a simple technological solution. Atlantropa would be held together by a vast energy net, which would extend from the gigantic hydroelectric plant in the Gibraltar dam and provide the entirety of Europe and Africa with electricity. The power plant would be overseen by an independent body who would have the power to switch off the energy supply to any individual country that posed a threat to peace. Moreover Sörgel calculated that the construction of the supercontinent would require each country to invest so much money and people power that none would have sufficient resources to finance a war. Putting his faith in the people of Europe and their desire for peace, Sörgel dedicated a large part of his work to the promotion and dissemination of the project through the popular press, radio programmes, films, talks, exhibitions and even poetry and an Atlantropa symphony. He hoped popular support would help him get the backing of politicians.  Unsurprisingly, in the eyes of his contemporaries the required collaboration between nation states always appeared even more utopian than the vast technological dimensions of Atlantropa. As the New York-based magazine UN World observed in 1948:  Harnessing Gibraltar for mankind’s good does sound like a dream, but in this 20th century no dream – not even that of cooperation among nations – is quite impossible. By 2012, when the European Union was awarded the Nobel Peace Prize in acknowledgement of its contribution to lasting peace in Europe, the hope expressed by the UN World appeared to finally have come true. However, in 2015, cooperation among nations sadly looks like a distant dream once again. Where once Herman Sörgel had used the image of a Europe bursting at the seams that is saved by a peaceful merger with the African continent, we are now confronted with the mirror image as people from across Africa and the Middle East seek refuge in Europe.  Now would be the time to prove that the Peace Prize was indeed deserved. Now would be the time to show solidarity and unity. Instead, the EU appears on the brink of being torn apart over its inability to find a communal solution to accommodate a group of refugees, whose number ultimately comes to no more than a meagre 0.11% of the overall population of the Union. Sadly European unity, and with it a solution for the refugee crisis, once again appears more utopian than Sörgel’s plans for draining the sea."
"
Share this...FacebookTwitterSerious Climate Doping Suspicion Against RSS: Satellite Temperatures Raised One And Half Tenths Of A Degree
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(Translated/edited by P Gosselin)
Temperatures can be measured from the ground and from satellites. Satellite data have two versions, UAH and RSS. The version of UAH (University of Alabama, Huntsville) makes a solid impression. The RSS version shows larger deviations and suggests a stronger warming. 
How come? 
Doping the data
Both datasets surely get their data from similar satellites. The explanation lies in a “post-processing” of the measured values ​​by the RSS group. In the chart below you can see the old version in red. 

Global temperature based on RSS satellite measurements. From Climate4You Newsletter June 2018.
At some point from mid 2015, the RSS people pushed the temperatures starting at  the year 2000 manually upwards. Therefore today you can find the values ​​of the blue curve in the database. As a result of this subsequent data change, additional warming was generated at a speed of one and a half tenths of a degree. It does not sound very much, but it is much if you consider that the 20th century warming was only eight-tenths of a degree.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Data on statistical steroids
It’s a little bit as like a year 2010 high jump world record of 2.40 meter later being changed to 2.45 meter by the International Athletics Federation. We could call this desktop doping, which would certainly not be a bad description for the RSS intervention. 
RSS statisticians massively massaged their data under the radar, without any interest from the media. A few years later new heat records get surprisingly reported, but in many cases likely solely through the heat-promoting measures of desktop doping. 
Change the data to fit the broken models
The changes happen to affect the hiatus phase, as it apparently had to do with the fear that the warming would not continue. The values ​​were simply raised. It’s a classic case where the readings did not confirm the models. But instead of improving the models, the measurement data were changed. There are hardly any other disciplines out there where things work this way.
Once again, it’s clear that we urgently need climate-related checks. The damage to the trust is already done. Now only stricter checks can help, and restricting employees in cases of suspicion – lifelong in the case of repeat-offenders. 
Criminal fraud
Proposal: Anyone who fabricates or falsifies climate data, or brings these willfully into the public, should be punished with 2 years in prison.
 
Share this...FacebookTwitter "
nan
"Pope Francis’s encyclical on the environment has quickly made him one of the world’s most significant figures in the climate debate. His message was notable not just for its acceptance of mainstream climate science but also for its outright rejection of market logic.  Nowhere is this more clear than when he addresses the various emissions trading and carbon offsetting schemes that leave decisions such as whether to phase out coal power in the hands of the market. These “carbon markets”, he said, are a “ploy which permits maintaining the excessive consumption of some countries and sectors”. If only our politicians were able to see this as clearly as Pope Francis. As we approach the 2015 UN climate conference in Paris, carbon markets just won’t go away – even despite the fact market solutions actively hinder our ability to make serious emissions cuts. The first round of pre-Paris negotiations in Geneva in February produced a draft negotiating text that is littered with references to new and expanded market mechanisms. The market-based agenda was pushed by negotiators from the EU, US, Japan and Brazil and provoked an optimistic response from financial, fossil fuel and other industry interests at the recent Carbon Expo in Barcelona. Ahead of Paris, many will ask whether we are in for a repeat of the disastrous Copenhagen climate change conference in 2009. But given the current focus on market-based approaches, it is necessary to look at the record of the carbon markets that formed the basis of the agreement that a Paris deal will replace: the 1997 Kyoto Protocol. Kyoto was a landmark agreement that bound developed countries to reduce their greenhouse gas emissions by an average of 5% between 2008 and 2012 from 1990 levels. It also included a number of novel market instruments for meeting that goal – one of the most important of which was the Clean Development Mechanism. The CDM allows developed countries to substitute domestic efforts to combat climate change for emissions reductions generated by projects in developing countries. The operators of these projects, which can be anything from wind farms to rubbish dumps, are awarded “carbon credits” for each tonne of carbon they reduce compared to what would otherwise have occurred. The credits are then traded, bought and surrendered by governments that ratified Kyoto, or corporations covered by the EU’s Emissions Trading System, as an alternative to reducing their own emissions. We have carried out research, recently published in a special carbon offsetting edition of the journal Environment and Planning A, which explores some of the problems with the CDM. We used the Gujarat Fluorochemicals Limited industrial gas destruction facility in Gujarat, India, as a case study – it was the first of more than 7,000 registered CDM projects. Our findings demonstrate why governments should exclude carbon markets from international climate negotiations. Between 2005 and 2013, the GFL project was awarded more than 55m carbon offset credits for destroying a potent greenhouse gas known as HFC-23, a by-product of the refrigerant gases produced by the factory. Sales of the credits proved to be extremely lucrative for the company, bringing in more than half a billion US dollars and generating business for associated carbon trading industries. However, local communities surrounding the project weren’t so happy. They claim to have suffered from pollution from the GFL plant for many years and have had to put up resistance. Local villagers, GFL workers and activists from NGOs told us the air, soil and water pollution generated by the plant had harmed their health and agricultural output.  The CDM entrenched and exacerbated these problems as it encouraged the company to maximise the production of refrigerant gases that were causing the pollution in order to destroy HFC-23 and receive as many carbon credits as possible. The company was effectively profiting from local pollution in order to let richer nations of the hook for their own emissions. While working on this article we put these accusations to GFL but the company did not respond. This perversity benefited the European corporations that purchased the credits but was bad news for the climate. For example, EDF Energy, which made a pro-carbon market submission to the UK’s Energy and Climate Change Committee, surrendered more than 200,000 GFL offset credits. The purchases allowed the company’s fossil fuel power stations in the UK to pollute over their level of allocated by the EU, while at the same time EDF could justify its attempts to cultivate a “green” marketing image, such as sponsoring the 2012 London Olympics as “official sustainability partner”. Campaigns from NGOs such as Carbon Market Watch and Paryavaran Mitra resulted in the EU banning the use of HFC-23 offsets and the United Nations making some changes to rules governing carbon credits. However, the poor social and ecological impacts of the GFL project were the product of the economic imperatives that underpin carbon markets in general. Carbon markets are in fact designed to seek out cheap emissions reductions such as HFC-23 destruction over fundamental structural changes to energy systems away from fossil fuels and towards renewables. Researchers and activists have linked this profit-driven logic to the creative accounting, financial fraud, phantom emissions reductions and polluter subsidies that have riddled carbon markets, arguing they cannot be reformed and should be scrapped. Further, the negative impacts of CDM offset projects have not been restricted to large industrial projects like HFC-23 destruction, with projects from forestry to biogas and coal to wind, repeatedly being exposed as fuelling local conflicts in developing countries. Expanding protections for local communities and environments beyond the “boutique” schemes currently in place face strong structural barriers because they interfere with the profits of project developers or fossil fuel industries. As a result, the continuation, expansion or creation of new market mechanisms in the Paris agreement is likely to generate further damaging outcomes at offset projects, mostly in the Global South. At the same time, relying on carbon markets will work against the capacity of governments around the world to end the era of coal, oil and gas. Policies that benefit the already powerful and harm those most affected by climate change? Nothing could be further from Pope Francis’s message linking climate issues with development and global justice. Perhaps he’ll be the man to finally make inroads with the people that matter, as governments will be faced with a stark choice in Paris: continue with the failed market-based approach or plan a serious transition away from fossil fuels."
"
Share this...FacebookTwitterNo matter how hard climate-catastrophe obsessed alarmists attempt to beat out a little doom from the data, their results still fall far way short of their projections. Moreover, the modest warming the planet has seen over the recent decades is tied more to natural cycles.
One alarmist tweeted in response to one of my recent posts with a WoodForTrees chart showing a temperature rise over the past 40 years. His aim was to say: The temperatures are rising fast and are right on course with the models:

At first glance we see that the satellite data do show a warming trend over the past 40 years, and so the alarmists must be right – some might think.
But look at the chart more closely.
If you do, you’ll see that the global temperature over the past 40 years has risen from an anomaly of -0.2°C to +0.3°C, meaning a whopping 0.5°C over 40 years, which is 1.2°C per century.
When we put this in perspective, this is far lower than the than 4 to 6°C per century that the alarmists often like to have the public believe.
Putting this on a chart (I had to do a little rescaling):


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Chart: P Gosselin, using WoodForTrees data.
Of course the recent pause was interrupted by an El Nino event and the latest satellite data show that the global surface temperature is down to a mere anomaly of only 0.12°C:

Chart snipped from Weatherbell Saturday Summary, July 14, 2018.
Temperature is not the only magnitude that global warming alarmists have totally exaggerated. Another example mentioned earlier is Arctic sea ice, which has been expanding over the past decade, i.e. doing the opposite of what was forecast:

Al Gore’s hysterical projections of ice-free Arctic late summers are exposed as an absolute sham. 2018 uses a conservative projected value.
Today the doomsday scenarios and projections made 10 years ago have yet to show any signs of coming true. In fact, many scientists are projecting a cooling tendency ahead.
Share this...FacebookTwitter "
"Orangutans are often more popular on the internet than in their native forests. Online, their attractive faces, fluffy bodies and swinging abilities make them perhaps the most shareable of all the great apes. But back in Borneo and Sumatra, where local populations are more ambivalent about orangutans, the situation is less straightforward. The third annual International Orangutan Day was held in August: a celebration of all things orangutan which aimed to highlight their crisis and encourage public action. For 24 hours, orangutan conservation organisations filled Facebook and Twitter with images, trivia and calls to save the rainforests of Borneo and Sumatra – their only home. People donated to charities, signed petitions, liked, tagged, shared and retweeted content, posted supportive selfies and even organised local gatherings to mark the day.  This was just one of many digital entry-points that has made orangutan conservation an increasingly accessible, everyday affair. Today, one doesn’t need to gain a PhD, spend months in the jungle or stage Greenpeace-style confrontations to help save orangutans. Thanks to digital technology and social networking, ordinary members of the public can do their bit.  The dominant narrative portrays orangutans as being pushed to the brink of extinction by deforestation and the expansion of oil palm plantations. This is often illustrated by a colourful cast of both stereotypical characters – the majestic, handsome male, the loving mother and the cute baby – and individual personalities such as Budi and Jemmi, two orphans in Sumatra whose adventures have been avidly followed across Facebook, Twitter and their rescue centre’s website.  These charismatic creatures bring a powerful immediacy and reality to the dominant narrative. Through them, an account of environmental destruction and species loss is turned into a series of gripping stories and personal tragedies: the innocent babies who have lost their mothers, the formidable male left helpless by chainsaws, the “saved” victims in need of help.  Not simply animals or scientific specimens, these orangutans are the very faces of the rainforest – threatened by appropriately large, faceless villains. As such, they’re immensely powerful magnets of public affection, support and funding.  In the midst of all this, however, some other faces and voices remain hidden. Among them are the people who live alongside orangutans in Borneo and Sumatra.  Many orangutan conservation bodies work closely with local partners and communities. But these collaborations tend to receive far less attention in online conversations and popular perceptions of the orangutan “crisis”. And when local communities do appear in conservation material, they’re often cast as either victims of deforestation or as “ecologically noble” allies who simply need to be educated about conservation. But as any anthropologist would point out, real life is far more complicated than that. Even the most exotic groups have internal divisions, ambitions, political leanings and ethical dilemmas. Not everybody is an instinctive defender of the forest or subscriber to Western conservation values.  Indeed, many rural Borneans are understandably more concerned about obtaining development and guarding their livelihoods – from crop-raiding orangutans, for instance – than the rather vague idea of saving the environment. And as recent research has shown, humans and orangutans are not always natural bedfellows. Hunting and conflict-related killing have also contributed to the decline of orangutan populations in recent decades.  Such findings don’t make for easy reading, not least because they reveal the complex humanity of Bornean and Sumatran populations. Like orangutans, these rainforest dwellers also have a vital stake in the fate of their environment – but in ways that can challenge the black-and-white morality of the dominant conservation narrative.  Only a small minority of these voices are currently part of digital conversations about orangutan conservation. But if orangutan conservation goals are to be realised, these local faces and voices can’t be glossed over. Rather, they need to be more carefully integrated into the dominant narrative – while ideally helping to transform it."
"
Share this...FacebookTwitterThe advocacy for widespread growth in renewable energy (especially wind, solar, and biomass) usage has increasingly become the clarion call of the anthropogenic global warming (AGW) movement.  And yet more and more published research documents the adverse effects of relying on renewables.

Image: Wasili Karbe, cropped from video here.
Over the course of the last year, at least 30 papers have been published in the peer-reviewed scientific literature detailing the fatuity of promoting renewable energy as a long-term “fix” for climate change mitigation.  A categorized list of these papers is provided below.
1. “More Renewables Mean Less Stable Grids” 
Schäfer et al., 2018    “Multiple types of fluctuations impact the collective dynamics of power grids and thus challenge their robust operation.”
(press release)   “More renewables mean less stable grids, researchers find …  [I]ntegrating growing numbers of renewable power installations and microgrids onto the grid can result in larger-than-expected fluctuations in grid frequency.”
2. Increasing Fossil Fuel Use (Natural Gas) Reduces Emissions More Than Increasing Wind/Solar Energy
Anderson et al., 2018     “Before considering the future, it is worth examining just how far we’ve already come without any federal CO2 regulation (for existing power plants) in the U.S. Figure 1 illustrates historical CO2 emissions and natural gas prices from 2005 through 2017 (estimated). During that period, emissions have declined from nearly 2.7 billion tons to approximately 1.9 billion tons (∼30%), while revealing a strong link to natural gas prices. To be sure, while other factors (such as renewable energy incentives) also had an impact, the clearest means by which to reduce CO2 emissions has been to reduce the cost of generating electricity with less CO2-emitting fuels (i.e., substituting natural gas for coal). So successful have market forces been under the existing regulatory framework to date that estimated 2017 CO2 emission levels are already at the CPP’s 2025 target(albeit without accounting for electricity demand growth between 2017 and 2025), well exceeding the AEO’s own Reference Case projections for 2025.”
Jewell et al., 2018     “Hopes are high that removing fossil fuel subsidies could help to mitigate climate change by discouraging inefficient energy consumption and leveling the playing field for renewable energy.Here we show that removing fossil fuel subsidies would have an unexpectedly small impact on global energy demand and carbon dioxide emissions and would not increase renewable energy use by 2030. Removing [fossil fuel] subsidies in most regions would deliver smaller emission reductions than the Paris Agreement (2015) climate pledges and in some regions global [fossil fuel] subsidy removal may actually lead to an increase in emissions, owing to either coal replacing subsidized oil and natural gas or natural-gas use shifting from subsidizing, energy-exporting regions to non-subsidizing, importing regions.”
3. Renewables Fail To Deliver: When Demand Is High, Generation Capacity Is Low
Cradden and McDermott, 2018     “Prolonged cold spells were experienced in Ireland in the winters of 2009–10 and 2010–11, and electricity demand was relatively high at these times, whilst wind generation capacity factors were low. Such situations can cause difficulties for an electricity system with a high dependence on wind energy.”
4. Renewable Energy Becomes More Costly The More It Is Deployed … Renewable Energy Expansion Ensures More Fossil Fuel Installation Is Necessary As Backup
Blazquez et al., 2018     “However, promoting renewables –in liberalized power markets– creates a paradox in that successful penetration of renewables could fall victim to its own success. With the current market architecture, future deployment of renewable energy will necessarily be more costly and less scalable. Moreover, transition towards a full 100% renewable electricity sector is unattainable. Paradoxically, in order for renewable technologies to continue growing their market share, they need to co-exist with fossil fuel technologies. … The paradox is that the same market design and renewables policies that led to current success become increasingly less successful in the future as the share of renewables in the energy mix grows. … Full decarbonization of a power sector that relies on renewable technologies alone, given the current design of these markets, is not possible as conventional technologies provide important price signals. Markets would collapse if the last unit of fossil fuel technologies was phased out. In the extreme (theoretical) case of 100 percent renewables, prices would be at the renewables marginal cost, equal to zero or even negative for long periods. These prices would not be capturing the system’s costs nor would they be useful to signal operation and investment decisions. The result would be a purely administered subsidy, i.e., a non-market outcome. This is already occurring in Germany as Praktiknjo and Erdmann [31] point out and is clearly an unstable outcome. Thus, non-dispatchable technologies need to coexist with fossil fuel technologies. This outcome makes it impossible for renewables policy to reach success, defined as achieving a specified level of deployment at the lowest possible cost. With volatile, low and even negative electricity prices, investors would be discouraged from entering the market and they would require more incentives to continue to operate.”
Marques et al., 2018     “The installed capacity of wind power preserves fossil fuel dependency. … Electricity consumption intensity and its peaks have been satisfied by burning fossil fuels. … [A]s RES [renewable energy sources] increases, the expected decreasing tendency in the installed capacity of electricity generation from fossil fuels, has not been found. Despite the high share of RES in the electricity mix, RES, namely wind power and solar PV, are characterised by intermittent electricity generation.  … The inability of RES-I [intermittent renewable energy sources like wind and solar] to satisfy high fluctuations in electricity consumption on its own constitutes one of the main obstacles to the deployment of renewables. This incapacity is due to both the intermittency of natural resource availability, and the difficulty or even impossibility of storing electricity on a large scale, to defer generation.  As a consequence, RES [renewable energy sources] might not fully replace fossil sources …  In fact, the characteristics of electricity consumption reinforce the need to burn fossil fuels to satisfy the demand for electricity. Specifically, the ECA results confirm the substitution effect between the installed capacity of solar PV and fossil fuels. In contrast, installed wind power capacity has required all fossil fuels and hydropower to back up its intermittency in the long-run equilibrium. The EGA outcomes show that hydropower has been substituting electricity generation through NRES [non-renewable energy sources], but that other RES have needed the flexibility of natural gas plants, to back them up. … [D]ue to the intermittency phenomenon, the growth of installed capacity of RES-I [intermittent renewable energy sources – wind power] could maintain or increase electricity generation from fossil fuels.  … In short, the results indicate that the EU’s domestic electricity production systems have preserved fossil fuel generation, and include several economic inefficiencies and inefficiencies in resource allocation. … [A]n increase of 1% in the installed capacity of wind power provokes an increase of 0.26%, and 0.22% in electricity generation from oil and natural gas, respectively in the long-run.”
5. Biofuels – Declared Carbon-Neutral Renewables By The EU – Increase Emissions More Than Coal 
Sterman et al., 2018     “[G]overnments around the world are promoting biomass to reduce their greenhouse gas (GHG) emissions. The European Union declared biofuels to be carbon-neutral to help meet its goal of 20% renewable energy by 2020, triggering a surge in use of wood for heat and electricity (European Commission 2003, Leturcq 2014, Stupak et al 2007). … But do biofuels actually reduce GHG emissions? … [A]lthough wood has approximately the same carbon intensity as coal (0.027 vs. 0.025 tC GJ−1 of primary energy […]), combustion efficiency of wood and wood pellets is lower (Netherlands Enterprise Agency; IEA 2016). Estimates also suggest higher processing losses in the wood supply chain (Roder et al 2015). Consequently, wood-fired power plants generate more CO2 per kWh than coal. Burning wood instead of coal therefore creates a carbon debt—an immediate increase in atmospheric CO2 compared to fossil energy—that can be repaid over time only as—and if— NPP [net primary production] rises above the flux of carbon from biomass and soils to the atmosphere on the harvested lands. … Growth in wood supply causes steady growth in atmospheric CO2 because more CO2 is added to the atmosphere every year in initial carbon debt than is paid back by regrowth, worsening global warming and climate change. The qualitative result that growth in bioenergy raises atmospheric CO2 does not depend on the parameters: as long as bioenergy generates an initial carbon debt, increasing harvests mean more is ‘borrowed’ every year than is paid back. More precisely, atmospheric CO2 rises as long as NPP [net primary production] remains below the initial carbon debt incurred each year plus the fluxes of carbon from biomass and soils to the atmosphere. … [C]ontrary to the policies of the EU and other nations, biomass used to displace fossil fuels injects CO2 into the atmosphere at the point of combustion and during harvest, processing and transport. Reductions in atmospheric CO2 come only later, and only if the harvested land is allowed to regrow.”
Fanous and Moomaw, 2018     “These nations fail to recognize the intensity of CO2 emissions linked to the burning of biomass. The chemical energy stored in wood is converted into heat or electricity by way of combustion and is sometimes used for combined heat and power cogeneration. At the point of combustion, biomass emits more carbon per unit of heat than most fossil fuels. Due to the inefficiencies of biomass energy, bioenergy power plants emit approximately 65 percent more CO2, per MWH than modern coal plants, and approximately 285 percent more than natural gas combined cycle plants. Furthermore, the Intergovernmental Panel on Climate Change (IPCC) states that combustion of biomass generates gross greenhouse gas (GHG) emissions roughly equivalent to the combustion of fossil fuels. In the case of forest timber turned into wood pellets for bioenergy use, the IPCC further indicates that the process produces higher CO2 emissions than fossil fuels for decades to centuries.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




6. Biofuels “Use More Energy At A Higher Cost” And Produce More Air Pollution Than Fossil Fuels
Richardson and Kumar, 2017     “A growing human population creates a larger demand for food products and makes conservation of resources and increased efficiency of agricultural production more vital. … These results conclude that feed production systems are more energy efficient and less environmentally costly than corn-based ethanol. … [A]ccording to the findings of this study, biofuels, derived for the purpose of producing energy with little environmental impacts, actually use more energy at a higher environmental cost than the alternative crop use. As technology stands now, in terms of energy and environmental sustainability, the benefits of switching land uses to the production of corn-based transportation biofuels are not as favorable as continuing to produce corn for feed/food consumption.”
Emery et al., 2017     “Although climate change mitigation and energy security policies are generally expected to be compatible with air pollution and health cost reductions (McCollum et al., 2013), there is evidence that first-generation alternative fuels such as corn ethanol lead to higher health costs due to air pollution than conventional fuels [gasoline]  (Hill et al., 2009). … We find that life-cycle non-GHG air pollutant emissions, particularly NOX [nitrous oxides] and PM [particulates], are higher for corn ethanol and other biofuel blends than conventional petroleum fuels. Emissions of volatile organic compounds (VOCs) and carbon monoxide (CO) increase by 9–50% per 100 km traveled for high-ethanol blends from corn grain and combined grain and stover feedstocks. NOX, PM [particulates], and SOX [sulfur dioxides] increase by 71–124% from corn grain and 56–110% from combined grain and stover, relative to conventional gasoline. Biodiesel blends show an increase of 1–11% (B20) and 4–55% (B100) in air pollution, with the largest increases in VOC [volatile organic compounds] and SOX [sulfur dioxides] emissions. … The total social costs of ethanol blends are higher than that of gasoline, due in part to higher life-cycle emissions of non-GHG pollutants and higher health and mortality costs per unit.”
7. Proximity To Wind Turbines Significantly Reduces Quality Of Life, Well-Being For Nearby Residents
Barry et al., 2018     “The findings indicate that residential proximity to wind turbines is correlated with annoyance and health-related quality of life measures. These associations differ in some respects from associations with noise measurements. Results can be used to support discussions between communities and wind-turbine developers regarding potential health effects of wind turbines.”
Krekel and Zerrahn, 2017     “We show that the construction of wind turbines close to households exerts significant negative external effects on residential well-being … In fact, beyond unpleasant noise emissions (Bakker et al., 2012; McCunney et al., 2014) and impacts on wildlife (Pearce-Higgins et al., 2012; Schuster et al., 2015), most importantly, wind turbines have been found to have negative impacts on landscape aesthetics (Devine-Wright, 2005; Jobert et al., 2007; Wolsink, 2007). … We show that the construction of a wind turbine within a radius of 4,000 metres has a significant negative and sizeable effect on life satisfaction. For larger radii, no negative externalities can be detected.”
Gortsas et al., 2017     “Infrasound, low frequency noise and soil vibrations produced by large wind turbines might disturb the comfort of nearby structures and residents. In addition repowering close to urban areas produces some fears to the nearby residents that the level of disturbance may increase. Due to wind loading, the foundation of a wind turbine interacts with the soil and creates micro-seismic surface waves that propagate for long distances and they are able to influence adversely sensitive measurements conducted by laboratories located far from the excitation point.”
8. “Renewable Energy Consumption Has A Negative Effect On Economic Growth”
Lee and Jung, 2018     “The results of the autoregressive distributed lag bounds test show that renewable energy consumption has a negative effect on economic growth, and the results of a vector error correction mechanism causality tests indicate a unidirectional relationship from economic growth to renewable energy consumption. The empirical results imply that economic growth is a direct driver expanding renewable energy use. In terms of policy implications, it is best for policy makers to focus on overall economic growth rather than expanding renewable energy to drive economic growth. … [O]ur result suggests that renewable energy policy should be implemented when the real GDP is enough large to overcome the negative impact from renewable energy, because the causality from economic growth to renewable energy consumption in the long run as one of our result is caused by both low productivity of renewable energy production and expansion of government-led renewable energy.”
9. Research: 100% Renewable Energy Is “Unattainable” In Reality – Decarbonization Is “Arguably Reckless”
Clack et al., 2017   “The scenarios of [Jacobson et al., 2015, “Low-cost solution to the grid reliability problem with 100% penetration of intermittent wind, water, and solar for all purposes”] can, at best, be described as a poorly executed exploration of an interesting hypothesis. The study’s numerous shortcomings and errors render it unreliable as a guide about the likely cost, technical reliability, or feasibility of a 100% wind, solar, and hydroelectric power system. It is one thing to explore the potential use of technologies in a clearly caveated hypothetical analysis; it is quite another to claim that a model using these technologies at an unprecedented scale conclusively shows the feasibility and reliability of the modeled energy system implemented by midcentury. From the information given by [Jacobson et al., 2015], it is clear that both hydroelectric power and flexible load have been modeled in erroneous ways and that these errors alone invalidate the study and its results.”
Heard et al., 2017     “While many modelled scenarios have been published claiming to show that a 100% renewable electricity system is achievable, there is no empirical or historical evidence that demonstrates that such systems are in fact feasible. Of the studies published to date, 24 have forecast regional, national or global energy requirements at sufficient detail to be considered potentially credible. We critically review these studies using four novel feasibility criteria for reliable electricity systems needed to meet electricity demand this century. [N]one of the 24 studies provides convincing evidence that these basic feasibility criteria can be met. Of a maximum possible unweighted feasibility score of seven, the highest score for any one study was four. … On the basis of this review, efforts to date seem to have substantially underestimated the challenge and delayed the identification and implementation of effective and comprehensive decarbonization pathways. … To date, efforts to assess the viability of 100% renewable systems, taking into account aspects such as financial cost, social acceptance, pace of roll-out, land use, and materials consumption, have substantially underestimated the challenge of excising fossil fuels from our energy supplies. This desire to push the 100%-renewable ideal without critical evaluation has ironically delayed the identification and implementation of effective and comprehensive decarbonization pathways. We argue that the early exclusion of other forms of technology from plans to decarbonize the global electricity supply is unsupportable, and arguably reckless. … The realization of 100% renewable electricity (and energy more broadly) appears diametrically opposed to other critical sustainability issues such as eradication of poverty, land conservation and reduced ecological footprints, reduction in air pollution, preservation of biodiversity, and social justice for indigenous people.”
10. Wealthy Countries Foist Social-Environmental Disruption From Wind, Solar Onto Poorer Countries 
Shakespear, 2018     “A trend was found, whereby developing countries tend to suffer the most socio-environmental disruption from material extraction for solar-panels and wind-turbines while exhibiting lower implementation of these technologies, and developed countries show opposite effects. This indicates that EUE [ecologically unequal exchange] effects constitute global solar-panel and wind-turbine systems, and that developed countries displace socio-environmental disruption from energy innovation onto developing countries. … [I]mplementation of solarpanels and wind-turbines tended to be the most prevalent within countries that suffer the least environmental and socio-economic consequences from the extraction of materials for these technologies. This effectively means that efforts to increase sustainability in relatively powerful countries via renewable energy implementation exacerbates unsustainable practices in the relatively less powerful countries that extract the minerals for these technologies.”
11. Wind Power Harming The Environment, Biosphere – Destroying Habitats, Endangering Rare Species 
Millon et al., 2018  (full paper)   “Wind turbines impact bat activity, leading to high losses of habitat use … Island bats represent 60% of bat species worldwide and the highest proportion of terrestrial mammals on isolated islands, including numerous endemic and threatened species (Fleming and Racey, 2009). … We present one of the first studies to quantify the indirect impact of wind farms on insectivorous bats in tropical hotspots of biodiversity. Bat activity [New Caledonia, Pacific Islands, which hosts nine species of bat] was compared between wind farm sites and control sites, via ultrasound recordings at stationary points [A bat pass is defined as a single or several echolocation calls during a five second interval.] The activity of bent winged bats (Miniopterus sp.) and wattled bats (Chalinolobus sp.) were both significantly lower at wind turbine sites. The result of the study demonstrates a large effect on bat habitat use at wind turbines sites compared to control sites. Bat activity was 20 times higher at control sites compared to wind turbine sites, which suggests that habitat loss is an important impact to consider in wind farm planning. …  Here, we provide evidence showing that two genera of insectivorous bat species are also threatened by wind farms.  … To our knowledge, this is one of the first studies quantifying the indirect negative impact of wind turbines on bat activity in the tropics. … The lower attractiveness of the foraging habitat under wind turbines, both in a tropical and in a temperate climate, indicates that the indirect impact of wind turbine is a worldwide phenomenon.”

Lopucki et al., 2018      “Living in habitats affected by wind turbines may result in an increase in corticosterone levels in ground dwelling animals… Environmental changes and disturbance factors caused by wind turbines may act as potential stressors for natural populations of both flying and ground dwelling animal species. The physiological stress response results in release of glucocorticoid hormones. … The common vole showed a distinct physiological response − the individuals living near the wind turbines had a higher level of corticosterone [physiological stress affecting regulation of energy, immune reactions]. … This is the first study suggesting impact of wind farms on physiological stress reactions in wild rodent populations. Such knowledge may be helpful in making environmental decisions when planning the development of wind energy and may contribute to optimization of conservation actions for wildlife.”
Ferrão da Costa et al., 2018     “According to a review by Lovich and Ennen (2013), the construction and operation of wind farms have both potential and known impacts on terrestrial vertebrates, such as: (i) increase in direct mortality due to traffic collisions; (ii) destruction and modification of the habitat, including road development, habitat fragmentation and barriers to gene flow; (iii) noise effects, visual impacts, vibration and shadow flicker effects from turbines; (iv) electromagnetic field generation; (v) macro and microclimate change; (vi) predator attraction; and (vii) increase in fire risks. … Helldin et al. (2012) also highlighted that the development of road networks associated with wind farms could promote increased access for traffic related to recreation, forestry, agriculture and hunting. The consequence, particularly on remote places, is the increase in human presence, affecting large mammals via significant disturbance, habitat loss and habitat fragmentation. These negative effects are expected to be particularly relevant for species that are more sensitive to human presence and activities, such as large carnivores. Large carnivores, such as the wolf, bear, lynx or wolverine, tend to avoid areas that are regularly used by humans and—especially for breeding—show a preference for rugged and undisturbed areas (Theuerkauf et al. 2003; George and Crooks 2006; May et al. 2006; Elfstrom et al. 2008; Sazatornil et al. 2016), which are often chosen for wind power development (Passoni et al. 2017). … Results have shown that the main impact of wind farms on wolves is the induced reduction on breeding site fidelity and reproductive rates. These effects, particularly when breeding sites shift to more unsuitable areas, may imply decreasing survival and pack viability in the short term.”
Watson et al., 2018     “The global potential for wind power generation is vast, and the number of installations is increasing rapidly. We review case studies from around the world of the effects on raptors of wind-energy development. Collision mortality, displacement, and habitat loss have the potential to cause population-level effects, especially for species that are rare or endangered.”
Aschwanden et al., 2018    “The extrapolated number of collisions was 20.7 birds/wind turbine (CI-95%: 14.3–29.6) for 8.5 months. Nocturnally migrating passerines, especially kinglets (Regulus sp.), represented 55% of the fatalities. 2.1% of the birds theoretically exposed to a collision (measured by radar at the height of the wind turbines) were effectively colliding.”
Naylor, 2018     “While wind energy provides a viable solution for emission reductions, it comes at an environmental cost, particularly for birds. As wind energy grows in popularity, its environmental impacts are becoming more apparent. Recent studies indicate that wind power has negative effects on proximate wildlife. These impacts can be direct—collision fatalities—and indirect—habitat loss (Fargione et al. 2012; Glen et al. 2013). Negative impacts associated with operational wind farms include collision mortalities from towers or transmission lines and barotrauma for bats. Habitat loss and fragmentation, as well as avoidance behavior, are also consequences resulting from wind farm construction and related infrastructure. The potential harm towards protected and migratory bird species are an urgent concern, especially for wind farms located along migratory flyways. In terms of mortality, wind turbines kill an estimated 300,000 to 500,000 birds, annually (Smallwood 2013). The high speed at which the fan wings move and the concentration of turbines create a gauntlet of hazards for birds to fly through. … [T]he height of most wind turbines aligns with the altitude many bird species fly at (Bowden 2015). Birds of prey— raptors—are of particular concern because of their slow reproductive cycles and long lifespans relative to other bird species (Kuvlesky 2007).”
Lange et al., 2018     “Results from our surface water extractions and aerial surveys suggest that the wind farm has negatively affected redheads through altered hydrology and disturbance displacement. Our surface water extraction analysis provides compelling evidence that the local hydrology has been greatly affected by the construction of the wind farm. … Our results suggest the occurrence of direct habitat loss and disturbance displacement of redheads from the wind farm along the lower Texas coast. Although our study was directed solely toward redheads, it is likely that this wind farm has affected other species that use these wetlands or migrate along the lower Texas coast (Contreras et al. 2017). Studies in Europe investigating the effects on waterfowl by wind turbines have reported similar results, showing that turbines have likely compromised foraging opportunities for waterfowl through disturbance displacement (Larsen and Madsen 2000).”
Chiebáo, 2018     “I studied the large-scale movements of white-tailed eagles during the dispersal period, assessing their space use in relation to the distribution of existing and proposed wind farms across Finland. I found that a breeding pair holding a territory closer to an installation has a lower probability to breed successfully when compared to a pair from a territory lying farther away. Such lower probability may in part reflect a harmful interaction between the eagles and wind turbines in the form of collision mortality, to which the adults appear to be particularly vulnerable during the breeding season. Regarding the post-fledging period, I found that the probability of a young eagle approaching a wind turbine decreases sharply as the turbine is installed at increasing distances from the nest.”
Frick et al., 2017     “Large numbers of migratory bats are killed every year at wind energy facilities. However, population-level impacts are unknown as we lack basic demographic information about these species. We investigated whether fatalities at wind turbines could impact population viability of migratory bats, focusing on the hoary bat (Lasiurus cinereus), the species most frequently killed by turbines in North America. Using expert elicitation and population projection models, we show that mortality from wind turbines may drastically reduce population size and increase the risk of extinction. For example, the hoary bat population could decline by as much as 90% in the next 50 years if the initial population size is near 2.5 million bats and annual population growth rate is similar to rates estimated for other bat species (λ = 1.01). Our results suggest that wind energy development may pose a substantial threat to migratory bats in North America. If viable populations are to be sustained, conservation measures to reduce mortality from turbine collisions likely need to be initiated soon. Our findings inform policy decisions regarding preventing or mitigating impacts of energy infrastructure development on wildlife.”
Hammerson et al, 2017      “Conservationists are increasingly concerned about North American bats due to the arrival and spread of the White-nose Syndrome (WNS) disease and mortality associated with wind turbine strikes. To place these novel threats in context for a group of mammals that provides important ecosystem services, we performed the first comprehensive conservation status assessment focusing exclusively on the 45 species occurring in North America north of Mexico. Although most North American bats have large range sizes and large populations, as of 2015, 18–31% of the species were at risk (categorized as having vulnerable, imperiled, or critically imperiled NatureServe conservation statuses) and therefore among the most imperiled terrestrial vertebrates on the continent.”
Vasilakis et al., 2017     “Numerous wind farms are planned in a region hosting the only cinereous vulture population in south-eastern Europe. We combined range use modelling and a Collision Risk Model (CRM) to predict the cumulative collision mortality for cinereous vulture under all operating and proposed wind farms. Four different vulture avoidance rates were considered in the CRM.  Cumulative collision mortality was expected to be eight to ten times greater in the future (proposed and operating wind farms) than currently (operating wind farms), equivalent to 44% of the current population (103 individuals) if all proposals are authorized (2744 MW). Even under the most optimistic scenario whereby authorized proposals will not collectively exceed the national target for wind harnessing in the study area (960 MW), cumulative collision mortality would still be high (17% of current population) and likely lead to population extinction.”
12. Wind Turbine Blade Waste Disposal A Growing Ecological Nightmare
Liu and Barlow, 2017     “Wind energy has developed rapidly over the last two decades to become one of the most promising and economically viable sources of renewable energy. Although wind energy is claimed to provide clean renewable energy without any emissions during operation, but it is only one side of the coin. The blades, one of the most important components in the wind turbines, made with composite, are currently regarded as unrecyclable.  With the first wave of early commercial wind turbine installations now approaching their end of life, the problem of blade disposal is just beginning to emerge as a significant factor for the future. … The research indicates that there will be 43 million tonnes of blade waste worldwide by 2050 with China possessing 40% of the waste, Europe 25%, the United States 16% and the rest of the world 19%.”
Ramirez-Tejeda et al., 2017     “Globally, more than seventy thousand wind turbine blades were deployed in 2012 and there were 433 gigawatts (GW) of wind installed capacity worldwide at the end of 2015. Moreover, the United States’ installed wind power capacity will need to increase from 74 GW to 300 GW3 to achieve its 20% wind production goal by 2030.  … The wind turbine blades are designed to have a lifespan of about twenty years, after which they would have to be dismantled due to physical degradation or damage beyond repair. … Estimations have suggested that between 330,000 tons/year by 2028 and 418,000 tons/year by 2040 of composite material from blades will need to be disposed worldwide. That would be equivalent to the amount of plastics waste generated by four million people in the United States in 2013. This anticipated increase in blade manufacturing and disposal will likely lead to adverse environmental consequences. … Despite its negative consequences, landfilling has so far been the most commonly utilized wind turbine blade disposal method. …  Landfilling is especially problematic because its high resistance to heat, sunlight, and moisture means that it will take hundreds of years to degrade in a landfill environment. The wood and other organic material present in the blades would also end up in landfills, potentially releasing methane, a potent greenhouse gas, and other volatile organic compounds to the environment.”
Share this...FacebookTwitter "
"Road traffic accidents are the number one cause of death among 15 to 29-year-olds. If no action is taken, it is predicted that road traffic will kill as many as 1.9m people worldwide per year by 2030. Add to this the negative impacts of greenhouse gas emissions, air and noise pollution, chronic diseases such as heart disease or diabetes and rising levels of obesity, and a future full of cars looks bleak indeed.  These are the concerns underpinning European Mobility Week – an annual campaign, which began in 2002 – to promote sustainable forms of urban transport. This year, more than 1,700 local authorities from 42 different countries play host to a range of public events such as bicycle masses, talks and seminars about green mobility patterns, walk-to-school initiatives and many other public activities to support the uptake of sustainable and active travel. Over the past few decades, most cities around the globe have been shaped by the car. The majority of our public spaces have been transformed into endless flows of traffic, to better accommodate our dependence on this form of transport. As the number of people living in urban areas continues to grow, so too will the number of cars on the roads. There is a serious risk that this type of car-centred urbanisation will become unsustainable, and damage living standards for all. As a result, governments are becoming increasingly committed to controlling the number of conventionally-fuelled cars on the roads. To complete the transition from a heavily car-dominated society to a resource-efficient one, cities will need to achieve a more equal “modal share” – that is, city-dwellers need to be encouraged to take up alternative modes of transport in greater numbers. As a part of this effort, hundreds of cities in Europe and around the world – from Barcelona, to Brussels, to Istanbul – will encourage motorists to give up their automobiles for 24 hours, typically by closing their central streets to cars, as part of World Car-Free Day. About half of all car trips in countries like the UK, the Netherlands, and the US are fewer than five miles long. Replacing cars with other modes of transport for these short journeys would be a colossal step in the right direction. To this end, policy-makers, transport planners and traffic engineers have a variety of stick and carrot measures to make car use undesirable or unnecessary.  The stick measures are often regulatory; designed to force people to reduce car usage. These mechanisms range from congestion charges, toll roads, parking levies, traffic calming and road restrictions to fuel taxes, vehicle excise duty and even expensive car ownership permits.  The carrots are often soft measures, which give car users the options they need to be able to change their travel behaviour on a voluntary basis. One example is to make additions and improvements to alternative infrastructure, such as bus and rail services. But they can also include things such as the provision of cycle routes, pedestrianisation, priority bus lanes and other special rights-of-way.  Hybrid public transport modes and cheaper fares also help, as do initiatives for buying alternatively-fuelled cars and tools or information to help people practice smarter and more fuel-efficient driving, which makes the most of advanced vehicle technologies, when car use cannot be avoided. The sharing economy has stepped in, too, with ride sharing apps and websites like BlaBlaCar and iThumb and more than 900 dedicated public bicycle programmes worldwide.  Events like car-free days are important reminders of the steps that need to be taken to ensure safe and sustainable urban development. We need to use all these tools, and more, to meet the travel needs of the present without compromising the ability of future generations to enjoy liveable cities."
"The National Trust is planning to plant 20 million trees over the next decade as part of efforts to achieve net zero emissions by 2030. The organisation made the announcement, which it says will cost £90m-100m, on Thursday to mark its 125th anniversary.  By the end of the decade, it says the new trees and natural regeneration of woods will cover more than 18,000 hectares (44,000 acres), an area one and a half times the size of Manchester. It will mean that 17% of the land the National Trust looks after will be wooded, up from 10%. The focus will be on planting on farmland – including in upland areas – that the trust owns, rather than in country estates, but the director general, Hilary McGrady, said the National Trust would be working with farmers to deliver the targets. The charity says a similar level of tree cover is needed nationwide to meet government targets to cut greenhouse gas emissions. Other initiatives announced by the trust include maintaining peat bogs, investing in more renewable energy and cutting its carbon footprint. Efforts will focus on the National Trust’s own pollution, but McGrady acknowledged the impact of visitors, many of whom travel by car to the organisation’s properties. She said the trust was measuring the impact of visitor emissions and suggesting ways to encourage more sustainable transport. The charity, which was founded in the 19th century to protect and care for natural and historic places, plans to work with other organisations to create “green corridors” that connect people in urban areas to nature. “As Europe’s biggest conservation charity, we have a responsibility to do everything we can to fight climate change, which poses the biggest threat to the places, nature and collections we care for,” McGrady said. “People need nature now more than ever. If they connect with it then they look after it. And working together is the only way we can reverse the decline in wildlife and the challenges we face due to climate change.” "
"I can quite happily go to a zoo just to watch the chimpanzees. It is not that the other animals are boring, but that chimps are so fascinating. In recent days the media has reported their drinking of alcohol, their ability to vary smiles and a US move to designate them as endangered. So, what makes chimps so attractive to scientists and the general public alike? From a scientific point of view they are our closest
genetic relative. We share more than 98% of the same DNA and had a common evolutionary ancestor only 5-7m years ago. So chimpanzee biology and behaviour can tell us much about ourselves. And of course chimps look like us (as do most primate species). Due to these similarities, chimps are one of the most studied primate species of all time. Chimps were first described approximately 300 years ago and ever since they have appeared in books, films, TV adverts and have even flown in space ships. Their importance in understanding human evolution cannot be denied and this further adds to their high profile within human societies. But during my childhood, chimps were portrayed on the TV as loveable clowns: just think of the Tarzan films or adverts for PG Tips. However, in my opinion there is something else in the human condition that leads us to be infatuated with chimps. And it is not that they are the most cute and cuddly looking animal. That title goes to the giant panda. Instead it is to do with our human propensity to be voyeurs: we love to watch other people. Interesting people are those who put on public display their loves, hates and passions. The problem is there is only so much staring and gawping that interesting people (celebrities aside) will tolerate. Chimps provide an alternative outlet for our fascination with others. Chimps are passionate, scheming, aggressive animals. In many ways they seem to represent the human condition in its most elemental state. When we observe them we are looking at ourselves. But they act without the restrictions that polite society puts on us. And in zoos on wildlife documentaries, groups that are used to being watched by humans are not shy about expressing their desires, be they sexual or otherwise. In other words they are a voyeur’s dream. To watch a group of chimpanzees is to watch a soap opera unfold before your eyes, but without the pretence of time passing quickly. They live life in the fast lane. Just as one example, chimpanzees are 100 to 1,000 times more aggressive than humans. Even TV soap operas do not show this much action happening in short spaces of time. If a male chimp is angry with someone or something then he lets them know in no uncertain terms. This happens not just in terms of bashing things, but also through pronounced facial expressions such as bearing teeth. I think we humans are jealous of chimps because they can vent their aggressive feelings without societal disapproval. A friend of mine use to work on a project observing captive giant pandas, the world’s most marketed animal. But despite their cuteness they were boring to watch, just eating bamboo, sleeping, defecating every half hour and mating once a year. I challenge anyone to spend a whole day observing them. They just have too little behavioural diversity, expressing interesting behaviours such as aggression or sex at very low frequencies. Chimps also have a caring side. Once they have attacked and beaten another individual, they will soon go over and give them a hug to prevent this negative interaction spiralling out of control. They show empathy towards sick members of their group. Older individuals are tolerant of the capers of the younger individuals.  They live in a loving society where individuals hold hands, hug and kiss in the manner of people from Latin countries. And their partiality to a spot of alcohol has now generated much excitement. Even when chimps are sitting around doing nothing, as a human observer you sense that something interesting could happen at any second. They never seem to have vacant expressions even when they are resting. They appear to be scheming away, working out how to manipulate other members of their group for food, friendship or sex. Chimps give the impression of being intelligent without the need to be making and using tools to procure food – just sitting down will do. Finally, chimps display remarkably strong personalities. Just one day of watching a group in a zoo is enough for you to determine their characters. Some are bold, others timid. Some are very agitated, whereas others seem serene. It is this blend of personalities that creates interesting group dynamics and the script for their soap operatic lives. We are addicted to chimps because they let us spy on their lives, lives that are so rich and amazing that one, whose name was Flo, even had her obituary published in the Sunday Times newspaper."
"
Share this...FacebookTwitterThe time in running out for the purveyors of the “rapidly accelerating sea level rise” scare story.
Especially IPCC alarmist scientists like spreading scare stories about sea level rise, and how it’s accelerating.
So far global CO2 emissions have in fact continued to climb at a rate that is defined as the “business as usual” emissions scenario RCP8.5, which means a sea level rise of up to 97 cm by 2100, according to the most recent IPCC projections:

IPCC AR5 sea level rise for 4 different emissions scenarios. So far CO2 emissions have been on the worst case path.
Could even be 90 by 2060!
And some experts even suggest that sea level rise may occur even far more quickly. For example the Pacific Islands Ocean Observing System (PACIOOS) here wrote. “Recent observations and projections suggest that 3 feet (90 cm) or more of sea level rise could occur earlier than 2100 and even as early as year 2060.”
Meanwhile some time ago alarmist climate site Skeptical Science here wrote: “Overall, the range of projected sea level rise by 2100 is 75 to 190 cm.”
Of course, hysterical sites like Skeptical Science don’t publish anything without first injecting a good dose of hyperbole. So we will put them down for 1200 mm of sea level rise by 2100.
Gap between reality and IPCC about to become glaring
The following chart depicts the IPCC alarmists, like Skeptical Science, projection (1200 mm), the conservative IPCC AR5 business as usual estimate (800 mm), the projected linear trend of the satellite measurements trend (320 mm), and the projected trend of what the tide gauges –  i.e. where people actually live – have been observing (160 mm):


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Observed data show no signs that sea levels are rising as quickly as IPCC models have been suggesting. IPCC alarmist scenarios are about 7 times higher than what is observed by tide gauges. Chart: notrickszone.com.
Acceleration not showing up in the observations
Naturally the alarmists always claim that the sea level rise rate will be modest at first, but that it will really begin to take off in a decade or two once the oceans warm and expand, and Greenland and Antarctica start to melt in earnest.
But there’s only one problem: So far there hasn’t been any noteworthy acceleration seen in neither the satellite data or tide gauge data.
Moreover, Greenland and Arctic ice volume have been increasing. And so has Antarctica. Of course we do see a paper from time to time with alarmist scientists statistically waterboarding some rate increase out of the sea level data, but almost always the increase gets traced back to natural variation.
Time is running out – for the alarmists
What’s clear is that we will certainly know what sea level rise is doing in 15 years, ca. 2033. by then the IPCC claimed acceleration should making its debut in earnest.
However, if the tide gauges don’t show some real, major acceleration by then, from 1.6 mm/year to say 4 mm/year, then it will be safe to say that any IPCC of over 70 cm was nothing but wolf-crying.
We’re watching carefully. The days of the sea level scare story are numbered.
Share this...FacebookTwitter "
"Australia’s unforgiving, unrelenting and unprecedented fires have demonstrated so clearly that the climate doesn’t recognise tricky “Kyoto carryover” accounting and doesn’t care for juvenile finger pointing at other countries. With a warming climate, this brutal summer is a preview of what will become a regular occurrence in our lifetimes. More and more Australians realise that climate change is a clear and present threat. Our only chance to maintain our standard of living, and our economy, is if all countries rapidly decarbonise. Many are committed to this, Australia is not. We cannot expect global progress if we ourselves aren’t prepared to at least pull our weight, let alone show any leadership. Yet, we have a prime minister who looks into the camera and speaks to a people in survival mode and deep trauma and waves away our responsibility. He claims that we are responsible for just 1.3% of global carbon dioxide emissions, as if we are irrelevant. Australia has never been irrelevant and we certainly aren’t now. Even though Scott Morrison’s logic for climate inaction has been debunked many times, let’s do it again, for the sake of letting the PM, his climate denier cronies and fossil fuel lobby puppet masters know they will be held accountable for their lies and negligent inaction. Australia is the 14th largest emitter out of 208 countries. If all countries with emissions under a “measly” 2% were lumped together we’d together be responsible for almost as much annual emissions as China and India put together. The physics of the climate system doesn’t care about political boundaries. Does Germany not matter because it’s responsible for (slightly) less than 2%, or does it matter because it’s part of the EU, responsible for 9.4% of emissions? How about if we divide China into 56 countries of 25 million people, each with emissions half of Australia’s – would that let them off the hook? Australia has the highest emissions per capita of all major nations. The average Australian has four times the carbon footprint of the average global citizen, significantly due to our unusually high reliance on coal for electricity, the poor energy efficiency of our vehicles and buildings and the high domestic emissions from coal and gas extraction and processing. China and India haven’t yet peaked their emissions – unsurprising given their stage of development – but both are decoupling emissions from development such that their average citizen will never have the carbon footprint the average Australian has now. The “too small to matter” argument is logically absurd, but it is also morally bankrupt and economically reckless. We all know that throwing one piece of litter out the window wouldn’t ruin the environment, but if all did we’d soon be surrounded by rubbish. How about voting? It is a foundation of our democracy that nobody’s voice is so small as to be meaningless. Likewise, if any one taxpayer stopped paying tax we all know it wouldn’t make a measurable difference to the government’s bottom line, but if everyone stopped paying tax it would smash consolidated revenue. So when did we become a nation of shirkers? We’ve always punched above our weight. A young Australia was immensely proud of the troops committed to the first world war, even though the Diggers comprised less than 1% of the Allied Powers. We are only 0.3% of the global population but are gutted whenever we’re not near the top of the Olympic medal tally. Carbon accounting standards push responsibility for the coal and gas we export onto the final customers, but now that we understand the negative consequences of the associated emissions, the argument “if they didn’t buy from us, they’d buy from someone else” feels shamefully like the drug dealer’s defence. Including these emissions more than triples our carbon footprint. Our prime minister claims we are doing our bit, however a close reading of the government’s most recent projections shows that the Department of the Environment expects us to make no progress on reducing emissions through this decade – and that’s assuming the LNG sector doesn’t grow and that we reach 51% renewables in the National Electricity Market, which will be unwelcome news to at least a couple of ministers. The projections also heroically assume that there are no methane leaks from the entire LNG sector, and while they give us credit for planting trees, preventing bushfires and protecting land from clearing, there’s no accounting for the massive emissions of the bushfires burning right now. The UN Environment Program recently announced that global emissions need to reduce by 7.6% every year for a decade to keep warming below 1.5C. With no emissions reductions projected, it’s no wonder that Australia’s climate policies were recently ranked dead last among 57 nations. Meanwhile, other countries are embracing the challenge. In November I visited a cement factory in Belgium that is trialling a low-cost technology – originally developed in Australia – for decarbonising cement manufacture. Globally, the cement sector is responsible for around 8% of emissions, as growing developing countries urbanise. In Essen, in Germany’s Ruhr Valley, I saw a technology that allows power-hungry aluminium smelters to operate well (and increase profits) in renewable-dominated grids. The technology was first developed in Gladstone and partly Australian-owned before being sold offshore. In nearby Duisburg, I visited ThyssenKrupp, a major German industrial company with a commitment to net-zero carbon emissions by 2050. The company has embarked on an ambitious plan to decarbonise steel production, also responsible for around 8% of global emissions, with the ultimate goal of replacing coal with hydrogen. ThyssenKrupp is also developing technology to combine “waste” gases with “green” hydrogen – hydrogen produced with renewable energy – to synthesise chemicals such as methanol and ammonia, providing a pathway to lowering emissions from aviation and agriculture. As these economies wean themselves off coal the demand for hydrogen will skyrocket. With the potential to harness vast quantities of low-cost renewable energy, Australia is well placed to become an energy superpower in a decarbonised global economy. None of the major industrial companies I visited in Europe sees decarbonisation through a sacrifice lens. There’s no talk of “economy wrecking targets”. Rather, having accepted that the economy must be decarbonised, they are rushing to seize a competitive advantage. Meanwhile, Australia is a world away, in every sense. A rich, talented, capable nation is being held back by a lack of honesty and a lack of imagination – a nation held back by the vested interests of those who profit from the extraction and sale of gas and coal. Our prime minister is paralysed, unable to acknowledge that fossil fuel emissions are changing the climate, and that the changing climate is hurting Australians. Until his government stands up to the vested interests and starts telling the truth, Morrison’s authority will shrink ever smaller – as will Australia’s position in the world and our nation’s future prospects. • Simon Holmes à Court is senior adviser to the Climate and Energy College at Melbourne University"
"China recently announced plans to build a 5,300 km railway  linking the Atlantic with the Pacific, cutting through the heart of the Amazon jungle in Brazil and Peru. Environmental groups are concerned that the railway will threaten sensitive ecosystems, wildlife and indigenous peoples. Indeed on the face of it, this would be a disaster for conservation in the most biologically rich place on Earth. But is a train line in fact the lesser of two evils? If the alternative is more roads, then yes it is. Roads bring access to previously remote areas – and consequently bring down a cascade of problems on tropical forests. Logging, mining, and hunting result in the destruction of forests, all paving the way for their complete conversion to agriculture. Indeed, in the Amazon 95% of deforestation occurs within 5km of a road. Train lines on the other hand are usually state-controlled and more easily regulated. Therefore land speculation is much more difficult around railways than roads. The proposed line will cost an estimated US$10 billion to build and will reduce the cost of shipping oil, iron ore, soya, beef and other commodities from Brazil and Peru to Asian markets. With the promise of investment from China the venture has gained considerable traction, with the leaders of each country signing a memorandum on the project. So it seems there is a good chance the railway will go ahead. China recently lifted a ban  on beef from Brazil, and China’s beef imports are likely to increase by 50% (770,000 tonnes) over the next five years. Opposition to the rail proposal is therefore relatively futile, as it is reasonable to assume that supply links between China and Latin America will continue to increase in one way or another, transporting goods by rail or by road.  The problem of the ever-expanding beef industry is thus not the proposed railway, but the policies that fail to prevent deforestation across the Amazon basin. Therefore, environmental groups should be advocating the best possible route for the railway, rather than blocking the plans – and subsequently paving the way for more road building. So what are the potential problems of a railway and how can they be avoided? Reports suggest that the proposed route could increase access to remote tribes living in voluntary isolation throughout the forests of Peru’s Madre de Dios region. This area is also among the most species-rich places on Earth: home to more than 10,000 species of plants, 600 species of birds and 200 mammal species. In addition, the railway is likely to pass through Brazil’s Cerrado, a unique area of tropical woodland and grassland which provides key habitat for iconic and threatened species including the maned wolf, giant anteater and Spix’s macaw. Unfortunately, previous mega-infrastructure developments in the Amazon such as the Trans-Amazonian Highway, and the Belo Monte dam were implemented with little consideration for the impact on nature and local people, so these areas could be threatened by the construction of a railway. But the railway is still just a line on a map. In fact the approximate route can be achieved by following existing roads and passing through land that has already been cultivated for the majority of the way. And this can easily be seen from Google Earth. There is almost no need for the train line to pass through any virgin forest. Even in the critical part of Peru, the Inter-Oceanic Highway already passes along the eastern portion of the Madre de Dios, and this area has already suffered from land speculation, mining and small-scale agriculture throughout its length. To meet the demand of export channels west of Brazil without the train line, this road would need expansion, increasing the likelihood of the area falling foul to the complete deforestation as seen around nearly all other major highways across the Amazon basin. If Latin American governments want this railway to have negligible impact on their precious forest resources, they can achieve that – with advice from environmental voices and proper investment in best practices from the planning stage all the way through to the management of the railway. The precise route of the railway is yet to be determined, so there is still time for the environmental community to help to minimise the impact of an inter-continental railway across South America."
"Heavy flooding has affected more than a million people in the north-eastern Indian state of Assam, with 45 dead and more than 200,000 in relief camps. And yet there is still very little coverage of the disaster in the international media – perhaps not surprising when you consider even most Indians aren’t paying attention. But they should – and so should you. The fact a region that is flooded regularly should be so unprepared for the latest downpour is scandalous, as is the shortsighted or uncaring government response.  The floods have also affected local wildlife, with the Kaziranga National Park – home to two thirds of the world’s Indian rhinos – reporting the electrocution of elephants fleeing from the water, as well as the death of at least three rhinos.  The floods come amid reports of increasing illegal immigration from Bangladesh and poor working conditions on local tea plantations, while armed conflicts between separatist groups and state security forces make the situation in the region even more unstable.  Assam is best known for its black tea, which grows well in the hot, steamy Brahmaputra valley. But while the monsoon may create perfect conditions for tea, it also means the region is highly susceptible to flooding.   More than 40% of the region is at risk and severe floods occur every few years, eroding riverbanks and dumping large amounts of sand on farmland, often rendering lands infertile. For local communities, these floods have been disastrous and many are not receiving sufficient aid. For example my own research on recovery after major floods in 2012 found affected families who hadn’t received the promised compensation from the government, even two years on.  Government initiatives to build new embankments have led to further distress. For example, new barriers constructed in 2012 displaced hundreds of families who found their resettled homes were now on the wrong side of the embankments. Compensation was poor, lower than market rates, while others received no support for resettlement due to identity and land ownership issues for illegal immigrants from Bangladesh. Some embankments built along the Brahmaputra in central Assam as an ad hoc response to the 2012 floods were so poorly constructed over natural drainage they actually failed to keep the river movements in check and increased erosion. The embankments simply breached in the following year’s monsoon. The subsequent relocations and distress were entirely preventable. The Brahmaputra has caused serious erosion for decades now, and yet the government response has been inefficient. Plans to tackle the problem remain confined only to paper. The floods in Assam have taken a heavy toll on water, sanitation, health and education systems. Affected people flee their homes and create makeshift camps, where access to essential facilities is inadequate for the hundreds of thousands displaced. The quality and accessibility of drinking water in particular is severely affected, and people are depending on contaminated sources – even when they know it isn’t clean. Defecation in the open becomes dangerous, especially for women and adolescent girls, all the more so during floods and regular displacement.  During floods the government turned some public schools into relief camps for a week or two. This of course affects the school term. Once the water recedes people start leaving the camps and are forced to fend for themselves. When they return to their villages they’ll be faced with destroyed homes, lost food grains and fields ruined by silt or sometimes even entirely lost to erosion. The road to recovery is hard to see, particularly as no long-term support is guaranteed by government, civil groups or NGOs. The floods also have an adverse affect on marginalised people, such as women, who bear the responsibilities of running households, childcare and rebuilding homes after floods. A 2013 study involving 900 households around Assam found that soil erosion, as a consequence of flooding, heavily affected the standard of living for farmers. This in turn forced women to leave the home and earn an income which resulted in girls dropping out of school to look after younger siblings and do the chores. India’s 2005 Disaster Management Act doesn’t recognise the chronic challenges of erosion as a natural disaster. The present development plans are shortsighted. They do not feature a long-term recovery, or take into consideration environmental factors. In the case of Assam, disaster resilience will only be possible through education and the participation of local communities and institutions. Something that needs to be done if the area is prone to flooding."
"The idea of a deep-frozen world, “snowball Earth”, has captured the imagination since first proposed in the 1990s. On several occasions in history, long before animals evolved, apparently synchronous ice sheets existed on all the continents. However, much like falling into a crevasse on a glacier, it’s easy enough to enter such an ice age, but very difficult to escape. The snowball Earth theory came from climate modellers who found that low carbon dioxide levels could trigger the growth of ice sheets. The whole planet would become glaciated and its mean temperature drop to as low as -45°C. As ice is much more reflective than the sea, or bare land, the Earth at that point would have been bouncing nearly all of the sun’s radiation back into space. So how could the planet ever emerge from such an ice age?  Volcanoes had to be the answer. Only they could emit enough carbon dioxide into the atmosphere to overcome the effects of Earth’s cool reflective surface. But climate models still found it difficult to plausibly describe how the Earth could have shed its glaciers. We now have the first full explanation for how the best-known snowball event, the Marinoan, finished 635 million years ago with a several hundred metre rise in sea level. The study is the result of work by an international team of scientists, including myself. Our results are published in the journal Nature Geoscience. We found slight wobbles of the Earth’s spin axis caused differences in the heat received at different places on the planet’s surface.  These changes were small, but enough over thousands of years to cause a change in the places where snow accumulated or melted, leading the glaciers to advance and retreat.   The Earth was left looking just like the McMurdo Dry Valleys in Antarctica – arid, with lots of bare ground, but also containing glaciers up to 3km thick. Such an Earth would have been darker than previously envisaged, absorbing more of the sun’s radiation; it was easier to see how the escape from the snowball happened. Today, to find exposed rocks that can tell us about the carbon dioxide content of the atmosphere in the Marinoan, you have to go to the Norwegian Arctic island of Svalbard. In 2009 snowball theory was vindicated after we found the telltale signal of high carbon dioxide levels in Svalbard limestone that formed during the ice age.  Immediately underneath the Marinoan deposits are some beds of rocks deposited at very regular intervals – so regular that they must have formed over thousands of years, influenced by wobbles in the Earth’s orbit. Since Svalbard was near the Equator at the time, the most likely type of wobble is caused by the Earth slowly shifting (“precessing”) its axis on cycles of approximately 20,000 years. Researchers also found evidence of the same process in the Snowball deposits themselves. Fluctuations in ice in relation to the Earth’s orbit are a feature of our modern ice ages over the past million years, but had not been found in such an old glaciation. For a long time the Earth was too cold for glaciers to erode and deposit sediment – the main snowball period. The sediments then show several advances and retreats of the ice. When the glaciers retreated, they left behind a patchwork of environments: shallow and deep lakes, river channels, and floodplains that appeared as arid as anything known in Earth’s history. Carbon dioxide appears to have remained at the same high level throughout the deposition of these sediments. Since it takes millions of years for CO2 to build up in the atmosphere, this implies the sediment layers must have formed quickly – on the order of 100,000 years.  All this fits with the idea of 20,000 year precession cycles.  A group of climate modellers from Paris tested the theory. The rocks and the models agreed: wobbles in the Earth’s axis had caused the planet to escape its snowball phase. So after several million years of being frozen, this icy Earth with a hot atmosphere rich in carbon dioxide had reached a Goldilocks zone – too warm to stay completely frozen, too cold to lose its ice. This transitional period lasted around 100,000 years before the glaciers fully melted and present-day Svalbard was flooded by the sea."
"
Share this...FacebookTwitterScientists have determined that today’s Arctic sea ice concentrations are still much higher than they have been for most of the last several thousand years, undermining claims that modern era Arctic sea ice changes are remarkable, unusual, or unprecedented. 

Source: Kolling et al., 2018
In the graphical illustration of Late Holocene West Greenland sea ice changes shown above, Kolling and colleagues (2018) indicate that both present-day and Little Ice Age era (~1300s to 1800s AD) sea ice does not melt until May.(Fig. 6a).
During most of the last 2,200 years — especially during the Medieval Warm Period (MWP) and Roman Warm Period (RWP) — spring sea ice melted in March, two months earlier than today (Fig. 6b).
The authors attribute the lower-than-today sea ice concentrations and warmer temperatures during the MWP and RWP to a “self-amplifiying system” involving variations in solar activity and the AMO.  Atmospheric CO2 concentrations are not mentioned in the paper as a factor influencing sea ice changes.
“The period between 2.2 and 1.2 kyr BP, with lower than modern sea ice conditions in Disko Bugt (Fig. 6b), coincides with generally warm conditions over the Greenland Ice Sheet.”
“A self-amplifying system may have caused the environmental changes observed in Disko Bugt area as follows: solar triggered Arctic sea ice melt [Ruzmaikin et al., 2004] increases freshwater supply towards the North Atlantic causing a reduction in sub-polar gyre activity and AMO [Holland et al., 2001, Schmith et al., 2003] as described by Sha et al. [2016].”
Consistent with other reconstructions for the region (Kryk et al., 2017; Durantou et al., 2012; Yamamoto et al., 2017; Perner et al., 2018), proxy evidence shows that current sea ice conditions are only modestly different than the indicated conditions during the past few centuries.


Source: Kryk et al., 2017; Durantou et al., 2012; Yamamoto et al., 2017; Perner et al., 2018
The lack of any unusual or remarkable change in sea ice conditions during the modern era relative to the past suggests there is a lack of conspicuous connection between rising anthropogenic CO2 emissions and the Arctic climate.

Kolling et al., 2018
New insights into sea ice changes over the
past 2.2 kyr in Disko Bugt, West Greenland
“Our biomarker record indicates that Disko Bugt [West Greenland] experienced a gradual expansion of seasonal sea ice during the last 2.2 kyr. Maximum sea ice extent was reached during the Little Ice Age around 0.2 kyr BP. Superimposed on this longer term trend, we find short-term oscillations in open water primary production and terrigenous input, which may be related to the Atlantic Multidecadal Oscillation and solar activity changes as potential climatic trigger mechanisms.
“The period between 2.2 and 1.2 kyr BP, with lower than modern sea ice conditions in Disko Bugt (Fig. 6b), coincides with generally warm conditions over the Greenland Ice Sheet.”
“Overall, IP25 concentrations remained relatively low and constant until 1.2 kyr BP, followed by a gradual increase (Fig. 3e). The lowest [sea ice] concentrations, around 0.06 µg/gTOC, are observed in the lowermost core section from 2.2 to 1.5 kyr BP (Fig. 3e).”
“During the last 0.1 kyr, all biomarker concentrations showed an increase, brassicasterol and HBI III reach maximum values in the uppermost sample (80 µg/gTOC and 1.8 µg/gTOC, respectively; Fig. 3b, d).”

Source: Kolling et al., 2018
“[During the Little Ice Age (0.7–0.2 kyr BP)] our biomarker record supports harsher sea ice conditions, possibly similar to conditions as observed today (Fig. 6b), indicated by strong increased in IP25 concentration and the PDIP25 index (Fig. 4c, d).”

Source: Kolling et al., 2018
“AMO variability has been linked to solar activity changes [Knudsen et al., 2011]. Changes in incoming radiation may influence sea ice extent and the Greenland Ice Sheet behaviour [Ruzmaikin et al., 2004] and consequently affect the freshwater discharge/inflow [Schmith et al., 2003] and nutrient availability to the area. A self-amplifying system may have caused the environmental changes observed in Disko Bugt area as follows: solar triggered Arctic sea ice melt [Ruzmaikin et al., 2004] increases freshwater supply towards the North Atlantic causing a reduction in sub-polar gyre activity and AMO [Holland et al., 2001, Schmith et al., 2003] as described by Sha et al. [2016]. This may in turn cause distinct changes in WGC composition and meltwater supply from the Greenland Ice Sheet that affects phytoplankton blooms in West Greenland.”
“We find that the Disko Bugt area was influenced by seasonal sea ice over the last 2.2 kyr BP. The overall sea ice trend indicates a development from a reduced sea ice cover during early spring, with sea ice algae productivity hampered by light availability to a gradual extend of the sea ice season from 1.2 kyr BP onwards. This change in sea ice extend is parallel to decreasing Northern Hemisphere atmospheric temperatures and culminates in the Little Ice Age around 0.2 kyr. We assume that modern conditions, with sea ice present until late spring and the presence of a stable ice edge at Disko Bugt, established around that time [~200 years ago].”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterEven though CO2 concentrations hovered well below 300 ppm throughout most of the Holocene, newly published paleoclimate reconstructions affirm that today’s surface temperatures are only slightly warmer (if at all) than the coldest periods of the last 10,000 years.  This contradicts the perspective that temperatures rise in concert with CO2 concentrations.

 Bottom Graph Source: Rosenthal et al. (2013)
1. Even Past Cold Periods Were 0.5–1.5 °С Warmer Than Today
Nosova et al., 2018
“According to the present climate reconstruction, mid Holocene warming started only at 7,700 cal bp, with temperatures higher than now during the mid Holocene period. This warming was due to an increase in winter temperatures (1–5 °С higher than current), while summer temperatures remained relatively stable, with a July temperature<1 °С higher than now. … During the mid Holocene, two cold periods at 6,900–6,500 and at 5,300–5,000 cal bp were observed. Interestingly, during the cold periods, the temperatures exceeded the current ones by 0.5–1.5 °С.”
“The transition from the mid Holocene thermal maximum to the following period occurred without considerable climatic changes. The mean annual temperatures remained much higher than the current ones by 0.5–2.5 °С until 2,500 cal bp. Local maximum temperatures were observed at 4,800, 4,300, 3,500 and 2,900–2,700 cal bp. The present climatic reconstruction demonstrates a gradual cooling down to current levels at ca. 2,500 cal bp, and then followed by a new warming phase with up to 1–2 °С increase at approximately 1,500 cal bp.”

2. Only 3 Of 116 Holocene Temperature Anomaly Records Were Colder Than Today
Bajolle et al., 2018
“The mean annual temperature recorded at the closest meteorological station [La Sarre: 1961–1990] is 0.8 °C, with August temperature averages of 15.0 °C (1961–1990) and 15.4 °C (1981–2010). … During zone Lch1 (8500–5800 cal year BP), the average reconstructed temperature was 16.9 °C, with a decrease from 19 °C (maximum) to 17 °C at the end of the zone. In zone Lch-2 (ca. 5700–3500 cal year BP), temperatures had an average of 16.8 °C, with a decrease from 17.8 °C around 5200 cal year BP to 16.2 °C at 3400 cal year BP. Zone Lch-3 (ca. 3500–1200 cal year BP) started with inferences for high temperatures (19.3–18.5 °C), followed by a decrease to 16.8 °C between ca. 3000 and 2500 cal year BP. An increase (18.3 and 19.6 °C) was inferred for the period between 1800 and 1500 cal year BP. The average chironomid inferred temperature during Zone 3 was 17.9 °C. In the last zone (Lch-4), the temperatures decreased from ca. 17.5 °C at the beginning of the zone to 14.8 °C at the end of the zone. The average during this zone was 16.5 °C. The temperature anomalies show that throughout the whole record, only six of the inferences were colder than the climate normal of 15.4 °C and three were colder than today, with the climate normal of 15 °C (Fig. 4b). The average anomaly from 15 °C (2.10 °C) and from 15.4 °C (1.70 °C) for the whole record showed that the temperature inferences were generally, and significantly, warmer than today.”

3. New England (USA) Colder Now Than Nearly All Of The Last 11,000 Years
Oswald et al., 2018

4. Today’s Temperatures Still Just As Cold As The Global Little Ice Age
Coffinet et al., 2018
“This study represents the first detailed late Holocene quantitative air temperature reconstruction from the RVP [Rungwe Volcanic Province, southwestern Tanzania/East Africa] region. We identified a succession of cold/warm/cold events, largely in phase with the other regional East African climate records and with the cold periods identified worldwide by Wanner et al. (2011). This further supports that global scale processes may be the main drivers of the Holocene climatic variability. Moreover, warm conditions during the MCA [Medieval Climate Anomaly] followed by abrupt cooling during the LIA were observed at Kyambangunguru and elsewhere in East Africa suggesting that these two recent events occurred globally.”

5. Modern Temperatures -2.9°C Colder Than 7,000 Years Ago
Zhao et al., 2018
“According to the interpolation of meteorological data of the two nearest weather stations at Linxia (ca. 46 km away; MAT [mean annual temperature] = 7.3 °C) and Minhe (ca. 54 km away; MAT [mean annual temperature] = 8.3 °C)… In this study, we reconstructed mid-late Holocene climatic changes using GDGT distributions in a loess-paleosol sequence in the Lajia Ruins of the Neolithic Qijia Culture, Guanting Basin, in the southwestern end of the Chinese Loess Plateau. … MAT [mean annual temperature] decreased from 11.9 °C to 8.0 °C [today], during the past ca. 7000 yr, and a drastic decline in MAP [mean annual precipitation] (70 mm), accompanied by a 0.8 °C decline in MAT [mean annual temperature], occurred at 3800–3400 yr BP.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




6. Temperatures “7–9°C Higher Than Modern during The Early Holocene”
Zheng et al., 2018
“In this study we present a detailed GDGT data set covering the last 13,000 years from a peat sequence in the Changbai Mountain in NE China. The brGDGT-based temperature reconstruction from Gushantun peat indicates that mean annual air temperatures in NE China during the early Holocene were 5–7°C higher than today.  Furthermore, MAAT records from the Chinese Loess Plateau also suggested temperature maxima 7–9°C higher than modern during the early Holocene (Peterse et al., 2014; Gao et al., 2012; Jia et al., 2013). Consequently, we consider the temperatures obtained using the global peat calibration to be representative of climate in (NE) China. … The highest temperatures occurred between ca. 8 and 6.8 kyr BP, with occasional annual mean temperatures >8.0 ± 4.7°C, compared to the modern-day MAAT of ∼3°C.”

7. 1950-2015 Just 0.7°C Warmer Than Coldest Temps Of The Last 9,000 Years
Harning et al., 2018
“Iceland’s terrestrial HTM [Holocene Thermal Maximum] has previously been constrained to ~7.9 to 5.5 ka based on qualitative lake sediment proxies (Larsen et al., 2012; Geirsdottir et al., 2013), likely in association with progressive strengthening and warming of the Irminger Current (Castaneda et al., 2004; Smith et al., 2005; Olafsdottir et al., 2010). Numerical modeling experiments for Drangajokull suggest that peak air temperatures were 2.5 – 3°C warmer at this time relative to the 1961-1990 CE average (Anderson et al., 2018). … During the Little Ice Age (LIA, 1250-1850 CE), the Vestfirðir region entered the lowest multi centennial spring/summer temperature anomalies of the last 9 ka.  Based on recent numerical  modeling simulations, this anomaly is estimated to be 0.6-0.8°C below the 1950-2015 average on Vestfirðir (Anderson et al., 2018).”


8. 2004-2007 Temps Colder Than All But 3 Other Holocene Periods
Wang et al., 2018   
“The average RAN15-MAAT of 18.4°C over the most recent part of the record (<0.8 ka BP) [the last 800 years BP] overlaps with the range of MAATs, ca. 16.2°C to 18.7°C (av. 17.5°C) measured since 1952 at the nearest meteorological station (Yichang, located ca. 100 km away) and is very close to the av. MAAT of 18°C measured directly outside the cave by a temperature logger between 2004 and 2007 (Hu et al., 2008a). This agreement between reconstructed temperatures and instrumental measurements increases our confidence in the potential of the RAN15 proxy. RAN15-MAATs in HS4 vary from 16.5°C to 20.6°C (av. 19°C), during the last 9 ka BP, and broadly follow a long-term trend of declining temperatures in line with declining solar insolation at 30°N in July (Laskar et al., 2004). … Interestingly, the most recent 0.9 ka BP [900 years BP] is distinguished by greater variability with the highest (20.5°C) and lowest (16.5°C) RAN15-MAATs occurring consecutively at 0.6 ka BP [600 years BP] and 0.5 ka BP [500 years BP].” [Surface temperatures dropped by -4.0°C within ~100 years.]

9. 1952-2014 Temps 4.0 to 7.0 °C Colder Than 8,000 – 10,000 Years Ago
McFarlin et al., 2018
“(Greenland)  Early Holocene peak warmth has been quantified at only a few sites, and terrestrial sedimentary records of prior interglacials are exceptionally rare due to glacial erosion during the last glacial period. Here, we discuss findings from a lacustrine archive that records both the Holocene and the Last Interglacial (LIG) from Greenland, allowing for direct comparison between two interglacials. Sedimentary chironomid assemblages indicate peak July temperatures [Greenland] 4.0 to 7.0 °C warmer than modern during the Early Holocene maximum [10,000 to 8,000 years ago] in summer insolation. Chaoborus and chironomids in LIG sediments indicate July temperatures at least 5.5 to 8.5 °C warmer than modern.”

Modern Derived Temps 0.2°C Above Coldest Of Last 14,000 Years
Wu et al., 2018
“Summer temperatures (MJT) at Xingyun Lake in the late glacial were low, increased during the early Holocene, were highest during the middle Holocene, and then decreased during the late Holocene.The range of inferred values [for the Holocene] was 21.0°- 26.5°C. The pollen inferred temperature derived from surface samples (21.2°C), is close to the modern instrumental July temperature in Kunming (22°C), supporting the reliability of reconstructions from down-core pollen assemblages.”

Share this...FacebookTwitter "
"
Share this...FacebookTwitterArctic sea ice volume data show earlier projections of ice-free Arctic summers were a sham. Sea ice now steady 10 years.
Lately Arctic sea ice volume has been a topic which climate skeptics have been looking at quite closely.
According to Al Gore and a number of climate ambulance chasers, Arctic sea ice in late summer should have long disappeared by now, see here..
But then just a few years after, the Arctic sea ice area began to recover from its lows of 2007 and 2012. So immediately alarmists shouted that area was not really what mattered, but rather sea ice volume is what really counted. Okay, that made perfect sense. Mass is in fact what’s important, and not area, when worrying about polar ice disappearing.
So naturally skeptics have since then been watching volume, which we were told by alarmists would shrink, and shrink, and shrink – until totally gone in late summer. In 2007 one US climate official declared the Arctic sea ice was in a “death spiral”.
Those alarmist projections have since turned up totally false
First, looking at peak ice, which occurs around April 1st, using the data from the Danish meteorological Institute (DMI) here, we find that Arctic sea ice VOLUME has totally defied the downward death spiral trend projected by experts and their models.

The chart above depicts Arctic sea ice volume on April 1st for the years 2003 to 2018, using the data from the DMI. Note the growing chasm between alarmist projections and reality. 
Humiliation of the alarmists


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The most closely watched measure of Arctic sea ice magnitude is the minimum that is typically reached in very late summer, i.e. around September 20.
Here as well using the DMI data, I’ve plotted the September 20 Arctic sea ice going back to 2003.
Here’s the result of the plot:

Al Gore’s hysterical projections of ice-free Arctic late summers are exposed as an absolute sham. 2018 uses a conservative projected value.
Today the doomsday scenarios and projections made 10 years ago have yet to show any signs of materializing. Late summer Arctic sea ice has been surprisingly stable over the past decade.  Gore and alarmists fell into the trap of applying an idiotic polynomial curve extrapolation into the future.
In fact there are indications that Arctic sea ice may be starting an upward trend as oceanic and solar cycles enter their cooler phases.
Low sea ice also occurred in the past
There’s no doubt that Arctic sea ice has dwindled considerably since it peaked back at around 1980, a time when climate scientists had warned the globe risked cooling into an ice age.
Also, today’s Arctic sea ice amount is in the same neighborhood as it was back in the 1930s. Moreover, today’s levels are considerbly higher than they were over a large part of the Holocene, which saw periods that were far warmer than today.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterThe purveyors of climate alarm posit that rising CO2 emissions cause up to 600% increases in burned area due to global warming. Newly published science thoroughly undermines these claims. Observational evidence affirms global-scale fire frequencies and burned area have actually been declining for decades (especially since the early 1900s), with overall biomass burning lower today than during the much colder Little Ice Age.

Bottom Graph Source: Ward et al., 2018
On a global scale, fire emissions/burned area peaked in the 1910s, but then plummeted to “about 5% below year 1700 levels by 2010” (Ward et al., 2018).
The decreasing trend in wildfires has continued unabated in the 21st century, as there has been “a strong statistically significant decline in 2001–2016 active fires globally” (Earl and Simmonds, 2018).
On a long-term scale, “global biomass burning during the past century has been lower than at any time in the past 2000 years” (Doerr and Santín, 2016).
Even in the Western United States, where wildfires are currently ravaging the landscape, there has been a “decline in burning over the past 3,000 y[ears], with the lowest levels attained during the 20th century and during the Little Ice Age (LIA, ca. 1400–1700 CE)” (Marlon et al., 2012).
The perception of increasing fire occurrence vs. the observations of decreasing trends
Doerr and Santín (2016) characterize the association between global warming and increases in wildfires as a “perception” spawned by using selective regional data and short timescales (in other words, by excluding contradictory evidence).  The alarming conclusions that wildfires are worsening due to rising anthropogenic CO2 emissions are then promulgated by mainstream media.
“Numerous reports, ranging from popular media through to peer-reviewed scientific literature, have led to a common perception
that fires have increased or worsened in recent years around the world. Where these reports are accompanied by quantitative observations, they are often based on short timescales and regional data for fire incidence or area burned, which do not necessarily reflect broader temporal or spatial realities.”
To summarize, there are “widely held perceptions both in the media and scientific papers of increasing fire occurrence, severity and resulting losses“, and yet “the quantitative evidence available does not support these perceived overall trends” (Doerr and Santín, 2016).

Ward et al., 2018
Trends and Variability of Global Fire Emissions
Due To Historical Anthropogenic Activities
“Globally, fires are a major source of carbon from the terrestrial biosphere to the atmosphere, occurring on a seasonal cycle and with substantial interannual variability. To understand past trends and variability in sources and sinks of terrestrial carbon, we need quantitative estimates of global fire distributions. … Global fire emissions of carbon increase by about 10% between 1700 and 1900, reaching a maximum of 3.4 Pg C yr−1 in the 1910s, followed by a decrease to about 5% below year 1700 levels by 2010. The decrease in emissions from the 1910s to the present day is driven mainly by land use change, with a smaller contribution from increased fire suppression due to increased human population and is largest in Sub‐Saharan Africa and South Asia. Interannual variability of global fire emissions is similar in the present day as in the early historical period, but present‐day wildfires would be more variable in the absence of land use change.”





























Earl and Simmonds, 2018
Spatial and Temporal Variability and
Trends in 2001–2016 Global Fire Activity


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




“We find that there is a strong statistically significant decline in 2001–2016 active fires globally linked to an increase in net primary productivity observed in northern Africa, along with global agricultural expansion and intensification, which generally reduces fire activity.”


Doerr and Santín, 2016
Global trends in wildfire and its impacts:
perceptions versus realities in a changing world
“Wildfire has been an important process affecting the Earth’s surface and atmosphere for over 350 million years and human societies have coexisted with fire since their emergence. Yet many consider wildfire as an accelerating problem, with widely held perceptions both in the media and scientific papers of increasing fire occurrence, severity and resulting losses.”
“However, important exceptions aside, the quantitative evidence available does not support these perceived overall trends. Instead, global area burned appears to have overall declined over past decades, and there is increasing evidence that there is less fire in the global landscape today than centuries ago.”
“Analysis of charcoal records in sediments [Marlon et al., 2008] and isotope-ratio records in ice cores [Wang et al., 2010] suggest that global biomass burning during the past century has been lower than at any time in the past 2000 years.”
“Regarding fire severity, limited data are available. For the western USA, they indicate little change overall, and also that area burned at high severity has overall declined compared to pre-European settlement. Direct fatalities from fire and economic losses also show no clear trends over the past three decades. Trends in indirect impacts, such as health problems from smoke or disruption to social functioning, remain insufficiently quantified to be examined. Global predictions for increased fire under a warming climate highlight the already urgent need for a more sustainable coexistence with fire. The data evaluation presented here aims to contribute to this by reducing misconceptions and facilitating a more informed understanding of the realities of global fire.”

Marlon et al., 2012
Long-term perspective on
wildfires in the western USA
“Understanding the causes and consequences of wildfires in forests of the western United States requires integrated information about fire, climate changes, and human activity on multiple temporal scales. We use sedimentary charcoal accumulation rates to construct long-term variations in fire during the past 3,000 y in the American West and compare this record to independent fire-history data from historical records and fire scars. There has been a slight decline in burning over the past 3,000 y, with the lowest levels attained during the 20th century and during the Little Ice Age (LIA, ca. 1400–1700 CE). Prominent peaks in forest fires occurred during the Medieval Climate Anomaly (ca. 950–1250 CE) and during the 1800s.”
“Analysis of climate reconstructions beginning from 500 CE and population data show that temperature and drought predict changes in biomass burning up to the late 1800s CE. Since the late 1800s , human activities and the ecological effects of recent high fire activity caused a large, abrupt decline in burning similar to the LIA fire decline. Consequently, there is now a forest “fire deficit” in the western United States attributable to the combined effects of human activities, ecological, and climate changes. Large fires in the late 20th and 21st century fires have begun to address the fire deficit, but it is continuing to grow.”

 

Share this...FacebookTwitter "
"
Share this...FacebookTwitterIt has long been established in the scientific literature (and affirmed by the IPCC) that CO2 concentration changes followed Antarctic temperature changes by about 600 to 1000 years during glacial-interglacial transitions throughout the last ~800,000 years (Fischer et al., 1999; Monnin et al., 2001; Caillon et al., 2003; Stott et al., 2007; Kawamura et al., 2007).
In contrast, two new papers cite evidence that the timing of the lagged CO2 response to temperature changes may have ranged between 1300 and 6500 years in some cases.  It would appear that a millennial-scale lagged response to temperature undermines the claim that CO2 concentration changes were a driver of climate in the ancient past.  

Koutavas et al., 2018
Temperature correlations between the eastern equatorial 
Pacific and Antarctica over the past 230,000 years
“The EEP [eastern equatorial Pacific] stack shows persistent covariation with Antarctic temperature on orbital and millennial timescales indicating tight coupling between the two regions. This coupling however cannot be explained solely by CO2 forcing because in at least one important case, the Marine Isotope Stage (MIS) 5e–5d glacial inception, both regions cooled ∼5–6.5 thousand years before CO2 decreased. More likely, their covariation was due to advection of Antarctic climate signals to the EEP by the ocean.”
“The discovery that atmospheric CO2 covaries with Antarctic temperature and global ice volume (Lorius et al., 1990; Lüthi et al., 2008; Petit et al., 1999) has propelled CO2 to the forefront as climatic “globalizer”.  However, the processes governing CO2 variability are themselves poorly understood, and likely require an oceanic/climatic trigger in the first place (Adkins, 2013; Ferrari et al., 2014; Sigman et al., 2010).”
“Antarctic ice core records are furthermore ambiguous with regard to the causal relationship between CO2 and temperature. Phase relationships show CO2 lagging behind temperature in the obliquity band (Jouzel et al., 2007) and across some major transitions (Caillon et al., 2003; Fischer et al., 1999; Kawamura et al., 2007; WAIS Divide Project Members, 2013), most prominently during the Marine Isotope Stage (MIS) 5e–5d boundary, i.e. the last glacial inception. Antarctic cooling at this time was associated with a major Milankovitch signal, and appears to have transpired almost entirely before the change in CO2 concentration. It remains unclear whether the temperature lead was restricted to Antarctica or was broader.”

Uemura et al., 2018
Asynchrony between Antarctic temperature and CO2
associated with obliquity over the past 720,000 years

“Precise knowledge of the relationship between changes in temperature, atmospheric CO2 and solar insolation is essential to understanding Earth’s climate system. The values of a temperature proxy, the hydrogen isotopic composition (δD), in the Antarctic EDC ice core have varied in parallel with CO2 concentrations over the past 800 thousand years (kyr; r2 = 0.82). However, δD [temperature] apparently leads CO2 variations.”
“The lead is ca. 2000 years at a West Antarctic site.”
“Over the past 420 kyr, the Vostok ice core shows that the Antarctic δD temperatures lead the CO2 variations by 1.3 ± 1.0 kyr.”
“During the lukewarm interglacials (430–650 kyr BP), Antarctic δD [temperature] leads CO2 by 1900 years, and the correlation between CO2 and δD is weaker (r2 = 0.57), as determined from the EDC core.”
“Although the mechanisms underlying the coupling and the phase lags remain unclear, the Southern Ocean region, rather than Antarctica, is thought to play the central role in regulating CO2 variations. A box model, for example, estimated a ca. 60% increase in CO2 during TI that is attributable to direct and indirect temperature effects, such as changes in sea ice cover and vertical mixing in the Southern Ocean. On millennial time scales, a multi-proxy study suggests that an antiphased hemispheric temperature response to ocean circulation changes resulted in Antarctic temperatures leading global temperatures and CO2 during TI [the last glacial termination].  … [O]ur data suggest that the lead in Antarctic δD temperatures (i.e. temperature without correcting for source effects) over CO2 is partly attributable to the effects of the moisture source on δD temperatures over the past 720 kyr in the obliquity band. These results suggest that the importance of moisture source effects for the obliquity signal in δD. Thus, the source effect must be considered in future research about the relationship between Antarctic temperatures and CO2.”
“Within the obliquity frequency band, our analyses suggest that temperature variations in Antarctica have led ocean temperatures throughout the past 720 kyr. This phenomenon is most likely explained by the strong influence of local AMI on ΔT. … During TI [the last glacial termination], CO2 rose at ~18 kyr BP, which is related to the melting of the Northern Hemisphere ice sheet and the subsequent weakening of the Atlantic meridional overturning circulation (AMOC). Thus, the timing at which CO2 begins to rise during a termination would be determined by when the Northern Hemisphere ice sheet begins to melt. When eccentricity is small, the summer insolation maxima are small. Thus, if obliquity rises beyond the threshold of melting, a moderate climate forcing could cause warming enough that the southern margin of the North American ice sheet begin to retreat.”

Studies Indicating Temperature-CO2 Lag Was 600-1000 Years

IPCC (2007)
“Atmospheric CO2 follows temperature changes in Antarctica with a lag of some hundreds of years.”

Stott et al., 2007
Southern Hemisphere and Deep-Sea Warming Led Deglacial Atmospheric CO2 Rise and Tropical Warming
“Deep sea temperatures warmed by ~2C between 19 and 17 ka B.P. (thousand years before present), leading the rise in atmospheric CO2 and tropical surface ocean warming by ~1000 years.”

Caillon et al., 2003
“The sequence of events during Termination III suggests that the CO2 increase lagged Antarctic deglacial warming by 800 ± 200 years and preceded the Northern Hemisphere deglaciation.”

Fischer et al., 1999
“High-resolution records from Antarctic ice cores show that carbon dioxide concentrations increased by 80 to 100 parts per million by volume 600 ± 400 years after the warming of the last three deglaciations.”

Monnin et al., 2001
“The start of the CO2 increase thus lagged the start of the [temperature] increase by 800 ± 600 years.”

Indermuhle  et al., 2000
“The lag was calculated for which the correlation coefficient of the CO2 record and the corresponding temperatures values reached a maximum. The simulation yields a [CO2] lag of (1200 ± 700) yr.”

Kawamura et al., 2007    
“Our chronology also indirectly gives the timing of the CO2 rise at [glacial] terminations, which occurs within 1 kyr of the increase in Antarctic temperature.”
Share this...FacebookTwitter "
"The Volkswagen emissions investigation looks set to be of one of the biggest corporate scandals in recent history – and we’ve seen quite a few. While most of the focus will be on VW in the coming days and weeks, the real scandal lies elsewhere: with European governments and regulators who turned a blind eye to rule-bending. In some cases they’ve actually helped carmakers avoid environmental restrictions.  Documents leaked to the Guardian reveal just four months ago the UK, France and Germany all lobbied to maintain loopholes from outdated car emissions tests. Such behaviour isn’t unusual. For decades European car industry regulation has been weak and inconsistent, while car traffic and the resulting air pollution levels have been allowed to increase manifold. The UK government quietly launched its consultation on air quality earlier this month. This was in response to a supreme court ruling stating the government must take immediate action to cut nitrogen dioxide pollution, which has reached dangerous levels in many of the UK’s big cities. The only national measure in the proposed plans are for clean air zones, similar to the one already run in London, but responsibility for their implementation has been passed onto local authorities for which no additional money is available. The document notes that approximately 80% of the NOx (nitrogen dioxide and nitric oxide) emissions are due to transport, with the largest source being diesel vehicles. Air pollution has been linked to coronary artery disease, heart attacks and strokes. In the consultation it is estimated that the impact of nitrogen dioxide on mortality is equivalent to 23,500 deaths every year in the UK. This figure has been taken, along with earlier estimates of mortality due to particulate matter (29,000), to give 52,500 premature deaths each year due to air pollution.  We can’t simply add up the mortality statistics from the two pollutants due to double counting, but this huge number should nevertheless be taken very seriously. In fact, it should be treated as a national emergency. Despite tightened emission standards for diesel vehicles, air pollution measurements in the UK have failed to show improvements. As such the gap between on-road and test measurements of emissions is not itself new. A number of studies have indicated that new diesel vehicles breach EU standards when tested under real world conditions. The recent report from campaign group Transport & Environment found that nine out of every ten new diesel vehicles broke EU limits. On average real world NOx emissions were about seven times higher than permitted levels. Cars from all the major motor manufacturers were in breach of the limits with the worst car producing 22 times than that permitted. It is evident that the current practice of allowing motor manufacturers to select the bodies to test and check their compliance with emission limits is not fit for purpose and an independent testing authority should be established. Yet for many years the European car industry has lobbied against tighter environmental regulation, despite the mounting evidence of car transports’ rising negative impact on the climate (carbon emissions) and urban air pollution (NOx emissions). In the UK, for example, successive governments have been very eager to support car manufacturers with operations in the country. Just earlier this year the industry celebrated record sales of cars and vans in the UK. Yet the dark shadows of this one-sided policy now become visible. While the overwhelming focus of the UK’s transport strategy has been on expanding individual car journeys, public transport has become more expensive and worse in terms of quality and reach. Hopefully something good will come out of the VW scandal. Perhaps the UK and European public will become more aware of the threats of air pollution, not only by diesel engines, but by all car traffic. We need a sustainable transport strategy and have a real go at tackling air pollution in our biggest cities. With urban centres getting ever bigger and car ownership steadily rising, the problem is not going to go away."
"Thwaites glacier, a vast river of ice the size of Great Britain, holds enough frozen water that were it to collapse, the world’s oceans would rise by more than 60cm. Part of the West Antarctic ice sheet, it is one of the most unstable glaciers on the continent. Since the 1980s, Thwaites has lost 540bn tonnes of ice into the dark waters of the Amundsen Sea. This single glacier is responsible for 4% of global sea level rise. The rate of Thwaites’s disintegration has alarmed scientists for good reason. In a handful of decades it could retreat to the point that collapse becomes inevitable and irreversible. That would lock us into a future sea level rise of far more than half a metre or so. The reason is simple: today, Thwaites is a brake on large inland glaciers. Lose Thwaites, and those it holds back will follow. Over centuries perhaps, they would add fully 2m to sea level rise.  Nearly 100 scientists and support staff recently arrived at Thwaites, a place as inhospitable as Earth can muster, for an urgent and ambitious field expedition. Among the British and American teams are scientists, engineers and technicians who have set up tents on Thwaites ice shelf, the slab of glacier that has slipped off the Antarctic bedrock on to the sea. They have now set up a hot water drill to bore through the 600m shelf into the frigid waters beneath. It is a process that takes days, with small teams working nonstop around the clock. Why drill down? With the borehole open, the researchers will winch down a torpedo-shaped robotic submarine called Icefin. It will slip into the depths and make for the grounding line, where the base of the glacier lifts off the land. There it will inspect a grim discovery that Nasa scientists made some months back. Flying over the glacier on a plane fitted with ice-penetrating radar, they spotted a gigantic hole at the base of Thwaites. At 4km wide and 10km long, it is two-thirds the area of Manhattan. The 350m-tall cavern formed over three years when 13bn tonnes of ice melted away. Water had found its way between the glacier’s rough base and the bedrock to melt it, unnoticed, from below. Thwaites will surely now deteriorate faster. It is a stark reminder that for all the observations and sophisticated climate models that scientists produce, nature can still serve up unwelcome surprises. The fact is that we are ill-equipped to model precisely a global system as devilishly complex as the climate. If we don’t know every detail – every process, every threshold, and the direction and strength of every feedback loop – we must always expect surprises. This might be the lesson of Thwaites glacier. In both the US and the UK – the countries behind the expedition – science is in peril. The Royal Society warns that Britain is losing top scientists amid ongoing Brexit uncertainty. In the US, the administration has set itself against science, particularly in environmental disciplines, and scores of researchers have quit their posts. If Thwaites tells us anything, it is that we need more science, not less, to survive the climate crisis. Without it, we will not understand the full threat we face, nor be well placed to mitigate its most dangerous consequences. If we want to avoid more unwelcome surprises, we must not let our guard down. "
"Ever thought how the ingredients for that bacon sandwich got to your plate? By that, I mean the amazing historical journey that has transformed the animal and plant species we farm today into the huge global biomass that now feeds billions of us. The shift from hunting and foraging to farming began some 12,000 years ago and was one of the most fundamental shifts in our own species’ evolutionary and cultural history. It set up exponential population growth and health consequences we still live with today. The animals and plants that underpin all this are those we changed forever through a phenomenon called “domestication”. It’s an enigmatic process we still know little about. For decades, scientists (including Charles Darwin) have argued about how domestication works, with much ink being spilt contrasting the deliberate human role versus that of a natural biological process. Back to that bacon sandwich. The pig was one of the first farmyard animals to be domesticated, and today pork is the most widely eaten meat across the globe. Pigs are also important for the pharmaceutical industry – they’re the source of more than 20 key drugs – while “transgenic” pigs can provide humans with heart-valve transplants and maybe in future entire organs. So where did this illustrious farmyard animal’s domestic relationship with humans begin? Its ancestor the wild boar (Sus scrofa) is distributed across the vast majority of Europe and Asia, meaning it could have been domesticated almost anywhere. However, zooarchaeological evidence (the bones and teeth of animals) indicate pig domestication probably began in Eastern Turkey some 9-10,000 years ago and then, independently, several thousand years later in central China. Recent research matching DNA from wild boar populations to domestic pigs suggests pig domestication occurred in additional places across the Old World – including Europe. Archaeologists traditionally thought humans directly intervened early in the process, isolating a few individuals from the local wild population. Once these “proto-domestic” animals were separated from their wild counterparts, the theory goes, there was no further significant breeding between the two. This should be especially true for pigs, since the re-introduction of “wild” traits back into domestic stock would be particularly undesirable – no farmer wants hairy pigs with attitude and dangerous tusks who keep wanting to escape. This form of domestication should result in a genetic “bottleneck” – an evolutionary process not unlike that involved in the natural (or human-mediated) dispersal by mammals to remote islands. Then, over the next several generations of breeding and selection in this small group, the looks and behaviour that differentiate domestic from wild forms would appear. Others, however, argue domestication was much more dynamic and fluid, occurring over a longer timescale and involving more-or less continuous gene flow between wild and domestic populations. They challenge claims of additional instances of pig domestication beyond the Near East and China, stating that genetic data could equally be explained by ongoing breeding with wild boar as domestic swineherds moved across Eurasia with early farmers. In a new paper published in Nature Genetics, researchers from Oxford and Wageningen University (Netherlands) have applied advanced modelling approaches to genomic data from pigs and wild boar in order to resolve these longstanding contradictory viewpoints. Their results are compelling and throw new light on the process of domestication. First, the data shows modern-day domestic pigs to be a mosaic of different wild boar populations, supporting previous conclusions drawn from studies of modern and ancient DNA. Their results, however, don’t support previous claims for the existence of numerous other centres of pig domestication outside Western Asia and China. Their modelling of genomic data from Western Asia and Europe instead implies continuous and significant gene flow between wild boar and domestic pigs across these regions and, crucially, no evidence for a genetic bottleneck in European domestic pigs. But how were the distinctive traits that differentiate wild and domestic forms of Sus scrofa maintained in the face of continued gene flow back and forth? The highly plausible explanation is that recurrent intentional or unintentional selection for similar traits somehow counteracted its effects, creating what the researchers calls “genomic islands of domestication” – that is, pigs in some regions were less affected by gene flow from wild boar.  These so-called genetic sweeps seem to have had the same affect on pig genomes in the two geographically isolated regions of the world where pigs were independently domesticated, hinting at a more fundamental underlying genetic and developmental basis for the process – perhaps involving a number of so called “domestication genes”. This new genetic data is finally allowing us to move beyond questions about when, where and how many times pigs were domesticated, to how the process actually worked. Something to think about, next time you tuck into your bacon sandwich."
nan
"Barclays is being urged to stop offering loans to fossil fuel companies as part of the first ever shareholder climate resolution aimed at a UK bank. A group of 11 pension and investment funds managing more than £130bn worth of assets have filed a resolution calling for Barclays to set clear targets to phase out services to energy companies that fail to align with Paris climate goals. That includes lending to specific fossil fuel projects or for companies themselves, which include electricity and gas providers which fall foul of climate targets. The Paris agreement requires emissions to peak then fall rapidly to reach net-zero by 2050. The resolution, spearheaded by the campaign group ShareAction and signed by more than 100 additional individual shareholders, will be voted on at Barclays annual general meeting in May 2020. The Brunel Pension Partnership (BPP) – which manages £30bn for local government pension schemes across counties such as Devon, Dorset, Oxfordshire, Somerset and Cornwall – was among the institutional investors backing the resolution. The 11-strong group owns about 0.2% of Barclays shares. BPP’s chief executive, Laura Chappell, said the climate crisis was putting its own client’s retirement benefits at risk. “Climate change poses significant risks to global financial stability and could thereby create climate-related financial risks to our own business operations, portfolios and client partner funds, unless action is taken to mitigate these risks.” She added: “We hope the Barclays Board formally supports this resolution.” A recent study commissioned by groups including the Rainforest Action Network singled Barclays out as the largest financier of fossil fuels in Europe and the sixth largest in the world. It showed that total lending and underwriting to carbon-intensive companies and projects totalled $85bn (£64bn) between 2015 and 2018. Barclays has also been criticised by groups including ShareAction and Greenpeace over its climate policy, which they say does not go far enough to address the crisis. While the bank said in January last year it would stop financing greenfield mining and construction or expansion of coal-fired power stations in all countries, it still allows Barclays to bankroll companies that are highly dependent on coal. It also stops short of ruling out backing controversial tar sands projects and allows the bank to support Arctic oil and gas projects. The resolution comes ahead of the Bank of England’s first ever climate stress tests, which will force the UK’s largest banks to report how exposed they are to the climate crisis and how they would respond to temperatures rising by up to 4C. The bank has warned that drastic environmental damage could hit financial institutions by reducing asset values, lowering profitability and raising the cost of underwriting insurance losses. Barclays is among the eight lenders expected to go through the exercise. While the central bank will only release aggregate results to the public, it plans to use the first batch of reports to inform how it supervises each company. Barclays said: “We are working to help tackle climate change, and we meet with Share Action and other shareholders regularly to update them on our progress.” Arcus Foundation As You Sow Brunel Pension Partnership Central Board of the Methodist Church Falkirk Council Pension Fund Folksam Jesuits in Britain Lankelly Chase LGPS Central Merseyside Pension Fund Sarasin & Partners"
nan
"The summer heatwaves of 2019 resulted in almost 900 extra deaths, according to statistical analysis from Public Health England. Over the past four years more than 3,400 people have died early during periods of extreme temperature in England. Global heating is increasing the frequency of heatwaves and a cross-party committee of MPs warned in July that the UK was “woefully unprepared” for this impact of the climate emergency.  All regions of England were affected except the south-west, and almost all the premature deaths were among people aged 65 or over. The frail elderly with heart or kidney problems are most at risk in a heatwave and dehydration can also lead to dizziness and falls. The physicist Edward Teller tells the American Petroleum Institute (API) a 10% increase in CO2 will be sufficient to melt the icecap and submerge New York. “I think that this chemical contamination is more serious than most people tend to believe.” Lyndon Johnson’s President’s Science Advisory Committee states that “pollutants have altered on a global scale the carbon dioxide content of the air”, with effects that “could be deleterious from the point of view of human beings”. Summarising the findings, the head of the API warned the industry: “Time is running out.” Shell and BP begin funding scientific research in Britain this decade to examine climate impacts from greenhouse gases. A recently filed lawsuit claims Exxon scientists told management in 1977 there was an “overwhelming” consensus that fossil fuels were responsible for atmospheric carbon dioxide increases. An internal Exxon memo warns “it is distinctly possible” that CO2 emissions from the company’s 50-year plan “will later produce effects which will indeed be catastrophic (at least for a substantial fraction of the Earth’s population)”. The Nasa scientist James Hansen testifies to the US Senate that “the greenhouse effect has been detected, and it is changing our climate now”. In the US presidential campaign, George Bush Sr says: “Those who think we are powerless to do anything about the greenhouse effect forget about the White House effect … As president, I intend to do something about it.” A confidential report prepared for Shell’s environmental conservation committee finds CO2 could raise temperatures by 1C to 2C over the next 40 years with changes that may be “the greatest in recorded history”. It urges rapid action by the energy industry. “By the time the global warming becomes detectable it could be too late to take effective countermeasures to reduce the effects or even stabilise the situation,” it states. Exxon, Shell, BP and other fossil fuel companies establish the Global Climate Coalition (GCC), a lobbying group that challenges the science on global warming and delays action to reduce emissions. Exxon funds two researchers, Dr Fred Seitz and Dr Fred Singer, who dispute the mainstream consensus on climate science. Seitz and Singer were previously paid by the tobacco industry and questioned the hazards of smoking. Singer, who has denied being on the payroll of the tobacco or energy industry, has said his financial relationships do not influence his research. Shell’s public information film Climate of Concern acknowledges there is a “possibility of change faster than at any time since the end of the ice age, change too fast, perhaps, for life to adapt without severe dislocation”. At the Rio Earth summit, countries sign up to the world’s first international agreement to stabilise greenhouse gases and prevent dangerous manmade interference with the climate system. This establishes the UN framework convention on climate change. Bush Sr says: “The US fully intends to be the pre-eminent world leader in protecting the global environment.” Two month’s before the Kyoto climate conference, Mobil (later merged with Exxon) takes out an ad in The New York Times titled Reset the Alarm, which says: “Let’s face it: the science of climate change is too uncertain to mandate a plan of action that could plunge economies into turmoil.” The US refuses to ratify the Kyoto protocol after intense opposition from oil companies and the GCC. The US senator Jim Inhofe, whose main donors are in the oil and gas industry, leads the “Climategate” misinformation attack on scientists on the opening day of the crucial UN climate conference in Copenhagen, which ends in disarray. A study by Richard Heede, published in the journal Climatic Change, reveals 90 companies are responsible for producing two-thirds of the carbon that has entered the atmosphere since the start of the industrial age in the mid-18th century. The API removes a claim on its website that the human contribution to climate change is “uncertain”, after an outcry. Exxon, Chevron and BP each donate at least $500,000 for the inauguration of Donald Trump as president. Mohammed Barkindo, secretary general of Opec, which represents Saudi Arabia, Kuwait, Algeria, Iran and several other oil states, says climate campaigners are the biggest threat to the industry and claims they are misleading the public with unscientific warnings about global warming. Jonathan Watts “Heatwaves continue to result in significant health impact,” said the PHE report. It reported the “excess deaths” during the heatwaves, ie the additional mortalities compared with the long-term average for those dates. Two heatwaves accounted for the 892 deaths. The first, from 21 to 28 July, included the highest temperature ever recorded in the UK: 38.7C in Cambridge. The second occurred between 23 and 29 August. The climate crisis made 2019 a year of record temperatures in the UK, according to the Met Office. The only region that recorded a statistically significant number of deaths in those under 65 was London, with 41 early deaths reported during the August heatwave. “Tragically, many of these deaths are likely to have been preventable,” said Bob Ward, at the Grantham Research Institute on Climate Change at the London School of Economics. “Many of the people who are killed by heatwave conditions die in their own homes or in care homes. The Committee on Climate Change (CCC) pointed out in July 2019 that the government has failed to set out a coherent plan for implementing the adaptations required.” The CCC said it had been recommending new building regulations to ensure homes, hospitals and schools do not overheat since 2015, but that this advice had been rejected by ministers, who cited a commitment to “reduce net regulation on homebuilders”. Without action, the number of people dying as a result of heat is expected to reach 7,000 a year by 2040, the CCC said. “The CCC also noted that although there has been a heatwave plan for England since 2004, there is no evidence that it has reduced the number of deaths that occur during hot weather,” said Ward. The report from the House of Commons environmental audit committee said hospitals and care homes in particular must be prepared for heatwaves, given that sick and elderly people are most vulnerable. But they say currently the NHS is only required to prepare plans for severe cold weather. “The government needs to take much more seriously the dangers of hot weather. The threat of deadly heatwaves is growing due to climate change and the death toll is likely to rise unless there is strong action,” said Ward. The Department of Health has been contacted for comment."
"The Australian actor Yael Stone has vowed to give up her green card, which allows her to work in the United States, as a “personal sacrifice” aimed at reducing carbon emissions in what she called the “climate war”. In a video posted to Twitter on Tuesday and Instagram on Sunday, the actor and star of Netflix’s Orange is the New Black said she came to the decision to give up her green card “after a long, considered process”.  “We’ve come to understand that it’s unethical for us to set up a life in two countries, knowing what we know,” Stone said in the video, calling such frequent travelling “environmentally unjust”. “The carbon emissions alone from that flying – it’s unethical. It’s not right. So I will be going through the process of giving up my green card, and saying goodbye to a life in America. I’m going to be here in Australia doing the the work I can to make a difference here. Because the time is now.” Not environmentally ethical to build a life across two continents. Time to make a sacrifice. pic.twitter.com/4gFVImMeMg In an earlier video posted to Instagram on Sunday, Stone expressed horror at the political response to Australia’s ongoing and months-long bushfire crisis. “I’m sitting in a dark room wondering what the hell is happening. Our country is on fire … and our prime minister has done absolutely nothing. Cold, calculated nothing. We don’t have leaders, we have cowards,” she said.  Death and destruction here in Australia. It’s time to act. This is war. A post shared by  Yael Stone (@yaelstone) on Jan 3, 2020 at 7:29pm PST The actor, who recently starred in Sydney Theatre Company’s production of The Beauty Queen of Leenane, also implored others to act. “The leaders we have are the people around us. And that’s what we have to become. “We have to step up because this is war. This is a climate war. And for the first time our enemy is not wearing a uniform that we’ll be able to recognise. Our enemy is our own behaviour.” Stone said giving up her green card was a way that she could put “skin in the game”. “This is war, and we’ve only got 10 years. So let’s make these sacrifices. Let’s make these changes. Let’s put some skin in the game and say yeah, I care, and this is what I’m going to do about it. This is just the beginning from me,” she said. “It’s corporate wide, it’s government wide, it’s systematic changes that must happen, and they must happen yesterday. It’s time to act.”"
nan
"Humans are notorious for cheating and deceiving. But we also like to see cheaters get punished. Surprisingly, our research has revealed that the same holds true in the animal kingdom – at least among birds.  We found that African cuckoo finches – brood parasites that rely on a different kind of bird to raise their young – have evolved to look like harmless weaver birds in an attempt to deceive their hosts. But we also discovered that their tawny-flanked prinia hosts have caught onto this and responded by being aggressive to anyone resembling their enemy – a form of collective punishment.  Brood parasites never build their own nests or raise their own offspring. Instead, they lay their eggs in the nests of other birds and abandon the care of their young to the hosts. The first act of most brood parasite species’ chicks after hatching is to do away with the host’s own brood. Different species do this by ejecting their nest mates from the nest, by using their sharp beaks to fatally injure them, or by physically dominating them.  While hosts obviously do all they can to defend their nests, brood parasites evolve responses to this behaviour. This in turn drives the evolution of better defences in the host, and so on – a process known as an “evolutionary arms race”.  One of the most common strategies for brood parasites to manipulate their hosts into raising their offspring is known as “aggressive mimicry”. This is a way for the birds to dupe a host by looking harmless, for example by resembling a species that is not parasitic. The strategy is already well-documented in a variety of brood parasite species: some lay eggs that resemble those of their hosts, while the chicks and fledglings of others look (and sound) like the host’s own chicks and fledglings. This is necessary, as hosts will reject parasitic eggs, chicks and fledglings, if they can detect them. The first challenge for brood parasites is for a female to get her egg into a host nest. Because of this hosts are often very aggressive towards adult brood parasites near their nests. Our research focused on whether natural selection has shaped aggressive mimicry in female brood parasites to help them slip past host defences.  We specifically looked at cuckoo finches, as there is already good evidence of an evolutionary arms race between it and its primary host in southern Zambia, the tawny-flanked prinia. We were suspicious that adult female cuckoo finches might be employing aggressive mimicry to get into their host’s nest because they look remarkably similar to another group of species that shares their grassy habitats: females of the several common species of weavers, known as bishopbirds or widowbirds. Is this coincidence, or a deceptive strategy shaped by natural selection? To answer this question, first we measured and compared the colour and pattern of cuckoo finches’ plumage to those of Vidua finches (the cuckoo finch’s closest relatives) and weavers at the Natural History Museum at Tring, UK.  If female cuckoo finches looked more similar to Vidua finches than to weavers, then it would suggest that the cuckoo finch plumage is a product of their shared ancestry. If they looked equally similar to Vidua finches and weavers, it would suggest that their plumage has been shaped through shared selection pressures from a shared environment (for example, having to avoid shared predators). However, if they looked more similar to the weavers than the Vidua finches, it would suggest that natural selection for mimicry has driven their resemblance. We found the latter, which suggested that female cuckoo finches have evolved to mimic weavers. We then conducted two field experiments in southern Zambia to test whether we could verify this apparent case of mimicry. This meant months of long days watching these birds from the inside of a hide, which was absolutely brilliant! Using model cuckoo finches and model southern red bishops (a common weaver species at the study site), we tested whether the prinias reacted differently towards female cuckoo finches and female southern red bishops, compared to male cuckoo finches and male southern red bishops. Unlike females, males of these two species look very different: male cuckoo finches are bright yellow and male southern red bishops are black and red. Surprisingly, we found that the prinias were extremely aggressive to both the harmful female cuckoo finches and harmless southern red bishops – treating both as threats. They were not, however, aggressive to males of either species.  So were the prinia really deceived by the cuckoo finches’ mimetic plumage? To answer this, we carried out one last experiment. We presented a female cuckoo finch, a female southern red bishop or a male southern red bishop model near a prinia nest. After that, we replaced a prinia egg with an experimental egg to simulate egg laying by a real cuckoo finch. Just as expected, we found that the prinias were much more likely to reject the foreign egg after seeing one of the two female species than when they saw a male bird. This showed that they were unable distinguish between the two female species and that the cuckoo’s mimicry is successful, but does not give the cuckoo finch the advantage in the arms race at this site.  The analogy of the “wolf in sheep’s clothing” could be helpful here. The prinias recognise the wolf as a threat, but as they are unable to tell wolves from sheep, they respond by punishing all the sheep, just to be safe.  This is unfortunate for the cuckoo finch – and we suspect this is because the rate of parasitism is consistently high at this site, making this strategy worthwhile for the crafty prinias. Similar to cheating in human society, it seems like the real loser in this situation is the innocent bystander: the unassuming female southern red bishop."
"Nearly a century has passed since Europe’s last major tsunami, a 13m wave caused by an earthquake off the coast of Sicily that was responsible for around 2,000 deaths. Sometimes tsunamis in the Mediterranean can be even more destructive – a large volcanic eruption on the island of Thera (Santorini) around 3500 years ago generated a wave that decimated an entire civilisation, the Minoans, and may have led to the legend of Atlantis. Millions more people live along the Mediterranean coastline these days, of course, and the volcanoes and earthquakes haven’t gone anywhere. Indeed a new study in the journal Ocean Science suggests even a moderate earthquake in the eastern Mediterranean could set off a tsunami with the potential to affect a large proportion of the 130m people who live on its coastline. The devastating tsunamis that hit Indonesia and surrounding countries in 2004 and Japan in 2011 were a wakeup call. Since the turn of the century 177 tsunamis have actually been recorded and of these, four occurred within the Mediterranean basin. These four were all relatively small, and no one died. But history – and seismology – suggests more destructive waves are inevitable. Are we prepared for the “big one”?  The Mediterranean is ultimately prone to tectonic (and volcanic) activity as a result of the collision of the African plate into the western portion of the Eurasian plate. For the past 65 million years or so, this collision has proceeded, producing the Alps, which are still growing, and closing the Tethys Sea which once separated both continents.  Today, the Mediterranean Sea is the remnant of the Tethys and it too is shrinking as the African plate continues to drive north at about 2.5cm per year. The boundary between these plates is not clear cut however, and as a result, the Mediterranean region is criss-crossed with active fault-lines and it is these, along with plate movements, which create a complex tectonic setting and produce the region’s earthquake risk.  Significantly however, the tectonics of the region are not at all that similar to those in Indonesia or Japan. In the Pacific and Indian Oceans, the tectonic hazard results largely from subduction, where one plate is driven beneath another. Large earthquakes are common at subduction boundaries, and often result in massive displacement at the ocean bed which generates very large tsunamis.  Although there are areas of subduction in the Mediterranean, the scale is much smaller meaning less displacement and smaller tsunamis. Scientists have, in fact, suggested that the 1908 Sicily tsunami was not directly a result of displacement at all, but rather the result of an earthquake-generated landslide on the sea bed. Often, it is not the size of a tsunami (or indeed any natural hazard) that results in human devastation but rather where it is focused. In 1958 for example, the largest tsunami on record struck Lituya Bay in Alaska. The 30 metre high wave was powerful enough to travel more than 500m up the valley sides but, given the remote location, just five people were killed. In contrast, the 2004 Indonesian tsunami reached around 24m in some places, but by striking in a densely populated region, the human impact was unimaginable. With this in mind, Mediterranean tsunamis pose a significant risk. Around 130 million people live on the coastline, often in big cities: Barcelona and Algiers in the west (both with a population of 1.6 m), Naples and Tripoli in the central region (both 1m) and Alexandria (4m) and Tel Aviv (400,000) to the east.  The risk is further compounded by the fact the Mediterranean is relatively small and enclosed, meaning any tsunami could spread throughout the whole basin. Warning times, essential for minimising human losses, would also be small. Economic impacts could also be significant, with the Mediterranean home to some large industrial centres and ports. Little can be done about the hazard itself – seismic and volcanic activity can neither be prevented nor (accurately) predicted. However there are steps which can, and in some cases have, been taken to reduce the potential impact of Mediterranean tsunamis.  Following the 2004 Indonesian tsunami, UNESCO set up the (take a deep breath) Intergovernmental Coordination Group for the Tsunami Early Warning and Mitigation System in the North-eastern Atlantic, the Mediterranean and connected seas (ICG/NEAMTWS). This group is responsible for monitoring seismic activity, sea levels and other relevant data, and disseminating warnings when necessary. Such warnings saved many lives in Japan in 2011.  Development of early warning systems is progressing, but workable and widespread availability of such warnings is likely to be far off. Given this, education of vulnerable communities is key so that they can identify early warning signs and act accordingly.  Unfortunately it might well take a large, devastating tsunami in the Mediterranean before warning and defences are taken seriously. We can only hope that the wave, when it comes, is not as destructive as could be."
"The world’s tides contain enough energy to power the entire UK’s electricity consumption. And, since it effectively harnesses the moon’s constant and predictable gravitational pull, tidal power overcomes one of renewable energy’s classic problems – the fact you never know quite how much sun, wind or rain to expect. Now, underwater windmills positioned just below the ocean surface could be a major breakthrough for tidal power. Costly technology and inaccessible locations have thus far held things back. Large, heavy and expensive turbines mounted on the seabed have been developed, but these are aimed at commercial scale developments. Tidal power needs its equivalent of the rooftop solar panel. Imagine then a wind turbine, but underwater, and not fixed to the seabed – these so-called “mobile floating turbines” are a cheaper and more adaptable alternative to big, fixed developments. Most floating turbines look something like this: They’re placed whereever tidal flows will be strongest, and are then loosely tethered to (but not built on) the seabed. Cables take power generated by the turbines down to the seabed and along to the shore. Floating turbines are able to capture energy from the fastest-flowing water, which tends to be just below surface. At the bottom, where the water bumps against the seabed, things slow down and the flow is less smooth. Turbines floating in the right place could generate significantly more energy than those stuck to the sea bed. Tidal currents also shift direction roughly every six hours, therefore an optimal turbine would take advantage of these two-way flows. Floating turbines can freely rotate in the changing tide, eliminating the need for costly and complex mechanical yawing systems used by bed-mounted turbines.  Deploying large, heavy turbines on the bed requires expensive specialised vessels and docks. Even routine maintenance is costly.  In contrast, floating turbines can be towed to a site and installed very quickly at a fraction of the cost. Internal machinery can be positioned above the waterline allowing instant access for routine maintenance and minimal waterproofing costs.  Since they’re relatively cheap to set up and operate, floating turbines are suited for a wider market, not just utility companies. Industries close to the coast could invest in a floating turbine to reduce their electricity bill, in much the same way as they are currently doing with solar or wind technologies. You can even “plug in” multiple turbines by sharing mooring points.   While bed-mounted turbines aren’t visible from the surface, most floating turbine designs would be visible and could interfere with shipping lanes or be exposed to floating debris.  Floating turbines could be best suited to sheltered tidal environments such as estuaries, since storm waves could interfere with their power output and operation. Numerous floating turbine designs exist, utilising a variety of interesting innovations. Some have a hull which floats on the surface while the turbines operate underwater, as in the case of Scotrenewable’s SR2000 which claims to be the “largest and most powerful tidal turbine in the world”. Its 64m long hull and 16m diameter turbine blades are designed to last for 20 years.  Other floating designs include a modular design for easy transportation and assembly anywhere in the world, or a specially-streamlined turbine moored to a swivelled connector, for use in rough seas. Some “floating” tidal turbines actually bob somewhere just below the surface. In one design a “hinge” on the sea bed is attached to a semi-submerged platform that can fit up to 36 turbines, which can freely rotate into the flow. Developer Black Rock considers lots of independent and inexpensive turbines positioned to catch the optimum tidal flow a better configuration than a single larger turbine. Floating turbines demonstrate the continued effort towards exploiting the vast tidal energy resource. The sector is growing ever closer to commercial scale arrays using bed-mounted turbines, but floating turbines could increase development opportunities further."
"Two senior Victorian ministers have endorsed a police call for climate activists to abandon a planned protest on the state’s next high fire danger day. The demonstration has been set down for Friday night in Melbourne’s CBD in response to the bushfires, which have blackened more than 1.2m hectares of Victoria. Authorities on Wednesday urged Uni Students for Climate Justice organisers to call off the action, change the date or at least confine it to one spot. The emergency services minister, Lisa Neville, said she was stunned to hear the protests were going ahead when fire conditions were expected to worsen and urged organisers to reconsider. “This is a really reckless and selfish thing people are doing,” she said. “I don’t want to see police having to pull people out of [fire-affected] communities to come in and manage a protest. “There is a time for protests. It’s not this Friday.” The link between rising greenhouse gas emissions and increased bushfire risk is complex but, according to major science agencies, clear. Climate change does not create bushfires, but it can and does make them worse. A number of factors contribute to bushfire risk, including temperature, fuel load, dryness, wind speed and humidity.  The Bureau of Meteorology and the CSIRO say Australia has warmed by 1C since 1910 and temperatures will increase in the future. The Intergovernmental Panel on Climate Change says it is extremely likely increased atmospheric concentrations of greenhouse gases since the mid-20th century is the main reason it is getting hotter. The Bushfire and Natural Hazards research centre says the variability of normal events sits on top of that. Warmer weather increases the number of days each year on which there is high or extreme bushfire risk. Dry fuel load - the amount of forest and scrub available to burn - has been linked to rising emissions. Under the right conditions, carbon dioxide acts as a kind of fertiliser that increases plant growth.  Dryness is more complicated. Complex computer models have not found a consistent climate change signal linked to rising CO2 in the decline in rain that has produced the current eastern Australian drought. But higher temperatures accelerate evaporation. They also extend the growing season for vegetation in many regions, leading to greater transpiration (the process by which water is drawn from the soil and evaporated from plant leaves and flowers). The result is that soils, vegetation and the air may be drier than they would have been with the same amount of rainfall in the past. The year coming into the 2019-20 summer has been unusually warm and dry for large parts of Australia. Above average temperatures now occur most years and 2019 has been the fifth driest start to the year on record, and the driest since 1970. Not a significant one. Two pieces of disinformation, that an “arson emergency”, rather than climate change, is behind the bushfires, and that “greenies” are preventing firefighters from reducing fuel loads in the Australian bush have spread across social media. They have found their way into major news outlets, the mouths of government MPs, and across the globe to Donald Trump Jr and prominent right-wing conspiracy theorists. NSW’s Rural Fire Service has said the major cause of ignition during the crisis has been dry lightning. Victoria police say they do not believe arson had a role in any of the destructive fires this summer. The RFS has also contradicted claims that environmentalists have been holding up hazard reduction work. The environment minister, Lily D’Ambrosio, said the last thing emergency services needed was people “deviated or distracted” by a well-meaning but poorly-timed protest. “People are entitled to protest, absolutely, but the timing is wrong,” she told reporters while at the airport to greet North American firefighters coming to help. “People are recovering, trying to recover, at the same time they’re preparing for another spike event.” The acting assistant police commissioner, Tim Hansen, also said Friday was not a good time. “This is a distraction for us. We see frontline staff returning from the fire ground ... fatigued that do need a break and this is now another operation we need to resource,” he told reporters. “We are frustrated by this protest timing and we are also frustrated by the lack of flexibility by the protest organisers to work with us in trying to find a more suitable time. “These are unprecedented times for emergency services.” The protest is expected to draw thousands of people who believe the fires are the result of decades of climate change. The protest organiser Anneke Demanuele has been contacted for comment."
"Antarctica’s ice sheets could totally collapse if the world’s fossil fuels are burnt off, according to a recent climate change simulation. While we are unlikely to see such a dramatic event any time soon, we are already observing big changes and it’s worth considering what the worst case scenario might look like for the continent’s ecosystems. How long before Antarctica turns into grassy tundra? For now, life thrives mostly at the very edge of the continent – it’s driven by the plankton-rich Southern Ocean and clustered around seasonally ice-free areas of coastal land. The interior might be sparsely inhabited, but the continent is not as barren as many think. There are around 110 native species of moss and two flowering plants, the Antarctic hairgrass and pearlwort. These plants have flourished along the relatively mild Antarctic Peninsula in recent decades. However they can’t go much further – they already occur at almost the most southern suitable ice-free ground. With ice-caps and glaciers receding already in the Peninsula region, native land plants and animals are benefiting from more easily available liquid water. Already we are starting to see increased populations, greater areas occupied and faster growth rates, consequences only expected to increase – everything is currently limited by the extreme physical environment.  It may eventually prove too warm for some native species, but the bigger issue in upcoming decades and centuries will be whether new and currently “non-native” species will arrive that are stronger competitors than the native organisms. Native polar species are inherently weak competitors, as they have evolved in an environment where surviving the cold, dry conditions is the overriding selective pressure rather than competition from other biological sources. If humans (or other wildlife expanding their range southwards) bring new competitors and diseases to Antarctica, that may pose a very grave risk to the existing biodiversity. Some native species would likely be pushed into the remaining more extreme regions where they can avoid competition and continue to rely on their inherent stress tolerance abilities. We usually split the process of natural colonisation – which applies even today in Antarctica – and that of movement of “alien” species by human agency. The best available data for the Antarctic region come from some sub-Antarctic islands, where it appears humans have been responsible for many more successful colonisations than nature. In fact, over the recent centuries of human contact with the region we have introduced 200-300 species compared to just two or three known natural colonisations.  Penguins, seals and flying seabirds move between islands and the Antarctic Peninsula, so there is potential for some natural colonisation. Vagrant birds are regularly observed across the sub-Antarctic and even along the Peninsula, some of which have colonised successfully (such as the starlings, redpolls and mallard ducks on Macquarie Island).  Migrants such as skuas and gulls, which spend time on land at both ends of their migration, could be important natural vectors of transfer for invertebrates, plant seeds and spores, and microbes into an ice-free Antarctica. Importantly, bird colonies also fertilise surrounding rock and soil with faeces, eggshells and carcasses. Plant and animal life flourishes near seabird colonies, encouraged by this enrichment. However it can be tough to predict what Antarctic melt would mean for individual species, never mind entire ecosystems. Take penguins, for instance – they have already survived previous inter-glacial retreats, but at reduced population sizes. This time round it is likely that Adélie and emperor penguins who are more dependent upon sea ice would decline, while less ice-dependent species such as gentoos and chinstraps might benefit. Indeed, there is already some evidence that emperors are struggling (although also that they may be adapting and learning to emigrate). However the fact fish-eating gentoo penguins are increasing on the Peninsula while Adélies and chinstraps (both krill eaters) aren’t doing so well suggests prey availability can be more to blame than ice cover. Figuring out the impact of large-scale environmental change at ecosystem or food-web level is hard – it’s a complex process that will no doubt throw up some unexpected results. The sub-Antarctic islands are full of examples of such unexpected impacts. Pigs, dogs, cats, sheep, reindeer and rabbits have all been intentionally introduced in the past, with often devastating effects. Rats and mice were introduced to South Georgia and other islands accidentally by sealers and whalers, for instance, and have decimated seabird populations. A recent eradication campaign appears to have been successful and pipits, ducks and small seabirds are showing some immediate signs of recovery.  The removal of non-native cats from Macquarie and Marion Islands has similarly helped native burrowing seabirds, although responses in such ecosystems can be far more complex and unpredictable – the removal of cats from Macquarie also led to increase in the introduced rabbit population, and considerably increased damage to sensitive native vegetation. Antarctic biodiversity is far more complex than widely assumed, with up to 15 distinct biogeographic regions that have been evolutionarily isolated for many millions of years. Humans present the greatest threat, not only of introducing new species, but also of moving “native” species between regions within Antarctica. This could be even more damaging, as these native species would already be pre-adapted to polar life. Visitors to Antarctica are subject to increasingly strict biosecurity measures but accidental introductions continue to occur, often through food shipments for scientists. Changes in sea and land ice affect access to new areas, so we can only expect plant and invertebrate invasions to increase unless biosecurity becomes more effective.  While cost issues may be raised, it is worth remembering that prevention will always be better – and cheaper – than subsequent control and eradication, even if such action is possible."
"Air pollution is rarely a major concern for most people in Western Europe. You seldom notice it except when sitting in heavy traffic or when it obscures the far horizon at a scenic spot.  However until the middle of last century it was a different story, with heavy industry and domestic heating filling city air with smoke, noxious gases and ozone. These air pollutants contribute to smog: the unpleasant combination of gases and particles that irritates the lungs and can do lasting damage to health. Many parts of the developing world still suffer from the high levels of air pollution that accompany unbridled industrial expansion and rapid economic development. New research on the health impacts of outdoor air pollution suggests that it is responsible for more than 3m premature deaths around the world each year and that this number could double by 2050. The study, published in Nature, looks at how the major sources of air pollutants, including traffic, industry, agriculture and domestic sources contribute to pollution levels in different parts of the world and estimates their associated impacts on mortality through heart and lung diseases. Unsurprisingly, the greatest effects were found in rapidly developing, heavily populated countries such as China and India. Despite large increases in industrial production, energy generation and vehicle traffic, the study identifies domestic and commercial energy use associated with heating and cooking as the biggest contributor to the high toll from outdoor air pollution in these regions. China suffers the most, accounting for more than 40% of air pollution-related deaths worldwide – more than 1.3m each year. The country’s large population, intensive agriculture and heavy industrialisation mean that economic development has come at a high environmental cost.  Major cities such as Beijing have experienced rapid deterioration in air quality associated with economic growth and the changing lifestyles of an expanding urban middle class. Traditional paper fans have long since been replaced by air conditioning as the preferred means of keeping cool in summer. At the turn of the century Beijing had one million vehicles; now, it has more than five times as many, bringing exhaust fumes and gridlocked streets. Towering new high-rise apartments are hidden from view behind a pollutant haze that turns the sky white and forces citizens to don protective face masks. Ordinary Chinese citizens are well aware of the problem. Environmental issues top the list of major public concerns and are a popular topic for online discussion. Air quality is monitored on a continuous basis at more than 1,000 sites nationwide, and a host of popular mobile phone apps stream live data on air pollution levels on an hourly basis. Acknowledging the problem has been a big step forward, but addressing it without damaging economic growth presents a major headache. Beijing’s geography means that its air quality can be particularly bad. Pollution from factories, farms and homes right across the vast and fertile North China Plain – the country’s traditional economic heart – is trapped by southerly winds against the mountains that surround the city to the north and west. Pollutants pool over the region, combining to form a haze that extends over hundreds of kilometres, appearing in satellite images as a murky blanket hiding the ground.  The Chinese government, keen to present the city’s best face to the world, imposed strict air pollution controls during the summer Olympics in 2008, for the APEC forum last autumn, and most recently for a military parade to mark the end of World War II. On each occasion the haze vanished – a clear demonstration of what can be achieved.  But the long-term changes needed to make this blue sky an everyday occurrence require greater effort. Plans are underway to relocate polluting industries, move to cleaner energy generation and tighten enforcement of environmental regulations.  Beijing steelworks was moved out of the city into neighbouring Hebei province before the Olympics; now other manufacturing industries are following suit. New, cleaner and more efficient facilities will reduce the sources of pollution and shift them downwind of the city. However, with a population of more than 100m and producing a quarter of China’s steel, Hebei already has major air pollution challenges of its own – and its pollution controls are less strict than in the capital. A shift in power generation from coal to gas is also underway, bringing benefits for climate as well as air quality. China currently leads the world in renewable energy production, with its huge investments in solar, wind and hydropower. These make up only 10% of the country’s energy needs, but are expected to rise to 16% by 2020. These large infrastructure changes are the key to controlling and reducing air pollution, but residential and agricultural sources must now be addressed, too, to bring the blue sky back.  However, the balance between economic development and environmental protection is starting to shift, much as it did in the West half a century ago. The new policies now being put in place will put China on a cleaner trajectory than the one assumed in the new Nature study.  The authors of the study are right to highlight the human costs of air pollution, and to warn of the future dangers of “business as usual” development. But in China now there is a new desire for clearer air that will put the nation on a different path – and reduce the heavy toll of air pollution-related deaths."
nan
"
Share this...FacebookTwitterThe peer-reviewed scientific literature robustly affirms that land-falling hurricane frequencies and intensities have remained steady or declined in recent decades.  So have droughts, floods, and other extreme weather events.  But the editorial board of The Washington Post spurns this scientific evidence and inexplicably blames politicians and “those who deny” climate change for landfalling hurricanes and the associated damage. 
Image Source: The Washington Post 11/09/2018
It is well documented in the scientific literature that a cooler climate is associated with more weather extremes and hurricane activity, whereas a warmer climate leads to a reduction in weather extremes and hurricane activity.

“Recent review papers reported that many high-resolution global climate models consistently projected a reduction of global tropical cyclone (TC) frequency in a future warmer climate.“ (Sugi et al., 2015)
“Our work illustrates a major constraint on the large-scale global atmospheric engine: As the climate warms, the system may be unable to increase its total entropy production enough to offset the moistening inefficiencies associated with phase transitions. This suggests thatin a future climate, the global atmospheric circulation might comprise highly energetic storms due to explosive latent heat release, but in such a case, the constraint on work output identified here will result in fewer numbers of such [highly energetic storm] events. … On a warming Earth, the increase in perceptible water has been identified as a reason for the tropical overturning to slow down,  and studies over a wide range of climates suggest that global atmospheric motions are reduced in extremely warm climates.“  (Laliberté et al., 2015)
“Extratropical cyclones cause much of the high impact weather over the mid-latitudes. With increasing greenhouse gases, enhanced high-latitude warming will lead to weaker cyclone activity. Here we show that between 1979 and 2014, the number of strong cyclones in Northern Hemisphere in summer has decreased at a rate of 4% per decade, with even larger decrease found near northeastern North America.” (Chang et al., 2016)
“The impact of climate change is seen in slightly decreased intensities in landfalling cyclones.” (Perrie et al., 2010)

The Washington Post editorial board has apparently decided that contrarian scientific evidence is subservient to their political aims.
This way they can justify blaming out-of-favor politicians and those who “deny” climate change for the devastating consequences of an impending landfalling hurricane.
Below are several scientific papers published within the last year that do not seem to support the Post’s angle that says we can reduce hurricane landfall frequencies if only we can agree to believe, rather than deny, that humans are responsible.

“Downward Trend Since 1950” In Landfalling Hurricane Frequency/Intensity

Truchelut and Staeling, 2018 
“The extremely active 2017 Atlantic hurricane season concluded an extended period of quiescent continental United States tropical cyclone landfall activity that began in 2006, commonly referred to as the landfall drought. We introduce an extended climatology of U.S. tropical cyclone activity based on accumulated cyclone energy (ACE) and use this data set to investigate variability and trends in landfall activity. The [hurricane landfall] drought years between 2006 and 2016 recorded an average value of total annual ACE [accumulated cyclone energy] over the U.S. that was less than 60% of the 1900–2017 average.”
“Scaling this landfall activity metric by basin-wide activity reveals a statistically significant downward trend since 1950, with the percentage of total Atlantic ACE expended over the continental U.S. at a series minimum during the recent drought period.”

Klotzbach et al., 2018
“Continental United States (CONUS) hurricane-related inflation-adjusted damage has increased significantly since 1900. However, since 1900 neither observed CONUS [Continental United States] landfalling hurricane frequency nor intensity show significant trends, including the devastating 2017 season.”


Zhang et al., 2018     
“Over the 1997–2014 period, the mean frequency of western North Pacific (WNP) tropical cyclones (TCs) was markedly lower (~18%) than the period 1980–1996. Here we show that these changes were driven by an intensification of the vertical wind shear in the southeastern/eastern WNP tied to the changes in the Walker circulation, which arose primarily in response to the enhanced sea surface temperature (SST) warming in the North Atlantic, while the SST anomalies associated with the negative phase of the Pacific Decadal Oscillation in the tropical Pacific and the anthropogenic forcing play only secondary roles.”

Zhao et al., 2018
“A vigorous debate has currently focused on the relationship between increasing TC [tropical cyclone] activity and increasing SST [sea surface temperatures] (Knutson et al. 2010). … [O]ver the WNP [Western North Pacific] basin,a significant decrease of TCF [tropical cyclone frequency] has been observed since 1998 (Liu and Chan 2013; Lin and Chan 2015; Zhao and Wang 2016). Global TCF [tropical cyclone frequency] has showed a similar reduction since the late 1990s (Maue 2011). Change of TCF over the past few decades does not appear to be consistent with changes in local SST. Observational analyses further pointed out that there is no significant correlation between the TCF [tropical cyclone frequency] and local SST [sea surface temperatures] over the WNP  [Western North Pacific] basin (Chan 2006; Yeh et al. 2010).”


Heller, 2017
“The hurricane analysis conducted by Burn and Palmer (2015) determined that hurricane activity was subdued during the [warm] Medieval Climate Anomaly (MCA) (~900-1350 CE) and became more produced during the [cold] Little Ice Age (LIA) (~1450-1850 CE), followed by a period of variability occurred between ~1850 and ~1900 before entering another subdued state during the industrial period (~1950-2000 CE). In general, the results of this study corroborate these findings.”
“[W]hile hurricane activity was greater during the LIA, it also had more frequent periods of drought compared to the MCA (Burn and Palmer 2014), suggesting that climate fluctuations were more pronounced in the LIA compared to the MCA. The changes in the diatom distribution and fluctuations in chl-a recorded in this study starting around 1350 also indicate that variations in climate have become more distinct during the LIA and from ~1850-1900. … [C]limate variability has increased following the onset of the Little Ice Age (~1450-1850 CE), however it is difficult to distinguish the impacts of recent anthropogenic climate warming on hurricane activity from those of natural Atlantic climate regimes, such as ENSO.”

Wellford et al., 2017
“Since the late 1800s, in contrast to much of the Southeastern USA, the Georgia coast has experienced infrequent hurricane landfalls, particularly in recent decades. As a result, coastal storm preparedness complacency appears to be rampant along the Georgia coastline. Both local and state governments were unprepared for shadow evacuation during Hurricane Floyd in 1999. The study described here includes an examination of temporal and spatial trends in hurricane landfall along the Georgia coast from 1750 to 2012. Since 1750, 18 of the 24 recorded hurricanes that made landfall along the Georgia coast occurred between 1801 and 1900, yet the hurricane intensities have declined since 1851.”



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




No Increasing Trend In Drought/Flood Frequency, Severity

Guo et al., 2018
“In drought-prone regions like Central Asia, drought monitoring studies are paramount to provide valuable information for drought risk mitigation. In this paper, the spatiotemporal drought characteristics in Central Asia are analyzed from 1966 to 2015 using the Climatic Research Unit (CRU) dataset. Central Asia showed an overall wetting trend with a switch to drying trend since 2003.”

Mangini et al., 2018
“The main objective of this paper is to detect the evidence of statistically significant flood trends across Europe using a high spatial resolution dataset. … Anticipated changes in flood frequency and magnitude due to enhanced greenhouse forcing are not generally evident at this time over large portions of the United States for several different measures of flood flows. … Thus, similarly to the main findings of Archfield et al. (2016) for the US, the picture of flood change in Europe is strongly heterogeneous and no general statements about uniform trends across the entire continent can be made.”

Zheng et al., 2018     
“For the extreme drought and flood events in total, more frequent of them occurred in the 1770s and 1790s, 1870s–1880s, 1900s–1920s and 1960s, among which the 1790s witnessed the highest frequency of extreme drought and flood events totally.”


Schedel, Jr. and Schedel, 2018    
“Flood events on the U.S. East Coast are not more severe or frequent than in the past. However, because of sea-level rise, these events are starting from a higher baseline height. Thus, the same severity of a flood event today reaches a greater absolute height than an identical flood would have reached 50 or 100 years ago.Based on current data, the good news is that the apparent worsening of flood events is due to a single, primary cause: sea level rise. Flood events are not getting stronger or occurring more frequently than in the past. They are instead starting from a higher point, allowing them to reach higher levels more often. The bad news is that sea-level rise will be a fact of life for many years into the future. Communities need to start now to make informed plans and decisions about how best to adapt.”


Valdés-Manzanilla, 2018
“This study presents a chronology of historical and measured flood events in the Papaloapan River basin of Mexico during 450 years. Twenty-eight historical floods were recorded during the period 1550–1948 [7 per century] on this river and one flood event (1969) in the instrumental era (1949–2000) [2 per century], of which 14 were extraordinary floods and only 15 were catastrophic ones. There were several flood-rich decades during 1860–1870, 1880–1890, 1920–1930 and 1940–1950. Wavelet analysis found a significant flooding periodicity of 58 years. The wavelet coherence analysis found that flooding had an in-phase relationship with the Atlantic Multidecadal Oscillation and also with the Pacific Decadal Oscillation.”

Dobrovolný et al., 2018
“The new MJJ precipitation reconstruction is restricted to inter-annual and inter-decadal variability, which is in line with our understanding of natural precipitation variability. Reconstruction reveals two long periods of low precipitation variability, in the 13th–14th centuries and 1630s–1850s. It also demonstrates that precipitation anomalies of larger amplitude and longer duration occurred in the earlier part of the last millennium than those found in the instrumental period. Negative trends in soil moisture content and gradual changes in annual precipitation distribution leading to higher extremity of precipitation regime may be responsible for the lower sensitivity of oaks to precipitation after the 1980s. The new reconstruction does not indicate any exceptional recent decline in MJJ precipitation.”


Extreme, Unstable Weather Decreases With Warming

Zou et al., 2018
“The Tibetan Plateau (TP), one of the world’s most sensitive areas to climate change, became significantly warmer during recent decades. Since 1960 (1980), storm (hail) days have been decreasing by 6.2%/decade (18.3%/decade) in the region.”
“Based on 53‐year continuous weather records at 48 TP stations and reanalysis data, we show here for the first time that the consistent decline of storm days is strongly related to a drier midtroposphere since 1960. Further analysis demonstrated that fewer hail days are driven by an elevation of the melting level (thermodynamically) and a weaker wind shear (dynamically) in a warming climate. These results imply that less storm and hail may occur over TP when climate warms.”

Zhang et al., 2017
“Based on continuous and coherent severe weather reports from over 500 manned stations, for the first time, this study shows a significant decreasing trend in severe weather occurrence across China during the past five decades. The total number of severe weather days that have either thunderstorm, hail and/or damaging wind decrease about 50% from 1961 to 2010. It is further shown that the reduction in severe weather occurrences correlates strongly with the weakening of East Asian summer monsoon which is the primary source of moisture and dynamic forcing conducive for warm-season severe weather over China.”

Chen et al., 2017
“Results indicate that the midlatitude summer cyclone activity over East Asia exhibits decadal changes in the period of 1979–2013 and is significantly weakened after early 1990s. …  Moreover, there is a close linkage between the weakening of cyclonic activity after the early 1990s and the nonuniform surface warming of the Eurasian continent.”
“Significant warming to the west of Mongolia tends to weaken the north–south temperature gradient and the atmospheric baroclinicity to its south and eventually can lead to weakening of the midlatitude cyclone activity over East Asia.”
Share this...FacebookTwitter "
"
Share this...FacebookTwitterMy daughter will be visiting Wilmington next week, and so Hurricane Florence has been very much on my mind.
Days ago, almost all weather models showed the cyclone curving out into the North Atlantic and going nowhere, but they’ve turned out to be wrong.
Bastardi saw it a week ago
Already a week ago veteran meteorologist Joe Bastardi got into the act, and his hunch did not quite agree with the models. On September 1st he brought up the real possibility of Florence missing the turn to the north, and instead heading out to the US east coast. What follows is the chart Joe used on his September 2 Daily Update:

On September 2nd, Joe Bastardi warned Florence could head to the US east coast. Chart: Weatherbell.
Today we already know that Joe’s forecast of Gordon was accurate, and now we are seeing that his hunch of Florence missing the turn to the north was right on.
On his Daily Update of Wednesday, September 5, it was becoming clear Florence had little intention of turning northward as Joe’s chart tells us:

By September 5 Joe had already sniffed out the likely general track. – more than a week before Florence is forecast to strike the east coast. Chart: Weatherbell. 
A day later at his Daily Update, on Thursday (September 6), ahead of everyone else, Joe showed Florence generating into a monster Category 4 storm and on a possible path to the Carolinas:

Chart: Weatherbell
Models can’t handle longer term forecasting – analogs needed
How does he do it? The veteran meteorologist not only uses models to make his forecasts, but relies heavily on analogs, i.e. similar recorded patterns having frequently occurred in the past. It’s happened before, and similar events can happen again.
His method often allows him to be days ahead of the purely mathematical models used by leading weather agencies, who find themselves constantly correcting them with every run. So today we wait with suspense to see Joe’s latest news on Florence’s projected track.
Models not in agreement
Though the latest forecasts from the different models are just about unanimous on Florence plowing into US coast (with still a small chance of curving out northward before reaching land) they are still in disagreement where the hurricane will strike the coast.
GFS model
Dr. Ryan Maue at Twitter informs the US GFS model has Florence landfalling on the coast of NORTH CAROLINA:

No change from the GFS model for #Florence … still a major hurricane landfall somewhere in the Carolinas by Thursday next week.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Since the track is curved, a small deviation or change in forward speed could yield a different landfall point or even a miss offshore. pic.twitter.com/1ImFP9UUuW
— Ryan Maue | weathermodels.com (@RyanMaue) September 8, 2018

UKMET model
Ben Noll at Twitter reports that the latest UKMet model run shows Florence going much further south, making landfall near the Florida-Georgia border!
European model
Meanwhile this morning Swiss meteorologist Jörg Kachelmann points out that the European model has Florence aiming between the GFS and UKMet models. Again the models are purely mathematical computations and do not directly take analogues into consideration like Joe Bastardi does.
Also see Ben Noll’s recent tweet here.
So follow Joe Bastardi’s daily updates at Weatherbell for the latest refined projections. Joe often sides with the European model.
Keep in mind, as every meteorologist knows, weather is highly unpredictable, and so surprises can never be excluded.
Here come the climate ambulance chasers!
One thing is certain: the global warming ambulance chasers and fake CNN-type media will be making all sorts of hysterical claims once Florence hits the coast. Naturally, despite all their climate “expertise”, none of these climate doomsday prophesiers ever had a clue about what track Florence would follow days ago.
Yet they’ll be the first (after the fact) to claim they predicted this sort of thing all along, and blame it on manmade climate change. The reality is that hurricanes have been trending downward over the past 50 years.
Media will blare Florence’s unusual track “unprecedented!”
What’s interesting about Florence is its relatively high latitude start position. As Dr. Philip Klotzback mentioned at Twitter, in the past no hurricane at Florence’s position ever managed to make it to the US east coast. All of them have turned away and disappeared somewhere in the Atlantic:

33 named storms (since 1851) have been within 100 miles of #Florence's current position.  None of these storms made US landfall.  The closest approach was #Hurricane George (1950) – the highlighted track.  However, Florence does not appear to be taking a climatological track. pic.twitter.com/4x02pasgPg
— Philip Klotzbach (@philklotzbach) September 7, 2018

Get ready for insane climate headlines
But Florence has managed to find its own track to the US east coast. So expect the global warming ambulance chasing scientists to call it “UNPRECEDENTED!” and say it must be because of human emissions of CO2! The media will accept it as Gospel Truth and go crazy with hysterical headlines. The USA Today here has already begun using the “unprecedented” label.
So what would Joe Bastardi, the person who was first to forecast the event, say about it? Joe will tell you it’s all natural, and not because of humans emitting some CO2 into the air.
Share this...FacebookTwitter "
"Have you heard the one about Jeremy Corbyn’s plans to renationalise the energy system? In an interview with Greenpeace, the Labour MP and leadership candidate said: “I would personally wish that the Big Six were under public ownership, or public control in some form.”  It would be easy to take this quote out of context, add up the market value of the Big Six and suggest the Corbyn campaign wants to spend £124 billion renationalising the utilities. Yet, in the next breath however Corbyn added: “But I don’t want to take into public ownership every last local facility because it’s just not efficient and it wouldn’t be a very good way of running things.” So what does the Corbyn camp suggest instead? The only clear evidence is in his Protecting Our Planet manifesto, which sets out ten energy pledges and details some key policies.  It’s no aggressive nationalisation plan. What it is, is a manifesto for a more decentralised and democratically accountable system, inspired more by present-day Germany than 1980s Britain.  So does Corbyn’s energy policy look like a throwback or a revolution? There are four reasons to suspect the latter. “Competition” in the UK energy market has left consumers bamboozled and overcharged. Our choices are like a shopping mall food court: you can have anything you like, as long as it’s fast food. The energy market is similar, most suppliers are operating the same big utility model with the same options; you can have anything you like, so long as it’s a national tariff from a large private utility.  Corbyn’s manifesto cites Germany, which allows consumers the option to buy energy from municipal utilities or co-operatives. Some new consumer options are being seen in the UK. Smarter ways of buying green energy are appearing, and Nottingham City Council has set up its own energy company with a name that sends a clear message: Robin Hood Energy.  But while it’s easy enough to build a wind turbine these days – or even a whole wind farm – it’s significantly harder for innovative new businesses to actually join the market. Corbyn’s manifesto commitment to growing municipal and co-operative models would mean consumers face more meaningful choices. The manifesto pledges to create a “route-map into tomorrow’s ‘smart energy’ systems” to “use smart technologies to run localised storage, balancing and distribution mechanisms” and allow customers the “right to have first use of the energy they generate themselves”. But why isn’t this happening already?  It’s useful to think of our electricity system as being like a big swimming pool. Everyone’s electricity has to go into this big pool and a vast amount of market regulation is needed to make sure the pool stays “balanced” at the right level, with all the buying and trading and using of power going on underneath the surface. This means small-scale solutions to generating and using power locally are extremely difficult to set up, as they all incur the costs of trading in the big pool. To stretch the metaphor, this means little fish have to swim in a big pond.  Such a setup creates barriers to innovation and is holding back new technologies. There is no technical reason why you shouldn’t be able to choose to buy energy from local sources these days – what stands in the way is the requirement that everyone has to swim in the big pool first. By creating local energy markets, smaller but still viable businesses can flourish. The manifesto commits to pursue energy investment through a National Investment Bank. While this model has seen success in Germany, what is less well understood is how important citizen banks have been in deploying this investment.  The UK doesn’t have a citizen banking sector like Germany. This means you can only invest in renewables by either buying shares in a green energy company or investing in a co-operative. However, new models are emerging. Abundance Generation, an online crowdsourcing platform, allows investors to participate in renewable energy schemes for as little as £5, and a German-style local bank is being developed in Hampshire.  While Corbyn’s manifesto sees the benefit of establishing a state investment bank to invest in the energy transition, it will be important to deliver this investment through the right institutions at the right level so citizen investment can complement state finance. Throughout, the manifesto argues for more citizen influence over the energy system – and not just through supposed consumer “choice”.  It is not only the German system that can be drawn on to change this. Energy decision-making can be brought closer to citizens by, for instance, looking at public value energy governance which draws on Danish and North American examples, direct action to take back ownership of key infrastructure, or reframing energy as a public good.  It is clear from the manifesto that the energy policies of the Corbyn camp are anything but a throwback to monolithic state utilities. There is potential for more competition through more diverse energy business models, a clear willingness to make space for smart energy innovation, a call for different approaches to energy system finance, and a platform for more plural approaches to energy governance. Whether or not people agree with these proposals, it should be clear that they are not “old solutions to old problems”, but provocative responses to increasingly urgent challenges."
"Images of distressed, caged puppies on their way to be slaughtered at Yulin dog meat festival in China have caused outrage around the world. Angry Facebook posts, tweets and online petitions supported by the likes of Ricky Gervais and Simon Cowell direct us to gruesome photos of dead dogs, skinned and boiled and hung up on butchers hooks. I too find myself heartbroken by these images. But as a vegan I find myself wondering why isn’t there more outrage in the world over the slaughter of other animals. For instance, each year in the US roughly 110m pigs are killed for meat. Where is the same public outcry over bacon? The simple answer is emotional prejudice. We just don’t care enough about pigs for their needless suffering to pull at our heartstrings. As Melanie Joy, social psychologist and expert on “carnism” points out, we love dogs, yet we eat pigs, and there are simply no good moral reasons for such hypocrisy. One popular argument is that we should care more about dogs because of their superior social intelligence. This twitter user is typical: However this belief really just reflects the fact that people spend more time getting to know dogs than pigs. Many people have dogs as pets and through this relationship with dogs we’ve come to learn about them and care deeply for them. But are dogs really that different from other animals we eat? Though obviously not identical, dogs and pigs are quite similar in all the features that seem to count morally to most people. They have similar social intelligence with rich emotional lives, both can use human-given cues to locate objects, both might be able to use a mirror to locate objects (though research suggests pigs might have an advantage here) and, of course, both animals have a deep capacity to suffer and a desire to avoid pain. So whether you believe, like the philosopher Peter Singer, that sentience should be the basis of our assigning moral value to an agent, or you believe, like Peter Carruthers, that higher intelligence or the capacity to act according to moral principles should be the basis, then dogs and pigs seem to be on equal footing. Yet where are the global protests on behalf of pigs? As a psychologist who studies the way people think morally, I am sobered (and saddened) by the cold truth that people are often blind to the inconsistencies in their thinking, particularly when animals are involved. Andrew Rowan, director of the Center for Animals and Public Policy at Tufts University, once observed that: “the only consistency in the way humans think about animals is inconsistency”. His statement is increasingly being backed up by new psychology research.  For one, people allow the wrong factors to influence their judgements of an animal’s moral standing. People often think with their heart rather than their head. For example, in one recent study conducted by my lab (not yet published) we presented people with images of farm animals and had them decide how wrong it would be to harm them. Unknown to participants, however, they were either presented baby animals (baby chicks, for example) or adult animals (fully-grown chickens).  By a large margin people said it would be more wrong to harm the baby animals than the adult animals. And why? Additional measures showed it was because baby animals are cute and evoke feelings of warmth and tenderness in people, while adult animals do not. The intelligence of the animal had nothing to do with the moral value that was assigned. While these results may not be terribly surprising, they do highlight a problem with our moral hardware. Our morals seem to be guided in this case by involuntary emotions rather than careful reasoning. Second, we are inconsistent in our use of “facts”. We tend to think the evidence is always on our side – what psychologists call myside bias. In one study I simply had people rate their level of agreement or disagreement about a number of potential benefits of going vegetarian. The benefits ranged from environmental benefits to animal welfare, health, and financial benefits. I thought people would be divided about the benefits of going vegetarian, endorsing some of the arguments but not all of them. This is not at all what I found. People did not simply endorse one or two benefits; they either endorsed all or none of them. In other words, people recruited all of the arguments that supported their foregone conclusions about eating meat or going vegetarian. Thirdly, we are quite flexible in our use of information about animals. Rather than thinking carefully about the issues or the facts, we tend to endorse evidence that supports our desired views. In another recent study not yet published, carried out with Steve Loughnan from the University of Edinburgh, we had people tell us how wrong it was to eat one of three different animals. One animal was a fictitious, alien animal they had never encountered before; a second was a tapir, a strange animal that is not used for food in their culture; finally, there was a pig. All participants received the same information about the animal’s intelligence and cognitive capacities, but people only thought it was wrong to kill the alien and the tapir for food. For the pig, participants ignored the intelligence information when making their moral judgement. It is normal that we eat pigs – and this seemed to be sufficient to lower pigs’ moral value, despite their equal intelligence. Thus, while the vegan inside me is puzzled to see people get upset about the use of dogs as food yet not think twice about chowing down on a pork chop, my inner psychologist is not at all surprised. Our moral psychologies are good at finding fault, but not when the spotlight is turned toward our own practices and preferences."
"
Share this...FacebookTwitterIn two new papers, scientists affirm a strong connection between solar activity and the Earth’s climate, as temperatures are said to be 3 times more sensitive to solar forcing than CO2 forcing.  
With the advent of  a grand minimum in the coming decades, a consequent “dampening” of temperatures (and slowing of sea level rise) is expected.  
Between 2000 and 2100, surface temperatures are only expected to warm by a total of about 1.1°C, a climate change that may ultimately be beneficial.  

McCrann et al., 2018
“The effect of the Sun’s activity on Earth’s climate has been identified since the 1800s.  However, there are still many unknowns regarding the mechanisms connecting the Earth’s climate to the variation in solar irradiance. Climate modelling that implements the solar sciences is a novel approach that accounts for the considerable effect that natural factors have on the climate, especially at regional level. This paper discusses the noticeable effect that planet oscillations have on the Sun’s activity, which gives a very good correlation with the observed patterns in global surface temperatures, rainfall records and sea levels.”
“A clear 60-year cycle has been identified in many studies, and in accordance with this, it is expected that temperatures will reach a trough of the cycle around 2030-2040. This is in agreement with the forecasted low sunspot activity that is usually linked to lower temperatures.”
“Furthermore, considering the influence of the Solar Inertial Motion, a solar slowdown is predicted for Solar Cycles 24 and 25, which will create a weak grand minimum. It is anticipated that this weak grand minimum will be reflected in a dampening effect of global temperatures, and a subsequent moderation in the rate of sea level rise.”

Booth, 2018
“The TCR [transient climate response] to doubled CO2 is less than 2K (1.93 ± 0.26K).  Only 1.1 K of HadCRUT4 warming is expected between 2000 and 2100AD.  ∼35% of the warming during 1980–2001 was from solar variability, by 2 different analyses.”
“Temperature is nearly 3 times as sensitive to solar radiation as to CO2 radiation.  A model for ocean warming estimates equilibrium sensitivity as 15% greater than TCR [transient climate sensitivity].”
Share this...FacebookTwitter "
"For years, scientists and environmentalists have debated the best ways to conserve and protect natural resources from pollution and over-exploitation.  In the late 19th century, conservation advocates with the help of President Roosevelt succeeded in making Yellowstone the first US national park. Yellowstone’s status sent a strong message against unregulated commercial extraction and the model has since been replicated worldwide. However, the strict exclusionary nature of national parks was extremely burdensome for local and indigenous peoples who remained reliant on natural resources within protected areas.  The policy of “fortress conservation” was intended to give way in the late 20th century to a host of more sustainable alternatives, announced at the first Earth Summit in Rio in 1992. Conservation and development would be better integrated, and rural poverty addressed by bringing the poor into a global marketplace, while simultaneously delivering the market deep into the rainforests. Since Rio, market-based conservation has gained a lot of traction, and almost all forms of nature have been commodified. Packaged into sleek financialised terminology such as carbon credits, ecosystem services or species banking, the market has become such a supposed panacea for conservation that selling nature has become, for many, the only method of conserving it. Yet a cautionary tale of bioprospecting challenges the dominant and countervailing logic that if conservation were somehow made profitable, nature could begin to pay for its own survival.  Bioprospecting is the process of turning indigenous medicinal knowledge and nature into commercial drugs. Its advocates say it would provide the motivation and more importantly financing for conservation in the world’s biodiversity hotspots. Why chop down the Amazon if the forest might contain all kinds of useful and valuable drugs? The drug discovery example planted in the public’s imagination the iconic image of the “‘barefoot doctor’ seeking to find the medicinal cure to humanity’s ills under the canopy of the rainforests”. But with little to show in terms of any new blockbuster drugs or significant biodiversity saved, we are left to ask why the market has thus far been so underwhelming at achieving its conservation goals? Capitalism has never really been compatible with conservation. It encourages concentration of resources in already wealthier areas, while the urgent need to protect certain species or habitats is rarely reflected in market prices which are driven by desires to turn a quick buck. For example, drug discovery takes place in large high-tech research laboratories far removed from biodiversity-rich source countries targeted for conservation.  It takes more than 15 years and hundreds of millions in research and development costs to bring drugs to market – investment costs too big for low-income counties and local communities to even conceive of, never mind getting involved in, in any meaningful way.  For conservation to be effective, there needs to be an understanding of the benefits and the burdens of bioprospecting participation for all parties involved.  Burdens include the displacement and loss of access for locals due to new conservation enclosures – sometimes involving violence – and the potential misappropriation of nature and knowledge, what critics refer to as “biopiracy”. Many of these issues have a serious effect on any local “buy-in” to conservation programmes, and indigenous people rarely see the value of nature in terms of individual market exchange. Bioprospecting has come a long way in addressing some of these issues. The 2010 Nagoya Protocol, signed by 63 countries and the EU, set up access and benefit sharing mechanisms for the world’s genetic resources.  But right as bioprospecting seemed to be working out many of its problems, large pharmaceutical companies started closing their natural products divisions and moved on to the next big thing: chemically-derived computer generated molecules, known as combichem – a portmanteau of combinatorial chemistry. As with many market conservation initiatives, this was a fix; the fluidity of the market left the rural poor with little hope of a potential windfall of conservation benefits in their hands. For conservation thinking to move forward it needs to take into account some very important and complex issues concerning markets.  As much as we would like to believe that we have moved beyond the Malthusian belief that overpopulation and local level mismanagement leads to environmental degradation and scarcity, the spectre of too many people in the world continues to cast a “dark shadow” across our current conservation policy. This naturalisation of environmental problems fails to take into account many of the real drivers of global environmental change, such as the marginalisation of rural resource users due to poorly planned conservation policies, complicit elites, consumption by the global north and large scale extraction by multinationals. Paradoxically, many of these same industries have now become the saviours for today’s market conservation. No one has all the answers to conservation’s complex challenges, and rarely if ever are we going to find a perfect solution. But we can find the optimal solution. It is astonishing that so many critical social and natural scientists, many of whom have devoted their lives to challenging the dominant narratives of conventional thinking, have become champions for market conservation. We can do better."
"Life on Earth is entering the greatest mass extinction since the death of the dinosaurs, according to a major new study – and humans may be among the casualties. Such a catastrophic loss of species would leave a huge hole in the world’s ecosystems, and all sorts of weird and wonderful life would evolve into the vacancies left behind. To consider what life after a mass extinction might involve, we can look to the past. There have been five major mass extinctions in Earth’s history – though colleagues and I recently proposed a sixth – and comparing current rates of change to the geological record of the “Big Five” extinctions suggests that this time the warning signs are real.  So let’s be pessimistic, and assume the apocalypse is going to happen. What does Earth look like afterwards? The Permian-Triassic boundary (251m years ago) saw the greatest crisis in Earth’s history, when at least 90% of species died off. Even insects suffered huge losses – the only mass extinction in their long history. The event is widely attributed to the effects of the Siberian Traps – huge volcanic outpourings of lava and associated greenhouse gases, in what is now northern Russia. This lead to global warming, ocean acidification and acid rain, marine oxygen depletion and poisoning by toxic metals such as mercury. Imagine today’s gloomiest climate predictions, but cranked up a few notches. The few species that survived gave rise to all life thereafter and there has not been such a profound restructuring of ecosystems since, perhaps because this “survival of the fittest” rendered their descendants more tolerant to global change.  What did the planet look like in the Early Triassic? It was hot – hot as hell – and seemingly lifeless over vast areas. Sea-surface temperatures reached up to 45°C in the tropics. In the vast Pangaean desert it was probably even hotter. The heat caused land animals, marine reptiles and fish to disappear from the fossil record in all but the high latitudes, which were presumably a little cooler, for millions of years. In fact, there are several “gaps” in the Early Triassic.  The bulk of the world’s coal today derives from vast swathes of the Permian seed fern Glossopteris – a prominent casualty, whose loss led to a “coal gap” of at least 12m years.  A series of Early Triassic “fungal spikes”, where rocks contain greatly enhanced numbers of spores, has been attributed to huge amounts of dead plant and animal matter available for fungi to feed upon. The heat, and acid rain-induced destruction of soils (which would have smelled of vanilla), must have rendered the planet largely uninhabitable.  Without plants there are no plant-eaters. Without herbivores there were no carnivores. One of the few “big” survivors on land was the “shovel lizard” Lystrosaurus, an odd-looking vegetarian which, in the absence of predators and competitors, diversified with some success during the Triassic.  The carnage was worse in the oceans, where up to 96% of species went extinct. The loss of all reef-building corals led to a 10m year Early Triassic “reef gap”. Think of it: a world without reefs – and without all the diverse and abundant life they support.  But Earth wasn’t quite lifeless – and as well as Lystrosaurus there were marine success stories amid the horror. Claraia was an opportunistic genus of scallop-like bivalve that survived the end-Permian, and then quickly diversified to fill the vacant niches left by the almost total annihilation of the dominant Permian sea-floor dwellers, the brachiopods. Claraia was tough and could withstand very low oxygen levels – a trait that came in very handy when most sea-bed life was being starved of oxygen.  Perhaps the most famous and eye-catching extinction saw the death of the (non-avian) dinosaurs around 66m years ago at the Cretaceous-Tertiary boundary. As well as picture-postcard victims such as T. rex, the turnover in tiny plankton at the other end of the food chain saw an end to the formation of the famous Cretaceous chalk cliffs that are so widespread across Europe (the period’s name comes from the German “kreide”, meaning chalk).  Whether it was a meteorite, more massive volcanic eruptions, or a bit of both that did the damage, in comparison to the Permian-Triassic scenario, the death of the dinosaurs was more modest (around 75% of global species lost) and the recovery was more rapid. Either Earth sorted itself out more quickly, or, following the “Great Dying” 185m years previously, life had become better at adapting to, and evolving with, stress.  Of course, dinosaurs are not exactly extinct. Birds are highly evolved dinosaurs that derive from the few dinosaurian survivors of the Cretaceous-Tertiary (K-T) event and nobody can deny their evolutionary success in the 66m years since the demise of the chicken-like T. rex. Crocodiles and alligators – the closest living relatives of birds – are among the other prominent survivors. While it’s clear that birds’ ability to fly to oases of calm and plenty allowed them to flourish amid the upheaval of the K-T boundary, it is not obvious why crocodilians survived. Theories suggest their cold-blooded bodies (vs. the supposed warm-blooded theropod dinosaurs), their fresh or brackish water habitat or even their high IQ enabled them to flourish. The good news amid all this death and destruction is that life on Earth always recovers, even when it has been really badly damaged. Without extinction, there is no evolution – the two are intrinsically linked.  The earliest dinosaurs evolved 20m years after the Permian-Triassic losses. Their evolution was almost certainly driven by a freshening of climate during the “Carnian Pluvial Event” (when it rained, a lot), new-found lush vegetation and the swathes of ecospace available to colonise.  Dinosaurs lived for 165m years before their demise, but without their death, humans probably wouldn’t be here today to do their damage. Mammals, of course, were the great beneficiaries of the dinosaurs’ downfall.  If humans are indeed doomed then we won’t be around to see what evolves to replace us. But rest assured, we geologists don’t take ourselves too seriously – we know that Earth is bigger than us, and it will bounce back."
"The G7 leaders have pledged to wean their economies off fossil fuels by the end of the century, as part of a series of commitments in the joint post-summit communique. It’s the first significant climate pledge since the new Conservative government came to power – and it might prove an important indicator of things to come.  After energy and climate change were barely mentioned in the recent election campaign, the G7 represents the first of a series of events which will force the government to reveal its hand. Climate policy may even define UK Prime Minister David Cameron’s legacy on the international stage. The Conservative manifesto provides some indication of the party’s likely policies: competition to keep energy bills low, securing energy supplies, limiting onshore wind farms, a commitment to meeting the UK’s climate change targets and support for the Climate Change Act. But as yet we know very few details. This risks leaving a vacuum which could be filled by untruth or misrepresentation. Scientists are having trouble convincing the public about climate science – polling released in early 2015 showed most people in the UK believed the climate was changing but just 18% were “very concerned”. This raises the important question of which camp our political leaders belong to. Cameron and his new energy and climate change secretary, Amber Rudd, must listen to scientists.  The science is clear on this – climate change is a real phenomenon caused principally by the increasing level of the greenhouse gas, CO2, in the atmosphere. The IPCC states human influence is the “dominant cause” of recent warming.  But the science doesn’t automatically filter through to politicians. The most recent IPCC report is a good example of this. The report included a 30-page “Summary for Policymakers”, which was the subject of intense debate in Copenhagen, with scientists and politicians editing and redrafting the main points. Somewhere in the edit, the scientific findings about the failure of the 1997 Kyoto protocol were chopped down to a pithy bullet point stating that it “offers lessons”. Perhaps our politicians would wish to believe they had achieved more than the scientific data suggested. Now the G7 is out of the way, the UK won’t have to wait long to show further international leadership and make a substantive and lasting impact on climate change. In December 2015 the world’s leaders will meet in Paris to negotiate an agreement to replace the Kyoto protocol on greenhouse gas emissions. Paris can correct some of Kyoto’s omissions. The US never ratified Kyoto, and China was exempted in 1997 as it was then classified as a developing country. How things have changed – China is now the largest emitter of greenhouse gases. There are promising signs. Rudd has in the past spoken out in support of the IPCC’s work – and Greenpeace described her appointment as a “hopeful sign” that the government remains committed to addressing climate change. Closer to home, Rudd will also have to respond to any recommendations from the Competition and Markets’ Authority antitrust probe into the power market and the “Big Six” energy companies. This is likely to occupy a lot of her time. But while it is essential that the UK energy market is fair, transparent and affords all people equitable access to energy, there are bigger concerns on a world stage which need addressing if we are to achieve the 2°C temperature rise target that for many scientists is a “red line”. I hope we might see the UK leading the debate in this area and making a real difference.  Cameron has said this will be his last term as prime minister – and if he wants a truly global legacy there’s always Paris. The UK’s scientists wish him and Rudd every success in this area. All our futures depend on it."
"If only Scott Morrison was as willing to spend money preventing climate change as he is to spend it on disaster repair. The idea that a “stitch in time saves nine” and “an ounce of prevention is worth a pound of cure” was once central to the conservative approach to politics and economics. But while deterrence still lies at the heart of Australia’s $38.7bn defence budget, when it comes to climate change, Australian conservatives opt for suck it and see. Of course, this radical approach to ignoring risk is neither “conservative” nor widely practised around the world. As the climate science denier and Liberal party MP Craig Kelly found out when interviewed by a British conservative, Piers Morgan, the bizarre arguments that rightwing commentators spew out in Australia just don’t cut the mustard in the old country. It seems that while every rightwing commentator knows that the best way to fight a bushfire is to prevent it, when it comes to the climate crisis the same idea appals them. Hazard reduction burning before the bushfire season costs money. It causes smoke, inconvenience and it sometimes gets out of control – causing the very bushfires it seeks to prevent. Those costs don’t make hazard reduction burning a bad idea, they just prove that conservatives are more than happy to spend money upfront to avoid bigger costs down the track. Except when it comes to investing in renewable energy. How depressing it must be for Australian conservatives to hear statements from the royal family warning that Australia is contributing to a global “ecocide”. But, if the right to be monarch (and Australia’s head of state) is so-called God-given, does that mean God isn’t talking to our future kings and queens any more? Doesn’t Scott Morrison talk to God too? And doesn’t the Pope think we should take urgent action to burn fewer fossil fuels? It’s confusions like these that, back in the 1700s, gave science a good name. Just as a fish can’t tell you how the water is, most Australians seem unaware just how detached from reality our debate about the climate emergency is. As the graph below shows, most of the richest economies in the world have managed to significantly reduce their greenhouse gas emissions. Many grow their economies at the same time. Yet in Australia we have been told that reducing emissions and reducing jobs are one and the same thing. The bushfires that have ravaged Australia for the last month, and are likely to burn for at least a month more, haven’t just burned up our forests. They have burned up the last shreds of the curtain that Australia’s climate deniers hide their wilful ignorance behind. Scott Morrison’s claim that Australia is “meeting and beating” our emissions reduction targets is as misleading as it is meaningless. Leaving aside the fact that Australia is relying on accounting tricks to meet our Paris targets and to cover up our rising emissions, even if Australia was “on track”, that track still leads us to a world that is at least 3C warmer than it was 100 years ago. Australia is now experiencing the early symptoms of what climate change looks like. While conservatives have trolled the public debate, saying “there is no climate emergency” and that “CO2 is plant food”, Australians have now had their first clear look at what an “extreme weather event” is. This summer’s fires were so fierce they made their own lightning, which started new fires. This summer’s fires were so intense they created a wind storm that flipped over ten-tonne firetrucks and killed a firefighter. This summer’s fires were so vast that we have no chance of extinguishing them all. They will burn for at least another month unless heavy rains show. Those commentators who, for years, have obsessed about the “costs” of avoiding climate change while telling their audiences about the benefits of a heating planet, will probably never hang their heads in shame. But perhaps the news outlets that provide a platform for their dangerous denialism will. Or, perhaps not. There is nothing in our constitution that says for-profit companies must act responsibly or in the interests of their readers. And most Australians with an instinctive support for free speech and freedom of the press are willing to accept that it’s hard to regulate against fake news. But it is no coincidence that the same voices who once denied climate change, and then denied that climate change is caused by fossil fuels, are now the ones declaring that climate change doesn’t make bushfires more frequent or more ferocious. And it is no coincidence that the prime minister is far happier to fund disaster repair than he is to invest in disaster avoidance. Just as the climate-denying commentators burned up their credibility when they focused on the “upside” of climate change, the Coalition burned up its policy credibility when they ripped up the carbon price. There was a brief moment after the last election when the prime minister and some in the press gallery thought climate policy could be put on the backburner. But reality bites. Hard. The people who told us that the quiet Australians weren’t that worried about climate change, and that December’s fires were a “state issue”, are now in charge of developing a national plan to repair this disaster and prevent the next ones. What could go wrong? Richard Denniss is chief economist at independent thinktank the Australia Institute, @RDNS_TAI"
"I have always wondered why our species Homo sapiens, that evolved in Africa about 200,000 years ago, seemed to do nothing special for the first 150,000 years.  Because it is not until about 50,000 years ago that the first sign of creative thinking emerged with beautiful cave paintings found in Spain, France and Indonesia.    Around the same time a new sub-species referred to as anatomically modern humans or Homo sapiens sapiens appears. Anatomically modern humans were more slender than their earlier ancestors; they had less hair, smaller skulls. They looked basically like us. But these changes weren’t just cosmetic. Two recent papers throw some light on how the revolutionary development of smaller and more fine-boned humans influenced the growth of cooperative culture, the birth of agriculture and human dominance of the planet.  The first is an analysis of the fossilised skulls of our ancestors during this transitional period, carried out by a team led by Robert Cieri at the University of Utah and published in the journal Current Anthropology.  Cieri and colleagues found the brow ridge (the bony bit above the eye sockets) became significantly less prominent and male facial shape became more similar to that of females. They referred to this as craniofacial feminisation, meaning that as Homo sapiens slimmed down their skulls became flatter and more “feminine” in shape. They think this must have been due to lower levels of testosterone, as there is a strong relationship between levels of this hormone and long faces with extended brow ridges, which we may perceive today as very “masculine” features.  People with lower levels of testosterone are less likely to be reactively or spontaneously violent, and therefore this enhanced social tolerance. This has a huge knock-on effect. As seen among humans today, we live in populations with extremely high densities with an incredible amount of social tolerance. So a reduction in reactive violence must have been an essential prerequisite for us to be able to live in larger groups and develop cooperative culture.  The idea that humans became more feminine, less aggressive and thus could cooperate in large groups is certainly very intriguing as it would have allowed individuals with different skills to be valued and be reproductively successful due to the reduction of particularly male-male violence. In most primates the physically strongest male tends to dominate, but in early humans the smartest or the most creative males may have come to the forefront. The question remains, how did we become more feminine, less violent and more creative? A second paper in the journal Animal Behaviour led by Brian Hare at Duke University may throw some light on to this.  He and colleagues compared chimpanzees (Pan troglodytes) and bonobos (Pan paniscus) in West Africa, two closely related species living in very similar environmental conditions either side of the Congo River.  One key distinction between the two species is the size difference between males and females, their “dimorphism”. Male chimps are significant larger than females, whereas the difference in bonobos is much smaller. This difference is driven by different levels of testosterone. The size is just one manifestation of deeper differences that also show up in how the animals interact with one another. Chimpanzees, particularly males are very aggressive, but violence within or between groups is almost non-existent among bonobos.  As both these species have a common ancestor there must have been strong selection going on to feminise the bonobos.   Hare and colleagues suggest a process of self-domestication whereby violent individuals are punished and prevented from reproducing.  The traits exhibited by bonobos are very similar to the changes observed in species that humans have domesticated such as dogs, cows, guinea pigs and foxes. They postulate the reason why bonobos were able to feminise and chimpanzees did not, is because on the Eastern side of the Congo where the chimps live they are in direct competition with gorillas, whereas the bonobos on the western side have no competition.  Harvard professor Richard Wrangham, a co-author of the Hare paper, suggested in a recent talk that the same process may have happened to early humans. This feminisation through self-domestication may not only have made humans more peaceful and evenly sized, but may have also produced a more sexually equal society.  A recent study in the journal Science by colleagues of mine at UCL showed that in hunter-gatherer groups in the Congo and the Philippines decisions about where to live and with whom were made equally by both genders.  Despite living in small communities, this resulted in hunter-gatherers living with a large number of individuals with whom they had no kinship ties. The authors argue this may have proved an evolutionary advantage for early human societies, as it would have fostered wider-ranging social networks, closer cooperation between unrelated individuals, a wider choice of mates, and reduced chances of inbreeding.   The frequent movement and interaction between groups also fostered the sharing of innovations, which may have helped the spread of culture. As Andrea Migliano, the leader of the study points out, “sex equality suggests a scenario where unique human traits, such as cooperation with unrelated individuals, could have emerged in our evolutionary past.” It may have only been with the rise of agriculture that an imbalance between the sexes reemerged, as individual men were suddenly able to concentrate enough resources to maintain several wives and many children.  Indeed the Robert Cieri led study does show slightly more masculine facial shapes emerging in recent agriculturalists relative to early humans and recent human foragers. So at the moment we have some tentative hints of what may have happened between 50,000 and 10,000 years ago.  Humans may have undergone self-domestication and over many generations weeded out those individuals that were unable to control their reactive violence.   This is not as far-fetched as it sounds – studies of the Gebusi tribe in Papua New Guinea by Bruce Knauft showed significant levels of male mortality due to the tribe deciding that an individual’s behaviour is so intolerable that for the good of the tribe they must be killed.   So human proactive violence – that is, thought out, discussed and planned violence – is used to curb, control and cull reactively violent individuals. This process combined with female mating choices over thousands of years could have selected for males with lower testosterone and more feminine features, which leads to a much more gender-equal society and the start of our cumulative culture."
"What makes Pope Francis and his 183-page encyclical so radical isn’t just his call to urgently tackle climate change. It’s the fact he openly and unashamedly goes against the grain of dominant social, economic and environment policies. While the Argentina-born pope is a very humble person whose vision is of a “poor church for the poor”, he seems increasingly determined to play a central role on the world stage. Untainted by the realities of government and the greed of big business, he is perhaps the only major figure who can legitimately confront the world’s economic and political elites in the way he has. However his radical message potentially puts him on a confrontation course with global powerbrokers and leaders of national governments, international institutions and multinational corporations. The backlash has begun even before the encyclical has been officially published. US presidential candidate Jeb Bush, a Catholic, feels the pope should stay out of the climate debate, joining other Republicans, fossil fuel lobbyists and climate denier think-tanks in seeking to discredit Pope Francis’s intervention. There are several meanings of the word “radical” that can be applied to the Pope and in particular his forthcoming encyclical. First, radical can be understood as going back to the roots (from Latin radix, root). The majority of Catholics live in the Global South; in Latin America and sub-Saharan Africa. Francis is the first pope from the Global South, and naming himself in honour of Saint Francis of Assisi, “a man of poverty and peace who loved nature and animals”, signalled to the world a commitment to going back to the roots of human existence. The pope knows the plight of the majority world. Before he became Archbishop of Buenos Aires, he was a priest in the vast, poor neighbourhoods, the villas miserias or slums, of Argentina’s capital. Improving the lives of slum dwellers and addressing climate change is, for Pope Francis, one and the same thing. Both require tackling the structural, root causes of inequality, injustice, poverty and environmental degradation. For example, his encyclical says:  Even as the quality of available water is constantly diminishing, in some places there is a growing tendency, despite its scarcity, to privatize this resource, turning it into a commodity subject to the laws of the market. Yet access to safe drink- able water is a basic and universal human right, since it is essential to human survival and, as such, is a condition for the exercise of other human rights. (p. 23) This stands in stark contrast to, for example, Peter Brabeck-Letmathe, the chairman of Nestlé, the world’s largest food and bottled water company, who thinks water is a normal commodity with a market value, and not a human right. Nestlé is far from unusual. Its stance is backed up by the official water privatisation policies  of the World Bank, IMF and other international institutions. In fact, the encyclical is a radical – for a pope and international leader, unprecedented – attack on the logic of the market and consumerism, which has been expanded into all spheres of life. The document states: Since the market tends to promote extreme consumerism in an effort to sell its products, people can easily get caught up in a whirlwind of needless buying and spending. Compulsive consumerism … leads people to believe that they are free as long as they have the supposed freedom to consume. But those really free are the minority who wield economic and financial power. (p. 149-150) The pope rejects market fundamentalism, instead arguing that “the market alone does not ensure human development and social inclusion.” In the same way, he warns us of the brave new world of carbon markets such as the EU Emissions Trading System  and the UN’s Clean Development Mechanism, which have been created to reduce the world’s carbon emissions. The encyclical states:  The strategy of buying and selling “carbon credits” can lead to a new form of speculation which would not help reduce the emission of polluting gases worldwide. This system seems to provide a quick and easy solution under the guise of a certain commitment to the environment, but in no way does it allow for the radical change which present circumstances require. Rather, it may simply become a ploy which permits maintaining the excessive consumption of some countries and sectors. (p. 126) The pope’s right. The same criticisms of carbon markets have been made by myself and others. Pope Francis has already angered conservative Catholics in the US by clearly stating that: Climate change is a global problem with grave implications: environmental, social, economic, political and for the distribution of goods. It represents one of the principal challenges facing humanity in our day. (p. 20) While the pope is not a politician – or maybe precisely because he is not one – he commands high moral and ethical authority that goes beyond traditional partisan lines. His encyclical speaks truth to power, and he might be the only person with both the clout and the desire to meaningfully deliver a message like this: Many of those who possess more resources and economic or political power seem mostly to be concerned with masking the problems or concealing their symptoms, simply making efforts to reduce some of the negative impacts of climate change. However, many of these symptoms indicate that such effects will continue to worsen if we continue with current models of production and consumption. There is an urgent need to develop policies so that, in the next few years, the emission of carbon dioxide and other highly polluting gases can be drastically reduced, for example, substituting for fossil fuels and developing sources of renewable energy. (p. 21) The bosses of Shell, ExxonMobil and other fossil fuel companies will not like this message, as it threatens their fundamental business model, and it also stands in contrast to the underwhelming ambitions of the G7 leaders who recently pledged to phase out fossil fuels only by 2100. The time for bold, radical action on the environment as well as poverty eradication has come. This seems to be Pope Francis’ message: “The same mindset which stands in the way of making radical decisions to reverse the trend of global warming also stands in the way of achieving the goal of eliminating poverty.” (p. 128) We need to think beyond the current, taken-for-granted logic that believes only markets and consumerism can solve the world’s social and environmental problems. The pope himself believes the situation is so grave that only a new, “true world political authority” will be able to address these problems.  This article was updated on 18 June to include quotes from the final encyclical rather than the earlier draft leaked to L'Espresso magazine."
"
Share this...FacebookTwitter
Russian Arctic in 1920-1940 was warmer than today
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P. Gosselin)
The topic today is the temperature trend in the Arctic. Of special interest are the hard facts. At Climate4You we find the satellite measured temperature development (UAH) of the Arctic:

 Figure 1: Temperature chart of the Arctic over the past 40 years (satellite measurement). Data: UAH. Chart: Climate4You
Arctic temperatures today “similar” to 1980
We do see a warming over the past 4 decades. Since the El Nino-induced peak of 2016, the temperature has fallen gradually. The coldest temperatures were recorded at the end of the 1980s and early 1990s.
At around 1980 similar temperatures as those of today were measured. Unfortunately there is no satellite data for the time before 1979, and so not even a full 60-year ocean cycle is covered, and thus this makes it really difficult to assign warming to man or to natural causes over the recent decades.
Russian Arctic just as warm in the 1930s as today!
But of course there were weather stations before 1979, and these showed a warming phase in the Arctic already in the 1930s and 1940s, a time when it was just as warm as it is today. Example: Opel et al. 2009 reconstructed the temperature history in the Russian Arctic for the last 100 years using ice cores. The warm maximum occurred in the 1930s and not today:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




115 year ice-core data from Akademii Nauk ice cap, Severnaya Zemlya: high-resolution record of Eurasian Arctic climate change
From 1999 to 2001 a 724 m deep ice core was drilled on Akademii Nauk ice cap, Severnaya Zemlya, to gain high-resolution proxy data from the central Russian Arctic. Despite strong summertime meltwater percolation, this ice core provides valuable information on the regional climate and environmental history. We present data of stable water isotopes, melt-layer content and major ions from the uppermost 57 m of this core, covering the period 1883–1998. Dating was achieved by counting seasonal isotopic cycles and using reference horizons. Multi-annual δ18O values reflect Eurasian sub-Arctic and Arctic surface air-temperature variations. We found strong correlations to instrumental temperature data from some stations (e.g. r = 0.62 for Vardø, northern Norway). The δ18O values show pronounced 20th-century temperature changes, with a strong rise about 1920 and the absolute temperature maximum in the 1930s. A recent decrease in the deuterium-excess time series indicates an increasing role of the Kara Sea as a regional moisture source. From the multi-annual ion variations we deduced decreasing sea-salt aerosol trends in the 20th century, as reflected by sodium and chloride, whereas sulphate and nitrate are strongly affected by anthropogenic pollution.”

Figure 2: Temperature chart Severnaya Zemlya (Russian Arctic) over the past 130 years. Upper peaks = warm. Source: Opel et al. 2009
A part of the warming by the way, has to do with measures that keep the air clean in Europe. The anthropogenic sulfate particle kept the Arctic cool for many years, so reports that University of Stockholm (via Science Daily). Should we get back to being dirty for reasons of climate change?

European clean air policies unmask Arctic warming by greenhouse gases
[…] The drastic cut in sulfate particle emissions in Europe partly explains the amplified Arctic warming since the 1980s, shows a new study published in Nature Geoscience. The team, which consists of scientists from Stockholm University and the Norwegian Meteorological Institute, say that their surprising finding highlights an even more urgent need for reducing greenhouse gas emissions to mitigate Arctic climate change. Human activities, such as industrial production, transport, power generation, and wood burning emit large amounts of tiny pollutant particles containing, for example, soot and sulfate, into the atmosphere. High airborne amounts of these particles, also known as aerosol particles, cause about 400,000 premature deaths every year in Europe and can be transported over long distances. Aerosol particles have different sizes, as well as chemical and physical properties, all of which determine their climate effects.

“Soot particles absorb solar radiation and warm the climate, in a similar way as greenhouse gases, such as carbon dioxide, do. Sulfate particles, on the other hand, reflect solar radiation and act as seeds for cloud droplet formation, cooling the climate as a result,” says Juan Acosta Navarro, PhD student at the Department of Environmental Science and Analytical Chemistry (ACES) and the Bolin Center for Climate Research, Stockholm University, and co-author of the study. He continues: “The overall effect of aerosol particles of human origin on climate has been a cooling one during the last century, which has partially masked the warming caused by the increase in greenhouse gas emissions.” […]
J. C. Acosta Navarro, V. Varma, I. Riipinen, Ø. Seland, A. Kirkevåg, H. Struthers, T. Iversen, H.-C. Hansson, A. M. L. Ekman. Amplification of Arctic warming by past air pollution reductions in Europe. Nature Geoscience, 2016; DOI: 10.1038/ngeo2673“

But also later alterations to the measurement data make the Arctic look warmer today than it actually is (see here and here). A nice summary of climate change in the Arctic can be found at Judith Curry’s site.

Share this...FacebookTwitter "
"With just under a week to go, more than £750,000 has been donated to the Guardian and Observer climate emergency charity appeal, which supports projects planting and protecting trees, woodlands and forests. More than 10,000 readers have contributed to the appeal, which promotes environmental and social justice through natural climate solutions, from safeguarding rainforests in the Amazon to rewilding the Scottish Highlands and planting trees in Britain’s towns, cities and countryside. The charities are: Woodland Trust, Trees for Life, Trees for Cities and Global Greengrants Fund UK. Responding to the news, the chair of Global Greengrants Fund UK, Stephen Pittam, said: “Thanks to Guardian and Observer readers we can enable more local communities in the Amazon region of Brazil to continue their struggles for environmental justice. Supporting these frontline defenders of the largest rainforest on earth is crucial for the future of every single person on this planet.” Scores of messages left by donors show many felt compelled to give in part to signal their frustration at the failure of many elected politicians to take the climate crisis seriously, as well as the need to take personal action in the absence of large-scale solutions to the most important issue facing the planet. One reader said: “I feel that large-scale government action is necessary in order to avert climate disaster. But that shouldn’t stop each of us individually trying to change our behaviours. We see this donation as a way of mitigating some of the climate damage we have been responsible for over the last year as a family.” Another said: “Trees can save the earth. Let’s stop cutting the ancient ones down, and cover bare land with young trees to help and beautify the future.” Introducing the appeal in December, the Guardian editor-in-chief, Katharine Viner, said although the onus was on governments and corporations to take major steps to avoid global climate catastrophe, this year’s charity appeal “highlights ways we as citizens can support practical, natural solutions to climate change”. The appeal continues until midnight on Sunday 12 January. Readers can donate online here or send a cheque (payable to the Guardian and Observer charity appeal 2019) to: The Guardian and Observer charity appeal 2019, Charities Trust, Suite 20-22, Century Building, Tower Street, Liverpool, L3 4BJ."
nan
"A large dog romps across a blue and white canvas, leaving a trail of brown paw prints. “Oh well,” shrugs Vivian Suter. “They’re part of the work now. I don’t think anyone will mind.” I realise Bonzo – one of three Alsatian crossbreeds that shadow the artist wherever she goes in her Guatemalan home – has just put the finishing touches to an artwork that will shortly be on public display thousands of miles away. The painting lies on the floor of her “laager” – a storage barn open to the elements, apart from a metre-high stone wall, which you have to clamber over with the help of a rickety chair. The wall is to guard against mudslides, she explains, gesturing at a ghostly tideline that rings the interior. Most of her works hang from a rack; the piles on the floor are for three upcoming exhibitions in Berlin, London and Madrid. Having just opened a 53-piece installation at Tate Liverpool, Suter is halfway through choosing the 200 works that will feature in her Camden Arts Centre exhibition, which opens next week.  It is the latest stage in an extraordinary renaissance for a 70-year-old Swiss-Argentinian artist who all but disappeared in her 30s. Suter was close to having to sell off part of her home when a curator tracked her down for an update of a group show in which she had featured in 1981. What he found was an artist perfectly attuned to an era of looming ecological crisis, with three decades of work in her backyard. Strapped for cash and far from specialist suppliers, she had learned to work with house paint and fish glue on cheap local fabric, which she would then leave outside for the weather to finish off. She stoops to stir a twig that has fallen into a tin brimming with scummy green water and says: “This is a good colour. I’ll definitely find a use for it.” The title of her Camden show, Tintin’s Sofa, pays tribute to another of the dogs with which she and her 97-year-old artist mother Elisabeth Wild share their hideaway on the slopes of a volcano, a bone-rattling three-hour drive from Guatemala City. Though Suter seldom ventures out, leaving shopping to her two assistants, she is well-known in the small lakeside town of Panajachel. “Just get a tuk-tuk and ask for the black door,” I am told. Walking through that black door, set into a high wall on the town’s outskirts, is like stepping through CS Lewis’s wardrobe into a timeless world that is both beautiful and menacing. Her hideaway, covering several acres of an old coffee plantation, is a tumble of rock and vegetation. Close to the small bungalow in which Suter has lived for more than three decades, lies a boulder that was washed down the mountain in the last rainstorm, and has yet to be colonised by the strangler figs whose roots lattice the ground. It was one such tree that drew her to this site back in the early 1980s when – recovering from a divorce and wearied by life in her home city of Basel – she took a road trip across Central America. On reaching Lake Atitlán in Guatemala, she decided to stay, entranced by its fierce beauty and remoteness. “Nobody told me there was a war going on,” she says. She fell in love, remarried (again briefly) and gave birth to a son, Pancho, now 34, who lives on the other side of the lake but has recently turned one of the sheds on the slopes of his mother’s garden into a recording studio. Suter is not sure if he will join us for lunch because a Nicaraguan rapper is about to turn up. Pancho has adopted his grandmother’s surname, and she in turn snaps up his cast-off clothes, greeting us for lunch in a badass graffiti T-shirt. Wild, too, has been enjoying a renaissance. A solo show in Dubai in 2019 will next year be followed by a retrospective at Vienna’s Museum of Modern Art. The reason for coming all this way to meet them is that, while Wild is confined to a wheelchair and no longer well enough to travel, the life and work of the two artists is so intertwined it would be hard to understand one without the other. It’s a pilgrimage that has already been made by the artist Rosalind Nashashibi, whose film Vivian’s Garden was part of her shortlisted 2017 Turner prize entry. Wild was born in Vienna in 1922 to a Jewish father and a Catholic mother, who fled Nazism, ending up in Argentina. While working there as textile designer, she met and married Suter’s factory owner father, before fleeing back to Europe to escape the dictatorship of Juan Perón. Settling in Basel with their 12-year-old daughter, they set up a furniture shop where Wild turned her skills to cabinet painting. “I would go to flea markets and find old furniture and restore it,” she says, leafing through an album of exquisitely painted work.  Suter recovered from all this uprooting to secure a place at art school in Basel at just 17. Within three years, she had landed her first group show. She made her solo debut a year later. When did Wild first know her daughter was an artist? “Always,” she says. The closeness between the two women is evident as they chat, gently challenging each other’s versions of history in a mixture of German, English and Spanish. They live yards apart in separate bungalows, with their shared artistic heritage covering the walls of both, from a couple of intricate botanical watercolours by Wild’s grandmother to a scattering of large abstracts painted by Pancho as a child. Mother and daughter have exhibited several times together, most recently in Los Angeles, where a critic’s remark that their work was “compositionally diametric yet chromatically in sync” captured the creative tension between them. While Suter works in a bold freestyle, often very quickly, in collaboration with whatever the weather throws at her, Wild sits at a desk snipping and glueing, composing a small geometric collage every day from architecture and lifestyle magazines. While Suter leaves all her work undated and unsigned, Wild painstakingly signs and logs every piece for storage in a painted chest which is the only piece of her furniture that made the journey to Guatemala. When I ask Wild how she would describe her daughter’s work, there is a long silence. “Sometimes,” cuts in Suter, “I showed my mother my things and I couldn’t stand her comments so I stopped showing her.” She admits that she too can be judgmental: “I look at my mother’s collages and sometimes, when she’s not there, I quickly move something. But she always notices. We have a relationship, and sometimes individually, without speaking about it, we make similar things. The spirit is the same.” Suter’s response to a question about the impact of her mother’s criticism is to lead me up a perilous flight of stone steps laid into the hillside to a studio that is most definitely not wheelchair-friendly. She does most of her work outside it, squeezed into a narrow gap between its side wall and the encroaching forest, “because I really like painting while squished”. Bare white canvases lean against the bright red wall waiting for her to start work on her next big project, a commission from Art on the Underground for London’s Stratford station. For such big works this seems less than ideal, and the peril of her perch is greatly increased by the mess of old paint cans that litter the ground. For all the nimbleness with which she flits around – a slight, otherworldly figure with a drift of auburn hair – there is an anxiety in her relationship with her surroundings. She has fortressed her garden with towering spears of bamboo. One wall of her studio has a built-in cupboard, the door of which stands ajar. “There’s probably some good paint in there but I haven’t looked for years.” Why? “Because it’s probably got scary things in it.” Like what? “Like snakes maybe.” She knows from bitter experience how dangerous this environment can be, and her respect for it has become the keystone of her work. In 2005, a hurricane sent a mudslide hurtling over everything she had created. “At the time I saw it as just a catastrophe,” she says, “but as they started drying, the colours began to come out, and I realised that I had to start working with nature and not against it. “Then I started leaving them outside in the rain so that they could get splashed. It was a turning-point which transformed everything. It made all I do into one work – and that’s how I see it now, not as single pieces but as a whole.” One of the ruined paintings hangs above her bed. It’s a rich burgundy that looks simultaneously cosy and sacramental. In a gesture, perhaps, to her truce with nature, she has hung it upside down so that its top 18 inches, rather than its bottom, is caked with mud. Does she ever tire of the isolation? “Why would I?” she says. “My best friend is here. The question is what will happen when she goes.” Towards the end of lunch, when Suter is out of earshot, I ask Wild again what she makes of her daughter’s work. This time there’s no hesitation. She leans back in her chair with a smile and says: “It’s free – in a good way.” Vivian Suter’s Nisyros (Vivian’s Bed) is at Tate Liverpool until 15 March; Tintin’s Sofa is Camden Arts Centre, London, 16 January-5 April. She is part of En Plein Air at the High Line, New York, until March. "
"
Share this...FacebookTwitterParts of Germany’s political leadership appear to be waking up to the harsh realities of green energies (wind and sun) and their inefficiencies.
Hat-tip: Die kalte Sonne
“Economic Minister accepts true condition of Energiewende”
The website of German national daily “Welt” here reported last month that Germany’s powerful Minister of Economics, Peter Altmaier “accepts the true condition of the Energiewende [transition to green energies]”.
In the Welt commentary, veteran journalist Daniel Wetzel wrote that Altmaier “avoided every mention of Germany functioning as a leader or role model”” for the world when it comes to green energies today. That’s change of course from what we used to hear.
Some ten years ago Germany boasted non-stop about being the global leader in green energies. Today, after seeing years of skyrocketing electricity prices and an increasingly destabilized power grid, the country has visibly backed off its once lofty green goals, which were aimed at making Germany 90% reliant on green energies by 2050. Lately it’s been dawning that this target was far too utopian.
Energiewende “no solution for single countries”
Wetzel quotes Altmaier, who was speaking before dozens of green business leaders at the international Energiewende Conference, stated that “the Energiewende will survive only if it is global” and that it is “no solution for single countries.”
In a nutshell, Altmaier admitted the Energiewende is a failure because it is already known that many other countries, like USA and China” are not going to adopt it and so will always have access to cheap, reliable energy and Germany will thus have no chance to compete internationally should it opt to stay on the green course.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Altmaier said it only made sense if it’s implemented worldwide. But today everyone knows worldwide implementation is a pipe dream and so Germany needs to start forgetting about its once ambitious Energiewende..
Wetzel then comments:
Altmaier’s sober message to the international eco-electricity scene: An Energiewende is more difficult than one thinks, and it takes longer than many think it does.”
Only efficient when everyone else accepts being inefficient
So why would Altmaier state that only a global Energiewende would make sense? To answer that one has to read between the lines. His claim in fact confirms that green energies are terribly inefficient, and thus uncompetitive, which means going it alone only makes the country inefficient and uncompetitive.
So according to Altmaier in order for the Energiewende to be “efficient in a country, all othe rcountries must adopt it and become energetically inefficient. Only when all countries become inefficient can Germany’s Energiewende be “efficient”.
No hurry to go green
Under the bottom line: Germany is no longer in a hurry to transform its energy supply system into a green one because it knows big competing coutries aren’t going to do it.
 
Share this...FacebookTwitter "
"The most powerful leaders in the West used the G7 summit in Germany to make a big statement on the environment. Their stated goal is to cut carbon emissions by 40% to 70% by 2050 and then end all fossil-fuel use by 2100. They announced a US$100bn (£65bn) fund by 2020 comprising public and private money to help smooth the transition. My response to David Cameron, Angela Merkel and the rest is pretty simple: good luck with that.  When people talk about decarbonisation, they tend to make the mistake of thinking about energy only in terms of electricity. If you ask how to wean us from fossil fuels, they will say build more solar power, more wind farms and so forth. There are several problems with this. We are already struggling with capacity on the grid and have a huge task to add as much renewable energy as it can cope with. To cover the extra requirements to make heat and domestic transport electric, we would need five times more. I don’t know anyone who thinks this is remotely realistic.  Because most forms of renewable energy only work when the power source is available, be it wind, sun or whatever, we will need large amounts of storage capability to allow them to replace electricity powered by fossil fuels. And while it’s easy to see how you can store kilowatts and megawatts of green power in the batteries of the future, getting up to gigawatts is another matter. The huge engineering requirement makes it almost impossible to get the costs to a point where this is viable.  Electricity is also the least of the big drains on energy. The big challenges are transport fuels, especially for long-distance haulage and trans-ocean shipping. We really don’t have any smart ideas for replacing diesel for these yet, and it’s difficult to see where they will come from. The Royal Academy of Engineering did a study in 2013 looking at the options for low-carbon fuelling of shipping. The best it could come up with was LNG (liquefied natural gas).  You can conceive of running large numbers of domestic cars on green electricity by charging them on the grid. But the idea that anybody is going to be able to produce a battery big enough to store the electricity to power a passenger aircraft or a major container ship is laughable.  Energy consumption by sector Energy consumption that is renewable Then there is hydrogen. It’s got fantastic potential. It has a few cost issues at the moment, but they can probably be sorted out over the next few decades. It may well emerge as a viable option for domestic transport, but it has nothing to offer heavy haulage either. To have enough hydrogen to power a trans-ocean ship or plane would require massive amounts of compression that would use so much energy that it would not be worthwhile. It appears beyond the limits of physics to overcome this.  So far I have only talked about energy – yet we have built our societies around many other uses of fossil fuel that rarely get mentioned. Fertilisers is a good example. Most of the world’s food supply is based on fertilisers, and I don’t know of anybody who is suggesting that the largely urban population we will have by 2050 can be fed without using the amount of fertilisers we use at the minute, or that they can be produced without using fossil fuels.  Then there is steel. We are recycling more and more steel, but 50% of it is still primary production from virgin materials (and this is expected to continue). Steel is actually an alloy of iron and carbon, so it’s not just a question of the energy that we need to produce it. You can reduce the fossil fuels on the energy side by switching to an arc furnace powered by hydroelectricity, for instance, but where are you going to get the carbon for primary production? Your only alternative to fossil fuels is charcoal, which would entail mass deforestation across the world to get enough – and massive carbon emissions to make it from wood.  Society also depends on plastics. Where are you going to get plastics in sufficient quantities to meet demand without fossil fuels? The same applies to materials we need for renewable-energy essentials like lightweight carbon-fibre wind-turbine blades, and thin-film photovoltaics. Nobody has a serious alternative to this. Equally we could talk about pharmaceuticals, cement – the list goes on.  That’s not to say I don’t welcome the $100bn fund. It means more funding for research into renewable energy, which is definitely needed. But even on an 85-year timescale, it’s difficult to see what we can do about the barriers of physics. I wish I could simply endorse the climate change protesters and say it can all be done, but that would require a suspension of disbelief at the expense of scientific honesty.  That’s not to say we can’t make a difference in many ways. Geothermal energy is not on most people’s radars, but it has vast potential that’s not even close to being exploited. We can change the game in short-haul transport by switching to electric and hydrogen-powered cars.  There are various ways in which nuclear power can potentially be improved, for example by using thorium instead of uranium as the feedstock, or by getting more energy from nuclear waste. There is nuclear fusion too, if it ever succeeds. But nuclear is no good at responding to fluctuations in power demand – and neither are renewables – and it’s difficult to conceive of this changing.  I have no sentimental attachment to fossil fuels. I have had relatives who died in coal mines. But as an engineer, I have to admit when I am beaten. I can see a Gandhian future where everyone uses many fewer fossil fuels and lives in a much more spiritual way, and I would welcome it. But I don’t see any signs of that coming out of the G7. Realistically the only solution to our fossil-fuel dependency is an end to mass consumer culture, but that’s just not what the politicians are proposing. Instead we are just encouraging the developing countries to get addicted to the same consumer lifestyle as those in the West.  Probably where we are more realistically heading is towards a world in 2100 where we depend more heavily on coal. Unlike oil, it will still be available in large quantities. We will remove the majority of the carbon emissions by coupling carbon capture and storage technology to underground coal gasification.  The fact that the politicians are not telling us this is a sign of the triumph of the protesters. They have managed to change the argument from reducing carbon emissions to getting rid of fossil fuels, since nuclear is low-carbon and not something they approve of. So instead we get platitudes that are empty and unachievable. Until we can have an honest conversation about the future of our relationship with energy, there is no point in taking our leaders seriously."
"There’s a famous British nursery rhyme about how many magpies one sees in a day. It begins: “One for sorrow, two for joy …”  The whole verse is strangely ambiguous, the lines alternating between good and evil as if we cannot make up our minds about this familiar bird. The rhyme ends with 13 magpies: “… beware it’s the devil himself.”  However I’ve got a soft spot for them. Perhaps I’m influenced by my local football team, Newcastle United, being nicknamed the magpies on account of their black and white stripes. Although the team seems wholly unable to acquire anything silver or glittery, unlike its feathered namesakes.  Magpies are commonplace in my city. Adults fuss and clatter as they tweak their twig nests, gangs of “teenage” birds loiter on park benches, inquisitive individuals tug at TV aerials or pry through the backyards tracking the fate of smaller birds. They have flourished in the UK in the past few decades, and their population trebled between 1970 to 1990 and has stabilised since then. But such a gaudy and notorious species was bound to attract public ire, especially as their reputation has been fed by centuries of superstition. Magpies, wherever they live, haunt folklore. Sometimes they appear as a sinister omen, but equally often as a friend. In the UK, a lone magpie is considered especially ominous and it is commonplace to voice a respectful enquiry as to the health of its wife and children. Conversely in China and Korea magpies are seen as bringing good luck.  The magpies of Europe seem to have been caught up with the dark reputation of their blacker feathered relatives, the crows and ravens. Shakespeare flings them into the supernatural mix of Macbeth as “maggot-pies”, a grim name, but likely to be a corruption of older words, “mag” for chatter and “pie” for black and white.  Except that they are not black, but an iridescent deep green with flashes of slick petrol blue and purple. Their stubby wings and long tail fan into art deco-like rays, and the whole colour scheme has a 1920s and 30s style and glittery appeal. They stroll and swagger, peer and prod. Compare one in flight to artists’ impressions of proto-bird Archaeopteryx and there is a striking similarity. Many palaeontologists refer to the T. rex and Velociraptor as “non-avian dinosaurs”. However, if you watch a magpie at its most confident, on the hunt, you’ll see the link between these modern aviators and those ancient carnivores.  Their malevolent reputation is also associated with an eye for a glittery trinket, thieves who will steal to decorate their nests. Note the fecklessness of this: they aren’t even stealing to make a living, but purely for vanity. “Thieving magpie” is a common insult. But a study published last year in the journal Animal Cognition seems to discredit this behaviour. Researchers found no evidence magpies were attracted to shiny objects offered to them, indeed the birds shunned the gifts. Instead they had “neophobia”, the researchers claimed; the birds were afraid of the unfamiliar, wary of the baubles. However, once you discover that the items on offer were metal screws and aluminium foil you could understand why any self-respecting jewel thief would turn up their beak at tawdry items of DIY hardware.  It is the magpie’s misfortune to have been swept up in the culture wars around birds of prey. The decline of sparrows, starlings and other smaller garden birds in recent decades and the simultaneous rise of the magpie and other predators such as sparrowhawks have been linked by campaign groups such as Song Bird Survival, with calls for culls of raptors and crows to help maintain a natural balance.  Conservation groups such as the RSPB have repeatedly pointed out the lack of evidence of impacts and asked why such campaign groups are so closely allied to hunting and shooting organisations. A recent review of 42 studies showed magpies and crows have very little impact and were unlikely to limit bird populations.  The effort and expense of controlling their numbers was disproportionate to the limited gains, done more because crows and magpies are conspicuous, the easy scapegoats of legend."
"If you know who Sean Hannity is, you probably know that he is no fan of the Green New Deal. The proposal has blanketed Fox News since it debuted in November 2018, with Hannity and fellow hosts on the network narrowing in a particular line of attack, summarized during a radio spot he did last year: “What they are proposing is so outrageously expensive and cost prohibitive even they acknowledge that if we confiscated all the billionaires’ wealth, it still wouldn’t be able to pay for this mess of theirs.” Along similar lines, Republicans circulated a bogus study from the industry-funded American Action Forum claiming a Green New Deal would cost $93tn, elevating the number into something of a meme among rightwing talking heads and politicians. Senate majority leader Mitch McConnell told his colleagues it would be more than enough to “buy every American a Ferrari”. Hannity and McConnell, along with most of the rest of the Republican party, have more recently been heaping praise onto Trump for assassinating Iranian Gen Qassem Suleimani. “This is a huge victory for American intelligence, a huge victory for our military, a huge victory for the state department, and a huge victory and total leadership by the president,” Hannity boasted after the killing. Without consulting Congress, the president kicked long-simmering US-Iran tensions up to a boil that now threatens to spill over into another full-blown war in the Middle East. His threats to bomb cultural sites throughout the country – in violation of international law – make that even more likely. So why aren’t Republicans asking how the government would pay for it?  A recent study from Brown University’s Watson Institute found that, since 2001, wars in Afghanistan, Syria and Pakistan have cost the US $6.4tn – $2tn more than all federal spending in 2018. The trouble with a prospective new war in Iran, of course, isn’t that it would cost too much money. It’s that it would put potentially millions of lives at risk, mostly to appease Donald Trump’s fragile ego, a coterie of neocons who’ve been edging toward it for years and a slew of defense contractors eager to cash in. Neither a Green New Deal nor another war would plummet the US into bankruptcy, a virtual impossibility barring earth-shattering changes to the make-up global economy. They probably wouldn’t even raise inflation. The disconnect between Republicans’ fiscal conservatism on climate and spendthrift war drums illustrates a basic fact about American politics: that our budgets are more than anything expressions of what it is the country chooses to value – not how much money we have in the bank. The only time costs become an issue is when it comes to programs that run counter to Republican policy priorities, whether by making sure that everyone has healthcare or taking on the urgent threat of the climate crisis, the potential real costs of which are virtually exponential. In office, Republicans have been prolific deficit spenders, from supposed small-government ideologue Ronald Reagan to George W Bush to Trump, who pushed through $2tn worth of tax cuts for the wealthy. Democrats all too often fall into the trap of worrying about the deficit, from the Clinton administration’s war on public programs to Nancy Pelosi’s seemingly religious commitment to enforcing so-called pay-as-you-go (“Paygo”) rules that would kneecap any progressive agenda. At the same time, the establishment Democrats urging fiscal prudence and (rightfully) calling Trump an illegitimate president have reliably voted to expand his military budget, arming him with $738bn for this year alone. At this point, nobody is expecting intellectual honesty from the Republican party. Democrats, though, shouldn’t play into their hands. It’s time to be as hawkish about taking on real threats as Republicans are about taking on fake ones, whatever the cost. Kate Aronoff is a writer based in New York"
"
Share this...FacebookTwitterIn direct contrast with CO2-centric climate modeling, extensive paleoclimate evidence affirms that the Holocene climate has been far more variable in the past 12,000 years than during the relatively quiescent period we’ve enjoyed since the mid-19th century. In the absence of CO2 concentration changes or human interference, abrupt global cooling episodes led to agricultural collapse, famines, and the extirpation of ancient civilizations.  These naturally-occurring climate events are likely to recur…and we will be powerless to intervene.

Between 1860 and 2014, CO2 concentrations rose dramatically (from 285 parts per million to 400 ppm), and yet global temperatures have fortunately remained relatively stable, with an overall per-decade change rate of just 0.05°C.

Image Source: Zhu et al., 2017
In contrast to the last 150 years of modest climate change, there was an instance 14,500 years ago in which “Northern Hemisphere temperatures increased by 4–5°C in just a few decades” and a concomitant “12–22 m sea level rise in less than 340 years” (Ivanovic et al., 2017), which is a warming of multiple degrees per decade and a sea level rise amounting to 3.5 to 6.5 meters per century.   This well-documented climate event occurred without CO2 levels fluctuating, indicating that CO2 was not causally involved in this explosive warming or sea level rise.
The 8.2 ka Abrupt Cooling/Warming Event
About 8,200 years ago, there was an abrupt, multiple-degree C cooling and warming episode (the “8.2 ka event”) that was global in scope, and lasted a total of about 150 years, with the amplitude of the cooling and warming phases lasting only decades.  The event was “associated with a total eustatic sea level rise of 0.8–2.2 m [Li et al., 2012; Törnqvist and Hijma, 2012]” (Ahn et al., 2013), indicating that there was far more pronounced climatic changes and sea level rise rates — ~1 meter per century — during this period than the mere 0.05°C per decade change and <0.2 meter of sea level rise that has occurred in the last 150 years.
Kobashi et al., 2007     “A large number of paleoclimatic records over a hemispheric area show a large and abrupt climate change around 8200 years BP. However, the duration and general character of the event have been ambiguous. Here, we provide a precise characterization and timing of the event using methane and nitrogen isotopes in trapped air in an ice core. Climate change in Greenland and at a hemispheric scale was simultaneous (within ~4 years) as supported by climate model results (LeGrande et al., 2006).  The event started around ~8175 years BP, and it took less than 20 years to reach the coldest period, with a magnitude of cooling of ~3.3°C [per decade] in central Greenland.   After 60 years of maximum cold, climate gradually recovered for 70 years to a similar state as before the event [+3.3°C within 70 years]. The total duration of the event was roughly 150 years. … The fall in temperatures that accompanied the 8.2 ka event also corresponded with abrupt migrations of human populations and abandonment of sites ranging from Spain to Greece and in the Middle East (Gonzalez-Samperiz et al., 2009)  ….  Ice cores from Greenland (Alley et al., 1997) and Africa (Thompson et al., 2002) suggest that the 8.2 ka event was global in extent.”
During this period, atmospheric CO2 concentrations effectively stayed the same, with “a small, about 1–2 ppm, increase of atmospheric CO2 during the 8.2 ka event” (Ahn et al., 2013), once again supporting a lack of causal connection between large-scale global warming and cooling and CO2 concentration changes.
Atwood et al., 2017     “The relatively stable climate of the Holocene epoch (11,700 yr BP-present) was punctuated by a period of large and abrupt climate change ca. 8,200 yr BP, when an outburst of glacial meltwater into the Labrador Sea drove large and abrupt climate changes across the globe.  Polar ice and marine records indicate that annual average surface temperatures dropped by 2-6 °C in central Greenland and by 1-3 °C in the North Atlantic Ocean and Europe [within decades]. The associated climate perturbations are generally thought to have persisted for 100-150 years [before temperatures returned to the previous baseline]. … These events stretch our understanding of the dynamical principles that govern the climate system, given the lack of these events in the modern record and the inability of climate models to reproduce such variability.”

Griffiths and Robinson, 2018     “The 8.2 ka BP (8200 cal. BP) event is regarded as the largest abrupt climate change event of the Holocene period (Alley et al., 1997; Alley and Agústsd ottir, 2005 ). It was first identified in the Greenland ice cores (Alley et al., 1997; Rasmussen et al., 2006; Thomas et al., 2007), but has subsequently been reported in multiple proxies across Europe (Magny et al., 2003; Seppa et al., 2007; Prasad et al., 2009; Zillen and Snowball, 2009; Daley et al., 2011; Giesecke et al., 2011), and throughout the Northern (Morrill and Jacobsen, 2005; Shuman, 2012; Liu et al., 2013; Dixit et al., 2014) and Southern Hemispheres (Morrill and Jacobsen, 2005; Cheng et al., 2009; Bustamante et al., 2016). In the Northern Hemisphere the event has been cited as precipitating a cold period, with a drop in temperature for example of 6 ± 2°C at Summit, Greenland (Alley et al., 1997) and of c. 1.6°C at Hawes Water, northwest England (Lang et al., 2010) that, according to counts of Greenland ice core layers, lasted a total of just over 160 years (Thomas et al., 2007). The event was reportedly caused by a glacier meltwater outburst from Laurentide lakes Agassiz and Ojibway around 8470 cal BP, which reduced deep water formation and caused an abrupt slowdown of the Atlantic meridional overturning circulation (Barber et al., 1999). This hypothesis has been supported by work showing two sea-level jumps between 8.5 and 8.25 ka BP (Tornqvist and Hijma, 2012).”
The 4.2 ka Abrupt Cooling/Warming Event
About 4,200 years ago, another abrupt global-scale cooling event occurred that was associated with severe Northern Hemisphere-wide drying period that lasted for centuries.  The accompanying megadroughts and famines wiped out human civilizations that had existed in the same locations  for centuries to millennia.  After about 300 years of enduring cold and drought-stricken climates, “unified Neolithic farming culture completely collapsed” (Fenggui et al., 2010 ).
Like the 8.2 ka event, the 4.2 ka event featured a sudden, decadal-scale drop in surface ocean temperatures of 1-2°C (Guo et al., 2018).  Also like the 8.2 ka event, the 4.2 ka event was not accompanied by changes in CO2 concentrations, again emphasizing the lack of a strong linkage between CO2 fluctuations and large-scale climate changes in the paleoclimate record.
Guo et al., 2018   “The mid-Holocene environmental transition was characterised by global cooling and the abrupt weakening of the Northern Hemisphere monsoon systems. It is generally considered the key driver of the collapse of several mid-Holocene agricultural societies, on a global scale. … The mid-Holocene environmental transition has attracted much attention from climate scientists and archaeologists, especially Holocene event 3 (HE3, ~4.2 ka) [4,2000 years ago],as termed by Bond et al. (1997), because it marks the termination of the Holocene climatic optimum (Perry and Hsu, 2000) and the initiation of the Neoglacial (Solomina et al., 2015). Existing records reveal that ocean surface temperatures decreased by ~1-2°C during HE3 [4.200 years ago] (Bond et al., 1997; deMenocal et al., 2000b), which persisted for ~300-600 years (Cullen et al., 2000; Perry and Hsu, 2000); while a total duration of up to ~1500 years was recorded in the North Atlantic (Bond et al., 1997, 2001). In addition, HE3 was punctuated by a series of geologically-rapid global cooling and/or dry events (Morrill et al., 2003; Marchant and Hooghiemstra, 2004; Booth et al., 2005; Shanahan et al., 2015) which were superimposed on the gradual drying trend of the mid-Holocene (Morrill et al., 2003; Mayewski et al., 2004; Wanner et al., 2008, 2011; Roberts et al., 2011). Associated with HE3 were the collapse of cultures in Pakistan (Staubwasser et al., 2003; Madella and Fuller, 2006; Macdonald, 2011; Giosan et al., 2012; Ponton et al., 2012; Leipe et al., 2014; Menzel et al., 2014; Prasad et al., 2014a), Mesopotamia (Weiss et al., 1993; Cullen et al., 2000; deMenocal, 2001), China (Jin and Liu, 2002; Wu and Liu, 2004; An et al., 2005; Innes et al., 2014; Zeng et al., 2016; Zhu et al., 2017) and Egypt (Thompson et al., 2002; Marshall et al., 2011; Phillipps et al., 2012). In high latitudes of the Northern Hemisphere, a peak in detrital carbonate flux on the East Greenland Shelf at 4.7 ka signaled both the beginning of the Neoglacial and a southward expansion of the Arctic sea ice (Jennings et al., 2002). In Europe, a 4.2 ka drought event is recorded by multi-proxy data from a cave flowstone in Italy (Drysdale et al., 2006); diatom assemblages from Montcortes Lake in the Iberian Peninsula indicate that lake levels were lower during a pronounced dry interval from 2360 to 1850 BCE (Scussolini et al., 2011); a decrease in deciduous Quercus and Pinus pinea-type percentages in Southwest Iberia at ~4.2 ka suggests an abrupt shift to dry conditions (Lillios et al., 2016); and a synthesis of records from the Mediterranean reveals an unusually dry interval from 4.5 to 3.9 ka (Mercuri et al., 2011; Roberts et al., 2011). Evidence from eastern tropical Africa indicates a shift to drier conditions at ~4.0 ka (Marchant and Hooghiemstra, 2004), although at this time wetter conditions were maintained in West Africa (Russell et al., 2003) and in parts of South America (Marchant and Hooghiemstra, 2004); and magnetic and geochemical data from the Holocene sediments of Lake Tana in northwest Ethiopia confirm that the driest interval occurred at ~4.2 ka (Marshall et al., 2011), which is also identified in the Mount Kilimanjaro ice core (Thompson et al., 2002) and in the Mauritian lowlands (de Boer et al., 2014). In eastern Russia, evidence of a cold spell between 4.5 ka and 3.5 ka is provided by a multi-proxy record from Two-Yurts Lake (Hoff et al., 2015). A severe centennial-scale megadrought in mid-continental North America occurred between 4.1 and 4.3 ka (Booth et al., 2005).”
Xiao et al., 2018     “Researches on the 4.2 ka event and its impact on cultural evolution in China have been encouraged by Hsü’s view (1998) that famines and mass migrations have occurred in the past. In ancient China, these could have resulted from regional droughts related to global cooling. Wu and Liu (2004) synthesized data from paleoclimatic records in eastern China and suggested that the climatic anomaly that occurred ~4.2 ka ago produced a drought in the northand flooding in the south, which was responsible for the collapse of neolithic cultures in the central plain of China during the late third millennium BC. … Fang and Sun (1998) first attributed the interruption of the Laohushan Culture to climatic cooling based on the impacts of ≥10°C cumulative temperature decreases on frost-free period in the lake region and of a temperature drop to agricultural production in areas along the Great Wall during the historical period. This interpretation has been followed by Tian (2000) and Tian and Guo (2004). As stated above, our multi-proxy data imply a decrease in regional precipitation rather than temperature.”
Klus et al., 2017     “Abrupt cold events have been detected in numerous North Atlantic climate records from the Holocene. … Here, we describe two cold events that occurred during an orbitally forced transient Holocene simulation using the Community Climate System Model version 3. Both events occurred during the late Holocene (event 1 referring to 4305-4267 BP [38 years] and event 2 referring to 3046-3018 BP [28 years]) and were characterized by substantial surface cooling (-2.7 and -2.2 °C, respectively [-0.71 °C/per decade and -0.78 °C/decade]) …  …  Northeast of Iceland, however, shows an increase in both SST and SSS, but a decline in sea ice concentration (event 1: warming of 1.6 °C [+0.42 °C/decade], rise of 0.7 PSU, decline of -5 % in sea ice concentration; event 2: warming of 1.9 °C [+0.68 °C/decade], rise of 0.9 PSU, decline of -11 % in sea ice concentration). … The events were triggered by prolonged phases of a positive North Atlantic Oscillation which, through changes in surface winds, caused substantial changes in the sub-polar ocean circulation and associated freshwater transports, resulting in a weakening of the sub-polar gyre. Our results suggest a possible mechanism by which abrupt cold events in the North Atlantic region may be triggered by internal climate variability without the need of an external (e.g. solar or volcanic) forcing.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





1-3°C Decadal-Scale Holocene Surface Cooling/Warming In the North Atlantic
In the subpolar North Atlantic, Holocene sea surface temperatures routinely rose and fell by 1°C to 3°C within a span of decades.
Berner et al., 2008  “Superimposed on general Holocene climate change is high-frequency [North Atlantic] SST [sea surface temperature] variability on the order of 1-3°C [during a ’10- to 50-year time resolution’].”

Modern Ocean Heat Content Changes So Minimal They Are “Below Detection”, While Holocene Ocean Temperature Changes Reached “>2 °C Within 200 Years”
According to Levitus et al. (2012), the global ocean heat content (0-2000 m layer) rose by a total of just 0.09°C during the 55 years between 1955 and 2010.   During the Holocene, temperatures in the 0-1000 m layer rose and/or fell by more than 2°C within 200 years, or 1°C per century.
Bova et al., 2016     “Rapid variations in deep ocean temperature detected in the Holocene … The observational record of deep-ocean variability is short, which makes it difficult to attribute the recent rise in deep ocean temperatures to anthropogenic forcing. Here, we test a new proxy – the oxygen isotopic signature of individual benthic foraminifera – to detect rapid (i.e. monthly to decadal) variations in deep ocean temperature and salinity in the sedimentary record. We apply this technique at 1000 m water depth in the Eastern Equatorial Pacific during seven 200-year Holocene intervals. Variability in foraminifer δ18O [water temperature proxy] over the past 200 years is below the detection limit [a change or variability in ocean heat cannot be detected in the past 200 years], but δ18O signatures from two mid-Holocene intervals indicate [natural, unforced] temperature swings >2 °C within 200 years.”
Between 80,000 and 20,000 Years Ago, Temperatures Rose By 10°C And More Within Decades Dozens Of Times
Referred to as Dansgaard-Oeschger (DO) events occurring during the last glacial (~80,000 to 20,000 years ago), global temperatures would rise by multiple degrees within decades about every 1,500 years, each time nearly reaching the modern interglacial’s warmth before gradually cooling back down over the course of centuries.  The amplitude of these explosive warming events reached 10 to 15°C in Greenland.   As usual, CO2 concentrations did not change during these abrupt warming/cooling episodes, as they remained flat and dangerously low at 180 to 190 ppm throughout the last glacial.  Scientists have concluded that  “DO events are part of the natural variability and not externally triggered” (Shao and Ditlevsen, 2016).
Sánchez et al., 2017      “The estimated increases in Greenland atmospheric temperature were 5–16°C [Capron et al., 2010] and the duration of the warming events between 10 to 200 years [Steffensen et al., 2008].”

Lohmann and Ditlevsen, 2018    “During the last glacial period, lasting from approximately 120 to 12 kya BP (thousands of years before present), a large number of abrupt large-scale climate changes have been recorded in Greenland ice cores and other Northern Hemisphere climate proxies. These so-called Dansgaard–Oeschger (DO) events (Dansgaard et al., 1993) are characterized by an abrupt warming of 10–15 K from cold conditions (stadials) to warmer conditions (interstadials) within a few decades. This is typically followed by gradual cooling, lasting centuries to thousands of years, until a more abrupt jump back to cold conditions is observed. … In conclusion, we show that the long-term variations in DO warming event frequency, often described as millennial climate activity, are consistent with a memory-less stationary random process. From the data at hand we cannot exclude the possibility that the long-term variations occurred by chance. If we however divide a DO cycle into two independent processes governing warming and cooling, this is not true anymore and significant time-varying structure is detected. We thus propose a model that incorporates long-term variations through forcing of the parameters with external climate factors. We find good agreement with the data in a model where the mean duration of interstadial phases of the DO cycle is controlled by global ice volume and the stadial phases by boreal summer insolation.”
Jensen et al., 2017     “The Dansgaard-Oeschger (DO) events of the last glacial are some of the most prominent climate variations known from the past. Ice cores from Greenland show multiple temperature excursions during the last glacial period as the climate over Greenland alternated between cold stadial (Greenland Stadial, GS), and warmer interstadial (Greenland Interstadial, GI) conditions with a period of roughly 1500 years (Grootes and Stuiver, 1997). Each DO-event is characterised by an initial temperature rise of 10±5 °C toward GI [Greenland Interstadial] conditions in a few decades, a more gradual cooling over the following several hundreds of years, and a relatively rapid temperature drop back to GS at the end of most of the events (Johnsen et al., 1992; Dansgaard et al., 1993; North-Greenland-Ice-Core-project members, 2004; Kindler et al., 2014).DO-events are manifested not only in Greenland, but around the world.”
Hewitt et al., 2016     “Many northern hemisphere climate records, particularly those from around the North Atlantic, show a series of rapid climate changes that recurred on centennial to millennial timescales throughout most of the last glacial period. These Dansgaard-Oeschger (D-O) sequences are observed most prominently in Greenland ice cores, although they havea global signature, including an out of phase Antarctic signal. They consist of warming jumps of order 10°C, occurring in typically 40 years, followed generally by a slow cooling (Greenland Interstadial, GI) lasting between a few centuries and a few millennia, and then a final rapid temperature drop into a cold Greenland Stadial (GS) that lasts for a similar period. … [S]teady changes in ice-sheet runoff, driven by the AMOC, lead to a naturally arising oscillator, in which the rapid warmings come about because the Arctic Ocean is starved of freshwater. The changing size of the ice sheets would have affected the magnitude and extent of runoff, and we suggest that this could provide a simple explanation for the absence of the events during interglacials and around the time of glacial maxima.”
Rasmussen et al., 2016  (press release)      “Extreme climate changes in the past Ice core records show that Greenland went through 25 extreme and abrupt climate changes during the last ice age some 20,000 to 70,000 years ago. In less than 50 years the air temperatures over Greenland could increase by 10 to 15 °C. However the warm periods were short; within a few centuries the frigid temperatures of the ice age returned. That kind of climate change would have been catastrophic for us today.  Ice core records from Antarctica also show climate changes in the same period, but they are more gradual, with less severe temperature swings.”
Jensen et al., 2016      “Proxy data suggests a large variability in the North Atlantic sea surface temperature (SST) and sea ice cover during the Dansgaard Oeschger (DO) events of the last glacial. However, the mechanisms behind these changes are still debated. … Based on our analysis, we suggest that the variability of the subpolar gyre during the analyzed DO event can be explained by internal variability of the climate system alone. Further research is needed to explain whether the lacking amplitude in the Nordic Seas is due to the model deficiencies or if external forcing or some feedback mechanisms could give rise to larger SST variability.”
Agosta and Compagnucci, 2016        “The climate in the North Atlantic Ocean during the Marine Isotope Stage 3 (MIS 3) —roughly between 80,000 years before present (B.P.) and 20,000 years B.P., within the last glacial period—is characterized by great instability, with opposing climate transitions including at least six colder Heinrich (H) events and fourteen warmer Dansgaard–Oeschger (D-O) events. …  During the D-O events, the high-latitude warming occurred abruptly (probably in decades to centuries), reaching temperatures close to interglacial conditions. Even though H and D-O events seemed to have been initiated in the North Atlantic Ocean, they had a global footprint. Global climate anomalies were consistent with a slowdown of AMOC and reduced ocean heat transport into the northern high latitudes.”
Olsen, 2016     “The most frequent abrupt stadial/interstadial changes retained from the marine sediments are known as Dansgaard-Oeschger (D-O) cycles, and appear every 1-2 kyr. These cycles are characterized by abrupt short-lived increase in temperatures (10 ± 5°C) followed by gradual cooling preceding the next rapid event. A second millennial scale feature detected in the sediments record is cooling events culminating significant iceberg discharges analogous to Heinrich events. Mechanisms triggering abrupt changes display uncertainties, but leading hypothesis is attributed to modifications in the Atlantic Meridional Overturning Circulation (AMOC) and deep-water formation initiated by freshwater input.”
Mayewski, 2016       “The demonstration using Greenland ice cores that abrupt shifts in climate, Dansgaard-Oeschger (D-O) events, existed during the last glacial period has had a transformational impact on our understanding of climate change in the naturally forced world. The demonstration that D-O events are globally distributed and that they operated during previous glacial periods has led to extensive research into the relative hemispheric timing and causes of these events. The emergence of civilization during our current interglacial, the Holocene, has been attributed to the “relative climate quiescence” of this period relative to the massive, abrupt shifts in climate that characterized glacial periods in the form of D-O events.”
Bogotá-A et al., 2016       “We reconstructed upper forest line (UFL) positions between ~2000 and ~3400 m elevation and the most abrupt temperature shifts ranged up to 10 °C/100 yr at Terminations II and III. Regional vegetation change is mainly driven by eccentricity (100 kyr) and obliquity (41 kyr) cycles, while changes in local aquatic vegetation show variability in the obliquity and precession (21 kyr) bands. Millennial-scale climate variability reflecting Dansgaard–Oeschger (DO) climate cycles in the upper part of the record, continues in this penultimate intergalcial–glacial cycle strongly suggesting that this variability has a persistent character in Pleistocene vegetation and climate dynamics.”
Shao and Ditlevsen, 2016       “The glacial climate is dominated by the strong multi-millennial Dansgaard–Oeschger (DO) events influencing the long-time correlation. However, by separately analysing the last glacial maximum lacking DO events, here we find the same scaling for that period as for the full glacial period. The unbroken scaling thus indicates that the DO events are part of the natural variability and not externally triggered.”
Lynch-Stieglitz, 2017     “Abrupt changes in climate have occurred in many locations around the globe over the last glacial cycle, with pronounced temperature swings on timescales of decades or less in the North Atlantic. The global pattern of these changes suggests that they reflect variability in the Atlantic meridional overturning circulation (AMOC). … In many locations in the Northern Hemisphere, abrupt changes in climate have occurred that span almost the full range of glacial to interglacial conditions, with the transition between climate states occurring in decades or less (Alley & Clark 1999, Voelker 2002). These abrupt climate changes are most clearly recorded in the climate records from glacial ice on Greenland (Andersen et al. 2004) and are referred to as DansgaardOeschger (D-O) events. The warm intervals are referred to as interstadials, and the cold intervals are referred to as stadials. … [T]he prevailing paradigm is that the abrupt climate changes are a result of changes in the northward transport of heat by the Atlantic meridional overturning circulation (AMOC) (Broecker et al. 1985, Clark et al. 2002, Rahmstorf 2002).”
Climate Modeling Rooted In CO2-Driven Temperature Change Cannot Reproduce This Variability 
In writing about the abrupt, global-scale climate changes during the 8.2 ka event that do not follow modeled expectations of an anthropogenically-driven modern climate, (Atwood et al., 2017) wrote:
“These events stretch our understanding of the dynamical principles that govern the climate system, given the lack of these events in the modern record and the inability of climate models to reproduce such variability.”   
Indeed, considering how profound past climate changes have been in the absence of CO2 fluctuations relative to the modest (0.05°C per decade) temperature changes of the last 150 years with pronounced CO2 rise, there does not appear to be a non-political justification for focusing our attention on CO2 as a driver of climate change.
Another abrupt global cooling event in line with the 8.2 ka or 4.2 ka may be in store for us in the coming decades.  And if it does happen, we will be powerless to stop it.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAnother new false-alarm paper reveals that coastal wetlands may not only persist well into the 21st century despite present rates of sea level rise, but the coasts may expand and even prosper due to the natural ability for soil to “build up vertically by sediment accretion”.  

Headline/image source: Sciencenews.org
“Coasts are growing all over the world”
Two years ago, a ground-breaking paper was published in the journal Nature Climate Change indicating that the Earth’s shorelines have been growing overall since the mid-1980s (Donchyts et al., 2016).
In other words, because “coasts are growing all over the world”, there is more land area above sea level today than there was 30 years ago.
This conclusion has again been confirmed by a new paper (Luijendijk et al., 2018) that indicates only 24% of the world’s beach shorelines are eroding, whereas 76% of the world’s beach shorelines are either growing (28%) or stable (48%).
Supposedly “vulnerable” Pacific islands are expanding 
Hisabayashi et al., 2018 found that 15 of 28 studied atoll islands in the southwest Pacific grew in shoreline area during 2005 to 2015.
Kench et al., 2018 examined “101 islands in Tuvalu over the past four decades (1971–2014)”, a period in which local sea level has risen at twice the global average.  They found a “land area increase in eight of nine atolls.”
“Surprisingly, we show that all islands have changed and that the dominant mode of change has been island expansion, which has increased the land area of the nation. … Using remotely sensed data, change is analysed over the past four decades, a period when local sea level has risen at twice the global average [<2 mm/yr-1] (~3.90 ± 0.4 mm.yr−1). Results highlight a net increase in land area in Tuvalu of 73.5 ha (2.9%), despite sea-level rise, and land area increase in eight of nine atolls.” (Kench et al., 2018)
Coastal marsh area has been stable or expanding


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Kirwan et al., 2016 reported that coastal marshes and their “vulnerable” ecosystems are not only persisting despite present-day sea level rise, coastal marsh area has generally been stable or expanding.
In fact, it was claimed that sea level rise rates of 10-50 mm/yr (1 to 5 meters per century) during the 21st century would not be substantial enough to submerge the globe’s coastal marshes.
“Coastal marshes are considered to be among the most valuable and vulnerable ecosystems on Earth, where the imminent loss of ecosystem services is a feared consequence of sea level rise. However, we show with a meta-analysis that global measurements of marsh elevation change indicate that marshes are generally building at rates similar to or exceeding historical sea level rise, and that process-based models predict survival under a wide range of future sea level scenarios. We argue that marsh vulnerability tends to be overstated because assessment methods often fail to consider biophysical feedback processes known to accelerate soil building with sea level rise, and the potential for marshes to migrate inland. … In summary, dynamic models of marsh vertical accretion indicate that marshes will generally survive relative SLR rates of 10–50 mm yr−1 during the twenty-first century, depending on tidal range and suspended sediment availability.” (Kirwan et al., 2016)
Coastal wetlands may not be threatened by sea level rise
Adding yet another layer to the strengthening conclusion that global sea levels aren’t rising fast enough to “spell doom” to “vulnerable” coastal ecosystems and communities, Schuerch et al. (2018) find that the natural ability of coastal wetlands to “build up vertically by sediment accretion” could potentially lead to “wetland gains of up to 60 per cent of the current area“.
More and more, scientists are undercutting alarmist proclamations of catastrophic 21st century sea level rise brought on by anthropogenic global warming.

“Rising sea levels don’t have to spell doom for the world’s coastal wetlands. A new study suggests salt marshes and other wetlands could accumulate soil quickly enough to avoid becoming fully submerged — if humans are willing to give them a little elbow room. … The new study builds on previous work that suggests rising seas will increase sediment buildup in some parts of coastal wetlands. This increased sediment, as well as human adaptations to allow wetlands to move inland as the seas rise, could allow the coastal fringes to not only survive but to increase their global area by as much as 60 percent.” (Sciencenews press release for Schuerch et al., 2018)

“On the basis of our simulations, we find that, globally, rather than losses, wetland gains of up to 60 per cent of the current area are possible, if more than 37 per cent (our upper estimate for current accommodation space) of coastal wetlands have sufficient accommodation space, and sediment supply remains at present levels.”
“[M]ost large-scale assessments have overestimated the vulnerability of coastal wetlands to SLR [present-day sea level rise]. These differences highlight a major knowledge gap in our understanding of the responses of coastal wetland areas to global environmental change. It has been argued that the reason for the observed discrepancy is that large-scale assessments have so far failed to consider the well understood biophysical feedback mechanisms that are typically included in local-scale models. These mechanisms include the ability of coastal wetlands to build up vertically by sediment accretion, which is enhanced with increasing inundation heights and frequencies, triggered, for example, by accelerating SLR [present-day sea level rise], and which enables coastal wetlands to persist or even prosper with SLR [present-day sea level rise].”
“[W]e project that until 2100, the loss of global coastal wetland area will range between 0 and 30 per cent, assuming no further accommodation space in addition to current levels. Our simulations suggest that the resilience of global wetlands is primarily driven by the availability of accommodation space, which is strongly influenced by the building of anthropogenic infrastructure in the coastal zone and such infrastructure is expected to change over the twenty-first century. Rather than being an inevitable consequence of global sea-level rise, our findings indicate that large-scale loss of coastal wetlands might be avoidable, if sufficient additional accommodation space can be created through careful nature-based adaptation solutions to coastal management.”
“[O]ur calibrated model, which includes mangroves as well as tidal salt and freshwater marshes, correctly predicts observations of present-day vertical wetland change, obtained from large meta-datasets from all over the world (Crosby et al., 2016; Kirwan et al., 2016; Lovelock et al., 2015), for 78% of all coastal areas where data are currently available (N=46).”
Share this...FacebookTwitter "
nan
"Big news from Lancashire in north England: the county council has rejected two planning applications to develop shale gas sites in recent days, the first in four years. Lancashire councillors’ decisions to reject planning applications by Cuadrilla at Roseacre Wood (June 25) and Little Plumpton (June 29) against the conditional approval of planning officers is a major blow for the industry. For reasons I will outline, though, it may not yet to lead to a national defeat.  The decision is unlikely to resolve any of the bigger and still outstanding public health issues surrounding unconventional gas extraction (as well as fracked shale gas, this also includes coal-bed methane and underground coal gasification). When it comes to the possible hazards, the scientific, regulatory and legal knowledge and opinion are both conflicting and conflicted. Such fears have led many communities, including a number of those in the relevant parts of Lancashire, to oppose fracking applications in their area. There is a growing scientific consensus that unconventional gas extraction in all its forms will contribute significantly to global climate change, which obviously has long-term public health effects. It might also cause water and air pollution, though industry voices disagree.  There are also fears about subsidence in coal-mining areas with a history of abandoned seams, and earthquakes, both of which have been played down by the government. Another concern is around mental health and well-being.  It doesn’t help that research on unconventional gas extraction has been heavily conflicted and fraught with evidence of substantial conflicts of interest in the US. Environmental groups and journalists have even coined the term “frackademia” to refer to universities winning contracts to undertake research for the companies involved.  The UK government has meanwhile insisted that the industry will be well regulated and that industry practice will be good. This is contrary to some research voices, while other governments have taken a very different view, with bans in Germany and France.  For their part, developers argue that unconventional gas extraction will be vital to meet our energy needs, at least in the medium term, as well as supplying feedstocks for the chemical industry and creating many jobs and prosperity for communities.  When it comes to developing policy for the industry, communities and activists argue that public-health considerations have been marginalised. The 2012 Royal Society report on unconventional gas extraction prepared by engineers and geologists contained no public-health experts in its working group and made minimal in-depth mention of public-health issues either.  A Scottish-government expert report published last year drew on this 2012 report and neither contained any experts on public health nor any independent experts on regulation or industry practice. Neither report learned from US failures to include public-health professionals either.  When agencies like Public Health England have reported on the prospects for unconventional gas extraction, they have tended to reflect the favourable assessments of these other bodies – as well as those of the UK government itself. The Public Health England report contained nothing on the wider public-health impacts via global climate change; nothing on socio-economic impacts, which have important health consequences; and nothing on work environments. These are serious gaps that need to be filled in.  American public-health professionals with practical experience of fracking said that claims in the report that the public-health problems related to the industry in the US such as poor regulation and bad industry practice would not apply in the UK were a “leap of faith unsubstantiated by scientific evidence”. They pointed out that the conclusions ignored the “inherent industry risks whatever regulation applies (casing failures, cement failures, waste and water spillage)” and argued the report overlooked the evidence about extra risks in heavily populated areas.  In this climate, decision-makers are being encouraged to turn a blind eye to the potential public-health issues. In Lancashire, for instance, newspaper reports suggest that the councillors were coming under pressure linked to the legal ramifications of approving and not approving the applications.  The impending Transatlantic Trade and Investment Partnership could make such considerations even more significant, if companies get the right to challenge local authorities or even governments over fracking bans. In this arena, public health risks being subordinated to company profits. Some planners have also suggested to me that local councils may in future not be able to consider any health factors in these decisions because they will be dealt with separately by regulatory agencies.  One other issue is also worth mentioning. The environmental statements that have to be included in all planning applications can contain narrow assessments of the potential health impacts of unconventional gas extraction. They ought to fully inform the planners about all the risks and benefits of the proposal.  They are not required to consider global climate-change issues, for instance, and have often focused just on noise and traffic. The quality and scope of the health-impact assessments in the US has varied a great deal – from the detailed and rigorous to the superficial. The assessments are also conducted by consultants who are mostly paid for by either interested companies or local authorities, which rarely if ever reach conclusions that conflict with the interests of who is paying. Community groups can rarely afford to pay for such reports.  Notwithstanding the Lancashire decisions, the challenge now facing the UK remains to ensure an independent, thorough, transparent and rigorous public-health impact assessment of unconventional gas extraction. This has to be conducted at national level, free of industry and commercial influences and capable of convincing the public of its lack of bias.  It should not rely on “theoretical solutions” but should draw on the best empirical evidence available, while acknowledging the potential shortcomings of the UK’s regulatory system. For many, it should rely on the precautionary principle against going ahead while there are uncertainties. That is arguably the only way to protect public health."
"
Share this...FacebookTwitterRecent research has emphasized that “critical mysteries remain” in our ability to quantify or even understand carbon cycle processes as they relate to Earth’s water bodies.  Observational constraints prevent the detection of an anthropogenic signal in ocean carbon uptake trends on decadal timescales (McKinley et al., 2017).  Many new papers even contradict the IPCC-endorsed conclusion that the oceans are a net sink for CO2 emission rather than a net natural source.  
The “We Had No Idea” Terrestrial Carbon Cycle
Since the mid-1980s, the Earth’s coasts and land area have been expanding (Donchyts et al., 2016), meaning there is more land mass above sea level today than there was three decades ago.  Sea level rise has not been rapid enough to keep pace with the natural shifts in Earth’s geological processes.
Net growth in global land and soil area could significantly affect the Earth’s carbon budget, especially since “Earth’s soil is releasing roughly nine times more carbon dioxide to the atmosphere than all human activities combined” (Carey et al., 2017).
Scientists frequently “discover” terrestrial locations that are new, unaccounted for sources of natural CO2 emission that “we had no idea” about.  They also routinely “discover” terrestrial surfaces that are deemed new CO2 net sinks that they never knew existed (Bastin et al., 2017).
Furthermore, scientists acknowledge that “the heterogeneous and sparsely measured terrestrial biosphere cannot be directly measured” (McKinley et al., 2017).
With new carbon sources and sinks “discovered” on a routine basis, as well as the very limited availability of direct measurements, why should there be any confidence that our land area carbon budget estimates are reliable?
Earth’s Water Bodies: “A Mechanistic Understanding of Carbon Sink Variability Requires Substantial Additional Elucidation”
Scientists have recently acknowledged that “critical mysteries remain” in ocean carbon uptake processes such that we lack a “detailed, quantitative, and mechanistic understanding of how the ocean carbon sink works” (McKinley et al., 2017).
Observational constraints do not even allow us to confirm that the alleged ocean carbon sink has been growing in recent decades due to anthropogenic emissions.

McKinley et al., 2017
“That the growth of the partial pressure of CO2 gas in the atmosphere ( pCO2 atm) drives a growing oceanic sink is consistent with our basic understanding that, as the globally averaged atmosphere-to-ocean pCO2 gradient increases, carbon accumulation in the ocean will occur at an increasing rate. This behavior has been illustrated clearly with models forced with only historically observed increases in pCO2 atm and no climate variability or change (Graven et al. 2012, Ciais et al. 2013). Nonetheless, critical mysteries remain and weigh heavily on our ability to quantify relationships between the perturbed global carbon cycle and climate change.”
“The current inability to accurately quantify the mean CO2 sink regionally or locally also suggests that present-day observational constraints are inadequate to support a detailed, quantitative, and mechanistic understanding of how the ocean carbon sink works and how it is responding to intensifying climate change. This lack of mechanistic understanding implies that our ability to model (Roy et al. 2011, Ciais et al. 2013, Frolicher et al. 2015, Randerson et al. 2015), and thus to project the future ocean carbon sink, including feedbacks caused by warming and other climate change, is seriously limited.”
“First, substantial uncertainty remains on the mean sink (∼30% of the total flux). Formally, the quantitative estimate of the 1980–1989 sink (−2.0 ± 0.7 Pg C y−1) is not statistically distinguishable from that for 2000–2009 (−2.3 ± 0.7 Pg C y−1). Reducing this uncertainty is absolutely critical to global partitioning of anthropogenic carbon sources and sinks. Each year, the Global Carbon Project (http://www.globalcarbonproject.org) estimates global sources and sinks of carbon, but because the heterogeneous and sparsely measured terrestrial biosphere cannot be directly measured, its flux is estimated by difference from estimated anthropogenic sources and the ocean sink (Le Quer´ e et al. 2015). In these budgets, land use change uncertainty is at least 50% of the mean flux, and uncertainty is growing for emissions from fossil fuel burning and cement manufacture (Ciais et al. 2013). Reduction in ocean sink uncertainty could therefore help to compensate from a global budgeting perspective.”
“The sum of the available evidence indicates that variability in the ocean carbon sink is significant and is driven primarily by physical processes of upwelling, convection, and advection. Despite evidence for a growing sink when globally integrated (Khatiwala et al. 2009, 2013; Ciais et al. 2013; DeVries 2014), this variability, combined with sparse sampling, means that it is not yet possible to directly confirm from surface observations that long-term growth in the oceanic sink is occurring.”
“Globally integrated variability fluctuates with ENSO. Yet, at regional scales outside the equatorial Pacific, these modes tend to explain less than 20% of the large-scale variance in pCO2 ocean and CO2 flux (McKinley et al. 2004, 2006; Breeden & McKinley 2016), indicating that much variance remains undescribed. Consistent with the limited amount of variance explained, the mechanistic connections of these modes are not well understood, except in the equatorial Pacific with ENSO. In the North Atlantic, a variety of studies have suggested a connection of the NAO and AMO to pCO2 ocean and CO2 fluxes, but whether these changes occur through convection or advection remains an open question. In the Southern Ocean, the SAM has been linked to pCO2 ocean and CO2 fluxes through impacts on wind-driven ventilation and subduction; however, since the mid-2000s, the clear relationship to SAM has substantially weakened (Fay & McKinley 2013, Landschutzer et al. 2015). In the North Pacific, the relative influence of the PDO ¨ as opposed to ENSO requires further study. Particularly as observations in the high latitudes have become more abundant, evidence has grown that climate modes do not adequately explain carbon cycle variability and that mechanistic understanding of carbon sink variability requires substantial additional elucidation.”
“[T]his CESM-LE analysis further illustrates that variability in CO2 flux is large and sufficient to prevent detection of anthropogenic trends in ocean carbon uptake on decadal timescales.”

The Earth’s Water Bodies: Net CO2 Source Or Sink?


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Observational analysis has indicated that water bodies release more of their stored CO2 as they warm and retain more of their stored CO2 as they cool.
This has been borne out in Mauna Loa CO2 records as they relate to a “warm water year” versus a “cold water year”.

Flohn (1982).
“The recent increase of the CO2-content of air varies distinctly from year to year, rather independent from the irregular annual increase of global CO2-production from fossil fuel and cement, which has since 1973 decreased from about 4.5 percent to 2.25 percent per year (Rotty 1981). … Indeed the cool upwelling water is not only rich in (anorganic) CO2 but also in nutrients and organisms. (algae) which consume much atmospheric CO2 in organic form, thus reducing the increase in atmospehreic CO2. Conversely the warm water of tropical oceans, with SST near 27°C, is barren, thus leading to a reduction of CO2 uptake by the ocean and greater increase of the CO2. … A crude estimate of these differences is demonstrated by the fact that during the period 1958-1974, the average CO2-increase within five selective years with prevailing cool water only 0.57 ppm/a, while during five years with prevailing warm water it was 1.11 ppm/a.  Thus in a a warm water year, more than one Gt (1015 g) carbon is additionally injected into the atmosphere, in comparison to a cold water year.”

The Intergovernmental Panel on Climate Change (IPCC) has nonetheless claimed the oceans are a net carbon sink  rather than a net source.
Recent research analysis has challenged this conclusion, including several new (2018) published papers.
Astor et al. (2013), for example, found that 72% of the attribution for the increase in CO2 emission for the studied region arose from warming sea temperatures, and thus they concluded “the ocean is primarily a source of CO2 to the atmosphere”.
A Partial List Of Papers Indicating Earth’s Water Bodies Are A Net Source Of CO2
Below is a very non-comprehensive compilation of 12 recently-published papers that challenge the IPCC conclusion that the oceans function as a net sink for CO2.
This list would appear to support the conclusion that “critical mysteries remain” in our ability to quantify or even understand carbon cycle processes as they relate to Earth’s water bodies.

Astor et al., 2013
“Based on these observations, 72% of the increase in fCO2 sea in Cariaco Basin between 1996 and 2008 can be attributed to an increasing temperature trend of surface waters, making this the primary factor controlling fugacity at this location. … An increase/decrease of 1°C is usually followed by an increase/decrease of 16–20 matm of fCO2sea. Thus, the SST increase of 1.3°C between 1996 and 2008 accounted for 16 matm increase in fCO2sea explaining around 72% of the fCO2sea observed variation. This suggests that the changes measured in fCO2 sea were primarily the result of surface-ocean warming in Cariaco Basin. … These observations confirm that this area is a consistent source of CO2 to the atmosphere. The main process controlling the long-term changes in surface fCO2sea at CARIACO was temperature, with net community production playing a secondary role. … At the CARIACO site, the ocean is primarily a source of CO2 to the atmosphere, except during strong upwelling events.”

Ikawa et al., 2013
“We estimated that the coastal area off Bodega Bay was likely an overall source of CO2 to the atmosphere based on the following conclusions: (1) the overall CO2 flux estimated from both eddy covariance and pCO2 measurements showed a source of CO2; (2) although the relaxation period during the 2008 measurements were favorable to CO2 uptake, CO2 flux during this period was still a slight source; (3) salinity and SST were found to be good predictors of the CO2 flux for both eddy covariance and pCO2 measurements, and 99% of the historical SST and salinity data available between 1988 and 2011 fell within the range of our observations in May–June 2007, August–September 2008 and November 2010–July~2011, which indicates that our data set was representative of the annual variations in the sea state. Based on the developed relationship between pCO2, SST and salinity, the study area between 1988 and 2011 was estimated to be an annual source of CO2 of ~ 35 mol C m−2 yr−1. The peak monthly CO2 flux of ~ 7 mol C m−2 month−1 accounted for almost 30% of the dissolved inorganic carbon in the surface mixed layer.”

Levy et al., 2013
“Although they are key components of the surface ocean carbon budget, physical processes inducing carbon fluxes across the mixed-layer base, i.e. subduction and obduction, have received much less attention than biological processes. Using a global model analysis of the pre-industrial ocean, physical carbon fluxes are quantified and compared to the other carbon fluxes through the surface mixed-layer, i.e. air-sea CO2 gas exchange and sedimentation of biogenic material. Model-based carbon obduction and subduction are evaluated against independent data-based estimates to the extent that was possible. We find that physical fluxes of DIC [Dissolved Inorganic Carbon] are two orders of magnitude larger than the other carbon fluxes and vary over the globe at smaller spatial scale. At temperate latitudes, the subduction of DIC and to a much lesser extent (<10%) the sinking of particles maintain CO2 undersaturation, whereas DIC is obducted back to the surface in the tropical band (75%) and Southern Ocean (25%). At the global scale, these two large counterbalancing fluxes of DIC [Dissolved Inorganic Carbon] amount to +275.5 PgC y−1 for the supply by obduction and -264.5 PgC y−1 for the removal by subduction [net +11.0 PgC y−1] which is ∼ 3 to 5 times larger than previous estimates.”

Reimer et al., 2013
“The study of air-sea CO2 fluxes (FCO2) in the coastal region is needed to better understand the processes which influence the direction and magnitude of FCO2 and to constrain the global carbon budget. The near-shore region was a weak annual net source of CO2 to the atmosphere (0.043 mol CO2 m-2 y-1); where 91% of the outgassed FCO2 was contributed during the upwelling season.”

Rutherford et al., 2016
“Continental shelves account for a large proportion of global primary production, and potentially a disproportionate fraction of the carbon dioxide (CO2) flux between atmosphere and ocean. The continental shelf pump hypothesis proposes that continental shelves at high latitudes act as net sinks of atmospheric CO2. However, direct measurements on the Scotian Shelf, off eastern Canada, indicate that this shelf region acts as a net source of CO2 to the atmosphere.”

Brown et al., 2015
“Complex oceanic circulation and air–sea interaction make the eastern tropical Pacific Ocean (ETPO) a highly variable source of CO2 to the atmosphere. … Inter-annual variability was observed within the region, with the location of the western extent of the freshpool moving westwards considerably between 2010 and 2014. Previous work within this region suggest that changes in thermocline depth related to ENSO are likely to influence pCO2 within this region. The region is a net contributor to atmospheric CO2, with average sea to air fluxes (over the four years of observations) of 1.6 mmolm−2d−1, with all regions of the ETPO outgassing year-round, except the rainfall diluted Gulf of Panama/Freshpool region.”

Xue et al., 2012
“Air–sea CO2 flux computations indicated that the NYS acted as a net CO2 source with respect to the atmosphere in each season, annually releasing 0.63 ± 0.10 mol C m− 2 to the atmosphere. In combination with the CO2 efflux rate (1.68 ± 0.33 mol C m− 2 yr− 1) reported in the southern Yellow Sea (SYS), we estimate that the entire Yellow Sea, including both the NYS and the SYS, was a net CO2 source at a rate of ~ 1.49 mol C m− 2 yr− 1, annually releasing ~ 6.78 Tg C to the atmosphere (1 Tg = 1012 g).”

Sisma-Ventura et al., 2017
“Seasonal pCO2 variability was studied in the Southeast Levantine (SE-Levantine) during 2009–2015 with the aim of quantifying air–sea CO2 fluxes in this ultra-oligotrophic, warm and highly evaporative marginal sea. Mixed layer pCO2 varied significantly between 560 ± 9.0 μatm in August (summer) and 350 ± 8.7 μatm in March (winter). Comparison of pCO2 to Sea Surface Temperature (SST) yielded a strong positive correlation (n = 135, r 2 = 0.94), suggesting that the seasonal variations are the result of a thermodynamic effect on the carbonate system in seawater. Using the coupling between pCO2 and SST, we calculated the mean monthly values and the air-sea fluxes in this region. These calculations indicated that this region is a net source of CO2 to the atmosphere over an annual cycle, with an average flux of 845 ± 270 mmol C m2 y−1 (~0.98 Tg C y−1 ).”

Biswas et al., 2018
“The era of global warming and increased emission of greenhouse gases can be marked by the beginning of the industrial age. It is also true that under several conditions, natural ecosystems can be equally responsible for CO2 emission like any other anthropogenic activities which continuously release heat-trapping gases in the process of development. … East Kolkata Wetland (EKW) is an urban or peri-urban wetland located on the outskirts of the Kolkata City which performs multi-facet activities, carbon sink being one of them. The raw waste from the city is naturally treated in this wetland system, however, the aquaculture ponds situated in these wetlands which make use of this waste water for fishery is rarely studied. The present study aims to see whether the aquaculture ponds of EKW complex are acting as a source or a sink. Airwater carbon dioxide (CO2) flux was estimated for three consecutive seasons in a year and it was found that the system is acting as a CO2 source in all the three seasons.”

Wang et al., 2018
“We conducted a free‐water mass balance‐based study to address the rate of metabolism and net carbon exchange for the tidal wetland and estuarine portion of the coastal ocean and the uncertainties associated with this approach were assessed. We measured open water diurnal O2 and dissolved inorganic carbon (DIC) dynamics seasonally in a salt marsh‐estuary in Georgia, U.S.A. with a focus on the marsh‐estuary linkage associated with tidal flooding. We observed that the overall estuarine system was a net source of CO2 to the atmosphere and coastal ocean and a net sink for oceanic and atmospheric O2.”

Li et al., 2018
“Our calculated CO2 areal fluxes were in the upper-level magnitude of published data, demonstrating the importance of mountainous rivers and streams as a global greenhouse gas source, and urgency for more detailed studies on CO2 degassing, to address a global data gap for these environments. …  Rivers have been widely reported to be supersaturated in carbon dioxide (CO2) with respect to the atmosphere, and are a net source of atmospheric CO2 (Butman and Raymond, 2011; Raymond et al., 2013).”

Rosentreter et al., 2018
“Although the overall status of mangroves [creeks] is net autotrophic (Alongi, 2002), mangrove sediments and waters have been shown to be a large source of CO2 to the atmosphere due to large organic matter inputs from diverse sources such as the mangrove biomass itself, other terrestrial detritus, nutrients from land, microphytobenthos, phytoplankton and the exchange of organic matter with the open ocean (Lekphet et al., 2005; Borges et al., 2005; Bouillon and Boschker, 2006; Kristensen et al., 2008). … The vast majority of mangrove CO2 gas exchange studies found surrounding waters were supersaturated in CO2 with respect to the atmosphere, hence, a net source of CO2.”
Share this...FacebookTwitter "
"A pine marten has been spotted in England recently, the first in more than 100 years. The reemergence of Britain’s second-rarest mammal, a cat-sized relative of badgers and weasels, is a great story in itself. But it may have another upside, as pine martens could be bad news for one of the UK’s least popular animals: the invasive grey squirrel. Unlike pine martens, grey squirrels are not native to Britain. These North American “aliens” were first introduced in the 1870s and soon made themselves at home. In the UK they are considered an invasive species – their “bark-stripping” harms the growth of new woodlands and has a big economic cost.  Grey squirrels’ success has also been to the detriment of the native red squirrel. Greys do not kill reds directly, but they do spread squirrel pox, a virus that causes distinctive ulcers on the reds’ eyes and nose, leading to death within a week. Grey squirrels themselves are unaffected – they’ve developed immunity.  Things are looking pretty dire for the UK’s red squirrels. Competition, disease and habitat loss mean that, if current grey squirrel control efforts were to stop, red squirrels would become extinct in Britain. I’m interested in how pine martens fit into this struggle. Habitat loss, hunting for fur and predator control by game keepers meant they became practically extinct in England and Wales. However in Scotland and Ireland they are making a comeback – and where they are returning, grey squirrels are disappearing. The impact in Ireland has been particularly notable. A four-year study I published in 2014 found pine marten recovery in the Irish midlands was linked to such a significant decline in grey squirrel numbers that the once beleaguered red squirrel population was able to recolonise its former range, including woodlands which had been dominated by greys for more than 30 years.   The study provided the first evidence for what foresters and gamekeepers had been saying for years – where pine martens had returned to healthy numbers, grey squirrels had all but disappeared. But in areas with few or no pine martens, grey squirrels persisted at “invasive” levels.   Red squirrels on the other hand have coexisted with pine martens throughout much of Europe for tens of thousands of years. The two species evolved together. While pine martens will very occasionally eat red squirrels, they don’t seem to have a negative impact on population numbers. In fact, in the Irish study, the areas that red squirrels had recolonised naturally were exclusively those with healthy pine marten populations. We do know that more pine martens in an area means fewer grey squirrels, but we don’t yet know if this is down to direct predation. It does happen though: the first evidence of a pine marten preying on the American grey squirrel was also recorded in Ireland in 2013, and we are now looking for evidence of this in the Scottish borders too.  Grey squirrels are larger and less agile than red squirrels and typically spend more of their time on the ground, making them an easier prey. However, having a healthy native predator around could also affect grey squirrels in various other ways: they might simply learn to avoid known pine marten areas, or they might spend less time on the ground foraging, leading to reduced fitness. Grey squirrels might even be suffering physiological effects such as stress-induced reproductive problems. Ultimately we need to determine whether the pine marten could act as a natural biological control for the grey squirrel in Britain and Ireland. That’s why I’m now looking at Scotland, where there have been reports of grey squirrel declines after pine marten recolonisation since the early 2000s. I want to know if the two processes are linked.  There are several subtle but potentially important differences between pine marten populations in the two countries that I’ll need to take into account – Scottish pine martens can feast on field voles, for instance, a rich food source that isn’t found in Ireland. Mass reintroduction of pine martens may be implausible but the creatures are moving south through Scotland and are literally just a few miles from the English border, so the process of natural recolonisation in England is almost underway. The recent sightings in Shropshire may even mean the remnant Welsh population is spreading into England too. It is important to remember pine martens are very slow breeders however, and it will take the recovering population quite some time to reach levels healthy enough to potentially impact on grey squirrel populations.  Predators are a vital part of a healthy ecosystem and predator prey interactions have an important function. What’s happening in Ireland and potentially Britain with squirrels and pine martens is a great example of how restoring natural predators can reduce the damage caused by invasive species. We are currently living in an unnaturally predator-poor environment, and it’s possible this has allowed some introduced species to reach “invasive” levels, which has ultimately wreaked havoc on our ecosystem.  Interaction between pine martens and squirrels is fascinating from a scientific point of view and we still have lots to learn. But you don’t have to be an ecologist to appreciate the value of promoting one of Britain’s most beautiful native species in order to preserve another."
"
Share this...FacebookTwitterTo keep informed on how the Atlantic hurricane season is developing, I find that hurricane expert Philip Klotzbach of the Colorado State University does a good job at that at Twitter.
A warmer planet does not mean more hurricanes
As the peak of the hurricane season approaches (September) he recently tweeted below average activity was forecast for the next two weeks:

Below-average Atlantic #hurricane activity predicted for the next two weeks (August 16-29) by @ColoradoStateU forecast team:https://t.co/xXojKUE6xE pic.twitter.com/DorPmJkoXC
— Philip Klotzbach (@philklotzbach) August 16, 2018

That’s good news, especially in light of the fact that global warming experts, who seem not to understand how hurricanes develop, warned that these Atlantic cyclones would keep getting more frequent and stronger. Data suggest this has been hardly the case.
Detrimental wind shear, cool sea surface temperatures
So what’s been keeping the lid on hurricanes in the tropical Atlantic development zone this year?
Klotzbach mainly points to two 2 factors: sea surface temperatures (SSTs) and vertical wind shear. A couple of days ago he tweeted that wind shear in the region has been “above average” and that this tends to “reduce hurricane activity”:

Latest output from the Climate Forecast System model calls for above-average vertical wind shear in the Caribbean and tropical Atlantic in September – the climatological peak of the Atlantic #hurricane season.  Strong shear reduces hurricane activity. @TropicalTidbits pic.twitter.com/sBt9mAmGIh
— Philip Klotzbach (@philklotzbach) August 14, 2018

Here Klotzbach even tweeted that vertical wind shear was “detrimental for hurricane formation.”
Shear 5th strongest since 1980


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




On August 10, the Colorado State University hurricane expert tweeted that wind shear had been at the 5th strongest in close to 40 years:

30-day-averaged shear in the Caribbean (10-20°N, 90-60°W) is the 5th strongest on record (since 1980).  Since 1980, the only years with stronger shear from July 10 – August 8 were: 1986, 1987, 1997 and 2015.  All of these were below-average Atlantic #hurricane seasons. pic.twitter.com/hm4bIdgVWK
— Philip Klotzbach (@philklotzbach) August 10, 2018

Mid August Tropical Atlantic surface temps cool
Although the tropical Atlantic surface has warmed up a bit, sea surface temperatures still remain cool there, which, according to Klotzbach, “for mid August are the coldest since 1994” and thus tend to suppress hurricane formation:

While there has been some recent anomalous warming, tropical Atlantic (10-20°N, 60-20°W) sea surface temperatures (SSTs) are still the coldest for mid August since 1994.  Cooler tropical Atlantic SSTs tend to suppress #hurricane formation. pic.twitter.com/6KJJgDtfjG
— Philip Klotzbach (@philklotzbach) August 13, 2018

Unfavorable peak season hurricane formation conditions 
Klotzbach sums up the forecast for the upcoming peak season in his tweet accompanying the first diagram above.
Latest output from the Climate Forecast System model calls for above-average vertical wind shear in the Caribbean and tropical Atlantic in September – the climatological peak of the Atlantic hurricane season. Strong shear reduces hurricane activity.”
Good news. But when it comes to weather, things can turn on a dime.
PS: Another great place for hurricane information is Tropical Tidbits.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterIn a new paper, scientists document another long-term cooling trend, this time in the North Atlantic’s sea surface temperatures.  Characterized as yet another stubborn “warming hole” in the anthropogenic “global” warming (AGW) narrative, the cooling trend amounts to “0.8 K century-1” and does not follow expectations outlined in models of  global-scale warming.

The portrayal of a globally-synchronous warming of the Earth with only small pockets of “warming hole” anomalies  is not supported by local and regional data reported in scientific papers.
In the Northern Hemisphere, for example, scientists (Kretschmer et al., 2018) have identified other “warming holes” in the temperature data for the 1990-2015 period.  About 80% of the contiguous U.S., Europe and much of Asia, including parts of the Arctic (Eastern Siberia), cooled during the 1990-2015 period, as shown here.
In the Southern Hemisphere, Antarctica has not warmed in the last 38 years.   And according to Purich et al., 2018, most of the Southern Ocean has been cooling since the late 1970s as well (as shown here).
There are not tiny, isolated holes of cooling in an otherwise uniformly-warming world.  These are gaping expanses of cooling…or non-warming.
Yes, some regions of the globe have been warming.  Some regions have been cooling.  And some regions remain trendless.
But in recent decades, the warming has not been global in scope.

Gervais et al., 2018
Mechanisms Governing the Development of the North Atlantic
Warming Hole in the CESM-LE Future Climate Simulations
“Recent studies have documented the development of a warming deficit in North Atlantic sea surface temperatures (SST) both in observations of the current climate (Rahmstorf et al. 2015; Drijfhout et al. 2012) and in future climate simulations (Drijfhout et al. 2012; Marshall et al. 2015; Woollings et al. 2012). This ‘North Atlantic warming hole’ (NAWH) is characterized in the observed record as a region south of Greenland with negative trends in SSTs of 0.8 K century-1 (Rahmstorf et al. 2015). In fully coupled global climate model (GCM) future simulations, the NAWH is seen as a significant deficit in warming within the North Atlantic subpolar gyre (Marshall et al. 2015; Winton et al. 2013; Gervais et al. 2016).  This local reduction in future warming is communicated to the overlying atmosphere and may impact atmospheric circulation (Gervais et al. 2016), including the North Atlantic storm track (Woollings et al. 2012).”

5 Other New Papers Also Document A Warming “Hole” In the North Atlantic

Grieman et al., 2018



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





2. Nicolle et al., 2018

3.  Thornalley et al., 2018

4. Smeed et al., 2018

5. Piecuch et al., 2017
 
Share this...FacebookTwitter "
"Senior government ministers have sought to distance themselves from conservative Liberal MP Craig Kelly who sparked controversy by telling UK television there was no link between climate change and Australia’s bushfire crisis. Kelly, a longstanding critic of climate change action, was lambasted as a “denier” and “disgraceful” by the conservative British commentator Piers Morgan and the meteorologist Laura Tobin in a combative interview on ITV overnight. He had earlier spoken to the BBC to claim that there was “no link” between climate change and Australia’s crippling drought, pegging blame for the bushfire crisis that has so far claimed 25 lives and destroyed almost 2,000 homes on a lack of hazard reduction. Asked about Kelly’s remarks, Treasurer Josh Frydenberg said the government’s view was that climate change was causing hotter, drier summers, while agreeing that fuel load was a contributing factor to the bushfires. “Our view of climate change is that it’s real. We accept the science,” Frydenberg said. Minister for the drought, David Littleproud, who has previously questioned whether climate change is being caused by human activity, also criticised Kelly’s remarks as a “sideshow”.“He doesn’t represent the views of the government,” Littleproud said. “I couldn’t give a rats what he said, it’s irrelevant, let’s just focus on those people that are out there that need our help.” Opposition leader Anthony Albanese said his reaction to Kelly’s comments was one of “despair”. “Despair not just that Craig Kelly has those views and continues to advocate them, not just here in Australia, but globally, and be seen to be representing the Australian government’s position, but the knowledge that he’s one of the people who has held back action,” Albanese said. “He’s one of the people who has stopped action on climate change domestically, which has led us to be in a position whereby we’re actually, as well, arguing for less action internationally, rather than more.” “The tragedy is that he’s imposed those views along with a few others to ensure that Australia isn’t taking action.” Labor’s shadow infrastructure minister Catherine King suggested Kelly had been put up for the interview by the government, saying it was “beyond embarrassing”. “I did @BBCRadio4 against him Sunday. The producer said they had asked for a senior government rep and this is who @ScottMorrisonMP thought was the best person to represent his government,” King said on Twitter. But a spokesman for the Coalition said “the suggestion was fanciful” that Kelly had been put forward to represent the views of the government, and Kelly told Guardian Australia he had not spoken to the prime minister’s office before agreeing to the interview request. Kelly had told ITV that the cause of the fire crisis was high fuel loads and the drought, and there was no evidence that climate change was causing Australia’s climate to warm. “This is a terrible disaster, this is one of our nation’s worst natural disasters, and in the past when we have these in our nation we all sat back and did what we could to fix it up, rather than people getting out there and scoring political points and that is what’s happening now,” he told ITV’s Good Morning Britain. “To try to make out as some politicians have to hijack this debate, exploit this tragedy and push their ideological barrow, that somehow or another the Australian government could have done something by reducing its carbon emissions that would have reduced these bushfires is just complete nonsense,” Kelly said. Morgan savaged Kelly for his remarks, saying he was taking a “nothing to see here, nothing to worry about” approach as “your entire country is eviscerated by fires”. “You are facing now one of the greatest crises you have ever faced, and there is you Mr Kelly, with respect, a senior politician who still doesn’t think this has anything to do with a heating-up planet,” Morgan said. Tobin accused Kelly of denying the science which showed that 2019 was Australia’s hottest and driest year on record. “At the moment we want everyone to commit in the world to be one and a half degrees to lower our global temperature rise,” Tobin said. “You can’t even commit to two degrees. “You have the second highest carbon emissions per person on Earth and you are burying your head in the sand. You aren’t a climate sceptic, you are a climate denier,” she said. Cutting off the interview, Morgan said: “I’ve got to say: wake up. Wake up. Climate change and global warming are real and Australia right now is showing the entire world just how devastating it is. “And for senior politicians in Australia to still pretend there’s no connection is absolutely disgraceful.” Kelly also used the interview to defend Scott Morrison for taking a holiday to Hawaii during the bushfire crisis, saying the management of fires was primarily the states’ responsibility. The remarks came after the conservative backbencher appeared on the BBC on Saturday, claiming that there was no link between climate change and Australia’s drought. “There is no link, the facts that cause the fires are the drought and the drying of the environment,” Kelly said. “On this, climate scientists down here have been very clear and they have said there is no link between drought and climate change.” “People here in Australia understand – if they look at the evidence and look at the signs – there is nothing that we can do here in Australia by sending billions more off to China to buy solar panels to replace our coal-fired electricity generators,” he said. “That is not going to change the weather here in Australia one iota and is not going to stop one bushfire.” Speaking on ABC’s Radio National on Tuesday morning, Kelly doubled down on the remarks, saying Morgan did “not want to hear the facts” and arguing that hazard reduction was more important than taking action on climate change. He said people were exploiting the bushfire tragedy “for ideology”, and the cause of the fires was “the dryness of the atmosphere and the landscape”, while rejecting suggestions that the Coalition was home to a group of denialist MPs. “There is no denialist cult,” Kelly said. He also referred to Tobin as a “weather girl” who “had no idea what she was talking about”. “She says the Australia continent is drying out and that is just not true.” Tobin responded to the criticism on Twitter on Tuesday morning, pointing to her degree in physics and meteorology, and her four years’ experience as an aviation forecaster at the Royal Air Force. Yes I’m a Meteorologist-A degree in Physics & Meteorology-4 yrs as an aviation forecaster at the RAF-12 yrs as a broadcast meteorologist-Attended a @WMO Climate course last year & upto date with all the science #NotAWeatherGirl #IKnowWhatImTalkingAbout#DoYou?#ClimateChange https://t.co/fvwTpzftTI The remarks come as Morrison defends the government’s climate change policy, while stressing there is “no dispute” in Australia about the impact of global warming on Australia’s climate. “I have seen a number of people suggest that somehow the government does not make this connection,” the prime minister said. “The government I lead has always made that connection and that has never been in dispute.” Kelly, who established the Parliamentary Friends of Coal Exports for likeminded MPs, has been a longstanding internal critic of government attempts to reduce carbon emissions, and was a vocal critic of the former prime minister Malcolm Turnbull’s attempt to introduce a national energy policy. He has also argued against any government investment into renewable energy, calling for subsidies for households and businesses to be scrapped. After Morrison became leader, Kelly was told to rein in media appearances, particularly on Sky News, where he had become a frequent guest of conservative commentators. Kelly has twice had his preselection threatened but in 2016 Turnbull intervened to prevent a moderate challenging him for the seat of Hughes, and before the 2019 election Morrison also moved to ensure his incumbency was protected."
"It is week nine of the current bushfire crisis; almost 20 people are dead, over 1,000 homes have been lost, half a billion animals have been killed and a land area twice the size of Belgium has been burned. Countless lives have been affected and we know there is more to come. The most important thing right now is to protect as much life and property as possible.  But looking beyond the immediate crisis, we need to start an honest discussion about something none of us want to admit – that these unprecedented, catastrophic fires may indeed mark the beginning of Australia’s new normal. As the world and Australia fail to make meaningful reductions in greenhouse gas emissions, it is clear that we are entering the next phase of climate change – that is, increasingly frequent and severe weather events, occurring in places that have never been affected before. It’s a scary and confronting reality to reckon with; perhaps that’s why some of us find it easier to write off scientists and bushfire survivors speaking hard truths as part of a “climate cult”. Thankfully, our emergency services have chosen not to shy away from the truth, preparing themselves for a horror summer while knowing that they did not have enough personnel, volunteers, equipment or funding to deal with the scale of the crisis. Influential figures in our financial system have also confronted the issue head-on. With worsening extreme weather events sending premiums soaring to the point that some regions are effectively uninsurable, the insurance industry is reviewing whether traditional insurance models can remain tenable. Meanwhile, banks such as NAB are developing “resilience investment” products to assist local governments to build infrastructure such as emergency centres and seawalls. This is encouraging, given the scale of the work needed to ensure local food, energy, water, transportation and communications systems can withstand extreme and prolonged weather events and recover quickly with minimal external assistance. But while some are facing the crisis, there has been a glaring lack of leadership from the federal government on a coordinated plan to support the growing numbers of families, business owners and communities affected by extreme weather. The announcement by the prime minister of a new National Bushfire Recovery Agency and a $2bn package to assist those affected by the bushfire crisis is a step in the right direction. But focusing on relief for this crisis alone misses the bigger picture – this is not a one-off event. We can no longer afford to react to each emergency by drawing on national and state budgets in an ad hoc way. What will happen when the next cyclone hits? Or the next major flood event? And what about the worsening drought? As increasing numbers of people become displaced from regions that are no longer inhabitable, there is an inescapable need for a systematic approach to not only disaster preparation and recovery, but also to building more climate-resilient regions. And to do this, we need much more than reactive measures from government that are propped up by generous donations from the public. Without a doubt, adaptation will be expensive. But not as expensive as the cost of inaction. Of course the billion-dollar question remains: where will the money come from? An obvious place to start the search is at the doorstep of the industry that is the most responsible for climate change: the fossil fuel industry. It is unconscionable that as Australia burns, the taxpayer subsidises this industry to the tune of $1,728 per person per year. What if instead we channelled the $41.8bn worth of fossil fuel subsidies into a transitions fund, to support not only disaster preparedness and relief, but also workers and communities to transition to new jobs and industries? A second option is found in the Australia Institute’s calls for a national climate disaster fund to be established. The Australia Institute’s modelling shows that a levy of $1 per tonne of embodied emissions from all coal, oil and gas mined in Australia would raise approximately $1.5bn per year. Both approaches would go a long way towards addressing the needs of the victims of this climate crisis, while also stopping it from getting worse in the future. What is notable about both approaches is that they place the primary responsibility for funding recovery and adaptation efforts on our elected leaders and the public purse. This crucial process, which will determine our future safety and wellbeing, should not be left to private, debt-driven investment or market forces. To be sure, there is a debate to be had about how much of the cost of climate resilience should be public versus privately funded. Getting the balance right is critical, but we already have existing models such as the Clean Energy Finance Corporation to turn to for inspiration. But however we fund it, the one truth that cuts through the (literal) smoke and mirrors is the fact that we need careful, long-term planning and coordination to ensure that we invest in the systems we need to keep our people, planet and economies safe even as Australia is battered by worsening climate impacts. If our government can show some leadership by listening to the experts and working with different industries to find a way forward, maybe we will come to see climate adaptation as less of a cost and more of an investment in a liveable future. Dr Amanda Cahill is the chief executive of the Next Economy and is an associate at the University of Queensland and the Sydney Policy Lab"
"
Share this...FacebookTwitterCharlatans exposed…when sham predictions clash with reality
Yesterday Japanese blogger Kirye prepared a chart (below) depicting Arctic sea ice volume since 2006, the year Al Gore’s Inconvenient Truth (AIT) was released, and just a year or two before a spate of ice-free-Arctic-by-2013 (or earlier) predictions were issued by a number of “experts”, which of course the fake news media lapped up.

Source: Japanese skeptic blogger Kirye.
Arctic did the opposite of what the experts forecast
As Kirye’s chart above shows, Arctic sea ice volume in reality has since increased since all the doomsday predictions of 10 years ago. The very opposite of what was confidently predicted has in fact taken place.
Same level as in the 1930s, when CO2 was far lower
Naturally the alarmists like using the sea ice extent chart that goes back to 1979, which shows a clear downward trend because 1979 was at a peak for Arctic sea ice.
However, when we look at charts depicting Arctic sea ice since 1900, we see that today’s Arctic sea ice situation is in fact similar to what we experienced some 80-90 years ago:

Chart: Alekseev et al, 2016. 
A false prediction is a false prediction


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




That Arctic sea ice has declined significantly since about 1970 is not the point here. The real story is all the bold predictions of an ice-free Arctic that were made at the time just after AIT was released, and how they all failed resoundingly.
To illustrate the point very clearly, I used Kirye’s plot and added those expert’s predictions so we can see how they all fare compared to reality:

Total failure of the ten-year forecasts made by “experts”. 
Even 10-year forecasts are total failures – can we trust 50-year forecasts?
These “experts” couldn’t even get the forecast for the next 10 years correct. So how are we supposed to take them seriously with their “robust” climate forecasts for the next 20, 50 or 100 years?
The latest idiotic, charlatan quality prediction comes from hockey-stick maker and climate-alarm hustler Dr. Michael Mann, who recently said that Trump’s legacy, beginning in 2024, will be “a charred planet”.
Glaring failure needs to be followed by swift firings
In private industries, where forecasts really count, persons with such a track record of undisputed glaring failure would have been given the boot long ago, and in many cases even sued for outright fraud.
The death spirals and ice-free Arctic predicted for 2013 to 2018 never came to pass. And by ice-free, they implied this would be the case in the later summer year after year.
It’s time for NASA and other climate institutes to clean house and re-staff with serious, competent scientists. As a taxpayer I’m fed up with all the garbage, nonsense and local climate ambulance chasing they’ve been giving us year after year. We the people have the right to get something of value for our money.
And it’s high time we start thinking about suing for fraud.
Share this...FacebookTwitter "
"Ordinary citizens have become increasingly important to scientific research over the past decade. Today, mobile phone technologies, relatively cheap cameras and almost ubiquitous internet connectivity have opened up new opportunities for conservation organisations to engage with ordinary citizens and encourage citizen science.  A citizen scientist is a volunteer who collects and/or processes data as part of a scientific enquiry. This could mean noting the plants found on a day trip or more systematically recording wildlife in a special area. While citizen science projects can be in any branch of science, my focus is on wildlife research. The list of citizen science projects is long. This year’s BBC Springwatch, which concludes this week, has highlighted a number of mass participation projects in which people can become involved, such as recording the first signs of spring. All such schemes are predicated on the idea that people will go out and report what they see. But technological advances are also changing the way that professional scientists collect and record data on animals. These changes often require specialised equipment and resources beyond the scope of most amateurs. Now that new technologies are changing the working practices of professional ecologists, what does this mean for citizen science? Until recently, the way to ascertain the presence of great crested newts in a pond was to go and look. Because the newt is a protected species, disturbing it is illegal. But just looking for the adults or their eggs is not. Today, however, finding great crested newts and other aquatic animals can be done using environmental DNA (eDNA). DNA is released into the water by plants and animals in a host of ways: from their skin, faeces, mucous, hair, eggs and sperm, or when they die. By simply collecting and analysing a water sample from the pond or stream, we can find traces of eDNA and identify the animals living there, even if they are hard to recognise.  DNA barcoding allows species to be identified using short genetic markers in an organism’s DNA.  And actually, these barcodes can be obtained from tiny amounts of tissue even by non-specialists. All that is required is the correct DNA processing and sequencing technology.   Genetic identification is not the only way in which technological advancement is changing the way that we record the species around us. Noting the birds in a woodland is more often than not a case of listening and identifying the songs rather than seeing the birds themselves. Eco-acoustics or soundscape ecology studies the relationships between animals and their environment based on sound. There are now technologies available that allow birds and amphibian communities to be identified from sound recordings. This means that it will soon be possible to place an audio recorder in the field and walk away while it records birdsong and other sounds over an extended period of time. The aim is that the recordings can be analysed automatically using software to draw up a species list for that area. But if the collection of wildlife data is to reveal useful information, it needs to be done systematically. Recording the presence of a wildlife species only tells you that it was there at the time that it was recorded. To spot trends, the recording needs to be repeated in the same way over a number of years. This can be difficult when relying on volunteers, but it is not impossible and there are many good examples of systematic surveys, but these are mainly carried out by people with a little more than basic knowledge. In fact, technology is now progressing to the point that it can do the work of a specialist on behalf of any citizen, helping to standardise measurements and carry out complex analysis instead of just simple observations. For example, a new app enables visitors to the New Forest to search for cicadas - last sighted in the forest in 2000 - by analysing sound recordings of background noise captured with a mobile phone. It’s not hard to imagine similar projects asking people to collect and study samples of eDNA or make regular recordings of the dawn chorus using easily available tools. Mass recording of wildlife sightings such as those requested by the BBC and the Mammal Society are not simply about recording wildlife for scientific enquiry. They are about individuals, couples and families going outside, exploring and connecting with their environment. Discovering what is there and being part of a larger group of people. It is about making new discoveries together.  But with new technologies, the details of citizen science will change. Future technological advances will present new ways to continue our long established heritage of amateur natural history."
"The average carbon dioxide emissions of cars sold in the UK rose for the third year in a row during 2019 as falling diesel sales and the rising popularity of SUVs dealt a blow to Britain’s hopes of reaching climate targets. Average CO2 emissions rose for the third year in a row, up 2.7% year on year to 127.9g of CO2 per kilometre, according to data from the car industry body. This is far above the newly introduced EU target of 95g per kilometre carmakers need to achieve over this year and next for all new cars. Cars account for just over 18% of UK emissions, according to government figures. Transport emissions as a whole account for a third of the UK total, with the sector viewed as vital contributor if the country is to achieve goals of cutting emissions to 51% of 1990 levels by 2025 and to reach net zero by 2050. All manufacturers selling in the EU are rushing to meet emissions regulations that came into force on 1 January. The regulations were introduced in response to the climate crisis, with road transport a major contributor to global CO2 emissions. Overall UK car sales fell by 2.4% year on year to about 2.3m, according to the Society of Motor Manufacturers and Traders, with the industry body blaming Brexit uncertainty and the slump in diesel sales as the main factors. This indicates the worst year for the UK market since 2013, when sales were 2.26m. They reached a peak of 2.7m in 2016 but have declined steadily since. A quarter of the CO2 increase was caused by the 21.8% drop in diesel sales over the year. Newer diesels on average have lower CO2 emissions than petrol cars, despite a backlash prompted by air quality concerns. Another quarter was caused by increased sales of SUVs, which are often heavier and have much worse aerodynamic profiles than smaller cars. Increased fuel use by SUVs was the second largest contributor to the increase in global CO2 emissions from 2010 to 2018, according to the International Energy Agency. The other half of the headline CO2 increase was caused by a change to testing standards. Mike Hawes, the SMMT chief executive, acknowledged the CO2 figures showed the challenge facing the industry. He said: “The step change that is required is significant.” Under the EU regulations, carmakers face fines potentially running into billions of euros across the UK and the rest of Europe if they surpass individual limits designed to ensure that average fleet emissions hit the 95g target.  One bright spot in an otherwise declining market was the rapid increase in sales of battery electric vehicles, which have zero CO2 tailpipe emissions, and hybrid vehicles, which combine an internal combustion engine with a battery-powered motor. Annual sales of alternatively fuelled vehicles rose by 20.6% to a record market share of 7.4%. That was driven by the surge in battery electric sales, which were up by 144%. However, sales of battery electric vehicles would need to rise from the 1.6% market share for 2019 to 27% to hit the 95g target alone, according to the SMMT’s calculations. Hawes repeated his industry’s plea for a post-Brexit trade deal that preserves frictionless trade between the EU and the UK, and that prevents the imposition of tariffs. He added that Brexit uncertainty remained his number one fear for the industry. “Undoubtedly consumer confidence around our big-ticket items is weak,” said Hawes, speaking at a briefing in London before the publication of the final figures."
"
Share this...FacebookTwitterA wave of media hysteria has been unleashed by the recent hot and dry “Sahara” weather Europe has seen over the past few weeks. Cries to shut down the coal power plants and to adopt vegan diets have reached peak volume!
ARD Fake News: “CO2 causing lung disease”
The neurosis has gotten so bad, that flagship German media have been reporting new breath-taking claims.
For example Germany’s version of the BBC ARD German public television, here claimed that CO2 is not only “killing the climate”, but is also even “causes lung disease”!
NBC’s Al Roker: Warming now causing less hurricanes!
In the US, NBC meteorologist Al Roker here did have some good news: Global warming is now causing less hurricanes (and not more): The melting Arctic ice is cooling the Atlantic, which works against the formation of hurricanes, he claimed.
Unfortunately that “information” from Mr. Roker has turned out to be really fake. Expert meteorologist Dr. Ryan Maue even called Roker’s outlandish claim “cringeworthy”.
“Not heat problem, rather hysteria problem”
But among the cacophony of hysteria emanating from the global fake news construct, there have been a few remaining voices of sanity – fortunately.
For example journalist/lead commentator Torsten Krauel of Germany’s flag ship national daily Die Welt here wrote an opinion piece titled: “Germany doesn’t have a heat problem, rather it has a hysteria problem.
In the opinion piece Krauel writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




There have been many hot summers, as well as rainy cool ones. Germany does not have a heat problem, and a look at the past shows this.”
Krauel then reminds the amnesia-prone German readers of the hot spells of the 1990s, or 2006, 1983, 1975, 1963 and 1958 as examples, where periods of heat and/or extreme drought also occurred.
Indeed according to Swiss meteorologist Jörg Kachelmann, July 2006 was much warmer than July 2018, by 2°C.
Going vegan our only hope
Die Welt’s Krauel adds with sarcasm:
But over 2018 in some places they complain like end-of world preachers. It is the largest anomaly since records have been kept. Water will be in short supply, Sea level is rising. Become a vegan, otherwise it will continue like this.”
Cold front erases the hysteria
In the meantime, a cold front has passed through the continent, thus dislodging the blocking high behind the unusually summerlike weather which many had been enjoying.
Central European temperatures today as of 1 p.m. ranged only from the low sixties to low seventies Fahrenheit.

Chart: Kachelmannwetter.de
It won’t be long before we start hearing complaints about all the cool and damp weather and longings for summer.
Share this...FacebookTwitter "
"Lemurs are cute – there is no denying it. Their big eyes and fluffy faces mean they really are the poster animals of Madagascar, an island known internationally for its unique flora and fauna. But the plight of Madagascar’s lemurs has made international headlines once again after experts warned the animals may be entirely extinct in the wild within 25 years.  The BBC showed gorgeous images of lemurs juxtaposed with the sad fact that nearly all of the 106 identified species of lemur are threatened. These stories appear in the international media with depressing frequency. Those not closely involved might wonder why, if lemurs are so special, they have not been properly protected yet. Surely Madagascar can’t afford to lose its lemurs and the world can’t just stand by and watch it happen?  Unfortunately, conservation is far from easy to achieve. The problems facing lemurs in Madagascar are a microcosm of the challenges of tropical forest conservation throughout the world. Madagascar’s forests and their lemurs are primarily threatened by agriculture. We are often told that Madagascar has lost 90% of its forest, and that rural people clearing land for agriculture are the problem.  Unfortunately, like many things, the truth is rather more complex. This narrative underplays the role of colonial era and commercial land conversion, and overplays the destructive nature of the traditional land use system.  Malagasy farmers traditionally cut then burn patches of forest and farm them for a few years, before leaving the land fallow to regain fertility. This isn’t a story of terrible people destroying their lovely pristine forest – such “shifting agriculture” (known locally as tavy) can be perfectly sustainable at low population densities. Pressure comes from Madagascar’s booming population. As the numbers living in rural areas increase, people clear the same land more frequently, soil fertility drops and the land becomes degraded and of little use for either agriculture or lemurs.  Deforestation also releases carbon dioxide into the atmosphere, contributing to climate change (in fact many would be surprised to know that land use change is the source of between 7% and 14% of the world’s emissions of greenhouse gases). With this in mind, it seems that forest conservation really should be a no brainer: it is good for the planet, good for biodiversity (remember those lovely lemurs) and, since shifting cultivation can be unsustainable anyway, people would be better off doing something else.   This is the thinking that underpins the proposed international climate mechanism REDD+ (Reducing Emissions from Deforestation and Degradation), in which poor tropical countries such as Madagascar get financial incentives to reduce their deforestation and so contribute to global efforts to slow climate change. So would REDD+ finally solve the problems of tropical forest conservation (and save those lemurs)? Unfortunately many challenges remain. A significant one is how the funds will be used to actually slow deforestation? In Madagascar the funds from REDD+ pilot projects have been used in part to fund community forest management: where legal management responsibility for forests is transferred to communities. Recent research from Madagascar provides some evidence that this can indeed slow deforestation but it is far from a panacea. A review of community forest management interventions around the world found there is limited evidence that the approach can deliver the hoped-for environmental, or local welfare, benefits.  To be successful, any project aiming to reduce deforestation will need to ensure that farmers at the edge of the forest do not lose out. This is vital both from a pragmatic perspective (if people don’t have alternatives they will have no option but to continue with existing land-use practices, however damaging) and from the perspective of environmental justice and human rights.  Key questions remain about how benefits from REDD+ payments will be distributed locally – the question of whether resources will be sufficient to compensate for lost livelihoods – and how the rights of those affected will be protected. There has been recent criticism that international commitments to these social safeguards in the REDD+ mechanism are too weak. Bruno Ramamonjisoa, a professor of forestry at the University of Antananarivo in Madagascar told me that: “Madagascar’s lemurs, and their forests, are a vital part of our natural heritage. However, forest conservation in Madagascar will only be successful if the people dependent on forests, and their needs, are fully incorporated into conservation plans. Those developing the REDD+ policies must understand the real challenges facing forest-edge communities in Madagascar”.  It is expected that REDD+ will be approved at the major climate summit in Paris later this year and this may well unlock funds for forest conservation in Madagascar in future. However the threats to lemurs will not be easily solved – and the real threats to people sharing habitat with lemurs, must not be ignored."
"We’ve all seen reports on TV: queues round the block, makeshift camps, furtive checking of watches, and the rapturous applause on the opening of the doors. Such is the clamour for new “must-have” technology. While I admire the leaps forward in mobile technology we’ve witnessed in the last decade, this rush for new devices is having a devastating effect on the environment. We must acknowledge this and deal with the problem if we are to continue to enjoy our planet as much as we do our new mobile lifestyles. Although individual phones are small, containing relatively little material, collectively the numbers are substantial. There are at least an estimated 85 million unused phones in the UK alone, each manufactured using gold, copper, silver and other precious metals which, if not recycled, must be extracted from the ground.  This adds up. These unused phones contain approximately four tonnes of gold, lost resource that would cost £110m and an equivalent of 84,000 tonnes of CO2 released into the atmosphere to replace. It is even estimated that phones contain more gold per tonne than ore mined from South Africa’s famous mines. My colleague Jacquetta Lee and I recently published research in the International Journal of Life Cycle Assessment, focused on the environmental impact throughout the lifecycle of mobile devices, from manufacture, use and disposal. We concluded that the current mobile phone business model, driven by volume of sales and frequent upgrade cycles, is costing the environment. The problem occurs when the upgrade cycle is shorter than the phone’s useful lifetime. Although mooted to be three years or more, phones are often replaced much sooner. Many are replaced through “free” contract upgrades. That itself would not be such an issue if they were returned for reuse or recycling. But consumers are wedded to the ability to communicate, so they often keep the replaced phone as a spare in case the new one breaks or is lost. It hibernates and languishes there until it is truly obsolete, when it has no value for communication or monetary worth for resale. Recycling metals from phones is currently not a profitable business, so there is little incentive to return the phone. All too often it can end up in landfill; the metals are lost and must be replaced by mining virgin ore. Given that the majority of a phone’s environmental impact occurs during manufacturing there is strong incentive to reduce the number of phones made each year, extend their working lifetime and if possible make them less complex. It needs a new business model, and there may be an alternative. We are now looking in to the possible benefits of a “cloud-based product service system”. Here, the heavy processing and memory storage of mobile devices are moved to a remote server, over the internet. With less need for powerful components, mobile devices could be less complex, designed to last longer and require less valuable resources to make.  The consumer buys the ability to communicate and access to the powerful processing of the server. This is accessed by a handset leased to them by the service provider. That provider then has incentive to ensure the device is used for an appropriate length of time before being returned for a new one. The valuable metals are recovered and components could be reused. This cloud model has been used already in the PC world, where replacing power-hungry desktops with thin client computers that run off the cloud, with less hardware, has reduced power consumption by up to 55%. But there are of course other challenges to overcome.  We need to work out how to implement such business models whilst convincing consumers that cloud services can be trusted to deliver high performance, and hold data privately and securely. Are you ready to move your phone’s entire photo collection into the cloud? In the meantime more work needs to be done to encourage recycling. From discussions with companies involved in phone returns, it is apparent that often even sending a prepaid envelope to the consumer for the old phone, to be dropped into the nearest letter box, is not incentive enough.  Recycling may be encouraged by something as intangible as benefit to the environment, but that is a low incentive at present. It will become large enough when the environmental value of recycling the phone translates into the price of the metals in them becoming high. It’s a big question and one that will not be answered easily. What is encouraging however is that manufacturers are acutely aware of the issues and open to ideas for change. In the meantime consumers need to face reality; that our lifestyles do not exist in a bubble. The choices we make now will affect our planet sooner than we realise and at some point the bubble will burst."
"
Share this...FacebookTwitterAerial photos show that the 15 temperature observation stations the JMA is using to determine mean temperature anomalies are likely impacted far more by urbanization than the agency claims.
By Kirye
and P. Gosselin
According to the Japanese Meteorological Agency (JMA) here, as of 2018, 15 observation stations are used to gather data to calculate surface temperature anomalies.
The 15 sites are Abashiri, Nemuro, Suttsu, Yamagata, Ishinomaki, Fushiki, Iida, Choshi, Sakai, Hamada, Hikone, Miyazaki, Tadotsu, Naze and Ishigakijima. Here’s a table of these stations from NASA:

NASA is using only 7 of these stations (marked). Many of these 15 stations used by the JMA have a high BI value, meaning they are heavily impacted by urbanization. 
An earlier document issued by the JMA stated that the agency had used 17 stations, see Table 1.2.3. Today they are using 15.
JMA selection criteria: “relatively small” urbanization influence 
The JMA says the criteria for selecting the 15 weather observation sites are: they have a long observation period and the influence of urbanization is “relatively small” and “not biased by a particular region”.
What follows is a location plot of the 15 JMA observation stations scattered across Japan:

How “relatively small” is the urbanization really?
To find out more about the siting quality of the stations, Kirye used Google Earth to locate the stations.
What follows are Google Earth photos of their location. You will see that the JMA’s description “relative small” influence of urbanization is quite an understatement.
It’s urban warming, and not global warming!
Many stations are in fact dubiously surrounded by massively heat-absorbing structures. Keep in mind the pinpoint location shown could be off by some meters.

Abashiri is in the middle of buildings and streets.
 

Choshi is also found in a densely built up area, which would tend to really heat up in the summer.
 

Fushiki observation station is somewhat better sited, with more green vegetation in the area, yet much temperature distorting paved surfaces are nearby.
 

Hamada station is also becoming increasingly choked off by urbanization.
 

Hikone is right in the middle asphalt and buildings. We can only wonder how much all the air conditioners around are heating up temperature readings in the summertime? This is urban warming, and not global warming!
 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Iida station. Wow! Hardly any green vegetation in sight, so the area must really heat up in the summertime sun, and keep things warm late into the evenings.
 

Miyazaki station. Japan loves concrete and asphalt. So little room for vegetation. Expect the green fields to go in the years ahead.
 

Ishinomaki station. Everywhere heat-absorbing buildings and asphalt streets that boost the readings.
 

Naze. NASA assigns it a BI of 0, meaning as rural as could be. Maybe the reason for this is because Naze is on an island in the middle of the ocean. But here we see the station is in the middle of a city.
 

Nemuro station is also surrounded by buildings, concrete, steel and asphalt. Perhaps the Google Earth marker is not so exact and so the station is in the field to the right. Still, lots buildings and hot asphalt around.
 

Sakai station has some green areas around it, but still great urban influences at work.
 

Suttsu, only the second station considered by NASA to be “rural” is so only on one side! If the wind blows from the forest to the west, then the readings will be more accurate.
 

Tadotsu is a terribly sited stations, due to obvious reasons. The whole place is a giant heat sink!
 

Yamagata, the last of the 15 stations JMA uses, is also completely surrounded by heat absorbing asphalt, concrete, steel and buildings.
What can we conclude?
Little wonder that global temps shot up just after 1990 when NASA stopped using so many stations worldwide, and seemed to focus more on those sited in urban environments.
Arguably the JMA’s claim of a “relatively small” influence from urbanization is an understatement of multiple degrees.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterGermany has seriously overestimated how much its neighboring countries are able to help out in the event wind and solar energy fail to deliver, thus putting it’s power supply at risk.
One of Germany’s strategies for making its energy supply renewable is to rely on its neighbors to step up when green energies fail to deliver.
As the country adds more volatile wind and solar energy to the grid, Germany hopes that neighboring countries will cooperate in helping to stabilize the power grid in the event the wind doesn’t blow and the sun doesn’t shine — especially after the country shuts down its remaining nuclear power plants and starts to shut down old coal plants. Nuclear and coal power make up the lion’s share of Germany’s stable baseload power supply.
“A dangerous miscalculation”
However, it appears German officials have made a major miscalculation: citing a recent study, journalist Daniel Wetzel at Die Welt writes: “Europe cannot bail out the German power supply. This is so because “hardly a neighboring country has any remaining extra power plant capacity.” The Die Welt economics journalist then calls the German strategy “a dangerous miscalculation.”
In 2014 the German Ministry of Economics assumed the country could rely on 60 gigawatts of over-capacity in related adjacent markets in Europe, but it turns out that the figure was overstated by a factor of 3 to 4. Consequently on windless and sunless days, Germany could end up missing considerable amounts of power.
Wetzel writes:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




As a result, soon all over Europe power stations with ‘secured power’ that can produce independently of current wind and sun conditions will be missing.”
He also adds that as every European country strives to add more wind and solar capacity, more of their baseload capacity plants are being shut down as well, which only makes the situation increasingly worse when sun and wind do not show up. The point is rapidly coming where there will not be sufficient baseload capacity to keep the grid stable.
One solution, Wetzel suggests, would be to install gas-fired power generators so that they could be fired up in times of low wind and solar output: “However, new gas-fired plants are being built nowhere because refinancing under the conditions of the Energiewende appears as being too risky,” Wetzel reports.
In a nutshell, as Europe expands its wind and solar capacity, more baseload capacity will be needed. But instead of adding it, Europe is reducing it, and thus making the supply and grid stability worse.
As for Germany, it is increasingly dawning on politicians that designing energy infrastructure is best left technical and electrical engineering experts, and not to climate -catastrophe obsessed politicians and green activists who seem to think such complex systems can be built up ad hoc as you go.
The price of this slipshod politicized approach could wind up being very painful in the midterm future.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter
Guest post by Kirye in Tokyo
An analysis of the rural-sited Japanese weather stations used by the Japanese Meteorological Agency (JMA) shows there’s been no warming at all over the the past 2 decades or more.
Strangely many of these stations, which are practically unimpacted by data-corruptive urban sprawl, are no longer used by NASA.
For example, NASA quit using the rural Fukaura station back in 1990. Up to that point Fukaura was cooling notably. What follows is the NASA chart for Fukaura:

Fukaura showed cooling before NASA dropped the station in 1990. Image: NASA
The same, for example, is true for Nikko.
NASA dropped rural Japanese stations
What follows below is a list of the rural stations I examined, which have a Brightness Index (BI) of 10 or less. The far right column shows the period they were used by NASA.

Source: NASA.
My earlier enquiries about stations sent to NASA via the Internet went without any answer. Perhaps they don’t reply to foreign requests. I don’t know.
The next chart below is the geographical plot of these rural sited stations. As you see they are all well scattered across the country:

Google Earth map showing location of the rural stations.
JMA data in fact show no warming
What follows below are temperature charts for each station, using the data from the JMA, arranged in more or less alphabetical order. On some charts I plotted more than one station.
Over 90% of rural stations show cooling or no trend
Of the 24 stations plotted, 22 show no change or some modest cooling over the past two or more decades – that’s more than 90%. Only two stations show some warming, but only a very modest amount.

Aburatsu data, Ushibuka data
 

Data Aikawa here. Oshima here. Katsuura here. Miyakejima here.
 

Akune data, Makurazaki data
 

 Fukaura here.
 

Fukue data, Yakushima data
 

Hachijojima data.
 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Data Irozaki
 

Miyama data. Note: NASA has never used Miyama’s temperature data, but the rural area in Kyoto Pref is also a slight cooling trend.
 

Murotomisaki data
 

Naze data
 

Nikko data here.
 

Shionomisaki data,

Sukumo data
 

Suttsu data
 

Tanegashima data
 

Okinoerabu data, Minamidatojima data, Kumejima data, Yonagunijima data
 
Japan shows no warming over past 2 decades
What follows next is the chart for all of Japan for the last 20 years, using data from the JMA:

As the chart above shows, using JMA data, the whole country of Japan shows no warming over the past two decades.
Urban environment
Tony Heller at Real Science here shows the environment that many Japanese weather stations – like the ones NASA use – find themselves having to deal with. 
But as the temperature chart for all of Japan mentioned above shows, even the urban heat island effect still is unable to produce warming over the past 20 years. Without the cities one could rightfully argue there would be a cooling trend.
=====================================================
Follow Kirye at Twitter.
Share this...FacebookTwitter "
"The G7 leaders’ pledge to eliminate the use of fossil fuels as an energy source by century’s end could be the most significant outcome of the most recent meeting. It also reinforces German host Angela Merkel’s claim to be the “climate chancellor”. As is customary with such pledges, however, the announcement was short on specifics and it’s really not clear how reductions in fossil fuel usage can be achieved.  After all, disasters at Chernobyl in 1986 and Fukushima in 2011 have made key G7 members considerably less enthusiastic about nuclear power, one obvious alternative. Both Germany and Japan have crucial roles to play over the coming decades in facing up to these challenges. It was Merkel’s Germany that decided in the wake of Fukushima to abandon nuclear power by 2020. Under an aggressive 50% expansion in renewables since then, in 2014 German fossil fuel consumption had fallen to an historic 35 year low. But what about Japan? After Fukushima the country initially shut down all its nuclear plants. However, since then successive pro-nuclear governments have tried to restart its reactors, in part to reduce the spiralling financial and environmental costs of the resulting sharp increase in oil, gas and coal imports. Japan is now the world’s second biggest importer of fossil fuels after China and the world’s fifth largest emitter of CO2. Despite efforts to restart the nuclear programme, all 43 operable reactors remain in shut-down mode due to public unease. Even the scheduled restart for Sendai No. 1 plant in Kyushu has been delayed until August due to technical difficulties. Hence the question the country faces is not whether it should restart its nuclear plants, but whether it can do so in the face of public fears of another earthquake or tsunami. Those fears are real. Evidence suggests that Japan may have experienced at least 22 tsunamis higher than 10m. Moreover, Japan has experienced the highest density of 8+ magnitude earthquakes in the world since modern records began in 1900. Within the coming decades seismologists expect powerful undersea earthquakes of the type that occurred off northeastern Japan in 2011 along the Nankai trough to the south of Honshu, Shikoku, and Kyushu. This would threaten the huge Hamaoka nuclear power plant, located roughly equidistant between the population centres of Nagoya and Tokyo-Yokohama. As recently as the 1970s just 3% of Japan’s electricity came from nuclear power. Since then, however, governments have nurtured nuclear under the assumption that the country lacks domestic energy resources and is vulnerable to overseas political volatility. In the intervening period Japan, like many other countries, has become addicted to oil.  While Japan might not sit on huge oilfields, the idea it lacks domestic energy potential is false. It has abundant geothermal energy, for instance, as the local macaque monkeys know well. Japan mostly receives 1,800 – 2,100 hours of sunshine per year, more than solar-friendly Germany, and at a similar latitude to sunny Spain. The country also has some of the most plentiful wind, tidal, and wave energy resources in Asia due to its mountainous island and marine geography. Despite this the state has invested huge sums in developing nuclear power while, according to former prime minister Naoto Kan, the electric power companies have treated renewables as a “nuisance”. This treatment appears to be continuing, even as local small-scale, or distributed, solar energy is catching on thanks to new feed-in tariffs which reward renewable generation. At first regional energy companies integrated this energy into the main grid but this has slowed; one provider, Kyushu Electric Power, has stopped accepting applications from renewable suppliers, stating that the company can’t cope with the destabilisation to their systems. Japan had intended to reduce fossil fuel dependence by building 14 new nuclear reactors, under the then-government’s 2010 Basic Energy Plan. These new reactors would have raised the nuclear share of electricity from 29% in 2011 to 50% by 2030, and its share of Japan’s primary energy mix from 10% to 24%.  But Fukushima consigned that plan to the dustbin, and the country has yet to develop a credible alternative that will satisfy the country’s energy demand while simultaneously matching pledges to reduce and, now, eliminate fossil fuel usage. In the near-term Japan faces huge obstacles in meeting its G7 targets for reducing fossil fuel usage. Over the longer term, the situation looks less bleak. Fertility levels far below the replacement rate means the country’s population is shrinking and some local authorities are developing smart compact cities in response, which should accelerate as depopulation deepens. Japan also possesses deep technological and economic resources to draw on in delivering solutions to the big questions of the 21st century. Once regional energy providers are able to absorb local solar and geothermal energy, the potential for renewables will rapidly expand. Japan faces perhaps the toughest 21st century energy challenges of the G7 states. Can it simultaneously address safety and environmental concerns by replacing nuclear and fossil fuel energy usage with renewables? It is in the resolution of this problem that Germany may be able to lend a hand."
"In 1997-98, extremely dry El Niño conditions in Indonesia kicked off a wave of large–scale uncontrolled burning, destroying about five million hectares of tropical forest (equivalent to seven million football fields).  Much of the burning occurred in carbon-rich peatland forests and continued in two phases from July 1997 until March 1998, releasing vast amounts of carbon dioxide into the atmosphere, and huge clouds of smoke and haze across the region.  Present conditions in the Pacific Ocean are similar to what they were in mid-1997.  El Niño is set to strengthen, and seasonal weather prediction models point towards this being an exceptionally dry season. Indonesia and its neighbours should be worried. In order to predict, and hopefully prevent, such fires in the future, we’ve looked at how far in advance they can be anticipated using a seasonal weather prediction model. During the dry season, numerous fires occur in Indonesia’s peatland forests, particularly in the southern region of Kalimantan and eastern Sumatra.  Although some rain falls during a normal dry season, it is sporadic, leaving many windows of opportunity for burning.   Most of these fires are deliberately lit to clear rainforest to establish oil palm and Acacia pulp and paper plantations. Fire spread is enhanced by the increased availability  of combustible material, notably, woody debris as a result of wasteful logging practices, and the widespread practice of draining peatlands. When El Niño strikes, however, the situation changes drastically.  During strong El Niño episodes, almost no rain falls during the dry season and the monsoon is delayed.  So in areas where peatlands have been degraded by logging and draining, fires ignite easily and once started, the peat is so dry that fires escape underground, and cannot be put out until after the monsoon reappears.   At their worst, the fires have enormous impacts on carbon emissions, regional haze production, biodiversity, and the economy, and are recognised as a serious health risk in Indonesia as well as neighbouring Singapore and Malaysia. The fires are a major threat to the remaining orangutans who live in the forests – the Bornean orangutan is rated endangered, and the Sumatran orangutan is critically endangered. During past El Niño years, around one gigatonne of carbon was emitted from peatland forest fires, equivalent to about 10% of annual global fossil fuel emissions, and regional haze from such fires has caused major disruptions to air traffic in nearby Singapore and Kuala Lumpur.  Sea surface temperatures from the vast array of sea buoys established across the Pacific Ocean plus other important meteorological data are now telling us that El Niño conditions are already in place.  Furthermore, most seasonal weather prediction models, which are driven by observed SSTs, predict El Niño will strengthen over the coming months.  This means the upcoming dry season in Indonesia will probably be much drier than usual, and the fires worse. 


Probability rainfall forecasts for Asia for the periods: June-July-August 2015 (top) and September-October-November 2015 (bottom).
Author providedInternational Research Institute (IRI)

 The regional haze problem has become so serious in recent years that the Singapore government passed the Trans-boundary Haze Pollution Act in 2014.  This act financially penalises companies listed on the Singapore stock exchange deemed responsible for smoke-haze affecting the city-state but originating elsewhere.  The governments of the ten ASEAN member states signed the ASEAN Agreement on Trans-boundary Haze Pollution on 10 June 2002, which Indonesia finally ratified in September 2014.  The agreement requires all states to implement measures to prevent, monitor and mitigate trans-boundary haze pollution by controlling peat land and forest fires.  It makes explicit mention of the development of an early fire warning system to help prevent and mitigate major haze events.  Since burning is opportunistic, it can happen as soon as conditions will allow it.  Research since the 1997 haze disaster has given us a fairly reliable understanding of how dry conditions must be in order for severe fires to happen. But by the time these conditions occur, burning has already started, fires have escaped, and it is too late for prevention.  Dry conditions instead need to be forecast weeks to months in advance for any prevention to be effective.  Up until now, the forecasting component has been missing. We wanted to see if past fires, especially severe El Niño-influenced fires, could have been predicted using seasonal weather forecasts.  Using satellite observations of fire activity and the case study region of southern-central Kalimantan, which is characterised by a June-November dry season, we demonstrated that most of the severe fires (and associated haze) since 1997 could have been anticipated using rainfall predictions from the European Centre for Medium-Range Weather Forecasts seasonal weather prediction model.  A second part of our work confirmed a clear link between severe fires and massive forest loss (also estimated from satellite data). Our findings were recently published in the journal Natural Hazards and Earth System Science. The implication of our work is that regional weather services, fire-fighting and resource management agencies are potentially able to identify areas that are likely to be dangerously dry ahead of time.  Preventing severe uncontrolled burning in Indonesia and associated impacts will ultimately depend on how well fire is managed.  This is a complex problem involving governments, multinational companies and indigenous people. Nonetheless, knowing ahead of time about a potentially bad fire situation will no doubt form part of the final answer.   While seasonal predictions are not perfect, and occasionally a year may turn out differently to what was expected, seasonal forecasts are anticipated to continue to show improved skill in future. The challenge remains to build on these advances to create an Indonesia-wide early fire warning system for operational use."
nan
"
Share this...FacebookTwitterAccelerating sea level rise due to global warming is supposed to eat away at the shorelines across the globe. However a recent paper published in the journal Nature here authored by a team scientists led by Arjen Luijendijk found that some 75% of the world’s sandy shorelines are stable or growing!
An analysis of satellite-derived shoreline data indicates that 24% of the world’s sandy beaches are eroding at rates exceeding 0.5 m/yr, but 28% are accreting and 48% are stable.
Also erosion rates exceed 5 m/yr along 4% of the sandy shoreline and are greater than 10 m/yr for 2% of the global sandy shoreline.
Image source: Luijendijk et al., 2018
According to the paper, the application of an automated shoreline detection method to the sandy shorelines resulted in a global dataset of shoreline change rates for the 33 year period 1984–2016.
The scientists also found that Australia and Africa are the only continents for which net erosion (−0.20 m/yr and −0.07 m/yr respectively) is found, with all other continents showing net accretion.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




What’s surprising is that another researcher has determined that melting ice caps from global warming induced ice melt does not contribute to sea level rise, and that sea level rise is mostly caused by the Earth’s shape.
 3 mm/yr sea level rise “definitely a conjecture”
In a scientific paper published by the journal Geoscience Frontiers, Aftab Alam Khan at the Department of Geology, University of Dhaka in Bangladesh found: “thermal expansion only explains part (about 0.4 mm/yr) of the 1.8 mm/yr observed sea level rise of the past few decades.” and that the claim and prediction of 3 mm/yr rise of sea-level due to global warming and polar ice-melt “is definitely a conjecture”
He added that the prediction of 4–6.6 ft sea level rise in the next 91 years between 2009 and 2100 is “highly erroneous”!
Khan then concludes that though global warming, both polar and terrestrial ice melts, and climate change might be a reality, all these phenomena are not related to sea level rise and fall.
Ice melt would not contribute to sea level rise
According to Khan, “Geophysical shape of the earth is the fundamental component of the global sea level distribution. Global warming and ice-melt, although a reality, would not contribute to sea-level rise.”
If Kahn’s assertion turns out to be correct, then IPCC scientists will have some major scientific revamping to do.
Share this...FacebookTwitter "
"The war on wildlife crime is taking a new technology-driven direction. Rhinos are being fitted with GPS trackers, heart rate monitors and spy cameras – all embedded within their horns. These small but high-tech devices could be a game changer for anti-poaching efforts in Africa.  That’s the claim of conservation group We Are Protect, whose Real-time Anti Poaching Intelligence Devices (RAPID) have completed proof-of-concept trials on black rhinos in South Africa. The project now aims to move forward to field testing. Here’s how it works. The unit is fitted within the horn of a wild rhino – a painless operation as their horns are made of keratin, just like human nails or hair – and data is then relayed live to a centralised control centre which could be many miles away. If the animal’s heart rate suddenly becomes heightened or declines, this triggers immediate analysis of the in-horn camera footage (at HQ) while an armed anti-poaching team scrambles on a rapid response mission to intercept the poachers at the location provided.  The original impetus for RAPID came from the inability of teams on the ground to detect poaching quickly and effectively enough to catch the poachers and prevent the horn reaching the illegal markets. However, the reality is that we want to stop poaching happening in the first place. We want to save the rhino, not just its horn.  To achieve this goal RAPID should operate as a deterrent, not just an arrest mechanism. This has raised the question of whether RAPID-tagged rhinos should ‘“advertise” that they are carrying the device. But that could simply drive poachers to target untagged rhino. So, in order to achieve the aim of the project, to render poaching a “pointless exercise”, we need all individual rhinos to be fitted with RAPID and tagged to indicate so. That sounds expensive and it is not clear who would foot the bill. Footage giving us a rhino’s eye (or rather a rhino horn’s) view of the world is fascinating and should attract support. However, advanced publicity for this anti-poaching game changer may encourage poachers into a frenzy of killings before it is widely adopted. One South African game reserve saw a similar killing spree shortly before some of its rhinos were due to be dehorned. Let’s hope that the project receives sufficient financial backing to facilitate a comprehensive and speedy roll-out on the ground. If that is the case, then RAPID could be a really progressive step in the continuing war against wildlife crime. We badly need a practical and positive development. Despite growing concern, and increasingly desperate conservation actions, poaching continues to increase and rhino populations continue to decline, year-on-year. South Africa, which houses the core global populations of white and black rhinoceros, has already lost 749 rhinos to poaching this year, on course to match last year’s record 1,215 (itself a 9,000-fold increase from 2007).  Meanwhile, the remnant population of the northern white rhino continues its sad and apparently inevitable decline to extinction. It has dropped to a genetic cliff-edge with the recent death of Nabire meaning only four geriatric individuals survive in the world. The northern white rhino may be dead on its feet, but RAPID offers hope for other species. The We Are Protect team is already looking beyond rhino, and aims to expand the use of RAPID to other endangered creatures under attack from poachers, including elephants and tigers.  We need to throw everything we have, from all angles, at wildlife crime. If we cannot save iconic species like rhinos, elephants, and tigers it does not bode well for the less celebrated animals out there that are also suffering."
nan
"Fishermen can’t win. The harder they work, the more successful they are, the more they are apparently despised. Take Scotland, for instance, where the EU (heavily influenced by well-financed NGO lobby groups) is attempting to exclude fishermen from large areas of the sea off the west coast that they may have fished for generations.  Most fishermen agree with conservationists that there is a need to protect deep-sea coral and other vulnerable ecosystems far beneath the waves. Fishing for species that live close to the sea bed, known as demersal fish, involves dragging a trawl over the sea floor which can disturb or bury other species found nearby.  These ecosystems can struggle to recover, especially if they are trawled regularly and aren’t used to being disturbed naturally. Many deep-sea species such as the orange roughy (Hoplostethus atlanticus) are extremely long lived, slow growing and have low rates of reproduction – some conservation organisations feel they should not be targeted at all. With agreement over the basic need for protection, the argument is instead over what rules should be applied. The EU and some fisheries managers would like to impose a blanket ban on fishing below 600m. The fishing industry argues this would protect areas that don’t need it and leave the sea above 600m vulnerable to increased efforts of fishing boats squeezed into a more limited area. The EU’s case was apparently given a “scientific basis” by a recent academic paper which argued for a blanket ban based on the idea biodiversity is greater below 600m, despite the fact that (as its authors acknowledge) fishing has had no noticeable impact on deep-sea biodiversity and despite the fact they used data from 1989 through to 2013 without analysing trends over time.   Perhaps the greatest fault in the paper is its use of data from scientific or pseudo-commercial nets rather than data from fishing boats. The authors then equate the results of scientific trawls with likely commercial catches. However fishermen don’t fish scientifically (or they would quickly go out of business); they fish in order to catch a particular species and to minimise discard rates. The particular fishery off the Scottish coast discussed in the paper has shrunk significantly since 2002. The boats still fishing are using much less destructive gear with larger mesh sizes and lighter ground gear that doesn’t impact on the seabed as much. To analyse deep-sea fisheries using some data which is almost 40 years out of date and then try to draw a conclusion that could have major economic implications on an important part of the fishing industry seems ambitious to say the least. The EU needs to think about who it listens to first – fishermen who have a vested interest in the renewal of their stocks, or NGOs who live for the next foundation, corporate or governmental handout? The deep-sea fishing industry, in fact the whole fishing industry, deserves some criticism for past actions that were wasteful and sometimes had an almost criminal disregard for the environment. Discard rates in some early trawl fisheries reached 80% and between 1992-2001 bottom trawling accounted for about 36% of global discards. But it is worth remembering that in the EU the quantity of discards were a product of management measures.  The industry is now focused on how it can sensibly deal with the forthcoming European “landings obligation” that will eliminate discards, requiring from 2019 fishermen to land everything that they catch, even if they do not have by-catch quota.  Well-resourced marine protected areas that have specific goals and measurable outcomes will be key, as conservationists hope fish will prosper in the protected areas and thus spill over into the “unprotected” sea. However it is ironic that, if protected areas are successful, it will become even more difficult for fishermen to comply with the discard ban and avoid catching fish for which they have no quota. This is one of the reasons we need highly-selective fishing gear, tailored to each boat and target species. We also need to expand consumer tastes to make otherwise discarded fish such as Baird’s slickhead a valuable commodity.  It’s a fact that catching fish takes fish out of the sea and that this has an impact on the environment. Yet wild-caught fish are free from additives, have been “reared” as nature intended and are generally an incredibly healthy foodstuff. It is also a fact that wild-caught fish are less costly in terms of carbon budget than pork or beef. And, unlike some sectors of the farming and aquaculture industries, wild fishing doesn’t depend on intensive doping with antibiotics, the gross simplification of habitats, or animals reared in intensive care wards.   We have to make choices – and I for one will choose wild-caught fish over farmed beef, salmon, chicken or pork every time. This article was amended on September 29, 2015 to remove a potential misrepresentation."
nan
"Europe’s weather systems tend to cross the Atlantic and slam into Britain, which should make the UK ideal for wind power. With very low running costs, cheap and easy integration into the grid in most of the country, and with wind being a mature industry that’s still evolving continuous improvements, how could it not be the country’s cheapest renewable?  Just look at the alternatives. There’s not that much hydro to be harnessed. Tide and wave power aren’t yet ready. Geothermal? This isn’t Iceland, not many volcanoes here. Straightforward, then? No, it never is. The government has announced it is to end subsidies for onshore windfarms from April 2016, a year earlier than expected. When asked about the decision to withdraw support from a growing industry, the Secretary of State for Energy and Climate Change, Amber Rudd, claimed solar energy is just as cost-effective as onshore wind. And that’s half-true: it has come down in price so far, so fast, that solar farms are bidding for deals as cheaply as some onshore wind farms.  Then again, this government also prefers more costly rooftop installations to solar farms. Anyway, solar and wind are complementary, not direct substitutes, with windfarms generally generating more power in winter.  Onshore wind is often more expensive than it needs to be in this country. Sure, 
some onshore wind in Britain is not only the cheapest renewable there is, it’s the cheapest electricity we’ve got from any source, once insurance, pollution and all the other costs are factored in. However quite a few planned UK onshore windfarms are more expensive than this. Bids to develop onshore wind came in at around £80 per MWh (8p per KWh) in the February 2015 round of CfD allocations, a bidding process meant to reveal the lowest available supply costs.  That’s about the same price as some proposed solar parks.  Onshore wind is cheaper in other countries such as Germany (between €0.05 and €0.11/kWh). That price premium for onshore wind in Britain seems to be back-to-front, given the UK’s powerful wind resource. There are several compounding factors. Many years of policy uncertainty and persistent meddling with the revenue schemes presents higher risks to investors. Planning regulations in England and Wales have created further uncertainty, with unpredictable local decisions. Often, rulings will be reversed on appeal, only for the energy secretary to step and reject the application. Investors, faced with higher risk, will require higher rewards.  Even more significantly, investors in windfarm supply chains can choose to locate instead in jurisdictions which offer far greater long-term clarity and security. This is why both Denmark and Germany have strong wind supply chains, and Britain’s is still nascent. Not only does that mean new turbines typically have to be shipped to the UK from factories overseas, it adds currency risk, and means that less of the money invested stays within the country. So, by removing the policy uncertainties, it is within the government’s power to remove part of the need for onshore wind to be subsidised. The chief assistance for onshore windfarm operators comes in the form of top-up payments from bill-payers, above what the operators receive from selling their electricity in the wholesale markets. The question is to what extent these are a subsidy at all.  Given the payment represents a transfer over and above the market price, it might seem surprising that this is even a question. But it has to be asked, due to a subtle process, known as the merit order effect. An electricity grid tends to rank different generators in order of marginal cost, prioritising the cheapest forms of generation. This is the merit order. Cheap electricity is brought online first, and the plants with the highest marginal generation cost are saved till last. The merit-order effect is the reduction in wholesale prices that comes about when more wind is generated. Wind is never the most expensive fuel on the grid, because its fuel is free. The cost of wind power is almost entirely in construction;  marginal generation cost is next to nothing. Therefore when the wind blows and power is generated, it knocks out the most expensive generator (and whether that’s coal or gas, depends on their relative prices, the carbon price, and the relative efficiency of the generators) and it lowers prices across the whole market. Previous research in Germany and Spain has found that these cost reductions outweigh the revenue support paid to wind. Wind is not subsidised in those two countries – indeed, quite the reverse, wind lowers total costs for consumers. The thing that is called a subsidy, whether existing schemes or future ones, acts to correct a market failure. First, it needs to figure out how much of these top-up payments merely reflect the merit order effect, simply levelling the playing field with regard to genuinely subsidised generators such as coal and gas. The rest is subsidy. But we can’t make true progress until we recognise this reality. Second, government policy could give windfarm developers much greater long-term assurances of a supportive and consistent policy environment, thus lowering their risks and hence lowering costs. Doing these will improve transparency, and reduce the cost of onshore wind further. It would give certainty to investors through decisiveness and leadership, and it would show that the government is taking a pragmatic and cost-effective approach to tackling climate change."
"“You are in no position to lecture the public about anything,” Golden Globes host Ricky Gervais told his audience in a pointedly irreverent opening speech on Sunday. By the evening’s end, following statements about the bushfires from actors including Russell Crowe and Cate Blanchett, he had apparently changed his mind – ending the evening with his own call for donations to the relief efforts. Charitable gifts will no doubt be welcomed by their recipients (a $500,000 pledge by another Australian actor, Nicole Kidman, emerged on the same day). But the evening’s most consequential remarks were those, including Mr Crowe’s and Ms Blanchett’s, that firmly linked the fires to global heating – directly challenging the denialism of the Australian prime minister, Scott Morrison, who, even in the face of record temperatures and unthinkable devastation, refuses to commit his government to stronger decarbonisation measures, or withdraw his support for coal production and exports. In an ideal world, it would probably not fall to film stars to advocate for evidence-based policies to protect the planet from catastrophe, particularly when such policies are supported by the UN and scientific institutions around the world. But while speeches and social media posts expressing sympathy for victims of this and other disasters, or promoting fundraisers and campaigns on other issues, are often and easily mocked, it makes more sense to focus on the policy failures that give rise to such efforts than to criticise pop or sports stars for their philanthropic activities, even when these appear clumsy or self-serving.  In the case of the climate emergency, the underlying failures are so grave and numerous as to remain extremely difficult for many people to take in. While denial of global heating itself is finally waning in the face of irrefutable proof, denial of the actions that are necessary to curb it (beginning with a 7.6% cut in emissions, every year for the next decade) is ubiquitous – as can be seen from the simple fact that emissions are still rising. Even as the bushfires dominate global headlines, climate-linked disasters in other parts of the world, such as a threatened famine in Zambia, or the battle for the Amazon being waged in Brazil, struggle to attract a fraction of the same attention. Anger is a justified response to such blatant climate injustices. Particularly when many of the worst-affected poorer countries are those with the lowest historic greenhouse gas emissions, philanthropy – even if it were forthcoming – would not provide an adequate form of redress. Lasting climate solutions will require a massive reallocation of global resources, with particular emphasis on infrastructure in developing countries. Only governments and international instituti ons have the necessary policymaking levers (hence the importance of the UN climate process). But where efforts such as those of Australian comedian Celeste Barber, whose bushfires fundraiser has made £20m, offer a reason to hope amid the grief and horror, is in the proof they offer that, when people truly believe that the future is imperilled, they want to help – and understand that this costs money. Politicians around the world should pay attention."
"
Share this...FacebookTwitterGermany used to be regarded as a global leader in the transition to renewable green energies — especially wind and solar power — a project dubbed the “Energiewende”. But this is no longer the case. Germany has fallen behind to the rear of the pack.
Ironically the USA is leading the world in cutting back CO2!
Germany’s “self-deception”
The Düsseldorf-based daily Rheinische Post (RP) here writes that it’s time for Germany to “face inconvenient truths” concerning green energies and that pragmatic (and not ideological) action is needed.
The title of the commentary: “Self-deception in the green energy transition“
Green, cult-like dream now colliding with harsh reality
For years the German government, activists and alarmist scientists promised that green energies — foremost wind and sun — would be plentiful, cheap and clean. “Hooray!” the entire exclaimed in jubilation.
But today in its commentary the RP concedes that “the reality looks totally different” and that it is requiring “an enormous effort” just to keep the power grids stable as waves of unpredictable green power repeatedly surge into the power grid.
According to the RP, emergency power grid interventions by grid operators cost electricity consumers last year 1,4 billion euros. German households consequently pay 47% more for their power than the average EU.
Energiewende: “risky, inefficient and expensive”
And so what have German consumers gotten in return in terms of climate and CO2 emissions for all the extra pain? Nothing.
German CO2 emissions have stagnated (i.e. haven’t fallen at all). And according to the RP: “The German transition to green energy is in reality risky, inefficient and expensive.”
Energiewende “derailed”

The RP comments that highly ballyhooed headlines of new record amounts of green energy being produced don’t change a thing with respect to the failing green energy transition, and notes that although green energies made up 37% of the gross share of gross power consumption, these clean energies amounted only to a measly 13 percent of the entire German energy mix!




<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The RP asks: “How could the German flagship project have derailed in this way?”
German dependence on coal “cemented for years to come”
The main reason for the failure, the RP writes, was Germany’s panicked rush to exit nuclear power in the wake Japan’s Fukushima nuclear disaster amid a deeply-rooted, collective and decades-old German aversion to nuclear power. This lead to the German government shutting down half of its nuclear power plants overnight and diving blindly into a rapid, unplanned expansion of wind and solar power.
The decision, the RP writes, was driven by the aim to shut down nuclear power, and not to reduce CO2.


The result, the RP comments: “Unfortunately, both goals are in direct contradiction. The politically desired phase-out of nuclear power has cemented our [German] dependence on coal for years to come. Its share is still 42 percent.”
The RP then comments that if Germany were really serious about reducing CO2, the country would not shut down its remaining nuclear power plants, which produce no “greenhouse” gas emissions.
Green energies “a naive illusion”
The RP also writes Germany should reconsider its efforts “to demonize diesel engines”, which have considerably higher fuel efficiency than gasoline engines. The move to eliminate diesel engines will make CO2 reductions more difficult. The RP also notes that electric cars “are no alternative” in terms of CO2.
100% renewables “a naive illusion” 
The RP calls the idea of covering all Germany’s energy needs through renewable energy “a naive illusion” and expects that the country will have to accept the fact that it will remain dependent on fossil fuels also over the long-term.
Also the collectively naive Germans in general need to get realistic and serious about what going 100% green entails. The RP comments:
Anyone who has solar cells mounted on the roof and then flies mindlessly to vacation on the Maldives, has not understood the problem.”
Public also opposes CCS
The RP finally comments on other possible technical solutions that could be employed to make the pain of having to go without fossil energies bearable, namely subsidizing CCS technology. However, a great number of Germans oppose that technology as well.
The way things are going, the RP suggests, Germany will never be able to meet its CO2 reductions targets.

Share this...FacebookTwitter "
"
Share this...FacebookTwitterScroll down to see some Media Bad Weather Exaggeration Award winners…
In the wake of Florence, climate ambulance chasers have been making wild exaggerations and claims.
WaPo Weirding
For example, the Washington Post editorial board claimed President Trump and climate change deniers were “complicit” in Florence because they play down humans role in increasing the risks our obstruction of addressing those risks.
Of course this is just the latest pathetic effort to criminalize climate science dissenters.
CNN fake news again
Meanwhile CNN even claimed there’s been a 40% increase in extreme storms since 1950, hat-tip Ryan Maue, who commented:

CNN has a great weather coverage team in Atlanta … but network in past has a checkered record on climate science using Bill Nye as their expert.  Lol!
Now, they just outsource it to the political team in NYC.  Mostly poorly sourced gibberish. They can do better. pic.twitter.com/GwwGj8GUBR
— Ryan Maue | weathermodels.com (@RyanMaue) September 13, 2018

In a nutshell, climate alarmists will say anything, no matter how absurd, to make the junk science look real. It’s time to come to terms with the reality that the mainstream media often deceives the public.
Media silent on “complicit” in hurricane disintegration
If climate skeptics are complicit in Florence, then on the other side of the coin skeptics also have to be responsible for the hurricanes that fizzle out.
At Friday’s Daily Update, veteran meteorologist Joe Bastardi posed a question to the climate ambulance chasers and folks at the Washington Post: “How come Florence didn’t intensify more? How come Isaac is falling apart at the heart of the hurricane season? […] How come everything is dying? There’s so much more than just simplistic arguments that are done for agendas.”

Media totally AWOL as Isaac and Joyce dissipate. Chart: Weatherbell Analytics.
Often things just don’t work out the way the alarmists would like them to. And so they need to resort to less than honest tactics to convey drama over to the audiences.
2018 Media Weather Exaggeration Award 


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Bad weather reporting has recently seen a series of blatant exaggerations aimed at making viewers think things are much worse than they really are.
This year’s 2018 Media Bad Weather Exaggeration Award has to go to Hurricane Florence reporter Mike Seidel below of The Weather Channel:

His projectile stunt also didn’t go very well.
Previous winners
And what follows are winners from previous years. Of course this is not to say that extreme weather can be taken lightly. But it would be nice if reporters stayed accurate. Their credibility is already pretty ruined and such antics don’t help.
One blooper comes from an MSNBC reporter covering the extreme conditions from tropical storm Hanna back in 2008:

 
What follows is my favorite, Hurricane Irene in 2011:

 
Next is Ryan Maue’s favorite — well, at least it’s one he brought up recently. In October, 2005, reporter Michelle Kosinski is using a canoe when a regular pair of rubber boots would have sufficed. Can we believe anything we see on our screens?

 
Right on par with Michelle Kozinski’s stagecraft is ABC’s Lucy Yang’s fake deep water after heavy rains in New Jersey, 2010:

 
It’s got to be frustrating when people totally ruin your dramatic story of danger and peril. The next video is of Hurricane Sandy in Atlantic City, New Jersey, 2012…CNN embarrassed again:

 
Finally, Anthony Watts presents here Anderson Cooper’s tactic used to fake deep flood water.
Share this...FacebookTwitter "
"The case of Russian scientists trapped in their remote Arctic base by a group of inquisitive yet hungry polar bears does not come as a surprise. By late summer, Arctic sea ice is at a minimum and polar bears are effectively landlocked in coastal areas eagerly awaiting the return of ice during the autumn freeze and the chance to hunt seals again. The Arctic summer is also the time of year when scientific activities are at their maximum, with bases operating at capacity and fieldwork operations at full flow, particularly in tundra and coastal regions. Polar bears are hungriest when scientists are busiest – “encounters” are inevitable. Researchers working in the Arctic, particularly in and around the Arctic Ocean and its coastal seas, usually have to undergo some type of polar bear encounter training before embarking on fieldwork. This inevitably involves familiarisation with a large calibre hunting rifle and getting practice on a shooting range. Most Arctic settlements and scientific bases have a designated area for target practice and this can be accompanied by a short course on polar bear awareness. A rifle is a “must have” and should be kept close to hand when out in the field. However, it is usually the last line of defence. A team of researchers in the field are likely to be equipped with flares and flare pistols – the latter equipped with special “flash-bang” rounds, aimed at scaring off inquisitive bears. Warning shots with a rifle should also work in deterring a bear, but equally the start-up of a noisy snowmobile engine should have the same effect. The best advice is to pay attention to your surroundings and stay alert. This may seem obvious when operating in the vicinity of one of the world’s largest predators, but it is very easy for scientists to become absorbed with the task in hand. A team of scientists huddled around a broken instrument or focused on a rare plant will not be aware of an approaching bear. Operating from scientific research ships carries its own risks. While the ship itself provides security, people operating on sea ice need protection. Surprisingly, visibility on sea ice is often restricted by the presence of ice ridges. These are formed when sheets of ice press up against one another and broken chunks of ice may extend up to three meters above the ice floe. The ridges serve as excellent cover for bears, who use them as hunting corridors, relying on their keen sense of smell to search out prey. For this reason, teams operating on sea ice usually have one team member designated to “ride shotgun”. Pump action shotguns equipped with shells fitted with solid lead slugs are commonly issued on Canadian icebreakers. In the past, trapping and hunting were the biggest threat to polar bears and some populations were decimated as a result. However numbers have stabilised at around 20,000 to 25,000 since an international conservation agreement was signed in the 1970s – though polar bears are still officially classified as vulnerable. These days, the biggest threats are climate change and pollution. As these marine animals are long-lived – a 15-20 year life span is not uncommon in the wild – they accumulate a variety of industrial chemicals that enter Arctic foodwebs through the atmosphere and ocean currents that flow northwards.  Legacy pollutants such as polychlorinated biphenyls (PCBs) and the pesticide DDT may have largely been banned, but they still linger in the environment. When I carry out fieldwork in the Arctic, it’s these sorts of chemicals I’m looking for. The pollutants “cycle” between air, soil and sea, eventually accumulating in snow, ice and marine sediments. Once present in seawater and sea ice they are picked up by tiny algae and plankton, which are eaten by fish, and then bigger fish, and so on. At each stage the concentration of these chemicals increases, until they reach astonishingly high levels in polar bears which sit at the top of the food chain.   Concern has grown recently about newer pollutants such as halogenated flame retardants and organofluorine chemicals used in the production of “non-stick” pots and pans. These chemicals interfere with the immune and hormonal systems of polar bears, and they may even be weakening their penis bones.  The effect of climate change, which is most pronounced in the Arctic, is to accelerate spring melt and delay winter freeze, meaning that bears remain landlocked for longer periods of time during the summer. This increases the risk of summer starvation and this, alongside the “co-stress” provided by a changing cocktail of contaminants, provides an existential threat to the polar bear. This brings us back to the poor Russian scientists holed up in their base. Bears will adapt and seek out new food sources during their summer wait. Hunger and starvation may make them bold and more persistent in their quest for food and is only likely to increase the frequency of human-bear encounters."
"Back in 1839, public health expert J F Murray published his article The Lungs of London, in Blackwood’s Edinburgh Magazine. Even then, city dwellers appreciated the advantages of open, green spaces. Murray described the benefits of the parks of London as “great vehicles of exercise, fresh air, health, and life to the myriads that congregate in the great metropolis”. Living in cities offers numerous advantages in terms of employment, education, healthcare and social communication, among others. But urban living also comes with its challenges: in particular, urban environments can put a strain on mental and physical health, because they tend to be noisy, polluted, overcrowded and hot.  Ecologists are increasingly turning their attention to urban areas, in an effort to find solutions to these problems. Their work is beginning to show us how cities can be designed to accommodate all the advantages – and minimise the disadvantages – of urban living.  Specifically, urban ecologists are considering how we can enhance “ecosystem services” for those living and working in cities. It is now widely recognised that ecosystems – including urban ecosystems such as parks, protected areas and waterways – provide essential services for people. Temperature regulation, air purification, noise reduction, human well-being, carbon storage (both above and below ground), water infiltration, agricultural production, pollination, and pest control are examples of the services that urban ecosystems can provide.  Of course, besides services there are also so-called disservices, such as noise pollution and high temperatures, that can be associated with open spaces. For instance, some people find that the dawn chorus of birds in spring affects their sleep patterns, or that they suffer from hayfever when there are high pollen counts. But now, armed with an understanding of ecosystems and the services they provide, ecologists are now able to shine some light on a central question in urban planning: should cities be designed so that intensive and extremely compact urbanisation sits alongside separate, large, continuous green spaces – an approach known as “land-sparing”? Or, is it better to adopt “land-sharing”, where compact green spaces are scattered throughout the urban sprawl?  A recent study by researchers from the University of Exeter and Hokkaido University, Japan, found that land-sparing is the most effective approach to maintain the majority of ecosystem services. But they also recognise that some degree of land-sharing is important, especially when it comes to the ecosystem services that benefit our well-being.  Being near high-quality green space can provide important health benefits, as well as “cultural ecosystem services”, such as places for recreation, spiritual and religious enrichment, education, cultural heritage, inspiration, social gatherings, and cultural diversity. If a city is to provide these services, it needs to be designed so that people can quickly and easily access green spaces as part of their everyday activities. The authors of the study concluded that the best way to ensure the optimum distribution of development and green space is to take a top-down, policy-led approach. Changing the design of a city is no easy matter, but we know from experience that it can be done.  As far back as 1809, architect John Nash began work on Regent’s Park in London, where much of his input can still be seen today. In 1858, Frederick Olmsted won the competition to design Central Park in the heart of New York. And in the 1870s, Baron Haussmann – who was charged with redesigning Paris – wanted to join the Bois de Boulogne with the Bois de Vincennes to make a green belt around the city.  These are all perfect examples of land-sparing, but it is worth noting that these green spaces were established when the cities were already in the process of being redesigned.  A more recent example of land-sparing is the 300 hectare Tempelhof Airport in Berlin. The site was earmarked for development, but the public voted to retain it as a large, open, green space in May 2014. Ingo Gräning, of the state-run Tempelhof Project stated: “No other city would treat itself to such a crown jewel [of open space]”.  Of course, not all cities have enough available land to “treat” themselves in this way. In densely-built cities like Hong Kong, the opportunity to create large open spaces may never arise. Berlin is an exception – many cities do not have the option of dropping a large park into a built-up area, and in most cases it is not feasible to combine lots of small parks and gardens into a large green area. A lot depends on the history of a city and its geography, and land-sparing is not an option for every location. Ebenezer Howard – the first modern urban planner theorist – recognised this, when he initiated the Garden City movement in 1898. His aim was to bring the advantages of nature to city dwellers, by introducing compact green areas and small parks into cities. The first examples of Howard’s organised land-sharing can still be seen today, in the UK towns of Letchworth and Welwyn. So when asking ourselves which approach is best, there is no straightforward answer. Whether land-sparing or land-sharing is most effective will depend on the context; factors such as the shape of the land and the existing developments in the area will all play a part. But there is no doubt that cities benefit from the services offered by urban ecosystems, and both land-sparing and land-sharing are important means of providing these advantages."
"
Share this...FacebookTwitterA very recent study by Swedish scientists appearing in the journal Climate of the Past examining bottom water temperature (BWT) off the coast of Western Sweden (Gullmar Fjord) going back 2500 years found that “the most recent warming of the 20th century does not stand out.”

Team of researchers led by Irina Polovodova Asteman, University of Gotheberg, produced a record of bottom water temperature off the coast of western Sweden and found 20th century warming “does not stand out.” Photo: ResearchGate, University of Gothenburg
The 2500-year winter temperature record was of reconstructed by using a fjord sediment archive from the NE Atlantic and through analysis of oxygen isotopes and other methods. The study was based on an approximately 8-meter long sediment core extracted from the Gullmar Fjord (Sweden).
They found that the Gullmar Fjord d18O record mainly reflects variability of the winter bottom water temperatures with a minor salinity influence.
The researchers also pointed out that a comparison with instrumental winter temperature observations from Central England and Stockholm shows that the fjord record picks up the contemporary warming of the 20th century, see following diagrams:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




t

t

Chart: Polovodova et al 2018
According to the scientists, the Gullmar Fjord record shows a substantial and long-term warming during the Roman Warm Period (~350 BCE – 450 CE) which was followed by variable bottom water temperatures during the Dark Ages (~450 – 850 CE).
The Viking Age/Medieval Climate Anomaly (~850 – 1350 CE) is also indicated by positive bottom water temperature anomalies, while the Little Ice Age (~1350 – 1850 CE) is characterized by a long-term cooling with distinct multidecadal variability.
The team of Swedish scientists, led by Irina Polovodova Asteman, Department of Marine Sciences, University of Gothenburg, Sweden, noted “the most recent warming of the 20th century does not stand out, but appears to be comparable to both the Roman Warm Period and the MCA (Medieval Climate Anomaly).”
 
Share this...FacebookTwitter "
nan
"Australia is a fire continent. Imagine California on the scale of the 48 contiguous states, but drier, more routinely kindled and with winds that can transform large swathes of land into a veritable fire flume. From time to time, its simmering flames boil over into seeming tsunamis of fire. And Australia has a culture to match. It has institutions to study, fight and light fire. It has a literature of fire, a folklore of fire and a fire art that is continuous from Indigenous bark paintings to modernist musings. It has special bushfire collections at its museums. It has a fire politics: on three occasions conflagrations have sparked royal commissions, and from 2009 to 2017, 51 official inquiries.  The worst fires have acquired names and become historical milestones, such as Red Tuesday (1898), Ash Wednesday (1983), Black Christmas (2001), Black Saturday (2009). Now they are joined by the as-yet unnamed megafires of 2019-20. Call them the Forever fires, for they seem inextinguishable, burning with implacable insistence and smoke palls that extend their reach far beyond the flames’ grasp. Yes, Australia and bushfire are old acquaintances. But the past 20 years feel different. The bad fires are more frequent, more eruptive and more damaging. The Black Saturday fires, which killed 173 people, struck with the cultural force of a terrorist attack, and seemed to call into question the very premises of a “first world” society on a land capable of such fury. The Forever bushfires deepen that query. But there are two other fires that provide a wider panorama. One is overt – the fires that burn living landscapes, the bush. The other fire is covert, because it burns lithic landscapes. These are the once living, now fossilized biomasses such as coal and gas that we combust to power our industrial economies. Those two fire realms are interacting in ways that are proving ever more entwined and threatening. That so many fires in Australia (and California) start from power lines is an apt metaphor for the way the two realms of fire interact. The secondary effects are not restricted to global warming or ocean acidification. They affect how people organize landscapes – their agriculture, nature reserves, transportation grids – all aspects of geography that, in turn, influence the character of bushfires. We have been burning our combustion candle at both ends. Now, it’s payback time, and the two types of fire are colluding. Australia’s predisposition to fire makes it an early flash point for what I like to call the Pyrocene. But many of the same phenomena are appearing in America – unstoppable fires, fire deaths and fire refugees, smoked-in and incinerated cities, damaged watersheds and post-burn floods, economic crunches from lost tourism, bankrupt utilities, snake-bit insurance companies. Wildfires moving from exurban fringes to city cores. Extended states of emergency. Prolonged and painful cleanups. Political anger. The areas of the US with a history of fire will suffer the worst burns, but the combustion miasma will seep into other, seemingly immune, parts of the country. Paradoxically, places like California long frequented by fire are better prepared to cope with the coming crises. Places unaccustomed to fires lack the institutions and infrastructure, and they will struggle. Even if fossil fuels somehow cease overnight, greenhouse gases will still take a long time to work their way out of the atmosphere, so the climatic effects will linger. This puts the immediate focus on coping with landscape fires. There is plenty to do – harden communities, get more good fire into the countryside, design to accept that landscape fire is not a freak apparition from the fringe but an informing fact of modern life. Wild, feral or prescribed, there is much more fire to come. We have created the fire equivalent of an ice age. The latest round of Australian fires will stop at the country’s shores. The Pyrocene, however, will affect all of us, and persist long into the future. Steve Pyne is an emeritus professor at Arizona State University, and the author of Burning Bush: A Fire History of Australia and most recently the second edition of Fire: A Brief History"
"Donald Trump is going to acquire a book. The book in question, as Gizmodo reported on Thursday, is titled Donald J Trump: An Environmental Hero, by Edward Russo. And the shocking news emerged as the president announced a rollback of environmental regulations at the White House, taking an axe to the environmental review process required for infrastructure projects. The move, which he pitched as a way around “endless delays” to various projects, poses a new threat to the climate and is likely to face legal challenges.  The president’s war on the environment is nothing new. His plan to bury his nose in a book is. Trump isn’t known for his literary bona fides. Though the bestseller The Art of the Deal helped make his name, it was ghostwritten by Tony Schwartz – who deeply regrets his work on the book. Ghostwriters have been involved in most, if not all, of his many other volumes. “He doesn’t read books and he doesn’t write them,” Schwartz told the Independent in 2018. (The late-night host Samantha Bee has developed a conspiracy theory that Trump can’t read at all.) But one subject fascinates the president so much that he’s willing to invest in a volume of prose. That subject is, of course, himself. The president highlighted Russo’s volume in his own defense after a question over whether he feels the climate crisis is made-up. “The environment is very important to me. Somebody wrote a book that I’m an environmentalist – it’s actually called The Environmentalist … I’d like to get it,” he said, before apparently contradicting himself and suggesting he already had it “in the other office”. Russo, who has advised Trump, describes himself as a lifelong advocate for the planet. His self-published work claims to offer “a personal picture of a man who doesn’t just care about success but the impact of his success on the world”. Trump, the book’s blurb says, offered Russo a job to ensure that Trump’s business developments wouldn’t “negatively affect habitats”, conjuring an image of a concerned Trump nodding thoughtfully as Russo warns of the toll his latest golf course could take on the local squirrel population. The book seeks to counter a narrative – supported by robust evidence, including Trump’s decision to pull the US out of the Paris climate agreement, his assault on Obama-era environmental rules, and his complaints about excessive toilet flushing due to low water pressure – that the president actually doesn’t care very much about the planet. Speaking to reporters on Thursday, Trump sought to paint a very different picture of himself. Asked about the climate crisis, he said, according to the pool report: “Nothing’s a hoax about that. It’s a very serious subject … I’m a big believer in that word, the environment.” That would seem to run counter to his previous claims that the climate emergency is a Chinese hoax and casting doubt on global warming during a snowstorm. As for Russo, his own brand of environmentalism seems a little shaky. He has hailed proposed EPA budget cuts, suggesting they will increase the agency’s “focus”. “Every time there’s lightning or thunder that, oh, it’s climate change,” he told the energy news site E&E News in 2017. “Climate change is a natural change in balance of the Earth, it happens all the time.” Whether the book’s claims of environmental heroism are accurate or not, the president appears to have developed an interest in the written word. We can only hope his newfound passion means a little less TV time."
"A Dutch district court has ordered the Netherlands to cut greenhouse gas emissions to 25% lower than 1990 levels by 2020. This is several percentage points deeper than the 17% reduction the country had been envisaging. While such a ruling may seem astonishing at first, the move by civil society to take on individual states for a global collective lack of progress on emissions reductions makes perfect sense. Whether anything will change in the Netherlands in the short term remains to be seen. Instead, by setting a precedent and inspiring further actions, this ruling may have its greatest impact elsewhere in the world. The judgment implies that failure to address climate change and the harm it may cause is seen as a civil wrong in the Netherlands, within the scope of the tort law that people can appeal to when they have been wrongfully harmed. True, the Dutch government had argued that it is fully complying with its international obligations. But the judges point out that, since the Netherlands agrees measures should be taken to limit global warming to 2℃ above pre-industrial levels, the presence of a gap between international obligations and what would actually be needed to meet the 2℃ target does not take away an independent duty of care. The government could have seen this coming. The 25% figure is the product of Dutch scientific assessment work done about a decade ago and recently updated in the run up to Paris. This work was subsequently included in the IPCC’s Fourth Assessment Report back in 2007. Furthermore, the country’s present implementation of its energy strategy – based on a 2013 cross-party Energy Accord which focused on efficiency and renewable targets, rather than reduced emissions – will result in only a 17% reduction for the Netherlands. The gap is obvious. The judges rightly observed that at present the numbers do not add up to what is needed. They subsequently argue the Netherlands should do more: if you see a disaster coming but you don’t do enough to mitigate it, when you could have, you are liable. The same reasoning used by the Dutch judges for declaring tort law valid for dealing with climate change could be applied elsewhere. Each government has a duty of care towards its own citizens – and also towards other and future citizens. Developed countries have both ethical and legal obligations to cut greenhouse gas emissions – an obligation that holds even if adequate international agreements have not yet materialised. It’s interesting to see the climate science accumulated over the past decades by the IPCC being used directly by national judges. This approach may receive a boost after the Paris summit later this year, as it’s questionable whether governments will deliver a strong and legally binding agreement on emissions. If they don’t, judges in other countries could produce similar rulings on the liability of their governments – they’d simply have to use the IPCC’s UN-validated body of knowledge to make a scientific case that the efforts do fall short. The essence of the ruling is that states can be judged to have failed to meet their duty of care and that the discretionary power vested in states is not unlimited: their care may not be below standard. Scientists don’t agree on everything to do with the climate, never mind the public, so it is heartening to see how the judges were able to deal explicitly with uncertainty and risk. Even the best expert advice involves some element of value judgment – the 2℃ target itself does not flow directly from climate science, for instance, but from a value-led assessment of impacts and the possibilities of adaptation. We’re also not certain just how sensitive the climate system will be to increasing greenhouse gas concentrations, or how emissions can and should be distributed over countries and time. Yet the Dutch judges observed that the IPCC has always allowed for scientific uncertainty and in their ruling they effectively include assessments of uncertainty as part of the “facts” relevant for managing risk. In that way, the judges – while making brief reference to the precautionary principle – were able to use the 25% emissions reduction number derived from the IPCC report as a norm which is not met by the EU or the Netherlands. Concerning values, while the judges missed the value-laden nature of judging climate change “dangerous”, they made a strong plea for the value of “duty of care”: the state must “mitigate as quickly and as much as possible”. And while the influence of the government is limited and the effects of some measures may be uncertain, the court concludes that the state “has the power to issue rules or other measures, including community information, to promote the transition to a sustainable society and to reduce greenhouse gas emission in the Netherlands”. For now, let’s hope this judgment will neither be ignored by the Dutch government nor addressed only with short-term measures focused entirely on 2020 without regard for the bigger picture. It’s a moment for a deeper discussion on the transition to a low-emission economy, not only in the Netherlands but also in the European Union and globally. And Paris may show a way forward after all."
"
Share this...FacebookTwitterGulf Stream is doing fine: Potsdam Institute horror story suffers bitter setback
By Dr. Sebastian Lüning and Prof. Fritz Vahrenholt
(German text translated/edited by P Gosselin)
The horror scenario from the movie The Day After Tomorrow keeps getting presented as a real plausible scenario for our future: Falling salt content of the upper Gulf Stream due to melting ice flowing into the Arctic is slowing down the North Atlantic Current (NAC), and so doom and gloom is about to sweep across the North Atlantic.
However a team of researchers led by Carina Bringedal from the University of Bergen recently studied the northern end of the North Atlantic ocean circulation (Bringedal & Eldevik 2018). The result: the inflow of warm water and the overflow of denser deep water are in good sync. And since 1998 we do not see any long-term divergence of the sort we would expect to observe when adding more fresh water that would slow the “pump” down.
On shorter timescales the currents are influenced by the winds and the NAO. On longer timescales the currents are influenced by the AMOC.
In short: There’s no sign of a “collapsing Gulf Stream” due to the anthropogenic warming of the Arctic and the associated melting of the ice:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Figure 1: Transported water volume in the North Atlantic during the past 25 years. Chart: Bringedal & Eldevik 2018
Observed rainfall contradicts doom & gloom claims
In the published paper that concerns the doom and gloom forecasts related to the weakening Gulf Stream (Caesar et al. 2018), there’s a second reason that gets named: anthropogenic impacts are causing more rainfall over the North Atlantic.
Yet, the following chart shows this as well is not being observed:

Figure 2: Chart depicting rainfall in the North Atlantic over the past 35 years. Source: KNMI Climate Explorer. Data: NOAA.
Share this...FacebookTwitter "
"
Share this...FacebookTwitter40-year veteran meteorologist Joe Bastardi at WeatherBell’s Saturday Summary shows how the Earth’s surface has cooled dramatically over the past three years and that Arctic sea ice is piling up.
Hurricane threat to East Coast due to natural factors
First at his most recent Saturday Summary, the 40-year meteorologist first warns that in-close developing hurricanes of the sort seen in the 1930s are a risk to the US East Coast this year, due the current Atlantic temperature pattern. The reason has nothing to do with CO2 in the atmosphere, but because of natural sea surface temperature cycles.
Sea surface temperatures see “pretty dramatic turnaround”
Next Joe Bastardi illustrates the stark sea surface cooling the globe has seen over the recent years. The following two charts show the “pretty dramatic” cooling that has occurred over the past three years, 2015 vs 2018:

Cropped from Weatherbell Saturday Summary.
The two images above show the surface temperatures of the globe for the years 2015 – 2018. Note the profound cooling that has taken place from 2015 to 2018.
Bastardi calls it “a pretty big flip” and “a pretty dramatic turnaround”.
Arctic turns frigid
As sea surface temperatures around Greenland and in the Arctic are currently below normal, they are having an impact on Arctic surface temperatures this summer.
Joe Bastardi notes that according to the Danish DMI, Arctic temperature has been below normal over the entire summer:

Moreover, Arctic mid-summer temperatures, north of 80°N latitude, have dipped to near freezing over the past days. This is likely in large part linked to the cold North Atlantic sea surface temperatures we’ve been witnessing. All this suggests ocean cycles, and not CO2, are the real Arctic drivers.
Snow and ice climbing past decade
The cold polar temperatures are naturally having an impact on Arctic snow and ice.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Japanese blogger Kirye tweeted here that Arctic sea ice volume is currently at the 4th highest level since 2003, thus defying the dire alarmist predictions of Arctic sea ice disappearing by now.

Arctic sea ice volume (m3) has eased off from third place and is now at the 4th highest level since 2003, and showing an upward recovering trend over the past decade. Chart: Kirye.
Also at the 11:50 mark of his Saturday Summary video, Joe shows that Arctic sea ice extent is well above the levels seen over the previous years.
Greenland gets buried in snow
According to Kirye here, warming and melting have also been AWOL in Greenland, which has been seeing a dramatic snow and ice mass balance increase:

Chart: DMI.
“Total nonsense” concerning Thailand monsoons
In his Saturday Summary, Joe Bastardi also sharply criticized the climate ambulance chasing we’ve witnessed from hysterical climate alarmists, who are desperately grasping at any straw they can find to keep the climate panic on life-support.
It was recently claimed that the group of Thailand teenagers and their coach got trapped in a cave due to monsoon rains which were induced by global warming!
But Joe Bastardi presents a chart showing that this year’s monsoon activity in Thailand is completely within the range of natural variability:

Chart: WeatherBell Saturday Summary.
Bastardi calls the claim the kids got trapped because of climate change “total nonsense”, and points out that the monsoons over Thailand over the past five years have been normal to even below normal!
Share this...FacebookTwitter "
"
Share this...FacebookTwitterYesterday German energy expert and scientist Prof. Fritz Vahrenholt commented at his monthly column at Die kalte Sonne site here on solar activity, CO2 and coal power in Germany.
Photo: Fritz Vahrenholt, source: Die kalte Sonne
Sun factor grossly underestimated
Lately the sun’s activity has been very quiet as the star at the center of our solar system transitions over to a new solar cycle. April sunspot activity was very low in May. Vahrenholt then cites a recent study by Lewis and Curry showing that climate sensitivity to CO2 is in fact “up to 45% less than what the IPCC and the mainstream of climate science would like to have us believe.” Vahrenholt comments:
What was interesting however was the reaction of the mainstream: the methods used by Curry and Lewis in the study were not doubted. However, it could mean – according to the mainstream – that the earth will react very differently to CO2 in the future, i.e. get warmer. That’s what we can call speculative science, namely trust in the models which in the past have failed and have not been able to depict ocean circulation and clouds.”

So with CO2 not being at the factor it was made out to be, and because the Paris Accord is based on the spectacle of a rapidly warming planet, Vahrenholt writes that the “foundation of the Paris Accord has collapsed.”
Only Europe and Canada exiting coal
Another reason the Paris Accord is collapsing is because it’s not going to do anything we were promised it would.
When it comes to coal, Vahrenholt notes, so far only Europe and Canada have expressed some sort of a commitment to exit coal, and then he reminds us China, India and all developing countries will still be permitted to continue “massively” expanding their use of coal. He writes:
In China 280,000 MW and in India 174,000 MW are going to be added. By comparison: the entire brown coal fleet in Germany has a capacity of 22,700 MW. 1600 coal-fired power plants will be built in 62 countries across the world, most of them, by the way, will be built by Chinese power plant builders with the help of credits from China. Approximately 15,300 MW in Pakistan, 16,000 in Bangladesh, and even Myanmar with 5100 MW. (Source: South China Morning Post).
In other words, Angela Merkel and her green punch drinkers think the climate is going to be saved if Germany shuts down 1/20 of what China and India are going to add. No wonder Trump dumped the idiotic Accord.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Coal to expand 43% worldwide
And to illustrate what a farce the Paris Accord has become, the German energy expert adds: “In total, coal power plant capacity will expand by 43% worldwide.”
Germany to lay out the blueprint for its own demise
Currently Germany is gradually growing obsessed with the idea of a coal exit, and is setting up a Coal Commission to launch the endeavor. The Commission “however will not be made up of energy, power grid and technology experts, but rather with Greenpeace, BUND and local citizens initiatives who are against brown coal,” writes Vahrenholt.
“The idea of including critics of alternative energy, which has become the largest destroyer of nature since WWII, never dawned on any politician.”
Green state fundamentalism
The Coal Commission of course should include Prof. Hans-Joachim Schellnhuber, fiormer director of the ultra-alarmist Potsdam Institute and architect of the Great Transformation masterplan, which calls for an immediate end to the economic model that is based on “fossil industrial metabolism”, making climate protection the “fundamental target of the state by which the legislative, executive and judicial branches are to align themselves.”
Paris absurdity

According to Vahrenholt, the phase-out of coal will mean the decarbonization of Germany, which in turn will mean its deindustrialization. This, according to Vahrenholt, all coming to the great delight of the Chinese
A dismayed Vahrenholt sums up:

“Trump was clever enough, to exit the Paris absurdity early enough.”

Share this...FacebookTwitter "
"In the scorching farmlands of south-west Bangladesh, a single coconut tree stands as a barometer of climate change. Dulal Mondal, 70, a farmer, points halfway up the tree about two feet off the ground to indicate where the waters came the last time the area flooded. “Next time if heavy rain comes I don’t think water will recede as there is no natural draining or anywhere for it to go,” he says. Mondal lives in the Jessore district of Bangladesh where increased levels of salt in the water, uneven rainfall and flooding are creating great uncertainty for a whole farming community. Bangladesh is one of dozens of countries on the frontline of the climate emergency. Here global heating is no theoretical calamity of the future, but a very real, present danger. By 2050, it is predicted that one in seven people in the country will be displaced by climate breakdown. The sea level is projected to rise by 50cm over this time period and Bangladesh may lose approximately 11% of its land. Deadly storms are usually a question of when, not if. Here, the climate crisis is so palpable that the debate is not about restricting carbon emissions or preventing global warming but about how to adapt to the change and survive in times of unpredictable weather. For example, Mondal says that where once his peers would farm mainly rice, now they have taken to fishing. They use floating cages, allowing fish to breed in a secure area. Also, if water levels rise, the cages will too, so flooding is less of an issue. “About 20 to 30 years ago there would be a minimum of two crops per farming family but now because of waterlogging we have no more than one,” he says. Each cage is owned by one home and yields about 15,000 taka (£135) in additional income for the families a year. It’s also a consistent source of food, which could be vital if natural disaster hits.  “In the last two years there was not too much rain but two years ago we were flooded,” Mondal says. “We worry about the future. If there is heavy rainfall the water could remain logged for a long period of time and we would have to take shelter on main road. We would stay there with our remaining belongings.” This farming evolution is just one element of a whole range of climate change adaptive practices taking root across southern Bangladesh, an area long prone to cyclones, rising sea levels and drought. “What’s important is investment in long-term development, to help people adapt to the effects that climate change is having now and help them to not only survive but thrive in their new climate reality,” said Adib Hossain, the head of programmes implementation at Practical Action, one of the charities helping to make changes. In this part of Bangladesh they have helped introduce effective fertilisers to increase crop growth as well as growing fish in cages and vegetation in sacks or beside rivers – a novel farming technique known as a “dyke garden”. Ever wondered why you feel so gloomy about the world - even at a time when humanity has never been this healthy and prosperous? Could it be because news is almost always grim, focusing on confrontation, disaster, antagonism and blame? This series is an antidote, an attempt to show that there is plenty of hope, as our journalists scour the planet looking for pioneers, trailblazers, best practice, unsung heroes, ideas that work, ideas that might and innovations whose time might have come. Readers can recommend other projects, people and progress that we should report on by contacting us at theupside@theguardian.com The cages are made using cheap materials. Bamboo poles form an outer frame that can float and is covered in netting. They have a top cover to prevent fish jumping and escaping, or being caught by birds. With a capacity of one cubic metre, they hold up to 300 fish at a time. These cages are used for two growing seasons each year. The fish can be fed on scraps and waste – duckweed, oil cake, kitchen waste, rice bran and snails – and in just a few months they grow to full size. A woman standing beside Mondal goes down in a small wooden boat and pulls up the mesh cage, within which fish jump up and splutter around. She drops the net and they swim around once more. For the worried farmers in this area, the introduction of these cages has been reassuring, a constant amid a lot of inconsistency. In the nearby district of South Atulia another innovative technique has been employed. Land here is being used for fishing, with pools of water separated by a cracked mud path and spiky vegetation. Omal Biswas, 48, has three daughters and an adopted son. He used to farm rice once a year and during the monsoon he would fish in freshwater. Now he is able to make more money with dyke gardening techniques, growing vegetables around pools of water used for fishing. Omal has just harvested a crop, he says. They grow bottle gourd, chillis, indian spinach, red amaranth, sponge gourd, ridge gourd and tomatoes. “Before this technology was used I would yield around 20-25,000 taka a year but last year I harvested 120,000 taka through using different varieties of vegetables and growing more in the year. “Now I can grow vegetables while fishing but I used to rotate the land. I eat the vegetables too,” he adds.  He adds that the additional income helps give them a better quality of life and now he has been able to buy six cows. “The cost of living is rising and the cost of production is increasing so it is a good portion of revenue,” he says. Practical Action isn’t the only charity supporting farmers. The National Agriculture Technology Program (NATP 2) by the World Bank has also helped people adopt resilient farming methods. Farmers have deployed ancient agricultural methods such as floating beds, which involve sowing crops onto floating islands made of the fast-growing water hyacinth. Crops such as cucumbers, gourds and eggplants flourish. Beds are raised so as to lie above the reach of tidal surges. In between, trenches serve as pools to farm fish and ducks. Others have turned to shrimp farming after land was flooded but Practical Action has helped people do this in a more effective way. Rubina Khatun is one woman who has benefited from this. “The cyclone affected my family. I swam across flood waters with my two sons and took refuge on the road and sheltered in a shop we own for two months. Then we returned to our home,” she says. Shrimp farming is now a major source of income for her family. The technique used to farm the shrimp more effectively includes using deeper water so the temperature does not change as quickly, and adding a fertiliser made from oil cake, date juice and sugar cane among other things. “I am not sure what I would do without it now,” Khatun says. “But this type of farming is weather dependent. We need rain. If there is less rainfall salinity increases.” Despite efforts to improve the situation, Bangladesh remains at the mercy of sharp changes in weather patterns. Deep uncertainty persists for millions, even if these newfound techniques are helped to mitigate environmental impact. “I am worried,” Khatun says. “Too much or too little rain, both are problematic.” For her, however, the concept of climate change is a world away. “I can feel it in terms of rain but I am not aware of this. I have heard non-government-organisations talking about it but just as a concept. All I know is shrimp farming is a major source of income out of all the ones remaining, so it’s a reassurance.” This article is part of a series on possible solutions to some of the world’s most stubborn problems. What else should we cover? Email us at theupside@theguardian.com"
"
Share this...FacebookTwitterThe upcoming 6th IPCC Sixth Assessment Report will be a “comprehensive assessment of the science” related to climate change and published in 2022. However, don’t expect it to be “comprehensive” at all as hundreds of scientific publications showing profound impacts by sun and oceans will go ignored.
Climate science has turned into a religion that centers on a single act of faith. Human CO2 is changing our climate.
In the past it was always understood that climate was impacted by a vast array of factors, such oceanic cycles, solar cycles, aerosols, cloud cover, etc. to name a few.

Images: NASA (public domain)
But over the years tremendous resources have been poured into an effort aimed at pinning the blame on man-made greenhouse gases. Models have been grossly distorted and corrupted to make CO2 the 90%+ climate driver.
Despite global temperatures having fallen by more than 0.5°C over the past two years due to the ending of an El Nino event, IPCC scientists continue to insist that trace gas CO2 is the main driver behi9nd climate warming. In the IPCC 5th summary report for policymakers, for example, solar and oceanic factors re described as having little effect on global temperatures:

Source: IPCC 5th Summary Report for Policymakers.
With such a disregard for natural factors, it is no surprise that we are already observing the spectacular failure of the climate models.
Not only have ocean cycles been grossly ignored in climate models, but so have solar factors. The sun is not constant in its behavior, and has been shown to act in cycles that have profound impacts on the earth’s climate system.
Research showing sun’s impact piles up
Despite all the effort to frame CO2, scientists are still conducting a formidable amount of research on the sun’s impact.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Indeed since the last IPCC report was released in 2013, there have been literally hundreds of scientific peer-reviewed publications showing that the sun directly and indirectly have a great impact on the earth’s climate. Yet IPCC scientists obstinately continue to refuse to acknowledge these in their models.
Back in 2013 I produced a list of 123 paper showing that the sun impacts global climate.
More than 600 published papers show clear solar impact on climate
NTZ guest author Kenneth Richard has been busy listing the papers as well. What follows are the list of papers showing the sun impacts global climate.
2012 123 papers had been published and ignored by IPCC 4AR
In 2014, 93 papers were published.
In 2015,  95 peer-reviewed papers were published
In 2016, 133 papers were published.
In 2017,  121 peer-reviewed solar papers were published.
In 2018, so far, ca. 60 papers.
That brings the total of scientific peer-reviewed papers that will be completely ignored by the IPCC to 625. If that isn’t fraudulent “science-based” policymaking, then what is?
Aim: human society in shackles
The aim of the IPCC is to ignore recognized standards of science, frame mankind for a nonexistent crime, and shackle human society. It’s the next planned slavery. The developing countries, who will be denied cheap and reliable energy, will bear the heaviest chains.
Share this...FacebookTwitter "
nan
"Rhinos have become one of the high-profile wildlife stories of the year, fuelled by a steady stream of depressing images of once-impressive rhino reduced to a bloodied mess. Heightened awareness among the general public is the dream for conservation biologists, who often struggle to generate widespread interest in their cause. But, while the media’s focus on the plight of Africa’s rhinos is commendable, it begs the question – why aren’t Asian rhino given the same attention? There are three rhino species in Asia (the Indian, Javan and Sumatran) and two in Africa (white and black). They’re all fairly similar: all five eat plants, weigh up to 2.5 tonnes and have a thick protective skin. Javan, Sumatran, and African black rhinos are classed as critically endangered by the International Union for the Conservation of Nature (IUCN). And the IUCN’s most recent assessments were made before the latest surge in poaching, So why are we in a situation where twice as many people attend Arsenal home games than there are rhino left in the wild? The recent surge has been driven by a relatively recent fad among the affluent middle classes of Vietnam, who consume ground rhino horn in drinks either as an aphrodisiac or hangover cure.  Yet despite Asian species appearing to be in a more perilous situation statistically, conservation spending on rhino appears heavily weighted towards African species.  More than 80% of money distributed by Save the Rhino between 2008-09 and 2012-13 went to programmes supporting conservation in Africa. Why? Even before the resurgence of rhino poaching in Africa, spending was biased towards the continent. It would be wrong to assume we have given up hope for the future of the species in Asia. Action plans exist for the Asian Rhino and governments and charities have committed to trying to conserve the species, by supporting dedicated rhino protection units.  The recovery of the one-horned rhino in Nepal – numbers are at their highest since the 1950s – is a result of the effectiveness of such measures, but you wouldn’t know it as hardly anyone reported it. So why are media outlets and conservation organisations focusing on African Rhino? Corruption, a recognised inhibitor to effective conservation, is arguably comparable in the regions that African and Asian species are found and can’t be used as an excuse. I also highly doubt that the global public value Asian species any less than African. It mainly comes down to one thing: money from tourism. Africa is largely made up of developing countries whose economies are based on agricultural, rather than industrial, output. Consequently tourism is an important stream of revenue for governments, private businesses and local people.   According to the World Tourism Organisation, wildlife watching represents 80% of annual sales for tour companies to Africa. The “big five” – lions, elephants, buffalo, leopards and rhino – are big money. In Indonesia and Nepal, where most of Asia’s wild rhinos live, tourists are mostly there for the beaches or the mountains. They simply aren’t as reliant on safari-dollars as a country like Botswana. The African rhino is therefore a perfect example of utilitarian-based conservation – the preservation of something because of its monetary value to humans. They are worth more, to more people, than their Asian counterparts and are as a result the focus of more conservation efforts.  This isn’t a criticism of those who invest huge amounts of time and effort protecting Africa’s rhinos. They undoubtedly believe in what they are doing and don’t want to see recent successes destroyed by a surge in poaching. But there is a trade off. The case of the African versus the Asian rhino exposes a complex side to conservation, one which the majority of people simply aren’t aware of.  The conservation of one species over another due its monetary value being higher, distracts from what the main reason to preserve biodiversity should be, and what I think the majority of conservationists believe in – because its loss is simply wrong."
"
Share this...FacebookTwitterGerman skeptic blog Science Skeptical here takes a look at the carbon footprint of Prof. Hans-Joachim (John) Schellnhuber, the former director of the ultra alarmist and activist Potsdam Institute for Climate Impact Research (PIK).
Professor Schellnhuber is so worried about man’s destruction of the climate through human CO2 emissions and the “fossil fuel metabolism” of our society that he’s written a number of books on the subject, warning we’re on the verge of burning ourselves to death.
Not surprisingly these vivid books have been very popular among end-of-world conspiracists and climate Armageddon believers. His latest: Selbstverbrennung (Self Immolation).

 Image: C. Bertelsmann Publishing. 
Mankind committing “collective suicide”
A short summary of his book explains how Schellnhuber warns that if “our civilization does not move to the often-mentioned two-degree limit, but much more dramatically to a warming of 3 to 4 degrees Celsius by the end of the century, the continued burning of fossil fuels threatens to lead to collective suicide.”
Himalayan glaciers on the verge of disappearing
The doomsday professor, known in Germany as the “Climate Pope” and whose every word is taken by most of the German mainstream media as infallible, once said that the ideal population for the planet is a billion people (meaning soon there will be 7 billion too many) and the Himalayan glaciers would be gone by 2030.
Do as I say, not as I do
So with Schellnhuber’s level of conviction, certainty and urgency, it would only seem logical that the Bavarian-born professor would himself be setting an example for the rest of us on how to live responsibly with CO2 and forego fossil fuels.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Unfortunately, like a Catholic Pope and Cardinals who allow themselves lavish life styles while preaching others not to do the same, Schellnhuber allows himself exorbitant CO2 and fossil fuel privileges. Do as I say, not as I do.
“Certainly fly 100 times a year”
According to Science Skeptical, Schellnhuber was interviewed in 2005 by Tagesspiegel. In the interview he confessed he was not doing his part in “protecting the climate”. When asked if he had ever calculated his own contribution to climate change, Schellnhuber responded:
Yes, it is quite high because I myself certainly fly 100 times a year.”
And when asked what car he drives:
A BMW from the new 1 series. It consumes 6 liters diesel [per 100 km], but that’s only half as much as my previous car.”
Science Skeptical then did a rough calculation of Schellnhuber’s CO2 output using the CO2 calculator provided by the German Ministry of Environment. The result, assuming normal consumer behavior, but flying 100 times a year, each flight on average 2 hours long: 50 tonnes of CO2 each year!
The average German emits only about 10 tonnes annually.
Skeptical Science next wonders how much CO2 the climate-doomsday-preaching Potsdam Institute with its 4.5 million euro super-computer, and all it’s jet-setting climate-rescuing scientists, emit into the atmosphere. Not a pretty picture. They all happily rely on the conveniences provided by the very fuels they profess to detest.
Contempt for regular workers
In terms of CO2, the employees at the PIK thus consume a multiple times what the average German worker does. But German workers, you see, really don’t do necessary worthwhile work, and so are producing CO2 needlessly. PIK workers, on the other hand, are rescuing the planet, and so their CO2 emissions are really necessary. 
 
Share this...FacebookTwitter "
"
Share this...FacebookTwitterOn June 13 Chris Mooney of the Washington Post wrote how Antarctica’s ice sheet was “melting at a rapidly increasing rate” and “pouring more than 200 billion tons of ice into the ocean annually” — all this according to “a team of 80 scientists”. The doomsday media response was immediate.
Mooney of course blamed CO2 for the speculated ice melt change, and renewed the calls for a cut in greenhouse gas emissions in order to save ourselves.
Adventurous conclusion
Firstly the CO2 ice-melt logic here is extremely flimsy and even preposterous: An already hugely uncertain 200 billion ton figure gets adventurously blamed on Co2 through a long, uncertain and highly complex chain of physical processes — one that ignores an array of natural factors.
“Rate increase” meaningless
Secondly, Mooney’s language sounds dramatic, but the reality isn’t dramatic at all. A worker with an annual salary of $100,000 who gets a raise of $100 this year compared to $50 a year earlier also sees “a rapidly increasing” pay raise “rate” (100%). In reality the raise was meaningless.
Mooney and the media here are using trick language to purvey fake images of significant activity.
Only 0.001% of the total mass
Though the (hugely uncertain) 200 billion ton ice melt figure may sound impressive, it is in fact very tiny compared to the entire Antarctic total ice volume, which according to Dr. Don Easterbrook’s book “Evidence-Based Climate Science: Data Opposing CO2 Emissions as the Primary Source of Global Warming Evidence-Based Climate Science” is estimated at 26.5 million cubic kilometers.
Artefact of statistical torture
200 cubic kilometers of 26.5 million cubic kilometers is in reality only about an estimated paltry 0.001% of the total Antarctic ice mass. And (if it were true) would have only a minor effect on overall sea level rise.
The scientists themselves admit there’s much uncertainty involved and that the calculated 200 billion ton ice loss depends in part on model assumptions. Read more here.
The 200 billion ton figure is indeed more an artefact of statistical torture and modelling. When it comes to complex Antarctic ice mass, you can make the paltry data that’s available say whatever you want.
In this case 80 scientists participated in the waterboarding of the data.
One decade is not climate, but rather weather variability
What is more, the authors compared the last decade to the one before. Well, changes seen in one decade and compared to the one earlier is what we call weather changes, not climate change. Just because one decade is wetter than the one before it, it doesn’t mean the next will be wetter as well. Junk science.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Reality: Antarctic ice area growing rapidly
The satellite imagery and data concerning Antarctic ice area, which go back almost 40 years, in fact show an increasing long-term trend, according to one recently published peer-reviewed study.

Antarctic cooling
And in order for Antarctica to lose ice through melting, the temperature there would necessarily need to rise. Yet the best satellite data we have on this show this is not the case at all.

Satellite data spanning four decades show no temperature increase. The RSS data in fact indicate slight cooling over the past decade where accelerated melting is being claimed. How can cooling cause more melting? Source: here.
Antarctic coastal surface stations show no warming
At Twitter, Japanese skeptic Kirye has been looking at NASA surface stations scattered over Antarctica, most of them near the coast, and found that many do not show any warming, e.g. Casey, Davis, Mawson, Syowa…
Other studies show ice growth!
Moreover NASA glaciologist Jay Zwally published a paper in 2015 showing ice sheet growth in eastern Antarctica had outweighed the losses in the western ice sheet, and so ice mass was growing and not shrinking.
And today Zwally is set to release a new study that will show that the eastern Antarctic ice sheet continues to gain enough ice to offset the losses in the west. “Basically, we agree about West Antarctica,” Zwally told The Daily Caller. “East Antarctica is still gaining mass. That’s where we disagree.”
Zwally believes ice sheet growth is anywhere from 50 gigatons to 200 gigatons a year, the Daily Caller reports here.
Ocean cycles responsible for west Antarctic ice melt
Ice loss in the western Antarctic ice sheet is suspected of being driven by “warm ocean water”, i.e. natural oceanic cycles, and not warming that still has yet to occur over the Antarctic.
Prof. Don Easterbrook concluded in 2016 concerning the West Antarctic Ice Sheet, which everyone loves to worry about:

The West Antarctic Ice Sheet is NOT collapsing, the retreat of these small glaciers is NOT caused by global warming, and sea level is NOT going to rise 10 ft.”

Share this...FacebookTwitter "
nan
"
Share this...FacebookTwitterUnearthed new evidence (Mangerud and Svendsen, 2018) reveals that during the Early Holocene, when CO2 concentrations hovered around 260 ppm, “warmth-demanding species” were living in locations 1,000 km farther north of where they exist today in Arctic Svalbard, indicating that summer temperatures must have been about “6°C warmer than at present”.
Proxy evidence from two other new papers suggests Svalbard’s Hinlopen Strait  may have reached about 5 – 9°C warmer than 1955-2012 during the Early Holocene (Bartels et al., 2018), and Greenland may have been “4.0 to 7.0 °C warmer than modern [1952-2014]” between 10,000 and 8,000 years ago according to evidence found in rock formations at the bottom of ancient lakes (McFarlin et al., 2018). 
In these 3 new papers, none of the scientists connect the “pronounced” and “exceptional” Early Holocene warmth to CO2 concentrations.  

  Mangerud and Svendsen, 2018
The Holocene Thermal Maximum around Svalbard, Arctic
North Atlantic; molluscs show early and exceptional warmth
“Shallow marine molluscs that are today extinct close to Svalbard, because of the cold climate, are found in deposits there dating to the early Holocene. The most warmth-demanding species found, Zirfaea crispata, currently has a northern limit 1000 km farther south, indicating that August temperatures on Svalbard were 6°C warmer at around 10.2–9.2 cal. ka BP, when this species lived there. … After 8.2 cal. ka, the climate around Svalbard warmed again, and although it did not reach the same peak in temperatures as prior to 9 ka, it was nevertheless some 4°C warmer than present between 8.2 and 6 cal. ka BP. … The occurrence of the blue mussel, Mytilus edulis, suggests that climate around Svalbard was 2°C warmer than at present as early as about 11 cal. ka BP.  The climate was about 6°C warmer than at present between 10.0 and 9.2 cal. ka BP, as shown by the presence of Zirfaea crispata.  One single specimen of Mytilus is dated to 900 years BP, suggesting a short-lived warm period during the Medieval Warm Period of northern Europe.”


Bartels et al., 2018
Wahlenbergfjord, eastern Svalbard: a glacier-surrounded fjord
reflecting regional hydrographic variability during the Holocene?
“During summer, AW [Atlantic Water] rises up to waterdepths as shallow as ~55 m. … Summer surface temperatures [1955-2012] range between up to 3°C at the northern mouth and <-1.5 °C at the southern mouth of the Hinlopen Strait, while winter surface temperatures vary between 0.5 and <~1.5°C (averaged, 1955–2012; Locarnini et al. 2013). … Increased summer insolation probably amplified the surface melting of the glaciers resulting in enhanced meltwater production and in a very high accumulation of finegrained sediments within the fjord […].”
“In addition, during the mild early Holocene conditions, summer sea-surface temperatures probably reaching 8–10°C [~5 – 9°C warmer than 1955-2012] (indicated by M. edulis findings as discussed in Hansen et al. 2011) may have contributed to reducing the number of glaciers that entered the fjord directly as tidewater glaciers and thus causing a diminished IRD input.  … In lake sediments from northwestern Spitsbergen a temperature drop of ~6°C is recorded between c. 7.8 and c. 7 ka [-0.8°C per century], which has been connected to a stronger influence of Arctic Water and expanding sea ice (van der Bilt et al. 2018).”


McFarlin et al., 2018
Pronounced summer warming in northwest Greenland
during the Holocene and Last Interglacial
“(Greenland)  Early Holocene peak warmth has been quantified at only a few sites, and terrestrial sedimentary records of prior interglacials are exceptionally rare due to glacial erosion during the last glacial period. Here, we discuss findings from a lacustrine archive that records both the Holocene and the Last Interglacial (LIG) from Greenland, allowing for direct comparison between two interglacials. Sedimentary chironomid assemblages indicate peak July temperatures [Greenland] 4.0 to 7.0 °C warmer than modern during the Early Holocene maximum [10,000 to 8,000 years ago] in summer insolation. Chaoborus and chironomids in LIG [the last interglacial] sediments indicate July temperatures at least 5.5 to 8.5 °C warmer than modern.”

Share this...FacebookTwitter "
"
Share this...FacebookTwitterFlorence shows that atmospheric water vapor dwarfs human emissions of trace gas CO2.
To put some perspective on the scale of water vapor and trace gas CO2 in our atmosphere, let’s compare the two in terms of rainfall from Hurricane Florence alone over the Carolinas and surrounding area.
Surely with man’s fossil fuel profligacy, the emitted CO2 must by far outweigh the water vapor associated with a single storm.
18 trillion gallons of rain
According to hurricane expert Dr. Ryan Maue, some 18 trillion gallons of water vapor could fall as rain from Hurricane Florence over the Carolinas’ region:

Forecast for total rainfall during next 7-days (data from @NWSOPC) is still roughly 10 trillion gallons for North Carolina.
Add in adjacent states that will also be impacted by #Florence gets up to about 18 Trillion total. pic.twitter.com/hpfHeJLA6o
— Ryan Maue | weathermodels.com (@RyanMaue) September 14, 2018


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





To better imagine the scale of this, that’s roughly 2400 one-gallon milk jugs for every man, woman and child on the planet.
70 billion metric tonnes
18 trillion gallons is roughly 70 trillion kg of water mass, which is 70 billion metric tonnes of water vapor in the atmosphere which will end up getting dumped on a few states over a few days by Florence.
Double the weight of human CO2 emissions in one year
How does this compare to human CO2 emissions into the atmosphere?
Globally and ANNUALLY, man emits about 36 billion metric tonnes of CO2 into the atmosphere. That means the water vapor falling as rain over the Carolinas’ region from Florence is double the weight of CO2 man emits into the atmosphere in an entire YEAR.
Human CO2 amounts pales in comparison to the daily global water vapor variations the planet sees. Clearly water vapor dwarfs CO2 in the atmosphere. Claiming that CO2 is the main driver is as silly as claiming President Trump is complicit in creating Florence.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterUnusually cold tropical Atlantic could suppress hurricane activity this year, says Colorado State University hurricane expert Phillip Klotzbach. However cold tropical Atlantic sea surface temperatures don’t necessarily mean reduced hurricane risk.
Colorado State University (CSU) hurricane expert Phillip Klotzback at Twitter commented that the tropical Atlantic sea surface temperatures are the 2nd coldest on record and that this could mean “significantly suppress Atlantic hurricane activity.”

Tropical Atlantic (10-20°N, 60-20°W) sea surface temperatures are currently 2nd coldest on record (since 1982).  Only year colder in early June was 1985.  Could  significantly suppress Atlantic #hurricane activity if anomalously cold SSTs persist. pic.twitter.com/9Rmobo9u3a
— Philip Klotzbach (@philklotzbach) June 6, 2018

Cold tropical Atlantic doesn’t mean fewer hurricanes hitting US!
However history shows that it is purely speculative that cold tropical Atlantic sea surface temperatures will act to suppress hurricanes hitting the US.
Klotzback notes that the coldest tropical sea surface temperatures seen in June were recorded in 1985, and looking at the 1985 US hurricane season Wikipedia tells us that season was in fact a rather nasty one for the entire east coast of the USA:
The 1985 Atlantic hurricane season featured eight landfalling tropical cyclones in the United States, including a record-tying six hurricanes, the most in a single year since 1916.“


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





 
1985 season record “destructive and disruptive”
Wikipedia writes that “the year featured average activity overall” but was “particularly destructive and disruptive for the United States, with damage amounting to a then-record US$4 billion.”
Further, Wikipedia adds: “The entire coastline from Brownsville, Texas, to Eastport, Maine, was under a gale warning at some point during the year and a portion of every state was under a hurricane warning.”
Bastardi warns of the “in-close” threat
Observing the 1985 hurricane chart, we see that the vast majority of the 11 named storms formed “in-close”, relatively near the US mainland.
Meteorologist Joe Bastardi warned in his May 26th WeatherBell Saturday Summary that warm waters near the coast needed real attention and harbored plenty of threat. In no way should people let themselves get casual about it.
So, don’t let all the cold tropical Atlantic surface water fool you into  thinking that the upcoming hurricane season is going to be on the light side for the US coast.
1985 shows us things can get pretty nasty even when the surface of the tropical Atlantic basin is cold.
===============================
Philip Klotzback is a meteorologist at CSU specializing in Atlantic basin seasonal hurricane forecasts. Avid runner, cyclist and hiker.
Share this...FacebookTwitter "
"What will become of UK energy policy now that the Conservative Party holds all the levers? The government has already given clear indications of its plans to pare back onshore wind in recent days. June 24 is the turn of offshore wind, when energy secretary Amber Rudd gives one of her first keynote speeches at the Global Offshore Wind Conference.  Rudd has been described as “really green” in the past, but that is unlikely to reassure the offshore wind industry. With the government apparently committed to nuclear and shale gas and oil, renewables companies are wondering if they still have a place at the table. Here’s how the policy landscape looks to us.  The government’s first big energy decision was confirmed with the announcement that the renewables-obligation subsidy scheme would be closing next April 1, a year earlier than planned. Confidence in the renewables industry has been wrecked as a result, though it goes further than that: the companies supporting renewables are the big power companies. The move is arguably as much a move against them as anyone.    Relations with the Scottish government have been damaged, with Nicola Sturgeon and others describing the decision as “wrong-headed”, “perverse” and “downright outrageous”. Scotland has backed onshore wind for more than a decade as a cheap and proven source of low-carbon electricity. According to industry body Scottish Renewables, the decision will cost Scotland alone up to £3bn in investment and put at risk many thousands of highly paid jobs.  The move will also hit consumer utility bills. Keith Anderson, chief operating officer of Scottish Power, has estimated it will cost consumers between £2bn-3bn in more expensive electricity generation. This will increase the risk of fuel poverty across the UK (which is much higher in Scotland than England). Even before the election, offshore wind was not a good place to be. The sector has seen many projects mothballed and a number of key players drop out altogether in the face of a subsidy regime that is insufficient. Offshore is already now much smaller than originally envisaged. It remains an expensive option in the UK even compared to new nuclear, and although costs are falling, it is not being deployed on the scale necessary to reduce costs to the point that it is commercially viable. If the subsidies are now cut, it will become a dead duck.  Compare Denmark, where the industry is now seeing costs fall dramatically through learning by doing. While the industry has benefited from highly competitive support mechanisms, deployment has been greatly facilitated by having 20% local ownership of projects. Shallower waters have helped too, but the UK could still learn from the Danish approach. Danish offshore wind costs are significantly less than the projected new nuclear build costs at Hinkley Point C in Somerset in the UK, the country’s first new nuclear plant since the 1990s.  The Tories have long backed new nuclear power as the panacea to combat the looming electricity crunch that is often talked about in energy circles. Yet new nuclear is proving so challenging across the world that delivering even one new station will be no easy task.  As Hinkley Point C has already illustrated, the financial costs of new nuclear are enormous, and construction overruns look inevitable. The government also faces an impending legal challenge by the Austrian government over the up to £25bn of state aid required to bring the project to fruition. This could delay completion by up to four years. Meanwhile Greenpeace is suing the European Commission for allowing the state aid to go ahead.  In sum, it might well be 2030 before we see the plant generating any new electricity for UK consumers – about seven years later than intended. This is a big problem for Rudd. Hinkley Point was promising to generate up to 7% of the UK’s electricity demand by 2023, at a time when big coal-fired stations in Scotland and England are closing. New and significant investment in energy infrastructure is needed before 2020 but it is currently unclear where this new generating capacity is going to come from.   David Cameron has also made clear the government’s commitment to shale gas and its desire to repeat the US revolution here. It promises new tax revenues, jobs and a more secure gas supply. Yet these benefits must be balanced  against the need to protect land and water supplies and manage hostile public opinion.  One widely overlooked issue is the infrastructure, which will take time and money to build. Fracking in the US requires an oil price to be at least $60 per barrel to be economical, and in some areas up to $100. With Brent Crude in the new era of mid $60 per barrel, is fracking economically feasible? Evidence from the US suggests not. Earlier this year the Commons environmental audit committee questioned whether fracking was compatible with UK climate-change targets. With the fifth carbon budget due soon to set targets beyond 2027, this presents Rudd with another conundrum. The UN climate change conference in Paris later this year may well prove a very challenging conversation for the government. It is hard to escape the conclusion that this central strand of the government’s new energy agenda has some serious credibility issues.  Put this all together and the government’s emerging approach to wind looks very unwise. New nuclear looks a very costly and unreliable drain on the government’s budget, while fracking looks expensive, incompatible with emissions targets and probably uneconomic at current oil prices. It remains to be seen if these technologies will yield any long-term and positive outcomes for the country. If the government gets it wrong, the consumer could be saddled with soaring electricity and gas bills for years to come. If ever we needed some sign of reprieve for UK renewables, it is now."
"Quorn is to become the first major brand to introduce carbon labelling on its products. The new labels, aimed at helping consumers understand the environmental impact of their shopping, will start appearing on some products from June and on the entire Quorn range by next year.  From Thursday, the “farm to shop” carbon footprint data, certified by the Carbon Trust, will be available online for Quorn’s 30 best-selling products. Quorn claims to be the first meat-free food manufacturer to achieve third-party certification of its carbon footprint figures – via the Carbon Trust – which is being integrated into its own food labelling. It says that in 2018 its products enabled savings of 200,000 tonnes of CO2 equivalent compared with meat. The greenhouse gas impact of mycoprotein – the fungi-based protein used in Quorn products – is 90% lower than beef. The most comprehensive analysis to date of the damage farming does to the planet revealed that avoiding meat and dairy products is the single biggest way in which consumers can reduce their environmental impact, with animal agriculture a significant and fast-growing source of global greenhouse gas emissions. But while Quorn’s products may now be part of a booming industry of meat alternatives – and a key ingredient in Greggs’ new vegan steak bake – that has not stemmed criticism that they are heavily processed and a far cry from natural, plant-based foods. Peter Harrison, chief commercial officer of Quorn Foods, said: “This is about giving people the information needed to make informed decisions about the food they eat and the effect it has on our planet’s climate – in the same way that nutrition information is clearly labelled to help inform decisions on health.” Manufacturers are stepping up efforts to give consumers more information about the environmental impact of their products, despite previous attempts ending in failure. The UK’s largest retailer Tesco, for example, dropped its plan to label all its products with their carbon footprint, after promising “a revolution in green consumption”, blaming the work involved and other supermarkets for failing to follow its lead. Carbon Trust research in 2019 found that two-thirds of consumers support the idea of a recognisable carbon label to demonstrate that products have been made with a commitment to measuring and reducing their carbon footprint."
"We are all going to die. Since the end result is the same, perhaps the way it happens shouldn’t matter, but it does. Given the choice, I’d rather not burn to death. This is probably why the spectre of nuclear war remains so frightening, despite being highly unlikely. The radiation poisoning and horrific injuries we saw in the television series Chernobyl were a reminder of a time when we lived in vivid fear of the power of the atom, whether in the form of a missile or a meltdown.  So the nuclear threat as a preoccupation of our collective consciousness makes sense. But the outsize role it plays in our political discourse is hard to justify. The circumstances in which a nuclear weapon would be used by the UK are so far-fetched that nobody can really describe what they are. And yet every contender for the leadership of a national party is forced to answer the simplistic question: would you push the button? Jeremy Corbyn has been goaded since 2015 for refusing to say yes or no. His pacifist stance probably helped give “the button” an even bigger platform during the election campaign. And now it is becoming a motif of the Labour leadership contest, with Rebecca Long Bailey being asked the same question on BBC Radio 4 on Tuesday morning. The amount of attention given to the prospect of a hypothetical nuclear war seems grossly out of proportion, especially compared to the existential threat we are actually facing: the climate emergency. Labour’s Green New Deal policy, which Long Bailey helped write, was a central theme of her pitch for leader. Yet in the same radio interview she wasn’t asked about it once. The Conservatives mentioned the climate crisis just 10 times in their manifesto. They have no convincing strategy for reducing carbon emissions at the speed required to avert disaster. So, outside of the left, where is the debate? Where is the outrage? Where is the fear? This week social media was flooded with pictures of near-apocalyptic scenes of scorched koala bodies and houses engulfed in flames as images of the fires in Australia spread around the world. Meanwhile, one columnist fumed on Twitter about an environmentally friendly vegan meal served at the Golden Globes. Frankly, we ran out of time for this type of silliness long ago. Global heating is a clearer and more present danger than Britain becoming embroiled in nuclear war. But the latter offers a misleadingly simple scenario: one action is required, and no thought given as to what might come next (pushing the button would be the start of a nuclear war, not the end). The climate crisis, in contrast, is unavoidably messy, requiring a radical overhaul of every system, everything we buy, everything we eat. I can imagine why some would prefer not to think about it. Boris Johnson decided not to bother attending Channel 4’s Climate Debate during the election campaign, and was represented by an ice sculpture instead. In absenting himself, the prime minister effectively announced that, when it comes to the climate crisis, he will not push the button. As that existential threat draws nearer, he will sit back and take no action. But relax: at least he has confirmed he’s willing to save us all by starting a nuclear war. • Rachel Connolly writes about technology, cultural trends and politics"
"Shrubs and grasses are springing up around Mount Everest and across the Himalayas, one of the most rapidly heating regions of the planet. The impact on water supplies of the small but significant increase in vegetation between the treeline and snowline is not yet known but could increase flooding in the vast Hindu Kush Himalayan region, which covers 4.2msq km(1.6m sq miles), feeds Asia’s 10 largest river systems and supplies 1.4 billion people with water. Scientists used satellite data to identify increases in vegetation in the inaccessible subnival (the highest zone allowing plant growth) ecosystem, made up of grasses and dwarf shrubs with seasonal snow. This ecosystem is known but could play a crucial role in the region’s hydrology, covering between five and 15 times the area of permanent glaciers and snow in the region. Studying images from 1993 to 2018 provided by Nasa’s Landsat satellites, researchers from Exeter University measured the spread of vegetation cover across four height brackets from 4,150 to 6,000 metres above sea level. The melting of Himalayan glaciers has doubled since the turn of the century, with more than a quarter of all ice lost over the last four decades. Research has suggested that its ecosystems are highly vulnerable to climate-induced shifts in vegetation. “A lot of research has been done on ice melting in the Himalayan region, including a study that showed how the rate of ice loss doubled between 2000 and 2016,” said Dr Karen Anderson, of the Environment and Sustainability Institute on Exeter’s Penryn Campus in Cornwall. “It’s important to monitor and understand ice loss in major mountain systems, but subnival ecosystems cover a much larger area than permanent snow and ice, and we know very little about them and how they moderate water supply.” It is not yet known how more vegetation might affect water supplies but studies of increased vegetation in the Arctic found that they delivered a warming effect in the surrounding landscape, with the plants absorbing more light and warming the soil. “That would be bad news for the Himalayas,” said Anderson. “The subnival zone is where seasonal snow is held and if it is warmer you will get flashy hydrology – quicker melt rates and an increased risk of flooding.” But Anderson said that more vegetation may not actually increase warming and flood risks in the Himalayas, with the only study in the region, in Tibet, finding that the water in the plants that is evaporated through their leaf surface actually exerted a cooling influence. “We really don’t know much about this area and we need to direct research attention towards it because it’s a major part of the water supply story in the Himalayas,” she added. The study, published in Global Change Biology, was made possible by Google’s new Earth Engine, which provides researchers with a freely accessible collection of government agency satellite data in the cloud. Previously, researchers would have had to build a super-computer to sift through the enormous quantities of satellite data. “It has really revolutionised this kind of work and enables large-scale, long time-series investigations like this to happen,” said Anderson."
"
Share this...FacebookTwitterGive Der Spiegel credit for offering some balance in a debate that sorely needs it…
Geology major, science journalist Axel Bojanowski just penned a commentary at Spiegel Online on the recent hot weather hype we witnessed in the wake of Europe’s warm and unusually dry summer.

Spiegel journalist Axel Bojanowski takes the recent climate heating hysteria head on, writing that the recent shrill claims by some scientists defy IPCC’s own findings. Photo image: cropped from Twitter here.
The title of his commentary: “Overheated – Forest Fires, Drought, Heat – Has The Climate Catastrophe Already Arrived? Time For A Cool Examination.”
Media “part of the problem”
Over the past couple of weeks, alarmists and media from the usual suspect institutes have been stopping at nothing to blame this year’s dry northern European summer on man-made climate change, and have renewed (from within their air-conditioned offices) calls for people to finally accept making the huge sacrifices needed to keep the climate system from “tipping” into irreversible catastrophe.
The Spiegel journalist comments on another shrill column, by Georg Diez, published a week earlier also by Spiegel. Diez echoed the doom and gloom presented to us in Losing Earth: The Decade We Almost Stopped Climate Change by Nathaniel Rich of the New York Times magazine.
According to Diez, it is now clear “what it means to live in a time of catastrophe”.
Here Bojanowski notes “it turns out that many reports are part of the problem.”
Global warming not known and “supported” until the 1990s
Firstly, Bojanowski calls the claim that we knew about global warming already back in the 1970s false, and that it was in reality first an idea that only came up in the 1980s and did not get scientifically supported until the 1990s. He then adds that “considerable uncertainties remain, that still have not been cleared away even until today.”
James Hansen “damaged trust in climate science”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Bojanowski also describes how James Hansen jumped the gun in 1988, and how his methods “damaged the trust in climate science even until today.” Another problem at the time was the media running with the most spectacular doomsday scenarios with the aim of capturing public attention.
Still fraught with “considerable uncertainties”
According to Bojanowski, although Hansens’s dramatic claims did thrust him into the pioneer role, they also contributed “to the division of society in the climate debate, which has made it more difficult to produce political solutions even today.”
He also points out that the media and alarmists continue to ignore the IPCC’s own findings on a number of fronts, such droughts, where he reports that drought scenarios as a consequence of climate change “are subject to considerable uncertainty, according to the UN climate report.”
‘Very sharp decline’ in the fires since 2001
The free-thinking Spiegel journalist also mentions how we seldom hear why fires worldwide have been on the decline over the past decades: “Since 2001, researchers have even noticed a ‘very sharp decline’ in the fires.”
“Debate in dilemma”
Bojanowski calls the media’s hope that exaggerations will motivate people to support climate change “a fallacy”. The more climate scientists hype up the science, the more people will turn away from the topic, he writes, citing sociologists.
Bojanowski’s assessment: “The debate is in a dilemma: only those who push themselves forward with hysteria, get attention.”
No new findings, old speculation
Finally the Spiegel journalist also expressed his surprise over how a recent shrill paper that announced the possibility a hot period was starting needed only 17 days to get published. Bojanowski noted that the paper “did not present any new findings” and that “it was about known speculations over so-called climate tipping points.”
Protecting climate protection
Without surprise, Bojanowski’s commentary was greeted by a less than friendly German reaction. He tweeted here of having been accused of “damaging climate protection”. Climate science dissent in Germany is not to be tolerated. Exercising dissent, or even just keeping a cool head, can make you an enemy of the cause.
 
Share this...FacebookTwitter "
"Despite government commitments to nuclear power, the proposed new plant at Hinkley Point is still some way off. This matters as new nuclear plants could have a critical role in providing the UK with low carbon electricity, while maintaining secure supplies.  Once complete, the new Hinkley plant alone should provide around 7% of the UK’s electricity. However further delays could pose a threat to the security of the UK’s electricity supplies. So is the country facing a looming “power gap” in the early 2020s? Old coal and gas plants will be under increasing pressure to close in the next decade due to the UK’s domestic climate change commitments as well as European air pollution regulations. The EU’s Industrial Emissions Directive (IED) essentially forces plants that don’t meet its standards on emissions to choose between fitting clean-up technologies to remove harmful air pollutants, or accepting strict limits on their operation before a final closure by the end of 2023. This latter option is known as the “limited life derogation”. The full effect of the IED is not yet clear. However, according to Reuters, the UK plants which are currently expected to close before the end of 2023 as a result of the directive represent around 12,000MW of capacity. This is equivalent to around 20% of the country’s peak electricity demand. The major attractions of new nuclear plants in this context are their “baseload” –  or unfluctuating – output, along with their sheer size: the planned Hinkley plant’s output is 3,200 MW. For comparison, the UK’s largest existing offshore wind farm, the London Array, weighs in at 630MW. With Chinese investors showing interest, the government clearly feels nuclear offers the most direct route for filling the gap and thereby avoiding the lights going out. However, with the completion of Hinkley Point by its scheduled 2023 finish date now unlikely, and with firm final investment decisions for other mooted UK nuclear projects not yet taken, the country needs additional solutions. By 2030, nuclear could play a significant role in a heavily decarbonised UK electricity system. However its prospects for the more medium-term horizon of the early 2020s remain uncertain. Although individual renewable projects are small in comparison to nuclear power stations, the renewable industry as a whole is showing that it can deliver substantial amounts of capacity at a rate of megawatts-per-year that is starting to put nuclear planning timsecales firmly in the shade. The longer we wait for nuclear, the more the current government’s “mixed messages” about renewables may themselves seem a threat to security of supply.  Public objections to wind and other renewables have been much publicised; however, there is evidence that innovative approaches to ownership and distribution of benefits within local communities could substantially increase support. Yet even with lots more wind, solar and tidal power in place the UK may still need more conventional capacity by the early 2020s, as the scale of IED closures becomes clearer – not least because variable weather makes it hard for renewables to guarantee full availability at peak times.  It may be that as the European regulations begin to bite, there will be some requirement for new, cleaner gas plants, which could be built relatively quickly. However these plants would have an increasingly intermittent operating schedule, getting called into action only to meet peak demands, or to cover weather-related drops in solar or wind output.  The commercial case for building such rarely-operating plants would be dependent on them being able to make enough money back from this style of occasional operation. The government’s current approach – the “capacity mechanism” – is to pay a retainer fee to generators in return for guaranteeing their availability if called upon at short notice. Faced with a possible shortage of supply, we’ve so far looked at ways to generate more electricity – but, clearly, another is to reduce demand. This could take the form of reductions in the overall level of demand, for example due to increased efficiency – better technologies, switching off lights, and so on. However, just as effective could be shifting electricity usage to avoid coinciding with “peak demand”, the point at which the system is under greatest stress. People or organisations who take part in such arrangements should rightly be rewarded, for example with lower electricity tariffs for providing a useful service to the system and helping to reduce overall costs.  While such innovations are sometimes castigated with headlines invoking the three day week of the 1970s, or “third world” electricity systems, in fact they constitute an economically rational approach to the problem of supply and demand, under which both users and suppliers stand to benefit.  The question of security of supply itself could also benefit from some more sober analysis. Any story which raises the spectre of the lights going out implies it is the responsibility of the government, National Grid, or the energy suppliers to guarantee a system which never fails.  This is not the case. As with all aspects of life, risk is inherent, and the expectation of zero-risk is not reasonable. Rather, the question should be: how much are we willing to spend on reducing risk any further? For example, the capacity mechanism will reduce the risk of supply shortages, in part by guaranteeing back-up plants; however these guarantees cost money, and these costs fall on consumers through their bills. The more secure we want our system to be, the more we will have to pay for it. It’s time for a more constructive debate on the balance between security and cost, including innovative demand-side responses, in the context of our transforming electricity system."
"It is said that on average, we take 66 days to form a new habit.  So when an initiative sets out to change our habits in just 24 hours, there’s cause for scepticism. World Car-Free Day aims to do just that. The thought is that by closing city centres to cars for one day a year, people will make a long-term switch to alternative modes of transport and help us to address the many problems caused by our dependence on cars.  Car-free days have been running for almost 20 years, with cities as far afield as Washington, Paris, Brussels, Stockholm and New Delhi participating. And though the impact of these initiatives has not been well evaluated, there are studies which suggest that events which disrupt the transport system can lead to longer term behaviour changes. Strikes and road closures, for example, force people to try something different, and alter their knowledge and perceptions of the travel alternatives on offer.  One worldwide 2002 study of over 70 road closures due to natural disasters and planned roadworks found that, on average, 11% of vehicles previously using the road could not be found in the surrounding area afterwards. A more recent study on the impact of strike action on the London Underground in February 2014 used data from travel cards to examine travel patterns before, during and after the strike. It found that 5% of travellers carried on using their newly discovered routes after the disruption was over. While these findings sound encouraging, it’s worth questioning whether the changes to travel patterns after a disruption are any greater than the day-to-day variability we see anyway. And if they are, there’s still no guarantee that enough people maintain these changes for long enough to alter overall travel patterns, such as the total kilometres driven from one year to the next. A three-year study on these topics confirmed that individual travel patterns undergo significant day-to-day and year-to-year churn. For instance, although over half of those who were asked by the researchers before and after the 2012 Olympics in London said they had changed their journeys to work during the games, three quarters said they did not always travel to work the same way on a typical day anyway.  Similarly, half of council employees in York revealed they could not be certain how many days they would travel in to the office in the following week. The study revealed that these variations were due to myriad reasons, from changing family and work schedules, avoiding bad weather or just feeling like making a change.  But if there’s so much churn and flexibility in the system already, why is it so difficult to achieve deep reductions in car use? For these reductions to materialise, we need more people to avoid taking single occupancy journeys in their car more of the time, so that being “multi-modal” – that is, relying on more than one mode of transport – becomes the norm.  But to achieve this, we’ll need a much broader understanding of how and what shapes people’s travel choices in the first place, and how this varies across locations and societal groups. The three-year disruption study suggests that we should think about these issues in terms of a broader “mobility system”.  The mobility system includes not only the transport system (infrastructure, legislation, fiscal arrangements like charges and fares, and public transport operators), but also the communication system (patterns of work, shopping and socialising as well as the information we use on the go) and the social context (the norms about how things are done, the know-how and resources of those in the system, including workplaces and communities).  At the centre of the mobility system are the activities which each generate travel and are influenced by the institutions and expectations in the system, such as school start and end times, or standardised business hours.  Unfortunately, the supporters of car-free day – like most policy targeting transport patterns – fall into the trap of thinking that altering the transport infrastructure and services is all that’s required to alter travel behaviour. While these initiatives can play a role in changing the behaviour of some people, for one day, occasionally, it is far from adequate to influence longer term changes at the scale required. Instead, we need to make changes across the whole mobility system, to continually reinforce greater uptake of alternative transport methods.  Flexible working hours, which relax rigid time and place constraints is an important part of the solution, as is wraparound childcare (such as before- and after-school clubs) to allow flexible schedules. Transport system solutions include payment systems to cater for multi-modal journeys such as the Mobility Mixx card in the Netherlands, which can be used to pay for all public transport, taxis, car pool, bike and car rental and park-and-ride tickets. Another option is seasonal reallocation of road space to pedestrian spaces or non-motorised road users as they did in New York.  We need to think more carefully about how, where and when activities are carried out, and then look at how transport provision fits with that. Only then could car-free days go from being rare annual events to part of making non-car journeys more likely, more of the time."
"
Share this...FacebookTwitterNo one understands the causes of weather better than highly experienced meteorologists. And so when it comes to questions about extreme weather events, there is no one better to ask than prominent Swiss meteorologist Jörg Kachelmann (or Joe Bastardi in the US).
Yesterday at Twitter the veteran, high-profile Swiss meteorologist Kachelmann tweeted about an interview he had given with Austrian online magazine profil.at on the topic of extreme weather in Europe, and how the interview was withdrawn before publication.
Low-blow, dirty media
The main reason behind the withdrawal was Mr. Kachelmann taking issue with what he viewed as low-blow journalism by profil.at, who in the introduction needlessly brought up the phony rape charges lodged against Kachelmann 8 years ago by a scornful ex-girlfriend.
Though the former German flagship ARD television meteorologist was cleared of the charges and got through the legal ordeal, his reputation tragically did not survive the media feeding frenzy and gutter journalism.
To make a long story short, Kachelmann yesterday simply posted a draft of the unpublished profil.at interview at Twitter, before later taking it down.
But I managed to read it and so now report on its content.
Click-hungry sites hyping weather extremes 
In the interview, Profil.at questioned Kachelmann about the warmer European springs, weather extremes, serious scientists, and other issues.
On the subject of the recent warmer springs and more severe thunderstorm activity, Kachelmann responded that it has gotten warmer, but that the alleged higher frequency and intensity of extreme weather events has more to do with hype coming from places like Facebook and click-hungry Internet sites.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Not linked to climate change
Kachelmann added it’s normal for large weather patterns “to act up” and that it “has nothing to do with climate change”.
However he does attribute the warmer temperatures and higher humidity to climate change and that it is “statistically significant”, but then reminds that the statistics for weather extremes have yet to be shown as being significant.
“Completely senseless tweets from Greenpeace”
When asked about climate denialism and why people like Donald Trump get votes with climate change denialism, the Swiss meteorologist says: “There’s a lack of scientific knowledge on both sides.”
Next he cited examples from on social media:
Over the last weeks I’ve seen so many completely senseless tweets from Greenpeace and green politicians, who wish to blame without any doubt the daily weather on climate change, often with fake statistics, and so climate deniers are not alone. Serious scientists are working quietly between the embarrassing megaphones on both sides.”
Blame measurement instruments?
As an example of just how absurd the media can be, in the interview profil.at unwittingly displayed a remarkable ignorance of climate (which all-too often prevails among the climate-ambulance-chasing-media) in posing the question: “Are there reliable instruments today that would allow us to determine if a weather event can be attributed to climate change, or indeed to the weather pattern at hand?”
Blaming weather on climate change “idiocy”
Kachelman answers by telling profil.at that weather events unfortunately don’t come with a certificate of origin, and any claim that they do needs to be viewed as “unscientific idiocy”.
Share this...FacebookTwitter "
"Some wild west African chimpanzees are teetotallers, whereas others are frequent drinkers given the opportunity – consuming the equivalent of three pints of strong lager per day.  These findings have been reported in a scientific study that lends support to the drunken monkey hypothesis, which suggests humans and their primate relatives are attracted to the smell of alcohol because in our common evolutionary history this indicates the presence of energy rich, albeit fermenting fruits.  And this could help explain why people and some primates become addicted to alcohol. The latest study, published in the journal Royal Society Open Science, describes how a group of wild chimpanzees in Guinea occasionally found and raided the sites of palm alcohol production. Often drinking from breakfast until nightfall – although, interestingly, only on one occasion was an individual observed who had had a few too many. As I always tell my research group as we head off for a happy hour on Fridays – alcohol in appropriate doses increases creativity and of course helps us relax. It would appear that chimpanzees may also be regulating their intake. Most of us have experienced the consequences of not regulating our alcohol intake – and I like to illustrate this in lectures about social behaviour by citing a 1970s study which used pigs to study alcoholism in humans. Pigs housed in groups of seven were given access to lots of alcohol three times a day. However, unlike the chimpanzees, these pigs overindulged from day one.   Pigs have a fairly rigid pecking order, which of course is hard to maintain when everyone is drunk. In this experiment after a few days the pig that was third in the hierarchy sobered up and moved up to be the dominant individual in the group. The previously dominant pig, perceiving its loss of status, then also “dried out” and regained its place at the top of the food chain.  This situation cascaded down the social hierarchy, except for those at the bottom who appeared to sense they had nothing to lose from being inebriated. Thus – for species which need to maintain their social status and where politicking is important – being able to control one’s alcohol consumption is vital. Vervet monkeys living free on the Caribbean island of St Kitts have also developed a taste for alcohol and are infamous for stealing cocktails from tourists.  Studies have shown that if offered the choice between sugary water or sugary water with alcohol they choose the latter. And will drink enough to change their behaviour, but not necessarily enough to get drunk. A number of studies on the voluntary intake of alcohol in primates and rodents in laboratory settings have shown that manipulations such as separating individuals from their social group for significant periods of time can induce a significant increase in alcohol consumption. This pattern of drinking behaviour may become fixed for a previously stressed or anxious individual.  This explains to some degree why individuals may turn to alcohol – but not necessarily overindulgence.  If you overindulged regularly like the aforementioned pigs you would lose all your social standing. Furthermore, studies of addiction using a variety of highly addictive morphine-based drugs have shown that rats from an enriched environment (lots of space, stimuli and opportunities for social interactions) do not usually use freely available drugs to get “high”. But those moved to rat paradise from a stressful environment (solitary confinement in a small cage without stimuli) where they have become addicted to narcotics, usually give up their addiction.  One cannot help but feel there are important lessons to be learnt from such studies. The question then is, other than humans, which species if any regularly drinks to intoxication? As a child I remember watching videos of staggering elephants who had gotten drunk from eating fermenting marula fruits.  But apparently this documentary was a set-up.  Physiologists have calculated that for elephants to get drunk they would have to eat fermenting marula fruits at four times their natural consumption speed for a whole day: so while possible it is unlikely to be a common occurrence. The hardest drinker appears to be a species of Malaysian treeshrew that regularly drinks naturally occurring alcoholic nectar in doses that would intoxicate humans. But they don’t appear to get drunk, perhaps due to the long evolutionary association between these animals and alcohol. All this suggests that if the drunken monkey hypothesis is correct, humans and our ancestors were probably not regulars at nature’s bar. But as Berkeley primatologist Katherine Milton points out, it could just be that humans like the intoxicating effects of alcohol, especially because its use is often promoted culturally and drinking excessively is not frowned upon in all societies."
nan
"
Share this...FacebookTwitterLong-term data show that Germany’s summers have gotten wetter over the past three decades, thus contradicting widespread media claims to increasing droughts over Central Europe.
Retired German meteorologist Klaus-Eckart Puls presents an analysis of Germany’s hot and dry summer this year at The European Institute for Climate and Energy (EIKE).
This summer produced a number of blaring headlines which claimed the unusually warm and dry weather was an undeniable sign of things to come. Climate experts warn that summers in Germany will certainly get hotter and droughts will become increasingly common, along with episodes of heavy rainfall accompanied by destructive high water.
According Puls:
Climate alarmists and the compliant media have now predicted hot times and droughts – based a single summer – for the next 100 years and beyond [8]”
No trend towards droughts
However, the veteran meteorologist points out that weather services around the world and even the IPCC have yet to detect any real trends, especially for Central Europe, namely Germany:
Using data from the German DWD national weather service, a plot of summer precipitation in millimeters for Germany was and follows:
&amp;lt;img class=”alignnone size-medium wp-image-48871″ src=”https://www.eike-klima-energie.eu/wp-content/uploads/2018/09/Abb.RR_.KÄMPFE-640×384.png” alt=”” width=”640″ height=”384″ /&amp;gt;
Summer precipitation in Germany: June, July andAugust 1881-2018.
For the summer of 2018, it is estimated that Germany will see a mean precipitation of 128 mm, which will be slightly above the 124 mm record low seen way back in 1911. Summer precipitation has in fact been trending upwards over the past 30 years.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




The above chart shows that there has been no trend in precipitation for Germany since systematic measurements began in 1881.
Early summer a bit wetter
And when analyzing the data for the period known as early summer (May, June , July), then we see that there has been a slight long term increase in precipitation for Germany since 1881:
&amp;lt;img class=”alignnone size-medium wp-image-48872″ src=”https://www.eike-klima-energie.eu/wp-content/uploads/2018/09/Abb.RR_.Puls_-640×452.jpg” alt=”” width=”640″ height=”452″ srcset=”https://www.eike-klima-energie.eu/wp-content/uploads/2018/09/Abb.RR_.Puls_-640×452.jpg 640w, https://www.eike-klima-energie.eu/wp-content/uploads/2018/09/Abb.RR_.Puls_-768×543.jpg 768w, https://www.eike-klima-energie.eu/wp-content/uploads/2018/09/Abb.RR_.Puls_-1024×724.jpg 1024w” sizes=”(max-width: 640px) 100vw, 640px” /&amp;gt;
May-June-July precipitation in Germany. Chart by Klaus-Eckart Puls.
Klaus-Eckart Puls also cites the IPCC concerning global trends for drought: no trend [10]. According to the the IPCC:
There is low confidence in a global-scale observed trend in drought or dryness“.
This summer Germany’s extreme drought intensity was more regional than national. Southern Germany for example, saw less extreme drought conditions, according to the data from the DWD.
To the south in Austria, the summer was also dry, but was only came in the Top 20 driest, according to the Austrian ZAMG national weather service.
In the Austria-wide evaluation (up to August 29, 2018) there was 20 to 25 percent less precipitation than the long-term average. This puts the result among the 20 driest summers in the since measurements began. […] At the top is undisputedly the summer of 1873 with 32 percent less precipitation than average.”
 
Share this...FacebookTwitter "
"For most people in the developed world, getting access to clean drinking water is as simple as turning on a tap. Would that paying for water were so simple. But when we think about the water we consume, few of us realise that as much as 80% of its cost is associated with electricity use – a figure that’s as high in Britain as in drought-prone California. It is surprising, then, that the energy argument rarely features in discussions about preserving water. Yes, water is itself a valuable and vulnerable resource. But when we wash our clothes, have a shower or simply rinse a mug, we should also keep in mind that energy is going down the drain. Let’s talk about our water future alongside our energy future. In a recent report by the Consumer Council for Water, more than 60% of the 100,000 complaints received by water companies in the UK in 2014/15 were related to bills and charges. But how many people appreciate that the steady increase in the cost of water is because of rising electricity costs? Water companies in the UK should take pride in their recent achievements. They have undertaken significant infrastructural upgrades, improved efficiencies in the treatment of water and waste water and have bolstered their renewable energy portfolios.  This increase in renewable energy contributions has been driven by water companies’ commitment to reducing their greenhouse gas footprint by 80%, encouraging them to get more of their power from alternative sources.  Indeed, renewable technologies have the potential to provide enough homegrown power to make the sector self-sufficient. Scottish Water is leading the way in this, but it will still be a few years before savings can be passed on to consumers. Even then, can we guarantee that domestic users will ever benefit fully? The prevailing attitude in the UK is that our fickle climate is far too wet for water shortages, but the truth is that we are running low on water where it is most needed. Our cities are growing as more and more people move from rural areas, but the rain doesn’t necessarily follow them. Our water networks, therefore, are under more pressure than ever to move water around the country to where demand is highest. In some cases, the pressure can be too much and this can cause leaks. Fortunately, we have valves that can release the excess pressure safely. But pressure lost is also more energy wasted. For water companies, investing in micro-hydropower for energy recovery  and increasing network efficiency are two of the ways forward. These opportunities can generate enough electricity to light thousands of homes, while at the same time keeping our water under a controlled pressure. But we can also improve our ability to harvest rainwater and re-use greywater, which could meet a substantial proportion of Britain’s water needs and up to 94% of the demand in Ireland. This would make countries far less dependent on their tapped supply. Water companies and organisations such as Waterwise are already educating UK domestic consumers about why and how to make water savings. Together, they can make a big difference. When we discuss the future of the water sector, my colleague often quotes the Japanese saying “pursuing the last grain of rice in the lunchbox” – essentially to aim for perfection, and not to miss any of the little opportunities along the way.  It is a lesson that should be applied to our water supply, an area where “very good” shouldn’t be good enough. It is tempting for water companies to chase the big, easy solutions, but they also need to focus on the micro opportunities. Only then, can they get close to perfection, and save us all a great deal in water – and energy – costs."
"The city of Plymouth, on England’s south coast, normally has fairly moderate tides. However this week it will have a 6m “supertide” – the highest tide in 18 years. This comes just days after the celebrated “supermoon”. In fact, many locations along the UK, US and Australian coasts will experience their highest tides for tens of years around September 29 or 30. Coastal roads in Miami, for instance, have already been closed in anticipation of exceptional tides. These high tides may bring water levels uncomfortably close to the tops of harbour walks and flood defences, emphasising the threat of rising sea levels. In the UK they are unlikely to be a major problem on their own unless they coincide with storms (a strong storm surge has a greater impact than even the most exotic of tides). However in other areas, like in parts of America and the Pacific, no storms are necessary: these high tides on their own can lead to nuisance flooding. Tides are controlled by changes in the position and alignment of the moon and sun relative to Earth. Every fortnight – at new moon or full moon – the Earth, sun and moon are in an approximately straight line as seen from space and the additional gravitational pull of the sun causes stronger tides, known as spring tides. Yet each month one set of spring tides is higher than the other. This is because tidal forces are strengthened when the moon is at “perigee” and its elliptical orbit takes it closest to Earth. Tide-generating forces are also enhanced when the moon is directly overhead at the equator, part of a cycle lasting 27.2 days – a so-called “draconic month”. Tides can differ over the course of a year, as the Earth moves from its closest (perihelion) to furthest (aphelion) point from the sun and back. More important is the variation in the sun’s position north or south of the equator, which causes the seasons. The tide-generating forces are greatest at the equinoxes in March and September when the sun is directly overhead at the equator. Spring tides are always higher at these times of year.  Over periods longer than a year, very large spring tides occur when all the astronomical factors we have mentioned earlier coincide.  Two longer-term motions of the moon’s orbit around the Earth are important. These motions (astronomers call them precessions) are the reason we are seeing unusually large spring tides this year.  The first precession is known as the cycle of lunar perigee, and influences tides about every four to five years. The elliptical orbit of the moon around the Earth slowly moves in relation to the sun, completing a full circuit every 8.8 years. This means at either the March or September equinox approximately every 4.5 years the moon is both at its closest point to the Earth, and is also overhead at the equator. The second precession is known as the lunar nodal cycle and is due to a very slow change in the moon’s orbit. Imagine the Earth’s orbit around the sun took place on an enormous sheet of glass – what astronomers call the ecliptic plane. The moon’s orbit cuts this surface at an angle of approximately 5 degrees. Over 18.6 years the moon’s orbit slowly rotates around so it cuts through the ecliptic plane in a different place.  One effect of this is to change how far above or below the equator the moon can reach in its orbit. In 2015 the moon is at the point where it deviates the least from the equator. This slightly increases the chances of the moon being directly overhead at the equator at any given point, and thus coinciding with the other factors that contribute to extreme tidal forces. A lot of things have to fall in place at once to generate record-breaking tides and this year the cycle of lunar perigee and the lunar nodal cycle nearly perfectly coincide, resulting in some of the highest spring tides for decades.  The authors help run the SurgeWatch website and would welcome any photos of high tides during this period."
"
Share this...FacebookTwitterUsing data from the Danish Meteorological Institute (DMI), Japanese skeptic blogger Kirye just tweeted how Arctic sea ice volume has surged to the 3rd highest level in 16 years.

Data source. Danish Meteorological Institute. Chart source: Kirye.
Today, there’s not a climate ambulance chaser to be found in the Arctic. Some ten years ago, a number of leading experts predicted the summertime Arctic would be ice free by now. Boy, did they goof!
Here’s a chart by Kirye showing a year-by-year plot:

Source: Kirye.
Note that over the past decade the trend has been steady, even somewhat upward.
Once reason Arctic ice is expanding is likely in part due to the cold Atlantic, especially the North Atlantic.

AMM second lowest since 1948
Hurricane expert Philip Klotzbach at Twitter presents a chart showing the standardized AMM for the past July: it shows this year to be rather astonishing:

AMM Index 2nd lowest since 1948. Chart: Philip Klotzbach.
Klotzbach writes:
This July’s Atlantic Meridional Mode (AMM) index value was the 2nd lowest July value on record (since 1948), trailing only 1972. A negative AMM tends to be associated with colder tropical N Atlantic SSTs, higher sea level pressures and less active Atlantic #hurricane seasons.”


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Record low relative tropical Atlantic sea surface temperatures
Moreover, days ago Klotzbach also presented another chart depicting July, 2018, relative sea surface temperatures for the Tropical Atlantic (10°N – 25°N):

Chart: Philip Klotzbach.
As the chart shows, in July they reached a record low since measurements began in 1948. In fact there’s never been such a steep drop over an 8-year period.
The cold temperatures will serve to significantly dampen hurricane activity this year, Klotzbach points out.
Michael Mann hyperventilating, expert hints
Lately there’s also been quite a bit of (hysterical, climate-ambulance chasing) talk about the regional heat waves and “extreme” weather that have hit parts of the northern hemisphere. Obviously they’ve been ignoring the huge cold developments at places they used to like focusing on.
At PBS activist/alarmist scientist Michael Mann attributes it to manmade climate change. However, expert meteorologist Dr. Ryan Maue differs, tweeting here that the factor behind it all hasn’t been behaving unusual at all:
Interesting, climate scientist Michael Mann attributes the last month of extreme weather to a “slow”, “more wild” and “undulating” jet stream. But that’s typical of “summer” in Northern Hemisphere regardless of climate change.
Maue explains:
Typically this jet stream theory is related to Arctic changes e.g. sea ice depletion. Mixed answers from empirical & modeling studies. This direct causal link from climate change to the actual behavior of jet stream in a given month seems beyond our attribution capabilities.”
And:
However, this thinking is consistent w/null hypothesis that climate change impacts [affects, causes, intensifies] all extreme weather events [always]. These jet stream “slow downs” or blocking events are actually poorly understood features of the climate system.”
 
Share this...FacebookTwitter "
"BlackRock, the world’s largest investor, has joined an influential pressure group calling for the biggest polluters to reduce their emissions, after criticisms that it was undermining action addressing the climate crisis. The US investment firm has signed up to Climate Action 100+, a group of investors managing assets worth more than $35tn (£27tn), that pressures fossil fuel producers and other companies responsible for two-thirds of annual global industrial emissions to show how they will reduce carbon dioxide pollution. In February 2019, one Climate Action 100+ resolution put to shareholders of BP forced the British oil supermajor to describe how its strategy is consistent with the Paris climate accord. BlackRock, which manages assets worth $6.9tn including major oil producers such as BP, Shell and Exxon Mobil, has faced a mounting backlash for actions that activists said were preventing oil companies from being held to account. BlackRock has directly voted against multiple shareholder resolutions brought by Climate Action 100+. BlackRock chief executive Larry Fink’s annual letter to investors, expected ahead of the World Economic Forum in Davos on 21 January, has previously called on companies to take more action on the climate crisis. BlackRock has faced protests from environmental campaigners, who have accused the company of hypocrisy for routinely voting against shareholder motions directing boards to take action on the climate crisis. A spokesperson for the investment giant said: “BlackRock has become a signatory to Climate Action 100+. This is a natural progression of the work our Investment Stewardship team has done to date. We believe evidence of the impact of climate risk on investment portfolios is building rapidly and we are accelerating our engagement with companies on this critical issue.” BlackRock is understood to have been considering joining the climate crisis investor coalition for a while and its membership could signal a transformation in how the firm uses its influence to hold the planet’s biggest polluters to account. Fiona Reynolds, the chief executive of Principles for Responsible Investment (PRI), a UN-backed investment group, said: “In joining CA100+, BlackRock is responding to the demands of its asset-owner clients and other groups globally that they take meaningful action to address climate change.” Last year, an investigation by the Guardian revealed that BlackRock’s retail investment portfolio in fossil fuel companies totals more than $87bn and that it is the largest investor in some of the biggest polluters on the planet. Edward Mason, the head of responsible investment at the Church Commissioners, which runs the pensions for British clergy, said: “The Church Commissioners warmly welcome BlackRock to Climate Action 100+ and look forward to working together as we seek commitments from the world’s largest corporate greenhouse gas emitters to achieve emissions reductions in line with the goals of the Paris agreement. “We know from our previous engagement with companies on climate change just how important BlackRock’s support can be for moving companies forward. This is a hugely welcome decision by BlackRock and a step-change for the entire investment industry as it collectively grapples ever more seriously with the financial implications of climate change.” It is thought that BlackRock staff have become increasingly uncomfortable with the criticism from activists and other investors, including the British hedge fund manager Sir Chris Hohn, who last month accused BlackRock of “greenwashing”. In December, the American investors Boston Trust Walden and Mercy Investment Services submitted shareholder proposals to BlackRock, a publicly listed company in New York, calling on it to use its votes to pressure companies to align with climate targets. Timothy Smith, the director of shareowner engagement on the environment at Boston Trust Walden, said he hoped BlackRock’s decision to join the group would prompt other major asset managers such as State Street to start voting on environmental issues. BlackRock has previously argued that its influence is better used in engaging with company managers over environmental issues, rather than exercising their often considerable voting power. BlackRock reports the number of engagements it carries out every year, but does not offer any transparency over the content of those conversations or the position it takes on company-specific issues. • This article was amended on 10 January 2020. An earlier version incorrectly said BlackRock voted against the Climate Action 100+ resolution at BP. BlackRock supported the resolution."
"Victoria police say there is no evidence any of the devastating bushfires in the state were caused by arson, contrary to the spread of global disinformation exaggerating arsonist arrests during the current crisis. A misleading figure suggesting 183 arsonists have been arrested “since the start of the bushfire season” spread across the globe on Wednesday, after initial reports in News Corp were picked up by Donald Trump Jr, US far-right websites and popular alt-right personalities.  Some outlets are reporting this responsibly but the distorted version is all over garbage-tier rightwing media. pic.twitter.com/U9XxmzuKHl The figure included statistics from some states covering the entirety of 2019, rather than just the current bushfire season, which began in September. In Victoria, 43 alleged arsonists were counted among the 183 arrested “in the past few months” and “since the start of the bushfire season”. That Victorian figure was, in fact, the figure for the year ending September 2019, meaning it had no relation to the current bushfire season. “There is currently no intelligence to indicate that the fires in East Gippsland and the North East have been caused by arson or any other suspicious behaviour,” a Victoria police spokeswoman said. The reported figure of 183 also includes 101 individuals from Queensland who were “picked up for setting fires in the bush”. But a Queensland police spokeswoman said the figure included a broader range of offences than arson, including the breaching of total fire bans, and was not a total of arrests, but a total of “police enforcement actions”. “Enforcement action includes charging, restorative justice or cautioning,” she said. Queensland police said between 10 September and 8 January there had been 1,068 reported bushfires in the state, of which 114 had been deliberately or maliciously lit through human involvement and have been subject to police enforcement action. The Australian subsequently updated its story to say the figure covered people “arrested since the start of 2019”. Victoria police said they were investigating a suspiciously lit fire in Euroa on 4 January, which burned through a large area of land but damaged no properties. Its cause remained unknown. NSW police statistics show 24 individuals have been arrested for deliberately lighting bushfires during the current fire season. But a Rural Fire Service spokesman told Sky News on Wednesday that the majority of the larger fires in the state were caused by lightning, and that arson was a relatively small source of ignition. Arsonists have been responsible for some of the bushfires this season – though specific numbers are not yet available. There is also no doubt that arson remains a serious problem in Australia, particularly during heightened periods of fire danger. Arsonists have been responsible for some of Australia’s worst fires, including a fire that killed 10 people on Black Saturday in 2009. But exaggerated claims about arson during the current crisis have also been used to undermine the link between climate change and the longer, more severe bushfire seasons currently being experienced in Australia. Preliminary research from the Queensland University of Technology suggests bots and trolls are involved in spreading disinformation about arson on Twitter. Regardless of the source of ignition, Australia’s scientific agencies all state that climate change is creating longer, more severe fire seasons. On Wednesday, the RFS commissioner, Shane Fitzsimmons, shot down another common argument blaming environmentalists for holding up hazard reduction work. Fitzsimmons said the main obstruction to hazard reduction was weather conditions. Hazard reduction burns are particularly fraught at times of heightened fire risk. ""We are not environmental bastards.""@NSWRFS Commissioner @RFSCommissioner on hazard reduction burning, which he stresses is not the panacea for stopping fires spreading.#nswfires #AustraliaFires pic.twitter.com/Jcm803vBx9 “Hazard reduction burning is really challenging, and the single biggest impediment to hazard reduction burning is the weather,” he said. “And with longer fire seasons, earlier starts and later finishes to fire seasons like we’ve been experiencing in recent times, you get a shrinking window of opportunity for more favourable hazard reduction burning periods.”"
"Nature presenter Chris Packham has used his most recent column for BBC Wildlife Magazine to attack conservation organisations for not doing more to oppose fox hunting and badger culls, or to protect hen harriers. These groups aren’t happy, and the Countryside Alliance has called on the BBC to fire Packham, alleging that he is abusing his power to promote a political agenda they do not agree with.  But this is rather like members of the Labour Party asking for the head of David Cameron because he promotes political policies that are not to their liking. The alliance is a lobby group for rural interests, not a wildlife protection charity. There is necessarily some form of antagonism between the two opposing sides. In any case Packham is entitled to his views. He is not a newsreader for the BBC, but a presenter and journalist for TV series such as Springwatch. He is employed to provide his opinion on wildlife and conservation.  His writings are not the rants of a weirdo on social media, but of someone who holds a degree in biology and participates in wildlife conservation organisations – he’s president or vice president of conservation charities working on to protect bats, hawks, butterflies and birds. Packham is clearly speaking from the position of a well-informed insider. Conservation, including wildlife conservation, is about how we as humans use resources. Packham argues against the over-exploitation or inhumane control of wildlife, especially when it is not based on firm scientific evidence. Others in society prioritise their own desires to make a profit from wildlife or to hunt it – this will always result in conflict.   Fortunately we live in a society where such conflicts are no longer resolved by combat but by democratic processes. In the UK, fox hunting with hounds was outlawed by a vote in parliament and to try to restore it through some backdoor process is highly undemocratic. On fox hunting, Packham is merely stating the wishes of the majority of the UK population. In the case of the badger cull, his position is that held by many prominent scientists. Not that I agree with everything Packham says. I believe he was wrong to say that giant pandas are doomed to extinction and therefore we shouldn’t spend money on their conservation.  All species are doomed, eventually, to extinction, even our own –- the question is whether it will be through natural processes or by our own hand. This is again a political argument about the use of resources, but a useful one to think about for those who donate money to wildlife conservation. The challenges facing conservation organisations both in the UK and abroad are growing exponentially. And if these organisations are to fulfil their remits effectively they need not only to be patted on the back for the great work they are doing, but also to be reminded that there is always room for improvement, which is what I believe Packham has done. His words should be seen as a means of stopping these top conservation organisations from becoming complacent and spouting policies which try to please everyone and end up benefiting no-one.  Packham is creating debate and I would suggest to the Countryside Alliance that rather than calling for his dismissal they get themselves a credible and informed “big mouth” who believes in their cause. Let’s get some debate going.  If they believe their arguments in support of issues such as fox hunting are so compelling, then they should share them with the rest of us and let the democratic processes take care of the rest."
"The climate has been a persistent theme of Game of Thrones ever since Ned Stark (remember him?) told us “winter is coming” back at the start of season one. The Warden of the North was referring, of course, to the anticipated shift in Westerosi weather from a long summer to a brutal winter that can last for many years. An unusual or changing climate is a big deal. George R R Martin’s world bears many similarities to Medieval Europe, where changes to the climate influenced social and economic developments through impacts on water resources, crop development and the potential for famine. We’re interested in whether Westeros’s climate science adds up, given what we’ve learned about how these things work here on Earth. It’s not easy to understand the mechanisms driving the climate system given we can’t climb into the Game of Thrones universe and take measurements ourselves. It’s hard enough to get an accurate picture of what’s driving the world’s climate even with many thousands of thermometers, buoys and satellite readings all plugging data into modern supercomputers – a few old maesters communicating by raven are bound to struggle.  The fundamental difference between our world and that of Westeros is of course the presence of seasons. Here on Earth, seasons are caused by the planet orbiting around the sun, which constantly bombards us with sunlight. However the amount of sunlight received is not the same throughout the year.  If you imagine the Earth with a long pole through its centre (with the top and bottom of the pole essentially the North and South Pole) and then tilt that by 23.5 degrees, the amount of sunlight received in the Northern and Southern Hemispheres will change throughout the year as the Earth orbits the Sun. Clearly the unnamed planet on which Game of Thrones is set is missing this axis tilt – or some other crucial part of Earth’s climate system. The simplest explanation could be linked to spatial fluctuations in solar radiation (sunlight) received at the surface. A reduction in incoming solar radiation would mean more snow and ice likely remaining on the ground during the summer in Westeros’s far north. Compared to the more absorbent soil or rock, snow reflects more of the Sun’s energy back out to space where in effect it cannot warm the Earth‘s surface. So more snow leads to a cooler planet, which means more snow cover on previously snow-free regions, and so on. This process is known as the snow albedo feedback. The collapse of large ice sheets north of the Wall could also rapidly destabilise ocean circulation, reducing northward heat transport and leading to the encroachment of snow and ice southwards towards King’s Landing.   To descend into glacial conditions would require a large decrease in solar radiation received at certain locations on the Earth’s surface and likewise an increase would be needed to return to warmer conditions. This is roughly what happened during the switches between “glacial” and “interglacial” (milder) conditions throughout the past million years on Earth. This is controlled primarily by different orbital configurations known as “Milankovitch cycles”, which affect the seasonality and location of sunlight received on Earth. However, these cycles are on the order of 23,000 to 100,000 years, whereas Game of Thrones seemingly has much shorter cycles of a decade or less.   Around 12,900 years ago there was a much more abrupt climate shift, known as the Younger Dryas, when a spell of near-glacial conditions interrupted a period of gradual rewarming after the last ice age peaked 21,000 years ago. The sudden thawing at the end of this cold spell happened in a matter of decades – a blink of an eye in geological terms – and led to the warm, interglacial conditions we still have today.  Various different theories have tried to explain why this spike occurred, including the sudden injection of freshwater into the North Atlantic from the outburst of North American glacial lakes, in response to the deglaciation, which destabilised ocean circulation by freshening the water and reducing ocean heat transport to the North Atlantic Ocean, cooling the regional climate.  Less likely explanations include shifts in the jet stream, volcanic eruptions blocking out the sun, or even an asteroid impact. The shift from the Medieval Warm Period to the Little Ice Age that began around 1300 AD represents a more recent, and more subtle, example of a “quick” climate change. Although the overall temperature change wasn’t too severe – a Northern Hemisphere decrease of around 1˚C compared with today – it was enough to cause much harsher winters in Northern Europe. None of these events indicate the abrupt transitions from long summers to long winters as described in Game of Thrones – and they still all happen on a much longer timescale than a Westeros winter. However they do demonstrate how extreme climate shifts are possible even on geologically short timescales. Regardless of the causes of the long and erratic seasons, winter in Westeros won’t be much fun. It may even make the struggle for the Iron Throne between the various factions seem irrelevant.  Indeed the House of Stark’s motto: “winter is coming” may have a lesson for us here on Earth. Anthropogenic climate change is one of the biggest challenges facing humankind today and if left unmitigated the potential environmental impact on society may be far greater than any global recession. Stop worrying about the Iron Throne, everyone, winter is coming."
"It makes for a dramatic headline, but it is unfortunate that the Guardian has produced such a partial report on what a council meeting in York decided (York to ban private city centre car journeys to cut air pollution, 1 January). The city tried to ban cars from crossing a single bridge in 2014 and it ended in failure – not because the idea of banning cars wasn’t a worthy one but because sticks have to be accompanied by carrots or they do not work. Banning cars is the easy bit. But what do you put in its place? Light rail? Biogas buses? A tram network? An electric car hire scheme?  York declared a climate emergency in March 2019 and the cross-party climate change committee is charged with delivering a zero-carbon future. Liberal Democrat, Green and Labour councillors are working to transform our response to the climate emergency. The committee has recommended the council adopt a cumulative carbon budget for 2020-30 and a science-based approach to evaluating the carbon cost of our activities, projects, procurement and investment from here on in. The city’s Lib Dem-Green administration is considering introducing amendments to this year’s council budget to enable these proposed changes to be implemented. Turfing people out of cars without producing a viable and attractive alternative is a recipe doomed to failure. Major investment is required and we must take residents and businesses with us. I believe we can. There is no planet B.Cllr Christian VassieChair of climate change committee, City of York council • Your article on York highlights how important it is for both central and local government to take urgent action to reduce air pollution in our cities and tackle the climate crisis. Transport is the only sector where CO2 emissions are rising as our reliance on motor vehicles remains at an all-time high. If we are to reduce harmful emissions, we need to make walking and cycling the most attractive option for short journeys. Bike Life 2017 – the UK’s biggest assessment of cycling in cities – revealed that 53% of people would like to start cycling or cycle more, but its perceived danger is still a barrier. Initiatives to take more cars off the road would make people feel safer and more confident. However, this is only a first step. To see a significant reduction in air pollution and meet the target of becoming carbon neutral by 2050, the government must commit greater funding to build dedicated walking and cycling infrastructure in our towns and cities. Until we end our reliance on motor vehicles, we will continue to live with dangerous levels of air pollution. The government must take action to ensure all cities can introduce changes such as this, and that streets are designed with people in mind, rather than motor vehicles.Rachel WhiteHead of public affairs, Sustrans • Your editorial (27 December) says that “In the age of climate emergency the car is no longer the star”. The car has never been the star – more an asteroid that hurtles on our roads, too often out of control. A significant omission from your long editorial was the annual global strike rate: 1.35 million killed, countless millions suffering life-changing injuries, many of whom are pedestrians and cyclists. Any other machine with this killing record would not be tolerated by intelligent caring creatures. No mention was made of the behavioural changes that overcome some otherwise careful and considerate individuals. Once behind the wheel of their box, they are isolated, feel secure and, with terrifying power under their feet, become reckless toads of our roads. Phase out the car, run trains on our motorways, trams and buses on our A roads, walk and cycle shorter town and city distances. Learn to share again and liberate our urban centres from the tyranny of the private car with all its undeniable ills.Dick FollowsLancaster  • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"Australia’s unprecedented bushfires are a wake-up call to the world about the importance of tackling climate change, Bernie Sanders’ economic adviser said, and the country should consider implementing a green new deal to transition to a low carbon economy. Stephanie Kelton said Australia could benefit from an ambitious program of spending, similar to the one proposed by Sanders and others that aims to transform the US economy and help keep global heating below 1.5C.  She told the Guardian that Australia’s longstanding bipartisan commitment to running a budget surplus where possible was “economically illiterate”, and governments should concentrate on getting the economy running properly rather than “what number falls out of the box at the end of each fiscal year”. “As tragic as the situation is here, it does seem to be serving as a real wake-up call for people living in all other parts of the world – I mean, the world is watching,” she said. “People are really starting to come to terms with the realities of climate change as a result of seeing these images and the devastation here. “I don’t know if it will provide that breakthrough moment that is necessary for galvanising the world around a shared commitment to dealing on an ambitious scale with the threat of climate change, but it feels like it has the potential to unleash that.” Kelton is in Australia to speak at a conference on the Green New Deal and other economic issues in Adelaide on the weekend that is supported by the School of Economics of the University of Adelaide, where Kelton is a visiting professor. Kelton will also be meeting with businesspeople at private events organised by accounting firms. The idea of a Green New Deal has been championed by New York congresswoman Alexandria Ocasio-Cortez, who has pushed the idea within the Democratic Party. In the version that forms part of Sanders’ presidential pitch, it would involve the US government spending US$16.3tn on decarbonising the economy, including by moving to renewable energy, upgrading public transport and funding a “just transition” for workers who lose their jobs in the resources industry as a result of the changes. The deal “is an ambitious response to the imminent threat of climate change on a scale that is commensurate with the threat that we are facing”, Kelton said. “To do something like this in 10 years time requires a mobilisation that is sort of parallel to what we did in world war two”. She said the economy would look very different after a Green New Deal. “We’re building a care economy, we’re caring for our community, we’re caring for people and we’re caring for the planet,” she said. “You can imagine millions and millions of people being put to work doing jobs that are associated with building a cleaner, safer, more secure and more prosperous economy.” She said a lot of people thought there was a tension “between jobs and growth or taking care of the planet”. “What the Green New Deal says is that we don’t have to pick one. “People have more secure jobs, higher paying, better paying, more prosperous economies – more savings, more wealth.” Kelton said Australia could “absolutely” benefit from a similar program. “This is definitely not conceptually a program that couldn’t work in any country,” she said. She mocked the idea it was “too hard”. “Imagine if we had said that after the bombing of Pearl Harbor – oh, I don’t know if we can fight back against the Nazi invasion and the threat. I don’t know, it seems awfully hard.” She said that the US pulled off the original New Deal under president Franklin D Roosevelt in the early 1930s, when the country was “about as poor as it had ever looked”, with unemployment running at about 25%. “What did FDR do? He came in, he advanced an alphabet soup of programs … he just created employment for millions and millions of people. “When you’re under threat and the alternative is just to let it burn? Somehow we muster to solve big problems when our lives are at stake – and they are.” Kelton is also one of the leading proponents of modern monetary theory, a controversial economic school of thought that holds that governments should simply print more money to finance spending needed to revive the listless global economy – as long as doing so does not cause inflation to soar. This contrasts with conventional economic thinking, which generally holds governments need to finance spending in excess of their incomes by borrowing money. She has little time for the Australian political scene’s obsession with running a budget surplus. “I don’t want to be disrespectful, but it’s economically illiterate,” she said. “It is the wrong way for a government to behave – in other words, prioritising a budget outcome as if the numbers that get churned out of the budget box each year are what matter. “I always say that governments that behave this way are willing to force their economies to balance their budgets and what I would do is the opposite of that – I would use my budget, allow my budget to balance the broader economy. “I don’t care what number falls out of the box at the end of each fiscal year as long as it delivers good macroeconomic conditions. “So if I have full employment, if my inflation rate remains low, I am indifferent to the budget outcome.”"
"When a gunman entered Sandy Hook elementary school and murdered 20 children and six adults after killing his mother in their home, the shock was so great you could assume that America would undergo a profound shift in consciousness. In addiction parlance, Sandy Hook was the rock bottom moment – where things are so bad you know they can no longer continue as is. After rock bottom, there is a choice: stasis and misery or growth and transformation.  With Sandy Hook, many of us in Australia assumed that after the grief, there would be a reckoning: the National Rifle Association would lose much of its power and influence, its spokespeople and shills would become pariahs, and meaningful legislation would pass so that this tragedy wouldn’t happen again. Right? Wrong. Since Sandy Hook, when much of the world said “never again”, 2,348 mass shootings have occurred. The number rises every day. For America, a shift in national consciousness did occur, but powerful interests (and the politicians beholden to these interests) stopped growth and transformation. Stasis and misery followed. From the other side of the world, many Australians were confused and appalled. How hard can it be, we tweeted, lectured and hectored. Even our conservative former prime minister John Howard did the rounds of the US late-night shows to explain how he enacted radical gun reform measures, how Australia used the painful and shocking experience of the Port Arthur massacre to change and evolve. There was more than a hint of moral superiority in how much we liked telling Americans they must lay down their weapons, that they needed to wake up. But soon it will be our time to look in the mirror. This apocalyptic-seeming Australian summer is our Sandy Hook moment. We have to seize it and change our thinking, our priorities and our politics. In doing so we can change our country, our future, and transform ourselves into global leaders on climate change. These fires without precedent have the potential to profoundly shift the national consciousness. This summer could shake us awake – if we let it. But if we don’t do it now, while things are raw and real, we never will. The alternative is bleak: another lost year, another lost decade. That’s another year of willing yourself to forget that 49.7C day in Penrith, of trying to block out the pictures you saw on social media of charred animal carcasses and the ash you see falling from the sky and the image of the New Year’s Day sky that turned black at 4pm, of the people you saw on television who tried not to cry when they said their house had burnt down, but were thankful to be alive. Of the friends you had to call in the fire zone to check if they were OK. It’s trying to forget the footage you saw of the woman who ripped off her shirt and ran into the bush to save a burning koala. Of the photo you saw of the people standing in the sea in the middle of the night, in the dark, as the fire tore down to the shore. Of the exhausted Nelligen firefighter who had seen seven houses lost that day, who collapsed on the ground – but not before he told the prime minister to “get fucked”. Of the tornadoes made of fire lifting up fire trucks weighing tonnes, of nightmarish dashcam footage of flames coursing through a fire truck with people in it, of vast fire fronts meeting up that are too big too fight (and the forests, lit up at night, look like when you’re on a plane, flying low over a metropolis). Of the man who died in Batlow of a heart attack after helping defend his friend’s home. Surely these things are powerful and terrifying enough to change us? What might our transformation look like? It might look like a simple acknowledgement of causation between climate change and this summer’s fires. Transformation is recognising the facts: Australia is a climate vandal, led by wreckers. We are ranked the worst of 57 countries on climate policy. Australia is the largest exporter of coal to the world, a global top 10 deforester and a world leader in mammal extinction. Our carbon-loving prime minister, supported by the Murdoch media and fossil fuel industry, came into parliament carrying a lump of coal. Climate scientists have proven time and time again, the link between carbon emissions and global heating. The ferocity of these fires was predicted. Once this causation has been established in our minds, we can and we must demand that the government create a meaningful climate policy. The painful lessons of this summer could be transformative, if we allow them to be. Australia – having experienced the pointy end of the climate catastrophe – could become a leader in the global fight to reduce emissions. The alternative is stasis and misery – or even more awful (and currently unimaginable) – a worsening of the current condition, a death spiral. When rock bottom is hit, change can happen. Four thousand people evacuated to a beach on New Years Eve. This is rock bottom. The largest evacuation in Australia’s history. This is rock bottom. One third of the koala population on the New South Wales mid-north coast  being destroyed, and the entire ecosystem ravaged. Again, rock bottom. This is our Sandy Hook moment. We must seize it and demand an effective climate policy. Or nature will be forced to teach us her hard lessons – over and over and over again. Brigid Delaney is a Guardian Australia columnist "
"“Two more just died in the last few minutes,” Tom Grant said as he inspected a lamb that had fallen to its haunches. “When they’re like this they give up. They just give up.”  Grant and a crew of helpers spent Tuesday carrying out the grisly task of burying about 200 sheep killed on his property near Cobargo near the New South Wales coast when fires tore through the area in the early hours of New Year’s Day. As he spoke to the Guardian, more of the lambs who survived the blaze dropped to the ground. “The only water I’ve got for the ones who are left is what’s in the troughs, and we’ve got very little feed,” he explained. “There are about 10 cattle we still haven’t found. If they do show up I don’t know what I’m going to feed them.” “A lot of them were our breeding stock for next season. We lost all four rams, too. It’s roughly $36,000 to $40,000. We’re insured though, so don’t feel too sorry for us.” A white pony which Grant had dressed as a unicorn for his grandchildren recently was also among the dead animals collected on Tuesday. Grant was one of dozens who lost his home in the blaze. As he used a tractor to lift sheep carcasses into a truck that then dumped them into graves dug with an excavator, his son Paul explained that Grant and his wife had built the home together as part of their retirement. “I think this will be it for them now,” Paul Grant said. “They’d talked about downsizing in the future and I think this will just speed that up. It’s pretty heartbreaking, though. Mum’s really gutted but I suppose at the end of the day it’s just things. Funny how life has a way of changing your plans for you, though.” All across the southern part of NSW, similar scenes are playing out as the clean-up continues.  More than 1,500 homes have been destroyed in the state since the start of the unprecedented fire season, and a record-breaking area of land – 4.9m hectares (12.1m acres), an area larger than Denmark – has been burned, according to the latest figures released by the Rural Fire Service. Almost 118 fires continue to burn across NSW with 50 uncontained. About 100km north, in the beachside suburb of North Rosedale, Dafydd Gwynn-Jones and his daughter Caitlin had driven down from their home in Canberra to find the ruins of the holiday house his parents built 41 years ago. As they dug through the rubble – “that was the door, that was the fridge” – searching for mementos that might have survived the fierce blaze that has levelled about 75% of this holiday suburb near Batemans Bay, they reflected on something that had always been there but now was not. “For my sister and I this house was pretty much the one constant,” Caitlin said. “We’ve lived in different cities, Sydney and Canberra, and different houses, but this was the one place that was constant. We tried to come here every year in the summer. Tried not to take it for granted.” The damage here is almost surreal. This small, out-of-the-way suburb was almost entirely levelled in the early hours of New Year’s Day. The panoramic views across the Pacific Ocean that drew holidaymakers are now offset by a brutal carnage. “It will take a long time to rebuild this place, a long time,” Dafydd Gwynn-Jones said. “But we absolutely will.” The bushfire emergency gripping the east coast of Australia did not begin with the New Year’s Day fires, and with more dangerous conditions expected this week it probably will not end with them either. But across hundreds of kilometres, the first week of 2020 has seen a trail of destruction. On Saturday, as thousands of Rural Fire Service volunteers battled an onslaught of  emergencies sparked by blazing heat and relentless winds, the Guardian watched as the sky in the Snowy Mountains town of Adaminaby turned black by 3pm. As the fire peaked over a ridge near the town and headed towards properties defended by thinly stretched fire crews, the RFS group captain, Scott Lonard, simply did not have the resources to protect all of them. “We’ll do our best but five trucks for this much space isn’t going to be enough,” he said.  While milder conditions on Sunday brought a reprieve for the mountains, a strong southerly wind only exacerbated things in the far south coast town of Eden. When it was evacuated on Sunday many in the town fled about half an hour north to Merimbula or west to Bega. When the evacuation centres in those towns began to fill, people began camping along the waterfront or under overpasses, a flood of people left with nowhere to stay and nothing to do but wait. “I don’t know when I’ll get back into Eden and to be honest I wouldn’t want to go back yet,” John Ironmonger said near the water at Merimbula on Sunday. “Everyone here has just been shuffled around from place to place.” When the Guardian spoke to Shelley Caban in her makeshift shelter on a bus on the Eden wharf, she had no idea whether the historic 150-year-old home she lived in with her husband and three daughters just south of the town had survived. By Tuesday it was still standing, but with conditions expected to deteriorate again the family are not out of the woods yet. “It came to literally within a paddock of the house and then the rain started,” she said. “In a weird way I’m kind of at peace with whatever happens now. I just want it to be over one way or the other.”"
nan
"New Zealand has experienced its fourth-warmest year since records began in 1909, with temperatures between 0.5C and 1.2C higher than annual averages across the country. There were 100 new daily temperature records set at spots around New Zealand.  The country has not experienced the severe weather extremes that have plagued neighbouring Australia and its climate is traditionally much more temperate. But the “trend towards warming shows that we are affected by climate change”, said Professor James Renwick, a climate scientist at Victoria University Wellington, in comments to New Zealand’s Science Media Centre. Renwick said that seas around New Zealand experienced “record warmth” in many locations. While the country’s climate was variable, mean temperatures had exceeded the 1981-2010 average in 80% of the past 20 years. “That’s how a warming climate works,” he said. “We see ups and downs but the chances of a warm year are increasing all the time.” Stronger than usual westerly winds blowing across the country had resulted in droughts. “The knock-on effect of this is we start 2020 with many eastern and northern regions of the country thirsty for some significant rainfall,” Lisa Murray, a meteorologist at New Zealand’s MetService, told the Science Media Centre. While rainfall was up in some parts of the South Island, large areas of the country had only 50-80% of their usual rainfall, according to National Institute of Water and Atmospheric Research figures. “This pattern is what we are likely to see more of as the climate changes this century, with more frequent drought and increased fire danger in eastern regions and in the northern North Island,” said Renwick. In other areas, however, flooding would be more common. “The average amount of moisture in the air is strongly related to temperature, so as the climate warms, heavy rainfalls become heavier and flooding becomes more common.” The MetService introduced a severe red weather warning in 2019 to caution people about destructive weather events that required immediate action, Murray said."
"
Share this...FacebookTwitterAnother paper titled The Solar Wind and Climate: Evaluating the Influence of the Solar Wind on Temperature and Teleconnection Patterns Using Correlation Maps lends great support to the claim that solar activity plays a major role in driving the Earth’s climate, and that CO2’s impact is being grossly overstated.
Hat-tip: Kirye.

The paper, authored by a team of researchers led by Japanese physical chemist Dr. Kiminori Itoh, photo right, examined the influence of changes in solar activity (solar wind in particular) on surface temperatures and major oceanic oscillations such as the Arctic Oscillation and the Pacific Decadal Oscillation, which have great impacts on regional and global climate.
The researchers feel that the major drivers of the Earth’s climate are more related to the sun and the oceans, and CO2’s role has been exaggerated.
Sun and oceans play great role
The paper cites, for example, Levitus et al., which found multidecadal temperature oscillations with magnitudes as large as 4°C for the Barents Sea at depths of 100–150m and that the timing of the oscillation coincided with the Atlantic Multidecadal Oscillation (AMO), a major factor in the Atlantic Ocean.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->





Chart: Itoh 2018.
IPCC models shoddy, major factors “not adequately represented”
The team of scientists found a clear influence of the solar wind on climate, and thus solar activity “should be considered much more than conventionally believed”.
The authors state, “once its mechanism becomes clearer and incorporated into climate models, it will greatly contribute to policy development.”
“The effectiveness of climate models is greatly reduced when the influence of the sun (and moon) is not adequately represented,” they state in the paper’s conclusion.
Dr. Kimimori Itoh has been a harsh critic of the mainstream, narrow scientific view that trace gas CO2 acts as the main driver behind global climate. He once called it “the worst scientific scandal in history” and that “when people come to know what the truth is, they will feel deceived by science and scientists.”
Dr. Itoh photo: cropped from Twitter.
Share this...FacebookTwitter "
"Scott Morrison has rejected criticism of the Coalition’s climate change policies amid the ongoing bushfire crisis, as a growing number of MPs privately concede that the government needs to do more to match the rising tide of concern over the issue. As firefighters continued to battle out-of-control bushfires across four states on Friday, the prime minister said it was “disappointing” that people were conflating the ongoing fire crisis with Australia’s emission reduction targets.  “We don’t want job-destroying, economy-destroying, economy-wrecking targets and goals, which won’t change the fact that there have been bushfires or anything like that in Australia,” Morrison told Sydney radio, 2GB. “The suggestion that there’s any one emissions reduction policy or climate policy that has contributed directly to any of these fire events is just ridiculous and the conflation of those two things, I think, has been very disappointing.” He said the government would “continue to consider our policies carefully here”, while conceding to the ABC that the bushfire crisis had elevated the debate over the government’s stance on climate change. “I think the public opinion on this issue, has been heightened across a whole range of factors and climate is one,” Morrison said. “But I mean, there are a range of other things … the drought, which is not unrelated to the issues we’re talking about, but the hazard reduction and how we manage that in the future, because hazard reduction has proved to be very difficult in recent times because of the drought.”  Experts have pointed to the link between climate change and an inability to undertake more hazard reduction burning, with hotter, drier conditions and a prolonged bushfire season narrowing the window of opportunity for the practice. When asked if a national inquiry into the fires that canvassed all issues, including climate change, could prompt a “recalibration” of the government’s climate change policies, Morrison said the government would review any recommendations arising from an inquiry. “I’m up to discuss all of those things and there’s no hesitancy or pushback from the government to address any of those things. And I think we have to address them calmly and rationally and in proper context and perspective.” But when pressed on whether he would revisit the vexed issue of energy policy – including the national energy guarantee that Morrison previously supported – the prime minister said that he believed the community wanted him to be “100% focused” on the response effort, rather than drawn into a policy debate. Coalition MPs have also been asked not to engage in public discussions about the government’s climate change policies until after the current bushfire threat has passed, urging a focus on the government’s emergency response. In a phone hook-up with government MPs on Thursday, Morrison also banned backbench MPs from doing any international media interviews, after conservative MP Craig Kelly was lambasted on UK television for denying the role of climate change. But as the prime minister fends off criticism for the government’s climate policies, a growing number of MPs are privately conceding that more needs to be done to match the growing level of public concern about the links between climate change and Australia’s drying climate. An update from the Bureau of Meteorology released on Thursday showed Australia recorded its hottest and driest year on record in 2019, with temperatures 1.52C above the long-term average. MPs say that the view being pushed by Labor and the Greens that the Coalition is not doing enough has penetrated, and will be politically damaging at the next election unless Morrison charts a more ambitious course. This would particularly be the case in inner-city seats where the issue was recognised as a key factor that won Labor votes in certain seats at the last election. A number of MPs have already joined a cross party pro-climate action group, the Parliamentary Friends of Climate Action group, including Liberals Tim Wilson, Dave Sharma, Jason Falinski, Katie Allen, Angie Bell and Trent Zimmerman. MPs told Guardian Australia that they believed the government needed to reposition on climate change, but recognised Morrison could not be seen to be responding in a knee-jerk fashion. The independent MP Zali Steggall, who defeated Tony Abbott on a platform of climate change action, is hoping that some Liberals wanting stronger action will cross the floor to support her bill to establish a climate change action framework. She is planning a public awareness campaign aimed at putting pressure on the government to allow a conscience vote on the legislation. Labor leader Anthony Albanese said the opposition wanted to see “strong action on climate change”, but the party was still considering its position following last year’s election loss. “We will announce our proposals based upon where we’re at closer to the election. We won’t let the government off the hook,” Albanese said. “[But] we want the government to act immediately. We will have strong policies, but they’ll be off the basis of what the starting point is. We don’t want the starting point to be the pathetic response with no climate change policy and no energy policy that we have from this government at the moment.” The environment minister, Sussan Ley, said the “majority view” within the Coalition party room was that climate change was an underlying factor for the fires. “I would say government policy reflects the majority view, and government policy is very clear about acknowledging that climate change and dry sequence years are increasing the frequency and the risk and the intensity [of fires],” Ley told ABC on Friday. She said the view of Kelly and a “minority” within the Coalition were not dictating the government’s policy approach."
"Two schools of thought regarding Hollywood environmentalism were on display at last weekend’s Golden Globes ceremony. In the blue corner were those determined not to stand idly by in the face of the mounting climate crisis, such as Cate Blanchett and Russell Crowe drawing attention to the Australian bushfires. Or Joaquin Phoenix, “not always a virtuous man”, who urged his fellow stars to look at themselves, too, and ditch the private jets. In the red corner was the lone, but unfailingly hectoring voice of host Ricky Gervais, railing against Hollywood hypocrisy. Should any of the winners find their minds drifting to politics while on the podium, they should “accept your little award, thank your agent and your God, and fuck off”.  It could be that the now near-regulation Gervais Golden Globes roast, playing to the court, is in fact an added layer of hypocrisy in the great Hollywood pageant. But it did at least draw attention again to the gap between good intentions and daily practice in the entertainment industry. Film and TV production has a hefty ecological footprint: a landmark 2006 University of California, Los Angeles (UCLA) study estimated that the industry produced 15m tonnes of CO2 a year. That might seem piddling next to the several billion tonnes emitted by the US economy that year, but in its principal sites of operation, such as Los Angeles, Hollywood was a big polluter – more so than the aerospace, clothing, hotel and semiconductor industries. The average film is estimated to produce 500 tonnes of CO2 emissions – as much as running 108 cars for a year With the cast and crew of top-end studio projects now running into thousands of people – from set-builders to sparks, masseurs and makeup artists, to high-end caterers and server-hungry special effects farms – there is no reason to think Hollywood is any less resource-hungry these days. The average film is estimated to produce 500 tonnes of CO2 emissions (equivalent to running 108 cars for a year), but this scales up with its budget; a $50m film can produce 4,000 tonnes. Who knows what something like Avengers: Infinity War racks up in production and beyond? If everyone’s favourite mauve Malthusian, Thanos, had really wanted to do his part for the environment, then finger-snapping half the people on the film’s jet-setting international press tour would have been a good start. Of course, Hollywood, a left-leaning eco-friendly constituency by nature, wants to do its part. From Phoenix to Leonardo DiCaprio, long a spokesman for environmental causes, it is not hard to find film stars and studio personnel who talk the talk and at least partially walk the walk, all the way down to their Prius. The Disney co-chair Alan Horn is the chair of the trustees of the environmental lobbying group Natural Resources Defense Council (NRDC) and in 1989 helped found the Environmental Media Association (EMA), which doles out Green Seal certification for movies that make efforts towards sustainable production. Most major film studios now have sustainability drives to encourage the use of clean energy on set and the recycling of production materials. Independent consultancies exist, such as Earth Angel and the Green Spark Group, to make this happen; the Green Production Guide – developed by all the major studios in the wake of the US pulling out of the Paris climate agreement – helps with finding such companies and calculating carbon footprints. Carbon-neutral productions, achieved through emissions offsetting, are now relatively common. Certain films make a point of pride, or at least of marketing, of their green credentials: Jason Bateman’s 2013 directorial debut Bad Words was the first fully solar-powered production. Unfortunately, it remains virtually impossible to meaningfully audit Hollywood’s eco-credentials because of a lack of overarching information. Only two of the big six traditional studios made their emissions totals freely available online in 2018: Disney (1.93m tonnes) and Sony-Columbia (1.34m). Along with those two, the others make varying corporation-wide pledges, but they remain as airily aspirational as a J Lo romcom: Universal, for example, touts its fuel-efficient transportation fleet as leading its zero-emissions drive, but will not put a date on zero-hour. Before its buyout by Disney, 21st Century Fox announced it was carbon-neutral in 2011, but the term then disappeared from later reports on the subject. The UCLA study, 14 years old and predating the recent sustainability boom, is still the only major overview available. But its authors admit that it is an approximate, anecdotal work, drawn from 43, mostly anonymised, interviews with people working in the industry. When it comes to understanding ecological footprints on a film-by-film basis, Hollywood’s famously gnomic accounting practices get in the way. Few productions release specific emissions information. The benchmark remains Roland Emmerich’s 2004 super-storm thriller The Day After Tomorrow, which because of its environmental theme, came clean about its carbon footprint: 10,000 tonnes, as estimated by Future Forests ($200,000 of a $125m budget was paid to offset this). So establishing general metrics for the ecological imprint of film productions that might help the industry as a whole whittle down emissions and wastage faster is still a far-off hope. The lack of both a clear roadmap and rigorous application leaves Hollywood open to the charge that its eco efforts, despite the growing momentum, are mere greenwashing. Disney’s emissions reductions (aiming at a 50% cut from 2012 levels by 2020) look good on paper until you realise that a high percentage are from its cruise-ship line – and it has just signed on for three more vessels (albeit powered by less-polluting liquefied natural gas). To go back to the Golden Globes, does it matter that this year’s guests were eating vegan in the overall scheme of an event with the kind of footprint that includes a $10,000 (£7,630) gift bag for VIPs? In the absence of true industry-wide practice, Hollywood eco initiatives remain piecemeal, and are usually opt-in or imposed by powerful stars with a conscience. It has been reported, for example, that it was Phoenix who persuaded the Hollywood Foreign Press Association to serve a vegan menu at the Globes. (The effect of his good work was rather undone when Stella McCartney commended him for his “bravery” in wearing a single tuxedo – hers – throughout awards season.) Maybe even the minimum gesture, carbon offsetting, is a form of cheap expiation that stops root-and-branch overhaul of how film productions are run. In the meantime, the disconnect between publicly declared environmentalism and daily practice in Hollywood continues. Not only is blockbuster film-making a resource-intensive activity, but it is part of a bigger superstructure of capitalist enterprise that is inherently ecologically costly. You have to remember that entertainment is market-driven. Audiences don’t want to hear about climate change To take two examples, 2018’s Jurassic World: Fallen Kingdom was touted for its sustainable shoot, distributing reusable water bottles to cast and crew, employing hybrid vehicles and using 75% LED lighting. It also contained product placement or commercial partnerships with Amazon, Jeep Wrangler, Dr Pepper, Dairy Queen and Doritos, among others; putting aside what this great network of commerce represents, the latter brand’s use of palm oil should have been reason enough to think twice. The Amazing Spider-Man 2, from 2014, has been brandished as a best-practice example, earning the EMA’s Green Seal for recycling practices that stopped 52% of the waste it generated from ending up in landfill. But how significant is this when the film comes slathered in placement for production company Sony’s laptops and mobile phones – built with components using rare-Earth elements, the extraction of which has a heavy impact? Hollywood is not alone in struggling with these contradictions. The value of small actions weighed against the bigger picture, whether these efforts are meaningful or self-deluding, is the great middle-class dilemma of the 21st century. But Hollywood is alone in its capacity to draw attention to these quandaries, through the subject matter it chooses to film. Here, again, its record is questionable – apart from documentaries such as An Inconvenient Truth. Environmental themes have never been catnip to Hollywood executives, despite the efforts of the likes of the NRDC to steer film-makers in this direction. Traditionally, they have crept into the context of certain top-tier films, such as Waterworld, AI or WALL-E, but less than a handful of mainstream directors, such as Emmerich, seem willing to engage with the issue directly. Maybe, as the global situation has darkened, there has been movement on this front. From Avatar to Mad Max: Fury Road to Interstellar to Blade Runner 2049 to Avengers: Infinity War to Aquaman, it does feel as if ecological collapse is now more fully normalised in the mainstream. But none of these films dared be explicitly political, whether out of fear of alienating the climate-sceptic middle-American audience, or just of tearing off the veil of Hollywood’s breezy escapism. The Asian mainstream – from Hayao Miyazaki’s longstanding ecological commitment to Stephen Chow’s recent eco-comedy The Mermaid and Bong Joon-ho’s Snowpiercer and Okja – does more heavy lifting. “The thing you have to remember is that entertainment is market-driven. Frankly, [audiences] don’t want to hear about climate change,” the director James Cameron – who is planning to make his Avatar sequels solar-powered and vegan-catered – recently told Variety. He remains doubtful about the impact of ecologically themed films: “I think you can insinuate these ideas into your storytelling. I’ve certainly done that with Avatar, but, frankly, Avatar came out 10 years ago. And in that time our population has grown by almost a billion people, and the effects of that alone on our environment and climate change are devastating. Does [storytelling] do that much good?” Perhaps the problem is the kind of storytelling. Maybe ecologically progressive thinking is too challenging to the capitalist paradigm of which Hollywood remains a central part. It is easier to put everyone’s planetary worst thoughts into the mouths of villains such as Thanos or Aquaman’s King Orm, or to let us wallow in postlapsarian dystopias than to write stories that envisage solutions, or even dig into the complexities. There is no magic gauntlet or golden sea-trident to wish away the climate crisis. But if Hollywood’s recent spate of ecologically conscious blockbusters is itself another form of greenwashing, then – as Cameron points out – we as paying viewers are ultimately responsible. Nothing illustrates this link between the entertainment industry and its consumers more directly than the rise of Netflix. Now, as cinema attendance continues to fall, we are ditching the collective viewing in favour of individual comfort that keeps the energy tab rolling every time we let the autoplay scroll through. It is the audiovisual equivalent of ditching public transport for private vehicles. The impact of this is huge: in 2018, video-related internet – 34% of which was accounted for by video-on-demand services – produced 300m tonnes of CO2; roughly the same as Spain. By 2022, Cisco estimates that 80% of internet traffic will be video-related in a field that is heating up as Disney+ and Apple TV+ chase down Netflix and Amazon. In his Globes speech, Gervais skewered the blind spot at the centre of Hollywood’s current tech obsession: “If Isis started a streaming service, you’d call your agent, wouldn’t you?” It seems like a matter of time before we are served up a Silicon Valley tech billionaire as blockbuster baddie, but that lets us off too easily. If we are demanding that Hollywood be honest about its ecological ledger, that means taking a long look in the black mirror, too."
"The impacts of the climate crisis are now clearly manifesting in ways beyond rising temperatures. In Australia, the conditions for severe bushfires are occurring far more regularly (hot days, dry land and high winds). And the country is now suffering its most intense bushfire season ever. The quantity of land burnt, the smoke pollution impacts, the temperatures and number of homes lost are all breaking historical records. At the same time, Australia is pioneering the denial of climate disaster. There is some interesting research around denialism. Researchers have essentially discovered a strong political divide when it comes to climate science: progressives are much more likely to accept it as fact than conservatives. And presenting climate deniers with scientific information in the hope that they’ll change their minds actually reinforces their rejection, because they are so taken aback by the information. This phenomenon affects solutions, too. If a policy proposal to reduce emissions conflicts with someone’s pre-existing beliefs – if it requires more government intervention in markets, for example – they tend to deny that the problem exists in the first place. Over the course of the past decade, Australia was a laboratory for this type of thinking. Research has shown that “climate scepticism gets substantial favourable exposure in mainstream Australian media”. As a result, Ipsos polling finds that Australia lags behind other nations in “acknowledging the threat of climate change”. And a renewable energy target of 42% – proposed in a landmark report by Australia’s chief scientist – was rejected by the conservative government partly because the number sounded too close to the opposition’s 50%. Rightwing media outlets in Australia have responded to the current bushfires by either refusing to give the story its due prominence or by spreading falsehoods. Specifically, there is a claim emerging that environmentalists have blocked hazard reduction efforts by supposedly opposing dry fuel loads being burned or manually removed. It isn’t one of those half-truths – there’s no truth in it at all. Once spread by a rightwing journalist over 10 years ago, it has been given a new lease of life as a meme on social media. There is a trajectory for memes like this: the idea emerges in the fever swamps of denialist groups, it slowly seeps into fringe blogs, and from those blogs into Australia’s rightwing media. Then fringe political players take it up, and it’s consequently absorbed by leaders from major parties. There is precedent for this phenomenon. In 2018, a fake Starbucks campaign supposedly offering free coffee to people of colour in the US was orchestrated on the 4chan message board; it was then featured on Fox News. There is already evidence emerging of 4chan boards trying to spread misinformation that fires are being started by Muslim terrorists. The latest story doing the rounds is that the fires have been caused by arsonists or even climate activists – and it has been particularly potent. It is currently somewhere between the blogs and the rightwing media; I imagine that it’ll be in the papers – and on the lips of politicians – shortly. In the comments of Sky News Australia tweets, the meme already dominates. The account of Gwyneth Montenegro, a “personal empowerment” influencer, tweeted to her 94k followers “climate terrorism, perhaps?”, which received thousands of retweets before being deleted. A Channel 7 Australia tweet declared that “Police are now working on the premise arson is to blame for much of the devastation caused this bushfire season”, receiving hundreds of retweets despite the voiceover in the clip stating: “7 News has been told that early indications are the south coast fires were likely started by lightning.” It was retweeted by the BBC journalist Andrew Neil with the judgment: “appalling”. The Australian government MP Craig Kelly appeared on Good Morning Britain, insisting that the climate crisis is not to blame for the shocking intensity of the country-wide disaster. Denialism comes directly from other leading Australian politicians. In 2013, this was more explicit, as when Tony Abbott said “fire is part of the Australian experience”, while then-environment minister Greg Hunt used Wikipedia to dismiss the link between the climate crisis and bushfires. The prime minister, Scott Morrison, always teeters at the edges of this style of disaster denialism, using coded digs that suggest there is nothing unusual about what’s going on. “We have faced these disasters before” and “I know how distressing that [smoke haze] has been, particularly for young people who haven’t seen it before” both stand out as examples of Morrison’s strategy: disguise straightforward climate denialism with appeals to “common sense”, collective memory or the misguided passions of young activists. When he won the election in May 2019, Morrison declared it a victory for the “quiet Australians”. That may have been true, but there are far fewer quiet Australians left today, as hundreds of thousands have experienced the largest mass evacuation in the history of the country. Still, anecdotal dispatches from Christmas dinner tables outline the success of rightwing memes in denying that Australia’s disaster is in any way related to the climate crisis. Morrison seals the deal, offering a comforting alternate reality that satisfies the craving to deny anything related to the climate crisis, whether it’s the science, the solutions or the impacts. If it works, it’ll kick off another decade of sustained inaction in a country that has incredibly disproportionate influence on the world’s climate system. This time, we must nip it in the bud. • Ketan Joshi is an Australian energy and climate science communicator"
"A sperm whale’s “click” is the loudest sound produced by any animal – and it has an identifying dialect. In fact, according to a study published in Nature Communications, the whales aren’t born with different vocal chords or a bit of the sea particularly suited to a certain kind of click. They simply acquire their dialects from one another in the same way you or I might have taken on our parents’ accent – by copying what they hear. Sperm whales aren’t the only animals who learn like this. I have spent time with bottlenose dolphins, for instance, in many different locations around the world. One thing that has always struck me is that while these dolphins tend to do the same thing – such as hunt fish or play together – the way they do this can differ quite drastically between populations.  In the late 1990s, Andy Whiten best articulated this “feeling” that field biologists have had for a long time in his study of chimpanzees, the first systematic look at behavioural differences between populations.  Whiten and colleagues showed different groups of chimps did the same thing in drastically different ways, for example the way they used tools to catch ants. These differences spanned the whole activity repertoire of chimpanzees and the authors posited that the best way to explain this variation was simple: chimpanzees have culture. This discovery started the “culture wars”, largely between animal behaviourists and anthropologists, a debate which raised the question of when we could talk about cultural variations in animal behaviour. A scientific approach is to make predictions we can challenge with experiments and observations. For animals to have culture, the observed differences must not be explained by any other mechanisms. The first mechanism is simply genetics: these differences could be “hardwired” in the genetic differences between populations. The second mechanism is landscape differences: for example, a monkey will not be able to crack nuts with a rock if there are no rocks to hand. So the observed differences cannot be caused by the lack of opportunity or need caused by the animal’s environment. Since Whiten’s work, many people have registered differences in behaviour in a wide range of species, which we cannot attribute to these two factors. For example, the detailed genetic work of Michael Kruetzen and his team has helped to dispel the “hardwiring” argument for tool use in dolphins. Cultural differences are something we pick up from others and pass on, it is a social process. We acquire cultural habits from our social circles and importantly by not being exposed to the way other groups do the same thing. So in order for behavioural differences to be culture, they need to be socially learned. Social learning is again a process we now know exist in many of the species we suspect have culture.  Culture can also be a hindrance to forming social relationships; in our case the simple language barrier is often limiting the social interactions individuals can have. So culture and social structure are intertwined in some ways: you are more likely to pick up the habits of individuals with whom you interact; and the more you pick up these habits, the harder it becomes to interact with others outside your group. Back to whales. In the latest study, Maurício Cantor, Hal Whitehead and their colleagues show that cultural difference is the best way to explain why sperm whales live in multilevel societies. This social structure is best described as having several levels of organisation. In the case of sperm whales, individuals live with their extended families, which belong to clans. Whitehead, along with his colleagues, has elegantly shown over the past two decades that it is hard to explain the differences we observed between sperm whale clans without invoking culture.  In their new work, they show these clans are not just a passive aggregation of genetically related families. We need to invoke the influence of socially learned dialects in order to explain the observed clans which Whitehead has been following for two decades. This happened if individuals not only learned from others, but conformed to the most used dialect in their group. So clans are more likely to form because sperm whales learn dialects from their extended family. Multi-level societies emerge from cultural differences and this is another piece of evidence pointing at animal culture. So, animals have culture. Is that culture going to look the same as ours? No. Imagine spending your time underwater with limited vision, but great hearing, and a hankering for squid. The way you are going to interact with others is going to be different, what you can do with your environment is going to be different, your opportunities are going to be different. Different does not mean a “lesser culture”. It means that we have to work hard to leave our human references to understand that culture. Sperm whales learn from others’ habits, and dialects, which are going to shape their lives and influence the structure of their societies. Their culture is unique, so is ours, and the culture of bottlenose dolphins and chimpanzees."
nan
"
Share this...FacebookTwitterThe abysmal track record of computer models in simulating climate trends has increasingly been highlighted in the scientific literature.  Recently published papers indicate that in some cases climate models actually get it right zero percent of the time (Luo et al., 2018; Hanna et al., 2018), or that hydrological models are off by a factor of 8 and 4 of 5 simulate trends opposite to real-world observations (Scanlon et al., 2018).  
Even the model-based assumption that positive water vapor feedback accompanies and amplifies CO2-forced temperature change is not supported by observations, with CO2 climate sensitivity overestimated by 200% (Ollila, 2018).  Simply put, climate modeling is increasingly being recognized in the scientific literature as lacking scientific merit.

ZERO Of The 126 Models Reproduce Recent Pacific Ocean Cooling
Luo et al., 2018
“Over the recent three decades sea surface temperate (SST) in the eastern equatorial Pacific has decreased, which helps reduce the rate of global warming. However, most CMIP5 model simulations with historical radiative forcing do not reproduce this Pacific La Niña-like cooling. Based on the assumption of “perfect” models, previous studies have suggested that errors in simulated internal climate variations and/or external radiative forcing may cause the discrepancy between the multi-model simulations and the observation…. Based on the total 126 realizations of the 38 CMIP5 model Historical simulations, the results show that none of the 126 model historical realizations reproduce the intensity of the observed eastern Pacific [1981-2010] cooling  and only one simulation produces a weak cooling (−0.007 °C per decade).”


ZERO Of 36 Models Capture Greenland’s Recent Blocking/Climatological Changes

Hanna et al., 2018
Recent changes in summer Greenland blocking captured by none of the CMIP5 models
“Recent studies note a signiﬁcant increase in high-pressure blocking over the Greenland region (Greenland Blocking Index, GBI) in summer since the 1990s. … We ﬁnd that the recent summer GBI increase lies well outside the range of modelled past reconstructions (Historical scenario) and future GBI projections (RCP4.5 and RCP8.5). The models consistently project a future decrease in GBI (linked to an increase in NAO), which highlights a likely key deﬁciency of current climate models if the recently-observed circulation changes continue to persist. Given well-established connections between atmospheric pressure over the Greenland region and air temperature and precipitation extremes downstream, e.g. over Northwest Europe, this brings into question the accuracy of simulated North Atlantic jet stream changes and resulting climatological anomalies […] as well as of future projections of GrIS mass balance produced using global and regional climate models.”

IPCC’s CO2 Climate Forcing Values 200% ‘Too Sensitive’, Water Vapor Feedback ‘Does Not Exist’
Ollila, 2018
“The temperature effects of the water and CO2 are based on spectral analysis calculations, which show that water is 11.8 times stronger a GH gas than CO2 in the present climate. … There are essential features in the long-term trends of temperature and TPW [total precipitable water], which are calculated and depicted as mean values 11 years running. The temperature has increased about 0.4°C since 1979 and has now paused at this level. The long-term trend of TPW [total precipitable water] effects shows that it has slightly decreased during the temperature-increasing period from 1979 to 2000. This means that the absolute water amount in the atmosphere does not follow the temperature increase, but is practically constant, reacting only very slightly to the long-term trends of temperature changes. The assumption that relative humidity is constant and that it amplifies the GH gas changes over the longer periods by doubling the warming effects finds no grounds based on the behavior of the TWP [total precipitable water] trend. The positive water feedback exists only during the short-term ENSO events (≤4 years).”
“The validity of the IPCC model can be tested against the observed temperature. It turns out that the IPCC-calculated temperature increase for 2016 is 1.27°C, which is 49 per cent higher than the observed 0.85°C. This validity test means that the IPCC climate forcing model using the radiative forcing value of CO2 is too sensitive for CO2 increase, and the CS [climate sensitivity] parameter, including the positive water feedback doubling the GH gas effects, does not exist.”
“The CO2 emissions from 2000 onward represent about one-third of the total emissions since 1750, but the temperature has not increased, and it has paused at the present level. This is worthy proof that the IPCC’s climate model has overestimated human-induced causes and has probably underestimated natural causes like the sun’s activity changes, considering the historical temperatures during the past 2000 years.”
“The RF [radiative forcing] value for the CO2 concentration of 560 ppm is 2.16 Wm−2 according to equation (3), which is 42 per cent smaller than 3.7 Wm−2 used by the IPCC. The same study of Ollila (2014) shows that the CS [climate sensitivity] parameter λ is 0.27 K/(Wm−2), which means that there is no water feedback. Using this λ value, equation (3) gives a TCS [transient climate sensitivity] value of 0.6°C only. This same result is also reported by Harde (2014) using the spectral analysis method. …There are both theoretical- and measurement-based studies showing results that can be explained only by the fact that there is no positive water feedback. This result reduces the CS [climate sensitivity] by 50 per cent. Some research studies show that the RF [radiative forcing] value of carbon dioxide is considerably smaller than the commonly used RF value, according to the equation of Myhre et al. (1998). Because of these two causes, the critical studies show a TCS [transient climate sensitivity] of about 0.6°C instead of 1.9°C by the IPCC, a 200 per cent difference.”

Observations Have ‘Factor Of Two’ Less Warming Than Modeled Projections
Christy et al., 2018
“All datasets produce high correlations of anomalies versus independent observations from radiosondes (balloons), but differ somewhat in the metric of most interest, the linear trend beginning in 1979. The trend is an indicator of the response of the climate system to rising greenhouse gas concentrations and other forcings, and so is critical to understanding the climate. The satellite results indicate a range of near-global (+0.07 to +0.13°C decade−1) […] trends (1979–2016), and suggestions are presented to account for these differences. We show evidence that MSUs on National Oceanic and Atmospheric Administration’s satellites (NOAA-12 and −14, 1990–2001+) contain spurious warming, especially noticeable in three of the four satellite datasets.”
“Comparisons with radiosonde datasets independently adjusted for inhomogeneities and Reanalyses suggest the actual tropical (20°S-20°N) trend is +0.10 ± 0.03°C decade−1. This tropical result is over a factor of two less than the trend projected from the average of the IPCC climate model simulations for this same period (+0.27°C decade−1). … Because the model trends are on average highly significantly more positive and with a pattern in which their warmest feature appears in the latent-heat release region of the atmosphere, we would hypothesize that a misrepresentation of the basic model physics of the tropical hydrologic cycle (i.e. water vapour, precipitation physics and cloud feedbacks) is a likely candidate.”

Climate Models Are Conceptual And We Don’t Understand The Mechanisms 
Collins et al., 2018
“Here there is a dynamical gap in our understanding. While we have conceptual models of how weather systems form and can predict their evolution over days to weeks, we do not have theories that can adequately explain the reasons for an extreme cold or warm, or wet or dry, winter at continental scales. More importantly, we do not have the ability to credibly predict such states. Likewise, we can build and run complex models of the Earth system, but we do not have adequate enough understanding of the processes and mechanisms to be able to quantitatively evaluate the predictions and projections they produce, or to understand why different models give different answers. … The global warming ‘hiatus’ provides an example of a climate event potentially related to inter-basin teleconnections. While decadal climate variations are expected, the magnitude of the recent event was unforeseen. A decadal period of intensified trade winds in the Pacific and cooler sea surface temperatures (SSTs) has been identified as a leading candidate mechanism for the global slowdown in warming.”


Hydrological Modeling Off By A Factor Of 8, With 4 Of 5 M0dels Yielding Opposite Trends Vs. Observations
Scanlon et al., 2018
“The models underestimate the large decadal (2002–2014) trends in water storage relative to GRACE satellites, both decreasing trends related to human intervention and climate and increasing trends related primarily to climate variations. The poor agreement between models and GRACE underscores the challenges remaining for global models to capture human or climate impacts on global water storage trends. … Increasing TWSA [total water storage anomalies] trends are found primarily in nonirrigated basins, mostly in humid regions, and may be related to climate variations. Models also underestimate median GRACE increasing trends (1.6–2.1 km3/y) by up to a factor of ∼8 in GHWRMs [global hydrological and water resource models] (0.3–0.6 km3/y). Underestimation of GRACE-derived TWSA increasing trends is much greater for LSMs [global land surface models], with four of the five LSMs [global land surface models] yielding opposite trends (i.e., median negative rather than positive trends).”
“Increasing GRACE trends are also found in surrounding basins, with most models yielding negative trends. Models greatly underestimate the increasing trends in Africa, particularly in southern Africa. .. TWSA trends from GRACE in northeast Asia are generally increasing, but many models show decreasing trends, particularly in the Yenisei.  … Subtracting the modeled human intervention contribution from the total land water storage contribution from GRACE results in an estimated climate-driven contribution of −0.44 to −0.38 mm/y. Therefore, the magnitude of the estimated climate contribution to GMSL [global mean sea level] is twice that of the human contribution and opposite in sign. While many previous studies emphasize the large contribution of human intervention to GMSL [global mean sea level], it has been more than counteracted by climate-driven storage increase on land over the past decade.”
“GRACE-positive TWSA trends (71 km3/y) contribute negatively (−0.2 mm/y) to GMSL, slowing the rate of rise of GMSL, whereas models contribute positively to GMSL, increasing the rate of rise of GMSL“

Share this...FacebookTwitter "
"
Share this...FacebookTwitterDespite hysterical headlines from the fake media claiming the weather is weirding out due to man-made climate change, recent studies show that it’s mostly superstition and that our modern climate in fact is well within the range of natural climate variability.
If one really wants to understand today’s weather and climate, it is essential to keep it in perspective with respect to what has happened over the past 1000 years or more. This is why a number of scientists are busy reconstructing past weather patterns at locations worldwide.
Central Asia climate likely dominated by natural cycles
First, a new study published in the journal Climate of the Past authored by a team of researchers led by Feng Chen of the Key Laboratory of Tree-ring Physical and Chemical Research of China Meteorological Administration found that drought records from western and eastern Central Asia capture the regional dry/wet periods and that analyses indicate the existence of centennial (100–150 years), decadal (50–60, 24.4 and 11.4 years) and interannual (8.0 and 2.0-3.5 years) cycles.
The authors suspect that they may be linked with climate forcings, such as solar activity and ENSO.

This would tell us that climate in Central Asia is greatly dependent on the natural factors of solar and oceanic cycles, and not CO2.
Western US droughts worse 1000 years ago
Another recent study just appeared in the Journal of Climate and was authored by a team of scientists led by Toby R. Ault, Department of Earth and Atmospheric Science, Cornell University. The findings indicate that the western United States was affected by several megadroughts during the last 1200 years, especially during the (MCA; 800 to 1300 CE).
The scientists found that such drought events are inevitable and occur purely as a consequence of internal climate variability. The researchers also concluded that the observed clustering of megadroughts of the Medieval Climate Anomaly were more likely to have been caused by either “external forcing or by internal climate variability”.
Canada: Scotian warm water “part of the natural variability “
The journal Continental Shelf Research published a study authored by scientists led by David Brickman of the Canadian Bedford Institute of Oceanography. The team examined the warm subsurface water temperatures in the Scotian Shelf region of Eastern Canada 2012, 2014, and 2015.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




They found that the observed warming trend should be considered as “part of the natural variability of the coupled atmosphere-ocean system”.
AMS: natural variability dominates observed trends
Another a team of scientists led by Elisabeth Kendon of the Met Office Hadley Centre in the United Kingdom published a paper in the journal of the American meteorological Society which found natural variability appears to dominate current observed trends over the southern United Kingdom (including an increase in the intensity of heavy summer rainfall over the last 30 years).
The authors, citing Sarojini et al., 2016, confirmed that the “attribution of rainfall trends to human influence on local and regional scales is not yet possible”. More uncertainty over the human fingerprint on global climate.
Central Europe precipitation anomalies even greater long ago
Finally a paper published in the International Journal of Climatology and authored by Petr Dobrovolný of the Department of Geography, Masaryk University, Czech Republic, reconstructed precipitation in Central Europe (Czech Republic).
 

Source: Dobrovolný et al., 2018.
Their findings revealed two long periods of low precipitation variability, in the 13th–14th centuries and 1630s–1850s, and that precipitation anomalies of larger amplitude and longer duration occurred in the earlier part of the last millennium than those found in the instrumental period. The new reconstruction does not indicate any exceptional recent decline in MJJ precipitation.
In summary, the new studies from all around the world show that weather extremes were as bad or worse in the past than they are currently. Today’s modern climate is in fact well in phase with natural variability.
The papers mentioned above are all presented by Kenneth Richard here.
Share this...FacebookTwitter "
"Fracking is relatively new and hi-tech – and even experts armed with cutting-edge instruments are only just beginning to get their heads around some of the risks involved. No one really knows exactly what it will mean in the medium to long-term. It’s not just that there aren’t enough informed opinions – there isn’t enough conclusive research anywhere in the world to enable anyone to make truly informed decisions on fracking and its risks. So why, then, would a county council in the UK be any different? The issue has come to a head as council officials in Lancashire, north-west England, decide on whether to let energy firm Cuadrilla begin shale gas operations at two sites in the region. Over the past decade, hydraulic fracturing of deep gas-rich shale formations – fracking – has become widespread in both the US and in Europe where there are estimated to be large reserves. Fracking relies on complex technological advances in horizontal drilling and hydraulic fracturing, where pressurised liquid is used to break open underground rocks and release natural gas. It is these advances which have made the production of shale gas economically viable. And fracking can indeed bring considerable benefits in some areas: significant economic growth, reduced carbon emissions and dependence on foreign oil imports. Yet scientists have uncovered numerous examples of potential environmental problems associated with fracking. The truth is that our current understanding of the links between fracking and freshwater and air contamination is still too limited to effectively reduce risks. Given this limited understanding, it seems unreasonable to expect regional authorities, like Lancashire County Council, to take on the burden of decision-making. Different risks are associated with different stages of the process. During exploration and drilling these include the destruction of various habitats and the contamination of drinking water due to spills, well leaks and drilling sludge stored on site, the depletion of freshwater supplies, leaks of volatile organic compounds, ozone and methane from well heads and machinery. During the fracturing and gas production stage, the major issues include surface water contamination, toxic chemicals in the fracturing mixture, depletion of water supplies, methane leakage, increased seismic activity, contamination of both groundwater and surface water, and increased emissions of greenhouse gases. Longer term, there is the risk of watershed contamination, continued leakage of methane and radioactive compounds in waste water. There is also the threat to human health and the environment from prolonged exposure to contaminants – not to mention reduced property values. The US experience should not be used as a model. There, the shale gas boom has in part leveraged the 2005 Energy Policy Act, which made fracking exempt from requirements of the 1974 Safe Drinking Water Act and, practically, limited research and controls on groundwater pollution. A study published in April 2015 in the Proceedings of the National Academy of Sciences in the US reports cases of groundwater pollution due to fracking in Pennsylvania. The detection of this was made possible only through the use of cutting-edge instrumentation not available in most commercial laboratories.  Another document released in early June by the US Environmental Protection Agency contains the results of a long-term study on the potential impact of fracking on groundwater resources. Although it shows that, thus far no consistent evidence has been found of widespread groundwater contamination due to fracking, the EPA recognises that this might well be an underestimation of these effects due to a lack of pre and post-development data, the short-term duration of available studies and limited or undisclosed information on fracking activities. These accounts confirm our limited scientific knowledge on the environmental impact of fracking. So extreme caution is needed before this technique is implemented safely in the UK. Lancashire County Council’s recommendation to allow shale gas exploration at one of the two sites may be allowed within the UK’s regulations, yet even so the council isn’t making a truly informed decision – there’s no such thing. We are surely expecting too much of regional planning authorities that cannot have the necessary expertise or knowledge needed to make a decision on the limited data that currently exists and perform site monitoring using conventional techniques. In order to fully understand fracking risks in the UK independent pilot studies are necessary before the technology can be safely implemented at a scale that makes it economically viable."
"The Trump administration on Thursday unveiled a plan to speed permitting for major infrastructure projects like oil pipelines, road expansions and bridges. It is one of the biggest deregulatory actions of the president’s tenure and comes at the cost of greatly narrowing the use of one of the country’s landmark environmental laws, especially assessments of how developments could exacerbate the climate crisis. Donald Trump is proposing changes that could allow projects ranging from oil pipelines to mines to move forward with far less federal review of their impact on the environment. The plan, released by the White House Council on Environmental Quality (CEQ), would help the administration advance big energy and infrastructure projects, such as the Keystone XL oil pipeline or roads, bridges and federal buildings. “For the first time in over 40 years today we are issuing a new rule under the National Environmental Policy Act (NEPA) to completely overhaul the dysfunctional bureaucratic system that has created these massive obstructions,” Trump said at the White House on Thursday. The proposal to update how NEPA, the 50-year bedrock federal environmental law, is implemented as part of Trump’s broader actions to cut regulations and oversight, a huge rollback effort that has dismayed and enraged environmentalists. Trump on proposed NEPA rollback: ""This is just the beginning. We will not stop until our nation's gleaming new infrastructure has made America the envy of the world again. It used to be the envy of the world, and now we're like a third world country. It's really sad."" “This proposal affects virtually every significant decision made by the federal government that affects the environment,” said the interior secretary, David Bernhardt, a former fossil fuels lobbyist. The proposed rule says federal agencies would not need to factor in the “cumulative impacts” of a project, which could include its impact on climate change, making it easier for major fossil fuel projects to sail through the approval process and avoid legal challenges. A statement from the League of Conservation Voters (LCV) president, Gene Karpinski, said: “President Trump is trying yet again to sell out the health and wellbeing of our children and families to corporate polluters. This misdirected proposal to change the implementation of the National Environmental Policy Act is one of the most egregious actions the Trump administration has taken to limit the federal government’s response to climate change yet.” He warned the implications for access to clean air and clean water and for public input “could be dire”. The proposal would also put one federal agency in charge of overseeing the review process, instead of giving multiple agencies oversight of the process and set a two-year deadline for environmental impact studies to be completed and a one-year deadline for less rigorous environmental assessments. Trump’s efforts to cut regulatory red tape have been praised by the industry. But they have so far largely backfired by triggering waves of lawsuits that the administration has lost in court, according to a running tally by the New York University School of Law’s Institute for Policy Integrity. Over the last few years, federal courts have ruled that NEPA requires the federal government to consider a project’s carbon footprint in decisions related to leasing public lands for drilling or building pipelines. Other proposed changes include widening the categories of projects that can be excluded from NEPA altogether. According to CEQ, the average length of a full-blown Environmental Impact Statement is currently 600 pages and takes 4.5 years to conclude. US federal agencies prepare approximately 170 such assessments per year. Trump, a commercial real estate developer before becoming president, frequently complained that the NEPA permitting process took too long. “It’s big government at its absolute worst,” Trump said of NEPA. Some of the country’s biggest industry groups, including the Chamber of Commerce and the American Petroleum Institute, also have complained about lengthy permitting delays. Environmental groups warned the plan will remove a powerful tool to protect local communities from the adverse impacts of a hastily designed and reviewed project. “Today’s destructive actions by Trump, if not blocked by the courts or immediately reversed by the next president, will have reverberations for decades to come,” said Rebecca Concepcion Apostol, US program director at Oil Change International, an environmental group. The plan will go through a public comment period before being finalized. Environmental groups are expected to challenge the final proposal."
"It’s encouraging to find agreement across the political divide on the potential of new technologies to combat climate change, reduce animal suffering and supplant massive agricultural subsidies. The Adam Smith Institute recently released a paper on the topic that made many of the same points as George Monbiot (Lab-grown food will end farming – and save the planet, Journal, 8 January). One overlooked benefit of lab-grown food is that it may help the UK tackle the crisis in housing affordability. As farming is superseded by precision fermentation, the significant amount of land currently used for livestock farming (including parts of the green belt) will be freed up for development in places that people actually want to live.  However, we’d take a different lesson from the promise of lab-grown meat. Free-market environmentalism and harnessing the power of innovative technologies – supported by market-based measures like a border-adjusted carbon tax – can successfully tackle the problem of manmade climate change without fundamentally uprooting the way we run society. Saving the planet doesn’t have to cost us the earth.Daniel PryorAdam Smith Institute • There are fundamental reasons why the Solar Foods system that George Monbiot refers to can’t compete with plants for sustainable food production. The supply of minerals for bacteria has to be assembled chemically, with all the chemical industry’s environmental downsides. By contrast, plant roots pull the right minerals in the right proportions out of mixed-up traces in the environment, using solar energy to fuel selective concentration at no cost, generating no heat or chemical pollution and requiring no purified water. The machinery by which plants acquire raw materials is itself built by the plant using solar energy in a non-polluting process, not made in a factory. Likewise, the light-energy-trapping machinery of plants is assembled on a planetary scale, with none of the unwelcome by-products of heat and chemical pollution associated with the fabrication of solar cells and wind turbines, and with the generation of hydrogen from water by electricity. The claim that “the hydrogen pathway used by Solar Foods is about 10 times as efficient as photosynthesis” is meaningless if we’re not told which aspects of the two processes are being compared. Unlike food from plants, no industrially generated food could provide the right mix of dietary constituents essential for health, such as balanced vitamins, minerals and bulk fibre. Supplying these as additives cancels any advantage of electric food. Plants are still the only source of food with long-term sustainability.David E HankeCambridge • There is much food for thought in George Monbiot’s paean to precision fermentation. He has undoubtedly made the case that agricultural business as usual is not an option. However, his techno-utopianism needs to come with a hefty side order of the precautionary principle. He acknowledges the likely impact on the agricultural sector, arguing that governments should “help farmers into other forms of employment” (that worked out well for the miners and steelworkers), and that “strong anti-trust laws” will limit the commercial rapaciousness of the new producers (ditto the digital giants and fossil fuel companies). Millions of people globally grow, hunt or raise food not to make money, but to feed their families. Where will they get the cash to buy the new stuff? The science may seem simple, but the politics is a minefield. On top of that we are talking about food, not fuel. Vitamin supplements are less effective for health and wellbeing than a varied, mostly plant-based diet. Will foods based on individual proteins meet all our dietary requirements as well as the complex foods we have evolved to consume? What will be the impact on our gut microbiomes? Or our immune systems? Taste, smell, colour and texture all play a part in palatability: enjoyment is a critical part of our food psychology. No doubt the food processing industry will rise to the challenge of making farmfree food fun, but it could take decades. A rapid switch to such foods would be a massive experiment on the global public: there would need to be clinical trials. We will not reap the potential advantages if the consequences are not fully explored.Georgina FerryOxford • Globally, over 1.3 billion people rely on livestock farming for their livelihoods, either as farmers or as part of the livestock food supply chain. Meat and dairy have known health benefits, and consumption of animal-based food during early life has been linked with lower levels of malnutrition and improved health outcomes. In many ways, British farming is the envy of the world, with high levels of sustainability and sensible land use – for example, most sheep are raised on land that could not be used for any other purpose – and the National Farmers’ Union has committed to the sector being carbon neutral by 2040. It is important to acknowledge that certain types of livestock farming may have issues with sustainability and climate change. But it is not true of all farming systems; and the issues that do exist are being dealt with using the latest research into genetics and biotechnology – for example, recent research has shown that certain types of seaweed can reduce methane emissions from cattle to close to zero. High-profile movements such as EAT-Lancet and Veganuary gain widespread press coverage, yet the fact that the World Health Organization rejected the EAT-Lancet recommendations was largely unreported, and a recent analysis of sales data showed that Veganuary in 2019 was not associated with a reduction in meat and dairy sales. Farmer data also shows that increased sales of alternative milks have not seen a corresponding reduction in dairy sales. The global food system, consumer choices and climate change are incredibly complex issues, and anyone who proposes simple solutions is almost certainly not in possession of all the relevant facts and data. Livestock are an important part of humanity’s future food needs.Prof Mick WatsonUniversity of Edinburgh • Join the debate – email guardian.letters@theguardian.com • Read more Guardian letters – click here to visit gu.com/letters • Do you have a photo you’d like to share with Guardian readers? Click here to upload it and we’ll publish the best submissions in the letters spread of our print edition"
"
Share this...FacebookTwitterJapanese skeptic blogger Kirye posted here at Twitter the latest news on Arctic sea ice volume, which earlier this spring took a sudden and unexpected jump upwards – adding some 2 trillion cubic meters.
What follows is the latest chart from the Danish Meteorological Institute (DMI):

Source: DMI.
As the chart shows, Arctic sea ice volume hasn’t really budged that much since it peaked back inApril.
Less than 4% below the mean
And when one looks at the chart closely, it is seen that the mean Arctic se ice volume for this time of year is just under 25,000 cubic kilometers. Currently we see that volume is the same as it was in 2014, at some 24,000 cubic kilometers.
The deviation from the mean is less than 1000 cubic kilometers, i.e. less than 4%. That means sea ice volume is well within the range of natural variability.


<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Predictions of an ice-free Arctic go back decades
Two days ago the Deplorable Science Blog here reminded us: “Sixty years ago, the New York Times predicted ships would be sailing over the North Pole ‘within the lifetime of our children.’”
The false prophets
In the same article Steve Goddard brings up a 2008 article by the AP’s Seth Borenstein, who quoted climate alarmist, Massachusetts Senator Ed Markey, who then called James Hansen a “climate prophet”.
Both Al Gore and former NASA GISS director James Hansen warned –“echoing work by other scientists” — that the Arctic would be ice-free in the summer by now!
So, add two more names to False Prophets Hall of Fame.
Skeptics right
Ironically the real “prophet” turns out to be Oklahoma Senator, global warming skeptic Sen. James Inhofe, who in 2008 dismissed all the predictions as media doom, and said that Americans weren’t buying it.
Ten years later Senator Inhofe turns out to be right.
Share this...FacebookTwitter "
"
Share this...FacebookTwitterNowadays the usual suspects are busily peddling the idea that Hurricane Florence’s intensity is due to climate change.
For example climate activist Stefan Rahmstorf of the alarmist Potsdam Institute blames Florence on global warming, telling the online Potsdamer Nachrichten (PNN) here: “In fact many of the strongest storms we have ever seen have occurred in the past years.”
Alarmist claims go down in flames
The German media and climate science establishment are out in full force implying recent hurricanes are mostly manmade and getting stronger and more frequent.
However, just as Kenneth Richard showed yesterday by presenting more than a dozen recent papers, when we look at the observed data, all these alarmist claims go down in flames.
Observed data refute alarmist/activist scientists
Firstly, climate ambulance chasing scientists, such as Messieurs Stefan Rahmstorf and Dim Coucou, like pretending storms are intensifying due to manmade global warming. Yet two days ago I tweeted a table showing that 75% of the most powerful hurricanes impacting the US actually happened before 1970, a time when CO2 was at supposedly safe levels:

9 of top 12 most powerful hurricanes making landfall in USA HAPPENED BEFORE 1970!! pic.twitter.com/GLR5Ksd8yE
— P Gosselin (@NoTricksZone) September 12, 2018

Although some people may think Florence is a major hurricane, it in fact made landfall as a Category 1 storm only – a far cry from the Category 4 many were warning us about just days ago — e.g. Erik Holthaus.
Hurricane number and strength not up
Prof. Philip Klotzbach recently tweeted two charts depicting the number of US landfalling hurricanes (Category 1-5) and major hurricanes (Category 3-5). If you’re a climate alarmist, then you may want to first take a seat before reading further:



<!--
google_ad_client = ""ca-pub-3545577860068042"";
/* neu test */
google_ad_slot = ""6412247007"";
google_ad_width = 200;
google_ad_height = 200;
//-->




Source: Klotzbach et al 2018
According to Klotzbach, “Since 1900 neither observed CONUS [Continental United States] landfalling hurricane frequency nor intensity show significant trends, including the devastating 2017 season.”
An unprecedented major hurricane absence
What is unprecedented is the long 12-year period from 2005 to 2017 which saw not a single major hurricane hitting the US. This is probably the most devastating and frustrating fact for the global warming ambulance chasers. That’s a glaring statistic that’s impossible to alter.
Western North Pacific cyclone frequency down 25%
The story is much the same in the North Western Pacific, where the following chart shows us cyclone frequency has been much lower over the past two decades compared to the two decades prior.

Source: Zhao et al, 2018
And using the data from the Japanese Meteorological Agency (JMA), skeptic blogger Kirye also tweeted that the number of typhoons being formed has declined modestly over the years:

Number of typhoons on the decline. Source: Kirye.
Hooligan storms
Cyclone bedwetters have even suggested that Florence’s odd track and stall at the Carolina coast is also a sign of climatatic weirding. Yet, weird storm tracks have always occurred and Florence is just run of the mill. For example, check out Typhoon Wayne back in 1986, which ran amok across the Western Pacific like a drunken hooligan:

Source: https://maps.wunderground.com/blog/
Share this...FacebookTwitter "
"
Share this...FacebookTwitterAccording to a new paper published in the Journal of Geophysical Research, the observed mean thickness of the sea ice in the region north of (Arctic) Svalbard was substantially thinner (0.94 m) in 1955 than it has been in recent years (~1.6 m, 2015/2017).

Graph Source: Rösel et al., 2018

In 1955, the atmospheric CO2 concentration hovered around 315 ppm, about 90 ppm lower than today’s CO2 values.
It is widely assumed that the steep and substantial rise in CO2 concentration since the 1950s is largely responsible for warming the Arctic, and consequently the decline in the Arctic’s sea ice volume and extent (IPCC, 2013).  This assumption is significantly predicated on the observation that sea ice has undergone precipitous losses since the 1970s, which is when the satellite era began.
However, longer-term observational data do not appear to support the conclusion that Arctic region sea ice is driven by linear trends in atmospheric CO2 concentration.  Indeed, there is evidence that Arctic sea ice extent was comparable or lower than now in the 1940s and 1950s (for example, see this annotated graph from Gagné et al., 2017).  Several other recently published papers also fail to support a CO2 – Arctic climate connection, as detailed in several articles found here at NoTricksZone during 2018.
1. 20 New Papers Crush Claims Of A Man-Made Link To Arctic Climate Change, Glacier Retreat, Sea Ice
2. Groundbreaking AGW-Undermining Study: Greenland’s Warming, Ice Loss Due To Geothermal Heat
3. Another New Paper Shows Arctic Sea Ice Has Been INCREASING Overall Since The 1930s
4. 12 New Papers Affirm A 21st Century Cessation Of Arctic Warming And A Rapid Cooling Across Antarctica
5.  Arctic Temps 2°-6°C Warmer Than Today With 4.5 Fewer Months Of Sea Ice Coverage 2,000 Years Ago
6.  New ‘Consensus’ Science: HALF Of 1979-Present Arctic Warming & Ice Loss Is Natural
7.  In 2015, Climate Scientists Wrecked Their Own CO2-Forced ‘Polar Amplification’ Narrative
8. Activists Continue To Peddle Unsupportable Claims Of NEVER-BEFORE Climate Alarm, Ignoring New Science
Regional Arctic sea ice was thicker than now in the 1950s?
In another newly published paper, observations from an Arctic region north of Svalbard affirm that sea ice thicknesses were indeed much higher than today during the 1970s, or when the linearly-decreasing sea ice trend documented by satellites (conveniently) commenced.
However, looking closely at Table 3 (shown in the introductory graph above) from the same paper, we see that sea ice thickness values may have been lower in the mid-1950s (0.94 m) than they are today (~1.6 m thicknesses on average).
If sea ice was was thinner than it is now during the same period of time that CO2 concentrations were substantially lower than they are now, this documented observational evidence appears to again undermine the conclusion that CO2 concentration rises are significantly connected to sea ice losses – or to the Arctic climate in general.

Rösel et al., 2018
Thin Sea Ice, Thick Snow, and Widespread Negative
Freeboard Observed During N‐ICE 2015 North of Svalbard
“We present a continuous time series of in situ measurements from the N‐ICE2015 expedition from January to June 2015 in the Arctic Basin north of Svalbard, comprising snow buoy and ice mass balance buoy data and local and regional data gained from electromagnetic induction (EM) surveys and snow probe measurements from four distinct drifts. 
“The observed mean snow depth of 0.53 m for April to early June [2015] is 73% above the average value of 0.30 m from historical [1955, 1970s] and recent observations in this region, covering the years 1955–2017.”
“The modal total ice and snow thicknesses, of 1.6 and 1.7 m [2015] measured with ground‐based EM and airborne EM measurements in April, May, and June 2015, respectively, lie below the [1970s] values ranging from 1.8 to 2.7 m, reported in historical observations from the same region and time of year [but well above the sea-ice thickness values of 0.94 m for 1955].”

Share this...FacebookTwitter "
"As a wildlife veterinarian, I often get asked about bats. I like bats, and I am always eager to talk about how interesting they are. Unfortunately the question is often not about biology but instead “what should I do about the ones in my roof?”.  With some unique talents and remarkable sex lives, bats are actually one of the most interesting, diverse and misunderstood groups of animals. Contrary to popular belief, they are beautiful creatures. Not necessarily in the cuddly, human-like sense – although some fruit bats with doey brown eyes and button noses could be considered so – but they are beautifully designed. This couldn’t be illustrated better than by the discovery of the oldest known complete bat fossil, more than 53 million-years-old yet with a similar wing design to those flying around today. To put it in perspective, 50m years ago our ancestors were still swinging from the trees and would certainly not be recognised as human. But even then bats already had the combination of thin, long forearms and fingers covered by an extremely thin, strong membrane, which allowed them to master the art of powered, agile flight.  Soon afterwards, fossils record another game-changing adaptation in the evolution of most bats, and that is the ability to accurately locate prey using sound (what we call echolocation). These two adaptations early in their history gave bats an evolutionary edge compared to some other mammals, and allowed them to diversify into almost all habitats, on every continent except Antarctica. There are now more than 1,300 different species, divided among 26 different families (compared to fewer than 500 primate species). Indonesia alone has 219 different bat species.  It is not just a quantity though – the variety is astonishing. The thumb-sized bumblebee bat of Thailand is the smallest species, weighing just two grammes. And like other insectivorous bats, it can eat its own body weight in insects every night. At the other end of the scale, some large flying foxes have wingspans of well over a metre and, having lost the ability to echolocate, eat fruit and nectar.  Everyone knows that some bats feed on blood, but despite the “vampire” myth, only three species actually feed on blood. And these haematophagous bats are only found in parts of South America. They also definitely don’t get tangled in your hair. Bats are far too good at flying.   If thus far I haven’t persuaded you to like bats, you must admit that they are useful. Bats defecate while regularly flying very long distances (up to 350km in one night), making them extremely effective at dispersing seeds. Add to that the fact that some fruit bats live in colonies up to 1m strong, and you can start to imagine their impact. So much so, they have been proven key in reforestation.  Another unappreciated and major role is as pest controllers. The sheer volume of insects that some bats species can eat makes them very effective at suppressing pest insects. Bats reduce the nuisance and disease threat of mosquitoes, and it has been estimated they save the US economy at least $3.7 billion every year through increased crop productivity and reduction of pesticide usage. Despite their ancient design, they show some remarkable talents. One of these is shared only by several select animals. Bats are vocal learners – able to learn and then imitate sounds even in adulthood. This is likely important for the development of the complex social organisation seen in many bat species. Most surprising of all is the recent revelation that they are also members of an even more exclusive and less salubrious club: animals known to partake in fellatio during copulation. Bats have had some bad press recently due to their association with infectious diseases, from rabies to Ebola. And they appear able to tolerate some viruses fatal to other species. If anything, that illustrates again why they should be respected, especially as various bat species are also endangered and therefore protected by law in many regions. So my response to those interested in what to do about the bats in their roof? Leave them alone."
